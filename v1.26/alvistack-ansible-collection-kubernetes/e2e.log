I0423 11:12:44.846909      13 e2e.go:126] Starting e2e run "1de117d5-5b32-4f50-b9f3-5af11d500051" on Ginkgo node 1
Apr 23 11:12:44.884: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1682248364 - will randomize all specs

Will run 368 of 7069 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:77
Apr 23 11:12:45.116: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:12:45.126: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 23 11:12:45.159: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 23 11:12:45.231: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 23 11:12:45.231: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Apr 23 11:12:45.231: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 23 11:12:45.255: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'cilium' (0 seconds elapsed)
Apr 23 11:12:45.255: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'cilium-node-init' (0 seconds elapsed)
Apr 23 11:12:45.255: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 23 11:12:45.255: INFO: e2e test version: v1.26.4
Apr 23 11:12:45.262: INFO: kube-apiserver version: v1.26.4
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:77
Apr 23 11:12:45.262: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:12:45.275: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.159 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:77
    Apr 23 11:12:45.116: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:12:45.126: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Apr 23 11:12:45.159: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Apr 23 11:12:45.231: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Apr 23 11:12:45.231: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
    Apr 23 11:12:45.231: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Apr 23 11:12:45.255: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'cilium' (0 seconds elapsed)
    Apr 23 11:12:45.255: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'cilium-node-init' (0 seconds elapsed)
    Apr 23 11:12:45.255: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
    Apr 23 11:12:45.255: INFO: e2e test version: v1.26.4
    Apr 23 11:12:45.262: INFO: kube-apiserver version: v1.26.4
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:77
    Apr 23 11:12:45.262: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:12:45.275: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:78
[BeforeEach] [sig-storage] Projected secret
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:12:45.34
Apr 23 11:12:45.340: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:12:45.342
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:12:45.377
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:12:45.381
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:78
STEP: Creating projection with secret that has name projected-secret-test-map-ce47fa48-7e06-4614-9918-f7d7fd734344 04/23/23 11:12:45.387
STEP: Creating a pod to test consume secrets 04/23/23 11:12:45.397
Apr 23 11:12:45.414: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41" in namespace "projected-5087" to be "Succeeded or Failed"
Apr 23 11:12:45.430: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 15.930668ms
Apr 23 11:12:47.437: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023190648s
Apr 23 11:12:49.442: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027915979s
Apr 23 11:12:51.437: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023117365s
Apr 23 11:12:53.439: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024513164s
Apr 23 11:12:55.437: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 10.02265419s
Apr 23 11:12:57.437: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 12.023334681s
Apr 23 11:12:59.437: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 14.023178349s
Apr 23 11:13:01.442: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 16.027922005s
Apr 23 11:13:03.441: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 18.026451448s
Apr 23 11:13:05.436: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Succeeded", Reason="", readiness=false. Elapsed: 20.022218165s
STEP: Saw pod success 04/23/23 11:13:05.437
Apr 23 11:13:05.438: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41" satisfied condition "Succeeded or Failed"
Apr 23 11:13:05.446: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/23/23 11:13:05.484
Apr 23 11:13:05.509: INFO: Waiting for pod pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41 to disappear
Apr 23 11:13:05.519: INFO: Pod pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/node/init/init.go:32
Apr 23 11:13:05.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected secret
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected secret
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-5087" for this suite. 04/23/23 11:13:05.53
------------------------------
â€¢ [SLOW TEST] [20.201 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:12:45.34
    Apr 23 11:12:45.340: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:12:45.342
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:12:45.377
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:12:45.381
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:78
    STEP: Creating projection with secret that has name projected-secret-test-map-ce47fa48-7e06-4614-9918-f7d7fd734344 04/23/23 11:12:45.387
    STEP: Creating a pod to test consume secrets 04/23/23 11:12:45.397
    Apr 23 11:12:45.414: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41" in namespace "projected-5087" to be "Succeeded or Failed"
    Apr 23 11:12:45.430: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 15.930668ms
    Apr 23 11:12:47.437: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023190648s
    Apr 23 11:12:49.442: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027915979s
    Apr 23 11:12:51.437: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023117365s
    Apr 23 11:12:53.439: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024513164s
    Apr 23 11:12:55.437: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 10.02265419s
    Apr 23 11:12:57.437: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 12.023334681s
    Apr 23 11:12:59.437: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 14.023178349s
    Apr 23 11:13:01.442: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 16.027922005s
    Apr 23 11:13:03.441: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Pending", Reason="", readiness=false. Elapsed: 18.026451448s
    Apr 23 11:13:05.436: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41": Phase="Succeeded", Reason="", readiness=false. Elapsed: 20.022218165s
    STEP: Saw pod success 04/23/23 11:13:05.437
    Apr 23 11:13:05.438: INFO: Pod "pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41" satisfied condition "Succeeded or Failed"
    Apr 23 11:13:05.446: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/23/23 11:13:05.484
    Apr 23 11:13:05.509: INFO: Waiting for pod pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41 to disappear
    Apr 23 11:13:05.519: INFO: Pod pod-projected-secrets-ce3c192f-59d3-4595-b51c-e53cc74d6a41 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:13:05.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected secret
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected secret
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-5087" for this suite. 04/23/23 11:13:05.53
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2191
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:13:05.553
Apr 23 11:13:05.553: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 11:13:05.556
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:13:05.586
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:13:05.596
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2191
STEP: creating service in namespace services-739 04/23/23 11:13:05.601
STEP: creating service affinity-clusterip in namespace services-739 04/23/23 11:13:05.601
STEP: creating replication controller affinity-clusterip in namespace services-739 04/23/23 11:13:05.63
I0423 11:13:05.653750      13 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-739, replica count: 3
I0423 11:13:08.705183      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:13:11.705495      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:13:14.706839      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:13:17.707469      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:13:20.707937      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:13:23.708941      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:13:26.709881      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:13:29.710385      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:13:32.712706      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:13:35.713004      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:13:38.713293      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:13:41.715131      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 23 11:13:41.731: INFO: Creating new exec pod
Apr 23 11:13:41.752: INFO: Waiting up to 5m0s for pod "execpod-affinitywtl67" in namespace "services-739" to be "running"
Apr 23 11:13:41.762: INFO: Pod "execpod-affinitywtl67": Phase="Pending", Reason="", readiness=false. Elapsed: 9.368405ms
Apr 23 11:13:43.772: INFO: Pod "execpod-affinitywtl67": Phase="Running", Reason="", readiness=true. Elapsed: 2.019363841s
Apr 23 11:13:43.772: INFO: Pod "execpod-affinitywtl67" satisfied condition "running"
Apr 23 11:13:44.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-739 exec execpod-affinitywtl67 -- /bin/sh -x -c nc -v -z -w 2 affinity-clusterip 80'
Apr 23 11:13:45.325: INFO: stderr: "+ nc -v -z -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Apr 23 11:13:45.325: INFO: stdout: ""
Apr 23 11:13:45.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-739 exec execpod-affinitywtl67 -- /bin/sh -x -c nc -v -z -w 2 10.233.49.75 80'
Apr 23 11:13:45.627: INFO: stderr: "+ nc -v -z -w 2 10.233.49.75 80\nConnection to 10.233.49.75 80 port [tcp/http] succeeded!\n"
Apr 23 11:13:45.627: INFO: stdout: ""
Apr 23 11:13:45.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-739 exec execpod-affinitywtl67 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.49.75:80/ ; done'
Apr 23 11:13:46.094: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n"
Apr 23 11:13:46.094: INFO: stdout: "\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s"
Apr 23 11:13:46.094: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.094: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.094: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.094: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.094: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
Apr 23 11:13:46.095: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-739, will wait for the garbage collector to delete the pods 04/23/23 11:13:46.181
Apr 23 11:13:46.258: INFO: Deleting ReplicationController affinity-clusterip took: 19.11597ms
Apr 23 11:13:46.458: INFO: Terminating ReplicationController affinity-clusterip pods took: 200.424093ms
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 11:13:48.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-739" for this suite. 04/23/23 11:13:48.72
------------------------------
â€¢ [SLOW TEST] [43.179 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:13:05.553
    Apr 23 11:13:05.553: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 11:13:05.556
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:13:05.586
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:13:05.596
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2191
    STEP: creating service in namespace services-739 04/23/23 11:13:05.601
    STEP: creating service affinity-clusterip in namespace services-739 04/23/23 11:13:05.601
    STEP: creating replication controller affinity-clusterip in namespace services-739 04/23/23 11:13:05.63
    I0423 11:13:05.653750      13 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-739, replica count: 3
    I0423 11:13:08.705183      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:13:11.705495      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:13:14.706839      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:13:17.707469      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:13:20.707937      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:13:23.708941      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:13:26.709881      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:13:29.710385      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:13:32.712706      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:13:35.713004      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:13:38.713293      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:13:41.715131      13 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 23 11:13:41.731: INFO: Creating new exec pod
    Apr 23 11:13:41.752: INFO: Waiting up to 5m0s for pod "execpod-affinitywtl67" in namespace "services-739" to be "running"
    Apr 23 11:13:41.762: INFO: Pod "execpod-affinitywtl67": Phase="Pending", Reason="", readiness=false. Elapsed: 9.368405ms
    Apr 23 11:13:43.772: INFO: Pod "execpod-affinitywtl67": Phase="Running", Reason="", readiness=true. Elapsed: 2.019363841s
    Apr 23 11:13:43.772: INFO: Pod "execpod-affinitywtl67" satisfied condition "running"
    Apr 23 11:13:44.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-739 exec execpod-affinitywtl67 -- /bin/sh -x -c nc -v -z -w 2 affinity-clusterip 80'
    Apr 23 11:13:45.325: INFO: stderr: "+ nc -v -z -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Apr 23 11:13:45.325: INFO: stdout: ""
    Apr 23 11:13:45.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-739 exec execpod-affinitywtl67 -- /bin/sh -x -c nc -v -z -w 2 10.233.49.75 80'
    Apr 23 11:13:45.627: INFO: stderr: "+ nc -v -z -w 2 10.233.49.75 80\nConnection to 10.233.49.75 80 port [tcp/http] succeeded!\n"
    Apr 23 11:13:45.627: INFO: stdout: ""
    Apr 23 11:13:45.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-739 exec execpod-affinitywtl67 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.49.75:80/ ; done'
    Apr 23 11:13:46.094: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.49.75:80/\n"
    Apr 23 11:13:46.094: INFO: stdout: "\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s\naffinity-clusterip-w9p9s"
    Apr 23 11:13:46.094: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.094: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.094: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.094: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.094: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.095: INFO: Received response from host: affinity-clusterip-w9p9s
    Apr 23 11:13:46.095: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-739, will wait for the garbage collector to delete the pods 04/23/23 11:13:46.181
    Apr 23 11:13:46.258: INFO: Deleting ReplicationController affinity-clusterip took: 19.11597ms
    Apr 23 11:13:46.458: INFO: Terminating ReplicationController affinity-clusterip pods took: 200.424093ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:13:48.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-739" for this suite. 04/23/23 11:13:48.72
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:13:48.749
Apr 23 11:13:48.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename svc-latency 04/23/23 11:13:48.753
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:13:48.796
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:13:48.804
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/metrics/init/init.go:31
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Apr 23 11:13:48.815: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8999 04/23/23 11:13:48.819
I0423 11:13:48.839003      13 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8999, replica count: 1
I0423 11:13:49.894222      13 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:13:50.894691      13 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:13:51.895723      13 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 23 11:13:52.019: INFO: Created: latency-svc-7hhnl
Apr 23 11:13:52.028: INFO: Got endpoints: latency-svc-7hhnl [31.327275ms]
Apr 23 11:13:52.060: INFO: Created: latency-svc-l52nq
Apr 23 11:13:52.072: INFO: Got endpoints: latency-svc-l52nq [42.645056ms]
Apr 23 11:13:52.081: INFO: Created: latency-svc-h2jdh
Apr 23 11:13:52.088: INFO: Created: latency-svc-crzbz
Apr 23 11:13:52.099: INFO: Created: latency-svc-248vk
Apr 23 11:13:52.105: INFO: Got endpoints: latency-svc-h2jdh [75.370488ms]
Apr 23 11:13:52.119: INFO: Got endpoints: latency-svc-248vk [86.840648ms]
Apr 23 11:13:52.119: INFO: Got endpoints: latency-svc-crzbz [87.581045ms]
Apr 23 11:13:52.139: INFO: Created: latency-svc-2vgfm
Apr 23 11:13:52.147: INFO: Created: latency-svc-sd98n
Apr 23 11:13:52.164: INFO: Got endpoints: latency-svc-2vgfm [131.957344ms]
Apr 23 11:13:52.167: INFO: Got endpoints: latency-svc-sd98n [134.337879ms]
Apr 23 11:13:52.170: INFO: Created: latency-svc-hts8b
Apr 23 11:13:52.183: INFO: Created: latency-svc-bl46p
Apr 23 11:13:52.190: INFO: Got endpoints: latency-svc-hts8b [156.96365ms]
Apr 23 11:13:52.205: INFO: Got endpoints: latency-svc-bl46p [172.885841ms]
Apr 23 11:13:52.207: INFO: Created: latency-svc-8xhjh
Apr 23 11:13:52.223: INFO: Created: latency-svc-rjnb8
Apr 23 11:13:52.227: INFO: Got endpoints: latency-svc-8xhjh [193.035859ms]
Apr 23 11:13:52.232: INFO: Created: latency-svc-pv5bg
Apr 23 11:13:52.268: INFO: Created: latency-svc-phxs8
Apr 23 11:13:52.280: INFO: Got endpoints: latency-svc-pv5bg [245.612548ms]
Apr 23 11:13:52.280: INFO: Got endpoints: latency-svc-rjnb8 [246.102596ms]
Apr 23 11:13:52.292: INFO: Created: latency-svc-84sh4
Apr 23 11:13:52.305: INFO: Got endpoints: latency-svc-phxs8 [270.905678ms]
Apr 23 11:13:52.307: INFO: Got endpoints: latency-svc-84sh4 [272.316486ms]
Apr 23 11:13:52.314: INFO: Created: latency-svc-p74zk
Apr 23 11:13:52.330: INFO: Created: latency-svc-5gxdl
Apr 23 11:13:52.333: INFO: Got endpoints: latency-svc-p74zk [298.763433ms]
Apr 23 11:13:52.347: INFO: Created: latency-svc-v9257
Apr 23 11:13:52.349: INFO: Got endpoints: latency-svc-5gxdl [314.498041ms]
Apr 23 11:13:52.392: INFO: Got endpoints: latency-svc-v9257 [318.807567ms]
Apr 23 11:13:52.404: INFO: Created: latency-svc-5cmqz
Apr 23 11:13:52.407: INFO: Created: latency-svc-rw4pg
Apr 23 11:13:52.424: INFO: Created: latency-svc-cbdwl
Apr 23 11:13:52.445: INFO: Got endpoints: latency-svc-cbdwl [325.656304ms]
Apr 23 11:13:52.446: INFO: Got endpoints: latency-svc-rw4pg [326.662009ms]
Apr 23 11:13:52.447: INFO: Got endpoints: latency-svc-5cmqz [341.420881ms]
Apr 23 11:13:52.463: INFO: Created: latency-svc-bqd6d
Apr 23 11:13:52.471: INFO: Got endpoints: latency-svc-bqd6d [303.925847ms]
Apr 23 11:13:52.514: INFO: Created: latency-svc-p6w5p
Apr 23 11:13:52.527: INFO: Got endpoints: latency-svc-p6w5p [358.081694ms]
Apr 23 11:13:52.537: INFO: Created: latency-svc-nqtlt
Apr 23 11:13:52.550: INFO: Got endpoints: latency-svc-nqtlt [353.939878ms]
Apr 23 11:13:52.581: INFO: Created: latency-svc-cj258
Apr 23 11:13:52.590: INFO: Got endpoints: latency-svc-cj258 [384.550259ms]
Apr 23 11:13:52.602: INFO: Created: latency-svc-sxz24
Apr 23 11:13:52.614: INFO: Created: latency-svc-2dkxx
Apr 23 11:13:52.619: INFO: Got endpoints: latency-svc-sxz24 [391.901512ms]
Apr 23 11:13:52.635: INFO: Got endpoints: latency-svc-2dkxx [352.663925ms]
Apr 23 11:13:52.640: INFO: Created: latency-svc-wqlc4
Apr 23 11:13:52.651: INFO: Got endpoints: latency-svc-wqlc4 [367.402481ms]
Apr 23 11:13:52.659: INFO: Created: latency-svc-8b6w6
Apr 23 11:13:52.669: INFO: Got endpoints: latency-svc-8b6w6 [360.458672ms]
Apr 23 11:13:52.672: INFO: Created: latency-svc-qfqvz
Apr 23 11:13:52.680: INFO: Got endpoints: latency-svc-qfqvz [373.097432ms]
Apr 23 11:13:52.704: INFO: Created: latency-svc-272bj
Apr 23 11:13:52.714: INFO: Created: latency-svc-gmd4g
Apr 23 11:13:52.718: INFO: Got endpoints: latency-svc-272bj [384.798666ms]
Apr 23 11:13:52.733: INFO: Got endpoints: latency-svc-gmd4g [383.610199ms]
Apr 23 11:13:52.737: INFO: Created: latency-svc-6qpmj
Apr 23 11:13:52.751: INFO: Created: latency-svc-pf7l9
Apr 23 11:13:52.757: INFO: Got endpoints: latency-svc-6qpmj [365.740141ms]
Apr 23 11:13:52.765: INFO: Got endpoints: latency-svc-pf7l9 [320.243602ms]
Apr 23 11:13:52.769: INFO: Created: latency-svc-bhfgr
Apr 23 11:13:52.780: INFO: Created: latency-svc-gsckg
Apr 23 11:13:52.789: INFO: Got endpoints: latency-svc-bhfgr [342.945242ms]
Apr 23 11:13:52.813: INFO: Got endpoints: latency-svc-gsckg [365.408579ms]
Apr 23 11:13:52.814: INFO: Created: latency-svc-p55dt
Apr 23 11:13:52.825: INFO: Got endpoints: latency-svc-p55dt [353.650782ms]
Apr 23 11:13:52.832: INFO: Created: latency-svc-smbb5
Apr 23 11:13:52.844: INFO: Got endpoints: latency-svc-smbb5 [316.52055ms]
Apr 23 11:13:52.852: INFO: Created: latency-svc-rlpp4
Apr 23 11:13:52.882: INFO: Created: latency-svc-t2rm7
Apr 23 11:13:52.883: INFO: Got endpoints: latency-svc-rlpp4 [333.043856ms]
Apr 23 11:13:52.898: INFO: Got endpoints: latency-svc-t2rm7 [307.616728ms]
Apr 23 11:13:52.902: INFO: Created: latency-svc-thf86
Apr 23 11:13:52.919: INFO: Got endpoints: latency-svc-thf86 [300.022479ms]
Apr 23 11:13:52.919: INFO: Created: latency-svc-vgz9d
Apr 23 11:13:52.945: INFO: Created: latency-svc-jtwx6
Apr 23 11:13:52.949: INFO: Got endpoints: latency-svc-vgz9d [314.17277ms]
Apr 23 11:13:52.956: INFO: Created: latency-svc-pc5l9
Apr 23 11:13:52.960: INFO: Got endpoints: latency-svc-jtwx6 [309.156156ms]
Apr 23 11:13:52.981: INFO: Created: latency-svc-dgc4g
Apr 23 11:13:52.982: INFO: Got endpoints: latency-svc-pc5l9 [312.902768ms]
Apr 23 11:13:52.994: INFO: Got endpoints: latency-svc-dgc4g [314.17006ms]
Apr 23 11:13:53.135: INFO: Created: latency-svc-mpq6t
Apr 23 11:13:53.136: INFO: Created: latency-svc-z2fzl
Apr 23 11:13:53.154: INFO: Created: latency-svc-2c9fq
Apr 23 11:13:53.156: INFO: Created: latency-svc-pm5qr
Apr 23 11:13:53.157: INFO: Created: latency-svc-cjvzt
Apr 23 11:13:53.159: INFO: Created: latency-svc-7hfdr
Apr 23 11:13:53.160: INFO: Created: latency-svc-6h884
Apr 23 11:13:53.161: INFO: Created: latency-svc-qddws
Apr 23 11:13:53.161: INFO: Created: latency-svc-xb4nh
Apr 23 11:13:53.165: INFO: Created: latency-svc-fv7zv
Apr 23 11:13:53.166: INFO: Created: latency-svc-gncxp
Apr 23 11:13:53.169: INFO: Created: latency-svc-tscbx
Apr 23 11:13:53.176: INFO: Got endpoints: latency-svc-mpq6t [350.609945ms]
Apr 23 11:13:53.176: INFO: Got endpoints: latency-svc-z2fzl [418.881392ms]
Apr 23 11:13:53.187: INFO: Created: latency-svc-s8krj
Apr 23 11:13:53.207: INFO: Created: latency-svc-wsgd8
Apr 23 11:13:53.207: INFO: Got endpoints: latency-svc-fv7zv [324.125705ms]
Apr 23 11:13:53.208: INFO: Created: latency-svc-shbp9
Apr 23 11:13:53.213: INFO: Got endpoints: latency-svc-tscbx [400.087679ms]
Apr 23 11:13:53.242: INFO: Created: latency-svc-x9vqv
Apr 23 11:13:53.245: INFO: Got endpoints: latency-svc-gncxp [295.660714ms]
Apr 23 11:13:53.245: INFO: Got endpoints: latency-svc-pm5qr [250.393599ms]
Apr 23 11:13:53.269: INFO: Got endpoints: latency-svc-xb4nh [535.538086ms]
Apr 23 11:13:53.270: INFO: Got endpoints: latency-svc-cjvzt [504.648342ms]
Apr 23 11:13:53.270: INFO: Got endpoints: latency-svc-7hfdr [481.722166ms]
Apr 23 11:13:53.280: INFO: Got endpoints: latency-svc-6h884 [319.885218ms]
Apr 23 11:13:53.289: INFO: Got endpoints: latency-svc-2c9fq [444.622915ms]
Apr 23 11:13:53.334: INFO: Got endpoints: latency-svc-wsgd8 [415.600889ms]
Apr 23 11:13:53.417: INFO: Created: latency-svc-xbkld
Apr 23 11:13:53.417: INFO: Created: latency-svc-x5q8h
Apr 23 11:13:53.419: INFO: Created: latency-svc-qjjk2
Apr 23 11:13:53.419: INFO: Created: latency-svc-2bwkn
Apr 23 11:13:53.419: INFO: Created: latency-svc-fzxkz
Apr 23 11:13:53.419: INFO: Created: latency-svc-hnrhp
Apr 23 11:13:53.420: INFO: Created: latency-svc-4pphc
Apr 23 11:13:53.420: INFO: Created: latency-svc-f4rgt
Apr 23 11:13:53.418: INFO: Got endpoints: latency-svc-shbp9 [520.418271ms]
Apr 23 11:13:53.428: INFO: Created: latency-svc-lp4r8
Apr 23 11:13:53.428: INFO: Created: latency-svc-tdfvc
Apr 23 11:13:53.433: INFO: Created: latency-svc-jhqdw
Apr 23 11:13:53.445: INFO: Got endpoints: latency-svc-s8krj [463.219553ms]
Apr 23 11:13:53.487: INFO: Created: latency-svc-c5h6q
Apr 23 11:13:53.487: INFO: Created: latency-svc-kzlmr
Apr 23 11:13:53.489: INFO: Got endpoints: latency-svc-qddws [770.470387ms]
Apr 23 11:13:53.508: INFO: Created: latency-svc-lgqp4
Apr 23 11:13:53.538: INFO: Got endpoints: latency-svc-x9vqv [361.053639ms]
Apr 23 11:13:53.580: INFO: Created: latency-svc-t9shm
Apr 23 11:13:53.595: INFO: Got endpoints: latency-svc-xbkld [323.477525ms]
Apr 23 11:13:53.638: INFO: Got endpoints: latency-svc-4pphc [430.863729ms]
Apr 23 11:13:53.640: INFO: Created: latency-svc-fjz6r
Apr 23 11:13:53.654: INFO: Created: latency-svc-pft7m
Apr 23 11:13:53.672: INFO: Got endpoints: latency-svc-x5q8h [391.492704ms]
Apr 23 11:13:53.699: INFO: Created: latency-svc-h7zzj
Apr 23 11:13:53.733: INFO: Got endpoints: latency-svc-qjjk2 [443.528705ms]
Apr 23 11:13:53.765: INFO: Created: latency-svc-gx4jr
Apr 23 11:13:53.782: INFO: Got endpoints: latency-svc-f4rgt [605.910061ms]
Apr 23 11:13:53.825: INFO: Created: latency-svc-mt9fq
Apr 23 11:13:53.831: INFO: Got endpoints: latency-svc-fzxkz [586.399515ms]
Apr 23 11:13:53.863: INFO: Created: latency-svc-8dsg2
Apr 23 11:13:53.878: INFO: Got endpoints: latency-svc-hnrhp [664.629871ms]
Apr 23 11:13:53.909: INFO: Created: latency-svc-28frv
Apr 23 11:13:53.934: INFO: Got endpoints: latency-svc-2bwkn [663.440729ms]
Apr 23 11:13:53.966: INFO: Created: latency-svc-hphfd
Apr 23 11:13:53.982: INFO: Got endpoints: latency-svc-lp4r8 [737.156135ms]
Apr 23 11:13:54.017: INFO: Created: latency-svc-7jbwm
Apr 23 11:13:54.045: INFO: Got endpoints: latency-svc-tdfvc [775.886654ms]
Apr 23 11:13:54.111: INFO: Created: latency-svc-4lfl4
Apr 23 11:13:54.111: INFO: Got endpoints: latency-svc-jhqdw [776.588583ms]
Apr 23 11:13:54.199: INFO: Got endpoints: latency-svc-c5h6q [778.402497ms]
Apr 23 11:13:54.222: INFO: Got endpoints: latency-svc-kzlmr [775.756761ms]
Apr 23 11:13:54.241: INFO: Created: latency-svc-r4hxf
Apr 23 11:13:54.249: INFO: Got endpoints: latency-svc-lgqp4 [759.639536ms]
Apr 23 11:13:54.257: INFO: Created: latency-svc-gdrtz
Apr 23 11:13:54.270: INFO: Created: latency-svc-52c6h
Apr 23 11:13:54.283: INFO: Got endpoints: latency-svc-t9shm [744.843905ms]
Apr 23 11:13:54.284: INFO: Created: latency-svc-pbpt2
Apr 23 11:13:54.316: INFO: Created: latency-svc-qqnc9
Apr 23 11:13:54.340: INFO: Got endpoints: latency-svc-fjz6r [745.113338ms]
Apr 23 11:13:54.368: INFO: Created: latency-svc-5zfnq
Apr 23 11:13:54.379: INFO: Got endpoints: latency-svc-pft7m [741.173563ms]
Apr 23 11:13:54.405: INFO: Created: latency-svc-tbrv8
Apr 23 11:13:54.445: INFO: Got endpoints: latency-svc-h7zzj [773.042454ms]
Apr 23 11:13:54.466: INFO: Created: latency-svc-hh4gv
Apr 23 11:13:54.477: INFO: Got endpoints: latency-svc-gx4jr [744.014252ms]
Apr 23 11:13:54.510: INFO: Created: latency-svc-tj7hw
Apr 23 11:13:54.564: INFO: Got endpoints: latency-svc-mt9fq [781.610189ms]
Apr 23 11:13:54.592: INFO: Got endpoints: latency-svc-8dsg2 [760.653627ms]
Apr 23 11:13:54.613: INFO: Created: latency-svc-8z6zd
Apr 23 11:13:54.632: INFO: Created: latency-svc-92jrp
Apr 23 11:13:54.641: INFO: Got endpoints: latency-svc-28frv [762.359062ms]
Apr 23 11:13:54.667: INFO: Created: latency-svc-57tf7
Apr 23 11:13:54.680: INFO: Got endpoints: latency-svc-hphfd [746.247439ms]
Apr 23 11:13:54.704: INFO: Created: latency-svc-mn9fr
Apr 23 11:13:54.722: INFO: Got endpoints: latency-svc-7jbwm [740.108564ms]
Apr 23 11:13:54.745: INFO: Created: latency-svc-2lphf
Apr 23 11:13:54.778: INFO: Got endpoints: latency-svc-4lfl4 [732.555472ms]
Apr 23 11:13:54.795: INFO: Created: latency-svc-45pl8
Apr 23 11:13:54.828: INFO: Got endpoints: latency-svc-r4hxf [716.721977ms]
Apr 23 11:13:54.847: INFO: Created: latency-svc-rwggv
Apr 23 11:13:54.877: INFO: Got endpoints: latency-svc-gdrtz [677.930549ms]
Apr 23 11:13:54.894: INFO: Created: latency-svc-hfd6h
Apr 23 11:13:54.923: INFO: Got endpoints: latency-svc-52c6h [701.248049ms]
Apr 23 11:13:54.946: INFO: Created: latency-svc-hhntd
Apr 23 11:13:54.978: INFO: Got endpoints: latency-svc-pbpt2 [728.637015ms]
Apr 23 11:13:55.001: INFO: Created: latency-svc-bk7bs
Apr 23 11:13:55.034: INFO: Got endpoints: latency-svc-qqnc9 [750.649785ms]
Apr 23 11:13:55.061: INFO: Created: latency-svc-7bz6k
Apr 23 11:13:55.089: INFO: Got endpoints: latency-svc-5zfnq [747.382928ms]
Apr 23 11:13:55.121: INFO: Created: latency-svc-kh5g8
Apr 23 11:13:55.143: INFO: Got endpoints: latency-svc-tbrv8 [763.364852ms]
Apr 23 11:13:55.184: INFO: Got endpoints: latency-svc-hh4gv [738.754488ms]
Apr 23 11:13:55.205: INFO: Created: latency-svc-pgw7r
Apr 23 11:13:55.234: INFO: Created: latency-svc-6kx7z
Apr 23 11:13:55.248: INFO: Got endpoints: latency-svc-tj7hw [770.847221ms]
Apr 23 11:13:55.282: INFO: Got endpoints: latency-svc-8z6zd [717.084414ms]
Apr 23 11:13:55.354: INFO: Created: latency-svc-9cfbn
Apr 23 11:13:55.384: INFO: Got endpoints: latency-svc-92jrp [791.230877ms]
Apr 23 11:13:55.402: INFO: Got endpoints: latency-svc-57tf7 [761.036235ms]
Apr 23 11:13:55.402: INFO: Created: latency-svc-6v4d2
Apr 23 11:13:55.436: INFO: Got endpoints: latency-svc-mn9fr [755.454456ms]
Apr 23 11:13:55.444: INFO: Created: latency-svc-69gpn
Apr 23 11:13:55.452: INFO: Created: latency-svc-bqgqt
Apr 23 11:13:55.464: INFO: Created: latency-svc-xq9kv
Apr 23 11:13:55.552: INFO: Got endpoints: latency-svc-2lphf [829.994174ms]
Apr 23 11:13:55.552: INFO: Got endpoints: latency-svc-45pl8 [774.655377ms]
Apr 23 11:13:55.583: INFO: Got endpoints: latency-svc-rwggv [754.720143ms]
Apr 23 11:13:55.602: INFO: Created: latency-svc-69zxg
Apr 23 11:13:55.620: INFO: Created: latency-svc-qskmj
Apr 23 11:13:55.636: INFO: Got endpoints: latency-svc-hfd6h [759.169168ms]
Apr 23 11:13:55.637: INFO: Created: latency-svc-hmtgz
Apr 23 11:13:55.695: INFO: Got endpoints: latency-svc-hhntd [771.658345ms]
Apr 23 11:13:55.707: INFO: Created: latency-svc-f2jl7
Apr 23 11:13:55.733: INFO: Got endpoints: latency-svc-bk7bs [754.333423ms]
Apr 23 11:13:55.744: INFO: Created: latency-svc-8gx97
Apr 23 11:13:55.758: INFO: Created: latency-svc-w4x87
Apr 23 11:13:55.777: INFO: Got endpoints: latency-svc-7bz6k [743.596848ms]
Apr 23 11:13:55.814: INFO: Created: latency-svc-jzbhr
Apr 23 11:13:55.831: INFO: Got endpoints: latency-svc-kh5g8 [741.471334ms]
Apr 23 11:13:55.859: INFO: Created: latency-svc-7qn6d
Apr 23 11:13:55.881: INFO: Got endpoints: latency-svc-pgw7r [737.743728ms]
Apr 23 11:13:55.930: INFO: Created: latency-svc-q269g
Apr 23 11:13:55.934: INFO: Got endpoints: latency-svc-6kx7z [749.756031ms]
Apr 23 11:13:55.963: INFO: Created: latency-svc-phpcl
Apr 23 11:13:55.973: INFO: Got endpoints: latency-svc-9cfbn [725.429168ms]
Apr 23 11:13:55.993: INFO: Created: latency-svc-f8lf7
Apr 23 11:13:56.026: INFO: Got endpoints: latency-svc-6v4d2 [743.337803ms]
Apr 23 11:13:56.042: INFO: Created: latency-svc-r22vr
Apr 23 11:13:56.075: INFO: Got endpoints: latency-svc-69gpn [691.142913ms]
Apr 23 11:13:56.099: INFO: Created: latency-svc-xcxfp
Apr 23 11:13:56.129: INFO: Got endpoints: latency-svc-bqgqt [726.875252ms]
Apr 23 11:13:56.151: INFO: Created: latency-svc-khv2c
Apr 23 11:13:56.185: INFO: Got endpoints: latency-svc-xq9kv [748.843929ms]
Apr 23 11:13:56.235: INFO: Got endpoints: latency-svc-69zxg [681.961823ms]
Apr 23 11:13:56.247: INFO: Created: latency-svc-9bxsv
Apr 23 11:13:56.282: INFO: Got endpoints: latency-svc-qskmj [729.604173ms]
Apr 23 11:13:56.287: INFO: Created: latency-svc-bq4xk
Apr 23 11:13:56.301: INFO: Created: latency-svc-zhkm7
Apr 23 11:13:56.329: INFO: Got endpoints: latency-svc-hmtgz [745.933859ms]
Apr 23 11:13:56.346: INFO: Created: latency-svc-j9wfz
Apr 23 11:13:56.382: INFO: Got endpoints: latency-svc-f2jl7 [745.597981ms]
Apr 23 11:13:56.406: INFO: Created: latency-svc-fbhsw
Apr 23 11:13:56.442: INFO: Got endpoints: latency-svc-8gx97 [747.052356ms]
Apr 23 11:13:56.493: INFO: Created: latency-svc-kf8qx
Apr 23 11:13:56.501: INFO: Got endpoints: latency-svc-w4x87 [768.178153ms]
Apr 23 11:13:56.523: INFO: Created: latency-svc-z72xc
Apr 23 11:13:56.530: INFO: Got endpoints: latency-svc-jzbhr [752.653079ms]
Apr 23 11:13:56.578: INFO: Created: latency-svc-gpmz4
Apr 23 11:13:56.585: INFO: Got endpoints: latency-svc-7qn6d [754.229762ms]
Apr 23 11:13:56.607: INFO: Created: latency-svc-x6fps
Apr 23 11:13:56.629: INFO: Got endpoints: latency-svc-q269g [748.309012ms]
Apr 23 11:13:56.648: INFO: Created: latency-svc-lqk6m
Apr 23 11:13:56.674: INFO: Got endpoints: latency-svc-phpcl [739.516112ms]
Apr 23 11:13:56.697: INFO: Created: latency-svc-72plr
Apr 23 11:13:56.729: INFO: Got endpoints: latency-svc-f8lf7 [755.040924ms]
Apr 23 11:13:56.749: INFO: Created: latency-svc-hb65r
Apr 23 11:13:56.774: INFO: Got endpoints: latency-svc-r22vr [748.083936ms]
Apr 23 11:13:56.793: INFO: Created: latency-svc-z7jms
Apr 23 11:13:56.832: INFO: Got endpoints: latency-svc-xcxfp [757.370618ms]
Apr 23 11:13:56.853: INFO: Created: latency-svc-tvwgk
Apr 23 11:13:56.881: INFO: Got endpoints: latency-svc-khv2c [752.10377ms]
Apr 23 11:13:56.903: INFO: Created: latency-svc-t4qdl
Apr 23 11:13:56.927: INFO: Got endpoints: latency-svc-9bxsv [742.144668ms]
Apr 23 11:13:56.954: INFO: Created: latency-svc-dnsfm
Apr 23 11:13:56.979: INFO: Got endpoints: latency-svc-bq4xk [734.099209ms]
Apr 23 11:13:57.013: INFO: Created: latency-svc-hl82b
Apr 23 11:13:57.032: INFO: Got endpoints: latency-svc-zhkm7 [749.556436ms]
Apr 23 11:13:57.066: INFO: Created: latency-svc-8v9lm
Apr 23 11:13:57.081: INFO: Got endpoints: latency-svc-j9wfz [752.090193ms]
Apr 23 11:13:57.099: INFO: Created: latency-svc-dpl66
Apr 23 11:13:57.127: INFO: Got endpoints: latency-svc-fbhsw [745.306925ms]
Apr 23 11:13:57.160: INFO: Created: latency-svc-h8n68
Apr 23 11:13:57.178: INFO: Got endpoints: latency-svc-kf8qx [736.175844ms]
Apr 23 11:13:57.197: INFO: Created: latency-svc-wsgcw
Apr 23 11:13:57.231: INFO: Got endpoints: latency-svc-z72xc [729.81709ms]
Apr 23 11:13:57.258: INFO: Created: latency-svc-2rgtl
Apr 23 11:13:57.276: INFO: Got endpoints: latency-svc-gpmz4 [745.752728ms]
Apr 23 11:13:57.304: INFO: Created: latency-svc-htq5m
Apr 23 11:13:57.326: INFO: Got endpoints: latency-svc-x6fps [740.567875ms]
Apr 23 11:13:57.347: INFO: Created: latency-svc-8g2q9
Apr 23 11:13:57.382: INFO: Got endpoints: latency-svc-lqk6m [752.93621ms]
Apr 23 11:13:57.415: INFO: Created: latency-svc-v7pdl
Apr 23 11:13:57.429: INFO: Got endpoints: latency-svc-72plr [755.260076ms]
Apr 23 11:13:57.481: INFO: Created: latency-svc-tm4bm
Apr 23 11:13:57.509: INFO: Got endpoints: latency-svc-hb65r [780.658335ms]
Apr 23 11:13:57.535: INFO: Got endpoints: latency-svc-z7jms [761.315022ms]
Apr 23 11:13:57.542: INFO: Created: latency-svc-74h2w
Apr 23 11:13:57.555: INFO: Created: latency-svc-x8kzm
Apr 23 11:13:57.580: INFO: Got endpoints: latency-svc-tvwgk [747.374899ms]
Apr 23 11:13:57.608: INFO: Created: latency-svc-m7bx8
Apr 23 11:13:57.628: INFO: Got endpoints: latency-svc-t4qdl [747.31559ms]
Apr 23 11:13:57.645: INFO: Created: latency-svc-6mkxw
Apr 23 11:13:57.677: INFO: Got endpoints: latency-svc-dnsfm [749.720798ms]
Apr 23 11:13:57.693: INFO: Created: latency-svc-972vs
Apr 23 11:13:57.726: INFO: Got endpoints: latency-svc-hl82b [746.127256ms]
Apr 23 11:13:57.755: INFO: Created: latency-svc-p59m8
Apr 23 11:13:57.786: INFO: Got endpoints: latency-svc-8v9lm [753.315125ms]
Apr 23 11:13:57.807: INFO: Created: latency-svc-zpsnw
Apr 23 11:13:57.829: INFO: Got endpoints: latency-svc-dpl66 [747.410812ms]
Apr 23 11:13:57.846: INFO: Created: latency-svc-tkjwc
Apr 23 11:13:57.876: INFO: Got endpoints: latency-svc-h8n68 [749.131694ms]
Apr 23 11:13:57.898: INFO: Created: latency-svc-c54k5
Apr 23 11:13:57.927: INFO: Got endpoints: latency-svc-wsgcw [748.952679ms]
Apr 23 11:13:57.942: INFO: Created: latency-svc-jjdqh
Apr 23 11:13:57.979: INFO: Got endpoints: latency-svc-2rgtl [747.898277ms]
Apr 23 11:13:57.997: INFO: Created: latency-svc-p52c4
Apr 23 11:13:58.023: INFO: Got endpoints: latency-svc-htq5m [746.952206ms]
Apr 23 11:13:58.047: INFO: Created: latency-svc-dl6t2
Apr 23 11:13:58.074: INFO: Got endpoints: latency-svc-8g2q9 [747.953242ms]
Apr 23 11:13:58.091: INFO: Created: latency-svc-cqnxj
Apr 23 11:13:58.132: INFO: Got endpoints: latency-svc-v7pdl [749.550205ms]
Apr 23 11:13:58.149: INFO: Created: latency-svc-jz9bz
Apr 23 11:13:58.175: INFO: Got endpoints: latency-svc-tm4bm [746.237504ms]
Apr 23 11:13:58.190: INFO: Created: latency-svc-vd4cz
Apr 23 11:13:58.226: INFO: Got endpoints: latency-svc-74h2w [716.044607ms]
Apr 23 11:13:58.243: INFO: Created: latency-svc-vwtvv
Apr 23 11:13:58.277: INFO: Got endpoints: latency-svc-x8kzm [741.159184ms]
Apr 23 11:13:58.295: INFO: Created: latency-svc-skq7w
Apr 23 11:13:58.333: INFO: Got endpoints: latency-svc-m7bx8 [752.27182ms]
Apr 23 11:13:58.359: INFO: Created: latency-svc-4ctpx
Apr 23 11:13:58.374: INFO: Got endpoints: latency-svc-6mkxw [745.427691ms]
Apr 23 11:13:58.399: INFO: Created: latency-svc-5phwl
Apr 23 11:13:58.427: INFO: Got endpoints: latency-svc-972vs [749.288678ms]
Apr 23 11:13:58.452: INFO: Created: latency-svc-hmbc6
Apr 23 11:13:58.485: INFO: Got endpoints: latency-svc-p59m8 [758.702274ms]
Apr 23 11:13:58.503: INFO: Created: latency-svc-fgdh6
Apr 23 11:13:58.532: INFO: Got endpoints: latency-svc-zpsnw [746.243183ms]
Apr 23 11:13:58.608: INFO: Got endpoints: latency-svc-tkjwc [778.582626ms]
Apr 23 11:13:58.632: INFO: Created: latency-svc-lw52p
Apr 23 11:13:58.655: INFO: Got endpoints: latency-svc-c54k5 [778.152084ms]
Apr 23 11:13:58.655: INFO: Created: latency-svc-mng6b
Apr 23 11:13:58.676: INFO: Got endpoints: latency-svc-jjdqh [748.780453ms]
Apr 23 11:13:58.696: INFO: Created: latency-svc-hxhtl
Apr 23 11:13:58.722: INFO: Created: latency-svc-mn755
Apr 23 11:13:58.734: INFO: Got endpoints: latency-svc-p52c4 [755.000583ms]
Apr 23 11:13:58.752: INFO: Created: latency-svc-4jcmn
Apr 23 11:13:58.775: INFO: Got endpoints: latency-svc-dl6t2 [751.535985ms]
Apr 23 11:13:58.808: INFO: Created: latency-svc-r4v4f
Apr 23 11:13:58.826: INFO: Got endpoints: latency-svc-cqnxj [751.445225ms]
Apr 23 11:13:58.850: INFO: Created: latency-svc-qlb9t
Apr 23 11:13:58.882: INFO: Got endpoints: latency-svc-jz9bz [750.165014ms]
Apr 23 11:13:58.914: INFO: Created: latency-svc-8w88p
Apr 23 11:13:58.928: INFO: Got endpoints: latency-svc-vd4cz [752.616531ms]
Apr 23 11:13:58.960: INFO: Created: latency-svc-w8gts
Apr 23 11:13:58.979: INFO: Got endpoints: latency-svc-vwtvv [753.761178ms]
Apr 23 11:13:59.002: INFO: Created: latency-svc-7n2hr
Apr 23 11:13:59.030: INFO: Got endpoints: latency-svc-skq7w [752.62511ms]
Apr 23 11:13:59.052: INFO: Created: latency-svc-569gn
Apr 23 11:13:59.074: INFO: Got endpoints: latency-svc-4ctpx [740.636031ms]
Apr 23 11:13:59.104: INFO: Created: latency-svc-k2jpw
Apr 23 11:13:59.133: INFO: Got endpoints: latency-svc-5phwl [758.259494ms]
Apr 23 11:13:59.164: INFO: Created: latency-svc-jnclq
Apr 23 11:13:59.181: INFO: Got endpoints: latency-svc-hmbc6 [753.91168ms]
Apr 23 11:13:59.201: INFO: Created: latency-svc-7jt9g
Apr 23 11:13:59.223: INFO: Got endpoints: latency-svc-fgdh6 [738.603421ms]
Apr 23 11:13:59.246: INFO: Created: latency-svc-xz67x
Apr 23 11:13:59.277: INFO: Got endpoints: latency-svc-lw52p [744.00188ms]
Apr 23 11:13:59.297: INFO: Created: latency-svc-gtf44
Apr 23 11:13:59.325: INFO: Got endpoints: latency-svc-mng6b [717.487521ms]
Apr 23 11:13:59.345: INFO: Created: latency-svc-tp5n8
Apr 23 11:13:59.383: INFO: Got endpoints: latency-svc-hxhtl [728.516693ms]
Apr 23 11:13:59.423: INFO: Created: latency-svc-tdcv5
Apr 23 11:13:59.447: INFO: Got endpoints: latency-svc-mn755 [770.88708ms]
Apr 23 11:13:59.500: INFO: Got endpoints: latency-svc-4jcmn [765.579822ms]
Apr 23 11:13:59.513: INFO: Created: latency-svc-h598h
Apr 23 11:13:59.528: INFO: Created: latency-svc-s5t8p
Apr 23 11:13:59.535: INFO: Got endpoints: latency-svc-r4v4f [759.473976ms]
Apr 23 11:13:59.557: INFO: Created: latency-svc-9fh24
Apr 23 11:13:59.580: INFO: Got endpoints: latency-svc-qlb9t [753.714992ms]
Apr 23 11:13:59.610: INFO: Created: latency-svc-8g8c5
Apr 23 11:13:59.632: INFO: Got endpoints: latency-svc-8w88p [749.438193ms]
Apr 23 11:13:59.653: INFO: Created: latency-svc-jdnnj
Apr 23 11:13:59.678: INFO: Got endpoints: latency-svc-w8gts [750.008058ms]
Apr 23 11:13:59.708: INFO: Created: latency-svc-l77qd
Apr 23 11:13:59.729: INFO: Got endpoints: latency-svc-7n2hr [749.078468ms]
Apr 23 11:13:59.758: INFO: Created: latency-svc-xhbss
Apr 23 11:13:59.778: INFO: Got endpoints: latency-svc-569gn [748.033192ms]
Apr 23 11:13:59.796: INFO: Created: latency-svc-vq4zl
Apr 23 11:13:59.825: INFO: Got endpoints: latency-svc-k2jpw [751.393563ms]
Apr 23 11:13:59.848: INFO: Created: latency-svc-r2qqp
Apr 23 11:13:59.880: INFO: Got endpoints: latency-svc-jnclq [747.399882ms]
Apr 23 11:13:59.935: INFO: Got endpoints: latency-svc-7jt9g [753.933234ms]
Apr 23 11:13:59.976: INFO: Got endpoints: latency-svc-xz67x [752.271989ms]
Apr 23 11:14:00.027: INFO: Got endpoints: latency-svc-gtf44 [749.655047ms]
Apr 23 11:14:00.079: INFO: Got endpoints: latency-svc-tp5n8 [753.061464ms]
Apr 23 11:14:00.129: INFO: Got endpoints: latency-svc-tdcv5 [744.728601ms]
Apr 23 11:14:00.176: INFO: Got endpoints: latency-svc-h598h [728.01059ms]
Apr 23 11:14:00.230: INFO: Got endpoints: latency-svc-s5t8p [729.932301ms]
Apr 23 11:14:00.279: INFO: Got endpoints: latency-svc-9fh24 [744.262923ms]
Apr 23 11:14:00.328: INFO: Got endpoints: latency-svc-8g8c5 [747.957682ms]
Apr 23 11:14:00.381: INFO: Got endpoints: latency-svc-jdnnj [748.624871ms]
Apr 23 11:14:00.435: INFO: Got endpoints: latency-svc-l77qd [756.61932ms]
Apr 23 11:14:00.484: INFO: Got endpoints: latency-svc-xhbss [755.227014ms]
Apr 23 11:14:00.527: INFO: Got endpoints: latency-svc-vq4zl [749.226897ms]
Apr 23 11:14:00.581: INFO: Got endpoints: latency-svc-r2qqp [755.596949ms]
Apr 23 11:14:00.581: INFO: Latencies: [42.645056ms 75.370488ms 86.840648ms 87.581045ms 131.957344ms 134.337879ms 156.96365ms 172.885841ms 193.035859ms 245.612548ms 246.102596ms 250.393599ms 270.905678ms 272.316486ms 295.660714ms 298.763433ms 300.022479ms 303.925847ms 307.616728ms 309.156156ms 312.902768ms 314.17006ms 314.17277ms 314.498041ms 316.52055ms 318.807567ms 319.885218ms 320.243602ms 323.477525ms 324.125705ms 325.656304ms 326.662009ms 333.043856ms 341.420881ms 342.945242ms 350.609945ms 352.663925ms 353.650782ms 353.939878ms 358.081694ms 360.458672ms 361.053639ms 365.408579ms 365.740141ms 367.402481ms 373.097432ms 383.610199ms 384.550259ms 384.798666ms 391.492704ms 391.901512ms 400.087679ms 415.600889ms 418.881392ms 430.863729ms 443.528705ms 444.622915ms 463.219553ms 481.722166ms 504.648342ms 520.418271ms 535.538086ms 586.399515ms 605.910061ms 663.440729ms 664.629871ms 677.930549ms 681.961823ms 691.142913ms 701.248049ms 716.044607ms 716.721977ms 717.084414ms 717.487521ms 725.429168ms 726.875252ms 728.01059ms 728.516693ms 728.637015ms 729.604173ms 729.81709ms 729.932301ms 732.555472ms 734.099209ms 736.175844ms 737.156135ms 737.743728ms 738.603421ms 738.754488ms 739.516112ms 740.108564ms 740.567875ms 740.636031ms 741.159184ms 741.173563ms 741.471334ms 742.144668ms 743.337803ms 743.596848ms 744.00188ms 744.014252ms 744.262923ms 744.728601ms 744.843905ms 745.113338ms 745.306925ms 745.427691ms 745.597981ms 745.752728ms 745.933859ms 746.127256ms 746.237504ms 746.243183ms 746.247439ms 746.952206ms 747.052356ms 747.31559ms 747.374899ms 747.382928ms 747.399882ms 747.410812ms 747.898277ms 747.953242ms 747.957682ms 748.033192ms 748.083936ms 748.309012ms 748.624871ms 748.780453ms 748.843929ms 748.952679ms 749.078468ms 749.131694ms 749.226897ms 749.288678ms 749.438193ms 749.550205ms 749.556436ms 749.655047ms 749.720798ms 749.756031ms 750.008058ms 750.165014ms 750.649785ms 751.393563ms 751.445225ms 751.535985ms 752.090193ms 752.10377ms 752.27182ms 752.271989ms 752.616531ms 752.62511ms 752.653079ms 752.93621ms 753.061464ms 753.315125ms 753.714992ms 753.761178ms 753.91168ms 753.933234ms 754.229762ms 754.333423ms 754.720143ms 755.000583ms 755.040924ms 755.227014ms 755.260076ms 755.454456ms 755.596949ms 756.61932ms 757.370618ms 758.259494ms 758.702274ms 759.169168ms 759.473976ms 759.639536ms 760.653627ms 761.036235ms 761.315022ms 762.359062ms 763.364852ms 765.579822ms 768.178153ms 770.470387ms 770.847221ms 770.88708ms 771.658345ms 773.042454ms 774.655377ms 775.756761ms 775.886654ms 776.588583ms 778.152084ms 778.402497ms 778.582626ms 780.658335ms 781.610189ms 791.230877ms 829.994174ms]
Apr 23 11:14:00.582: INFO: 50 %ile: 744.014252ms
Apr 23 11:14:00.582: INFO: 90 %ile: 762.359062ms
Apr 23 11:14:00.582: INFO: 99 %ile: 791.230877ms
Apr 23 11:14:00.582: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/node/init/init.go:32
Apr 23 11:14:00.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Service endpoints latency
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Service endpoints latency
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Service endpoints latency
  tear down framework | framework.go:193
STEP: Destroying namespace "svc-latency-8999" for this suite. 04/23/23 11:14:00.598
------------------------------
â€¢ [SLOW TEST] [11.865 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:13:48.749
    Apr 23 11:13:48.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename svc-latency 04/23/23 11:13:48.753
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:13:48.796
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:13:48.804
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/metrics/init/init.go:31
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Apr 23 11:13:48.815: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-8999 04/23/23 11:13:48.819
    I0423 11:13:48.839003      13 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8999, replica count: 1
    I0423 11:13:49.894222      13 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:13:50.894691      13 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:13:51.895723      13 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 23 11:13:52.019: INFO: Created: latency-svc-7hhnl
    Apr 23 11:13:52.028: INFO: Got endpoints: latency-svc-7hhnl [31.327275ms]
    Apr 23 11:13:52.060: INFO: Created: latency-svc-l52nq
    Apr 23 11:13:52.072: INFO: Got endpoints: latency-svc-l52nq [42.645056ms]
    Apr 23 11:13:52.081: INFO: Created: latency-svc-h2jdh
    Apr 23 11:13:52.088: INFO: Created: latency-svc-crzbz
    Apr 23 11:13:52.099: INFO: Created: latency-svc-248vk
    Apr 23 11:13:52.105: INFO: Got endpoints: latency-svc-h2jdh [75.370488ms]
    Apr 23 11:13:52.119: INFO: Got endpoints: latency-svc-248vk [86.840648ms]
    Apr 23 11:13:52.119: INFO: Got endpoints: latency-svc-crzbz [87.581045ms]
    Apr 23 11:13:52.139: INFO: Created: latency-svc-2vgfm
    Apr 23 11:13:52.147: INFO: Created: latency-svc-sd98n
    Apr 23 11:13:52.164: INFO: Got endpoints: latency-svc-2vgfm [131.957344ms]
    Apr 23 11:13:52.167: INFO: Got endpoints: latency-svc-sd98n [134.337879ms]
    Apr 23 11:13:52.170: INFO: Created: latency-svc-hts8b
    Apr 23 11:13:52.183: INFO: Created: latency-svc-bl46p
    Apr 23 11:13:52.190: INFO: Got endpoints: latency-svc-hts8b [156.96365ms]
    Apr 23 11:13:52.205: INFO: Got endpoints: latency-svc-bl46p [172.885841ms]
    Apr 23 11:13:52.207: INFO: Created: latency-svc-8xhjh
    Apr 23 11:13:52.223: INFO: Created: latency-svc-rjnb8
    Apr 23 11:13:52.227: INFO: Got endpoints: latency-svc-8xhjh [193.035859ms]
    Apr 23 11:13:52.232: INFO: Created: latency-svc-pv5bg
    Apr 23 11:13:52.268: INFO: Created: latency-svc-phxs8
    Apr 23 11:13:52.280: INFO: Got endpoints: latency-svc-pv5bg [245.612548ms]
    Apr 23 11:13:52.280: INFO: Got endpoints: latency-svc-rjnb8 [246.102596ms]
    Apr 23 11:13:52.292: INFO: Created: latency-svc-84sh4
    Apr 23 11:13:52.305: INFO: Got endpoints: latency-svc-phxs8 [270.905678ms]
    Apr 23 11:13:52.307: INFO: Got endpoints: latency-svc-84sh4 [272.316486ms]
    Apr 23 11:13:52.314: INFO: Created: latency-svc-p74zk
    Apr 23 11:13:52.330: INFO: Created: latency-svc-5gxdl
    Apr 23 11:13:52.333: INFO: Got endpoints: latency-svc-p74zk [298.763433ms]
    Apr 23 11:13:52.347: INFO: Created: latency-svc-v9257
    Apr 23 11:13:52.349: INFO: Got endpoints: latency-svc-5gxdl [314.498041ms]
    Apr 23 11:13:52.392: INFO: Got endpoints: latency-svc-v9257 [318.807567ms]
    Apr 23 11:13:52.404: INFO: Created: latency-svc-5cmqz
    Apr 23 11:13:52.407: INFO: Created: latency-svc-rw4pg
    Apr 23 11:13:52.424: INFO: Created: latency-svc-cbdwl
    Apr 23 11:13:52.445: INFO: Got endpoints: latency-svc-cbdwl [325.656304ms]
    Apr 23 11:13:52.446: INFO: Got endpoints: latency-svc-rw4pg [326.662009ms]
    Apr 23 11:13:52.447: INFO: Got endpoints: latency-svc-5cmqz [341.420881ms]
    Apr 23 11:13:52.463: INFO: Created: latency-svc-bqd6d
    Apr 23 11:13:52.471: INFO: Got endpoints: latency-svc-bqd6d [303.925847ms]
    Apr 23 11:13:52.514: INFO: Created: latency-svc-p6w5p
    Apr 23 11:13:52.527: INFO: Got endpoints: latency-svc-p6w5p [358.081694ms]
    Apr 23 11:13:52.537: INFO: Created: latency-svc-nqtlt
    Apr 23 11:13:52.550: INFO: Got endpoints: latency-svc-nqtlt [353.939878ms]
    Apr 23 11:13:52.581: INFO: Created: latency-svc-cj258
    Apr 23 11:13:52.590: INFO: Got endpoints: latency-svc-cj258 [384.550259ms]
    Apr 23 11:13:52.602: INFO: Created: latency-svc-sxz24
    Apr 23 11:13:52.614: INFO: Created: latency-svc-2dkxx
    Apr 23 11:13:52.619: INFO: Got endpoints: latency-svc-sxz24 [391.901512ms]
    Apr 23 11:13:52.635: INFO: Got endpoints: latency-svc-2dkxx [352.663925ms]
    Apr 23 11:13:52.640: INFO: Created: latency-svc-wqlc4
    Apr 23 11:13:52.651: INFO: Got endpoints: latency-svc-wqlc4 [367.402481ms]
    Apr 23 11:13:52.659: INFO: Created: latency-svc-8b6w6
    Apr 23 11:13:52.669: INFO: Got endpoints: latency-svc-8b6w6 [360.458672ms]
    Apr 23 11:13:52.672: INFO: Created: latency-svc-qfqvz
    Apr 23 11:13:52.680: INFO: Got endpoints: latency-svc-qfqvz [373.097432ms]
    Apr 23 11:13:52.704: INFO: Created: latency-svc-272bj
    Apr 23 11:13:52.714: INFO: Created: latency-svc-gmd4g
    Apr 23 11:13:52.718: INFO: Got endpoints: latency-svc-272bj [384.798666ms]
    Apr 23 11:13:52.733: INFO: Got endpoints: latency-svc-gmd4g [383.610199ms]
    Apr 23 11:13:52.737: INFO: Created: latency-svc-6qpmj
    Apr 23 11:13:52.751: INFO: Created: latency-svc-pf7l9
    Apr 23 11:13:52.757: INFO: Got endpoints: latency-svc-6qpmj [365.740141ms]
    Apr 23 11:13:52.765: INFO: Got endpoints: latency-svc-pf7l9 [320.243602ms]
    Apr 23 11:13:52.769: INFO: Created: latency-svc-bhfgr
    Apr 23 11:13:52.780: INFO: Created: latency-svc-gsckg
    Apr 23 11:13:52.789: INFO: Got endpoints: latency-svc-bhfgr [342.945242ms]
    Apr 23 11:13:52.813: INFO: Got endpoints: latency-svc-gsckg [365.408579ms]
    Apr 23 11:13:52.814: INFO: Created: latency-svc-p55dt
    Apr 23 11:13:52.825: INFO: Got endpoints: latency-svc-p55dt [353.650782ms]
    Apr 23 11:13:52.832: INFO: Created: latency-svc-smbb5
    Apr 23 11:13:52.844: INFO: Got endpoints: latency-svc-smbb5 [316.52055ms]
    Apr 23 11:13:52.852: INFO: Created: latency-svc-rlpp4
    Apr 23 11:13:52.882: INFO: Created: latency-svc-t2rm7
    Apr 23 11:13:52.883: INFO: Got endpoints: latency-svc-rlpp4 [333.043856ms]
    Apr 23 11:13:52.898: INFO: Got endpoints: latency-svc-t2rm7 [307.616728ms]
    Apr 23 11:13:52.902: INFO: Created: latency-svc-thf86
    Apr 23 11:13:52.919: INFO: Got endpoints: latency-svc-thf86 [300.022479ms]
    Apr 23 11:13:52.919: INFO: Created: latency-svc-vgz9d
    Apr 23 11:13:52.945: INFO: Created: latency-svc-jtwx6
    Apr 23 11:13:52.949: INFO: Got endpoints: latency-svc-vgz9d [314.17277ms]
    Apr 23 11:13:52.956: INFO: Created: latency-svc-pc5l9
    Apr 23 11:13:52.960: INFO: Got endpoints: latency-svc-jtwx6 [309.156156ms]
    Apr 23 11:13:52.981: INFO: Created: latency-svc-dgc4g
    Apr 23 11:13:52.982: INFO: Got endpoints: latency-svc-pc5l9 [312.902768ms]
    Apr 23 11:13:52.994: INFO: Got endpoints: latency-svc-dgc4g [314.17006ms]
    Apr 23 11:13:53.135: INFO: Created: latency-svc-mpq6t
    Apr 23 11:13:53.136: INFO: Created: latency-svc-z2fzl
    Apr 23 11:13:53.154: INFO: Created: latency-svc-2c9fq
    Apr 23 11:13:53.156: INFO: Created: latency-svc-pm5qr
    Apr 23 11:13:53.157: INFO: Created: latency-svc-cjvzt
    Apr 23 11:13:53.159: INFO: Created: latency-svc-7hfdr
    Apr 23 11:13:53.160: INFO: Created: latency-svc-6h884
    Apr 23 11:13:53.161: INFO: Created: latency-svc-qddws
    Apr 23 11:13:53.161: INFO: Created: latency-svc-xb4nh
    Apr 23 11:13:53.165: INFO: Created: latency-svc-fv7zv
    Apr 23 11:13:53.166: INFO: Created: latency-svc-gncxp
    Apr 23 11:13:53.169: INFO: Created: latency-svc-tscbx
    Apr 23 11:13:53.176: INFO: Got endpoints: latency-svc-mpq6t [350.609945ms]
    Apr 23 11:13:53.176: INFO: Got endpoints: latency-svc-z2fzl [418.881392ms]
    Apr 23 11:13:53.187: INFO: Created: latency-svc-s8krj
    Apr 23 11:13:53.207: INFO: Created: latency-svc-wsgd8
    Apr 23 11:13:53.207: INFO: Got endpoints: latency-svc-fv7zv [324.125705ms]
    Apr 23 11:13:53.208: INFO: Created: latency-svc-shbp9
    Apr 23 11:13:53.213: INFO: Got endpoints: latency-svc-tscbx [400.087679ms]
    Apr 23 11:13:53.242: INFO: Created: latency-svc-x9vqv
    Apr 23 11:13:53.245: INFO: Got endpoints: latency-svc-gncxp [295.660714ms]
    Apr 23 11:13:53.245: INFO: Got endpoints: latency-svc-pm5qr [250.393599ms]
    Apr 23 11:13:53.269: INFO: Got endpoints: latency-svc-xb4nh [535.538086ms]
    Apr 23 11:13:53.270: INFO: Got endpoints: latency-svc-cjvzt [504.648342ms]
    Apr 23 11:13:53.270: INFO: Got endpoints: latency-svc-7hfdr [481.722166ms]
    Apr 23 11:13:53.280: INFO: Got endpoints: latency-svc-6h884 [319.885218ms]
    Apr 23 11:13:53.289: INFO: Got endpoints: latency-svc-2c9fq [444.622915ms]
    Apr 23 11:13:53.334: INFO: Got endpoints: latency-svc-wsgd8 [415.600889ms]
    Apr 23 11:13:53.417: INFO: Created: latency-svc-xbkld
    Apr 23 11:13:53.417: INFO: Created: latency-svc-x5q8h
    Apr 23 11:13:53.419: INFO: Created: latency-svc-qjjk2
    Apr 23 11:13:53.419: INFO: Created: latency-svc-2bwkn
    Apr 23 11:13:53.419: INFO: Created: latency-svc-fzxkz
    Apr 23 11:13:53.419: INFO: Created: latency-svc-hnrhp
    Apr 23 11:13:53.420: INFO: Created: latency-svc-4pphc
    Apr 23 11:13:53.420: INFO: Created: latency-svc-f4rgt
    Apr 23 11:13:53.418: INFO: Got endpoints: latency-svc-shbp9 [520.418271ms]
    Apr 23 11:13:53.428: INFO: Created: latency-svc-lp4r8
    Apr 23 11:13:53.428: INFO: Created: latency-svc-tdfvc
    Apr 23 11:13:53.433: INFO: Created: latency-svc-jhqdw
    Apr 23 11:13:53.445: INFO: Got endpoints: latency-svc-s8krj [463.219553ms]
    Apr 23 11:13:53.487: INFO: Created: latency-svc-c5h6q
    Apr 23 11:13:53.487: INFO: Created: latency-svc-kzlmr
    Apr 23 11:13:53.489: INFO: Got endpoints: latency-svc-qddws [770.470387ms]
    Apr 23 11:13:53.508: INFO: Created: latency-svc-lgqp4
    Apr 23 11:13:53.538: INFO: Got endpoints: latency-svc-x9vqv [361.053639ms]
    Apr 23 11:13:53.580: INFO: Created: latency-svc-t9shm
    Apr 23 11:13:53.595: INFO: Got endpoints: latency-svc-xbkld [323.477525ms]
    Apr 23 11:13:53.638: INFO: Got endpoints: latency-svc-4pphc [430.863729ms]
    Apr 23 11:13:53.640: INFO: Created: latency-svc-fjz6r
    Apr 23 11:13:53.654: INFO: Created: latency-svc-pft7m
    Apr 23 11:13:53.672: INFO: Got endpoints: latency-svc-x5q8h [391.492704ms]
    Apr 23 11:13:53.699: INFO: Created: latency-svc-h7zzj
    Apr 23 11:13:53.733: INFO: Got endpoints: latency-svc-qjjk2 [443.528705ms]
    Apr 23 11:13:53.765: INFO: Created: latency-svc-gx4jr
    Apr 23 11:13:53.782: INFO: Got endpoints: latency-svc-f4rgt [605.910061ms]
    Apr 23 11:13:53.825: INFO: Created: latency-svc-mt9fq
    Apr 23 11:13:53.831: INFO: Got endpoints: latency-svc-fzxkz [586.399515ms]
    Apr 23 11:13:53.863: INFO: Created: latency-svc-8dsg2
    Apr 23 11:13:53.878: INFO: Got endpoints: latency-svc-hnrhp [664.629871ms]
    Apr 23 11:13:53.909: INFO: Created: latency-svc-28frv
    Apr 23 11:13:53.934: INFO: Got endpoints: latency-svc-2bwkn [663.440729ms]
    Apr 23 11:13:53.966: INFO: Created: latency-svc-hphfd
    Apr 23 11:13:53.982: INFO: Got endpoints: latency-svc-lp4r8 [737.156135ms]
    Apr 23 11:13:54.017: INFO: Created: latency-svc-7jbwm
    Apr 23 11:13:54.045: INFO: Got endpoints: latency-svc-tdfvc [775.886654ms]
    Apr 23 11:13:54.111: INFO: Created: latency-svc-4lfl4
    Apr 23 11:13:54.111: INFO: Got endpoints: latency-svc-jhqdw [776.588583ms]
    Apr 23 11:13:54.199: INFO: Got endpoints: latency-svc-c5h6q [778.402497ms]
    Apr 23 11:13:54.222: INFO: Got endpoints: latency-svc-kzlmr [775.756761ms]
    Apr 23 11:13:54.241: INFO: Created: latency-svc-r4hxf
    Apr 23 11:13:54.249: INFO: Got endpoints: latency-svc-lgqp4 [759.639536ms]
    Apr 23 11:13:54.257: INFO: Created: latency-svc-gdrtz
    Apr 23 11:13:54.270: INFO: Created: latency-svc-52c6h
    Apr 23 11:13:54.283: INFO: Got endpoints: latency-svc-t9shm [744.843905ms]
    Apr 23 11:13:54.284: INFO: Created: latency-svc-pbpt2
    Apr 23 11:13:54.316: INFO: Created: latency-svc-qqnc9
    Apr 23 11:13:54.340: INFO: Got endpoints: latency-svc-fjz6r [745.113338ms]
    Apr 23 11:13:54.368: INFO: Created: latency-svc-5zfnq
    Apr 23 11:13:54.379: INFO: Got endpoints: latency-svc-pft7m [741.173563ms]
    Apr 23 11:13:54.405: INFO: Created: latency-svc-tbrv8
    Apr 23 11:13:54.445: INFO: Got endpoints: latency-svc-h7zzj [773.042454ms]
    Apr 23 11:13:54.466: INFO: Created: latency-svc-hh4gv
    Apr 23 11:13:54.477: INFO: Got endpoints: latency-svc-gx4jr [744.014252ms]
    Apr 23 11:13:54.510: INFO: Created: latency-svc-tj7hw
    Apr 23 11:13:54.564: INFO: Got endpoints: latency-svc-mt9fq [781.610189ms]
    Apr 23 11:13:54.592: INFO: Got endpoints: latency-svc-8dsg2 [760.653627ms]
    Apr 23 11:13:54.613: INFO: Created: latency-svc-8z6zd
    Apr 23 11:13:54.632: INFO: Created: latency-svc-92jrp
    Apr 23 11:13:54.641: INFO: Got endpoints: latency-svc-28frv [762.359062ms]
    Apr 23 11:13:54.667: INFO: Created: latency-svc-57tf7
    Apr 23 11:13:54.680: INFO: Got endpoints: latency-svc-hphfd [746.247439ms]
    Apr 23 11:13:54.704: INFO: Created: latency-svc-mn9fr
    Apr 23 11:13:54.722: INFO: Got endpoints: latency-svc-7jbwm [740.108564ms]
    Apr 23 11:13:54.745: INFO: Created: latency-svc-2lphf
    Apr 23 11:13:54.778: INFO: Got endpoints: latency-svc-4lfl4 [732.555472ms]
    Apr 23 11:13:54.795: INFO: Created: latency-svc-45pl8
    Apr 23 11:13:54.828: INFO: Got endpoints: latency-svc-r4hxf [716.721977ms]
    Apr 23 11:13:54.847: INFO: Created: latency-svc-rwggv
    Apr 23 11:13:54.877: INFO: Got endpoints: latency-svc-gdrtz [677.930549ms]
    Apr 23 11:13:54.894: INFO: Created: latency-svc-hfd6h
    Apr 23 11:13:54.923: INFO: Got endpoints: latency-svc-52c6h [701.248049ms]
    Apr 23 11:13:54.946: INFO: Created: latency-svc-hhntd
    Apr 23 11:13:54.978: INFO: Got endpoints: latency-svc-pbpt2 [728.637015ms]
    Apr 23 11:13:55.001: INFO: Created: latency-svc-bk7bs
    Apr 23 11:13:55.034: INFO: Got endpoints: latency-svc-qqnc9 [750.649785ms]
    Apr 23 11:13:55.061: INFO: Created: latency-svc-7bz6k
    Apr 23 11:13:55.089: INFO: Got endpoints: latency-svc-5zfnq [747.382928ms]
    Apr 23 11:13:55.121: INFO: Created: latency-svc-kh5g8
    Apr 23 11:13:55.143: INFO: Got endpoints: latency-svc-tbrv8 [763.364852ms]
    Apr 23 11:13:55.184: INFO: Got endpoints: latency-svc-hh4gv [738.754488ms]
    Apr 23 11:13:55.205: INFO: Created: latency-svc-pgw7r
    Apr 23 11:13:55.234: INFO: Created: latency-svc-6kx7z
    Apr 23 11:13:55.248: INFO: Got endpoints: latency-svc-tj7hw [770.847221ms]
    Apr 23 11:13:55.282: INFO: Got endpoints: latency-svc-8z6zd [717.084414ms]
    Apr 23 11:13:55.354: INFO: Created: latency-svc-9cfbn
    Apr 23 11:13:55.384: INFO: Got endpoints: latency-svc-92jrp [791.230877ms]
    Apr 23 11:13:55.402: INFO: Got endpoints: latency-svc-57tf7 [761.036235ms]
    Apr 23 11:13:55.402: INFO: Created: latency-svc-6v4d2
    Apr 23 11:13:55.436: INFO: Got endpoints: latency-svc-mn9fr [755.454456ms]
    Apr 23 11:13:55.444: INFO: Created: latency-svc-69gpn
    Apr 23 11:13:55.452: INFO: Created: latency-svc-bqgqt
    Apr 23 11:13:55.464: INFO: Created: latency-svc-xq9kv
    Apr 23 11:13:55.552: INFO: Got endpoints: latency-svc-2lphf [829.994174ms]
    Apr 23 11:13:55.552: INFO: Got endpoints: latency-svc-45pl8 [774.655377ms]
    Apr 23 11:13:55.583: INFO: Got endpoints: latency-svc-rwggv [754.720143ms]
    Apr 23 11:13:55.602: INFO: Created: latency-svc-69zxg
    Apr 23 11:13:55.620: INFO: Created: latency-svc-qskmj
    Apr 23 11:13:55.636: INFO: Got endpoints: latency-svc-hfd6h [759.169168ms]
    Apr 23 11:13:55.637: INFO: Created: latency-svc-hmtgz
    Apr 23 11:13:55.695: INFO: Got endpoints: latency-svc-hhntd [771.658345ms]
    Apr 23 11:13:55.707: INFO: Created: latency-svc-f2jl7
    Apr 23 11:13:55.733: INFO: Got endpoints: latency-svc-bk7bs [754.333423ms]
    Apr 23 11:13:55.744: INFO: Created: latency-svc-8gx97
    Apr 23 11:13:55.758: INFO: Created: latency-svc-w4x87
    Apr 23 11:13:55.777: INFO: Got endpoints: latency-svc-7bz6k [743.596848ms]
    Apr 23 11:13:55.814: INFO: Created: latency-svc-jzbhr
    Apr 23 11:13:55.831: INFO: Got endpoints: latency-svc-kh5g8 [741.471334ms]
    Apr 23 11:13:55.859: INFO: Created: latency-svc-7qn6d
    Apr 23 11:13:55.881: INFO: Got endpoints: latency-svc-pgw7r [737.743728ms]
    Apr 23 11:13:55.930: INFO: Created: latency-svc-q269g
    Apr 23 11:13:55.934: INFO: Got endpoints: latency-svc-6kx7z [749.756031ms]
    Apr 23 11:13:55.963: INFO: Created: latency-svc-phpcl
    Apr 23 11:13:55.973: INFO: Got endpoints: latency-svc-9cfbn [725.429168ms]
    Apr 23 11:13:55.993: INFO: Created: latency-svc-f8lf7
    Apr 23 11:13:56.026: INFO: Got endpoints: latency-svc-6v4d2 [743.337803ms]
    Apr 23 11:13:56.042: INFO: Created: latency-svc-r22vr
    Apr 23 11:13:56.075: INFO: Got endpoints: latency-svc-69gpn [691.142913ms]
    Apr 23 11:13:56.099: INFO: Created: latency-svc-xcxfp
    Apr 23 11:13:56.129: INFO: Got endpoints: latency-svc-bqgqt [726.875252ms]
    Apr 23 11:13:56.151: INFO: Created: latency-svc-khv2c
    Apr 23 11:13:56.185: INFO: Got endpoints: latency-svc-xq9kv [748.843929ms]
    Apr 23 11:13:56.235: INFO: Got endpoints: latency-svc-69zxg [681.961823ms]
    Apr 23 11:13:56.247: INFO: Created: latency-svc-9bxsv
    Apr 23 11:13:56.282: INFO: Got endpoints: latency-svc-qskmj [729.604173ms]
    Apr 23 11:13:56.287: INFO: Created: latency-svc-bq4xk
    Apr 23 11:13:56.301: INFO: Created: latency-svc-zhkm7
    Apr 23 11:13:56.329: INFO: Got endpoints: latency-svc-hmtgz [745.933859ms]
    Apr 23 11:13:56.346: INFO: Created: latency-svc-j9wfz
    Apr 23 11:13:56.382: INFO: Got endpoints: latency-svc-f2jl7 [745.597981ms]
    Apr 23 11:13:56.406: INFO: Created: latency-svc-fbhsw
    Apr 23 11:13:56.442: INFO: Got endpoints: latency-svc-8gx97 [747.052356ms]
    Apr 23 11:13:56.493: INFO: Created: latency-svc-kf8qx
    Apr 23 11:13:56.501: INFO: Got endpoints: latency-svc-w4x87 [768.178153ms]
    Apr 23 11:13:56.523: INFO: Created: latency-svc-z72xc
    Apr 23 11:13:56.530: INFO: Got endpoints: latency-svc-jzbhr [752.653079ms]
    Apr 23 11:13:56.578: INFO: Created: latency-svc-gpmz4
    Apr 23 11:13:56.585: INFO: Got endpoints: latency-svc-7qn6d [754.229762ms]
    Apr 23 11:13:56.607: INFO: Created: latency-svc-x6fps
    Apr 23 11:13:56.629: INFO: Got endpoints: latency-svc-q269g [748.309012ms]
    Apr 23 11:13:56.648: INFO: Created: latency-svc-lqk6m
    Apr 23 11:13:56.674: INFO: Got endpoints: latency-svc-phpcl [739.516112ms]
    Apr 23 11:13:56.697: INFO: Created: latency-svc-72plr
    Apr 23 11:13:56.729: INFO: Got endpoints: latency-svc-f8lf7 [755.040924ms]
    Apr 23 11:13:56.749: INFO: Created: latency-svc-hb65r
    Apr 23 11:13:56.774: INFO: Got endpoints: latency-svc-r22vr [748.083936ms]
    Apr 23 11:13:56.793: INFO: Created: latency-svc-z7jms
    Apr 23 11:13:56.832: INFO: Got endpoints: latency-svc-xcxfp [757.370618ms]
    Apr 23 11:13:56.853: INFO: Created: latency-svc-tvwgk
    Apr 23 11:13:56.881: INFO: Got endpoints: latency-svc-khv2c [752.10377ms]
    Apr 23 11:13:56.903: INFO: Created: latency-svc-t4qdl
    Apr 23 11:13:56.927: INFO: Got endpoints: latency-svc-9bxsv [742.144668ms]
    Apr 23 11:13:56.954: INFO: Created: latency-svc-dnsfm
    Apr 23 11:13:56.979: INFO: Got endpoints: latency-svc-bq4xk [734.099209ms]
    Apr 23 11:13:57.013: INFO: Created: latency-svc-hl82b
    Apr 23 11:13:57.032: INFO: Got endpoints: latency-svc-zhkm7 [749.556436ms]
    Apr 23 11:13:57.066: INFO: Created: latency-svc-8v9lm
    Apr 23 11:13:57.081: INFO: Got endpoints: latency-svc-j9wfz [752.090193ms]
    Apr 23 11:13:57.099: INFO: Created: latency-svc-dpl66
    Apr 23 11:13:57.127: INFO: Got endpoints: latency-svc-fbhsw [745.306925ms]
    Apr 23 11:13:57.160: INFO: Created: latency-svc-h8n68
    Apr 23 11:13:57.178: INFO: Got endpoints: latency-svc-kf8qx [736.175844ms]
    Apr 23 11:13:57.197: INFO: Created: latency-svc-wsgcw
    Apr 23 11:13:57.231: INFO: Got endpoints: latency-svc-z72xc [729.81709ms]
    Apr 23 11:13:57.258: INFO: Created: latency-svc-2rgtl
    Apr 23 11:13:57.276: INFO: Got endpoints: latency-svc-gpmz4 [745.752728ms]
    Apr 23 11:13:57.304: INFO: Created: latency-svc-htq5m
    Apr 23 11:13:57.326: INFO: Got endpoints: latency-svc-x6fps [740.567875ms]
    Apr 23 11:13:57.347: INFO: Created: latency-svc-8g2q9
    Apr 23 11:13:57.382: INFO: Got endpoints: latency-svc-lqk6m [752.93621ms]
    Apr 23 11:13:57.415: INFO: Created: latency-svc-v7pdl
    Apr 23 11:13:57.429: INFO: Got endpoints: latency-svc-72plr [755.260076ms]
    Apr 23 11:13:57.481: INFO: Created: latency-svc-tm4bm
    Apr 23 11:13:57.509: INFO: Got endpoints: latency-svc-hb65r [780.658335ms]
    Apr 23 11:13:57.535: INFO: Got endpoints: latency-svc-z7jms [761.315022ms]
    Apr 23 11:13:57.542: INFO: Created: latency-svc-74h2w
    Apr 23 11:13:57.555: INFO: Created: latency-svc-x8kzm
    Apr 23 11:13:57.580: INFO: Got endpoints: latency-svc-tvwgk [747.374899ms]
    Apr 23 11:13:57.608: INFO: Created: latency-svc-m7bx8
    Apr 23 11:13:57.628: INFO: Got endpoints: latency-svc-t4qdl [747.31559ms]
    Apr 23 11:13:57.645: INFO: Created: latency-svc-6mkxw
    Apr 23 11:13:57.677: INFO: Got endpoints: latency-svc-dnsfm [749.720798ms]
    Apr 23 11:13:57.693: INFO: Created: latency-svc-972vs
    Apr 23 11:13:57.726: INFO: Got endpoints: latency-svc-hl82b [746.127256ms]
    Apr 23 11:13:57.755: INFO: Created: latency-svc-p59m8
    Apr 23 11:13:57.786: INFO: Got endpoints: latency-svc-8v9lm [753.315125ms]
    Apr 23 11:13:57.807: INFO: Created: latency-svc-zpsnw
    Apr 23 11:13:57.829: INFO: Got endpoints: latency-svc-dpl66 [747.410812ms]
    Apr 23 11:13:57.846: INFO: Created: latency-svc-tkjwc
    Apr 23 11:13:57.876: INFO: Got endpoints: latency-svc-h8n68 [749.131694ms]
    Apr 23 11:13:57.898: INFO: Created: latency-svc-c54k5
    Apr 23 11:13:57.927: INFO: Got endpoints: latency-svc-wsgcw [748.952679ms]
    Apr 23 11:13:57.942: INFO: Created: latency-svc-jjdqh
    Apr 23 11:13:57.979: INFO: Got endpoints: latency-svc-2rgtl [747.898277ms]
    Apr 23 11:13:57.997: INFO: Created: latency-svc-p52c4
    Apr 23 11:13:58.023: INFO: Got endpoints: latency-svc-htq5m [746.952206ms]
    Apr 23 11:13:58.047: INFO: Created: latency-svc-dl6t2
    Apr 23 11:13:58.074: INFO: Got endpoints: latency-svc-8g2q9 [747.953242ms]
    Apr 23 11:13:58.091: INFO: Created: latency-svc-cqnxj
    Apr 23 11:13:58.132: INFO: Got endpoints: latency-svc-v7pdl [749.550205ms]
    Apr 23 11:13:58.149: INFO: Created: latency-svc-jz9bz
    Apr 23 11:13:58.175: INFO: Got endpoints: latency-svc-tm4bm [746.237504ms]
    Apr 23 11:13:58.190: INFO: Created: latency-svc-vd4cz
    Apr 23 11:13:58.226: INFO: Got endpoints: latency-svc-74h2w [716.044607ms]
    Apr 23 11:13:58.243: INFO: Created: latency-svc-vwtvv
    Apr 23 11:13:58.277: INFO: Got endpoints: latency-svc-x8kzm [741.159184ms]
    Apr 23 11:13:58.295: INFO: Created: latency-svc-skq7w
    Apr 23 11:13:58.333: INFO: Got endpoints: latency-svc-m7bx8 [752.27182ms]
    Apr 23 11:13:58.359: INFO: Created: latency-svc-4ctpx
    Apr 23 11:13:58.374: INFO: Got endpoints: latency-svc-6mkxw [745.427691ms]
    Apr 23 11:13:58.399: INFO: Created: latency-svc-5phwl
    Apr 23 11:13:58.427: INFO: Got endpoints: latency-svc-972vs [749.288678ms]
    Apr 23 11:13:58.452: INFO: Created: latency-svc-hmbc6
    Apr 23 11:13:58.485: INFO: Got endpoints: latency-svc-p59m8 [758.702274ms]
    Apr 23 11:13:58.503: INFO: Created: latency-svc-fgdh6
    Apr 23 11:13:58.532: INFO: Got endpoints: latency-svc-zpsnw [746.243183ms]
    Apr 23 11:13:58.608: INFO: Got endpoints: latency-svc-tkjwc [778.582626ms]
    Apr 23 11:13:58.632: INFO: Created: latency-svc-lw52p
    Apr 23 11:13:58.655: INFO: Got endpoints: latency-svc-c54k5 [778.152084ms]
    Apr 23 11:13:58.655: INFO: Created: latency-svc-mng6b
    Apr 23 11:13:58.676: INFO: Got endpoints: latency-svc-jjdqh [748.780453ms]
    Apr 23 11:13:58.696: INFO: Created: latency-svc-hxhtl
    Apr 23 11:13:58.722: INFO: Created: latency-svc-mn755
    Apr 23 11:13:58.734: INFO: Got endpoints: latency-svc-p52c4 [755.000583ms]
    Apr 23 11:13:58.752: INFO: Created: latency-svc-4jcmn
    Apr 23 11:13:58.775: INFO: Got endpoints: latency-svc-dl6t2 [751.535985ms]
    Apr 23 11:13:58.808: INFO: Created: latency-svc-r4v4f
    Apr 23 11:13:58.826: INFO: Got endpoints: latency-svc-cqnxj [751.445225ms]
    Apr 23 11:13:58.850: INFO: Created: latency-svc-qlb9t
    Apr 23 11:13:58.882: INFO: Got endpoints: latency-svc-jz9bz [750.165014ms]
    Apr 23 11:13:58.914: INFO: Created: latency-svc-8w88p
    Apr 23 11:13:58.928: INFO: Got endpoints: latency-svc-vd4cz [752.616531ms]
    Apr 23 11:13:58.960: INFO: Created: latency-svc-w8gts
    Apr 23 11:13:58.979: INFO: Got endpoints: latency-svc-vwtvv [753.761178ms]
    Apr 23 11:13:59.002: INFO: Created: latency-svc-7n2hr
    Apr 23 11:13:59.030: INFO: Got endpoints: latency-svc-skq7w [752.62511ms]
    Apr 23 11:13:59.052: INFO: Created: latency-svc-569gn
    Apr 23 11:13:59.074: INFO: Got endpoints: latency-svc-4ctpx [740.636031ms]
    Apr 23 11:13:59.104: INFO: Created: latency-svc-k2jpw
    Apr 23 11:13:59.133: INFO: Got endpoints: latency-svc-5phwl [758.259494ms]
    Apr 23 11:13:59.164: INFO: Created: latency-svc-jnclq
    Apr 23 11:13:59.181: INFO: Got endpoints: latency-svc-hmbc6 [753.91168ms]
    Apr 23 11:13:59.201: INFO: Created: latency-svc-7jt9g
    Apr 23 11:13:59.223: INFO: Got endpoints: latency-svc-fgdh6 [738.603421ms]
    Apr 23 11:13:59.246: INFO: Created: latency-svc-xz67x
    Apr 23 11:13:59.277: INFO: Got endpoints: latency-svc-lw52p [744.00188ms]
    Apr 23 11:13:59.297: INFO: Created: latency-svc-gtf44
    Apr 23 11:13:59.325: INFO: Got endpoints: latency-svc-mng6b [717.487521ms]
    Apr 23 11:13:59.345: INFO: Created: latency-svc-tp5n8
    Apr 23 11:13:59.383: INFO: Got endpoints: latency-svc-hxhtl [728.516693ms]
    Apr 23 11:13:59.423: INFO: Created: latency-svc-tdcv5
    Apr 23 11:13:59.447: INFO: Got endpoints: latency-svc-mn755 [770.88708ms]
    Apr 23 11:13:59.500: INFO: Got endpoints: latency-svc-4jcmn [765.579822ms]
    Apr 23 11:13:59.513: INFO: Created: latency-svc-h598h
    Apr 23 11:13:59.528: INFO: Created: latency-svc-s5t8p
    Apr 23 11:13:59.535: INFO: Got endpoints: latency-svc-r4v4f [759.473976ms]
    Apr 23 11:13:59.557: INFO: Created: latency-svc-9fh24
    Apr 23 11:13:59.580: INFO: Got endpoints: latency-svc-qlb9t [753.714992ms]
    Apr 23 11:13:59.610: INFO: Created: latency-svc-8g8c5
    Apr 23 11:13:59.632: INFO: Got endpoints: latency-svc-8w88p [749.438193ms]
    Apr 23 11:13:59.653: INFO: Created: latency-svc-jdnnj
    Apr 23 11:13:59.678: INFO: Got endpoints: latency-svc-w8gts [750.008058ms]
    Apr 23 11:13:59.708: INFO: Created: latency-svc-l77qd
    Apr 23 11:13:59.729: INFO: Got endpoints: latency-svc-7n2hr [749.078468ms]
    Apr 23 11:13:59.758: INFO: Created: latency-svc-xhbss
    Apr 23 11:13:59.778: INFO: Got endpoints: latency-svc-569gn [748.033192ms]
    Apr 23 11:13:59.796: INFO: Created: latency-svc-vq4zl
    Apr 23 11:13:59.825: INFO: Got endpoints: latency-svc-k2jpw [751.393563ms]
    Apr 23 11:13:59.848: INFO: Created: latency-svc-r2qqp
    Apr 23 11:13:59.880: INFO: Got endpoints: latency-svc-jnclq [747.399882ms]
    Apr 23 11:13:59.935: INFO: Got endpoints: latency-svc-7jt9g [753.933234ms]
    Apr 23 11:13:59.976: INFO: Got endpoints: latency-svc-xz67x [752.271989ms]
    Apr 23 11:14:00.027: INFO: Got endpoints: latency-svc-gtf44 [749.655047ms]
    Apr 23 11:14:00.079: INFO: Got endpoints: latency-svc-tp5n8 [753.061464ms]
    Apr 23 11:14:00.129: INFO: Got endpoints: latency-svc-tdcv5 [744.728601ms]
    Apr 23 11:14:00.176: INFO: Got endpoints: latency-svc-h598h [728.01059ms]
    Apr 23 11:14:00.230: INFO: Got endpoints: latency-svc-s5t8p [729.932301ms]
    Apr 23 11:14:00.279: INFO: Got endpoints: latency-svc-9fh24 [744.262923ms]
    Apr 23 11:14:00.328: INFO: Got endpoints: latency-svc-8g8c5 [747.957682ms]
    Apr 23 11:14:00.381: INFO: Got endpoints: latency-svc-jdnnj [748.624871ms]
    Apr 23 11:14:00.435: INFO: Got endpoints: latency-svc-l77qd [756.61932ms]
    Apr 23 11:14:00.484: INFO: Got endpoints: latency-svc-xhbss [755.227014ms]
    Apr 23 11:14:00.527: INFO: Got endpoints: latency-svc-vq4zl [749.226897ms]
    Apr 23 11:14:00.581: INFO: Got endpoints: latency-svc-r2qqp [755.596949ms]
    Apr 23 11:14:00.581: INFO: Latencies: [42.645056ms 75.370488ms 86.840648ms 87.581045ms 131.957344ms 134.337879ms 156.96365ms 172.885841ms 193.035859ms 245.612548ms 246.102596ms 250.393599ms 270.905678ms 272.316486ms 295.660714ms 298.763433ms 300.022479ms 303.925847ms 307.616728ms 309.156156ms 312.902768ms 314.17006ms 314.17277ms 314.498041ms 316.52055ms 318.807567ms 319.885218ms 320.243602ms 323.477525ms 324.125705ms 325.656304ms 326.662009ms 333.043856ms 341.420881ms 342.945242ms 350.609945ms 352.663925ms 353.650782ms 353.939878ms 358.081694ms 360.458672ms 361.053639ms 365.408579ms 365.740141ms 367.402481ms 373.097432ms 383.610199ms 384.550259ms 384.798666ms 391.492704ms 391.901512ms 400.087679ms 415.600889ms 418.881392ms 430.863729ms 443.528705ms 444.622915ms 463.219553ms 481.722166ms 504.648342ms 520.418271ms 535.538086ms 586.399515ms 605.910061ms 663.440729ms 664.629871ms 677.930549ms 681.961823ms 691.142913ms 701.248049ms 716.044607ms 716.721977ms 717.084414ms 717.487521ms 725.429168ms 726.875252ms 728.01059ms 728.516693ms 728.637015ms 729.604173ms 729.81709ms 729.932301ms 732.555472ms 734.099209ms 736.175844ms 737.156135ms 737.743728ms 738.603421ms 738.754488ms 739.516112ms 740.108564ms 740.567875ms 740.636031ms 741.159184ms 741.173563ms 741.471334ms 742.144668ms 743.337803ms 743.596848ms 744.00188ms 744.014252ms 744.262923ms 744.728601ms 744.843905ms 745.113338ms 745.306925ms 745.427691ms 745.597981ms 745.752728ms 745.933859ms 746.127256ms 746.237504ms 746.243183ms 746.247439ms 746.952206ms 747.052356ms 747.31559ms 747.374899ms 747.382928ms 747.399882ms 747.410812ms 747.898277ms 747.953242ms 747.957682ms 748.033192ms 748.083936ms 748.309012ms 748.624871ms 748.780453ms 748.843929ms 748.952679ms 749.078468ms 749.131694ms 749.226897ms 749.288678ms 749.438193ms 749.550205ms 749.556436ms 749.655047ms 749.720798ms 749.756031ms 750.008058ms 750.165014ms 750.649785ms 751.393563ms 751.445225ms 751.535985ms 752.090193ms 752.10377ms 752.27182ms 752.271989ms 752.616531ms 752.62511ms 752.653079ms 752.93621ms 753.061464ms 753.315125ms 753.714992ms 753.761178ms 753.91168ms 753.933234ms 754.229762ms 754.333423ms 754.720143ms 755.000583ms 755.040924ms 755.227014ms 755.260076ms 755.454456ms 755.596949ms 756.61932ms 757.370618ms 758.259494ms 758.702274ms 759.169168ms 759.473976ms 759.639536ms 760.653627ms 761.036235ms 761.315022ms 762.359062ms 763.364852ms 765.579822ms 768.178153ms 770.470387ms 770.847221ms 770.88708ms 771.658345ms 773.042454ms 774.655377ms 775.756761ms 775.886654ms 776.588583ms 778.152084ms 778.402497ms 778.582626ms 780.658335ms 781.610189ms 791.230877ms 829.994174ms]
    Apr 23 11:14:00.582: INFO: 50 %ile: 744.014252ms
    Apr 23 11:14:00.582: INFO: 90 %ile: 762.359062ms
    Apr 23 11:14:00.582: INFO: 99 %ile: 791.230877ms
    Apr 23 11:14:00.582: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:14:00.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Service endpoints latency
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Service endpoints latency
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Service endpoints latency
      tear down framework | framework.go:193
    STEP: Destroying namespace "svc-latency-8999" for this suite. 04/23/23 11:14:00.598
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:803
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:14:00.633
Apr 23 11:14:00.633: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename resourcequota 04/23/23 11:14:00.636
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:00.665
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:00.669
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:803
STEP: Creating a ResourceQuota with best effort scope 04/23/23 11:14:00.673
STEP: Ensuring ResourceQuota status is calculated 04/23/23 11:14:00.687
STEP: Creating a ResourceQuota with not best effort scope 04/23/23 11:14:02.694
STEP: Ensuring ResourceQuota status is calculated 04/23/23 11:14:02.703
STEP: Creating a best-effort pod 04/23/23 11:14:04.708
STEP: Ensuring resource quota with best effort scope captures the pod usage 04/23/23 11:14:04.735
STEP: Ensuring resource quota with not best effort ignored the pod usage 04/23/23 11:14:06.752
STEP: Deleting the pod 04/23/23 11:14:08.761
STEP: Ensuring resource quota status released the pod usage 04/23/23 11:14:08.804
STEP: Creating a not best-effort pod 04/23/23 11:14:10.832
STEP: Ensuring resource quota with not best effort scope captures the pod usage 04/23/23 11:14:10.89
STEP: Ensuring resource quota with best effort scope ignored the pod usage 04/23/23 11:14:12.899
STEP: Deleting the pod 04/23/23 11:14:14.906
STEP: Ensuring resource quota status released the pod usage 04/23/23 11:14:14.937
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Apr 23 11:14:16.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-8926" for this suite. 04/23/23 11:14:16.95
------------------------------
â€¢ [SLOW TEST] [16.329 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:803

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:14:00.633
    Apr 23 11:14:00.633: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename resourcequota 04/23/23 11:14:00.636
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:00.665
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:00.669
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:803
    STEP: Creating a ResourceQuota with best effort scope 04/23/23 11:14:00.673
    STEP: Ensuring ResourceQuota status is calculated 04/23/23 11:14:00.687
    STEP: Creating a ResourceQuota with not best effort scope 04/23/23 11:14:02.694
    STEP: Ensuring ResourceQuota status is calculated 04/23/23 11:14:02.703
    STEP: Creating a best-effort pod 04/23/23 11:14:04.708
    STEP: Ensuring resource quota with best effort scope captures the pod usage 04/23/23 11:14:04.735
    STEP: Ensuring resource quota with not best effort ignored the pod usage 04/23/23 11:14:06.752
    STEP: Deleting the pod 04/23/23 11:14:08.761
    STEP: Ensuring resource quota status released the pod usage 04/23/23 11:14:08.804
    STEP: Creating a not best-effort pod 04/23/23 11:14:10.832
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 04/23/23 11:14:10.89
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 04/23/23 11:14:12.899
    STEP: Deleting the pod 04/23/23 11:14:14.906
    STEP: Ensuring resource quota status released the pod usage 04/23/23 11:14:14.937
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:14:16.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-8926" for this suite. 04/23/23 11:14:16.95
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:14:16.963
Apr 23 11:14:16.964: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename lease-test 04/23/23 11:14:16.972
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:16.999
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:17.004
[BeforeEach] [sig-node] Lease
  test/e2e/framework/metrics/init/init.go:31
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/node/init/init.go:32
Apr 23 11:14:17.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Lease
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Lease
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Lease
  tear down framework | framework.go:193
STEP: Destroying namespace "lease-test-362" for this suite. 04/23/23 11:14:17.097
------------------------------
â€¢ [0.147 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:14:16.963
    Apr 23 11:14:16.964: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename lease-test 04/23/23 11:14:16.972
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:16.999
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:17.004
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/metrics/init/init.go:31
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:14:17.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Lease
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Lease
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Lease
      tear down framework | framework.go:193
    STEP: Destroying namespace "lease-test-362" for this suite. 04/23/23 11:14:17.097
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:742
[BeforeEach] [sig-auth] ServiceAccounts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:14:17.111
Apr 23 11:14:17.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename svcaccounts 04/23/23 11:14:17.114
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:17.137
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:17.143
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:31
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:742
Apr 23 11:14:17.151: INFO: Got root ca configmap in namespace "svcaccounts-8729"
Apr 23 11:14:17.160: INFO: Deleted root ca configmap in namespace "svcaccounts-8729"
STEP: waiting for a new root ca configmap created 04/23/23 11:14:17.661
Apr 23 11:14:17.667: INFO: Recreated root ca configmap in namespace "svcaccounts-8729"
Apr 23 11:14:17.677: INFO: Updated root ca configmap in namespace "svcaccounts-8729"
STEP: waiting for the root ca configmap reconciled 04/23/23 11:14:18.177
Apr 23 11:14:18.184: INFO: Reconciled root ca configmap in namespace "svcaccounts-8729"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/node/init/init.go:32
Apr 23 11:14:18.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  tear down framework | framework.go:193
STEP: Destroying namespace "svcaccounts-8729" for this suite. 04/23/23 11:14:18.193
------------------------------
â€¢ [1.094 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:742

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:14:17.111
    Apr 23 11:14:17.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename svcaccounts 04/23/23 11:14:17.114
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:17.137
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:17.143
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:31
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:742
    Apr 23 11:14:17.151: INFO: Got root ca configmap in namespace "svcaccounts-8729"
    Apr 23 11:14:17.160: INFO: Deleted root ca configmap in namespace "svcaccounts-8729"
    STEP: waiting for a new root ca configmap created 04/23/23 11:14:17.661
    Apr 23 11:14:17.667: INFO: Recreated root ca configmap in namespace "svcaccounts-8729"
    Apr 23 11:14:17.677: INFO: Updated root ca configmap in namespace "svcaccounts-8729"
    STEP: waiting for the root ca configmap reconciled 04/23/23 11:14:18.177
    Apr 23 11:14:18.184: INFO: Reconciled root ca configmap in namespace "svcaccounts-8729"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:14:18.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      tear down framework | framework.go:193
    STEP: Destroying namespace "svcaccounts-8729" for this suite. 04/23/23 11:14:18.193
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:14:18.207
Apr 23 11:14:18.207: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pod-network-test 04/23/23 11:14:18.21
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:18.235
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:18.239
[BeforeEach] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:31
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-3547 04/23/23 11:14:18.243
STEP: creating a selector 04/23/23 11:14:18.244
STEP: Creating the service pods in kubernetes 04/23/23 11:14:18.245
Apr 23 11:14:18.245: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 23 11:14:18.320: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3547" to be "running and ready"
Apr 23 11:14:18.347: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 26.700747ms
Apr 23 11:14:18.347: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:14:20.353: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.033157578s
Apr 23 11:14:20.353: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:14:22.354: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.033611371s
Apr 23 11:14:22.354: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:14:24.358: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.037549908s
Apr 23 11:14:24.358: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:14:26.356: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.035740973s
Apr 23 11:14:26.356: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:14:28.355: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.035180696s
Apr 23 11:14:28.355: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:14:30.355: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.034973155s
Apr 23 11:14:30.355: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:14:32.357: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.036621175s
Apr 23 11:14:32.357: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:14:34.352: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.032313451s
Apr 23 11:14:34.353: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:14:36.356: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.03569445s
Apr 23 11:14:36.356: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:14:38.359: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.0389357s
Apr 23 11:14:38.359: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:14:40.354: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.033684118s
Apr 23 11:14:40.354: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 23 11:14:40.354: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 23 11:14:40.359: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3547" to be "running and ready"
Apr 23 11:14:40.365: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 6.180666ms
Apr 23 11:14:40.365: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 23 11:14:40.365: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 23 11:14:40.370: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3547" to be "running and ready"
Apr 23 11:14:40.375: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 5.297497ms
Apr 23 11:14:40.375: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 23 11:14:40.375: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/23/23 11:14:40.38
Apr 23 11:14:40.402: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3547" to be "running"
Apr 23 11:14:40.415: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.755404ms
Apr 23 11:14:42.422: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.018988086s
Apr 23 11:14:42.422: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 23 11:14:42.428: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-3547" to be "running"
Apr 23 11:14:42.433: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.345616ms
Apr 23 11:14:42.433: INFO: Pod "host-test-container-pod" satisfied condition "running"
Apr 23 11:14:42.440: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 23 11:14:42.440: INFO: Going to poll 10.233.65.148 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 23 11:14:42.445: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.65.148 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3547 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 11:14:42.445: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:14:42.447: INFO: ExecWithOptions: Clientset creation
Apr 23 11:14:42.447: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3547/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.65.148+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 23 11:14:43.612: INFO: Found all 1 expected endpoints: [netserver-0]
Apr 23 11:14:43.612: INFO: Going to poll 10.233.66.82 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 23 11:14:43.619: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.66.82 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3547 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 11:14:43.620: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:14:43.621: INFO: ExecWithOptions: Clientset creation
Apr 23 11:14:43.621: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3547/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.66.82+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 23 11:14:44.743: INFO: Found all 1 expected endpoints: [netserver-1]
Apr 23 11:14:44.743: INFO: Going to poll 10.233.64.160 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 23 11:14:44.759: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.64.160 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3547 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 11:14:44.759: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:14:44.761: INFO: ExecWithOptions: Clientset creation
Apr 23 11:14:44.761: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3547/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.64.160+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 23 11:14:45.858: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/node/init/init.go:32
Apr 23 11:14:45.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Networking
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Networking
  tear down framework | framework.go:193
STEP: Destroying namespace "pod-network-test-3547" for this suite. 04/23/23 11:14:45.868
------------------------------
â€¢ [SLOW TEST] [27.686 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:14:18.207
    Apr 23 11:14:18.207: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pod-network-test 04/23/23 11:14:18.21
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:18.235
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:18.239
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:31
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-3547 04/23/23 11:14:18.243
    STEP: creating a selector 04/23/23 11:14:18.244
    STEP: Creating the service pods in kubernetes 04/23/23 11:14:18.245
    Apr 23 11:14:18.245: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 23 11:14:18.320: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3547" to be "running and ready"
    Apr 23 11:14:18.347: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 26.700747ms
    Apr 23 11:14:18.347: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:14:20.353: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.033157578s
    Apr 23 11:14:20.353: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:14:22.354: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.033611371s
    Apr 23 11:14:22.354: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:14:24.358: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.037549908s
    Apr 23 11:14:24.358: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:14:26.356: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.035740973s
    Apr 23 11:14:26.356: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:14:28.355: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.035180696s
    Apr 23 11:14:28.355: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:14:30.355: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.034973155s
    Apr 23 11:14:30.355: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:14:32.357: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.036621175s
    Apr 23 11:14:32.357: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:14:34.352: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.032313451s
    Apr 23 11:14:34.353: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:14:36.356: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.03569445s
    Apr 23 11:14:36.356: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:14:38.359: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.0389357s
    Apr 23 11:14:38.359: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:14:40.354: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.033684118s
    Apr 23 11:14:40.354: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 23 11:14:40.354: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 23 11:14:40.359: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3547" to be "running and ready"
    Apr 23 11:14:40.365: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 6.180666ms
    Apr 23 11:14:40.365: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 23 11:14:40.365: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 23 11:14:40.370: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3547" to be "running and ready"
    Apr 23 11:14:40.375: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 5.297497ms
    Apr 23 11:14:40.375: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 23 11:14:40.375: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/23/23 11:14:40.38
    Apr 23 11:14:40.402: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3547" to be "running"
    Apr 23 11:14:40.415: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.755404ms
    Apr 23 11:14:42.422: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.018988086s
    Apr 23 11:14:42.422: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 23 11:14:42.428: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-3547" to be "running"
    Apr 23 11:14:42.433: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.345616ms
    Apr 23 11:14:42.433: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Apr 23 11:14:42.440: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 23 11:14:42.440: INFO: Going to poll 10.233.65.148 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Apr 23 11:14:42.445: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.65.148 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3547 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 11:14:42.445: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:14:42.447: INFO: ExecWithOptions: Clientset creation
    Apr 23 11:14:42.447: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3547/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.65.148+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 23 11:14:43.612: INFO: Found all 1 expected endpoints: [netserver-0]
    Apr 23 11:14:43.612: INFO: Going to poll 10.233.66.82 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Apr 23 11:14:43.619: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.66.82 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3547 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 11:14:43.620: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:14:43.621: INFO: ExecWithOptions: Clientset creation
    Apr 23 11:14:43.621: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3547/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.66.82+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 23 11:14:44.743: INFO: Found all 1 expected endpoints: [netserver-1]
    Apr 23 11:14:44.743: INFO: Going to poll 10.233.64.160 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Apr 23 11:14:44.759: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.64.160 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3547 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 11:14:44.759: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:14:44.761: INFO: ExecWithOptions: Clientset creation
    Apr 23 11:14:44.761: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3547/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.64.160+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 23 11:14:45.858: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:14:45.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Networking
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Networking
      tear down framework | framework.go:193
    STEP: Destroying namespace "pod-network-test-3547" for this suite. 04/23/23 11:14:45.868
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1812
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:14:45.901
Apr 23 11:14:45.901: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 11:14:45.903
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:45.935
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:45.94
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1812
STEP: Starting the proxy 04/23/23 11:14:45.946
Apr 23 11:14:45.947: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-6230 proxy --unix-socket=/tmp/kubectl-proxy-unix2710696935/test'
STEP: retrieving proxy /api/ output 04/23/23 11:14:46.073
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 11:14:46.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-6230" for this suite. 04/23/23 11:14:46.083
------------------------------
â€¢ [0.194 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1780
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1812

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:14:45.901
    Apr 23 11:14:45.901: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 11:14:45.903
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:45.935
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:45.94
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1812
    STEP: Starting the proxy 04/23/23 11:14:45.946
    Apr 23 11:14:45.947: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-6230 proxy --unix-socket=/tmp/kubectl-proxy-unix2710696935/test'
    STEP: retrieving proxy /api/ output 04/23/23 11:14:46.073
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:14:46.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-6230" for this suite. 04/23/23 11:14:46.083
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:100
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:14:46.096
Apr 23 11:14:46.096: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename resourcequota 04/23/23 11:14:46.098
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:46.117
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:46.121
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:100
STEP: Counting existing ResourceQuota 04/23/23 11:14:46.125
STEP: Creating a ResourceQuota 04/23/23 11:14:51.133
STEP: Ensuring resource quota status is calculated 04/23/23 11:14:51.151
STEP: Creating a Service 04/23/23 11:14:53.162
STEP: Creating a NodePort Service 04/23/23 11:14:53.206
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 04/23/23 11:14:53.387
STEP: Ensuring resource quota status captures service creation 04/23/23 11:14:53.499
STEP: Deleting Services 04/23/23 11:14:55.509
STEP: Ensuring resource quota status released usage 04/23/23 11:14:55.586
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Apr 23 11:14:57.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-2564" for this suite. 04/23/23 11:14:57.609
------------------------------
â€¢ [SLOW TEST] [11.529 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:14:46.096
    Apr 23 11:14:46.096: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename resourcequota 04/23/23 11:14:46.098
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:46.117
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:46.121
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:100
    STEP: Counting existing ResourceQuota 04/23/23 11:14:46.125
    STEP: Creating a ResourceQuota 04/23/23 11:14:51.133
    STEP: Ensuring resource quota status is calculated 04/23/23 11:14:51.151
    STEP: Creating a Service 04/23/23 11:14:53.162
    STEP: Creating a NodePort Service 04/23/23 11:14:53.206
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 04/23/23 11:14:53.387
    STEP: Ensuring resource quota status captures service creation 04/23/23 11:14:53.499
    STEP: Deleting Services 04/23/23 11:14:55.509
    STEP: Ensuring resource quota status released usage 04/23/23 11:14:55.586
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:14:57.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-2564" for this suite. 04/23/23 11:14:57.609
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:14:57.632
Apr 23 11:14:57.632: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubelet-test 04/23/23 11:14:57.635
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:57.681
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:57.69
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/node/init/init.go:32
Apr 23 11:14:57.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Kubelet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Kubelet
  tear down framework | framework.go:193
STEP: Destroying namespace "kubelet-test-7162" for this suite. 04/23/23 11:14:57.806
------------------------------
â€¢ [0.189 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:14:57.632
    Apr 23 11:14:57.632: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubelet-test 04/23/23 11:14:57.635
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:57.681
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:57.69
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:14:57.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Kubelet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Kubelet
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubelet-test-7162" for this suite. 04/23/23 11:14:57.806
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:391
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:14:57.834
Apr 23 11:14:57.834: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 11:14:57.835
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:57.869
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:57.879
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:391
STEP: set up a multi version CRD 04/23/23 11:14:57.885
Apr 23 11:14:57.887: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: rename a version 04/23/23 11:15:03.32
STEP: check the new version name is served 04/23/23 11:15:03.373
STEP: check the old version name is removed 04/23/23 11:15:05.439
STEP: check the other version is not changed 04/23/23 11:15:06.331
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:15:10.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-5971" for this suite. 04/23/23 11:15:10.498
------------------------------
â€¢ [SLOW TEST] [12.696 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:391

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:14:57.834
    Apr 23 11:14:57.834: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 11:14:57.835
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:14:57.869
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:14:57.879
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:391
    STEP: set up a multi version CRD 04/23/23 11:14:57.885
    Apr 23 11:14:57.887: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: rename a version 04/23/23 11:15:03.32
    STEP: check the new version name is served 04/23/23 11:15:03.373
    STEP: check the old version name is removed 04/23/23 11:15:05.439
    STEP: check the other version is not changed 04/23/23 11:15:06.331
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:15:10.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-5971" for this suite. 04/23/23 11:15:10.498
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:267
[BeforeEach] [sig-node] Downward API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:15:10.538
Apr 23 11:15:10.538: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 11:15:10.54
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:15:10.584
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:15:10.593
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:31
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:267
STEP: Creating a pod to test downward api env vars 04/23/23 11:15:10.606
Apr 23 11:15:10.624: INFO: Waiting up to 5m0s for pod "downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec" in namespace "downward-api-176" to be "Succeeded or Failed"
Apr 23 11:15:10.628: INFO: Pod "downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.296688ms
Apr 23 11:15:12.639: INFO: Pod "downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014777642s
Apr 23 11:15:14.634: INFO: Pod "downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010542114s
STEP: Saw pod success 04/23/23 11:15:14.634
Apr 23 11:15:14.635: INFO: Pod "downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec" satisfied condition "Succeeded or Failed"
Apr 23 11:15:14.639: INFO: Trying to get logs from node eingavuivie7-3 pod downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec container dapi-container: <nil>
STEP: delete the pod 04/23/23 11:15:14.664
Apr 23 11:15:14.686: INFO: Waiting for pod downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec to disappear
Apr 23 11:15:14.692: INFO: Pod downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/node/init/init.go:32
Apr 23 11:15:14.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Downward API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Downward API
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-176" for this suite. 04/23/23 11:15:14.703
------------------------------
â€¢ [4.180 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:15:10.538
    Apr 23 11:15:10.538: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 11:15:10.54
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:15:10.584
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:15:10.593
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:267
    STEP: Creating a pod to test downward api env vars 04/23/23 11:15:10.606
    Apr 23 11:15:10.624: INFO: Waiting up to 5m0s for pod "downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec" in namespace "downward-api-176" to be "Succeeded or Failed"
    Apr 23 11:15:10.628: INFO: Pod "downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.296688ms
    Apr 23 11:15:12.639: INFO: Pod "downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014777642s
    Apr 23 11:15:14.634: INFO: Pod "downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010542114s
    STEP: Saw pod success 04/23/23 11:15:14.634
    Apr 23 11:15:14.635: INFO: Pod "downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec" satisfied condition "Succeeded or Failed"
    Apr 23 11:15:14.639: INFO: Trying to get logs from node eingavuivie7-3 pod downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec container dapi-container: <nil>
    STEP: delete the pod 04/23/23 11:15:14.664
    Apr 23 11:15:14.686: INFO: Waiting for pod downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec to disappear
    Apr 23 11:15:14.692: INFO: Pod downward-api-1195cdb8-ba64-4ff6-a0a6-8d91563e1eec no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:15:14.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Downward API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Downward API
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-176" for this suite. 04/23/23 11:15:14.703
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:845
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:15:14.723
Apr 23 11:15:14.723: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pods 04/23/23 11:15:14.725
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:15:14.751
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:15:14.756
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:845
STEP: Create set of pods 04/23/23 11:15:14.764
Apr 23 11:15:14.785: INFO: created test-pod-1
Apr 23 11:15:14.802: INFO: created test-pod-2
Apr 23 11:15:14.835: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 04/23/23 11:15:14.835
Apr 23 11:15:14.836: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-3234' to be running and ready
Apr 23 11:15:14.888: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 23 11:15:14.888: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 23 11:15:14.888: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 23 11:15:14.888: INFO: 0 / 3 pods in namespace 'pods-3234' are running and ready (0 seconds elapsed)
Apr 23 11:15:14.888: INFO: expected 0 pod replicas in namespace 'pods-3234', 0 are Running and Ready.
Apr 23 11:15:14.888: INFO: POD         NODE            PHASE    GRACE  CONDITIONS
Apr 23 11:15:14.888: INFO: test-pod-1  eingavuivie7-3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC  }]
Apr 23 11:15:14.888: INFO: test-pod-2  eingavuivie7-3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC  }]
Apr 23 11:15:14.888: INFO: test-pod-3  eingavuivie7-1  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC  }]
Apr 23 11:15:14.888: INFO: 
Apr 23 11:15:16.906: INFO: 3 / 3 pods in namespace 'pods-3234' are running and ready (2 seconds elapsed)
Apr 23 11:15:16.907: INFO: expected 0 pod replicas in namespace 'pods-3234', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 04/23/23 11:15:16.946
Apr 23 11:15:16.953: INFO: Pod quantity 3 is different from expected quantity 0
Apr 23 11:15:17.962: INFO: Pod quantity 3 is different from expected quantity 0
Apr 23 11:15:18.962: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Apr 23 11:15:19.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-3234" for this suite. 04/23/23 11:15:19.978
------------------------------
â€¢ [SLOW TEST] [5.274 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:845

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:15:14.723
    Apr 23 11:15:14.723: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pods 04/23/23 11:15:14.725
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:15:14.751
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:15:14.756
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:845
    STEP: Create set of pods 04/23/23 11:15:14.764
    Apr 23 11:15:14.785: INFO: created test-pod-1
    Apr 23 11:15:14.802: INFO: created test-pod-2
    Apr 23 11:15:14.835: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 04/23/23 11:15:14.835
    Apr 23 11:15:14.836: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-3234' to be running and ready
    Apr 23 11:15:14.888: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 23 11:15:14.888: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 23 11:15:14.888: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 23 11:15:14.888: INFO: 0 / 3 pods in namespace 'pods-3234' are running and ready (0 seconds elapsed)
    Apr 23 11:15:14.888: INFO: expected 0 pod replicas in namespace 'pods-3234', 0 are Running and Ready.
    Apr 23 11:15:14.888: INFO: POD         NODE            PHASE    GRACE  CONDITIONS
    Apr 23 11:15:14.888: INFO: test-pod-1  eingavuivie7-3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC  }]
    Apr 23 11:15:14.888: INFO: test-pod-2  eingavuivie7-3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC  }]
    Apr 23 11:15:14.888: INFO: test-pod-3  eingavuivie7-1  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 11:15:14 +0000 UTC  }]
    Apr 23 11:15:14.888: INFO: 
    Apr 23 11:15:16.906: INFO: 3 / 3 pods in namespace 'pods-3234' are running and ready (2 seconds elapsed)
    Apr 23 11:15:16.907: INFO: expected 0 pod replicas in namespace 'pods-3234', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 04/23/23 11:15:16.946
    Apr 23 11:15:16.953: INFO: Pod quantity 3 is different from expected quantity 0
    Apr 23 11:15:17.962: INFO: Pod quantity 3 is different from expected quantity 0
    Apr 23 11:15:18.962: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:15:19.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-3234" for this suite. 04/23/23 11:15:19.978
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:636
[BeforeEach] [sig-apps] Job
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:15:20.005
Apr 23 11:15:20.005: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename job 04/23/23 11:15:20.008
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:15:20.055
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:15:20.06
[BeforeEach] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:31
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:636
STEP: Creating a job 04/23/23 11:15:20.068
STEP: Ensure pods equal to parallelism count is attached to the job 04/23/23 11:15:20.08
STEP: patching /status 04/23/23 11:15:22.091
STEP: updating /status 04/23/23 11:15:22.103
STEP: get /status 04/23/23 11:15:22.149
[AfterEach] [sig-apps] Job
  test/e2e/framework/node/init/init.go:32
Apr 23 11:15:22.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Job
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Job
  tear down framework | framework.go:193
STEP: Destroying namespace "job-6487" for this suite. 04/23/23 11:15:22.164
------------------------------
â€¢ [2.171 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:636

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:15:20.005
    Apr 23 11:15:20.005: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename job 04/23/23 11:15:20.008
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:15:20.055
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:15:20.06
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:31
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:636
    STEP: Creating a job 04/23/23 11:15:20.068
    STEP: Ensure pods equal to parallelism count is attached to the job 04/23/23 11:15:20.08
    STEP: patching /status 04/23/23 11:15:22.091
    STEP: updating /status 04/23/23 11:15:22.103
    STEP: get /status 04/23/23 11:15:22.149
    [AfterEach] [sig-apps] Job
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:15:22.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Job
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Job
      tear down framework | framework.go:193
    STEP: Destroying namespace "job-6487" for this suite. 04/23/23 11:15:22.164
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:15:22.185
Apr 23 11:15:22.185: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename gc 04/23/23 11:15:22.187
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:15:22.209
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:15:22.214
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:31
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 04/23/23 11:15:22.229
STEP: create the rc2 04/23/23 11:15:22.243
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 04/23/23 11:15:27.299
STEP: delete the rc simpletest-rc-to-be-deleted 04/23/23 11:15:32.481
STEP: wait for the rc to be deleted 04/23/23 11:15:32.955
Apr 23 11:15:38.701: INFO: 87 pods remaining
Apr 23 11:15:38.701: INFO: 69 pods has nil DeletionTimestamp
Apr 23 11:15:38.701: INFO: 
Apr 23 11:15:43.057: INFO: 76 pods remaining
Apr 23 11:15:43.057: INFO: 50 pods has nil DeletionTimestamp
Apr 23 11:15:43.057: INFO: 
STEP: Gathering metrics 04/23/23 11:15:48.007
Apr 23 11:15:48.334: INFO: Waiting up to 5m0s for pod "kube-controller-manager-eingavuivie7-2" in namespace "kube-system" to be "running and ready"
Apr 23 11:15:48.345: INFO: Pod "kube-controller-manager-eingavuivie7-2": Phase="Running", Reason="", readiness=true. Elapsed: 10.808215ms
Apr 23 11:15:48.345: INFO: The phase of Pod kube-controller-manager-eingavuivie7-2 is Running (Ready = true)
Apr 23 11:15:48.345: INFO: Pod "kube-controller-manager-eingavuivie7-2" satisfied condition "running and ready"
Apr 23 11:15:48.892: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr 23 11:15:48.893: INFO: Deleting pod "simpletest-rc-to-be-deleted-2ft4t" in namespace "gc-4297"
Apr 23 11:15:48.962: INFO: Deleting pod "simpletest-rc-to-be-deleted-2kv5j" in namespace "gc-4297"
Apr 23 11:15:49.102: INFO: Deleting pod "simpletest-rc-to-be-deleted-2nd5s" in namespace "gc-4297"
Apr 23 11:15:49.160: INFO: Deleting pod "simpletest-rc-to-be-deleted-2ts6z" in namespace "gc-4297"
Apr 23 11:15:49.194: INFO: Deleting pod "simpletest-rc-to-be-deleted-444bp" in namespace "gc-4297"
Apr 23 11:15:49.272: INFO: Deleting pod "simpletest-rc-to-be-deleted-4pr2g" in namespace "gc-4297"
Apr 23 11:15:49.331: INFO: Deleting pod "simpletest-rc-to-be-deleted-4wrx2" in namespace "gc-4297"
Apr 23 11:15:49.380: INFO: Deleting pod "simpletest-rc-to-be-deleted-525wz" in namespace "gc-4297"
Apr 23 11:15:49.454: INFO: Deleting pod "simpletest-rc-to-be-deleted-5b8mv" in namespace "gc-4297"
Apr 23 11:15:49.540: INFO: Deleting pod "simpletest-rc-to-be-deleted-5fmcm" in namespace "gc-4297"
Apr 23 11:15:49.621: INFO: Deleting pod "simpletest-rc-to-be-deleted-5qm6j" in namespace "gc-4297"
Apr 23 11:15:49.712: INFO: Deleting pod "simpletest-rc-to-be-deleted-5s2lx" in namespace "gc-4297"
Apr 23 11:15:49.799: INFO: Deleting pod "simpletest-rc-to-be-deleted-6b69b" in namespace "gc-4297"
Apr 23 11:15:49.865: INFO: Deleting pod "simpletest-rc-to-be-deleted-6l6n7" in namespace "gc-4297"
Apr 23 11:15:49.948: INFO: Deleting pod "simpletest-rc-to-be-deleted-6qd5m" in namespace "gc-4297"
Apr 23 11:15:49.982: INFO: Deleting pod "simpletest-rc-to-be-deleted-6t4rg" in namespace "gc-4297"
Apr 23 11:15:50.042: INFO: Deleting pod "simpletest-rc-to-be-deleted-6tm7m" in namespace "gc-4297"
Apr 23 11:15:50.132: INFO: Deleting pod "simpletest-rc-to-be-deleted-78mrl" in namespace "gc-4297"
Apr 23 11:15:50.204: INFO: Deleting pod "simpletest-rc-to-be-deleted-7kb26" in namespace "gc-4297"
Apr 23 11:15:50.321: INFO: Deleting pod "simpletest-rc-to-be-deleted-7lljs" in namespace "gc-4297"
Apr 23 11:15:50.396: INFO: Deleting pod "simpletest-rc-to-be-deleted-82522" in namespace "gc-4297"
Apr 23 11:15:50.717: INFO: Deleting pod "simpletest-rc-to-be-deleted-86v4z" in namespace "gc-4297"
Apr 23 11:15:50.786: INFO: Deleting pod "simpletest-rc-to-be-deleted-8b66b" in namespace "gc-4297"
Apr 23 11:15:50.926: INFO: Deleting pod "simpletest-rc-to-be-deleted-8p9lq" in namespace "gc-4297"
Apr 23 11:15:50.969: INFO: Deleting pod "simpletest-rc-to-be-deleted-8sbvj" in namespace "gc-4297"
Apr 23 11:15:51.138: INFO: Deleting pod "simpletest-rc-to-be-deleted-94tdl" in namespace "gc-4297"
Apr 23 11:15:51.225: INFO: Deleting pod "simpletest-rc-to-be-deleted-96xt5" in namespace "gc-4297"
Apr 23 11:15:51.279: INFO: Deleting pod "simpletest-rc-to-be-deleted-9m89x" in namespace "gc-4297"
Apr 23 11:15:51.331: INFO: Deleting pod "simpletest-rc-to-be-deleted-9nqm7" in namespace "gc-4297"
Apr 23 11:15:51.388: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qk7f" in namespace "gc-4297"
Apr 23 11:15:51.500: INFO: Deleting pod "simpletest-rc-to-be-deleted-9x7zz" in namespace "gc-4297"
Apr 23 11:15:51.767: INFO: Deleting pod "simpletest-rc-to-be-deleted-b6lx9" in namespace "gc-4297"
Apr 23 11:15:51.884: INFO: Deleting pod "simpletest-rc-to-be-deleted-bb7qk" in namespace "gc-4297"
Apr 23 11:15:51.924: INFO: Deleting pod "simpletest-rc-to-be-deleted-bfw86" in namespace "gc-4297"
Apr 23 11:15:51.997: INFO: Deleting pod "simpletest-rc-to-be-deleted-bk267" in namespace "gc-4297"
Apr 23 11:15:52.084: INFO: Deleting pod "simpletest-rc-to-be-deleted-bmr27" in namespace "gc-4297"
Apr 23 11:15:52.122: INFO: Deleting pod "simpletest-rc-to-be-deleted-c98jx" in namespace "gc-4297"
Apr 23 11:15:52.161: INFO: Deleting pod "simpletest-rc-to-be-deleted-cc7cs" in namespace "gc-4297"
Apr 23 11:15:52.220: INFO: Deleting pod "simpletest-rc-to-be-deleted-cnjpg" in namespace "gc-4297"
Apr 23 11:15:52.304: INFO: Deleting pod "simpletest-rc-to-be-deleted-cwglq" in namespace "gc-4297"
Apr 23 11:15:52.388: INFO: Deleting pod "simpletest-rc-to-be-deleted-d695c" in namespace "gc-4297"
Apr 23 11:15:52.563: INFO: Deleting pod "simpletest-rc-to-be-deleted-d6qgt" in namespace "gc-4297"
Apr 23 11:15:52.748: INFO: Deleting pod "simpletest-rc-to-be-deleted-dhbk8" in namespace "gc-4297"
Apr 23 11:15:52.893: INFO: Deleting pod "simpletest-rc-to-be-deleted-dhdgk" in namespace "gc-4297"
Apr 23 11:15:52.961: INFO: Deleting pod "simpletest-rc-to-be-deleted-dk74g" in namespace "gc-4297"
Apr 23 11:15:53.009: INFO: Deleting pod "simpletest-rc-to-be-deleted-dsjq6" in namespace "gc-4297"
Apr 23 11:15:53.121: INFO: Deleting pod "simpletest-rc-to-be-deleted-dt4c8" in namespace "gc-4297"
Apr 23 11:15:53.167: INFO: Deleting pod "simpletest-rc-to-be-deleted-fd55x" in namespace "gc-4297"
Apr 23 11:15:53.266: INFO: Deleting pod "simpletest-rc-to-be-deleted-fgt5w" in namespace "gc-4297"
Apr 23 11:15:53.390: INFO: Deleting pod "simpletest-rc-to-be-deleted-fzdrf" in namespace "gc-4297"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/node/init/init.go:32
Apr 23 11:15:53.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  tear down framework | framework.go:193
STEP: Destroying namespace "gc-4297" for this suite. 04/23/23 11:15:53.494
------------------------------
â€¢ [SLOW TEST] [31.388 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:15:22.185
    Apr 23 11:15:22.185: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename gc 04/23/23 11:15:22.187
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:15:22.209
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:15:22.214
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:31
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 04/23/23 11:15:22.229
    STEP: create the rc2 04/23/23 11:15:22.243
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 04/23/23 11:15:27.299
    STEP: delete the rc simpletest-rc-to-be-deleted 04/23/23 11:15:32.481
    STEP: wait for the rc to be deleted 04/23/23 11:15:32.955
    Apr 23 11:15:38.701: INFO: 87 pods remaining
    Apr 23 11:15:38.701: INFO: 69 pods has nil DeletionTimestamp
    Apr 23 11:15:38.701: INFO: 
    Apr 23 11:15:43.057: INFO: 76 pods remaining
    Apr 23 11:15:43.057: INFO: 50 pods has nil DeletionTimestamp
    Apr 23 11:15:43.057: INFO: 
    STEP: Gathering metrics 04/23/23 11:15:48.007
    Apr 23 11:15:48.334: INFO: Waiting up to 5m0s for pod "kube-controller-manager-eingavuivie7-2" in namespace "kube-system" to be "running and ready"
    Apr 23 11:15:48.345: INFO: Pod "kube-controller-manager-eingavuivie7-2": Phase="Running", Reason="", readiness=true. Elapsed: 10.808215ms
    Apr 23 11:15:48.345: INFO: The phase of Pod kube-controller-manager-eingavuivie7-2 is Running (Ready = true)
    Apr 23 11:15:48.345: INFO: Pod "kube-controller-manager-eingavuivie7-2" satisfied condition "running and ready"
    Apr 23 11:15:48.892: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Apr 23 11:15:48.893: INFO: Deleting pod "simpletest-rc-to-be-deleted-2ft4t" in namespace "gc-4297"
    Apr 23 11:15:48.962: INFO: Deleting pod "simpletest-rc-to-be-deleted-2kv5j" in namespace "gc-4297"
    Apr 23 11:15:49.102: INFO: Deleting pod "simpletest-rc-to-be-deleted-2nd5s" in namespace "gc-4297"
    Apr 23 11:15:49.160: INFO: Deleting pod "simpletest-rc-to-be-deleted-2ts6z" in namespace "gc-4297"
    Apr 23 11:15:49.194: INFO: Deleting pod "simpletest-rc-to-be-deleted-444bp" in namespace "gc-4297"
    Apr 23 11:15:49.272: INFO: Deleting pod "simpletest-rc-to-be-deleted-4pr2g" in namespace "gc-4297"
    Apr 23 11:15:49.331: INFO: Deleting pod "simpletest-rc-to-be-deleted-4wrx2" in namespace "gc-4297"
    Apr 23 11:15:49.380: INFO: Deleting pod "simpletest-rc-to-be-deleted-525wz" in namespace "gc-4297"
    Apr 23 11:15:49.454: INFO: Deleting pod "simpletest-rc-to-be-deleted-5b8mv" in namespace "gc-4297"
    Apr 23 11:15:49.540: INFO: Deleting pod "simpletest-rc-to-be-deleted-5fmcm" in namespace "gc-4297"
    Apr 23 11:15:49.621: INFO: Deleting pod "simpletest-rc-to-be-deleted-5qm6j" in namespace "gc-4297"
    Apr 23 11:15:49.712: INFO: Deleting pod "simpletest-rc-to-be-deleted-5s2lx" in namespace "gc-4297"
    Apr 23 11:15:49.799: INFO: Deleting pod "simpletest-rc-to-be-deleted-6b69b" in namespace "gc-4297"
    Apr 23 11:15:49.865: INFO: Deleting pod "simpletest-rc-to-be-deleted-6l6n7" in namespace "gc-4297"
    Apr 23 11:15:49.948: INFO: Deleting pod "simpletest-rc-to-be-deleted-6qd5m" in namespace "gc-4297"
    Apr 23 11:15:49.982: INFO: Deleting pod "simpletest-rc-to-be-deleted-6t4rg" in namespace "gc-4297"
    Apr 23 11:15:50.042: INFO: Deleting pod "simpletest-rc-to-be-deleted-6tm7m" in namespace "gc-4297"
    Apr 23 11:15:50.132: INFO: Deleting pod "simpletest-rc-to-be-deleted-78mrl" in namespace "gc-4297"
    Apr 23 11:15:50.204: INFO: Deleting pod "simpletest-rc-to-be-deleted-7kb26" in namespace "gc-4297"
    Apr 23 11:15:50.321: INFO: Deleting pod "simpletest-rc-to-be-deleted-7lljs" in namespace "gc-4297"
    Apr 23 11:15:50.396: INFO: Deleting pod "simpletest-rc-to-be-deleted-82522" in namespace "gc-4297"
    Apr 23 11:15:50.717: INFO: Deleting pod "simpletest-rc-to-be-deleted-86v4z" in namespace "gc-4297"
    Apr 23 11:15:50.786: INFO: Deleting pod "simpletest-rc-to-be-deleted-8b66b" in namespace "gc-4297"
    Apr 23 11:15:50.926: INFO: Deleting pod "simpletest-rc-to-be-deleted-8p9lq" in namespace "gc-4297"
    Apr 23 11:15:50.969: INFO: Deleting pod "simpletest-rc-to-be-deleted-8sbvj" in namespace "gc-4297"
    Apr 23 11:15:51.138: INFO: Deleting pod "simpletest-rc-to-be-deleted-94tdl" in namespace "gc-4297"
    Apr 23 11:15:51.225: INFO: Deleting pod "simpletest-rc-to-be-deleted-96xt5" in namespace "gc-4297"
    Apr 23 11:15:51.279: INFO: Deleting pod "simpletest-rc-to-be-deleted-9m89x" in namespace "gc-4297"
    Apr 23 11:15:51.331: INFO: Deleting pod "simpletest-rc-to-be-deleted-9nqm7" in namespace "gc-4297"
    Apr 23 11:15:51.388: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qk7f" in namespace "gc-4297"
    Apr 23 11:15:51.500: INFO: Deleting pod "simpletest-rc-to-be-deleted-9x7zz" in namespace "gc-4297"
    Apr 23 11:15:51.767: INFO: Deleting pod "simpletest-rc-to-be-deleted-b6lx9" in namespace "gc-4297"
    Apr 23 11:15:51.884: INFO: Deleting pod "simpletest-rc-to-be-deleted-bb7qk" in namespace "gc-4297"
    Apr 23 11:15:51.924: INFO: Deleting pod "simpletest-rc-to-be-deleted-bfw86" in namespace "gc-4297"
    Apr 23 11:15:51.997: INFO: Deleting pod "simpletest-rc-to-be-deleted-bk267" in namespace "gc-4297"
    Apr 23 11:15:52.084: INFO: Deleting pod "simpletest-rc-to-be-deleted-bmr27" in namespace "gc-4297"
    Apr 23 11:15:52.122: INFO: Deleting pod "simpletest-rc-to-be-deleted-c98jx" in namespace "gc-4297"
    Apr 23 11:15:52.161: INFO: Deleting pod "simpletest-rc-to-be-deleted-cc7cs" in namespace "gc-4297"
    Apr 23 11:15:52.220: INFO: Deleting pod "simpletest-rc-to-be-deleted-cnjpg" in namespace "gc-4297"
    Apr 23 11:15:52.304: INFO: Deleting pod "simpletest-rc-to-be-deleted-cwglq" in namespace "gc-4297"
    Apr 23 11:15:52.388: INFO: Deleting pod "simpletest-rc-to-be-deleted-d695c" in namespace "gc-4297"
    Apr 23 11:15:52.563: INFO: Deleting pod "simpletest-rc-to-be-deleted-d6qgt" in namespace "gc-4297"
    Apr 23 11:15:52.748: INFO: Deleting pod "simpletest-rc-to-be-deleted-dhbk8" in namespace "gc-4297"
    Apr 23 11:15:52.893: INFO: Deleting pod "simpletest-rc-to-be-deleted-dhdgk" in namespace "gc-4297"
    Apr 23 11:15:52.961: INFO: Deleting pod "simpletest-rc-to-be-deleted-dk74g" in namespace "gc-4297"
    Apr 23 11:15:53.009: INFO: Deleting pod "simpletest-rc-to-be-deleted-dsjq6" in namespace "gc-4297"
    Apr 23 11:15:53.121: INFO: Deleting pod "simpletest-rc-to-be-deleted-dt4c8" in namespace "gc-4297"
    Apr 23 11:15:53.167: INFO: Deleting pod "simpletest-rc-to-be-deleted-fd55x" in namespace "gc-4297"
    Apr 23 11:15:53.266: INFO: Deleting pod "simpletest-rc-to-be-deleted-fgt5w" in namespace "gc-4297"
    Apr 23 11:15:53.390: INFO: Deleting pod "simpletest-rc-to-be-deleted-fzdrf" in namespace "gc-4297"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:15:53.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      tear down framework | framework.go:193
    STEP: Destroying namespace "gc-4297" for this suite. 04/23/23 11:15:53.494
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:227
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:15:53.609
Apr 23 11:15:53.610: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 11:15:53.621
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:15:53.66
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:15:53.667
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:227
STEP: Creating Pod 04/23/23 11:15:53.679
Apr 23 11:15:53.709: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-a8227c52-8d1a-46d4-a517-ccb09d626198" in namespace "emptydir-7285" to be "running"
Apr 23 11:15:53.721: INFO: Pod "pod-sharedvolume-a8227c52-8d1a-46d4-a517-ccb09d626198": Phase="Pending", Reason="", readiness=false. Elapsed: 12.515673ms
Apr 23 11:15:55.732: INFO: Pod "pod-sharedvolume-a8227c52-8d1a-46d4-a517-ccb09d626198": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023419651s
Apr 23 11:15:57.732: INFO: Pod "pod-sharedvolume-a8227c52-8d1a-46d4-a517-ccb09d626198": Phase="Running", Reason="", readiness=false. Elapsed: 4.02348873s
Apr 23 11:15:57.732: INFO: Pod "pod-sharedvolume-a8227c52-8d1a-46d4-a517-ccb09d626198" satisfied condition "running"
STEP: Reading file content from the nginx-container 04/23/23 11:15:57.732
Apr 23 11:15:57.733: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7285 PodName:pod-sharedvolume-a8227c52-8d1a-46d4-a517-ccb09d626198 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 11:15:57.733: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:15:57.734: INFO: ExecWithOptions: Clientset creation
Apr 23 11:15:57.735: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/emptydir-7285/pods/pod-sharedvolume-a8227c52-8d1a-46d4-a517-ccb09d626198/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Apr 23 11:15:57.850: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 11:15:57.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-7285" for this suite. 04/23/23 11:15:57.863
------------------------------
â€¢ [4.268 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:227

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:15:53.609
    Apr 23 11:15:53.610: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 11:15:53.621
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:15:53.66
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:15:53.667
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:227
    STEP: Creating Pod 04/23/23 11:15:53.679
    Apr 23 11:15:53.709: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-a8227c52-8d1a-46d4-a517-ccb09d626198" in namespace "emptydir-7285" to be "running"
    Apr 23 11:15:53.721: INFO: Pod "pod-sharedvolume-a8227c52-8d1a-46d4-a517-ccb09d626198": Phase="Pending", Reason="", readiness=false. Elapsed: 12.515673ms
    Apr 23 11:15:55.732: INFO: Pod "pod-sharedvolume-a8227c52-8d1a-46d4-a517-ccb09d626198": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023419651s
    Apr 23 11:15:57.732: INFO: Pod "pod-sharedvolume-a8227c52-8d1a-46d4-a517-ccb09d626198": Phase="Running", Reason="", readiness=false. Elapsed: 4.02348873s
    Apr 23 11:15:57.732: INFO: Pod "pod-sharedvolume-a8227c52-8d1a-46d4-a517-ccb09d626198" satisfied condition "running"
    STEP: Reading file content from the nginx-container 04/23/23 11:15:57.732
    Apr 23 11:15:57.733: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7285 PodName:pod-sharedvolume-a8227c52-8d1a-46d4-a517-ccb09d626198 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 11:15:57.733: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:15:57.734: INFO: ExecWithOptions: Clientset creation
    Apr 23 11:15:57.735: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/emptydir-7285/pods/pod-sharedvolume-a8227c52-8d1a-46d4-a517-ccb09d626198/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Apr 23 11:15:57.850: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:15:57.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-7285" for this suite. 04/23/23 11:15:57.863
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1515
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:15:57.88
Apr 23 11:15:57.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 11:15:57.884
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:15:57.913
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:15:57.919
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1515
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7391 04/23/23 11:15:57.929
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/23/23 11:15:57.952
STEP: creating service externalsvc in namespace services-7391 04/23/23 11:15:57.953
STEP: creating replication controller externalsvc in namespace services-7391 04/23/23 11:15:58.015
I0423 11:15:58.046856      13 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7391, replica count: 2
I0423 11:16:01.099218      13 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:16:04.099980      13 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:16:07.100886      13 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 04/23/23 11:16:07.117
Apr 23 11:16:07.180: INFO: Creating new exec pod
Apr 23 11:16:07.206: INFO: Waiting up to 5m0s for pod "execpodwzbt6" in namespace "services-7391" to be "running"
Apr 23 11:16:07.228: INFO: Pod "execpodwzbt6": Phase="Pending", Reason="", readiness=false. Elapsed: 22.023561ms
Apr 23 11:16:09.237: INFO: Pod "execpodwzbt6": Phase="Running", Reason="", readiness=true. Elapsed: 2.030542449s
Apr 23 11:16:09.237: INFO: Pod "execpodwzbt6" satisfied condition "running"
Apr 23 11:16:09.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-7391 exec execpodwzbt6 -- /bin/sh -x -c nslookup clusterip-service.services-7391.svc.cluster.local'
Apr 23 11:16:09.778: INFO: stderr: "+ nslookup clusterip-service.services-7391.svc.cluster.local\n"
Apr 23 11:16:09.778: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nclusterip-service.services-7391.svc.cluster.local\tcanonical name = externalsvc.services-7391.svc.cluster.local.\nName:\texternalsvc.services-7391.svc.cluster.local\nAddress: 10.233.34.138\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7391, will wait for the garbage collector to delete the pods 04/23/23 11:16:09.778
Apr 23 11:16:09.870: INFO: Deleting ReplicationController externalsvc took: 27.572615ms
Apr 23 11:16:09.972: INFO: Terminating ReplicationController externalsvc pods took: 101.614194ms
Apr 23 11:16:12.824: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 11:16:12.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-7391" for this suite. 04/23/23 11:16:12.859
------------------------------
â€¢ [SLOW TEST] [14.994 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1515

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:15:57.88
    Apr 23 11:15:57.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 11:15:57.884
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:15:57.913
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:15:57.919
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1515
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7391 04/23/23 11:15:57.929
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/23/23 11:15:57.952
    STEP: creating service externalsvc in namespace services-7391 04/23/23 11:15:57.953
    STEP: creating replication controller externalsvc in namespace services-7391 04/23/23 11:15:58.015
    I0423 11:15:58.046856      13 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7391, replica count: 2
    I0423 11:16:01.099218      13 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:16:04.099980      13 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:16:07.100886      13 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 04/23/23 11:16:07.117
    Apr 23 11:16:07.180: INFO: Creating new exec pod
    Apr 23 11:16:07.206: INFO: Waiting up to 5m0s for pod "execpodwzbt6" in namespace "services-7391" to be "running"
    Apr 23 11:16:07.228: INFO: Pod "execpodwzbt6": Phase="Pending", Reason="", readiness=false. Elapsed: 22.023561ms
    Apr 23 11:16:09.237: INFO: Pod "execpodwzbt6": Phase="Running", Reason="", readiness=true. Elapsed: 2.030542449s
    Apr 23 11:16:09.237: INFO: Pod "execpodwzbt6" satisfied condition "running"
    Apr 23 11:16:09.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-7391 exec execpodwzbt6 -- /bin/sh -x -c nslookup clusterip-service.services-7391.svc.cluster.local'
    Apr 23 11:16:09.778: INFO: stderr: "+ nslookup clusterip-service.services-7391.svc.cluster.local\n"
    Apr 23 11:16:09.778: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nclusterip-service.services-7391.svc.cluster.local\tcanonical name = externalsvc.services-7391.svc.cluster.local.\nName:\texternalsvc.services-7391.svc.cluster.local\nAddress: 10.233.34.138\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-7391, will wait for the garbage collector to delete the pods 04/23/23 11:16:09.778
    Apr 23 11:16:09.870: INFO: Deleting ReplicationController externalsvc took: 27.572615ms
    Apr 23 11:16:09.972: INFO: Terminating ReplicationController externalsvc pods took: 101.614194ms
    Apr 23 11:16:12.824: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:16:12.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-7391" for this suite. 04/23/23 11:16:12.859
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:16:12.882
Apr 23 11:16:12.882: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename gc 04/23/23 11:16:12.885
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:16:12.908
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:16:12.912
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:31
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 04/23/23 11:16:12.923
STEP: delete the rc 04/23/23 11:16:18.052
STEP: wait for the rc to be deleted 04/23/23 11:16:18.132
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 04/23/23 11:16:23.281
STEP: Gathering metrics 04/23/23 11:16:53.307
Apr 23 11:16:53.341: INFO: Waiting up to 5m0s for pod "kube-controller-manager-eingavuivie7-2" in namespace "kube-system" to be "running and ready"
Apr 23 11:16:53.351: INFO: Pod "kube-controller-manager-eingavuivie7-2": Phase="Running", Reason="", readiness=true. Elapsed: 10.3564ms
Apr 23 11:16:53.351: INFO: The phase of Pod kube-controller-manager-eingavuivie7-2 is Running (Ready = true)
Apr 23 11:16:53.351: INFO: Pod "kube-controller-manager-eingavuivie7-2" satisfied condition "running and ready"
Apr 23 11:16:53.445: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr 23 11:16:53.445: INFO: Deleting pod "simpletest.rc-2hbzg" in namespace "gc-4410"
Apr 23 11:16:53.469: INFO: Deleting pod "simpletest.rc-2k27k" in namespace "gc-4410"
Apr 23 11:16:53.528: INFO: Deleting pod "simpletest.rc-2pkxw" in namespace "gc-4410"
Apr 23 11:16:53.647: INFO: Deleting pod "simpletest.rc-45pjl" in namespace "gc-4410"
Apr 23 11:16:53.724: INFO: Deleting pod "simpletest.rc-478h2" in namespace "gc-4410"
Apr 23 11:16:53.789: INFO: Deleting pod "simpletest.rc-4chpj" in namespace "gc-4410"
Apr 23 11:16:53.858: INFO: Deleting pod "simpletest.rc-4h4pl" in namespace "gc-4410"
Apr 23 11:16:53.923: INFO: Deleting pod "simpletest.rc-4kxgw" in namespace "gc-4410"
Apr 23 11:16:54.011: INFO: Deleting pod "simpletest.rc-4mdtv" in namespace "gc-4410"
Apr 23 11:16:54.064: INFO: Deleting pod "simpletest.rc-4pdnq" in namespace "gc-4410"
Apr 23 11:16:54.098: INFO: Deleting pod "simpletest.rc-4qfws" in namespace "gc-4410"
Apr 23 11:16:54.147: INFO: Deleting pod "simpletest.rc-4xkg9" in namespace "gc-4410"
Apr 23 11:16:54.225: INFO: Deleting pod "simpletest.rc-55tdj" in namespace "gc-4410"
Apr 23 11:16:54.322: INFO: Deleting pod "simpletest.rc-56g74" in namespace "gc-4410"
Apr 23 11:16:54.385: INFO: Deleting pod "simpletest.rc-5n9mj" in namespace "gc-4410"
Apr 23 11:16:54.495: INFO: Deleting pod "simpletest.rc-5nk8d" in namespace "gc-4410"
Apr 23 11:16:54.668: INFO: Deleting pod "simpletest.rc-5pgrw" in namespace "gc-4410"
Apr 23 11:16:54.849: INFO: Deleting pod "simpletest.rc-65fg8" in namespace "gc-4410"
Apr 23 11:16:54.945: INFO: Deleting pod "simpletest.rc-6bsz4" in namespace "gc-4410"
Apr 23 11:16:55.096: INFO: Deleting pod "simpletest.rc-6dvvw" in namespace "gc-4410"
Apr 23 11:16:55.190: INFO: Deleting pod "simpletest.rc-6pg72" in namespace "gc-4410"
Apr 23 11:16:55.274: INFO: Deleting pod "simpletest.rc-6tjz5" in namespace "gc-4410"
Apr 23 11:16:55.396: INFO: Deleting pod "simpletest.rc-7jx8z" in namespace "gc-4410"
Apr 23 11:16:55.490: INFO: Deleting pod "simpletest.rc-7qvsf" in namespace "gc-4410"
Apr 23 11:16:55.785: INFO: Deleting pod "simpletest.rc-7vbmt" in namespace "gc-4410"
Apr 23 11:16:55.917: INFO: Deleting pod "simpletest.rc-8dbkj" in namespace "gc-4410"
Apr 23 11:16:55.975: INFO: Deleting pod "simpletest.rc-8sclx" in namespace "gc-4410"
Apr 23 11:16:56.009: INFO: Deleting pod "simpletest.rc-8x964" in namespace "gc-4410"
Apr 23 11:16:56.040: INFO: Deleting pod "simpletest.rc-9bntq" in namespace "gc-4410"
Apr 23 11:16:56.089: INFO: Deleting pod "simpletest.rc-9cb2q" in namespace "gc-4410"
Apr 23 11:16:56.187: INFO: Deleting pod "simpletest.rc-9hmxj" in namespace "gc-4410"
Apr 23 11:16:56.258: INFO: Deleting pod "simpletest.rc-b8fs5" in namespace "gc-4410"
Apr 23 11:16:56.378: INFO: Deleting pod "simpletest.rc-c6pnr" in namespace "gc-4410"
Apr 23 11:16:56.451: INFO: Deleting pod "simpletest.rc-cs5fj" in namespace "gc-4410"
Apr 23 11:16:56.637: INFO: Deleting pod "simpletest.rc-d8lrc" in namespace "gc-4410"
Apr 23 11:16:56.872: INFO: Deleting pod "simpletest.rc-dff4j" in namespace "gc-4410"
Apr 23 11:16:56.996: INFO: Deleting pod "simpletest.rc-dhrh4" in namespace "gc-4410"
Apr 23 11:16:57.088: INFO: Deleting pod "simpletest.rc-dn4js" in namespace "gc-4410"
Apr 23 11:16:57.199: INFO: Deleting pod "simpletest.rc-dssks" in namespace "gc-4410"
Apr 23 11:16:57.269: INFO: Deleting pod "simpletest.rc-dxdb7" in namespace "gc-4410"
Apr 23 11:16:57.333: INFO: Deleting pod "simpletest.rc-f9nn7" in namespace "gc-4410"
Apr 23 11:16:57.391: INFO: Deleting pod "simpletest.rc-ffsch" in namespace "gc-4410"
Apr 23 11:16:57.465: INFO: Deleting pod "simpletest.rc-fx95d" in namespace "gc-4410"
Apr 23 11:16:57.580: INFO: Deleting pod "simpletest.rc-gps2p" in namespace "gc-4410"
Apr 23 11:16:57.675: INFO: Deleting pod "simpletest.rc-h9nb2" in namespace "gc-4410"
Apr 23 11:16:57.784: INFO: Deleting pod "simpletest.rc-hg5b8" in namespace "gc-4410"
Apr 23 11:16:57.843: INFO: Deleting pod "simpletest.rc-hg7vm" in namespace "gc-4410"
Apr 23 11:16:57.902: INFO: Deleting pod "simpletest.rc-hng84" in namespace "gc-4410"
Apr 23 11:16:58.024: INFO: Deleting pod "simpletest.rc-hq8p5" in namespace "gc-4410"
Apr 23 11:16:58.052: INFO: Deleting pod "simpletest.rc-jcklj" in namespace "gc-4410"
Apr 23 11:16:58.096: INFO: Deleting pod "simpletest.rc-jqjl6" in namespace "gc-4410"
Apr 23 11:16:58.203: INFO: Deleting pod "simpletest.rc-jqxvc" in namespace "gc-4410"
Apr 23 11:16:58.273: INFO: Deleting pod "simpletest.rc-k5gmx" in namespace "gc-4410"
Apr 23 11:16:58.340: INFO: Deleting pod "simpletest.rc-k7bfh" in namespace "gc-4410"
Apr 23 11:16:58.443: INFO: Deleting pod "simpletest.rc-k7bkd" in namespace "gc-4410"
Apr 23 11:16:58.579: INFO: Deleting pod "simpletest.rc-kvw7c" in namespace "gc-4410"
Apr 23 11:16:58.868: INFO: Deleting pod "simpletest.rc-l7g7l" in namespace "gc-4410"
Apr 23 11:16:59.162: INFO: Deleting pod "simpletest.rc-l7swg" in namespace "gc-4410"
Apr 23 11:16:59.332: INFO: Deleting pod "simpletest.rc-ldqwn" in namespace "gc-4410"
Apr 23 11:16:59.410: INFO: Deleting pod "simpletest.rc-lk9km" in namespace "gc-4410"
Apr 23 11:16:59.510: INFO: Deleting pod "simpletest.rc-lt9s6" in namespace "gc-4410"
Apr 23 11:16:59.884: INFO: Deleting pod "simpletest.rc-lvj9b" in namespace "gc-4410"
Apr 23 11:16:59.925: INFO: Deleting pod "simpletest.rc-lx8dg" in namespace "gc-4410"
Apr 23 11:16:59.986: INFO: Deleting pod "simpletest.rc-mcxbd" in namespace "gc-4410"
Apr 23 11:17:00.043: INFO: Deleting pod "simpletest.rc-mn77m" in namespace "gc-4410"
Apr 23 11:17:00.107: INFO: Deleting pod "simpletest.rc-mxpj4" in namespace "gc-4410"
Apr 23 11:17:00.167: INFO: Deleting pod "simpletest.rc-nhdzb" in namespace "gc-4410"
Apr 23 11:17:00.213: INFO: Deleting pod "simpletest.rc-nnhsg" in namespace "gc-4410"
Apr 23 11:17:00.240: INFO: Deleting pod "simpletest.rc-nr28k" in namespace "gc-4410"
Apr 23 11:17:00.320: INFO: Deleting pod "simpletest.rc-ns5fc" in namespace "gc-4410"
Apr 23 11:17:00.377: INFO: Deleting pod "simpletest.rc-phxvx" in namespace "gc-4410"
Apr 23 11:17:00.456: INFO: Deleting pod "simpletest.rc-q7497" in namespace "gc-4410"
Apr 23 11:17:00.582: INFO: Deleting pod "simpletest.rc-qbvg2" in namespace "gc-4410"
Apr 23 11:17:00.707: INFO: Deleting pod "simpletest.rc-qkbdf" in namespace "gc-4410"
Apr 23 11:17:00.855: INFO: Deleting pod "simpletest.rc-qnhrk" in namespace "gc-4410"
Apr 23 11:17:01.073: INFO: Deleting pod "simpletest.rc-r4h88" in namespace "gc-4410"
Apr 23 11:17:01.188: INFO: Deleting pod "simpletest.rc-rkq2l" in namespace "gc-4410"
Apr 23 11:17:01.237: INFO: Deleting pod "simpletest.rc-rvs9r" in namespace "gc-4410"
Apr 23 11:17:01.299: INFO: Deleting pod "simpletest.rc-s8rn6" in namespace "gc-4410"
Apr 23 11:17:01.461: INFO: Deleting pod "simpletest.rc-sdsjt" in namespace "gc-4410"
Apr 23 11:17:01.638: INFO: Deleting pod "simpletest.rc-sq4fw" in namespace "gc-4410"
Apr 23 11:17:01.686: INFO: Deleting pod "simpletest.rc-srqgf" in namespace "gc-4410"
Apr 23 11:17:01.747: INFO: Deleting pod "simpletest.rc-ss5l6" in namespace "gc-4410"
Apr 23 11:17:01.793: INFO: Deleting pod "simpletest.rc-tkvkc" in namespace "gc-4410"
Apr 23 11:17:01.896: INFO: Deleting pod "simpletest.rc-tmrk9" in namespace "gc-4410"
Apr 23 11:17:01.956: INFO: Deleting pod "simpletest.rc-tt5vg" in namespace "gc-4410"
Apr 23 11:17:02.017: INFO: Deleting pod "simpletest.rc-v5tpq" in namespace "gc-4410"
Apr 23 11:17:02.119: INFO: Deleting pod "simpletest.rc-v7pvd" in namespace "gc-4410"
Apr 23 11:17:02.182: INFO: Deleting pod "simpletest.rc-v7wf9" in namespace "gc-4410"
Apr 23 11:17:02.254: INFO: Deleting pod "simpletest.rc-vlpt2" in namespace "gc-4410"
Apr 23 11:17:02.325: INFO: Deleting pod "simpletest.rc-wllj5" in namespace "gc-4410"
Apr 23 11:17:02.424: INFO: Deleting pod "simpletest.rc-wnvnt" in namespace "gc-4410"
Apr 23 11:17:02.651: INFO: Deleting pod "simpletest.rc-wplf6" in namespace "gc-4410"
Apr 23 11:17:02.713: INFO: Deleting pod "simpletest.rc-wvfl2" in namespace "gc-4410"
Apr 23 11:17:02.950: INFO: Deleting pod "simpletest.rc-xhvzr" in namespace "gc-4410"
Apr 23 11:17:03.062: INFO: Deleting pod "simpletest.rc-xsx99" in namespace "gc-4410"
Apr 23 11:17:03.100: INFO: Deleting pod "simpletest.rc-xzb6z" in namespace "gc-4410"
Apr 23 11:17:03.229: INFO: Deleting pod "simpletest.rc-zc2b9" in namespace "gc-4410"
Apr 23 11:17:03.290: INFO: Deleting pod "simpletest.rc-zg7f9" in namespace "gc-4410"
Apr 23 11:17:03.361: INFO: Deleting pod "simpletest.rc-zz7lv" in namespace "gc-4410"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/node/init/init.go:32
Apr 23 11:17:03.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  tear down framework | framework.go:193
STEP: Destroying namespace "gc-4410" for this suite. 04/23/23 11:17:03.48
------------------------------
â€¢ [SLOW TEST] [50.754 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:16:12.882
    Apr 23 11:16:12.882: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename gc 04/23/23 11:16:12.885
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:16:12.908
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:16:12.912
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:31
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 04/23/23 11:16:12.923
    STEP: delete the rc 04/23/23 11:16:18.052
    STEP: wait for the rc to be deleted 04/23/23 11:16:18.132
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 04/23/23 11:16:23.281
    STEP: Gathering metrics 04/23/23 11:16:53.307
    Apr 23 11:16:53.341: INFO: Waiting up to 5m0s for pod "kube-controller-manager-eingavuivie7-2" in namespace "kube-system" to be "running and ready"
    Apr 23 11:16:53.351: INFO: Pod "kube-controller-manager-eingavuivie7-2": Phase="Running", Reason="", readiness=true. Elapsed: 10.3564ms
    Apr 23 11:16:53.351: INFO: The phase of Pod kube-controller-manager-eingavuivie7-2 is Running (Ready = true)
    Apr 23 11:16:53.351: INFO: Pod "kube-controller-manager-eingavuivie7-2" satisfied condition "running and ready"
    Apr 23 11:16:53.445: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Apr 23 11:16:53.445: INFO: Deleting pod "simpletest.rc-2hbzg" in namespace "gc-4410"
    Apr 23 11:16:53.469: INFO: Deleting pod "simpletest.rc-2k27k" in namespace "gc-4410"
    Apr 23 11:16:53.528: INFO: Deleting pod "simpletest.rc-2pkxw" in namespace "gc-4410"
    Apr 23 11:16:53.647: INFO: Deleting pod "simpletest.rc-45pjl" in namespace "gc-4410"
    Apr 23 11:16:53.724: INFO: Deleting pod "simpletest.rc-478h2" in namespace "gc-4410"
    Apr 23 11:16:53.789: INFO: Deleting pod "simpletest.rc-4chpj" in namespace "gc-4410"
    Apr 23 11:16:53.858: INFO: Deleting pod "simpletest.rc-4h4pl" in namespace "gc-4410"
    Apr 23 11:16:53.923: INFO: Deleting pod "simpletest.rc-4kxgw" in namespace "gc-4410"
    Apr 23 11:16:54.011: INFO: Deleting pod "simpletest.rc-4mdtv" in namespace "gc-4410"
    Apr 23 11:16:54.064: INFO: Deleting pod "simpletest.rc-4pdnq" in namespace "gc-4410"
    Apr 23 11:16:54.098: INFO: Deleting pod "simpletest.rc-4qfws" in namespace "gc-4410"
    Apr 23 11:16:54.147: INFO: Deleting pod "simpletest.rc-4xkg9" in namespace "gc-4410"
    Apr 23 11:16:54.225: INFO: Deleting pod "simpletest.rc-55tdj" in namespace "gc-4410"
    Apr 23 11:16:54.322: INFO: Deleting pod "simpletest.rc-56g74" in namespace "gc-4410"
    Apr 23 11:16:54.385: INFO: Deleting pod "simpletest.rc-5n9mj" in namespace "gc-4410"
    Apr 23 11:16:54.495: INFO: Deleting pod "simpletest.rc-5nk8d" in namespace "gc-4410"
    Apr 23 11:16:54.668: INFO: Deleting pod "simpletest.rc-5pgrw" in namespace "gc-4410"
    Apr 23 11:16:54.849: INFO: Deleting pod "simpletest.rc-65fg8" in namespace "gc-4410"
    Apr 23 11:16:54.945: INFO: Deleting pod "simpletest.rc-6bsz4" in namespace "gc-4410"
    Apr 23 11:16:55.096: INFO: Deleting pod "simpletest.rc-6dvvw" in namespace "gc-4410"
    Apr 23 11:16:55.190: INFO: Deleting pod "simpletest.rc-6pg72" in namespace "gc-4410"
    Apr 23 11:16:55.274: INFO: Deleting pod "simpletest.rc-6tjz5" in namespace "gc-4410"
    Apr 23 11:16:55.396: INFO: Deleting pod "simpletest.rc-7jx8z" in namespace "gc-4410"
    Apr 23 11:16:55.490: INFO: Deleting pod "simpletest.rc-7qvsf" in namespace "gc-4410"
    Apr 23 11:16:55.785: INFO: Deleting pod "simpletest.rc-7vbmt" in namespace "gc-4410"
    Apr 23 11:16:55.917: INFO: Deleting pod "simpletest.rc-8dbkj" in namespace "gc-4410"
    Apr 23 11:16:55.975: INFO: Deleting pod "simpletest.rc-8sclx" in namespace "gc-4410"
    Apr 23 11:16:56.009: INFO: Deleting pod "simpletest.rc-8x964" in namespace "gc-4410"
    Apr 23 11:16:56.040: INFO: Deleting pod "simpletest.rc-9bntq" in namespace "gc-4410"
    Apr 23 11:16:56.089: INFO: Deleting pod "simpletest.rc-9cb2q" in namespace "gc-4410"
    Apr 23 11:16:56.187: INFO: Deleting pod "simpletest.rc-9hmxj" in namespace "gc-4410"
    Apr 23 11:16:56.258: INFO: Deleting pod "simpletest.rc-b8fs5" in namespace "gc-4410"
    Apr 23 11:16:56.378: INFO: Deleting pod "simpletest.rc-c6pnr" in namespace "gc-4410"
    Apr 23 11:16:56.451: INFO: Deleting pod "simpletest.rc-cs5fj" in namespace "gc-4410"
    Apr 23 11:16:56.637: INFO: Deleting pod "simpletest.rc-d8lrc" in namespace "gc-4410"
    Apr 23 11:16:56.872: INFO: Deleting pod "simpletest.rc-dff4j" in namespace "gc-4410"
    Apr 23 11:16:56.996: INFO: Deleting pod "simpletest.rc-dhrh4" in namespace "gc-4410"
    Apr 23 11:16:57.088: INFO: Deleting pod "simpletest.rc-dn4js" in namespace "gc-4410"
    Apr 23 11:16:57.199: INFO: Deleting pod "simpletest.rc-dssks" in namespace "gc-4410"
    Apr 23 11:16:57.269: INFO: Deleting pod "simpletest.rc-dxdb7" in namespace "gc-4410"
    Apr 23 11:16:57.333: INFO: Deleting pod "simpletest.rc-f9nn7" in namespace "gc-4410"
    Apr 23 11:16:57.391: INFO: Deleting pod "simpletest.rc-ffsch" in namespace "gc-4410"
    Apr 23 11:16:57.465: INFO: Deleting pod "simpletest.rc-fx95d" in namespace "gc-4410"
    Apr 23 11:16:57.580: INFO: Deleting pod "simpletest.rc-gps2p" in namespace "gc-4410"
    Apr 23 11:16:57.675: INFO: Deleting pod "simpletest.rc-h9nb2" in namespace "gc-4410"
    Apr 23 11:16:57.784: INFO: Deleting pod "simpletest.rc-hg5b8" in namespace "gc-4410"
    Apr 23 11:16:57.843: INFO: Deleting pod "simpletest.rc-hg7vm" in namespace "gc-4410"
    Apr 23 11:16:57.902: INFO: Deleting pod "simpletest.rc-hng84" in namespace "gc-4410"
    Apr 23 11:16:58.024: INFO: Deleting pod "simpletest.rc-hq8p5" in namespace "gc-4410"
    Apr 23 11:16:58.052: INFO: Deleting pod "simpletest.rc-jcklj" in namespace "gc-4410"
    Apr 23 11:16:58.096: INFO: Deleting pod "simpletest.rc-jqjl6" in namespace "gc-4410"
    Apr 23 11:16:58.203: INFO: Deleting pod "simpletest.rc-jqxvc" in namespace "gc-4410"
    Apr 23 11:16:58.273: INFO: Deleting pod "simpletest.rc-k5gmx" in namespace "gc-4410"
    Apr 23 11:16:58.340: INFO: Deleting pod "simpletest.rc-k7bfh" in namespace "gc-4410"
    Apr 23 11:16:58.443: INFO: Deleting pod "simpletest.rc-k7bkd" in namespace "gc-4410"
    Apr 23 11:16:58.579: INFO: Deleting pod "simpletest.rc-kvw7c" in namespace "gc-4410"
    Apr 23 11:16:58.868: INFO: Deleting pod "simpletest.rc-l7g7l" in namespace "gc-4410"
    Apr 23 11:16:59.162: INFO: Deleting pod "simpletest.rc-l7swg" in namespace "gc-4410"
    Apr 23 11:16:59.332: INFO: Deleting pod "simpletest.rc-ldqwn" in namespace "gc-4410"
    Apr 23 11:16:59.410: INFO: Deleting pod "simpletest.rc-lk9km" in namespace "gc-4410"
    Apr 23 11:16:59.510: INFO: Deleting pod "simpletest.rc-lt9s6" in namespace "gc-4410"
    Apr 23 11:16:59.884: INFO: Deleting pod "simpletest.rc-lvj9b" in namespace "gc-4410"
    Apr 23 11:16:59.925: INFO: Deleting pod "simpletest.rc-lx8dg" in namespace "gc-4410"
    Apr 23 11:16:59.986: INFO: Deleting pod "simpletest.rc-mcxbd" in namespace "gc-4410"
    Apr 23 11:17:00.043: INFO: Deleting pod "simpletest.rc-mn77m" in namespace "gc-4410"
    Apr 23 11:17:00.107: INFO: Deleting pod "simpletest.rc-mxpj4" in namespace "gc-4410"
    Apr 23 11:17:00.167: INFO: Deleting pod "simpletest.rc-nhdzb" in namespace "gc-4410"
    Apr 23 11:17:00.213: INFO: Deleting pod "simpletest.rc-nnhsg" in namespace "gc-4410"
    Apr 23 11:17:00.240: INFO: Deleting pod "simpletest.rc-nr28k" in namespace "gc-4410"
    Apr 23 11:17:00.320: INFO: Deleting pod "simpletest.rc-ns5fc" in namespace "gc-4410"
    Apr 23 11:17:00.377: INFO: Deleting pod "simpletest.rc-phxvx" in namespace "gc-4410"
    Apr 23 11:17:00.456: INFO: Deleting pod "simpletest.rc-q7497" in namespace "gc-4410"
    Apr 23 11:17:00.582: INFO: Deleting pod "simpletest.rc-qbvg2" in namespace "gc-4410"
    Apr 23 11:17:00.707: INFO: Deleting pod "simpletest.rc-qkbdf" in namespace "gc-4410"
    Apr 23 11:17:00.855: INFO: Deleting pod "simpletest.rc-qnhrk" in namespace "gc-4410"
    Apr 23 11:17:01.073: INFO: Deleting pod "simpletest.rc-r4h88" in namespace "gc-4410"
    Apr 23 11:17:01.188: INFO: Deleting pod "simpletest.rc-rkq2l" in namespace "gc-4410"
    Apr 23 11:17:01.237: INFO: Deleting pod "simpletest.rc-rvs9r" in namespace "gc-4410"
    Apr 23 11:17:01.299: INFO: Deleting pod "simpletest.rc-s8rn6" in namespace "gc-4410"
    Apr 23 11:17:01.461: INFO: Deleting pod "simpletest.rc-sdsjt" in namespace "gc-4410"
    Apr 23 11:17:01.638: INFO: Deleting pod "simpletest.rc-sq4fw" in namespace "gc-4410"
    Apr 23 11:17:01.686: INFO: Deleting pod "simpletest.rc-srqgf" in namespace "gc-4410"
    Apr 23 11:17:01.747: INFO: Deleting pod "simpletest.rc-ss5l6" in namespace "gc-4410"
    Apr 23 11:17:01.793: INFO: Deleting pod "simpletest.rc-tkvkc" in namespace "gc-4410"
    Apr 23 11:17:01.896: INFO: Deleting pod "simpletest.rc-tmrk9" in namespace "gc-4410"
    Apr 23 11:17:01.956: INFO: Deleting pod "simpletest.rc-tt5vg" in namespace "gc-4410"
    Apr 23 11:17:02.017: INFO: Deleting pod "simpletest.rc-v5tpq" in namespace "gc-4410"
    Apr 23 11:17:02.119: INFO: Deleting pod "simpletest.rc-v7pvd" in namespace "gc-4410"
    Apr 23 11:17:02.182: INFO: Deleting pod "simpletest.rc-v7wf9" in namespace "gc-4410"
    Apr 23 11:17:02.254: INFO: Deleting pod "simpletest.rc-vlpt2" in namespace "gc-4410"
    Apr 23 11:17:02.325: INFO: Deleting pod "simpletest.rc-wllj5" in namespace "gc-4410"
    Apr 23 11:17:02.424: INFO: Deleting pod "simpletest.rc-wnvnt" in namespace "gc-4410"
    Apr 23 11:17:02.651: INFO: Deleting pod "simpletest.rc-wplf6" in namespace "gc-4410"
    Apr 23 11:17:02.713: INFO: Deleting pod "simpletest.rc-wvfl2" in namespace "gc-4410"
    Apr 23 11:17:02.950: INFO: Deleting pod "simpletest.rc-xhvzr" in namespace "gc-4410"
    Apr 23 11:17:03.062: INFO: Deleting pod "simpletest.rc-xsx99" in namespace "gc-4410"
    Apr 23 11:17:03.100: INFO: Deleting pod "simpletest.rc-xzb6z" in namespace "gc-4410"
    Apr 23 11:17:03.229: INFO: Deleting pod "simpletest.rc-zc2b9" in namespace "gc-4410"
    Apr 23 11:17:03.290: INFO: Deleting pod "simpletest.rc-zg7f9" in namespace "gc-4410"
    Apr 23 11:17:03.361: INFO: Deleting pod "simpletest.rc-zz7lv" in namespace "gc-4410"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:17:03.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      tear down framework | framework.go:193
    STEP: Destroying namespace "gc-4410" for this suite. 04/23/23 11:17:03.48
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:17:03.637
Apr 23 11:17:03.638: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename crd-watch 04/23/23 11:17:03.645
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:17:03.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:17:03.748
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Apr 23 11:17:03.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Creating first CR  04/23/23 11:17:06.608
Apr 23 11:17:06.720: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-23T11:17:06Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-23T11:17:06Z]] name:name1 resourceVersion:11520 uid:bfc7af74-5c49-4d1f-aa82-ac15a8d1051e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 04/23/23 11:17:16.722
Apr 23 11:17:16.734: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-23T11:17:16Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-23T11:17:16Z]] name:name2 resourceVersion:12058 uid:b0683ae2-91d4-4083-b58c-3563bc0548e8] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 04/23/23 11:17:26.735
Apr 23 11:17:26.755: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-23T11:17:06Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-23T11:17:26Z]] name:name1 resourceVersion:12081 uid:bfc7af74-5c49-4d1f-aa82-ac15a8d1051e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 04/23/23 11:17:36.756
Apr 23 11:17:36.772: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-23T11:17:16Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-23T11:17:36Z]] name:name2 resourceVersion:12104 uid:b0683ae2-91d4-4083-b58c-3563bc0548e8] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 04/23/23 11:17:46.774
Apr 23 11:17:46.792: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-23T11:17:06Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-23T11:17:26Z]] name:name1 resourceVersion:12127 uid:bfc7af74-5c49-4d1f-aa82-ac15a8d1051e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 04/23/23 11:17:56.793
Apr 23 11:17:56.809: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-23T11:17:16Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-23T11:17:36Z]] name:name2 resourceVersion:12150 uid:b0683ae2-91d4-4083-b58c-3563bc0548e8] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:18:07.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-watch-3429" for this suite. 04/23/23 11:18:07.449
------------------------------
â€¢ [SLOW TEST] [63.825 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:17:03.637
    Apr 23 11:17:03.638: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename crd-watch 04/23/23 11:17:03.645
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:17:03.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:17:03.748
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Apr 23 11:17:03.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Creating first CR  04/23/23 11:17:06.608
    Apr 23 11:17:06.720: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-23T11:17:06Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-23T11:17:06Z]] name:name1 resourceVersion:11520 uid:bfc7af74-5c49-4d1f-aa82-ac15a8d1051e] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 04/23/23 11:17:16.722
    Apr 23 11:17:16.734: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-23T11:17:16Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-23T11:17:16Z]] name:name2 resourceVersion:12058 uid:b0683ae2-91d4-4083-b58c-3563bc0548e8] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 04/23/23 11:17:26.735
    Apr 23 11:17:26.755: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-23T11:17:06Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-23T11:17:26Z]] name:name1 resourceVersion:12081 uid:bfc7af74-5c49-4d1f-aa82-ac15a8d1051e] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 04/23/23 11:17:36.756
    Apr 23 11:17:36.772: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-23T11:17:16Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-23T11:17:36Z]] name:name2 resourceVersion:12104 uid:b0683ae2-91d4-4083-b58c-3563bc0548e8] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 04/23/23 11:17:46.774
    Apr 23 11:17:46.792: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-23T11:17:06Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-23T11:17:26Z]] name:name1 resourceVersion:12127 uid:bfc7af74-5c49-4d1f-aa82-ac15a8d1051e] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 04/23/23 11:17:56.793
    Apr 23 11:17:56.809: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-23T11:17:16Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-23T11:17:36Z]] name:name2 resourceVersion:12150 uid:b0683ae2-91d4-4083-b58c-3563bc0548e8] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:18:07.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-watch-3429" for this suite. 04/23/23 11:18:07.449
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController
  should get and update a ReplicationController scale [Conformance]
  test/e2e/apps/rc.go:402
[BeforeEach] [sig-apps] ReplicationController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:18:07.473
Apr 23 11:18:07.473: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename replication-controller 04/23/23 11:18:07.484
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:18:07.544
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:18:07.549
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:57
[It] should get and update a ReplicationController scale [Conformance]
  test/e2e/apps/rc.go:402
STEP: Creating ReplicationController "e2e-rc-wfszz" 04/23/23 11:18:07.555
Apr 23 11:18:07.564: INFO: Get Replication Controller "e2e-rc-wfszz" to confirm replicas
Apr 23 11:18:08.572: INFO: Get Replication Controller "e2e-rc-wfszz" to confirm replicas
Apr 23 11:18:08.583: INFO: Found 1 replicas for "e2e-rc-wfszz" replication controller
STEP: Getting scale subresource for ReplicationController "e2e-rc-wfszz" 04/23/23 11:18:08.583
STEP: Updating a scale subresource 04/23/23 11:18:08.589
STEP: Verifying replicas where modified for replication controller "e2e-rc-wfszz" 04/23/23 11:18:08.596
Apr 23 11:18:08.597: INFO: Get Replication Controller "e2e-rc-wfszz" to confirm replicas
Apr 23 11:18:09.606: INFO: Get Replication Controller "e2e-rc-wfszz" to confirm replicas
Apr 23 11:18:09.615: INFO: Found 2 replicas for "e2e-rc-wfszz" replication controller
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/node/init/init.go:32
Apr 23 11:18:09.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicationController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicationController
  tear down framework | framework.go:193
STEP: Destroying namespace "replication-controller-4321" for this suite. 04/23/23 11:18:09.625
------------------------------
â€¢ [2.170 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should get and update a ReplicationController scale [Conformance]
  test/e2e/apps/rc.go:402

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:18:07.473
    Apr 23 11:18:07.473: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename replication-controller 04/23/23 11:18:07.484
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:18:07.544
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:18:07.549
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:57
    [It] should get and update a ReplicationController scale [Conformance]
      test/e2e/apps/rc.go:402
    STEP: Creating ReplicationController "e2e-rc-wfszz" 04/23/23 11:18:07.555
    Apr 23 11:18:07.564: INFO: Get Replication Controller "e2e-rc-wfszz" to confirm replicas
    Apr 23 11:18:08.572: INFO: Get Replication Controller "e2e-rc-wfszz" to confirm replicas
    Apr 23 11:18:08.583: INFO: Found 1 replicas for "e2e-rc-wfszz" replication controller
    STEP: Getting scale subresource for ReplicationController "e2e-rc-wfszz" 04/23/23 11:18:08.583
    STEP: Updating a scale subresource 04/23/23 11:18:08.589
    STEP: Verifying replicas where modified for replication controller "e2e-rc-wfszz" 04/23/23 11:18:08.596
    Apr 23 11:18:08.597: INFO: Get Replication Controller "e2e-rc-wfszz" to confirm replicas
    Apr 23 11:18:09.606: INFO: Get Replication Controller "e2e-rc-wfszz" to confirm replicas
    Apr 23 11:18:09.615: INFO: Found 2 replicas for "e2e-rc-wfszz" replication controller
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:18:09.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      tear down framework | framework.go:193
    STEP: Destroying namespace "replication-controller-4321" for this suite. 04/23/23 11:18:09.625
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:135
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:18:09.648
Apr 23 11:18:09.648: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-probe 04/23/23 11:18:09.65
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:18:09.701
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:18:09.711
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:135
STEP: Creating pod busybox-2df156d3-232d-440b-b556-69e2d276d55e in namespace container-probe-4303 04/23/23 11:18:09.731
Apr 23 11:18:09.772: INFO: Waiting up to 5m0s for pod "busybox-2df156d3-232d-440b-b556-69e2d276d55e" in namespace "container-probe-4303" to be "not pending"
Apr 23 11:18:09.799: INFO: Pod "busybox-2df156d3-232d-440b-b556-69e2d276d55e": Phase="Pending", Reason="", readiness=false. Elapsed: 26.804194ms
Apr 23 11:18:11.808: INFO: Pod "busybox-2df156d3-232d-440b-b556-69e2d276d55e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035712986s
Apr 23 11:18:13.808: INFO: Pod "busybox-2df156d3-232d-440b-b556-69e2d276d55e": Phase="Running", Reason="", readiness=true. Elapsed: 4.035728858s
Apr 23 11:18:13.808: INFO: Pod "busybox-2df156d3-232d-440b-b556-69e2d276d55e" satisfied condition "not pending"
Apr 23 11:18:13.808: INFO: Started pod busybox-2df156d3-232d-440b-b556-69e2d276d55e in namespace container-probe-4303
STEP: checking the pod's current state and verifying that restartCount is present 04/23/23 11:18:13.808
Apr 23 11:18:13.814: INFO: Initial restart count of pod busybox-2df156d3-232d-440b-b556-69e2d276d55e is 0
Apr 23 11:19:02.024: INFO: Restart count of pod container-probe-4303/busybox-2df156d3-232d-440b-b556-69e2d276d55e is now 1 (48.21010386s elapsed)
STEP: deleting the pod 04/23/23 11:19:02.024
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Apr 23 11:19:02.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-4303" for this suite. 04/23/23 11:19:02.071
------------------------------
â€¢ [SLOW TEST] [52.449 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:18:09.648
    Apr 23 11:18:09.648: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-probe 04/23/23 11:18:09.65
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:18:09.701
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:18:09.711
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:135
    STEP: Creating pod busybox-2df156d3-232d-440b-b556-69e2d276d55e in namespace container-probe-4303 04/23/23 11:18:09.731
    Apr 23 11:18:09.772: INFO: Waiting up to 5m0s for pod "busybox-2df156d3-232d-440b-b556-69e2d276d55e" in namespace "container-probe-4303" to be "not pending"
    Apr 23 11:18:09.799: INFO: Pod "busybox-2df156d3-232d-440b-b556-69e2d276d55e": Phase="Pending", Reason="", readiness=false. Elapsed: 26.804194ms
    Apr 23 11:18:11.808: INFO: Pod "busybox-2df156d3-232d-440b-b556-69e2d276d55e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035712986s
    Apr 23 11:18:13.808: INFO: Pod "busybox-2df156d3-232d-440b-b556-69e2d276d55e": Phase="Running", Reason="", readiness=true. Elapsed: 4.035728858s
    Apr 23 11:18:13.808: INFO: Pod "busybox-2df156d3-232d-440b-b556-69e2d276d55e" satisfied condition "not pending"
    Apr 23 11:18:13.808: INFO: Started pod busybox-2df156d3-232d-440b-b556-69e2d276d55e in namespace container-probe-4303
    STEP: checking the pod's current state and verifying that restartCount is present 04/23/23 11:18:13.808
    Apr 23 11:18:13.814: INFO: Initial restart count of pod busybox-2df156d3-232d-440b-b556-69e2d276d55e is 0
    Apr 23 11:19:02.024: INFO: Restart count of pod container-probe-4303/busybox-2df156d3-232d-440b-b556-69e2d276d55e is now 1 (48.21010386s elapsed)
    STEP: deleting the pod 04/23/23 11:19:02.024
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:19:02.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-4303" for this suite. 04/23/23 11:19:02.071
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:531
[BeforeEach] [sig-auth] ServiceAccounts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:19:02.108
Apr 23 11:19:02.108: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename svcaccounts 04/23/23 11:19:02.111
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:19:02.159
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:19:02.167
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:31
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:531
Apr 23 11:19:02.202: INFO: created pod
Apr 23 11:19:02.202: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-2476" to be "Succeeded or Failed"
Apr 23 11:19:02.210: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 7.963916ms
Apr 23 11:19:04.218: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015864772s
Apr 23 11:19:06.217: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014506101s
STEP: Saw pod success 04/23/23 11:19:06.217
Apr 23 11:19:06.217: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Apr 23 11:19:36.218: INFO: polling logs
Apr 23 11:19:36.261: INFO: Pod logs: 
I0423 11:19:03.146505       1 log.go:198] OK: Got token
I0423 11:19:03.146659       1 log.go:198] validating with in-cluster discovery
I0423 11:19:03.147984       1 log.go:198] OK: got issuer https://kubernetes.default.svc.cluster.local
I0423 11:19:03.148071       1 log.go:198] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-2476:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682249342, NotBefore:1682248742, IssuedAt:1682248742, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-2476", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"a2d9720f-1dc7-428e-b6f0-31731df04326"}}}
I0423 11:19:03.169337       1 log.go:198] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
I0423 11:19:03.179625       1 log.go:198] OK: Validated signature on JWT
I0423 11:19:03.180051       1 log.go:198] OK: Got valid claims from token!
I0423 11:19:03.180230       1 log.go:198] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-2476:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682249342, NotBefore:1682248742, IssuedAt:1682248742, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-2476", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"a2d9720f-1dc7-428e-b6f0-31731df04326"}}}

Apr 23 11:19:36.261: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/node/init/init.go:32
Apr 23 11:19:36.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  tear down framework | framework.go:193
STEP: Destroying namespace "svcaccounts-2476" for this suite. 04/23/23 11:19:36.288
------------------------------
â€¢ [SLOW TEST] [34.193 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:19:02.108
    Apr 23 11:19:02.108: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename svcaccounts 04/23/23 11:19:02.111
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:19:02.159
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:19:02.167
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:31
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:531
    Apr 23 11:19:02.202: INFO: created pod
    Apr 23 11:19:02.202: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-2476" to be "Succeeded or Failed"
    Apr 23 11:19:02.210: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 7.963916ms
    Apr 23 11:19:04.218: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015864772s
    Apr 23 11:19:06.217: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014506101s
    STEP: Saw pod success 04/23/23 11:19:06.217
    Apr 23 11:19:06.217: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Apr 23 11:19:36.218: INFO: polling logs
    Apr 23 11:19:36.261: INFO: Pod logs: 
    I0423 11:19:03.146505       1 log.go:198] OK: Got token
    I0423 11:19:03.146659       1 log.go:198] validating with in-cluster discovery
    I0423 11:19:03.147984       1 log.go:198] OK: got issuer https://kubernetes.default.svc.cluster.local
    I0423 11:19:03.148071       1 log.go:198] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-2476:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682249342, NotBefore:1682248742, IssuedAt:1682248742, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-2476", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"a2d9720f-1dc7-428e-b6f0-31731df04326"}}}
    I0423 11:19:03.169337       1 log.go:198] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
    I0423 11:19:03.179625       1 log.go:198] OK: Validated signature on JWT
    I0423 11:19:03.180051       1 log.go:198] OK: Got valid claims from token!
    I0423 11:19:03.180230       1 log.go:198] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-2476:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1682249342, NotBefore:1682248742, IssuedAt:1682248742, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-2476", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"a2d9720f-1dc7-428e-b6f0-31731df04326"}}}

    Apr 23 11:19:36.261: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:19:36.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      tear down framework | framework.go:193
    STEP: Destroying namespace "svcaccounts-2476" for this suite. 04/23/23 11:19:36.288
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1509
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:19:36.302
Apr 23 11:19:36.302: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 11:19:36.303
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:19:36.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:19:36.349
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1494
STEP: creating the pod 04/23/23 11:19:36.359
Apr 23 11:19:36.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 create -f -'
Apr 23 11:19:38.097: INFO: stderr: ""
Apr 23 11:19:38.097: INFO: stdout: "pod/pause created\n"
Apr 23 11:19:38.097: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 23 11:19:38.097: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1486" to be "running and ready"
Apr 23 11:19:38.108: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.519869ms
Apr 23 11:19:38.108: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'eingavuivie7-3' to be 'Running' but was 'Pending'
Apr 23 11:19:40.115: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.017623169s
Apr 23 11:19:40.115: INFO: Pod "pause" satisfied condition "running and ready"
Apr 23 11:19:40.115: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1509
STEP: adding the label testing-label with value testing-label-value to a pod 04/23/23 11:19:40.115
Apr 23 11:19:40.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 label pods pause testing-label=testing-label-value'
Apr 23 11:19:40.277: INFO: stderr: ""
Apr 23 11:19:40.277: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 04/23/23 11:19:40.277
Apr 23 11:19:40.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 get pod pause -L testing-label'
Apr 23 11:19:40.445: INFO: stderr: ""
Apr 23 11:19:40.445: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod 04/23/23 11:19:40.445
Apr 23 11:19:40.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 label pods pause testing-label-'
Apr 23 11:19:40.643: INFO: stderr: ""
Apr 23 11:19:40.643: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 04/23/23 11:19:40.644
Apr 23 11:19:40.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 get pod pause -L testing-label'
Apr 23 11:19:40.773: INFO: stderr: ""
Apr 23 11:19:40.773: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1500
STEP: using delete to clean up resources 04/23/23 11:19:40.774
Apr 23 11:19:40.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 delete --grace-period=0 --force -f -'
Apr 23 11:19:40.909: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 11:19:40.909: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 23 11:19:40.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 get rc,svc -l name=pause --no-headers'
Apr 23 11:19:41.093: INFO: stderr: "No resources found in kubectl-1486 namespace.\n"
Apr 23 11:19:41.093: INFO: stdout: ""
Apr 23 11:19:41.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 23 11:19:41.207: INFO: stderr: ""
Apr 23 11:19:41.207: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 11:19:41.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-1486" for this suite. 04/23/23 11:19:41.22
------------------------------
â€¢ [4.930 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1492
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1509

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:19:36.302
    Apr 23 11:19:36.302: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 11:19:36.303
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:19:36.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:19:36.349
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1494
    STEP: creating the pod 04/23/23 11:19:36.359
    Apr 23 11:19:36.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 create -f -'
    Apr 23 11:19:38.097: INFO: stderr: ""
    Apr 23 11:19:38.097: INFO: stdout: "pod/pause created\n"
    Apr 23 11:19:38.097: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Apr 23 11:19:38.097: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1486" to be "running and ready"
    Apr 23 11:19:38.108: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.519869ms
    Apr 23 11:19:38.108: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'eingavuivie7-3' to be 'Running' but was 'Pending'
    Apr 23 11:19:40.115: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.017623169s
    Apr 23 11:19:40.115: INFO: Pod "pause" satisfied condition "running and ready"
    Apr 23 11:19:40.115: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1509
    STEP: adding the label testing-label with value testing-label-value to a pod 04/23/23 11:19:40.115
    Apr 23 11:19:40.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 label pods pause testing-label=testing-label-value'
    Apr 23 11:19:40.277: INFO: stderr: ""
    Apr 23 11:19:40.277: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 04/23/23 11:19:40.277
    Apr 23 11:19:40.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 get pod pause -L testing-label'
    Apr 23 11:19:40.445: INFO: stderr: ""
    Apr 23 11:19:40.445: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 04/23/23 11:19:40.445
    Apr 23 11:19:40.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 label pods pause testing-label-'
    Apr 23 11:19:40.643: INFO: stderr: ""
    Apr 23 11:19:40.643: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 04/23/23 11:19:40.644
    Apr 23 11:19:40.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 get pod pause -L testing-label'
    Apr 23 11:19:40.773: INFO: stderr: ""
    Apr 23 11:19:40.773: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1500
    STEP: using delete to clean up resources 04/23/23 11:19:40.774
    Apr 23 11:19:40.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 delete --grace-period=0 --force -f -'
    Apr 23 11:19:40.909: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 23 11:19:40.909: INFO: stdout: "pod \"pause\" force deleted\n"
    Apr 23 11:19:40.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 get rc,svc -l name=pause --no-headers'
    Apr 23 11:19:41.093: INFO: stderr: "No resources found in kubectl-1486 namespace.\n"
    Apr 23 11:19:41.093: INFO: stdout: ""
    Apr 23 11:19:41.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-1486 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 23 11:19:41.207: INFO: stderr: ""
    Apr 23 11:19:41.207: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:19:41.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-1486" for this suite. 04/23/23 11:19:41.22
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:398
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:19:41.236
Apr 23 11:19:41.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pods 04/23/23 11:19:41.239
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:19:41.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:19:41.269
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:398
STEP: creating the pod 04/23/23 11:19:41.272
STEP: submitting the pod to kubernetes 04/23/23 11:19:41.272
Apr 23 11:19:41.285: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482" in namespace "pods-1532" to be "running and ready"
Apr 23 11:19:41.313: INFO: Pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482": Phase="Pending", Reason="", readiness=false. Elapsed: 27.364736ms
Apr 23 11:19:41.313: INFO: The phase of Pod pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:19:43.321: INFO: Pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482": Phase="Running", Reason="", readiness=true. Elapsed: 2.03519871s
Apr 23 11:19:43.321: INFO: The phase of Pod pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482 is Running (Ready = true)
Apr 23 11:19:43.321: INFO: Pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 04/23/23 11:19:43.325
STEP: updating the pod 04/23/23 11:19:43.329
Apr 23 11:19:43.867: INFO: Successfully updated pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482"
Apr 23 11:19:43.867: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482" in namespace "pods-1532" to be "terminated with reason DeadlineExceeded"
Apr 23 11:19:43.876: INFO: Pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482": Phase="Running", Reason="", readiness=true. Elapsed: 8.987439ms
Apr 23 11:19:45.884: INFO: Pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482": Phase="Running", Reason="", readiness=true. Elapsed: 2.016149244s
Apr 23 11:19:47.886: INFO: Pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.018535446s
Apr 23 11:19:47.886: INFO: Pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Apr 23 11:19:47.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-1532" for this suite. 04/23/23 11:19:47.896
------------------------------
â€¢ [SLOW TEST] [6.676 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:398

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:19:41.236
    Apr 23 11:19:41.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pods 04/23/23 11:19:41.239
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:19:41.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:19:41.269
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:398
    STEP: creating the pod 04/23/23 11:19:41.272
    STEP: submitting the pod to kubernetes 04/23/23 11:19:41.272
    Apr 23 11:19:41.285: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482" in namespace "pods-1532" to be "running and ready"
    Apr 23 11:19:41.313: INFO: Pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482": Phase="Pending", Reason="", readiness=false. Elapsed: 27.364736ms
    Apr 23 11:19:41.313: INFO: The phase of Pod pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:19:43.321: INFO: Pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482": Phase="Running", Reason="", readiness=true. Elapsed: 2.03519871s
    Apr 23 11:19:43.321: INFO: The phase of Pod pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482 is Running (Ready = true)
    Apr 23 11:19:43.321: INFO: Pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 04/23/23 11:19:43.325
    STEP: updating the pod 04/23/23 11:19:43.329
    Apr 23 11:19:43.867: INFO: Successfully updated pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482"
    Apr 23 11:19:43.867: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482" in namespace "pods-1532" to be "terminated with reason DeadlineExceeded"
    Apr 23 11:19:43.876: INFO: Pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482": Phase="Running", Reason="", readiness=true. Elapsed: 8.987439ms
    Apr 23 11:19:45.884: INFO: Pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482": Phase="Running", Reason="", readiness=true. Elapsed: 2.016149244s
    Apr 23 11:19:47.886: INFO: Pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.018535446s
    Apr 23 11:19:47.886: INFO: Pod "pod-update-activedeadlineseconds-d12be939-107e-48de-9806-e53fd52c1482" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:19:47.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-1532" for this suite. 04/23/23 11:19:47.896
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:61
[BeforeEach] [sig-scheduling] LimitRange
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:19:47.913
Apr 23 11:19:47.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename limitrange 04/23/23 11:19:47.918
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:19:47.945
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:19:47.954
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/metrics/init/init.go:31
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:61
STEP: Creating a LimitRange 04/23/23 11:19:47.961
STEP: Setting up watch 04/23/23 11:19:47.962
STEP: Submitting a LimitRange 04/23/23 11:19:48.078
STEP: Verifying LimitRange creation was observed 04/23/23 11:19:48.092
STEP: Fetching the LimitRange to ensure it has proper values 04/23/23 11:19:48.093
Apr 23 11:19:48.098: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 23 11:19:48.098: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 04/23/23 11:19:48.098
STEP: Ensuring Pod has resource requirements applied from LimitRange 04/23/23 11:19:48.106
Apr 23 11:19:48.114: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 23 11:19:48.114: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 04/23/23 11:19:48.115
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 04/23/23 11:19:48.123
Apr 23 11:19:48.128: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Apr 23 11:19:48.128: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 04/23/23 11:19:48.128
STEP: Failing to create a Pod with more than max resources 04/23/23 11:19:48.147
STEP: Updating a LimitRange 04/23/23 11:19:48.15
STEP: Verifying LimitRange updating is effective 04/23/23 11:19:48.157
STEP: Creating a Pod with less than former min resources 04/23/23 11:19:50.164
STEP: Failing to create a Pod with more than max resources 04/23/23 11:19:50.178
STEP: Deleting a LimitRange 04/23/23 11:19:50.188
STEP: Verifying the LimitRange was deleted 04/23/23 11:19:50.204
Apr 23 11:19:55.210: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 04/23/23 11:19:55.21
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/node/init/init.go:32
Apr 23 11:19:55.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-scheduling] LimitRange
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] LimitRange
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] LimitRange
  tear down framework | framework.go:193
STEP: Destroying namespace "limitrange-3629" for this suite. 04/23/23 11:19:55.238
------------------------------
â€¢ [SLOW TEST] [7.336 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:61

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:19:47.913
    Apr 23 11:19:47.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename limitrange 04/23/23 11:19:47.918
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:19:47.945
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:19:47.954
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:61
    STEP: Creating a LimitRange 04/23/23 11:19:47.961
    STEP: Setting up watch 04/23/23 11:19:47.962
    STEP: Submitting a LimitRange 04/23/23 11:19:48.078
    STEP: Verifying LimitRange creation was observed 04/23/23 11:19:48.092
    STEP: Fetching the LimitRange to ensure it has proper values 04/23/23 11:19:48.093
    Apr 23 11:19:48.098: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Apr 23 11:19:48.098: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 04/23/23 11:19:48.098
    STEP: Ensuring Pod has resource requirements applied from LimitRange 04/23/23 11:19:48.106
    Apr 23 11:19:48.114: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Apr 23 11:19:48.114: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 04/23/23 11:19:48.115
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 04/23/23 11:19:48.123
    Apr 23 11:19:48.128: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Apr 23 11:19:48.128: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 04/23/23 11:19:48.128
    STEP: Failing to create a Pod with more than max resources 04/23/23 11:19:48.147
    STEP: Updating a LimitRange 04/23/23 11:19:48.15
    STEP: Verifying LimitRange updating is effective 04/23/23 11:19:48.157
    STEP: Creating a Pod with less than former min resources 04/23/23 11:19:50.164
    STEP: Failing to create a Pod with more than max resources 04/23/23 11:19:50.178
    STEP: Deleting a LimitRange 04/23/23 11:19:50.188
    STEP: Verifying the LimitRange was deleted 04/23/23 11:19:50.204
    Apr 23 11:19:55.210: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 04/23/23 11:19:55.21
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:19:55.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-scheduling] LimitRange
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] LimitRange
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] LimitRange
      tear down framework | framework.go:193
    STEP: Destroying namespace "limitrange-3629" for this suite. 04/23/23 11:19:55.238
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:19:55.253
Apr 23 11:19:55.253: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename events 04/23/23 11:19:55.255
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:19:55.278
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:19:55.282
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/metrics/init/init.go:31
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 04/23/23 11:19:55.287
Apr 23 11:19:55.294: INFO: created test-event-1
Apr 23 11:19:55.300: INFO: created test-event-2
Apr 23 11:19:55.305: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 04/23/23 11:19:55.305
STEP: delete collection of events 04/23/23 11:19:55.31
Apr 23 11:19:55.310: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 04/23/23 11:19:55.337
Apr 23 11:19:55.337: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/node/init/init.go:32
Apr 23 11:19:55.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-instrumentation] Events
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-instrumentation] Events
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-instrumentation] Events
  tear down framework | framework.go:193
STEP: Destroying namespace "events-2162" for this suite. 04/23/23 11:19:55.347
------------------------------
â€¢ [0.105 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:19:55.253
    Apr 23 11:19:55.253: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename events 04/23/23 11:19:55.255
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:19:55.278
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:19:55.282
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/metrics/init/init.go:31
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 04/23/23 11:19:55.287
    Apr 23 11:19:55.294: INFO: created test-event-1
    Apr 23 11:19:55.300: INFO: created test-event-2
    Apr 23 11:19:55.305: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 04/23/23 11:19:55.305
    STEP: delete collection of events 04/23/23 11:19:55.31
    Apr 23 11:19:55.310: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 04/23/23 11:19:55.337
    Apr 23 11:19:55.337: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:19:55.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-instrumentation] Events
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-instrumentation] Events
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-instrumentation] Events
      tear down framework | framework.go:193
    STEP: Destroying namespace "events-2162" for this suite. 04/23/23 11:19:55.347
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:217
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:19:55.385
Apr 23 11:19:55.385: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 11:19:55.387
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:19:55.413
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:19:55.422
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:217
STEP: Creating a pod to test emptydir 0777 on node default medium 04/23/23 11:19:55.427
Apr 23 11:19:55.460: INFO: Waiting up to 5m0s for pod "pod-0b7fbbe5-af49-4381-992a-18d26f1cf632" in namespace "emptydir-9794" to be "Succeeded or Failed"
Apr 23 11:19:55.467: INFO: Pod "pod-0b7fbbe5-af49-4381-992a-18d26f1cf632": Phase="Pending", Reason="", readiness=false. Elapsed: 6.312062ms
Apr 23 11:19:57.472: INFO: Pod "pod-0b7fbbe5-af49-4381-992a-18d26f1cf632": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011973906s
Apr 23 11:19:59.493: INFO: Pod "pod-0b7fbbe5-af49-4381-992a-18d26f1cf632": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032278649s
STEP: Saw pod success 04/23/23 11:19:59.493
Apr 23 11:19:59.493: INFO: Pod "pod-0b7fbbe5-af49-4381-992a-18d26f1cf632" satisfied condition "Succeeded or Failed"
Apr 23 11:19:59.497: INFO: Trying to get logs from node eingavuivie7-3 pod pod-0b7fbbe5-af49-4381-992a-18d26f1cf632 container test-container: <nil>
STEP: delete the pod 04/23/23 11:19:59.517
Apr 23 11:19:59.536: INFO: Waiting for pod pod-0b7fbbe5-af49-4381-992a-18d26f1cf632 to disappear
Apr 23 11:19:59.542: INFO: Pod pod-0b7fbbe5-af49-4381-992a-18d26f1cf632 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 11:19:59.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-9794" for this suite. 04/23/23 11:19:59.556
------------------------------
â€¢ [4.186 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:217

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:19:55.385
    Apr 23 11:19:55.385: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 11:19:55.387
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:19:55.413
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:19:55.422
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:217
    STEP: Creating a pod to test emptydir 0777 on node default medium 04/23/23 11:19:55.427
    Apr 23 11:19:55.460: INFO: Waiting up to 5m0s for pod "pod-0b7fbbe5-af49-4381-992a-18d26f1cf632" in namespace "emptydir-9794" to be "Succeeded or Failed"
    Apr 23 11:19:55.467: INFO: Pod "pod-0b7fbbe5-af49-4381-992a-18d26f1cf632": Phase="Pending", Reason="", readiness=false. Elapsed: 6.312062ms
    Apr 23 11:19:57.472: INFO: Pod "pod-0b7fbbe5-af49-4381-992a-18d26f1cf632": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011973906s
    Apr 23 11:19:59.493: INFO: Pod "pod-0b7fbbe5-af49-4381-992a-18d26f1cf632": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032278649s
    STEP: Saw pod success 04/23/23 11:19:59.493
    Apr 23 11:19:59.493: INFO: Pod "pod-0b7fbbe5-af49-4381-992a-18d26f1cf632" satisfied condition "Succeeded or Failed"
    Apr 23 11:19:59.497: INFO: Trying to get logs from node eingavuivie7-3 pod pod-0b7fbbe5-af49-4381-992a-18d26f1cf632 container test-container: <nil>
    STEP: delete the pod 04/23/23 11:19:59.517
    Apr 23 11:19:59.536: INFO: Waiting for pod pod-0b7fbbe5-af49-4381-992a-18d26f1cf632 to disappear
    Apr 23 11:19:59.542: INFO: Pod pod-0b7fbbe5-af49-4381-992a-18d26f1cf632 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:19:59.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-9794" for this suite. 04/23/23 11:19:59.556
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:193
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:19:59.576
Apr 23 11:19:59.577: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 11:19:59.579
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:19:59.614
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:19:59.619
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:193
STEP: Creating a pod to test downward API volume plugin 04/23/23 11:19:59.622
Apr 23 11:19:59.636: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3" in namespace "downward-api-4083" to be "Succeeded or Failed"
Apr 23 11:19:59.641: INFO: Pod "downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.941768ms
Apr 23 11:20:01.649: INFO: Pod "downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3": Phase="Running", Reason="", readiness=true. Elapsed: 2.013442217s
Apr 23 11:20:03.650: INFO: Pod "downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3": Phase="Running", Reason="", readiness=false. Elapsed: 4.01426304s
Apr 23 11:20:05.650: INFO: Pod "downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013823908s
STEP: Saw pod success 04/23/23 11:20:05.651
Apr 23 11:20:05.652: INFO: Pod "downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3" satisfied condition "Succeeded or Failed"
Apr 23 11:20:05.661: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3 container client-container: <nil>
STEP: delete the pod 04/23/23 11:20:05.674
Apr 23 11:20:05.697: INFO: Waiting for pod downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3 to disappear
Apr 23 11:20:05.702: INFO: Pod downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Apr 23 11:20:05.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-4083" for this suite. 04/23/23 11:20:05.717
------------------------------
â€¢ [SLOW TEST] [6.164 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:19:59.576
    Apr 23 11:19:59.577: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 11:19:59.579
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:19:59.614
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:19:59.619
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:193
    STEP: Creating a pod to test downward API volume plugin 04/23/23 11:19:59.622
    Apr 23 11:19:59.636: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3" in namespace "downward-api-4083" to be "Succeeded or Failed"
    Apr 23 11:19:59.641: INFO: Pod "downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.941768ms
    Apr 23 11:20:01.649: INFO: Pod "downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3": Phase="Running", Reason="", readiness=true. Elapsed: 2.013442217s
    Apr 23 11:20:03.650: INFO: Pod "downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3": Phase="Running", Reason="", readiness=false. Elapsed: 4.01426304s
    Apr 23 11:20:05.650: INFO: Pod "downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013823908s
    STEP: Saw pod success 04/23/23 11:20:05.651
    Apr 23 11:20:05.652: INFO: Pod "downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3" satisfied condition "Succeeded or Failed"
    Apr 23 11:20:05.661: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3 container client-container: <nil>
    STEP: delete the pod 04/23/23 11:20:05.674
    Apr 23 11:20:05.697: INFO: Waiting for pod downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3 to disappear
    Apr 23 11:20:05.702: INFO: Pod downwardapi-volume-5550e5c0-ce73-4987-afc1-3d15fc1108c3 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:20:05.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-4083" for this suite. 04/23/23 11:20:05.717
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:426
[BeforeEach] [sig-apps] Job
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:20:05.741
Apr 23 11:20:05.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename job 04/23/23 11:20:05.747
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:20:05.777
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:20:05.786
[BeforeEach] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:31
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:426
STEP: Creating a job 04/23/23 11:20:05.794
STEP: Ensuring job reaches completions 04/23/23 11:20:05.809
[AfterEach] [sig-apps] Job
  test/e2e/framework/node/init/init.go:32
Apr 23 11:20:19.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Job
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Job
  tear down framework | framework.go:193
STEP: Destroying namespace "job-8969" for this suite. 04/23/23 11:20:19.827
------------------------------
â€¢ [SLOW TEST] [14.097 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:426

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:20:05.741
    Apr 23 11:20:05.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename job 04/23/23 11:20:05.747
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:20:05.777
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:20:05.786
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:31
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:426
    STEP: Creating a job 04/23/23 11:20:05.794
    STEP: Ensuring job reaches completions 04/23/23 11:20:05.809
    [AfterEach] [sig-apps] Job
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:20:19.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Job
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Job
      tear down framework | framework.go:193
    STEP: Destroying namespace "job-8969" for this suite. 04/23/23 11:20:19.827
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:75
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:20:19.853
Apr 23 11:20:19.853: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename resourcequota 04/23/23 11:20:19.855
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:20:19.885
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:20:19.892
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:75
STEP: Counting existing ResourceQuota 04/23/23 11:20:19.899
STEP: Creating a ResourceQuota 04/23/23 11:20:24.904
STEP: Ensuring resource quota status is calculated 04/23/23 11:20:24.915
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Apr 23 11:20:26.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-9893" for this suite. 04/23/23 11:20:26.932
------------------------------
â€¢ [SLOW TEST] [7.090 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:20:19.853
    Apr 23 11:20:19.853: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename resourcequota 04/23/23 11:20:19.855
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:20:19.885
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:20:19.892
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:75
    STEP: Counting existing ResourceQuota 04/23/23 11:20:19.899
    STEP: Creating a ResourceQuota 04/23/23 11:20:24.904
    STEP: Ensuring resource quota status is calculated 04/23/23 11:20:24.915
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:20:26.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-9893" for this suite. 04/23/23 11:20:26.932
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:44
[BeforeEach] [sig-storage] Projected combined
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:20:26.944
Apr 23 11:20:26.945: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:20:26.949
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:20:26.968
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:20:26.973
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/metrics/init/init.go:31
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:44
STEP: Creating configMap with name configmap-projected-all-test-volume-136cdfc9-0e48-4598-86d8-fa3683b13943 04/23/23 11:20:26.977
STEP: Creating secret with name secret-projected-all-test-volume-91bc00a9-019d-4360-b72b-266788add05e 04/23/23 11:20:26.984
STEP: Creating a pod to test Check all projections for projected volume plugin 04/23/23 11:20:26.992
Apr 23 11:20:27.008: INFO: Waiting up to 5m0s for pod "projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77" in namespace "projected-4858" to be "Succeeded or Failed"
Apr 23 11:20:27.017: INFO: Pod "projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77": Phase="Pending", Reason="", readiness=false. Elapsed: 9.168806ms
Apr 23 11:20:29.025: INFO: Pod "projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016765397s
Apr 23 11:20:31.027: INFO: Pod "projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018386478s
STEP: Saw pod success 04/23/23 11:20:31.027
Apr 23 11:20:31.027: INFO: Pod "projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77" satisfied condition "Succeeded or Failed"
Apr 23 11:20:31.033: INFO: Trying to get logs from node eingavuivie7-3 pod projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77 container projected-all-volume-test: <nil>
STEP: delete the pod 04/23/23 11:20:31.046
Apr 23 11:20:31.068: INFO: Waiting for pod projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77 to disappear
Apr 23 11:20:31.075: INFO: Pod projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/node/init/init.go:32
Apr 23 11:20:31.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected combined
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected combined
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected combined
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-4858" for this suite. 04/23/23 11:20:31.082
------------------------------
â€¢ [4.150 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:20:26.944
    Apr 23 11:20:26.945: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:20:26.949
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:20:26.968
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:20:26.973
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/metrics/init/init.go:31
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:44
    STEP: Creating configMap with name configmap-projected-all-test-volume-136cdfc9-0e48-4598-86d8-fa3683b13943 04/23/23 11:20:26.977
    STEP: Creating secret with name secret-projected-all-test-volume-91bc00a9-019d-4360-b72b-266788add05e 04/23/23 11:20:26.984
    STEP: Creating a pod to test Check all projections for projected volume plugin 04/23/23 11:20:26.992
    Apr 23 11:20:27.008: INFO: Waiting up to 5m0s for pod "projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77" in namespace "projected-4858" to be "Succeeded or Failed"
    Apr 23 11:20:27.017: INFO: Pod "projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77": Phase="Pending", Reason="", readiness=false. Elapsed: 9.168806ms
    Apr 23 11:20:29.025: INFO: Pod "projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016765397s
    Apr 23 11:20:31.027: INFO: Pod "projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018386478s
    STEP: Saw pod success 04/23/23 11:20:31.027
    Apr 23 11:20:31.027: INFO: Pod "projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77" satisfied condition "Succeeded or Failed"
    Apr 23 11:20:31.033: INFO: Trying to get logs from node eingavuivie7-3 pod projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77 container projected-all-volume-test: <nil>
    STEP: delete the pod 04/23/23 11:20:31.046
    Apr 23 11:20:31.068: INFO: Waiting for pod projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77 to disappear
    Apr 23 11:20:31.075: INFO: Pod projected-volume-e3376f77-1678-4d5e-bad0-98e13b43ee77 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:20:31.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected combined
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected combined
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected combined
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-4858" for this suite. 04/23/23 11:20:31.082
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:215
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:20:31.109
Apr 23 11:20:31.110: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-probe 04/23/23 11:20:31.112
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:20:31.137
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:20:31.141
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:215
STEP: Creating pod test-webserver-afb9c137-b92a-4d61-8dae-1629b686d683 in namespace container-probe-2319 04/23/23 11:20:31.145
Apr 23 11:20:31.157: INFO: Waiting up to 5m0s for pod "test-webserver-afb9c137-b92a-4d61-8dae-1629b686d683" in namespace "container-probe-2319" to be "not pending"
Apr 23 11:20:31.164: INFO: Pod "test-webserver-afb9c137-b92a-4d61-8dae-1629b686d683": Phase="Pending", Reason="", readiness=false. Elapsed: 6.808404ms
Apr 23 11:20:33.169: INFO: Pod "test-webserver-afb9c137-b92a-4d61-8dae-1629b686d683": Phase="Running", Reason="", readiness=true. Elapsed: 2.012259693s
Apr 23 11:20:33.169: INFO: Pod "test-webserver-afb9c137-b92a-4d61-8dae-1629b686d683" satisfied condition "not pending"
Apr 23 11:20:33.169: INFO: Started pod test-webserver-afb9c137-b92a-4d61-8dae-1629b686d683 in namespace container-probe-2319
STEP: checking the pod's current state and verifying that restartCount is present 04/23/23 11:20:33.169
Apr 23 11:20:33.176: INFO: Initial restart count of pod test-webserver-afb9c137-b92a-4d61-8dae-1629b686d683 is 0
STEP: deleting the pod 04/23/23 11:24:34.237
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Apr 23 11:24:34.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-2319" for this suite. 04/23/23 11:24:34.298
------------------------------
â€¢ [SLOW TEST] [243.212 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:20:31.109
    Apr 23 11:20:31.110: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-probe 04/23/23 11:20:31.112
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:20:31.137
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:20:31.141
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:215
    STEP: Creating pod test-webserver-afb9c137-b92a-4d61-8dae-1629b686d683 in namespace container-probe-2319 04/23/23 11:20:31.145
    Apr 23 11:20:31.157: INFO: Waiting up to 5m0s for pod "test-webserver-afb9c137-b92a-4d61-8dae-1629b686d683" in namespace "container-probe-2319" to be "not pending"
    Apr 23 11:20:31.164: INFO: Pod "test-webserver-afb9c137-b92a-4d61-8dae-1629b686d683": Phase="Pending", Reason="", readiness=false. Elapsed: 6.808404ms
    Apr 23 11:20:33.169: INFO: Pod "test-webserver-afb9c137-b92a-4d61-8dae-1629b686d683": Phase="Running", Reason="", readiness=true. Elapsed: 2.012259693s
    Apr 23 11:20:33.169: INFO: Pod "test-webserver-afb9c137-b92a-4d61-8dae-1629b686d683" satisfied condition "not pending"
    Apr 23 11:20:33.169: INFO: Started pod test-webserver-afb9c137-b92a-4d61-8dae-1629b686d683 in namespace container-probe-2319
    STEP: checking the pod's current state and verifying that restartCount is present 04/23/23 11:20:33.169
    Apr 23 11:20:33.176: INFO: Initial restart count of pod test-webserver-afb9c137-b92a-4d61-8dae-1629b686d683 is 0
    STEP: deleting the pod 04/23/23 11:24:34.237
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:24:34.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-2319" for this suite. 04/23/23 11:24:34.298
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:24:34.324
Apr 23 11:24:34.325: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename watch 04/23/23 11:24:34.327
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:24:34.37
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:24:34.377
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:31
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 04/23/23 11:24:34.392
STEP: modifying the configmap once 04/23/23 11:24:34.406
STEP: modifying the configmap a second time 04/23/23 11:24:34.429
STEP: deleting the configmap 04/23/23 11:24:34.45
STEP: creating a watch on configmaps from the resource version returned by the first update 04/23/23 11:24:34.462
STEP: Expecting to observe notifications for all changes to the configmap after the first update 04/23/23 11:24:34.466
Apr 23 11:24:34.467: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5064  c74ca100-adf5-442f-b620-0d45bd1f38b1 13507 0 2023-04-23 11:24:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-23 11:24:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 23 11:24:34.468: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5064  c74ca100-adf5-442f-b620-0d45bd1f38b1 13508 0 2023-04-23 11:24:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-23 11:24:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/node/init/init.go:32
Apr 23 11:24:34.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  tear down framework | framework.go:193
STEP: Destroying namespace "watch-5064" for this suite. 04/23/23 11:24:34.48
------------------------------
â€¢ [0.179 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:24:34.324
    Apr 23 11:24:34.325: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename watch 04/23/23 11:24:34.327
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:24:34.37
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:24:34.377
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:31
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 04/23/23 11:24:34.392
    STEP: modifying the configmap once 04/23/23 11:24:34.406
    STEP: modifying the configmap a second time 04/23/23 11:24:34.429
    STEP: deleting the configmap 04/23/23 11:24:34.45
    STEP: creating a watch on configmaps from the resource version returned by the first update 04/23/23 11:24:34.462
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 04/23/23 11:24:34.466
    Apr 23 11:24:34.467: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5064  c74ca100-adf5-442f-b620-0d45bd1f38b1 13507 0 2023-04-23 11:24:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-23 11:24:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 23 11:24:34.468: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5064  c74ca100-adf5-442f-b620-0d45bd1f38b1 13508 0 2023-04-23 11:24:34 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-23 11:24:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:24:34.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      tear down framework | framework.go:193
    STEP: Destroying namespace "watch-5064" for this suite. 04/23/23 11:24:34.48
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:78
[BeforeEach] [sig-auth] ServiceAccounts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:24:34.526
Apr 23 11:24:34.527: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename svcaccounts 04/23/23 11:24:34.529
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:24:34.593
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:24:34.598
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:31
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:78
Apr 23 11:24:34.630: INFO: Waiting up to 5m0s for pod "pod-service-account-82ff57b3-8d3f-4d81-ac92-ed2bd31ee729" in namespace "svcaccounts-6697" to be "running"
Apr 23 11:24:34.639: INFO: Pod "pod-service-account-82ff57b3-8d3f-4d81-ac92-ed2bd31ee729": Phase="Pending", Reason="", readiness=false. Elapsed: 7.931127ms
Apr 23 11:24:36.646: INFO: Pod "pod-service-account-82ff57b3-8d3f-4d81-ac92-ed2bd31ee729": Phase="Running", Reason="", readiness=true. Elapsed: 2.015105617s
Apr 23 11:24:36.646: INFO: Pod "pod-service-account-82ff57b3-8d3f-4d81-ac92-ed2bd31ee729" satisfied condition "running"
STEP: reading a file in the container 04/23/23 11:24:36.646
Apr 23 11:24:36.647: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6697 pod-service-account-82ff57b3-8d3f-4d81-ac92-ed2bd31ee729 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 04/23/23 11:24:36.909
Apr 23 11:24:36.911: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6697 pod-service-account-82ff57b3-8d3f-4d81-ac92-ed2bd31ee729 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 04/23/23 11:24:37.175
Apr 23 11:24:37.175: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6697 pod-service-account-82ff57b3-8d3f-4d81-ac92-ed2bd31ee729 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Apr 23 11:24:37.489: INFO: Got root ca configmap in namespace "svcaccounts-6697"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/node/init/init.go:32
Apr 23 11:24:37.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  tear down framework | framework.go:193
STEP: Destroying namespace "svcaccounts-6697" for this suite. 04/23/23 11:24:37.504
------------------------------
â€¢ [2.996 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:24:34.526
    Apr 23 11:24:34.527: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename svcaccounts 04/23/23 11:24:34.529
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:24:34.593
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:24:34.598
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:31
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:78
    Apr 23 11:24:34.630: INFO: Waiting up to 5m0s for pod "pod-service-account-82ff57b3-8d3f-4d81-ac92-ed2bd31ee729" in namespace "svcaccounts-6697" to be "running"
    Apr 23 11:24:34.639: INFO: Pod "pod-service-account-82ff57b3-8d3f-4d81-ac92-ed2bd31ee729": Phase="Pending", Reason="", readiness=false. Elapsed: 7.931127ms
    Apr 23 11:24:36.646: INFO: Pod "pod-service-account-82ff57b3-8d3f-4d81-ac92-ed2bd31ee729": Phase="Running", Reason="", readiness=true. Elapsed: 2.015105617s
    Apr 23 11:24:36.646: INFO: Pod "pod-service-account-82ff57b3-8d3f-4d81-ac92-ed2bd31ee729" satisfied condition "running"
    STEP: reading a file in the container 04/23/23 11:24:36.646
    Apr 23 11:24:36.647: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6697 pod-service-account-82ff57b3-8d3f-4d81-ac92-ed2bd31ee729 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 04/23/23 11:24:36.909
    Apr 23 11:24:36.911: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6697 pod-service-account-82ff57b3-8d3f-4d81-ac92-ed2bd31ee729 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 04/23/23 11:24:37.175
    Apr 23 11:24:37.175: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6697 pod-service-account-82ff57b3-8d3f-4d81-ac92-ed2bd31ee729 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Apr 23 11:24:37.489: INFO: Got root ca configmap in namespace "svcaccounts-6697"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:24:37.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      tear down framework | framework.go:193
    STEP: Destroying namespace "svcaccounts-6697" for this suite. 04/23/23 11:24:37.504
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:152
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:24:37.528
Apr 23 11:24:37.528: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-probe 04/23/23 11:24:37.532
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:24:37.571
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:24:37.576
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:152
STEP: Creating pod busybox-87c5d22b-456b-4d0c-ade9-70436a05bdc7 in namespace container-probe-2212 04/23/23 11:24:37.582
Apr 23 11:24:37.608: INFO: Waiting up to 5m0s for pod "busybox-87c5d22b-456b-4d0c-ade9-70436a05bdc7" in namespace "container-probe-2212" to be "not pending"
Apr 23 11:24:37.618: INFO: Pod "busybox-87c5d22b-456b-4d0c-ade9-70436a05bdc7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.115487ms
Apr 23 11:24:39.626: INFO: Pod "busybox-87c5d22b-456b-4d0c-ade9-70436a05bdc7": Phase="Running", Reason="", readiness=true. Elapsed: 2.0172812s
Apr 23 11:24:39.626: INFO: Pod "busybox-87c5d22b-456b-4d0c-ade9-70436a05bdc7" satisfied condition "not pending"
Apr 23 11:24:39.626: INFO: Started pod busybox-87c5d22b-456b-4d0c-ade9-70436a05bdc7 in namespace container-probe-2212
STEP: checking the pod's current state and verifying that restartCount is present 04/23/23 11:24:39.626
Apr 23 11:24:39.634: INFO: Initial restart count of pod busybox-87c5d22b-456b-4d0c-ade9-70436a05bdc7 is 0
STEP: deleting the pod 04/23/23 11:28:40.845
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Apr 23 11:28:40.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-2212" for this suite. 04/23/23 11:28:40.95
------------------------------
â€¢ [SLOW TEST] [243.453 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:24:37.528
    Apr 23 11:24:37.528: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-probe 04/23/23 11:24:37.532
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:24:37.571
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:24:37.576
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:152
    STEP: Creating pod busybox-87c5d22b-456b-4d0c-ade9-70436a05bdc7 in namespace container-probe-2212 04/23/23 11:24:37.582
    Apr 23 11:24:37.608: INFO: Waiting up to 5m0s for pod "busybox-87c5d22b-456b-4d0c-ade9-70436a05bdc7" in namespace "container-probe-2212" to be "not pending"
    Apr 23 11:24:37.618: INFO: Pod "busybox-87c5d22b-456b-4d0c-ade9-70436a05bdc7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.115487ms
    Apr 23 11:24:39.626: INFO: Pod "busybox-87c5d22b-456b-4d0c-ade9-70436a05bdc7": Phase="Running", Reason="", readiness=true. Elapsed: 2.0172812s
    Apr 23 11:24:39.626: INFO: Pod "busybox-87c5d22b-456b-4d0c-ade9-70436a05bdc7" satisfied condition "not pending"
    Apr 23 11:24:39.626: INFO: Started pod busybox-87c5d22b-456b-4d0c-ade9-70436a05bdc7 in namespace container-probe-2212
    STEP: checking the pod's current state and verifying that restartCount is present 04/23/23 11:24:39.626
    Apr 23 11:24:39.634: INFO: Initial restart count of pod busybox-87c5d22b-456b-4d0c-ade9-70436a05bdc7 is 0
    STEP: deleting the pod 04/23/23 11:28:40.845
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:28:40.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-2212" for this suite. 04/23/23 11:28:40.95
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:28:40.987
Apr 23 11:28:40.987: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename dns 04/23/23 11:28:40.994
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:28:41.079
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:28:41.083
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 04/23/23 11:28:41.087
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7380.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7380.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 04/23/23 11:28:41.099
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7380.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7380.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 04/23/23 11:28:41.099
STEP: creating a pod to probe DNS 04/23/23 11:28:41.099
STEP: submitting the pod to kubernetes 04/23/23 11:28:41.1
Apr 23 11:28:41.126: INFO: Waiting up to 15m0s for pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9" in namespace "dns-7380" to be "running"
Apr 23 11:28:41.138: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.900196ms
Apr 23 11:28:43.150: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023482771s
Apr 23 11:28:45.152: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025494154s
Apr 23 11:28:47.146: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019856733s
Apr 23 11:28:49.147: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.020257769s
Apr 23 11:28:51.146: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020103234s
Apr 23 11:28:53.147: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.020726063s
Apr 23 11:28:55.146: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.019366708s
Apr 23 11:28:57.152: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.025704309s
Apr 23 11:28:59.150: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.024166994s
Apr 23 11:29:01.147: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.020736436s
Apr 23 11:29:03.148: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Running", Reason="", readiness=true. Elapsed: 22.02196956s
Apr 23 11:29:03.148: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9" satisfied condition "running"
STEP: retrieving the pod 04/23/23 11:29:03.149
STEP: looking for the results for each expected name from probers 04/23/23 11:29:03.157
Apr 23 11:29:03.202: INFO: DNS probes using dns-7380/dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9 succeeded

STEP: deleting the pod 04/23/23 11:29:03.202
STEP: deleting the test headless service 04/23/23 11:29:03.241
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Apr 23 11:29:03.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-7380" for this suite. 04/23/23 11:29:03.296
------------------------------
â€¢ [SLOW TEST] [22.332 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:28:40.987
    Apr 23 11:28:40.987: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename dns 04/23/23 11:28:40.994
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:28:41.079
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:28:41.083
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 04/23/23 11:28:41.087
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7380.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7380.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     04/23/23 11:28:41.099
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7380.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7380.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     04/23/23 11:28:41.099
    STEP: creating a pod to probe DNS 04/23/23 11:28:41.099
    STEP: submitting the pod to kubernetes 04/23/23 11:28:41.1
    Apr 23 11:28:41.126: INFO: Waiting up to 15m0s for pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9" in namespace "dns-7380" to be "running"
    Apr 23 11:28:41.138: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.900196ms
    Apr 23 11:28:43.150: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023482771s
    Apr 23 11:28:45.152: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025494154s
    Apr 23 11:28:47.146: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019856733s
    Apr 23 11:28:49.147: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.020257769s
    Apr 23 11:28:51.146: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020103234s
    Apr 23 11:28:53.147: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.020726063s
    Apr 23 11:28:55.146: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.019366708s
    Apr 23 11:28:57.152: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.025704309s
    Apr 23 11:28:59.150: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.024166994s
    Apr 23 11:29:01.147: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.020736436s
    Apr 23 11:29:03.148: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9": Phase="Running", Reason="", readiness=true. Elapsed: 22.02196956s
    Apr 23 11:29:03.148: INFO: Pod "dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9" satisfied condition "running"
    STEP: retrieving the pod 04/23/23 11:29:03.149
    STEP: looking for the results for each expected name from probers 04/23/23 11:29:03.157
    Apr 23 11:29:03.202: INFO: DNS probes using dns-7380/dns-test-1d1a9028-5f80-435c-b356-6cee29a9d5b9 succeeded

    STEP: deleting the pod 04/23/23 11:29:03.202
    STEP: deleting the test headless service 04/23/23 11:29:03.241
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:29:03.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-7380" for this suite. 04/23/23 11:29:03.296
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:381
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:29:03.322
Apr 23 11:29:03.322: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 11:29:03.332
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:03.358
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:03.363
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 11:29:03.4
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 11:29:04.21
STEP: Deploying the webhook pod 04/23/23 11:29:04.221
STEP: Wait for the deployment to be ready 04/23/23 11:29:04.273
Apr 23 11:29:04.315: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/23/23 11:29:06.339
STEP: Verifying the service has paired with the endpoint 04/23/23 11:29:06.359
Apr 23 11:29:07.360: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:381
STEP: Setting timeout (1s) shorter than webhook latency (5s) 04/23/23 11:29:07.372
STEP: Registering slow webhook via the AdmissionRegistration API 04/23/23 11:29:07.373
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 04/23/23 11:29:07.416
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 04/23/23 11:29:08.453
STEP: Registering slow webhook via the AdmissionRegistration API 04/23/23 11:29:08.453
STEP: Having no error when timeout is longer than webhook latency 04/23/23 11:29:09.545
STEP: Registering slow webhook via the AdmissionRegistration API 04/23/23 11:29:09.545
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 04/23/23 11:29:14.649
STEP: Registering slow webhook via the AdmissionRegistration API 04/23/23 11:29:14.649
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:29:19.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-5243" for this suite. 04/23/23 11:29:19.907
STEP: Destroying namespace "webhook-5243-markers" for this suite. 04/23/23 11:29:19.935
------------------------------
â€¢ [SLOW TEST] [16.630 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:381

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:29:03.322
    Apr 23 11:29:03.322: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 11:29:03.332
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:03.358
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:03.363
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 11:29:03.4
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 11:29:04.21
    STEP: Deploying the webhook pod 04/23/23 11:29:04.221
    STEP: Wait for the deployment to be ready 04/23/23 11:29:04.273
    Apr 23 11:29:04.315: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/23/23 11:29:06.339
    STEP: Verifying the service has paired with the endpoint 04/23/23 11:29:06.359
    Apr 23 11:29:07.360: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:381
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 04/23/23 11:29:07.372
    STEP: Registering slow webhook via the AdmissionRegistration API 04/23/23 11:29:07.373
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 04/23/23 11:29:07.416
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 04/23/23 11:29:08.453
    STEP: Registering slow webhook via the AdmissionRegistration API 04/23/23 11:29:08.453
    STEP: Having no error when timeout is longer than webhook latency 04/23/23 11:29:09.545
    STEP: Registering slow webhook via the AdmissionRegistration API 04/23/23 11:29:09.545
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 04/23/23 11:29:14.649
    STEP: Registering slow webhook via the AdmissionRegistration API 04/23/23 11:29:14.649
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:29:19.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-5243" for this suite. 04/23/23 11:29:19.907
    STEP: Destroying namespace "webhook-5243-markers" for this suite. 04/23/23 11:29:19.935
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:151
[BeforeEach] [sig-node] Container Lifecycle Hook
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:29:20.008
Apr 23 11:29:20.009: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-lifecycle-hook 04/23/23 11:29:20.011
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:20.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:20.053
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:77
STEP: create the container to handle the HTTPGet hook request. 04/23/23 11:29:20.07
Apr 23 11:29:20.090: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8864" to be "running and ready"
Apr 23 11:29:20.112: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 22.530188ms
Apr 23 11:29:20.113: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:29:22.120: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.029757181s
Apr 23 11:29:22.120: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 23 11:29:22.120: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:151
STEP: create the pod with lifecycle hook 04/23/23 11:29:22.126
Apr 23 11:29:22.135: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-8864" to be "running and ready"
Apr 23 11:29:22.143: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 7.27025ms
Apr 23 11:29:22.143: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:29:24.149: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.013687763s
Apr 23 11:29:24.149: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Apr 23 11:29:24.149: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 04/23/23 11:29:24.154
Apr 23 11:29:24.170: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 23 11:29:24.176: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 23 11:29:26.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 23 11:29:26.184: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 04/23/23 11:29:26.184
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/node/init/init.go:32
Apr 23 11:29:26.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  tear down framework | framework.go:193
STEP: Destroying namespace "container-lifecycle-hook-8864" for this suite. 04/23/23 11:29:26.23
------------------------------
â€¢ [SLOW TEST] [6.236 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:29:20.008
    Apr 23 11:29:20.009: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/23/23 11:29:20.011
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:20.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:20.053
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:77
    STEP: create the container to handle the HTTPGet hook request. 04/23/23 11:29:20.07
    Apr 23 11:29:20.090: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8864" to be "running and ready"
    Apr 23 11:29:20.112: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 22.530188ms
    Apr 23 11:29:20.113: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:29:22.120: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.029757181s
    Apr 23 11:29:22.120: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 23 11:29:22.120: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:151
    STEP: create the pod with lifecycle hook 04/23/23 11:29:22.126
    Apr 23 11:29:22.135: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-8864" to be "running and ready"
    Apr 23 11:29:22.143: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 7.27025ms
    Apr 23 11:29:22.143: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:29:24.149: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.013687763s
    Apr 23 11:29:24.149: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Apr 23 11:29:24.149: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 04/23/23 11:29:24.154
    Apr 23 11:29:24.170: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 23 11:29:24.176: INFO: Pod pod-with-prestop-exec-hook still exists
    Apr 23 11:29:26.177: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 23 11:29:26.184: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 04/23/23 11:29:26.184
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:29:26.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-lifecycle-hook-8864" for this suite. 04/23/23 11:29:26.23
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:57
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:29:26.247
Apr 23 11:29:26.248: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:29:26.25
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:26.276
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:26.294
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:57
STEP: Creating configMap with name projected-configmap-test-volume-453cf6bb-c57e-4306-be30-288480e8bff0 04/23/23 11:29:26.303
STEP: Creating a pod to test consume configMaps 04/23/23 11:29:26.319
Apr 23 11:29:26.346: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40" in namespace "projected-7423" to be "Succeeded or Failed"
Apr 23 11:29:26.360: INFO: Pod "pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40": Phase="Pending", Reason="", readiness=false. Elapsed: 13.104575ms
Apr 23 11:29:28.369: INFO: Pod "pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022056849s
Apr 23 11:29:30.370: INFO: Pod "pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023641181s
STEP: Saw pod success 04/23/23 11:29:30.37
Apr 23 11:29:30.371: INFO: Pod "pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40" satisfied condition "Succeeded or Failed"
Apr 23 11:29:30.377: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40 container agnhost-container: <nil>
STEP: delete the pod 04/23/23 11:29:30.405
Apr 23 11:29:30.427: INFO: Waiting for pod pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40 to disappear
Apr 23 11:29:30.434: INFO: Pod pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Apr 23 11:29:30.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-7423" for this suite. 04/23/23 11:29:30.446
------------------------------
â€¢ [4.214 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:29:26.247
    Apr 23 11:29:26.248: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:29:26.25
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:26.276
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:26.294
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:57
    STEP: Creating configMap with name projected-configmap-test-volume-453cf6bb-c57e-4306-be30-288480e8bff0 04/23/23 11:29:26.303
    STEP: Creating a pod to test consume configMaps 04/23/23 11:29:26.319
    Apr 23 11:29:26.346: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40" in namespace "projected-7423" to be "Succeeded or Failed"
    Apr 23 11:29:26.360: INFO: Pod "pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40": Phase="Pending", Reason="", readiness=false. Elapsed: 13.104575ms
    Apr 23 11:29:28.369: INFO: Pod "pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022056849s
    Apr 23 11:29:30.370: INFO: Pod "pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023641181s
    STEP: Saw pod success 04/23/23 11:29:30.37
    Apr 23 11:29:30.371: INFO: Pod "pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40" satisfied condition "Succeeded or Failed"
    Apr 23 11:29:30.377: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40 container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 11:29:30.405
    Apr 23 11:29:30.427: INFO: Waiting for pod pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40 to disappear
    Apr 23 11:29:30.434: INFO: Pod pod-projected-configmaps-237653e7-801f-4043-9101-0b054cbc7d40 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:29:30.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-7423" for this suite. 04/23/23 11:29:30.446
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:862
[BeforeEach] [sig-apps] Daemon set [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:29:30.465
Apr 23 11:29:30.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename daemonsets 04/23/23 11:29:30.468
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:30.512
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:30.523
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:146
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:862
STEP: Creating simple DaemonSet "daemon-set" 04/23/23 11:29:30.631
STEP: Check that daemon pods launch on every node of the cluster. 04/23/23 11:29:30.649
Apr 23 11:29:30.673: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:29:30.673: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 11:29:31.748: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:29:31.749: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 11:29:32.693: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 11:29:32.693: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:29:33.694: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 11:29:33.694: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:29:34.690: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 11:29:34.690: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:29:35.705: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 11:29:35.705: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:29:36.695: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 11:29:36.695: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:29:37.692: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 11:29:37.693: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:29:38.703: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 11:29:38.705: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:29:39.698: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 11:29:39.698: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:29:40.709: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 23 11:29:40.710: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 04/23/23 11:29:40.719
Apr 23 11:29:40.734: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 04/23/23 11:29:40.734
Apr 23 11:29:40.761: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 04/23/23 11:29:40.761
Apr 23 11:29:40.768: INFO: Observed &DaemonSet event: ADDED
Apr 23 11:29:40.769: INFO: Observed &DaemonSet event: MODIFIED
Apr 23 11:29:40.770: INFO: Observed &DaemonSet event: MODIFIED
Apr 23 11:29:40.770: INFO: Observed &DaemonSet event: MODIFIED
Apr 23 11:29:40.771: INFO: Observed &DaemonSet event: MODIFIED
Apr 23 11:29:40.771: INFO: Found daemon set daemon-set in namespace daemonsets-4423 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 23 11:29:40.771: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 04/23/23 11:29:40.771
STEP: watching for the daemon set status to be patched 04/23/23 11:29:40.786
Apr 23 11:29:40.792: INFO: Observed &DaemonSet event: ADDED
Apr 23 11:29:40.793: INFO: Observed &DaemonSet event: MODIFIED
Apr 23 11:29:40.794: INFO: Observed &DaemonSet event: MODIFIED
Apr 23 11:29:40.795: INFO: Observed &DaemonSet event: MODIFIED
Apr 23 11:29:40.796: INFO: Observed &DaemonSet event: MODIFIED
Apr 23 11:29:40.796: INFO: Observed daemon set daemon-set in namespace daemonsets-4423 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 23 11:29:40.797: INFO: Observed &DaemonSet event: MODIFIED
Apr 23 11:29:40.798: INFO: Found daemon set daemon-set in namespace daemonsets-4423 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Apr 23 11:29:40.798: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:111
STEP: Deleting DaemonSet "daemon-set" 04/23/23 11:29:40.806
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4423, will wait for the garbage collector to delete the pods 04/23/23 11:29:40.807
Apr 23 11:29:40.904: INFO: Deleting DaemonSet.extensions daemon-set took: 27.353259ms
Apr 23 11:29:41.004: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.724308ms
Apr 23 11:29:43.817: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:29:43.817: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 23 11:29:43.830: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"14531"},"items":null}

Apr 23 11:29:43.836: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"14531"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:29:43.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "daemonsets-4423" for this suite. 04/23/23 11:29:43.887
------------------------------
â€¢ [SLOW TEST] [13.438 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:862

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:29:30.465
    Apr 23 11:29:30.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename daemonsets 04/23/23 11:29:30.468
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:30.512
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:30.523
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:146
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:862
    STEP: Creating simple DaemonSet "daemon-set" 04/23/23 11:29:30.631
    STEP: Check that daemon pods launch on every node of the cluster. 04/23/23 11:29:30.649
    Apr 23 11:29:30.673: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:29:30.673: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 11:29:31.748: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:29:31.749: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 11:29:32.693: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 11:29:32.693: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:29:33.694: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 11:29:33.694: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:29:34.690: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 11:29:34.690: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:29:35.705: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 11:29:35.705: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:29:36.695: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 11:29:36.695: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:29:37.692: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 11:29:37.693: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:29:38.703: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 11:29:38.705: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:29:39.698: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 11:29:39.698: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:29:40.709: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 23 11:29:40.710: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 04/23/23 11:29:40.719
    Apr 23 11:29:40.734: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 04/23/23 11:29:40.734
    Apr 23 11:29:40.761: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 04/23/23 11:29:40.761
    Apr 23 11:29:40.768: INFO: Observed &DaemonSet event: ADDED
    Apr 23 11:29:40.769: INFO: Observed &DaemonSet event: MODIFIED
    Apr 23 11:29:40.770: INFO: Observed &DaemonSet event: MODIFIED
    Apr 23 11:29:40.770: INFO: Observed &DaemonSet event: MODIFIED
    Apr 23 11:29:40.771: INFO: Observed &DaemonSet event: MODIFIED
    Apr 23 11:29:40.771: INFO: Found daemon set daemon-set in namespace daemonsets-4423 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 23 11:29:40.771: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 04/23/23 11:29:40.771
    STEP: watching for the daemon set status to be patched 04/23/23 11:29:40.786
    Apr 23 11:29:40.792: INFO: Observed &DaemonSet event: ADDED
    Apr 23 11:29:40.793: INFO: Observed &DaemonSet event: MODIFIED
    Apr 23 11:29:40.794: INFO: Observed &DaemonSet event: MODIFIED
    Apr 23 11:29:40.795: INFO: Observed &DaemonSet event: MODIFIED
    Apr 23 11:29:40.796: INFO: Observed &DaemonSet event: MODIFIED
    Apr 23 11:29:40.796: INFO: Observed daemon set daemon-set in namespace daemonsets-4423 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 23 11:29:40.797: INFO: Observed &DaemonSet event: MODIFIED
    Apr 23 11:29:40.798: INFO: Found daemon set daemon-set in namespace daemonsets-4423 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Apr 23 11:29:40.798: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:111
    STEP: Deleting DaemonSet "daemon-set" 04/23/23 11:29:40.806
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4423, will wait for the garbage collector to delete the pods 04/23/23 11:29:40.807
    Apr 23 11:29:40.904: INFO: Deleting DaemonSet.extensions daemon-set took: 27.353259ms
    Apr 23 11:29:41.004: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.724308ms
    Apr 23 11:29:43.817: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:29:43.817: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 23 11:29:43.830: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"14531"},"items":null}

    Apr 23 11:29:43.836: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"14531"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:29:43.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "daemonsets-4423" for this suite. 04/23/23 11:29:43.887
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:375
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:29:43.91
Apr 23 11:29:43.911: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:29:43.913
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:43.943
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:43.951
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:375
STEP: Creating configMap with name projected-configmap-test-volume-ed742c59-c0c2-4ba8-863f-87bc7146ff51 04/23/23 11:29:43.957
STEP: Creating a pod to test consume configMaps 04/23/23 11:29:43.965
Apr 23 11:29:43.985: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0" in namespace "projected-3717" to be "Succeeded or Failed"
Apr 23 11:29:44.001: INFO: Pod "pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0": Phase="Pending", Reason="", readiness=false. Elapsed: 16.005151ms
Apr 23 11:29:46.009: INFO: Pod "pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024058899s
Apr 23 11:29:48.029: INFO: Pod "pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043586994s
STEP: Saw pod success 04/23/23 11:29:48.029
Apr 23 11:29:48.029: INFO: Pod "pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0" satisfied condition "Succeeded or Failed"
Apr 23 11:29:48.042: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0 container projected-configmap-volume-test: <nil>
STEP: delete the pod 04/23/23 11:29:48.061
Apr 23 11:29:48.089: INFO: Waiting for pod pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0 to disappear
Apr 23 11:29:48.096: INFO: Pod pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Apr 23 11:29:48.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-3717" for this suite. 04/23/23 11:29:48.106
------------------------------
â€¢ [4.208 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:375

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:29:43.91
    Apr 23 11:29:43.911: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:29:43.913
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:43.943
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:43.951
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:375
    STEP: Creating configMap with name projected-configmap-test-volume-ed742c59-c0c2-4ba8-863f-87bc7146ff51 04/23/23 11:29:43.957
    STEP: Creating a pod to test consume configMaps 04/23/23 11:29:43.965
    Apr 23 11:29:43.985: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0" in namespace "projected-3717" to be "Succeeded or Failed"
    Apr 23 11:29:44.001: INFO: Pod "pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0": Phase="Pending", Reason="", readiness=false. Elapsed: 16.005151ms
    Apr 23 11:29:46.009: INFO: Pod "pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024058899s
    Apr 23 11:29:48.029: INFO: Pod "pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043586994s
    STEP: Saw pod success 04/23/23 11:29:48.029
    Apr 23 11:29:48.029: INFO: Pod "pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0" satisfied condition "Succeeded or Failed"
    Apr 23 11:29:48.042: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 04/23/23 11:29:48.061
    Apr 23 11:29:48.089: INFO: Waiting for pod pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0 to disappear
    Apr 23 11:29:48.096: INFO: Pod pod-projected-configmaps-a14c6d4e-b8a0-48e5-a231-41aaa41561a0 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:29:48.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-3717" for this suite. 04/23/23 11:29:48.106
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:29:48.12
Apr 23 11:29:48.120: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename custom-resource-definition 04/23/23 11:29:48.122
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:48.156
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:48.164
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 04/23/23 11:29:48.168
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 04/23/23 11:29:48.171
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 04/23/23 11:29:48.171
STEP: fetching the /apis/apiextensions.k8s.io discovery document 04/23/23 11:29:48.171
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 04/23/23 11:29:48.173
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 04/23/23 11:29:48.173
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 04/23/23 11:29:48.175
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:29:48.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "custom-resource-definition-7681" for this suite. 04/23/23 11:29:48.187
------------------------------
â€¢ [0.081 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:29:48.12
    Apr 23 11:29:48.120: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename custom-resource-definition 04/23/23 11:29:48.122
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:48.156
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:48.164
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 04/23/23 11:29:48.168
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 04/23/23 11:29:48.171
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 04/23/23 11:29:48.171
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 04/23/23 11:29:48.171
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 04/23/23 11:29:48.173
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 04/23/23 11:29:48.173
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 04/23/23 11:29:48.175
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:29:48.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "custom-resource-definition-7681" for this suite. 04/23/23 11:29:48.187
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:29:48.203
Apr 23 11:29:48.203: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename deployment 04/23/23 11:29:48.207
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:48.239
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:48.243
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 04/23/23 11:29:48.258
Apr 23 11:29:48.258: INFO: Creating simple deployment test-deployment-2qpml
Apr 23 11:29:48.303: INFO: deployment "test-deployment-2qpml" doesn't have the required revision set
STEP: Getting /status 04/23/23 11:29:50.326
Apr 23 11:29:50.334: INFO: Deployment test-deployment-2qpml has Conditions: [{Available True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:50 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2qpml-54bc444df" has successfully progressed.}]
STEP: updating Deployment Status 04/23/23 11:29:50.334
Apr 23 11:29:50.355: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 29, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 29, 50, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 29, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 29, 48, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-2qpml-54bc444df\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 04/23/23 11:29:50.355
Apr 23 11:29:50.359: INFO: Observed &Deployment event: ADDED
Apr 23 11:29:50.359: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2qpml-54bc444df"}
Apr 23 11:29:50.360: INFO: Observed &Deployment event: MODIFIED
Apr 23 11:29:50.360: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2qpml-54bc444df"}
Apr 23 11:29:50.360: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 23 11:29:50.360: INFO: Observed &Deployment event: MODIFIED
Apr 23 11:29:50.360: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 23 11:29:50.361: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-2qpml-54bc444df" is progressing.}
Apr 23 11:29:50.361: INFO: Observed &Deployment event: MODIFIED
Apr 23 11:29:50.361: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:50 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 23 11:29:50.361: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2qpml-54bc444df" has successfully progressed.}
Apr 23 11:29:50.362: INFO: Observed &Deployment event: MODIFIED
Apr 23 11:29:50.362: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:50 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 23 11:29:50.362: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2qpml-54bc444df" has successfully progressed.}
Apr 23 11:29:50.362: INFO: Found Deployment test-deployment-2qpml in namespace deployment-8043 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 23 11:29:50.362: INFO: Deployment test-deployment-2qpml has an updated status
STEP: patching the Statefulset Status 04/23/23 11:29:50.362
Apr 23 11:29:50.363: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 23 11:29:50.375: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 04/23/23 11:29:50.375
Apr 23 11:29:50.378: INFO: Observed &Deployment event: ADDED
Apr 23 11:29:50.378: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2qpml-54bc444df"}
Apr 23 11:29:50.379: INFO: Observed &Deployment event: MODIFIED
Apr 23 11:29:50.379: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2qpml-54bc444df"}
Apr 23 11:29:50.380: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 23 11:29:50.381: INFO: Observed &Deployment event: MODIFIED
Apr 23 11:29:50.381: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 23 11:29:50.381: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-2qpml-54bc444df" is progressing.}
Apr 23 11:29:50.382: INFO: Observed &Deployment event: MODIFIED
Apr 23 11:29:50.382: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:50 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 23 11:29:50.383: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2qpml-54bc444df" has successfully progressed.}
Apr 23 11:29:50.383: INFO: Observed &Deployment event: MODIFIED
Apr 23 11:29:50.383: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:50 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 23 11:29:50.384: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2qpml-54bc444df" has successfully progressed.}
Apr 23 11:29:50.384: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 23 11:29:50.384: INFO: Observed &Deployment event: MODIFIED
Apr 23 11:29:50.384: INFO: Found deployment test-deployment-2qpml in namespace deployment-8043 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Apr 23 11:29:50.384: INFO: Deployment test-deployment-2qpml has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 23 11:29:50.390: INFO: Deployment "test-deployment-2qpml":
&Deployment{ObjectMeta:{test-deployment-2qpml  deployment-8043  2d5aeb19-e514-463e-b167-f8a7cc1e27bb 14621 1 2023-04-23 11:29:48 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-23 11:29:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-04-23 11:29:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-04-23 11:29:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e186e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-2qpml-54bc444df",LastUpdateTime:2023-04-23 11:29:50 +0000 UTC,LastTransitionTime:2023-04-23 11:29:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 23 11:29:50.402: INFO: New ReplicaSet "test-deployment-2qpml-54bc444df" of Deployment "test-deployment-2qpml":
&ReplicaSet{ObjectMeta:{test-deployment-2qpml-54bc444df  deployment-8043  bae5635f-b909-45ab-ba6b-2465fbf7b6ae 14617 1 2023-04-23 11:29:48 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:54bc444df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-2qpml 2d5aeb19-e514-463e-b167-f8a7cc1e27bb 0xc004e18ae0 0xc004e18ae1}] [] [{kube-controller-manager Update apps/v1 2023-04-23 11:29:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2d5aeb19-e514-463e-b167-f8a7cc1e27bb\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 11:29:50 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 54bc444df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:54bc444df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e18b88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 23 11:29:50.414: INFO: Pod "test-deployment-2qpml-54bc444df-pn6f8" is available:
&Pod{ObjectMeta:{test-deployment-2qpml-54bc444df-pn6f8 test-deployment-2qpml-54bc444df- deployment-8043  8afe0e77-9771-49af-b9f4-1af5177d1a46 14616 0 2023-04-23 11:29:48 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:54bc444df] map[] [{apps/v1 ReplicaSet test-deployment-2qpml-54bc444df bae5635f-b909-45ab-ba6b-2465fbf7b6ae 0xc004e18f60 0xc004e18f61}] [] [{kube-controller-manager Update v1 2023-04-23 11:29:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bae5635f-b909-45ab-ba6b-2465fbf7b6ae\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 11:29:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.116\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p5xwj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p5xwj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:29:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:29:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:29:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:29:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.116,StartTime:2023-04-23 11:29:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 11:29:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://7195504c28f24eacc22b79f7dac48cf6476f4f50f2a4ce41ba6e938f7c3af39c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.116,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Apr 23 11:29:50.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-8043" for this suite. 04/23/23 11:29:50.422
------------------------------
â€¢ [2.233 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:29:48.203
    Apr 23 11:29:48.203: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename deployment 04/23/23 11:29:48.207
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:48.239
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:48.243
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 04/23/23 11:29:48.258
    Apr 23 11:29:48.258: INFO: Creating simple deployment test-deployment-2qpml
    Apr 23 11:29:48.303: INFO: deployment "test-deployment-2qpml" doesn't have the required revision set
    STEP: Getting /status 04/23/23 11:29:50.326
    Apr 23 11:29:50.334: INFO: Deployment test-deployment-2qpml has Conditions: [{Available True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:50 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2qpml-54bc444df" has successfully progressed.}]
    STEP: updating Deployment Status 04/23/23 11:29:50.334
    Apr 23 11:29:50.355: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 29, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 29, 50, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 29, 50, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 29, 48, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-2qpml-54bc444df\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 04/23/23 11:29:50.355
    Apr 23 11:29:50.359: INFO: Observed &Deployment event: ADDED
    Apr 23 11:29:50.359: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2qpml-54bc444df"}
    Apr 23 11:29:50.360: INFO: Observed &Deployment event: MODIFIED
    Apr 23 11:29:50.360: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2qpml-54bc444df"}
    Apr 23 11:29:50.360: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 23 11:29:50.360: INFO: Observed &Deployment event: MODIFIED
    Apr 23 11:29:50.360: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 23 11:29:50.361: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-2qpml-54bc444df" is progressing.}
    Apr 23 11:29:50.361: INFO: Observed &Deployment event: MODIFIED
    Apr 23 11:29:50.361: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:50 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 23 11:29:50.361: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2qpml-54bc444df" has successfully progressed.}
    Apr 23 11:29:50.362: INFO: Observed &Deployment event: MODIFIED
    Apr 23 11:29:50.362: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:50 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 23 11:29:50.362: INFO: Observed Deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2qpml-54bc444df" has successfully progressed.}
    Apr 23 11:29:50.362: INFO: Found Deployment test-deployment-2qpml in namespace deployment-8043 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 23 11:29:50.362: INFO: Deployment test-deployment-2qpml has an updated status
    STEP: patching the Statefulset Status 04/23/23 11:29:50.362
    Apr 23 11:29:50.363: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 23 11:29:50.375: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 04/23/23 11:29:50.375
    Apr 23 11:29:50.378: INFO: Observed &Deployment event: ADDED
    Apr 23 11:29:50.378: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2qpml-54bc444df"}
    Apr 23 11:29:50.379: INFO: Observed &Deployment event: MODIFIED
    Apr 23 11:29:50.379: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2qpml-54bc444df"}
    Apr 23 11:29:50.380: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 23 11:29:50.381: INFO: Observed &Deployment event: MODIFIED
    Apr 23 11:29:50.381: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 23 11:29:50.381: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:48 +0000 UTC 2023-04-23 11:29:48 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-2qpml-54bc444df" is progressing.}
    Apr 23 11:29:50.382: INFO: Observed &Deployment event: MODIFIED
    Apr 23 11:29:50.382: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:50 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 23 11:29:50.383: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2qpml-54bc444df" has successfully progressed.}
    Apr 23 11:29:50.383: INFO: Observed &Deployment event: MODIFIED
    Apr 23 11:29:50.383: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:50 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 23 11:29:50.384: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-23 11:29:50 +0000 UTC 2023-04-23 11:29:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2qpml-54bc444df" has successfully progressed.}
    Apr 23 11:29:50.384: INFO: Observed deployment test-deployment-2qpml in namespace deployment-8043 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 23 11:29:50.384: INFO: Observed &Deployment event: MODIFIED
    Apr 23 11:29:50.384: INFO: Found deployment test-deployment-2qpml in namespace deployment-8043 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Apr 23 11:29:50.384: INFO: Deployment test-deployment-2qpml has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 23 11:29:50.390: INFO: Deployment "test-deployment-2qpml":
    &Deployment{ObjectMeta:{test-deployment-2qpml  deployment-8043  2d5aeb19-e514-463e-b167-f8a7cc1e27bb 14621 1 2023-04-23 11:29:48 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-23 11:29:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-04-23 11:29:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-04-23 11:29:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e186e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-2qpml-54bc444df",LastUpdateTime:2023-04-23 11:29:50 +0000 UTC,LastTransitionTime:2023-04-23 11:29:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 23 11:29:50.402: INFO: New ReplicaSet "test-deployment-2qpml-54bc444df" of Deployment "test-deployment-2qpml":
    &ReplicaSet{ObjectMeta:{test-deployment-2qpml-54bc444df  deployment-8043  bae5635f-b909-45ab-ba6b-2465fbf7b6ae 14617 1 2023-04-23 11:29:48 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:54bc444df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-2qpml 2d5aeb19-e514-463e-b167-f8a7cc1e27bb 0xc004e18ae0 0xc004e18ae1}] [] [{kube-controller-manager Update apps/v1 2023-04-23 11:29:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2d5aeb19-e514-463e-b167-f8a7cc1e27bb\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 11:29:50 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 54bc444df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:54bc444df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e18b88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 23 11:29:50.414: INFO: Pod "test-deployment-2qpml-54bc444df-pn6f8" is available:
    &Pod{ObjectMeta:{test-deployment-2qpml-54bc444df-pn6f8 test-deployment-2qpml-54bc444df- deployment-8043  8afe0e77-9771-49af-b9f4-1af5177d1a46 14616 0 2023-04-23 11:29:48 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:54bc444df] map[] [{apps/v1 ReplicaSet test-deployment-2qpml-54bc444df bae5635f-b909-45ab-ba6b-2465fbf7b6ae 0xc004e18f60 0xc004e18f61}] [] [{kube-controller-manager Update v1 2023-04-23 11:29:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bae5635f-b909-45ab-ba6b-2465fbf7b6ae\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 11:29:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.116\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p5xwj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p5xwj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:29:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:29:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:29:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:29:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.116,StartTime:2023-04-23 11:29:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 11:29:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://7195504c28f24eacc22b79f7dac48cf6476f4f50f2a4ce41ba6e938f7c3af39c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.116,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:29:50.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-8043" for this suite. 04/23/23 11:29:50.422
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:528
[BeforeEach] [sig-node] Security Context
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:29:50.443
Apr 23 11:29:50.443: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename security-context-test 04/23/23 11:29:50.445
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:50.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:50.476
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:50
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:528
Apr 23 11:29:50.498: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-f30e7b2c-7b02-4958-8a83-c85cb6b991fc" in namespace "security-context-test-6541" to be "Succeeded or Failed"
Apr 23 11:29:50.504: INFO: Pod "busybox-privileged-false-f30e7b2c-7b02-4958-8a83-c85cb6b991fc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.424636ms
Apr 23 11:29:52.513: INFO: Pod "busybox-privileged-false-f30e7b2c-7b02-4958-8a83-c85cb6b991fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015155837s
Apr 23 11:29:54.511: INFO: Pod "busybox-privileged-false-f30e7b2c-7b02-4958-8a83-c85cb6b991fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01303761s
Apr 23 11:29:54.511: INFO: Pod "busybox-privileged-false-f30e7b2c-7b02-4958-8a83-c85cb6b991fc" satisfied condition "Succeeded or Failed"
Apr 23 11:29:54.525: INFO: Got logs for pod "busybox-privileged-false-f30e7b2c-7b02-4958-8a83-c85cb6b991fc": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/node/init/init.go:32
Apr 23 11:29:54.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Security Context
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Security Context
  tear down framework | framework.go:193
STEP: Destroying namespace "security-context-test-6541" for this suite. 04/23/23 11:29:54.534
------------------------------
â€¢ [4.129 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:491
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:29:50.443
    Apr 23 11:29:50.443: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename security-context-test 04/23/23 11:29:50.445
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:50.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:50.476
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:50
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:528
    Apr 23 11:29:50.498: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-f30e7b2c-7b02-4958-8a83-c85cb6b991fc" in namespace "security-context-test-6541" to be "Succeeded or Failed"
    Apr 23 11:29:50.504: INFO: Pod "busybox-privileged-false-f30e7b2c-7b02-4958-8a83-c85cb6b991fc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.424636ms
    Apr 23 11:29:52.513: INFO: Pod "busybox-privileged-false-f30e7b2c-7b02-4958-8a83-c85cb6b991fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015155837s
    Apr 23 11:29:54.511: INFO: Pod "busybox-privileged-false-f30e7b2c-7b02-4958-8a83-c85cb6b991fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01303761s
    Apr 23 11:29:54.511: INFO: Pod "busybox-privileged-false-f30e7b2c-7b02-4958-8a83-c85cb6b991fc" satisfied condition "Succeeded or Failed"
    Apr 23 11:29:54.525: INFO: Got logs for pod "busybox-privileged-false-f30e7b2c-7b02-4958-8a83-c85cb6b991fc": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:29:54.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Security Context
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Security Context
      tear down framework | framework.go:193
    STEP: Destroying namespace "security-context-test-6541" for this suite. 04/23/23 11:29:54.534
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:848
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:29:54.573
Apr 23 11:29:54.573: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename statefulset 04/23/23 11:29:54.579
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:54.608
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:54.617
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-8632 04/23/23 11:29:54.624
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:848
STEP: Creating statefulset ss in namespace statefulset-8632 04/23/23 11:29:54.639
Apr 23 11:29:54.672: INFO: Found 0 stateful pods, waiting for 1
Apr 23 11:30:04.680: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 04/23/23 11:30:04.695
STEP: updating a scale subresource 04/23/23 11:30:04.703
STEP: verifying the statefulset Spec.Replicas was modified 04/23/23 11:30:04.713
STEP: Patch a scale subresource 04/23/23 11:30:04.735
STEP: verifying the statefulset Spec.Replicas was modified 04/23/23 11:30:04.804
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Apr 23 11:30:04.819: INFO: Deleting all statefulset in ns statefulset-8632
Apr 23 11:30:04.862: INFO: Scaling statefulset ss to 0
Apr 23 11:30:14.940: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 11:30:14.946: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Apr 23 11:30:14.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-8632" for this suite. 04/23/23 11:30:14.991
------------------------------
â€¢ [SLOW TEST] [20.435 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:848

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:29:54.573
    Apr 23 11:29:54.573: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename statefulset 04/23/23 11:29:54.579
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:29:54.608
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:29:54.617
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-8632 04/23/23 11:29:54.624
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:848
    STEP: Creating statefulset ss in namespace statefulset-8632 04/23/23 11:29:54.639
    Apr 23 11:29:54.672: INFO: Found 0 stateful pods, waiting for 1
    Apr 23 11:30:04.680: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 04/23/23 11:30:04.695
    STEP: updating a scale subresource 04/23/23 11:30:04.703
    STEP: verifying the statefulset Spec.Replicas was modified 04/23/23 11:30:04.713
    STEP: Patch a scale subresource 04/23/23 11:30:04.735
    STEP: verifying the statefulset Spec.Replicas was modified 04/23/23 11:30:04.804
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Apr 23 11:30:04.819: INFO: Deleting all statefulset in ns statefulset-8632
    Apr 23 11:30:04.862: INFO: Scaling statefulset ss to 0
    Apr 23 11:30:14.940: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 23 11:30:14.946: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:30:14.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-8632" for this suite. 04/23/23 11:30:14.991
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:261
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:30:15.019
Apr 23 11:30:15.019: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 11:30:15.021
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:15.056
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:15.062
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:261
STEP: Creating a pod to test downward API volume plugin 04/23/23 11:30:15.072
Apr 23 11:30:15.092: INFO: Waiting up to 5m0s for pod "downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f" in namespace "downward-api-438" to be "Succeeded or Failed"
Apr 23 11:30:15.099: INFO: Pod "downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.978831ms
Apr 23 11:30:17.108: INFO: Pod "downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f": Phase="Running", Reason="", readiness=true. Elapsed: 2.015503683s
Apr 23 11:30:19.106: INFO: Pod "downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f": Phase="Running", Reason="", readiness=false. Elapsed: 4.013443376s
Apr 23 11:30:21.108: INFO: Pod "downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015597762s
STEP: Saw pod success 04/23/23 11:30:21.108
Apr 23 11:30:21.109: INFO: Pod "downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f" satisfied condition "Succeeded or Failed"
Apr 23 11:30:21.114: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f container client-container: <nil>
STEP: delete the pod 04/23/23 11:30:21.129
Apr 23 11:30:21.149: INFO: Waiting for pod downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f to disappear
Apr 23 11:30:21.157: INFO: Pod downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Apr 23 11:30:21.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-438" for this suite. 04/23/23 11:30:21.167
------------------------------
â€¢ [SLOW TEST] [6.163 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:261

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:30:15.019
    Apr 23 11:30:15.019: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 11:30:15.021
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:15.056
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:15.062
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:261
    STEP: Creating a pod to test downward API volume plugin 04/23/23 11:30:15.072
    Apr 23 11:30:15.092: INFO: Waiting up to 5m0s for pod "downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f" in namespace "downward-api-438" to be "Succeeded or Failed"
    Apr 23 11:30:15.099: INFO: Pod "downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.978831ms
    Apr 23 11:30:17.108: INFO: Pod "downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f": Phase="Running", Reason="", readiness=true. Elapsed: 2.015503683s
    Apr 23 11:30:19.106: INFO: Pod "downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f": Phase="Running", Reason="", readiness=false. Elapsed: 4.013443376s
    Apr 23 11:30:21.108: INFO: Pod "downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015597762s
    STEP: Saw pod success 04/23/23 11:30:21.108
    Apr 23 11:30:21.109: INFO: Pod "downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f" satisfied condition "Succeeded or Failed"
    Apr 23 11:30:21.114: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f container client-container: <nil>
    STEP: delete the pod 04/23/23 11:30:21.129
    Apr 23 11:30:21.149: INFO: Waiting for pod downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f to disappear
    Apr 23 11:30:21.157: INFO: Pod downwardapi-volume-acaaa839-8679-469f-a840-b769c711ec3f no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:30:21.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-438" for this suite. 04/23/23 11:30:21.167
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:251
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:30:21.187
Apr 23 11:30:21.187: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename namespaces 04/23/23 11:30:21.191
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:21.222
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:21.228
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:31
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:251
STEP: Creating a test namespace 04/23/23 11:30:21.234
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:21.26
STEP: Creating a service in the namespace 04/23/23 11:30:21.264
STEP: Deleting the namespace 04/23/23 11:30:21.294
STEP: Waiting for the namespace to be removed. 04/23/23 11:30:21.317
STEP: Recreating the namespace 04/23/23 11:30:28.33
STEP: Verifying there is no service in the namespace 04/23/23 11:30:28.357
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:30:28.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "namespaces-6470" for this suite. 04/23/23 11:30:28.369
STEP: Destroying namespace "nsdeletetest-1538" for this suite. 04/23/23 11:30:28.379
Apr 23 11:30:28.385: INFO: Namespace nsdeletetest-1538 was already deleted
STEP: Destroying namespace "nsdeletetest-6521" for this suite. 04/23/23 11:30:28.386
------------------------------
â€¢ [SLOW TEST] [7.208 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:30:21.187
    Apr 23 11:30:21.187: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename namespaces 04/23/23 11:30:21.191
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:21.222
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:21.228
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:251
    STEP: Creating a test namespace 04/23/23 11:30:21.234
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:21.26
    STEP: Creating a service in the namespace 04/23/23 11:30:21.264
    STEP: Deleting the namespace 04/23/23 11:30:21.294
    STEP: Waiting for the namespace to be removed. 04/23/23 11:30:21.317
    STEP: Recreating the namespace 04/23/23 11:30:28.33
    STEP: Verifying there is no service in the namespace 04/23/23 11:30:28.357
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:30:28.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "namespaces-6470" for this suite. 04/23/23 11:30:28.369
    STEP: Destroying namespace "nsdeletetest-1538" for this suite. 04/23/23 11:30:28.379
    Apr 23 11:30:28.385: INFO: Namespace nsdeletetest-1538 was already deleted
    STEP: Destroying namespace "nsdeletetest-6521" for this suite. 04/23/23 11:30:28.386
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:45
[BeforeEach] [sig-node] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:30:28.397
Apr 23 11:30:28.397: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 11:30:28.401
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:28.43
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:28.435
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:45
STEP: Creating configMap configmap-807/configmap-test-74bdef3a-6e29-4a8d-9a4a-574b0791cd86 04/23/23 11:30:28.443
STEP: Creating a pod to test consume configMaps 04/23/23 11:30:28.458
Apr 23 11:30:28.480: INFO: Waiting up to 5m0s for pod "pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd" in namespace "configmap-807" to be "Succeeded or Failed"
Apr 23 11:30:28.515: INFO: Pod "pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd": Phase="Pending", Reason="", readiness=false. Elapsed: 35.095635ms
Apr 23 11:30:30.521: INFO: Pod "pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041427093s
Apr 23 11:30:32.523: INFO: Pod "pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043261766s
STEP: Saw pod success 04/23/23 11:30:32.523
Apr 23 11:30:32.524: INFO: Pod "pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd" satisfied condition "Succeeded or Failed"
Apr 23 11:30:32.530: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd container env-test: <nil>
STEP: delete the pod 04/23/23 11:30:32.547
Apr 23 11:30:32.586: INFO: Waiting for pod pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd to disappear
Apr 23 11:30:32.600: INFO: Pod pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 11:30:32.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-807" for this suite. 04/23/23 11:30:32.615
------------------------------
â€¢ [4.231 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:30:28.397
    Apr 23 11:30:28.397: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 11:30:28.401
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:28.43
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:28.435
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:45
    STEP: Creating configMap configmap-807/configmap-test-74bdef3a-6e29-4a8d-9a4a-574b0791cd86 04/23/23 11:30:28.443
    STEP: Creating a pod to test consume configMaps 04/23/23 11:30:28.458
    Apr 23 11:30:28.480: INFO: Waiting up to 5m0s for pod "pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd" in namespace "configmap-807" to be "Succeeded or Failed"
    Apr 23 11:30:28.515: INFO: Pod "pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd": Phase="Pending", Reason="", readiness=false. Elapsed: 35.095635ms
    Apr 23 11:30:30.521: INFO: Pod "pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041427093s
    Apr 23 11:30:32.523: INFO: Pod "pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043261766s
    STEP: Saw pod success 04/23/23 11:30:32.523
    Apr 23 11:30:32.524: INFO: Pod "pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd" satisfied condition "Succeeded or Failed"
    Apr 23 11:30:32.530: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd container env-test: <nil>
    STEP: delete the pod 04/23/23 11:30:32.547
    Apr 23 11:30:32.586: INFO: Waiting for pod pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd to disappear
    Apr 23 11:30:32.600: INFO: Pod pod-configmaps-b04d7996-cbf3-4b4c-a58a-9b7a7bcd84fd no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:30:32.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-807" for this suite. 04/23/23 11:30:32.615
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:30:32.636
Apr 23 11:30:32.636: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename proxy 04/23/23 11:30:32.638
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:32.672
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:32.677
[BeforeEach] version v1
  test/e2e/framework/metrics/init/init.go:31
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Apr 23 11:30:32.682: INFO: Creating pod...
Apr 23 11:30:32.706: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-2400" to be "running"
Apr 23 11:30:32.723: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 11.212208ms
Apr 23 11:30:34.729: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.017462367s
Apr 23 11:30:34.729: INFO: Pod "agnhost" satisfied condition "running"
Apr 23 11:30:34.729: INFO: Creating service...
Apr 23 11:30:34.745: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/pods/agnhost/proxy?method=DELETE
Apr 23 11:30:34.769: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 23 11:30:34.769: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/pods/agnhost/proxy?method=OPTIONS
Apr 23 11:30:34.785: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 23 11:30:34.785: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/pods/agnhost/proxy?method=PATCH
Apr 23 11:30:34.800: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 23 11:30:34.800: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/pods/agnhost/proxy?method=POST
Apr 23 11:30:34.810: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 23 11:30:34.810: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/pods/agnhost/proxy?method=PUT
Apr 23 11:30:34.822: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 23 11:30:34.822: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/services/e2e-proxy-test-service/proxy?method=DELETE
Apr 23 11:30:34.839: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 23 11:30:34.839: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/services/e2e-proxy-test-service/proxy?method=OPTIONS
Apr 23 11:30:34.852: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 23 11:30:34.852: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/services/e2e-proxy-test-service/proxy?method=PATCH
Apr 23 11:30:34.864: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 23 11:30:34.864: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/services/e2e-proxy-test-service/proxy?method=POST
Apr 23 11:30:34.885: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 23 11:30:34.885: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/services/e2e-proxy-test-service/proxy?method=PUT
Apr 23 11:30:34.901: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 23 11:30:34.901: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/pods/agnhost/proxy?method=GET
Apr 23 11:30:34.909: INFO: http.Client request:GET StatusCode:301
Apr 23 11:30:34.909: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/services/e2e-proxy-test-service/proxy?method=GET
Apr 23 11:30:34.917: INFO: http.Client request:GET StatusCode:301
Apr 23 11:30:34.917: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/pods/agnhost/proxy?method=HEAD
Apr 23 11:30:34.923: INFO: http.Client request:HEAD StatusCode:301
Apr 23 11:30:34.923: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/services/e2e-proxy-test-service/proxy?method=HEAD
Apr 23 11:30:34.930: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/node/init/init.go:32
Apr 23 11:30:34.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] version v1
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] version v1
  dump namespaces | framework.go:196
[DeferCleanup (Each)] version v1
  tear down framework | framework.go:193
STEP: Destroying namespace "proxy-2400" for this suite. 04/23/23 11:30:34.941
------------------------------
â€¢ [2.327 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:30:32.636
    Apr 23 11:30:32.636: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename proxy 04/23/23 11:30:32.638
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:32.672
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:32.677
    [BeforeEach] version v1
      test/e2e/framework/metrics/init/init.go:31
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Apr 23 11:30:32.682: INFO: Creating pod...
    Apr 23 11:30:32.706: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-2400" to be "running"
    Apr 23 11:30:32.723: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 11.212208ms
    Apr 23 11:30:34.729: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.017462367s
    Apr 23 11:30:34.729: INFO: Pod "agnhost" satisfied condition "running"
    Apr 23 11:30:34.729: INFO: Creating service...
    Apr 23 11:30:34.745: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/pods/agnhost/proxy?method=DELETE
    Apr 23 11:30:34.769: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 23 11:30:34.769: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/pods/agnhost/proxy?method=OPTIONS
    Apr 23 11:30:34.785: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 23 11:30:34.785: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/pods/agnhost/proxy?method=PATCH
    Apr 23 11:30:34.800: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 23 11:30:34.800: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/pods/agnhost/proxy?method=POST
    Apr 23 11:30:34.810: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 23 11:30:34.810: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/pods/agnhost/proxy?method=PUT
    Apr 23 11:30:34.822: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 23 11:30:34.822: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/services/e2e-proxy-test-service/proxy?method=DELETE
    Apr 23 11:30:34.839: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 23 11:30:34.839: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Apr 23 11:30:34.852: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 23 11:30:34.852: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/services/e2e-proxy-test-service/proxy?method=PATCH
    Apr 23 11:30:34.864: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 23 11:30:34.864: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/services/e2e-proxy-test-service/proxy?method=POST
    Apr 23 11:30:34.885: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 23 11:30:34.885: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/services/e2e-proxy-test-service/proxy?method=PUT
    Apr 23 11:30:34.901: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 23 11:30:34.901: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/pods/agnhost/proxy?method=GET
    Apr 23 11:30:34.909: INFO: http.Client request:GET StatusCode:301
    Apr 23 11:30:34.909: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/services/e2e-proxy-test-service/proxy?method=GET
    Apr 23 11:30:34.917: INFO: http.Client request:GET StatusCode:301
    Apr 23 11:30:34.917: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/pods/agnhost/proxy?method=HEAD
    Apr 23 11:30:34.923: INFO: http.Client request:HEAD StatusCode:301
    Apr 23 11:30:34.923: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-2400/services/e2e-proxy-test-service/proxy?method=HEAD
    Apr 23 11:30:34.930: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:30:34.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] version v1
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] version v1
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] version v1
      tear down framework | framework.go:193
    STEP: Destroying namespace "proxy-2400" for this suite. 04/23/23 11:30:34.941
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:30:34.974
Apr 23 11:30:34.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename custom-resource-definition 04/23/23 11:30:34.977
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:35.005
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:35.012
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Apr 23 11:30:35.019: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:30:42.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "custom-resource-definition-3731" for this suite. 04/23/23 11:30:42.017
------------------------------
â€¢ [SLOW TEST] [7.096 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:30:34.974
    Apr 23 11:30:34.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename custom-resource-definition 04/23/23 11:30:34.977
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:35.005
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:35.012
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Apr 23 11:30:35.019: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:30:42.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "custom-resource-definition-3731" for this suite. 04/23/23 11:30:42.017
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:124
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:30:42.075
Apr 23 11:30:42.075: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 11:30:42.077
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:42.239
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:42.249
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:124
STEP: Creating configMap with name configmap-test-upd-11003ef6-5f3a-43b6-9810-2f80e0d43be9 04/23/23 11:30:42.326
STEP: Creating the pod 04/23/23 11:30:42.337
Apr 23 11:30:42.353: INFO: Waiting up to 5m0s for pod "pod-configmaps-ab014b1e-03dc-4024-8108-d81b3ca8fe1f" in namespace "configmap-245" to be "running and ready"
Apr 23 11:30:42.358: INFO: Pod "pod-configmaps-ab014b1e-03dc-4024-8108-d81b3ca8fe1f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.701412ms
Apr 23 11:30:42.359: INFO: The phase of Pod pod-configmaps-ab014b1e-03dc-4024-8108-d81b3ca8fe1f is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:30:44.368: INFO: Pod "pod-configmaps-ab014b1e-03dc-4024-8108-d81b3ca8fe1f": Phase="Running", Reason="", readiness=true. Elapsed: 2.014916835s
Apr 23 11:30:44.368: INFO: The phase of Pod pod-configmaps-ab014b1e-03dc-4024-8108-d81b3ca8fe1f is Running (Ready = true)
Apr 23 11:30:44.368: INFO: Pod "pod-configmaps-ab014b1e-03dc-4024-8108-d81b3ca8fe1f" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-11003ef6-5f3a-43b6-9810-2f80e0d43be9 04/23/23 11:30:44.39
STEP: waiting to observe update in volume 04/23/23 11:30:44.402
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 11:30:46.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-245" for this suite. 04/23/23 11:30:46.463
------------------------------
â€¢ [4.420 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:30:42.075
    Apr 23 11:30:42.075: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 11:30:42.077
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:42.239
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:42.249
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:124
    STEP: Creating configMap with name configmap-test-upd-11003ef6-5f3a-43b6-9810-2f80e0d43be9 04/23/23 11:30:42.326
    STEP: Creating the pod 04/23/23 11:30:42.337
    Apr 23 11:30:42.353: INFO: Waiting up to 5m0s for pod "pod-configmaps-ab014b1e-03dc-4024-8108-d81b3ca8fe1f" in namespace "configmap-245" to be "running and ready"
    Apr 23 11:30:42.358: INFO: Pod "pod-configmaps-ab014b1e-03dc-4024-8108-d81b3ca8fe1f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.701412ms
    Apr 23 11:30:42.359: INFO: The phase of Pod pod-configmaps-ab014b1e-03dc-4024-8108-d81b3ca8fe1f is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:30:44.368: INFO: Pod "pod-configmaps-ab014b1e-03dc-4024-8108-d81b3ca8fe1f": Phase="Running", Reason="", readiness=true. Elapsed: 2.014916835s
    Apr 23 11:30:44.368: INFO: The phase of Pod pod-configmaps-ab014b1e-03dc-4024-8108-d81b3ca8fe1f is Running (Ready = true)
    Apr 23 11:30:44.368: INFO: Pod "pod-configmaps-ab014b1e-03dc-4024-8108-d81b3ca8fe1f" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-11003ef6-5f3a-43b6-9810-2f80e0d43be9 04/23/23 11:30:44.39
    STEP: waiting to observe update in volume 04/23/23 11:30:44.402
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:30:46.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-245" for this suite. 04/23/23 11:30:46.463
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1415
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:30:46.502
Apr 23 11:30:46.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 11:30:46.505
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:46.572
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:46.577
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1415
STEP: creating Agnhost RC 04/23/23 11:30:46.583
Apr 23 11:30:46.583: INFO: namespace kubectl-8399
Apr 23 11:30:46.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8399 create -f -'
Apr 23 11:30:48.729: INFO: stderr: ""
Apr 23 11:30:48.729: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/23/23 11:30:48.729
Apr 23 11:30:49.741: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 23 11:30:49.741: INFO: Found 0 / 1
Apr 23 11:30:50.739: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 23 11:30:50.739: INFO: Found 0 / 1
Apr 23 11:30:51.737: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 23 11:30:51.737: INFO: Found 1 / 1
Apr 23 11:30:51.737: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 23 11:30:51.744: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 23 11:30:51.744: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 23 11:30:51.744: INFO: wait on agnhost-primary startup in kubectl-8399 
Apr 23 11:30:51.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8399 logs agnhost-primary-d5qkd agnhost-primary'
Apr 23 11:30:52.096: INFO: stderr: ""
Apr 23 11:30:52.096: INFO: stdout: "Paused\n"
STEP: exposing RC 04/23/23 11:30:52.096
Apr 23 11:30:52.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8399 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Apr 23 11:30:52.355: INFO: stderr: ""
Apr 23 11:30:52.355: INFO: stdout: "service/rm2 exposed\n"
Apr 23 11:30:52.370: INFO: Service rm2 in namespace kubectl-8399 found.
STEP: exposing service 04/23/23 11:30:54.388
Apr 23 11:30:54.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8399 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Apr 23 11:30:54.601: INFO: stderr: ""
Apr 23 11:30:54.601: INFO: stdout: "service/rm3 exposed\n"
Apr 23 11:30:54.619: INFO: Service rm3 in namespace kubectl-8399 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 11:30:56.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-8399" for this suite. 04/23/23 11:30:56.645
------------------------------
â€¢ [SLOW TEST] [10.158 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1409
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:30:46.502
    Apr 23 11:30:46.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 11:30:46.505
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:46.572
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:46.577
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1415
    STEP: creating Agnhost RC 04/23/23 11:30:46.583
    Apr 23 11:30:46.583: INFO: namespace kubectl-8399
    Apr 23 11:30:46.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8399 create -f -'
    Apr 23 11:30:48.729: INFO: stderr: ""
    Apr 23 11:30:48.729: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/23/23 11:30:48.729
    Apr 23 11:30:49.741: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 23 11:30:49.741: INFO: Found 0 / 1
    Apr 23 11:30:50.739: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 23 11:30:50.739: INFO: Found 0 / 1
    Apr 23 11:30:51.737: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 23 11:30:51.737: INFO: Found 1 / 1
    Apr 23 11:30:51.737: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Apr 23 11:30:51.744: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 23 11:30:51.744: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 23 11:30:51.744: INFO: wait on agnhost-primary startup in kubectl-8399 
    Apr 23 11:30:51.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8399 logs agnhost-primary-d5qkd agnhost-primary'
    Apr 23 11:30:52.096: INFO: stderr: ""
    Apr 23 11:30:52.096: INFO: stdout: "Paused\n"
    STEP: exposing RC 04/23/23 11:30:52.096
    Apr 23 11:30:52.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8399 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Apr 23 11:30:52.355: INFO: stderr: ""
    Apr 23 11:30:52.355: INFO: stdout: "service/rm2 exposed\n"
    Apr 23 11:30:52.370: INFO: Service rm2 in namespace kubectl-8399 found.
    STEP: exposing service 04/23/23 11:30:54.388
    Apr 23 11:30:54.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8399 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Apr 23 11:30:54.601: INFO: stderr: ""
    Apr 23 11:30:54.601: INFO: stdout: "service/rm3 exposed\n"
    Apr 23 11:30:54.619: INFO: Service rm3 in namespace kubectl-8399 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:30:56.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-8399" for this suite. 04/23/23 11:30:56.645
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:169
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:30:56.667
Apr 23 11:30:56.671: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-probe 04/23/23 11:30:56.677
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:56.713
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:56.719
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:169
STEP: Creating pod liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d in namespace container-probe-1230 04/23/23 11:30:56.727
Apr 23 11:30:56.748: INFO: Waiting up to 5m0s for pod "liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d" in namespace "container-probe-1230" to be "not pending"
Apr 23 11:30:56.768: INFO: Pod "liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d": Phase="Pending", Reason="", readiness=false. Elapsed: 19.940445ms
Apr 23 11:30:58.778: INFO: Pod "liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d": Phase="Running", Reason="", readiness=true. Elapsed: 2.030320273s
Apr 23 11:30:58.779: INFO: Pod "liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d" satisfied condition "not pending"
Apr 23 11:30:58.779: INFO: Started pod liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d in namespace container-probe-1230
STEP: checking the pod's current state and verifying that restartCount is present 04/23/23 11:30:58.779
Apr 23 11:30:58.787: INFO: Initial restart count of pod liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d is 0
Apr 23 11:31:18.881: INFO: Restart count of pod container-probe-1230/liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d is now 1 (20.093441313s elapsed)
STEP: deleting the pod 04/23/23 11:31:18.881
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Apr 23 11:31:18.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-1230" for this suite. 04/23/23 11:31:18.94
------------------------------
â€¢ [SLOW TEST] [22.294 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:169

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:30:56.667
    Apr 23 11:30:56.671: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-probe 04/23/23 11:30:56.677
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:30:56.713
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:30:56.719
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:169
    STEP: Creating pod liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d in namespace container-probe-1230 04/23/23 11:30:56.727
    Apr 23 11:30:56.748: INFO: Waiting up to 5m0s for pod "liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d" in namespace "container-probe-1230" to be "not pending"
    Apr 23 11:30:56.768: INFO: Pod "liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d": Phase="Pending", Reason="", readiness=false. Elapsed: 19.940445ms
    Apr 23 11:30:58.778: INFO: Pod "liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d": Phase="Running", Reason="", readiness=true. Elapsed: 2.030320273s
    Apr 23 11:30:58.779: INFO: Pod "liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d" satisfied condition "not pending"
    Apr 23 11:30:58.779: INFO: Started pod liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d in namespace container-probe-1230
    STEP: checking the pod's current state and verifying that restartCount is present 04/23/23 11:30:58.779
    Apr 23 11:30:58.787: INFO: Initial restart count of pod liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d is 0
    Apr 23 11:31:18.881: INFO: Restart count of pod container-probe-1230/liveness-b8ae8cf8-3342-4e57-9539-000bd1f6615d is now 1 (20.093441313s elapsed)
    STEP: deleting the pod 04/23/23 11:31:18.881
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:31:18.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-1230" for this suite. 04/23/23 11:31:18.94
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:31:18.961
Apr 23 11:31:18.962: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename runtimeclass 04/23/23 11:31:18.966
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:31:19.004
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:31:19.01
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:31
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-6260-delete-me 04/23/23 11:31:19.024
STEP: Waiting for the RuntimeClass to disappear 04/23/23 11:31:19.036
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/node/init/init.go:32
Apr 23 11:31:19.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] RuntimeClass
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] RuntimeClass
  tear down framework | framework.go:193
STEP: Destroying namespace "runtimeclass-6260" for this suite. 04/23/23 11:31:19.063
------------------------------
â€¢ [0.118 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:31:18.961
    Apr 23 11:31:18.962: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename runtimeclass 04/23/23 11:31:18.966
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:31:19.004
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:31:19.01
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:31
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-6260-delete-me 04/23/23 11:31:19.024
    STEP: Waiting for the RuntimeClass to disappear 04/23/23 11:31:19.036
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:31:19.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      tear down framework | framework.go:193
    STEP: Destroying namespace "runtimeclass-6260" for this suite. 04/23/23 11:31:19.063
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:177
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:31:19.084
Apr 23 11:31:19.084: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename init-container 04/23/23 11:31:19.086
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:31:19.115
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:31:19.122
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:165
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:177
STEP: creating the pod 04/23/23 11:31:19.128
Apr 23 11:31:19.128: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:31:24.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  tear down framework | framework.go:193
STEP: Destroying namespace "init-container-5794" for this suite. 04/23/23 11:31:24.998
------------------------------
â€¢ [SLOW TEST] [5.926 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:177

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:31:19.084
    Apr 23 11:31:19.084: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename init-container 04/23/23 11:31:19.086
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:31:19.115
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:31:19.122
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:165
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:177
    STEP: creating the pod 04/23/23 11:31:19.128
    Apr 23 11:31:19.128: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:31:24.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      tear down framework | framework.go:193
    STEP: Destroying namespace "init-container-5794" for this suite. 04/23/23 11:31:24.998
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1557
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:31:25.011
Apr 23 11:31:25.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 11:31:25.014
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:31:25.046
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:31:25.052
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1557
STEP: creating a service nodeport-service with the type=NodePort in namespace services-3278 04/23/23 11:31:25.058
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/23/23 11:31:25.086
STEP: creating service externalsvc in namespace services-3278 04/23/23 11:31:25.089
STEP: creating replication controller externalsvc in namespace services-3278 04/23/23 11:31:25.13
I0423 11:31:25.151126      13 runners.go:193] Created replication controller with name: externalsvc, namespace: services-3278, replica count: 2
I0423 11:31:28.203160      13 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 04/23/23 11:31:28.21
Apr 23 11:31:28.245: INFO: Creating new exec pod
Apr 23 11:31:28.267: INFO: Waiting up to 5m0s for pod "execpodz78rr" in namespace "services-3278" to be "running"
Apr 23 11:31:28.281: INFO: Pod "execpodz78rr": Phase="Pending", Reason="", readiness=false. Elapsed: 13.943898ms
Apr 23 11:31:30.290: INFO: Pod "execpodz78rr": Phase="Running", Reason="", readiness=true. Elapsed: 2.023068437s
Apr 23 11:31:30.290: INFO: Pod "execpodz78rr" satisfied condition "running"
Apr 23 11:31:30.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-3278 exec execpodz78rr -- /bin/sh -x -c nslookup nodeport-service.services-3278.svc.cluster.local'
Apr 23 11:31:30.766: INFO: stderr: "+ nslookup nodeport-service.services-3278.svc.cluster.local\n"
Apr 23 11:31:30.766: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nnodeport-service.services-3278.svc.cluster.local\tcanonical name = externalsvc.services-3278.svc.cluster.local.\nName:\texternalsvc.services-3278.svc.cluster.local\nAddress: 10.233.24.18\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3278, will wait for the garbage collector to delete the pods 04/23/23 11:31:30.766
Apr 23 11:31:30.837: INFO: Deleting ReplicationController externalsvc took: 14.393463ms
Apr 23 11:31:30.947: INFO: Terminating ReplicationController externalsvc pods took: 110.019701ms
Apr 23 11:31:33.304: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 11:31:33.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-3278" for this suite. 04/23/23 11:31:33.381
------------------------------
â€¢ [SLOW TEST] [8.398 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1557

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:31:25.011
    Apr 23 11:31:25.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 11:31:25.014
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:31:25.046
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:31:25.052
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1557
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-3278 04/23/23 11:31:25.058
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/23/23 11:31:25.086
    STEP: creating service externalsvc in namespace services-3278 04/23/23 11:31:25.089
    STEP: creating replication controller externalsvc in namespace services-3278 04/23/23 11:31:25.13
    I0423 11:31:25.151126      13 runners.go:193] Created replication controller with name: externalsvc, namespace: services-3278, replica count: 2
    I0423 11:31:28.203160      13 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 04/23/23 11:31:28.21
    Apr 23 11:31:28.245: INFO: Creating new exec pod
    Apr 23 11:31:28.267: INFO: Waiting up to 5m0s for pod "execpodz78rr" in namespace "services-3278" to be "running"
    Apr 23 11:31:28.281: INFO: Pod "execpodz78rr": Phase="Pending", Reason="", readiness=false. Elapsed: 13.943898ms
    Apr 23 11:31:30.290: INFO: Pod "execpodz78rr": Phase="Running", Reason="", readiness=true. Elapsed: 2.023068437s
    Apr 23 11:31:30.290: INFO: Pod "execpodz78rr" satisfied condition "running"
    Apr 23 11:31:30.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-3278 exec execpodz78rr -- /bin/sh -x -c nslookup nodeport-service.services-3278.svc.cluster.local'
    Apr 23 11:31:30.766: INFO: stderr: "+ nslookup nodeport-service.services-3278.svc.cluster.local\n"
    Apr 23 11:31:30.766: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nnodeport-service.services-3278.svc.cluster.local\tcanonical name = externalsvc.services-3278.svc.cluster.local.\nName:\texternalsvc.services-3278.svc.cluster.local\nAddress: 10.233.24.18\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-3278, will wait for the garbage collector to delete the pods 04/23/23 11:31:30.766
    Apr 23 11:31:30.837: INFO: Deleting ReplicationController externalsvc took: 14.393463ms
    Apr 23 11:31:30.947: INFO: Terminating ReplicationController externalsvc pods took: 110.019701ms
    Apr 23 11:31:33.304: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:31:33.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-3278" for this suite. 04/23/23 11:31:33.381
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:31:33.412
Apr 23 11:31:33.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename subpath 04/23/23 11:31:33.415
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:31:33.448
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:31:33.457
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/23/23 11:31:33.463
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-xmh6 04/23/23 11:31:33.483
STEP: Creating a pod to test atomic-volume-subpath 04/23/23 11:31:33.484
Apr 23 11:31:33.503: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xmh6" in namespace "subpath-6945" to be "Succeeded or Failed"
Apr 23 11:31:33.509: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.22075ms
Apr 23 11:31:35.518: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 2.015131652s
Apr 23 11:31:37.518: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 4.015300073s
Apr 23 11:31:39.544: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 6.041291041s
Apr 23 11:31:41.536: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 8.032727782s
Apr 23 11:31:43.543: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 10.04001951s
Apr 23 11:31:45.516: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 12.013344789s
Apr 23 11:31:47.517: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 14.014476648s
Apr 23 11:31:49.530: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 16.026950438s
Apr 23 11:31:51.530: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 18.0266078s
Apr 23 11:31:53.516: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 20.013401994s
Apr 23 11:31:55.528: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=false. Elapsed: 22.025271391s
Apr 23 11:31:57.516: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.013224264s
STEP: Saw pod success 04/23/23 11:31:57.516
Apr 23 11:31:57.517: INFO: Pod "pod-subpath-test-configmap-xmh6" satisfied condition "Succeeded or Failed"
Apr 23 11:31:57.525: INFO: Trying to get logs from node eingavuivie7-3 pod pod-subpath-test-configmap-xmh6 container test-container-subpath-configmap-xmh6: <nil>
STEP: delete the pod 04/23/23 11:31:57.556
Apr 23 11:31:57.588: INFO: Waiting for pod pod-subpath-test-configmap-xmh6 to disappear
Apr 23 11:31:57.601: INFO: Pod pod-subpath-test-configmap-xmh6 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xmh6 04/23/23 11:31:57.601
Apr 23 11:31:57.601: INFO: Deleting pod "pod-subpath-test-configmap-xmh6" in namespace "subpath-6945"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/node/init/init.go:32
Apr 23 11:31:57.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Subpath
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Subpath
  tear down framework | framework.go:193
STEP: Destroying namespace "subpath-6945" for this suite. 04/23/23 11:31:57.624
------------------------------
â€¢ [SLOW TEST] [24.240 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:31:33.412
    Apr 23 11:31:33.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename subpath 04/23/23 11:31:33.415
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:31:33.448
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:31:33.457
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/23/23 11:31:33.463
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-xmh6 04/23/23 11:31:33.483
    STEP: Creating a pod to test atomic-volume-subpath 04/23/23 11:31:33.484
    Apr 23 11:31:33.503: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xmh6" in namespace "subpath-6945" to be "Succeeded or Failed"
    Apr 23 11:31:33.509: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.22075ms
    Apr 23 11:31:35.518: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 2.015131652s
    Apr 23 11:31:37.518: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 4.015300073s
    Apr 23 11:31:39.544: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 6.041291041s
    Apr 23 11:31:41.536: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 8.032727782s
    Apr 23 11:31:43.543: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 10.04001951s
    Apr 23 11:31:45.516: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 12.013344789s
    Apr 23 11:31:47.517: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 14.014476648s
    Apr 23 11:31:49.530: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 16.026950438s
    Apr 23 11:31:51.530: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 18.0266078s
    Apr 23 11:31:53.516: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=true. Elapsed: 20.013401994s
    Apr 23 11:31:55.528: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Running", Reason="", readiness=false. Elapsed: 22.025271391s
    Apr 23 11:31:57.516: INFO: Pod "pod-subpath-test-configmap-xmh6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.013224264s
    STEP: Saw pod success 04/23/23 11:31:57.516
    Apr 23 11:31:57.517: INFO: Pod "pod-subpath-test-configmap-xmh6" satisfied condition "Succeeded or Failed"
    Apr 23 11:31:57.525: INFO: Trying to get logs from node eingavuivie7-3 pod pod-subpath-test-configmap-xmh6 container test-container-subpath-configmap-xmh6: <nil>
    STEP: delete the pod 04/23/23 11:31:57.556
    Apr 23 11:31:57.588: INFO: Waiting for pod pod-subpath-test-configmap-xmh6 to disappear
    Apr 23 11:31:57.601: INFO: Pod pod-subpath-test-configmap-xmh6 no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-xmh6 04/23/23 11:31:57.601
    Apr 23 11:31:57.601: INFO: Deleting pod "pod-subpath-test-configmap-xmh6" in namespace "subpath-6945"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:31:57.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Subpath
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Subpath
      tear down framework | framework.go:193
    STEP: Destroying namespace "subpath-6945" for this suite. 04/23/23 11:31:57.624
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:31:57.657
Apr 23 11:31:57.657: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename cronjob 04/23/23 11:31:57.673
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:31:57.718
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:31:57.724
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:31
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 04/23/23 11:31:57.731
STEP: Ensuring no jobs are scheduled 04/23/23 11:31:57.747
STEP: Ensuring no job exists by listing jobs explicitly 04/23/23 11:36:57.765
STEP: Removing cronjob 04/23/23 11:36:57.783
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/node/init/init.go:32
Apr 23 11:36:57.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] CronJob
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] CronJob
  tear down framework | framework.go:193
STEP: Destroying namespace "cronjob-6775" for this suite. 04/23/23 11:36:57.814
------------------------------
â€¢ [SLOW TEST] [300.170 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:31:57.657
    Apr 23 11:31:57.657: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename cronjob 04/23/23 11:31:57.673
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:31:57.718
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:31:57.724
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:31
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 04/23/23 11:31:57.731
    STEP: Ensuring no jobs are scheduled 04/23/23 11:31:57.747
    STEP: Ensuring no job exists by listing jobs explicitly 04/23/23 11:36:57.765
    STEP: Removing cronjob 04/23/23 11:36:57.783
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:36:57.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] CronJob
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] CronJob
      tear down framework | framework.go:193
    STEP: Destroying namespace "cronjob-6775" for this suite. 04/23/23 11:36:57.814
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:36:57.841
Apr 23 11:36:57.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename deployment 04/23/23 11:36:57.845
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:36:57.878
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:36:57.882
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Apr 23 11:36:57.904: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 23 11:37:02.924: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/23/23 11:37:02.926
Apr 23 11:37:02.927: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 23 11:37:04.938: INFO: Creating deployment "test-rollover-deployment"
Apr 23 11:37:04.956: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 23 11:37:06.972: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 23 11:37:06.985: INFO: Ensure that both replica sets have 1 created replica
Apr 23 11:37:06.996: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 23 11:37:07.021: INFO: Updating deployment test-rollover-deployment
Apr 23 11:37:07.021: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 23 11:37:09.036: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 23 11:37:09.047: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 23 11:37:09.061: INFO: all replica sets need to contain the pod-template-hash label
Apr 23 11:37:09.061: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 11:37:11.081: INFO: all replica sets need to contain the pod-template-hash label
Apr 23 11:37:11.081: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 11:37:13.076: INFO: all replica sets need to contain the pod-template-hash label
Apr 23 11:37:13.076: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 11:37:15.075: INFO: all replica sets need to contain the pod-template-hash label
Apr 23 11:37:15.076: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 11:37:17.079: INFO: all replica sets need to contain the pod-template-hash label
Apr 23 11:37:17.079: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 11:37:19.075: INFO: 
Apr 23 11:37:19.075: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 23 11:37:19.090: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-9529  b00a823b-1fd1-4d19-8455-911ceb8e90ff 16335 2 2023-04-23 11:37:04 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-23 11:37:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 11:37:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000cd9a48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-23 11:37:05 +0000 UTC,LastTransitionTime:2023-04-23 11:37:05 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6c6df9974f" has successfully progressed.,LastUpdateTime:2023-04-23 11:37:18 +0000 UTC,LastTransitionTime:2023-04-23 11:37:04 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 23 11:37:19.095: INFO: New ReplicaSet "test-rollover-deployment-6c6df9974f" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6c6df9974f  deployment-9529  d8219aed-f42c-4e59-b9fc-7e228f113eb3 16324 2 2023-04-23 11:37:07 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6c6df9974f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment b00a823b-1fd1-4d19-8455-911ceb8e90ff 0xc0042d8337 0xc0042d8338}] [] [{kube-controller-manager Update apps/v1 2023-04-23 11:37:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b00a823b-1fd1-4d19-8455-911ceb8e90ff\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 11:37:18 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6c6df9974f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6c6df9974f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0042d83f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 23 11:37:19.095: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 23 11:37:19.095: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9529  ed62f177-d251-4c9e-a45e-1de52c9e5b7d 16334 2 2023-04-23 11:36:57 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment b00a823b-1fd1-4d19-8455-911ceb8e90ff 0xc0042d81f7 0xc0042d81f8}] [] [{e2e.test Update apps/v1 2023-04-23 11:36:57 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 11:37:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b00a823b-1fd1-4d19-8455-911ceb8e90ff\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-23 11:37:18 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0042d82c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 23 11:37:19.095: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-768dcbc65b  deployment-9529  bbecbd7d-cc04-4bfb-bb1a-edf4832b932a 16288 2 2023-04-23 11:37:04 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:768dcbc65b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment b00a823b-1fd1-4d19-8455-911ceb8e90ff 0xc0042d8467 0xc0042d8468}] [] [{kube-controller-manager Update apps/v1 2023-04-23 11:37:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b00a823b-1fd1-4d19-8455-911ceb8e90ff\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 11:37:07 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 768dcbc65b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:768dcbc65b] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0042d8528 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 23 11:37:19.101: INFO: Pod "test-rollover-deployment-6c6df9974f-g54zj" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6c6df9974f-g54zj test-rollover-deployment-6c6df9974f- deployment-9529  234fafd8-4ca3-4226-81cc-c6dd61134503 16299 0 2023-04-23 11:37:07 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6c6df9974f] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6c6df9974f d8219aed-f42c-4e59-b9fc-7e228f113eb3 0xc0042d8aa7 0xc0042d8aa8}] [] [{kube-controller-manager Update v1 2023-04-23 11:37:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d8219aed-f42c-4e59-b9fc-7e228f113eb3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 11:37:08 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.47\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bjjhb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bjjhb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:37:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:37:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:37:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:37:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.47,StartTime:2023-04-23 11:37:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 11:37:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:cri-o://c578e2d43ddd307fe7b6a3b8d888f329a7b53f4633b3584fb3dd65212a692a13,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.47,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Apr 23 11:37:19.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-9529" for this suite. 04/23/23 11:37:19.109
------------------------------
â€¢ [SLOW TEST] [21.278 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:36:57.841
    Apr 23 11:36:57.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename deployment 04/23/23 11:36:57.845
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:36:57.878
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:36:57.882
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Apr 23 11:36:57.904: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Apr 23 11:37:02.924: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/23/23 11:37:02.926
    Apr 23 11:37:02.927: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Apr 23 11:37:04.938: INFO: Creating deployment "test-rollover-deployment"
    Apr 23 11:37:04.956: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Apr 23 11:37:06.972: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Apr 23 11:37:06.985: INFO: Ensure that both replica sets have 1 created replica
    Apr 23 11:37:06.996: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Apr 23 11:37:07.021: INFO: Updating deployment test-rollover-deployment
    Apr 23 11:37:07.021: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Apr 23 11:37:09.036: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Apr 23 11:37:09.047: INFO: Make sure deployment "test-rollover-deployment" is complete
    Apr 23 11:37:09.061: INFO: all replica sets need to contain the pod-template-hash label
    Apr 23 11:37:09.061: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 11:37:11.081: INFO: all replica sets need to contain the pod-template-hash label
    Apr 23 11:37:11.081: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 11:37:13.076: INFO: all replica sets need to contain the pod-template-hash label
    Apr 23 11:37:13.076: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 11:37:15.075: INFO: all replica sets need to contain the pod-template-hash label
    Apr 23 11:37:15.076: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 11:37:17.079: INFO: all replica sets need to contain the pod-template-hash label
    Apr 23 11:37:17.079: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 5, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 37, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 37, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6c6df9974f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 11:37:19.075: INFO: 
    Apr 23 11:37:19.075: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 23 11:37:19.090: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-9529  b00a823b-1fd1-4d19-8455-911ceb8e90ff 16335 2 2023-04-23 11:37:04 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-23 11:37:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 11:37:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000cd9a48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-23 11:37:05 +0000 UTC,LastTransitionTime:2023-04-23 11:37:05 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6c6df9974f" has successfully progressed.,LastUpdateTime:2023-04-23 11:37:18 +0000 UTC,LastTransitionTime:2023-04-23 11:37:04 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 23 11:37:19.095: INFO: New ReplicaSet "test-rollover-deployment-6c6df9974f" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6c6df9974f  deployment-9529  d8219aed-f42c-4e59-b9fc-7e228f113eb3 16324 2 2023-04-23 11:37:07 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6c6df9974f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment b00a823b-1fd1-4d19-8455-911ceb8e90ff 0xc0042d8337 0xc0042d8338}] [] [{kube-controller-manager Update apps/v1 2023-04-23 11:37:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b00a823b-1fd1-4d19-8455-911ceb8e90ff\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 11:37:18 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6c6df9974f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6c6df9974f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0042d83f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 23 11:37:19.095: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Apr 23 11:37:19.095: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9529  ed62f177-d251-4c9e-a45e-1de52c9e5b7d 16334 2 2023-04-23 11:36:57 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment b00a823b-1fd1-4d19-8455-911ceb8e90ff 0xc0042d81f7 0xc0042d81f8}] [] [{e2e.test Update apps/v1 2023-04-23 11:36:57 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 11:37:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b00a823b-1fd1-4d19-8455-911ceb8e90ff\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-23 11:37:18 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0042d82c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 23 11:37:19.095: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-768dcbc65b  deployment-9529  bbecbd7d-cc04-4bfb-bb1a-edf4832b932a 16288 2 2023-04-23 11:37:04 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:768dcbc65b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment b00a823b-1fd1-4d19-8455-911ceb8e90ff 0xc0042d8467 0xc0042d8468}] [] [{kube-controller-manager Update apps/v1 2023-04-23 11:37:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b00a823b-1fd1-4d19-8455-911ceb8e90ff\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 11:37:07 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 768dcbc65b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:768dcbc65b] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0042d8528 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 23 11:37:19.101: INFO: Pod "test-rollover-deployment-6c6df9974f-g54zj" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6c6df9974f-g54zj test-rollover-deployment-6c6df9974f- deployment-9529  234fafd8-4ca3-4226-81cc-c6dd61134503 16299 0 2023-04-23 11:37:07 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6c6df9974f] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6c6df9974f d8219aed-f42c-4e59-b9fc-7e228f113eb3 0xc0042d8aa7 0xc0042d8aa8}] [] [{kube-controller-manager Update v1 2023-04-23 11:37:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d8219aed-f42c-4e59-b9fc-7e228f113eb3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 11:37:08 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.47\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bjjhb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bjjhb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:37:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:37:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:37:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 11:37:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.47,StartTime:2023-04-23 11:37:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 11:37:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:cri-o://c578e2d43ddd307fe7b6a3b8d888f329a7b53f4633b3584fb3dd65212a692a13,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.47,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:37:19.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-9529" for this suite. 04/23/23 11:37:19.109
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:235
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:37:19.122
Apr 23 11:37:19.122: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 11:37:19.126
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:37:19.149
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:37:19.154
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:235
STEP: Creating a pod to test downward API volume plugin 04/23/23 11:37:19.159
Apr 23 11:37:19.181: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35" in namespace "downward-api-9052" to be "Succeeded or Failed"
Apr 23 11:37:19.195: INFO: Pod "downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35": Phase="Pending", Reason="", readiness=false. Elapsed: 13.086971ms
Apr 23 11:37:21.203: INFO: Pod "downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021338247s
Apr 23 11:37:23.204: INFO: Pod "downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022015734s
STEP: Saw pod success 04/23/23 11:37:23.204
Apr 23 11:37:23.204: INFO: Pod "downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35" satisfied condition "Succeeded or Failed"
Apr 23 11:37:23.208: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35 container client-container: <nil>
STEP: delete the pod 04/23/23 11:37:23.245
Apr 23 11:37:23.270: INFO: Waiting for pod downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35 to disappear
Apr 23 11:37:23.275: INFO: Pod downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Apr 23 11:37:23.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-9052" for this suite. 04/23/23 11:37:23.282
------------------------------
â€¢ [4.170 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:37:19.122
    Apr 23 11:37:19.122: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 11:37:19.126
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:37:19.149
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:37:19.154
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:235
    STEP: Creating a pod to test downward API volume plugin 04/23/23 11:37:19.159
    Apr 23 11:37:19.181: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35" in namespace "downward-api-9052" to be "Succeeded or Failed"
    Apr 23 11:37:19.195: INFO: Pod "downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35": Phase="Pending", Reason="", readiness=false. Elapsed: 13.086971ms
    Apr 23 11:37:21.203: INFO: Pod "downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021338247s
    Apr 23 11:37:23.204: INFO: Pod "downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022015734s
    STEP: Saw pod success 04/23/23 11:37:23.204
    Apr 23 11:37:23.204: INFO: Pod "downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35" satisfied condition "Succeeded or Failed"
    Apr 23 11:37:23.208: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35 container client-container: <nil>
    STEP: delete the pod 04/23/23 11:37:23.245
    Apr 23 11:37:23.270: INFO: Waiting for pod downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35 to disappear
    Apr 23 11:37:23.275: INFO: Pod downwardapi-volume-99988dc5-344f-4c6f-9c04-57dc570dba35 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:37:23.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-9052" for this suite. 04/23/23 11:37:23.282
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:205
[BeforeEach] [sig-network] EndpointSlice
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:37:23.294
Apr 23 11:37:23.294: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename endpointslice 04/23/23 11:37:23.296
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:37:23.318
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:37:23.323
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:52
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:205
STEP: referencing a single matching pod 04/23/23 11:37:28.481
STEP: referencing matching pods with named port 04/23/23 11:37:33.502
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 04/23/23 11:37:38.517
STEP: recreating EndpointSlices after they've been deleted 04/23/23 11:37:43.562
Apr 23 11:37:43.621: INFO: EndpointSlice for Service endpointslice-2667/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/node/init/init.go:32
Apr 23 11:37:53.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] EndpointSlice
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] EndpointSlice
  tear down framework | framework.go:193
STEP: Destroying namespace "endpointslice-2667" for this suite. 04/23/23 11:37:53.678
------------------------------
â€¢ [SLOW TEST] [30.406 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:205

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:37:23.294
    Apr 23 11:37:23.294: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename endpointslice 04/23/23 11:37:23.296
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:37:23.318
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:37:23.323
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:52
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:205
    STEP: referencing a single matching pod 04/23/23 11:37:28.481
    STEP: referencing matching pods with named port 04/23/23 11:37:33.502
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 04/23/23 11:37:38.517
    STEP: recreating EndpointSlices after they've been deleted 04/23/23 11:37:43.562
    Apr 23 11:37:43.621: INFO: EndpointSlice for Service endpointslice-2667/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:37:53.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      tear down framework | framework.go:193
    STEP: Destroying namespace "endpointslice-2667" for this suite. 04/23/23 11:37:53.678
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:703
[BeforeEach] [sig-apps] Job
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:37:53.702
Apr 23 11:37:53.702: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename job 04/23/23 11:37:53.711
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:37:53.746
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:37:53.754
[BeforeEach] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:31
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:703
STEP: Creating a suspended job 04/23/23 11:37:53.763
STEP: Patching the Job 04/23/23 11:37:53.771
STEP: Watching for Job to be patched 04/23/23 11:37:53.808
Apr 23 11:37:53.811: INFO: Event ADDED observed for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw] and annotations: map[batch.kubernetes.io/job-tracking:]
Apr 23 11:37:53.811: INFO: Event MODIFIED found for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 04/23/23 11:37:53.811
STEP: Watching for Job to be updated 04/23/23 11:37:53.841
Apr 23 11:37:53.848: INFO: Event MODIFIED found for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 23 11:37:53.848: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 04/23/23 11:37:53.849
Apr 23 11:37:53.858: INFO: Job: e2e-qtfcw as labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched]
STEP: Waiting for job to complete 04/23/23 11:37:53.858
STEP: Delete a job collection with a labelselector 04/23/23 11:38:05.869
STEP: Watching for Job to be deleted 04/23/23 11:38:05.889
Apr 23 11:38:05.898: INFO: Event MODIFIED observed for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 23 11:38:05.898: INFO: Event MODIFIED observed for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 23 11:38:05.907: INFO: Event MODIFIED observed for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 23 11:38:05.908: INFO: Event MODIFIED observed for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 23 11:38:05.908: INFO: Event MODIFIED observed for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 23 11:38:05.908: INFO: Event DELETED found for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 04/23/23 11:38:05.908
[AfterEach] [sig-apps] Job
  test/e2e/framework/node/init/init.go:32
Apr 23 11:38:05.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Job
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Job
  tear down framework | framework.go:193
STEP: Destroying namespace "job-1580" for this suite. 04/23/23 11:38:05.949
------------------------------
â€¢ [SLOW TEST] [12.273 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:703

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:37:53.702
    Apr 23 11:37:53.702: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename job 04/23/23 11:37:53.711
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:37:53.746
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:37:53.754
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:31
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:703
    STEP: Creating a suspended job 04/23/23 11:37:53.763
    STEP: Patching the Job 04/23/23 11:37:53.771
    STEP: Watching for Job to be patched 04/23/23 11:37:53.808
    Apr 23 11:37:53.811: INFO: Event ADDED observed for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw] and annotations: map[batch.kubernetes.io/job-tracking:]
    Apr 23 11:37:53.811: INFO: Event MODIFIED found for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 04/23/23 11:37:53.811
    STEP: Watching for Job to be updated 04/23/23 11:37:53.841
    Apr 23 11:37:53.848: INFO: Event MODIFIED found for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 23 11:37:53.848: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 04/23/23 11:37:53.849
    Apr 23 11:37:53.858: INFO: Job: e2e-qtfcw as labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched]
    STEP: Waiting for job to complete 04/23/23 11:37:53.858
    STEP: Delete a job collection with a labelselector 04/23/23 11:38:05.869
    STEP: Watching for Job to be deleted 04/23/23 11:38:05.889
    Apr 23 11:38:05.898: INFO: Event MODIFIED observed for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 23 11:38:05.898: INFO: Event MODIFIED observed for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 23 11:38:05.907: INFO: Event MODIFIED observed for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 23 11:38:05.908: INFO: Event MODIFIED observed for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 23 11:38:05.908: INFO: Event MODIFIED observed for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 23 11:38:05.908: INFO: Event DELETED found for Job e2e-qtfcw in namespace job-1580 with labels: map[e2e-job-label:e2e-qtfcw e2e-qtfcw:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 04/23/23 11:38:05.908
    [AfterEach] [sig-apps] Job
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:38:05.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Job
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Job
      tear down framework | framework.go:193
    STEP: Destroying namespace "job-1580" for this suite. 04/23/23 11:38:05.949
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:38:05.977
Apr 23 11:38:05.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename tables 04/23/23 11:38:05.98
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:38:06.013
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:38:06.021
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/node/init/init.go:32
Apr 23 11:38:06.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Servers with support for Table transformation
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Servers with support for Table transformation
  tear down framework | framework.go:193
STEP: Destroying namespace "tables-2021" for this suite. 04/23/23 11:38:06.044
------------------------------
â€¢ [0.078 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:38:05.977
    Apr 23 11:38:05.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename tables 04/23/23 11:38:05.98
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:38:06.013
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:38:06.021
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:38:06.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Servers with support for Table transformation
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Servers with support for Table transformation
      tear down framework | framework.go:193
    STEP: Destroying namespace "tables-2021" for this suite. 04/23/23 11:38:06.044
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:624
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:38:06.058
Apr 23 11:38:06.058: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename sched-preemption 04/23/23 11:38:06.06
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:38:06.08
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:38:06.085
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:97
Apr 23 11:38:06.116: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 23 11:39:06.176: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:39:06.183
Apr 23 11:39:06.184: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename sched-preemption-path 04/23/23 11:39:06.188
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:39:06.213
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:39:06.216
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:576
STEP: Finding an available node 04/23/23 11:39:06.221
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/23/23 11:39:06.221
Apr 23 11:39:06.243: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-3316" to be "running"
Apr 23 11:39:06.254: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 10.71968ms
Apr 23 11:39:08.261: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.017581622s
Apr 23 11:39:08.261: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/23/23 11:39:08.269
Apr 23 11:39:08.291: INFO: found a healthy node: eingavuivie7-3
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:624
Apr 23 11:39:14.468: INFO: pods created so far: [1 1 1]
Apr 23 11:39:14.468: INFO: length of pods created so far: 3
Apr 23 11:39:16.490: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/node/init/init.go:32
Apr 23 11:39:23.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:549
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:39:23.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:84
[DeferCleanup (Each)] PreemptionExecutionPath
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] PreemptionExecutionPath
  dump namespaces | framework.go:196
[DeferCleanup (Each)] PreemptionExecutionPath
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-preemption-path-3316" for this suite. 04/23/23 11:39:23.674
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-preemption-7413" for this suite. 04/23/23 11:39:23.686
------------------------------
â€¢ [SLOW TEST] [77.639 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:537
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:624

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:38:06.058
    Apr 23 11:38:06.058: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename sched-preemption 04/23/23 11:38:06.06
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:38:06.08
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:38:06.085
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:97
    Apr 23 11:38:06.116: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 23 11:39:06.176: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:39:06.183
    Apr 23 11:39:06.184: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename sched-preemption-path 04/23/23 11:39:06.188
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:39:06.213
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:39:06.216
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:576
    STEP: Finding an available node 04/23/23 11:39:06.221
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/23/23 11:39:06.221
    Apr 23 11:39:06.243: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-3316" to be "running"
    Apr 23 11:39:06.254: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 10.71968ms
    Apr 23 11:39:08.261: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.017581622s
    Apr 23 11:39:08.261: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/23/23 11:39:08.269
    Apr 23 11:39:08.291: INFO: found a healthy node: eingavuivie7-3
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:624
    Apr 23 11:39:14.468: INFO: pods created so far: [1 1 1]
    Apr 23 11:39:14.468: INFO: length of pods created so far: 3
    Apr 23 11:39:16.490: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:39:23.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:549
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:39:23.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:84
    [DeferCleanup (Each)] PreemptionExecutionPath
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] PreemptionExecutionPath
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] PreemptionExecutionPath
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-preemption-path-3316" for this suite. 04/23/23 11:39:23.674
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-preemption-7413" for this suite. 04/23/23 11:39:23.686
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:193
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:39:23.698
Apr 23 11:39:23.698: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:39:23.702
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:39:23.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:39:23.748
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:193
STEP: Creating a pod to test downward API volume plugin 04/23/23 11:39:23.753
Apr 23 11:39:23.769: INFO: Waiting up to 5m0s for pod "downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3" in namespace "projected-8273" to be "Succeeded or Failed"
Apr 23 11:39:23.782: INFO: Pod "downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3": Phase="Pending", Reason="", readiness=false. Elapsed: 13.185692ms
Apr 23 11:39:25.789: INFO: Pod "downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020421194s
Apr 23 11:39:27.792: INFO: Pod "downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023400341s
STEP: Saw pod success 04/23/23 11:39:27.792
Apr 23 11:39:27.793: INFO: Pod "downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3" satisfied condition "Succeeded or Failed"
Apr 23 11:39:27.799: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3 container client-container: <nil>
STEP: delete the pod 04/23/23 11:39:27.826
Apr 23 11:39:27.856: INFO: Waiting for pod downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3 to disappear
Apr 23 11:39:27.865: INFO: Pod downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Apr 23 11:39:27.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-8273" for this suite. 04/23/23 11:39:27.875
------------------------------
â€¢ [4.188 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:39:23.698
    Apr 23 11:39:23.698: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:39:23.702
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:39:23.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:39:23.748
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:193
    STEP: Creating a pod to test downward API volume plugin 04/23/23 11:39:23.753
    Apr 23 11:39:23.769: INFO: Waiting up to 5m0s for pod "downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3" in namespace "projected-8273" to be "Succeeded or Failed"
    Apr 23 11:39:23.782: INFO: Pod "downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3": Phase="Pending", Reason="", readiness=false. Elapsed: 13.185692ms
    Apr 23 11:39:25.789: INFO: Pod "downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020421194s
    Apr 23 11:39:27.792: INFO: Pod "downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023400341s
    STEP: Saw pod success 04/23/23 11:39:27.792
    Apr 23 11:39:27.793: INFO: Pod "downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3" satisfied condition "Succeeded or Failed"
    Apr 23 11:39:27.799: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3 container client-container: <nil>
    STEP: delete the pod 04/23/23 11:39:27.826
    Apr 23 11:39:27.856: INFO: Waiting for pod downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3 to disappear
    Apr 23 11:39:27.865: INFO: Pod downwardapi-volume-53de6fdc-8120-484d-a546-93f9d80a83a3 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:39:27.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-8273" for this suite. 04/23/23 11:39:27.875
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:125
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:39:27.89
Apr 23 11:39:27.890: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename secrets 04/23/23 11:39:27.895
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:39:27.918
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:39:27.925
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:125
STEP: Creating secret with name secret-test-12f35654-04e4-4f1a-8d26-2bca71498b7f 04/23/23 11:39:27.932
STEP: Creating a pod to test consume secrets 04/23/23 11:39:27.939
Apr 23 11:39:27.958: INFO: Waiting up to 5m0s for pod "pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4" in namespace "secrets-7879" to be "Succeeded or Failed"
Apr 23 11:39:27.983: INFO: Pod "pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4": Phase="Pending", Reason="", readiness=false. Elapsed: 24.803893ms
Apr 23 11:39:29.998: INFO: Pod "pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040481094s
Apr 23 11:39:31.993: INFO: Pod "pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035186283s
STEP: Saw pod success 04/23/23 11:39:31.993
Apr 23 11:39:31.994: INFO: Pod "pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4" satisfied condition "Succeeded or Failed"
Apr 23 11:39:32.004: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4 container secret-volume-test: <nil>
STEP: delete the pod 04/23/23 11:39:32.026
Apr 23 11:39:32.058: INFO: Waiting for pod pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4 to disappear
Apr 23 11:39:32.070: INFO: Pod pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Apr 23 11:39:32.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-7879" for this suite. 04/23/23 11:39:32.079
------------------------------
â€¢ [4.202 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:39:27.89
    Apr 23 11:39:27.890: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename secrets 04/23/23 11:39:27.895
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:39:27.918
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:39:27.925
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:125
    STEP: Creating secret with name secret-test-12f35654-04e4-4f1a-8d26-2bca71498b7f 04/23/23 11:39:27.932
    STEP: Creating a pod to test consume secrets 04/23/23 11:39:27.939
    Apr 23 11:39:27.958: INFO: Waiting up to 5m0s for pod "pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4" in namespace "secrets-7879" to be "Succeeded or Failed"
    Apr 23 11:39:27.983: INFO: Pod "pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4": Phase="Pending", Reason="", readiness=false. Elapsed: 24.803893ms
    Apr 23 11:39:29.998: INFO: Pod "pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040481094s
    Apr 23 11:39:31.993: INFO: Pod "pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035186283s
    STEP: Saw pod success 04/23/23 11:39:31.993
    Apr 23 11:39:31.994: INFO: Pod "pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4" satisfied condition "Succeeded or Failed"
    Apr 23 11:39:32.004: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4 container secret-volume-test: <nil>
    STEP: delete the pod 04/23/23 11:39:32.026
    Apr 23 11:39:32.058: INFO: Waiting for pod pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4 to disappear
    Apr 23 11:39:32.070: INFO: Pod pod-secrets-8a179ff5-9db3-462e-9939-082ddef48ea4 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:39:32.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-7879" for this suite. 04/23/23 11:39:32.079
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:326
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:39:32.094
Apr 23 11:39:32.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename resourcequota 04/23/23 11:39:32.098
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:39:32.115
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:39:32.122
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:326
STEP: Counting existing ResourceQuota 04/23/23 11:39:49.134
STEP: Creating a ResourceQuota 04/23/23 11:39:54.144
STEP: Ensuring resource quota status is calculated 04/23/23 11:39:54.154
STEP: Creating a ConfigMap 04/23/23 11:39:56.164
STEP: Ensuring resource quota status captures configMap creation 04/23/23 11:39:56.182
STEP: Deleting a ConfigMap 04/23/23 11:39:58.191
STEP: Ensuring resource quota status released usage 04/23/23 11:39:58.204
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Apr 23 11:40:00.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-7342" for this suite. 04/23/23 11:40:00.22
------------------------------
â€¢ [SLOW TEST] [28.140 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:39:32.094
    Apr 23 11:39:32.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename resourcequota 04/23/23 11:39:32.098
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:39:32.115
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:39:32.122
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:326
    STEP: Counting existing ResourceQuota 04/23/23 11:39:49.134
    STEP: Creating a ResourceQuota 04/23/23 11:39:54.144
    STEP: Ensuring resource quota status is calculated 04/23/23 11:39:54.154
    STEP: Creating a ConfigMap 04/23/23 11:39:56.164
    STEP: Ensuring resource quota status captures configMap creation 04/23/23 11:39:56.182
    STEP: Deleting a ConfigMap 04/23/23 11:39:58.191
    STEP: Ensuring resource quota status released usage 04/23/23 11:39:58.204
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:40:00.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-7342" for this suite. 04/23/23 11:40:00.22
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply an update to a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:366
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:40:00.239
Apr 23 11:40:00.239: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename namespaces 04/23/23 11:40:00.242
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:40:00.268
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:40:00.282
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:31
[It] should apply an update to a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:366
STEP: Updating Namespace "namespaces-2992" 04/23/23 11:40:00.292
Apr 23 11:40:00.307: INFO: Namespace "namespaces-2992" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"1de117d5-5b32-4f50-b9f3-5af11d500051", "kubernetes.io/metadata.name":"namespaces-2992", "namespaces-2992":"updated", "pod-security.kubernetes.io/enforce":"baseline"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:40:00.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "namespaces-2992" for this suite. 04/23/23 11:40:00.316
------------------------------
â€¢ [0.090 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply an update to a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:366

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:40:00.239
    Apr 23 11:40:00.239: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename namespaces 04/23/23 11:40:00.242
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:40:00.268
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:40:00.282
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [It] should apply an update to a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:366
    STEP: Updating Namespace "namespaces-2992" 04/23/23 11:40:00.292
    Apr 23 11:40:00.307: INFO: Namespace "namespaces-2992" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"1de117d5-5b32-4f50-b9f3-5af11d500051", "kubernetes.io/metadata.name":"namespaces-2992", "namespaces-2992":"updated", "pod-security.kubernetes.io/enforce":"baseline"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:40:00.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "namespaces-2992" for this suite. 04/23/23 11:40:00.316
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:40:00.332
Apr 23 11:40:00.332: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename cronjob 04/23/23 11:40:00.335
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:40:00.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:40:00.361
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:31
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 04/23/23 11:40:00.367
STEP: Ensuring more than one job is running at a time 04/23/23 11:40:00.377
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 04/23/23 11:42:00.386
STEP: Removing cronjob 04/23/23 11:42:00.396
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/node/init/init.go:32
Apr 23 11:42:00.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] CronJob
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] CronJob
  tear down framework | framework.go:193
STEP: Destroying namespace "cronjob-4369" for this suite. 04/23/23 11:42:00.442
------------------------------
â€¢ [SLOW TEST] [120.149 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:40:00.332
    Apr 23 11:40:00.332: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename cronjob 04/23/23 11:40:00.335
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:40:00.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:40:00.361
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:31
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 04/23/23 11:40:00.367
    STEP: Ensuring more than one job is running at a time 04/23/23 11:40:00.377
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 04/23/23 11:42:00.386
    STEP: Removing cronjob 04/23/23 11:42:00.396
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:42:00.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] CronJob
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] CronJob
      tear down framework | framework.go:193
    STEP: Destroying namespace "cronjob-4369" for this suite. 04/23/23 11:42:00.442
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1083
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:42:00.511
Apr 23 11:42:00.511: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pods 04/23/23 11:42:00.519
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:42:00.574
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:42:00.599
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1083
STEP: Create a pod 04/23/23 11:42:00.608
Apr 23 11:42:00.631: INFO: Waiting up to 5m0s for pod "pod-2vzzl" in namespace "pods-1819" to be "running"
Apr 23 11:42:00.646: INFO: Pod "pod-2vzzl": Phase="Pending", Reason="", readiness=false. Elapsed: 15.378781ms
Apr 23 11:42:02.654: INFO: Pod "pod-2vzzl": Phase="Running", Reason="", readiness=true. Elapsed: 2.023489415s
Apr 23 11:42:02.655: INFO: Pod "pod-2vzzl" satisfied condition "running"
STEP: patching /status 04/23/23 11:42:02.655
Apr 23 11:42:02.667: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Apr 23 11:42:02.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-1819" for this suite. 04/23/23 11:42:02.677
------------------------------
â€¢ [2.182 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1083

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:42:00.511
    Apr 23 11:42:00.511: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pods 04/23/23 11:42:00.519
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:42:00.574
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:42:00.599
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1083
    STEP: Create a pod 04/23/23 11:42:00.608
    Apr 23 11:42:00.631: INFO: Waiting up to 5m0s for pod "pod-2vzzl" in namespace "pods-1819" to be "running"
    Apr 23 11:42:00.646: INFO: Pod "pod-2vzzl": Phase="Pending", Reason="", readiness=false. Elapsed: 15.378781ms
    Apr 23 11:42:02.654: INFO: Pod "pod-2vzzl": Phase="Running", Reason="", readiness=true. Elapsed: 2.023489415s
    Apr 23 11:42:02.655: INFO: Pod "pod-2vzzl" satisfied condition "running"
    STEP: patching /status 04/23/23 11:42:02.655
    Apr 23 11:42:02.667: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:42:02.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-1819" for this suite. 04/23/23 11:42:02.677
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:582
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:42:02.695
Apr 23 11:42:02.695: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 11:42:02.698
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:42:02.732
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:42:02.743
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 11:42:02.809
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 11:42:03.883
STEP: Deploying the webhook pod 04/23/23 11:42:03.899
STEP: Wait for the deployment to be ready 04/23/23 11:42:03.922
Apr 23 11:42:03.942: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/23/23 11:42:05.973
STEP: Verifying the service has paired with the endpoint 04/23/23 11:42:05.997
Apr 23 11:42:06.998: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:582
STEP: Listing all of the created validation webhooks 04/23/23 11:42:07.122
STEP: Creating a configMap that does not comply to the validation webhook rules 04/23/23 11:42:07.202
STEP: Deleting the collection of validation webhooks 04/23/23 11:42:07.254
STEP: Creating a configMap that does not comply to the validation webhook rules 04/23/23 11:42:07.378
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:42:07.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-788" for this suite. 04/23/23 11:42:07.553
STEP: Destroying namespace "webhook-788-markers" for this suite. 04/23/23 11:42:07.568
------------------------------
â€¢ [4.902 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:582

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:42:02.695
    Apr 23 11:42:02.695: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 11:42:02.698
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:42:02.732
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:42:02.743
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 11:42:02.809
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 11:42:03.883
    STEP: Deploying the webhook pod 04/23/23 11:42:03.899
    STEP: Wait for the deployment to be ready 04/23/23 11:42:03.922
    Apr 23 11:42:03.942: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/23/23 11:42:05.973
    STEP: Verifying the service has paired with the endpoint 04/23/23 11:42:05.997
    Apr 23 11:42:06.998: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:582
    STEP: Listing all of the created validation webhooks 04/23/23 11:42:07.122
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/23/23 11:42:07.202
    STEP: Deleting the collection of validation webhooks 04/23/23 11:42:07.254
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/23/23 11:42:07.378
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:42:07.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-788" for this suite. 04/23/23 11:42:07.553
    STEP: Destroying namespace "webhook-788-markers" for this suite. 04/23/23 11:42:07.568
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1747
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:42:07.623
Apr 23 11:42:07.623: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 11:42:07.625
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:42:07.653
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:42:07.658
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1734
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1747
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 04/23/23 11:42:07.663
Apr 23 11:42:07.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5069 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr 23 11:42:08.130: INFO: stderr: ""
Apr 23 11:42:08.130: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 04/23/23 11:42:08.13
STEP: verifying the pod e2e-test-httpd-pod was created 04/23/23 11:42:13.181
Apr 23 11:42:13.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5069 get pod e2e-test-httpd-pod -o json'
Apr 23 11:42:13.361: INFO: stderr: ""
Apr 23 11:42:13.361: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-04-23T11:42:08Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5069\",\n        \"resourceVersion\": \"17674\",\n        \"uid\": \"b28b701a-7619-4b90-9499-6164847b33f7\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-s428f\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"eingavuivie7-3\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-s428f\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-23T11:42:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-23T11:42:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-23T11:42:10Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-23T11:42:08Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://28564d4d978e57aa686b596d8258cb90d9b366fb273248125c0c595b6d3de324\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-04-23T11:42:09Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.121.198\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.64.221\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.64.221\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-04-23T11:42:08Z\"\n    }\n}\n"
STEP: replace the image in the pod 04/23/23 11:42:13.361
Apr 23 11:42:13.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5069 replace -f -'
Apr 23 11:42:14.290: INFO: stderr: ""
Apr 23 11:42:14.290: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-4 04/23/23 11:42:14.29
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1738
Apr 23 11:42:14.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5069 delete pods e2e-test-httpd-pod'
Apr 23 11:42:16.243: INFO: stderr: ""
Apr 23 11:42:16.243: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 11:42:16.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-5069" for this suite. 04/23/23 11:42:16.258
------------------------------
â€¢ [SLOW TEST] [8.648 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1731
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1747

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:42:07.623
    Apr 23 11:42:07.623: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 11:42:07.625
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:42:07.653
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:42:07.658
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1734
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1747
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 04/23/23 11:42:07.663
    Apr 23 11:42:07.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5069 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Apr 23 11:42:08.130: INFO: stderr: ""
    Apr 23 11:42:08.130: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 04/23/23 11:42:08.13
    STEP: verifying the pod e2e-test-httpd-pod was created 04/23/23 11:42:13.181
    Apr 23 11:42:13.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5069 get pod e2e-test-httpd-pod -o json'
    Apr 23 11:42:13.361: INFO: stderr: ""
    Apr 23 11:42:13.361: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-04-23T11:42:08Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5069\",\n        \"resourceVersion\": \"17674\",\n        \"uid\": \"b28b701a-7619-4b90-9499-6164847b33f7\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-s428f\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"eingavuivie7-3\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-s428f\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-23T11:42:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-23T11:42:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-23T11:42:10Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-23T11:42:08Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://28564d4d978e57aa686b596d8258cb90d9b366fb273248125c0c595b6d3de324\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-04-23T11:42:09Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.121.198\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.64.221\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.64.221\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-04-23T11:42:08Z\"\n    }\n}\n"
    STEP: replace the image in the pod 04/23/23 11:42:13.361
    Apr 23 11:42:13.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5069 replace -f -'
    Apr 23 11:42:14.290: INFO: stderr: ""
    Apr 23 11:42:14.290: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-4 04/23/23 11:42:14.29
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1738
    Apr 23 11:42:14.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5069 delete pods e2e-test-httpd-pod'
    Apr 23 11:42:16.243: INFO: stderr: ""
    Apr 23 11:42:16.243: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:42:16.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-5069" for this suite. 04/23/23 11:42:16.258
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:704
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:42:16.281
Apr 23 11:42:16.282: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename sched-pred 04/23/23 11:42:16.287
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:42:16.32
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:42:16.332
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:97
Apr 23 11:42:16.343: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 23 11:42:16.366: INFO: Waiting for terminating namespaces to be deleted...
Apr 23 11:42:16.376: INFO: 
Logging pods the apiserver thinks is on node eingavuivie7-1 before test
Apr 23 11:42:16.396: INFO: cilium-node-init-j475c from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.396: INFO: 	Container node-init ready: true, restart count 0
Apr 23 11:42:16.396: INFO: cilium-tcvk2 from kube-system started at 2023-04-23 10:44:39 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.396: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 23 11:42:16.396: INFO: kube-addon-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.396: INFO: 	Container kube-addon-manager ready: true, restart count 0
Apr 23 11:42:16.396: INFO: kube-apiserver-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.396: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 23 11:42:16.396: INFO: kube-controller-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.396: INFO: 	Container kube-controller-manager ready: true, restart count 0
Apr 23 11:42:16.396: INFO: kube-proxy-qx9mz from kube-system started at 2023-04-23 10:40:00 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.396: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 11:42:16.396: INFO: kube-scheduler-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:29 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.396: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 23 11:42:16.396: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-tdgvz from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 11:42:16.396: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 11:42:16.396: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 23 11:42:16.396: INFO: 
Logging pods the apiserver thinks is on node eingavuivie7-2 before test
Apr 23 11:42:16.421: INFO: cilium-cw5l6 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.421: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 23 11:42:16.421: INFO: cilium-node-init-tpqk9 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.422: INFO: 	Container node-init ready: true, restart count 0
Apr 23 11:42:16.422: INFO: coredns-787d4945fb-v7bjj from kube-system started at 2023-04-23 10:46:03 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.422: INFO: 	Container coredns ready: true, restart count 0
Apr 23 11:42:16.422: INFO: kube-addon-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.423: INFO: 	Container kube-addon-manager ready: true, restart count 0
Apr 23 11:42:16.423: INFO: kube-apiserver-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.423: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 23 11:42:16.424: INFO: kube-controller-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.424: INFO: 	Container kube-controller-manager ready: true, restart count 0
Apr 23 11:42:16.424: INFO: kube-proxy-hzwld from kube-system started at 2023-04-23 10:40:58 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.425: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 11:42:16.425: INFO: kube-scheduler-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.425: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 23 11:42:16.425: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-ntx29 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 11:42:16.425: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 11:42:16.426: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 23 11:42:16.426: INFO: 
Logging pods the apiserver thinks is on node eingavuivie7-3 before test
Apr 23 11:42:16.448: INFO: concurrent-28037501-rq9f2 from cronjob-4369 started at 2023-04-23 11:41:00 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.449: INFO: 	Container c ready: true, restart count 0
Apr 23 11:42:16.449: INFO: concurrent-28037502-hnbvw from cronjob-4369 started at 2023-04-23 11:42:00 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.449: INFO: 	Container c ready: true, restart count 0
Apr 23 11:42:16.449: INFO: cilium-node-init-btj27 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.449: INFO: 	Container node-init ready: true, restart count 0
Apr 23 11:42:16.449: INFO: cilium-operator-968f66564-jmvk7 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.450: INFO: 	Container cilium-operator ready: true, restart count 0
Apr 23 11:42:16.450: INFO: cilium-vpc26 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.450: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 23 11:42:16.450: INFO: coredns-787d4945fb-8tms9 from kube-system started at 2023-04-23 10:45:47 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.450: INFO: 	Container coredns ready: true, restart count 0
Apr 23 11:42:16.450: INFO: kube-proxy-lsxv6 from kube-system started at 2023-04-23 10:41:59 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.451: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 11:42:16.451: INFO: sonobuoy from sonobuoy started at 2023-04-23 11:11:26 +0000 UTC (1 container statuses recorded)
Apr 23 11:42:16.451: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 23 11:42:16.451: INFO: sonobuoy-e2e-job-27be2b9757534547 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 11:42:16.451: INFO: 	Container e2e ready: true, restart count 0
Apr 23 11:42:16.451: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 11:42:16.452: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-k7sgm from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 11:42:16.452: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 11:42:16.452: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:704
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/23/23 11:42:16.453
Apr 23 11:42:16.481: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-2767" to be "running"
Apr 23 11:42:16.504: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 23.491766ms
Apr 23 11:42:18.511: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.029945037s
Apr 23 11:42:18.511: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/23/23 11:42:18.517
STEP: Trying to apply a random label on the found node. 04/23/23 11:42:18.579
STEP: verifying the node has the label kubernetes.io/e2e-ae6e689b-115c-49de-871e-6dcf94e0bbfd 95 04/23/23 11:42:18.615
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 04/23/23 11:42:18.629
Apr 23 11:42:18.649: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-2767" to be "not pending"
Apr 23 11:42:18.680: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 31.13828ms
Apr 23 11:42:20.691: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.042227958s
Apr 23 11:42:20.691: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.121.198 on the node which pod4 resides and expect not scheduled 04/23/23 11:42:20.691
Apr 23 11:42:20.699: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-2767" to be "not pending"
Apr 23 11:42:20.705: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.993551ms
Apr 23 11:42:22.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013450186s
Apr 23 11:42:24.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014746254s
Apr 23 11:42:26.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016220411s
Apr 23 11:42:28.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.020187168s
Apr 23 11:42:30.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.018702494s
Apr 23 11:42:32.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.013475658s
Apr 23 11:42:34.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.019424807s
Apr 23 11:42:36.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.020007788s
Apr 23 11:42:38.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.018874498s
Apr 23 11:42:40.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.018228835s
Apr 23 11:42:42.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.016295591s
Apr 23 11:42:44.728: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.028340982s
Apr 23 11:42:46.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.014686162s
Apr 23 11:42:48.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.013556771s
Apr 23 11:42:50.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.013417059s
Apr 23 11:42:52.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.014712114s
Apr 23 11:42:54.712: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.012495557s
Apr 23 11:42:56.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.013315875s
Apr 23 11:42:58.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.015469832s
Apr 23 11:43:00.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.014573437s
Apr 23 11:43:02.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.015109478s
Apr 23 11:43:04.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.017288198s
Apr 23 11:43:06.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.014583239s
Apr 23 11:43:08.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.016503057s
Apr 23 11:43:10.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.01352647s
Apr 23 11:43:12.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.020214862s
Apr 23 11:43:14.711: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.011908655s
Apr 23 11:43:16.723: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.023952683s
Apr 23 11:43:18.711: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.011769883s
Apr 23 11:43:20.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.013509759s
Apr 23 11:43:22.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.01559431s
Apr 23 11:43:24.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.018239849s
Apr 23 11:43:26.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.014123774s
Apr 23 11:43:28.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.01721685s
Apr 23 11:43:30.752: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.052938186s
Apr 23 11:43:32.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.015368309s
Apr 23 11:43:34.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.015711411s
Apr 23 11:43:36.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.01936611s
Apr 23 11:43:38.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.014645443s
Apr 23 11:43:40.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.018151156s
Apr 23 11:43:42.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.016970969s
Apr 23 11:43:44.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.017269468s
Apr 23 11:43:46.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.015330558s
Apr 23 11:43:48.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.014039343s
Apr 23 11:43:50.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.017533123s
Apr 23 11:43:52.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.020297866s
Apr 23 11:43:54.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.017262109s
Apr 23 11:43:56.712: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.012641113s
Apr 23 11:43:58.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.014352342s
Apr 23 11:44:00.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.015737196s
Apr 23 11:44:02.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.018841303s
Apr 23 11:44:04.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.01470099s
Apr 23 11:44:06.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.01435077s
Apr 23 11:44:08.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.015183583s
Apr 23 11:44:10.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.013005426s
Apr 23 11:44:12.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.01493653s
Apr 23 11:44:14.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.01722633s
Apr 23 11:44:16.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.013225019s
Apr 23 11:44:18.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.014472019s
Apr 23 11:44:20.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.014050257s
Apr 23 11:44:22.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.014536255s
Apr 23 11:44:24.712: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.012447818s
Apr 23 11:44:26.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.014457607s
Apr 23 11:44:28.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.013675104s
Apr 23 11:44:30.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.014506156s
Apr 23 11:44:32.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.013157882s
Apr 23 11:44:34.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.01812347s
Apr 23 11:44:36.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.019460416s
Apr 23 11:44:38.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.016330222s
Apr 23 11:44:40.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.020956714s
Apr 23 11:44:42.725: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.025320757s
Apr 23 11:44:44.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.013515888s
Apr 23 11:44:46.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.016766515s
Apr 23 11:44:48.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.019967087s
Apr 23 11:44:50.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.016950091s
Apr 23 11:44:52.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.019057989s
Apr 23 11:44:54.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.015341292s
Apr 23 11:44:56.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.015104362s
Apr 23 11:44:58.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.017775059s
Apr 23 11:45:00.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.017600367s
Apr 23 11:45:02.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.016731986s
Apr 23 11:45:04.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.015449253s
Apr 23 11:45:06.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.016203622s
Apr 23 11:45:08.721: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.021144227s
Apr 23 11:45:10.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.015313624s
Apr 23 11:45:12.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.016944411s
Apr 23 11:45:14.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.014920935s
Apr 23 11:45:16.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.016314533s
Apr 23 11:45:18.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.017898303s
Apr 23 11:45:20.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.020918478s
Apr 23 11:45:22.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.013329298s
Apr 23 11:45:24.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.015115234s
Apr 23 11:45:26.712: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.012483368s
Apr 23 11:45:28.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.016728688s
Apr 23 11:45:30.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.014736919s
Apr 23 11:45:32.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.016276835s
Apr 23 11:45:34.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.013298858s
Apr 23 11:45:36.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.013319826s
Apr 23 11:45:38.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.015988438s
Apr 23 11:45:40.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.013391094s
Apr 23 11:45:42.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.015203729s
Apr 23 11:45:44.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.014683419s
Apr 23 11:45:46.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.018077743s
Apr 23 11:45:48.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.01310866s
Apr 23 11:45:50.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.013008315s
Apr 23 11:45:52.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.016497841s
Apr 23 11:45:54.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.018998363s
Apr 23 11:45:56.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.019168257s
Apr 23 11:45:58.723: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.023625328s
Apr 23 11:46:00.721: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.021391888s
Apr 23 11:46:02.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.01970715s
Apr 23 11:46:04.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.018894792s
Apr 23 11:46:06.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.018614908s
Apr 23 11:46:08.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.013782805s
Apr 23 11:46:10.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.013120176s
Apr 23 11:46:12.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.0143466s
Apr 23 11:46:14.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.016889874s
Apr 23 11:46:16.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.015258683s
Apr 23 11:46:18.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.015424233s
Apr 23 11:46:20.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.014301433s
Apr 23 11:46:22.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.014368561s
Apr 23 11:46:24.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.01433969s
Apr 23 11:46:26.712: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.012325581s
Apr 23 11:46:28.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.015603031s
Apr 23 11:46:30.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.017272174s
Apr 23 11:46:32.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.016529563s
Apr 23 11:46:34.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.016473929s
Apr 23 11:46:36.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.014484193s
Apr 23 11:46:38.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.013069617s
Apr 23 11:46:40.722: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.02241443s
Apr 23 11:46:42.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.015130539s
Apr 23 11:46:44.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.017348059s
Apr 23 11:46:46.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.01507853s
Apr 23 11:46:48.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.014519014s
Apr 23 11:46:50.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.016577302s
Apr 23 11:46:52.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.016631047s
Apr 23 11:46:54.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.014922757s
Apr 23 11:46:56.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.020885166s
Apr 23 11:46:58.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.016270857s
Apr 23 11:47:00.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.013470186s
Apr 23 11:47:02.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.019358608s
Apr 23 11:47:04.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.018262255s
Apr 23 11:47:06.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.014705217s
Apr 23 11:47:08.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.013422019s
Apr 23 11:47:10.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.0144411s
Apr 23 11:47:12.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.015116278s
Apr 23 11:47:14.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.016172107s
Apr 23 11:47:16.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.014426778s
Apr 23 11:47:18.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.015867148s
Apr 23 11:47:20.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.013746683s
Apr 23 11:47:20.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.020163554s
STEP: removing the label kubernetes.io/e2e-ae6e689b-115c-49de-871e-6dcf94e0bbfd off the node eingavuivie7-3 04/23/23 11:47:20.72
STEP: verifying the node doesn't have the label kubernetes.io/e2e-ae6e689b-115c-49de-871e-6dcf94e0bbfd 04/23/23 11:47:20.748
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:47:20.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:88
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-pred-2767" for this suite. 04/23/23 11:47:20.789
------------------------------
â€¢ [SLOW TEST] [304.528 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:704

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:42:16.281
    Apr 23 11:42:16.282: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename sched-pred 04/23/23 11:42:16.287
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:42:16.32
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:42:16.332
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:97
    Apr 23 11:42:16.343: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 23 11:42:16.366: INFO: Waiting for terminating namespaces to be deleted...
    Apr 23 11:42:16.376: INFO: 
    Logging pods the apiserver thinks is on node eingavuivie7-1 before test
    Apr 23 11:42:16.396: INFO: cilium-node-init-j475c from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.396: INFO: 	Container node-init ready: true, restart count 0
    Apr 23 11:42:16.396: INFO: cilium-tcvk2 from kube-system started at 2023-04-23 10:44:39 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.396: INFO: 	Container cilium-agent ready: true, restart count 0
    Apr 23 11:42:16.396: INFO: kube-addon-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.396: INFO: 	Container kube-addon-manager ready: true, restart count 0
    Apr 23 11:42:16.396: INFO: kube-apiserver-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.396: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 23 11:42:16.396: INFO: kube-controller-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.396: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Apr 23 11:42:16.396: INFO: kube-proxy-qx9mz from kube-system started at 2023-04-23 10:40:00 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.396: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 23 11:42:16.396: INFO: kube-scheduler-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:29 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.396: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 23 11:42:16.396: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-tdgvz from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 11:42:16.396: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 11:42:16.396: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 23 11:42:16.396: INFO: 
    Logging pods the apiserver thinks is on node eingavuivie7-2 before test
    Apr 23 11:42:16.421: INFO: cilium-cw5l6 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.421: INFO: 	Container cilium-agent ready: true, restart count 0
    Apr 23 11:42:16.421: INFO: cilium-node-init-tpqk9 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.422: INFO: 	Container node-init ready: true, restart count 0
    Apr 23 11:42:16.422: INFO: coredns-787d4945fb-v7bjj from kube-system started at 2023-04-23 10:46:03 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.422: INFO: 	Container coredns ready: true, restart count 0
    Apr 23 11:42:16.422: INFO: kube-addon-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.423: INFO: 	Container kube-addon-manager ready: true, restart count 0
    Apr 23 11:42:16.423: INFO: kube-apiserver-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.423: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 23 11:42:16.424: INFO: kube-controller-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.424: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Apr 23 11:42:16.424: INFO: kube-proxy-hzwld from kube-system started at 2023-04-23 10:40:58 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.425: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 23 11:42:16.425: INFO: kube-scheduler-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.425: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 23 11:42:16.425: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-ntx29 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 11:42:16.425: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 11:42:16.426: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 23 11:42:16.426: INFO: 
    Logging pods the apiserver thinks is on node eingavuivie7-3 before test
    Apr 23 11:42:16.448: INFO: concurrent-28037501-rq9f2 from cronjob-4369 started at 2023-04-23 11:41:00 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.449: INFO: 	Container c ready: true, restart count 0
    Apr 23 11:42:16.449: INFO: concurrent-28037502-hnbvw from cronjob-4369 started at 2023-04-23 11:42:00 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.449: INFO: 	Container c ready: true, restart count 0
    Apr 23 11:42:16.449: INFO: cilium-node-init-btj27 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.449: INFO: 	Container node-init ready: true, restart count 0
    Apr 23 11:42:16.449: INFO: cilium-operator-968f66564-jmvk7 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.450: INFO: 	Container cilium-operator ready: true, restart count 0
    Apr 23 11:42:16.450: INFO: cilium-vpc26 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.450: INFO: 	Container cilium-agent ready: true, restart count 0
    Apr 23 11:42:16.450: INFO: coredns-787d4945fb-8tms9 from kube-system started at 2023-04-23 10:45:47 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.450: INFO: 	Container coredns ready: true, restart count 0
    Apr 23 11:42:16.450: INFO: kube-proxy-lsxv6 from kube-system started at 2023-04-23 10:41:59 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.451: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 23 11:42:16.451: INFO: sonobuoy from sonobuoy started at 2023-04-23 11:11:26 +0000 UTC (1 container statuses recorded)
    Apr 23 11:42:16.451: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 23 11:42:16.451: INFO: sonobuoy-e2e-job-27be2b9757534547 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 11:42:16.451: INFO: 	Container e2e ready: true, restart count 0
    Apr 23 11:42:16.451: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 11:42:16.452: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-k7sgm from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 11:42:16.452: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 11:42:16.452: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:704
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/23/23 11:42:16.453
    Apr 23 11:42:16.481: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-2767" to be "running"
    Apr 23 11:42:16.504: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 23.491766ms
    Apr 23 11:42:18.511: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.029945037s
    Apr 23 11:42:18.511: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/23/23 11:42:18.517
    STEP: Trying to apply a random label on the found node. 04/23/23 11:42:18.579
    STEP: verifying the node has the label kubernetes.io/e2e-ae6e689b-115c-49de-871e-6dcf94e0bbfd 95 04/23/23 11:42:18.615
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 04/23/23 11:42:18.629
    Apr 23 11:42:18.649: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-2767" to be "not pending"
    Apr 23 11:42:18.680: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 31.13828ms
    Apr 23 11:42:20.691: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.042227958s
    Apr 23 11:42:20.691: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.121.198 on the node which pod4 resides and expect not scheduled 04/23/23 11:42:20.691
    Apr 23 11:42:20.699: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-2767" to be "not pending"
    Apr 23 11:42:20.705: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.993551ms
    Apr 23 11:42:22.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013450186s
    Apr 23 11:42:24.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014746254s
    Apr 23 11:42:26.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016220411s
    Apr 23 11:42:28.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.020187168s
    Apr 23 11:42:30.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.018702494s
    Apr 23 11:42:32.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.013475658s
    Apr 23 11:42:34.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.019424807s
    Apr 23 11:42:36.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.020007788s
    Apr 23 11:42:38.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.018874498s
    Apr 23 11:42:40.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.018228835s
    Apr 23 11:42:42.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.016295591s
    Apr 23 11:42:44.728: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.028340982s
    Apr 23 11:42:46.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.014686162s
    Apr 23 11:42:48.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.013556771s
    Apr 23 11:42:50.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.013417059s
    Apr 23 11:42:52.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.014712114s
    Apr 23 11:42:54.712: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.012495557s
    Apr 23 11:42:56.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.013315875s
    Apr 23 11:42:58.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.015469832s
    Apr 23 11:43:00.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.014573437s
    Apr 23 11:43:02.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.015109478s
    Apr 23 11:43:04.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.017288198s
    Apr 23 11:43:06.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.014583239s
    Apr 23 11:43:08.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.016503057s
    Apr 23 11:43:10.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.01352647s
    Apr 23 11:43:12.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.020214862s
    Apr 23 11:43:14.711: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.011908655s
    Apr 23 11:43:16.723: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.023952683s
    Apr 23 11:43:18.711: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.011769883s
    Apr 23 11:43:20.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.013509759s
    Apr 23 11:43:22.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.01559431s
    Apr 23 11:43:24.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.018239849s
    Apr 23 11:43:26.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.014123774s
    Apr 23 11:43:28.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.01721685s
    Apr 23 11:43:30.752: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.052938186s
    Apr 23 11:43:32.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.015368309s
    Apr 23 11:43:34.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.015711411s
    Apr 23 11:43:36.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.01936611s
    Apr 23 11:43:38.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.014645443s
    Apr 23 11:43:40.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.018151156s
    Apr 23 11:43:42.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.016970969s
    Apr 23 11:43:44.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.017269468s
    Apr 23 11:43:46.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.015330558s
    Apr 23 11:43:48.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.014039343s
    Apr 23 11:43:50.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.017533123s
    Apr 23 11:43:52.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.020297866s
    Apr 23 11:43:54.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.017262109s
    Apr 23 11:43:56.712: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.012641113s
    Apr 23 11:43:58.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.014352342s
    Apr 23 11:44:00.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.015737196s
    Apr 23 11:44:02.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.018841303s
    Apr 23 11:44:04.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.01470099s
    Apr 23 11:44:06.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.01435077s
    Apr 23 11:44:08.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.015183583s
    Apr 23 11:44:10.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.013005426s
    Apr 23 11:44:12.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.01493653s
    Apr 23 11:44:14.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.01722633s
    Apr 23 11:44:16.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.013225019s
    Apr 23 11:44:18.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.014472019s
    Apr 23 11:44:20.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.014050257s
    Apr 23 11:44:22.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.014536255s
    Apr 23 11:44:24.712: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.012447818s
    Apr 23 11:44:26.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.014457607s
    Apr 23 11:44:28.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.013675104s
    Apr 23 11:44:30.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.014506156s
    Apr 23 11:44:32.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.013157882s
    Apr 23 11:44:34.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.01812347s
    Apr 23 11:44:36.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.019460416s
    Apr 23 11:44:38.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.016330222s
    Apr 23 11:44:40.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.020956714s
    Apr 23 11:44:42.725: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.025320757s
    Apr 23 11:44:44.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.013515888s
    Apr 23 11:44:46.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.016766515s
    Apr 23 11:44:48.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.019967087s
    Apr 23 11:44:50.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.016950091s
    Apr 23 11:44:52.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.019057989s
    Apr 23 11:44:54.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.015341292s
    Apr 23 11:44:56.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.015104362s
    Apr 23 11:44:58.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.017775059s
    Apr 23 11:45:00.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.017600367s
    Apr 23 11:45:02.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.016731986s
    Apr 23 11:45:04.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.015449253s
    Apr 23 11:45:06.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.016203622s
    Apr 23 11:45:08.721: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.021144227s
    Apr 23 11:45:10.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.015313624s
    Apr 23 11:45:12.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.016944411s
    Apr 23 11:45:14.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.014920935s
    Apr 23 11:45:16.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.016314533s
    Apr 23 11:45:18.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.017898303s
    Apr 23 11:45:20.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.020918478s
    Apr 23 11:45:22.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.013329298s
    Apr 23 11:45:24.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.015115234s
    Apr 23 11:45:26.712: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.012483368s
    Apr 23 11:45:28.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.016728688s
    Apr 23 11:45:30.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.014736919s
    Apr 23 11:45:32.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.016276835s
    Apr 23 11:45:34.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.013298858s
    Apr 23 11:45:36.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.013319826s
    Apr 23 11:45:38.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.015988438s
    Apr 23 11:45:40.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.013391094s
    Apr 23 11:45:42.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.015203729s
    Apr 23 11:45:44.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.014683419s
    Apr 23 11:45:46.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.018077743s
    Apr 23 11:45:48.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.01310866s
    Apr 23 11:45:50.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.013008315s
    Apr 23 11:45:52.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.016497841s
    Apr 23 11:45:54.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.018998363s
    Apr 23 11:45:56.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.019168257s
    Apr 23 11:45:58.723: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.023625328s
    Apr 23 11:46:00.721: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.021391888s
    Apr 23 11:46:02.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.01970715s
    Apr 23 11:46:04.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.018894792s
    Apr 23 11:46:06.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.018614908s
    Apr 23 11:46:08.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.013782805s
    Apr 23 11:46:10.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.013120176s
    Apr 23 11:46:12.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.0143466s
    Apr 23 11:46:14.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.016889874s
    Apr 23 11:46:16.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.015258683s
    Apr 23 11:46:18.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.015424233s
    Apr 23 11:46:20.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.014301433s
    Apr 23 11:46:22.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.014368561s
    Apr 23 11:46:24.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.01433969s
    Apr 23 11:46:26.712: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.012325581s
    Apr 23 11:46:28.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.015603031s
    Apr 23 11:46:30.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.017272174s
    Apr 23 11:46:32.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.016529563s
    Apr 23 11:46:34.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.016473929s
    Apr 23 11:46:36.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.014484193s
    Apr 23 11:46:38.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.013069617s
    Apr 23 11:46:40.722: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.02241443s
    Apr 23 11:46:42.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.015130539s
    Apr 23 11:46:44.717: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.017348059s
    Apr 23 11:46:46.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.01507853s
    Apr 23 11:46:48.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.014519014s
    Apr 23 11:46:50.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.016577302s
    Apr 23 11:46:52.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.016631047s
    Apr 23 11:46:54.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.014922757s
    Apr 23 11:46:56.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.020885166s
    Apr 23 11:46:58.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.016270857s
    Apr 23 11:47:00.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.013470186s
    Apr 23 11:47:02.719: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.019358608s
    Apr 23 11:47:04.718: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.018262255s
    Apr 23 11:47:06.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.014705217s
    Apr 23 11:47:08.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.013422019s
    Apr 23 11:47:10.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.0144411s
    Apr 23 11:47:12.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.015116278s
    Apr 23 11:47:14.716: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.016172107s
    Apr 23 11:47:16.714: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.014426778s
    Apr 23 11:47:18.715: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.015867148s
    Apr 23 11:47:20.713: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.013746683s
    Apr 23 11:47:20.720: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.020163554s
    STEP: removing the label kubernetes.io/e2e-ae6e689b-115c-49de-871e-6dcf94e0bbfd off the node eingavuivie7-3 04/23/23 11:47:20.72
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-ae6e689b-115c-49de-871e-6dcf94e0bbfd 04/23/23 11:47:20.748
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:47:20.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:88
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-pred-2767" for this suite. 04/23/23 11:47:20.789
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:47:20.815
Apr 23 11:47:20.816: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename runtimeclass 04/23/23 11:47:20.825
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:47:20.869
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:47:20.876
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:31
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 04/23/23 11:47:20.887
STEP: getting /apis/node.k8s.io 04/23/23 11:47:20.899
STEP: getting /apis/node.k8s.io/v1 04/23/23 11:47:20.903
STEP: creating 04/23/23 11:47:20.907
STEP: watching 04/23/23 11:47:20.956
Apr 23 11:47:20.956: INFO: starting watch
STEP: getting 04/23/23 11:47:20.973
STEP: listing 04/23/23 11:47:20.984
STEP: patching 04/23/23 11:47:20.992
STEP: updating 04/23/23 11:47:21.007
Apr 23 11:47:21.022: INFO: waiting for watch events with expected annotations
STEP: deleting 04/23/23 11:47:21.022
STEP: deleting a collection 04/23/23 11:47:21.047
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/node/init/init.go:32
Apr 23 11:47:21.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] RuntimeClass
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] RuntimeClass
  tear down framework | framework.go:193
STEP: Destroying namespace "runtimeclass-3325" for this suite. 04/23/23 11:47:21.091
------------------------------
â€¢ [0.296 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:47:20.815
    Apr 23 11:47:20.816: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename runtimeclass 04/23/23 11:47:20.825
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:47:20.869
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:47:20.876
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:31
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 04/23/23 11:47:20.887
    STEP: getting /apis/node.k8s.io 04/23/23 11:47:20.899
    STEP: getting /apis/node.k8s.io/v1 04/23/23 11:47:20.903
    STEP: creating 04/23/23 11:47:20.907
    STEP: watching 04/23/23 11:47:20.956
    Apr 23 11:47:20.956: INFO: starting watch
    STEP: getting 04/23/23 11:47:20.973
    STEP: listing 04/23/23 11:47:20.984
    STEP: patching 04/23/23 11:47:20.992
    STEP: updating 04/23/23 11:47:21.007
    Apr 23 11:47:21.022: INFO: waiting for watch events with expected annotations
    STEP: deleting 04/23/23 11:47:21.022
    STEP: deleting a collection 04/23/23 11:47:21.047
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:47:21.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      tear down framework | framework.go:193
    STEP: Destroying namespace "runtimeclass-3325" for this suite. 04/23/23 11:47:21.091
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3654
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:47:21.114
Apr 23 11:47:21.114: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 11:47:21.116
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:47:21.14
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:47:21.145
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3654
STEP: creating a collection of services 04/23/23 11:47:21.151
Apr 23 11:47:21.151: INFO: Creating e2e-svc-a-4h477
Apr 23 11:47:21.171: INFO: Creating e2e-svc-b-px9bc
Apr 23 11:47:21.191: INFO: Creating e2e-svc-c-82xq5
STEP: deleting service collection 04/23/23 11:47:21.224
Apr 23 11:47:21.307: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 11:47:21.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-3803" for this suite. 04/23/23 11:47:21.324
------------------------------
â€¢ [0.227 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3654

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:47:21.114
    Apr 23 11:47:21.114: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 11:47:21.116
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:47:21.14
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:47:21.145
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3654
    STEP: creating a collection of services 04/23/23 11:47:21.151
    Apr 23 11:47:21.151: INFO: Creating e2e-svc-a-4h477
    Apr 23 11:47:21.171: INFO: Creating e2e-svc-b-px9bc
    Apr 23 11:47:21.191: INFO: Creating e2e-svc-c-82xq5
    STEP: deleting service collection 04/23/23 11:47:21.224
    Apr 23 11:47:21.307: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:47:21.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-3803" for this suite. 04/23/23 11:47:21.324
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:53
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:47:21.363
Apr 23 11:47:21.365: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:47:21.369
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:47:21.405
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:47:21.411
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:53
STEP: Creating a pod to test downward API volume plugin 04/23/23 11:47:21.417
Apr 23 11:47:21.441: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2" in namespace "projected-7412" to be "Succeeded or Failed"
Apr 23 11:47:21.452: INFO: Pod "downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.021288ms
Apr 23 11:47:23.461: INFO: Pod "downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020282339s
Apr 23 11:47:25.461: INFO: Pod "downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019547653s
Apr 23 11:47:27.466: INFO: Pod "downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02527833s
STEP: Saw pod success 04/23/23 11:47:27.466
Apr 23 11:47:27.467: INFO: Pod "downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2" satisfied condition "Succeeded or Failed"
Apr 23 11:47:27.546: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2 container client-container: <nil>
STEP: delete the pod 04/23/23 11:47:27.614
Apr 23 11:47:27.636: INFO: Waiting for pod downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2 to disappear
Apr 23 11:47:27.642: INFO: Pod downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Apr 23 11:47:27.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-7412" for this suite. 04/23/23 11:47:27.649
------------------------------
â€¢ [SLOW TEST] [6.299 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:47:21.363
    Apr 23 11:47:21.365: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:47:21.369
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:47:21.405
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:47:21.411
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:53
    STEP: Creating a pod to test downward API volume plugin 04/23/23 11:47:21.417
    Apr 23 11:47:21.441: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2" in namespace "projected-7412" to be "Succeeded or Failed"
    Apr 23 11:47:21.452: INFO: Pod "downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.021288ms
    Apr 23 11:47:23.461: INFO: Pod "downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020282339s
    Apr 23 11:47:25.461: INFO: Pod "downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019547653s
    Apr 23 11:47:27.466: INFO: Pod "downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02527833s
    STEP: Saw pod success 04/23/23 11:47:27.466
    Apr 23 11:47:27.467: INFO: Pod "downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2" satisfied condition "Succeeded or Failed"
    Apr 23 11:47:27.546: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2 container client-container: <nil>
    STEP: delete the pod 04/23/23 11:47:27.614
    Apr 23 11:47:27.636: INFO: Waiting for pod downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2 to disappear
    Apr 23 11:47:27.642: INFO: Pod downwardapi-volume-cfebf85b-ac2c-49d9-9c39-9871554626c2 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:47:27.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-7412" for this suite. 04/23/23 11:47:27.649
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:339
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:47:27.666
Apr 23 11:47:27.666: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 11:47:27.683
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:47:27.713
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:47:27.722
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:326
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:339
STEP: creating a replication controller 04/23/23 11:47:27.729
Apr 23 11:47:27.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 create -f -'
Apr 23 11:47:28.481: INFO: stderr: ""
Apr 23 11:47:28.481: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/23/23 11:47:28.481
Apr 23 11:47:28.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 23 11:47:28.658: INFO: stderr: ""
Apr 23 11:47:28.658: INFO: stdout: "update-demo-nautilus-p5dm2 update-demo-nautilus-tbfxv "
Apr 23 11:47:28.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods update-demo-nautilus-p5dm2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 23 11:47:28.794: INFO: stderr: ""
Apr 23 11:47:28.794: INFO: stdout: ""
Apr 23 11:47:28.794: INFO: update-demo-nautilus-p5dm2 is created but not running
Apr 23 11:47:33.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 23 11:47:34.043: INFO: stderr: ""
Apr 23 11:47:34.045: INFO: stdout: "update-demo-nautilus-p5dm2 update-demo-nautilus-tbfxv "
Apr 23 11:47:34.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods update-demo-nautilus-p5dm2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 23 11:47:34.255: INFO: stderr: ""
Apr 23 11:47:34.256: INFO: stdout: ""
Apr 23 11:47:34.256: INFO: update-demo-nautilus-p5dm2 is created but not running
Apr 23 11:47:39.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 23 11:47:39.427: INFO: stderr: ""
Apr 23 11:47:39.428: INFO: stdout: "update-demo-nautilus-p5dm2 update-demo-nautilus-tbfxv "
Apr 23 11:47:39.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods update-demo-nautilus-p5dm2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 23 11:47:39.621: INFO: stderr: ""
Apr 23 11:47:39.621: INFO: stdout: ""
Apr 23 11:47:39.621: INFO: update-demo-nautilus-p5dm2 is created but not running
Apr 23 11:47:44.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 23 11:47:44.766: INFO: stderr: ""
Apr 23 11:47:44.766: INFO: stdout: "update-demo-nautilus-p5dm2 update-demo-nautilus-tbfxv "
Apr 23 11:47:44.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods update-demo-nautilus-p5dm2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 23 11:47:44.898: INFO: stderr: ""
Apr 23 11:47:44.898: INFO: stdout: "true"
Apr 23 11:47:44.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods update-demo-nautilus-p5dm2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 23 11:47:45.039: INFO: stderr: ""
Apr 23 11:47:45.039: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Apr 23 11:47:45.039: INFO: validating pod update-demo-nautilus-p5dm2
Apr 23 11:47:45.062: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 11:47:45.063: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 11:47:45.063: INFO: update-demo-nautilus-p5dm2 is verified up and running
Apr 23 11:47:45.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods update-demo-nautilus-tbfxv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 23 11:47:45.219: INFO: stderr: ""
Apr 23 11:47:45.219: INFO: stdout: "true"
Apr 23 11:47:45.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods update-demo-nautilus-tbfxv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 23 11:47:45.387: INFO: stderr: ""
Apr 23 11:47:45.387: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Apr 23 11:47:45.387: INFO: validating pod update-demo-nautilus-tbfxv
Apr 23 11:47:45.407: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 11:47:45.407: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 11:47:45.407: INFO: update-demo-nautilus-tbfxv is verified up and running
STEP: using delete to clean up resources 04/23/23 11:47:45.407
Apr 23 11:47:45.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 delete --grace-period=0 --force -f -'
Apr 23 11:47:45.602: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 11:47:45.602: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 23 11:47:45.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get rc,svc -l name=update-demo --no-headers'
Apr 23 11:47:45.907: INFO: stderr: "No resources found in kubectl-8230 namespace.\n"
Apr 23 11:47:45.907: INFO: stdout: ""
Apr 23 11:47:45.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 23 11:47:46.287: INFO: stderr: ""
Apr 23 11:47:46.287: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 11:47:46.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-8230" for this suite. 04/23/23 11:47:46.298
------------------------------
â€¢ [SLOW TEST] [18.647 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:324
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:339

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:47:27.666
    Apr 23 11:47:27.666: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 11:47:27.683
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:47:27.713
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:47:27.722
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:326
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:339
    STEP: creating a replication controller 04/23/23 11:47:27.729
    Apr 23 11:47:27.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 create -f -'
    Apr 23 11:47:28.481: INFO: stderr: ""
    Apr 23 11:47:28.481: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/23/23 11:47:28.481
    Apr 23 11:47:28.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 23 11:47:28.658: INFO: stderr: ""
    Apr 23 11:47:28.658: INFO: stdout: "update-demo-nautilus-p5dm2 update-demo-nautilus-tbfxv "
    Apr 23 11:47:28.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods update-demo-nautilus-p5dm2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 23 11:47:28.794: INFO: stderr: ""
    Apr 23 11:47:28.794: INFO: stdout: ""
    Apr 23 11:47:28.794: INFO: update-demo-nautilus-p5dm2 is created but not running
    Apr 23 11:47:33.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 23 11:47:34.043: INFO: stderr: ""
    Apr 23 11:47:34.045: INFO: stdout: "update-demo-nautilus-p5dm2 update-demo-nautilus-tbfxv "
    Apr 23 11:47:34.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods update-demo-nautilus-p5dm2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 23 11:47:34.255: INFO: stderr: ""
    Apr 23 11:47:34.256: INFO: stdout: ""
    Apr 23 11:47:34.256: INFO: update-demo-nautilus-p5dm2 is created but not running
    Apr 23 11:47:39.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 23 11:47:39.427: INFO: stderr: ""
    Apr 23 11:47:39.428: INFO: stdout: "update-demo-nautilus-p5dm2 update-demo-nautilus-tbfxv "
    Apr 23 11:47:39.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods update-demo-nautilus-p5dm2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 23 11:47:39.621: INFO: stderr: ""
    Apr 23 11:47:39.621: INFO: stdout: ""
    Apr 23 11:47:39.621: INFO: update-demo-nautilus-p5dm2 is created but not running
    Apr 23 11:47:44.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 23 11:47:44.766: INFO: stderr: ""
    Apr 23 11:47:44.766: INFO: stdout: "update-demo-nautilus-p5dm2 update-demo-nautilus-tbfxv "
    Apr 23 11:47:44.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods update-demo-nautilus-p5dm2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 23 11:47:44.898: INFO: stderr: ""
    Apr 23 11:47:44.898: INFO: stdout: "true"
    Apr 23 11:47:44.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods update-demo-nautilus-p5dm2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 23 11:47:45.039: INFO: stderr: ""
    Apr 23 11:47:45.039: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Apr 23 11:47:45.039: INFO: validating pod update-demo-nautilus-p5dm2
    Apr 23 11:47:45.062: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 23 11:47:45.063: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 23 11:47:45.063: INFO: update-demo-nautilus-p5dm2 is verified up and running
    Apr 23 11:47:45.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods update-demo-nautilus-tbfxv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 23 11:47:45.219: INFO: stderr: ""
    Apr 23 11:47:45.219: INFO: stdout: "true"
    Apr 23 11:47:45.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods update-demo-nautilus-tbfxv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 23 11:47:45.387: INFO: stderr: ""
    Apr 23 11:47:45.387: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Apr 23 11:47:45.387: INFO: validating pod update-demo-nautilus-tbfxv
    Apr 23 11:47:45.407: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 23 11:47:45.407: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 23 11:47:45.407: INFO: update-demo-nautilus-tbfxv is verified up and running
    STEP: using delete to clean up resources 04/23/23 11:47:45.407
    Apr 23 11:47:45.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 delete --grace-period=0 --force -f -'
    Apr 23 11:47:45.602: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 23 11:47:45.602: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Apr 23 11:47:45.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get rc,svc -l name=update-demo --no-headers'
    Apr 23 11:47:45.907: INFO: stderr: "No resources found in kubectl-8230 namespace.\n"
    Apr 23 11:47:45.907: INFO: stdout: ""
    Apr 23 11:47:45.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8230 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 23 11:47:46.287: INFO: stderr: ""
    Apr 23 11:47:46.287: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:47:46.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-8230" for this suite. 04/23/23 11:47:46.298
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:138
[BeforeEach] [sig-node] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:47:46.316
Apr 23 11:47:46.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 11:47:46.323
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:47:46.38
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:47:46.389
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:138
STEP: Creating configMap that has name configmap-test-emptyKey-f5e44837-d64e-483e-983f-5d63eb7c6f39 04/23/23 11:47:46.409
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 11:47:46.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-7118" for this suite. 04/23/23 11:47:46.42
------------------------------
â€¢ [0.116 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:138

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:47:46.316
    Apr 23 11:47:46.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 11:47:46.323
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:47:46.38
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:47:46.389
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:138
    STEP: Creating configMap that has name configmap-test-emptyKey-f5e44837-d64e-483e-983f-5d63eb7c6f39 04/23/23 11:47:46.409
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:47:46.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-7118" for this suite. 04/23/23 11:47:46.42
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:432
[BeforeEach] [sig-apps] Daemon set [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:47:46.435
Apr 23 11:47:46.435: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename daemonsets 04/23/23 11:47:46.439
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:47:46.47
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:47:46.494
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:146
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:432
Apr 23 11:47:46.645: INFO: Create a RollingUpdate DaemonSet
Apr 23 11:47:46.656: INFO: Check that daemon pods launch on every node of the cluster
Apr 23 11:47:46.673: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:47:46.673: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 11:47:47.695: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:47:47.695: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 11:47:48.691: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 11:47:48.691: INFO: Node eingavuivie7-3 is running 0 daemon pod, expected 1
Apr 23 11:47:49.690: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 23 11:47:49.690: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Apr 23 11:47:49.690: INFO: Update the DaemonSet to trigger a rollout
Apr 23 11:47:49.714: INFO: Updating DaemonSet daemon-set
Apr 23 11:47:51.803: INFO: Roll back the DaemonSet before rollout is complete
Apr 23 11:47:51.834: INFO: Updating DaemonSet daemon-set
Apr 23 11:47:51.834: INFO: Make sure DaemonSet rollback is complete
Apr 23 11:47:51.859: INFO: Wrong image for pod: daemon-set-mnnzm. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
Apr 23 11:47:51.859: INFO: Pod daemon-set-mnnzm is not available
Apr 23 11:47:59.880: INFO: Pod daemon-set-hzkw6 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:111
STEP: Deleting DaemonSet "daemon-set" 04/23/23 11:47:59.914
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8158, will wait for the garbage collector to delete the pods 04/23/23 11:47:59.914
Apr 23 11:47:59.995: INFO: Deleting DaemonSet.extensions daemon-set took: 23.469017ms
Apr 23 11:48:00.095: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.583784ms
Apr 23 11:48:02.626: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:48:02.626: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 23 11:48:02.637: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18806"},"items":null}

Apr 23 11:48:02.643: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18806"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:48:02.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "daemonsets-8158" for this suite. 04/23/23 11:48:02.707
------------------------------
â€¢ [SLOW TEST] [16.291 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:432

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:47:46.435
    Apr 23 11:47:46.435: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename daemonsets 04/23/23 11:47:46.439
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:47:46.47
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:47:46.494
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:146
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:432
    Apr 23 11:47:46.645: INFO: Create a RollingUpdate DaemonSet
    Apr 23 11:47:46.656: INFO: Check that daemon pods launch on every node of the cluster
    Apr 23 11:47:46.673: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:47:46.673: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 11:47:47.695: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:47:47.695: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 11:47:48.691: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 11:47:48.691: INFO: Node eingavuivie7-3 is running 0 daemon pod, expected 1
    Apr 23 11:47:49.690: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 23 11:47:49.690: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Apr 23 11:47:49.690: INFO: Update the DaemonSet to trigger a rollout
    Apr 23 11:47:49.714: INFO: Updating DaemonSet daemon-set
    Apr 23 11:47:51.803: INFO: Roll back the DaemonSet before rollout is complete
    Apr 23 11:47:51.834: INFO: Updating DaemonSet daemon-set
    Apr 23 11:47:51.834: INFO: Make sure DaemonSet rollback is complete
    Apr 23 11:47:51.859: INFO: Wrong image for pod: daemon-set-mnnzm. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
    Apr 23 11:47:51.859: INFO: Pod daemon-set-mnnzm is not available
    Apr 23 11:47:59.880: INFO: Pod daemon-set-hzkw6 is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:111
    STEP: Deleting DaemonSet "daemon-set" 04/23/23 11:47:59.914
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8158, will wait for the garbage collector to delete the pods 04/23/23 11:47:59.914
    Apr 23 11:47:59.995: INFO: Deleting DaemonSet.extensions daemon-set took: 23.469017ms
    Apr 23 11:48:00.095: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.583784ms
    Apr 23 11:48:02.626: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:48:02.626: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 23 11:48:02.637: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18806"},"items":null}

    Apr 23 11:48:02.643: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18806"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:48:02.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "daemonsets-8158" for this suite. 04/23/23 11:48:02.707
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:249
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:48:02.729
Apr 23 11:48:02.729: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 11:48:02.732
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:02.759
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:02.768
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:249
STEP: Creating a pod to test downward API volume plugin 04/23/23 11:48:02.774
Apr 23 11:48:02.798: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775" in namespace "downward-api-1385" to be "Succeeded or Failed"
Apr 23 11:48:02.809: INFO: Pod "downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775": Phase="Pending", Reason="", readiness=false. Elapsed: 11.051115ms
Apr 23 11:48:04.822: INFO: Pod "downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775": Phase="Running", Reason="", readiness=true. Elapsed: 2.02409259s
Apr 23 11:48:06.819: INFO: Pod "downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775": Phase="Running", Reason="", readiness=false. Elapsed: 4.02143858s
Apr 23 11:48:08.822: INFO: Pod "downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023818936s
STEP: Saw pod success 04/23/23 11:48:08.822
Apr 23 11:48:08.822: INFO: Pod "downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775" satisfied condition "Succeeded or Failed"
Apr 23 11:48:08.830: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775 container client-container: <nil>
STEP: delete the pod 04/23/23 11:48:08.848
Apr 23 11:48:08.892: INFO: Waiting for pod downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775 to disappear
Apr 23 11:48:08.910: INFO: Pod downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Apr 23 11:48:08.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-1385" for this suite. 04/23/23 11:48:08.926
------------------------------
â€¢ [SLOW TEST] [6.218 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:249

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:48:02.729
    Apr 23 11:48:02.729: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 11:48:02.732
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:02.759
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:02.768
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:249
    STEP: Creating a pod to test downward API volume plugin 04/23/23 11:48:02.774
    Apr 23 11:48:02.798: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775" in namespace "downward-api-1385" to be "Succeeded or Failed"
    Apr 23 11:48:02.809: INFO: Pod "downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775": Phase="Pending", Reason="", readiness=false. Elapsed: 11.051115ms
    Apr 23 11:48:04.822: INFO: Pod "downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775": Phase="Running", Reason="", readiness=true. Elapsed: 2.02409259s
    Apr 23 11:48:06.819: INFO: Pod "downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775": Phase="Running", Reason="", readiness=false. Elapsed: 4.02143858s
    Apr 23 11:48:08.822: INFO: Pod "downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023818936s
    STEP: Saw pod success 04/23/23 11:48:08.822
    Apr 23 11:48:08.822: INFO: Pod "downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775" satisfied condition "Succeeded or Failed"
    Apr 23 11:48:08.830: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775 container client-container: <nil>
    STEP: delete the pod 04/23/23 11:48:08.848
    Apr 23 11:48:08.892: INFO: Waiting for pod downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775 to disappear
    Apr 23 11:48:08.910: INFO: Pod downwardapi-volume-c11a5a81-a540-446a-8f29-677187be1775 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:48:08.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-1385" for this suite. 04/23/23 11:48:08.926
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:230
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:48:08.95
Apr 23 11:48:08.950: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename resourcequota 04/23/23 11:48:08.953
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:08.999
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:09.003
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:230
STEP: Counting existing ResourceQuota 04/23/23 11:48:09.008
STEP: Creating a ResourceQuota 04/23/23 11:48:14.016
STEP: Ensuring resource quota status is calculated 04/23/23 11:48:14.03
STEP: Creating a Pod that fits quota 04/23/23 11:48:16.04
STEP: Ensuring ResourceQuota status captures the pod usage 04/23/23 11:48:16.074
STEP: Not allowing a pod to be created that exceeds remaining quota 04/23/23 11:48:18.088
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 04/23/23 11:48:18.096
STEP: Ensuring a pod cannot update its resource requirements 04/23/23 11:48:18.102
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 04/23/23 11:48:18.114
STEP: Deleting the pod 04/23/23 11:48:20.129
STEP: Ensuring resource quota status released the pod usage 04/23/23 11:48:20.159
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Apr 23 11:48:22.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-4397" for this suite. 04/23/23 11:48:22.179
------------------------------
â€¢ [SLOW TEST] [13.244 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:230

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:48:08.95
    Apr 23 11:48:08.950: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename resourcequota 04/23/23 11:48:08.953
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:08.999
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:09.003
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:230
    STEP: Counting existing ResourceQuota 04/23/23 11:48:09.008
    STEP: Creating a ResourceQuota 04/23/23 11:48:14.016
    STEP: Ensuring resource quota status is calculated 04/23/23 11:48:14.03
    STEP: Creating a Pod that fits quota 04/23/23 11:48:16.04
    STEP: Ensuring ResourceQuota status captures the pod usage 04/23/23 11:48:16.074
    STEP: Not allowing a pod to be created that exceeds remaining quota 04/23/23 11:48:18.088
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 04/23/23 11:48:18.096
    STEP: Ensuring a pod cannot update its resource requirements 04/23/23 11:48:18.102
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 04/23/23 11:48:18.114
    STEP: Deleting the pod 04/23/23 11:48:20.129
    STEP: Ensuring resource quota status released the pod usage 04/23/23 11:48:20.159
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:48:22.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-4397" for this suite. 04/23/23 11:48:22.179
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:109
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:48:22.201
Apr 23 11:48:22.202: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 11:48:22.204
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:22.239
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:22.246
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:109
STEP: Creating configMap with name configmap-test-volume-map-f2e89622-0263-4d84-ad1c-c94df5dd9b15 04/23/23 11:48:22.254
STEP: Creating a pod to test consume configMaps 04/23/23 11:48:22.262
Apr 23 11:48:22.279: INFO: Waiting up to 5m0s for pod "pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25" in namespace "configmap-8094" to be "Succeeded or Failed"
Apr 23 11:48:22.289: INFO: Pod "pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25": Phase="Pending", Reason="", readiness=false. Elapsed: 10.530946ms
Apr 23 11:48:24.313: INFO: Pod "pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034254796s
Apr 23 11:48:26.299: INFO: Pod "pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019915947s
STEP: Saw pod success 04/23/23 11:48:26.299
Apr 23 11:48:26.299: INFO: Pod "pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25" satisfied condition "Succeeded or Failed"
Apr 23 11:48:26.306: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25 container agnhost-container: <nil>
STEP: delete the pod 04/23/23 11:48:26.316
Apr 23 11:48:26.338: INFO: Waiting for pod pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25 to disappear
Apr 23 11:48:26.347: INFO: Pod pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 11:48:26.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-8094" for this suite. 04/23/23 11:48:26.357
------------------------------
â€¢ [4.171 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:48:22.201
    Apr 23 11:48:22.202: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 11:48:22.204
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:22.239
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:22.246
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:109
    STEP: Creating configMap with name configmap-test-volume-map-f2e89622-0263-4d84-ad1c-c94df5dd9b15 04/23/23 11:48:22.254
    STEP: Creating a pod to test consume configMaps 04/23/23 11:48:22.262
    Apr 23 11:48:22.279: INFO: Waiting up to 5m0s for pod "pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25" in namespace "configmap-8094" to be "Succeeded or Failed"
    Apr 23 11:48:22.289: INFO: Pod "pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25": Phase="Pending", Reason="", readiness=false. Elapsed: 10.530946ms
    Apr 23 11:48:24.313: INFO: Pod "pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034254796s
    Apr 23 11:48:26.299: INFO: Pod "pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019915947s
    STEP: Saw pod success 04/23/23 11:48:26.299
    Apr 23 11:48:26.299: INFO: Pod "pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25" satisfied condition "Succeeded or Failed"
    Apr 23 11:48:26.306: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25 container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 11:48:26.316
    Apr 23 11:48:26.338: INFO: Waiting for pod pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25 to disappear
    Apr 23 11:48:26.347: INFO: Pod pod-configmaps-21056ebe-32b0-47e7-92c5-520402477e25 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:48:26.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-8094" for this suite. 04/23/23 11:48:26.357
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3244
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:48:26.386
Apr 23 11:48:26.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 11:48:26.389
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:26.471
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:26.489
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3244
STEP: creating an Endpoint 04/23/23 11:48:26.505
STEP: waiting for available Endpoint 04/23/23 11:48:26.524
STEP: listing all Endpoints 04/23/23 11:48:26.531
STEP: updating the Endpoint 04/23/23 11:48:26.569
STEP: fetching the Endpoint 04/23/23 11:48:26.588
STEP: patching the Endpoint 04/23/23 11:48:26.595
STEP: fetching the Endpoint 04/23/23 11:48:26.611
STEP: deleting the Endpoint by Collection 04/23/23 11:48:26.615
STEP: waiting for Endpoint deletion 04/23/23 11:48:26.628
STEP: fetching the Endpoint 04/23/23 11:48:26.632
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 11:48:26.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-6096" for this suite. 04/23/23 11:48:26.646
------------------------------
â€¢ [0.273 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3244

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:48:26.386
    Apr 23 11:48:26.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 11:48:26.389
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:26.471
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:26.489
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3244
    STEP: creating an Endpoint 04/23/23 11:48:26.505
    STEP: waiting for available Endpoint 04/23/23 11:48:26.524
    STEP: listing all Endpoints 04/23/23 11:48:26.531
    STEP: updating the Endpoint 04/23/23 11:48:26.569
    STEP: fetching the Endpoint 04/23/23 11:48:26.588
    STEP: patching the Endpoint 04/23/23 11:48:26.595
    STEP: fetching the Endpoint 04/23/23 11:48:26.611
    STEP: deleting the Endpoint by Collection 04/23/23 11:48:26.615
    STEP: waiting for Endpoint deletion 04/23/23 11:48:26.628
    STEP: fetching the Endpoint 04/23/23 11:48:26.632
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:48:26.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-6096" for this suite. 04/23/23 11:48:26.646
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:249
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:48:26.663
Apr 23 11:48:26.663: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:48:26.666
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:26.698
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:26.701
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:249
STEP: Creating a pod to test downward API volume plugin 04/23/23 11:48:26.705
Apr 23 11:48:26.720: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b" in namespace "projected-7910" to be "Succeeded or Failed"
Apr 23 11:48:26.731: INFO: Pod "downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.854893ms
Apr 23 11:48:28.740: INFO: Pod "downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b": Phase="Running", Reason="", readiness=true. Elapsed: 2.020470941s
Apr 23 11:48:30.739: INFO: Pod "downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b": Phase="Running", Reason="", readiness=false. Elapsed: 4.018883497s
Apr 23 11:48:32.739: INFO: Pod "downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019614175s
STEP: Saw pod success 04/23/23 11:48:32.74
Apr 23 11:48:32.740: INFO: Pod "downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b" satisfied condition "Succeeded or Failed"
Apr 23 11:48:32.745: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b container client-container: <nil>
STEP: delete the pod 04/23/23 11:48:32.758
Apr 23 11:48:32.778: INFO: Waiting for pod downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b to disappear
Apr 23 11:48:32.788: INFO: Pod downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Apr 23 11:48:32.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-7910" for this suite. 04/23/23 11:48:32.799
------------------------------
â€¢ [SLOW TEST] [6.157 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:249

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:48:26.663
    Apr 23 11:48:26.663: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:48:26.666
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:26.698
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:26.701
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:249
    STEP: Creating a pod to test downward API volume plugin 04/23/23 11:48:26.705
    Apr 23 11:48:26.720: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b" in namespace "projected-7910" to be "Succeeded or Failed"
    Apr 23 11:48:26.731: INFO: Pod "downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.854893ms
    Apr 23 11:48:28.740: INFO: Pod "downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b": Phase="Running", Reason="", readiness=true. Elapsed: 2.020470941s
    Apr 23 11:48:30.739: INFO: Pod "downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b": Phase="Running", Reason="", readiness=false. Elapsed: 4.018883497s
    Apr 23 11:48:32.739: INFO: Pod "downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019614175s
    STEP: Saw pod success 04/23/23 11:48:32.74
    Apr 23 11:48:32.740: INFO: Pod "downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b" satisfied condition "Succeeded or Failed"
    Apr 23 11:48:32.745: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b container client-container: <nil>
    STEP: delete the pod 04/23/23 11:48:32.758
    Apr 23 11:48:32.778: INFO: Waiting for pod downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b to disappear
    Apr 23 11:48:32.788: INFO: Pod downwardapi-volume-c3a56709-6c73-4ef1-b62b-a8bb75965d8b no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:48:32.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-7910" for this suite. 04/23/23 11:48:32.799
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:127
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:48:32.826
Apr 23 11:48:32.826: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 11:48:32.829
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:32.872
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:32.877
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:127
STEP: Creating a pod to test emptydir 0644 on tmpfs 04/23/23 11:48:32.882
Apr 23 11:48:32.909: INFO: Waiting up to 5m0s for pod "pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4" in namespace "emptydir-5804" to be "Succeeded or Failed"
Apr 23 11:48:32.919: INFO: Pod "pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.596128ms
Apr 23 11:48:34.931: INFO: Pod "pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4": Phase="Running", Reason="", readiness=true. Elapsed: 2.02193905s
Apr 23 11:48:36.928: INFO: Pod "pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4": Phase="Running", Reason="", readiness=false. Elapsed: 4.018777684s
Apr 23 11:48:38.926: INFO: Pod "pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017261744s
STEP: Saw pod success 04/23/23 11:48:38.926
Apr 23 11:48:38.927: INFO: Pod "pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4" satisfied condition "Succeeded or Failed"
Apr 23 11:48:38.932: INFO: Trying to get logs from node eingavuivie7-3 pod pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4 container test-container: <nil>
STEP: delete the pod 04/23/23 11:48:38.945
Apr 23 11:48:38.964: INFO: Waiting for pod pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4 to disappear
Apr 23 11:48:38.978: INFO: Pod pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 11:48:38.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-5804" for this suite. 04/23/23 11:48:38.992
------------------------------
â€¢ [SLOW TEST] [6.177 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:127

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:48:32.826
    Apr 23 11:48:32.826: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 11:48:32.829
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:32.872
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:32.877
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:127
    STEP: Creating a pod to test emptydir 0644 on tmpfs 04/23/23 11:48:32.882
    Apr 23 11:48:32.909: INFO: Waiting up to 5m0s for pod "pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4" in namespace "emptydir-5804" to be "Succeeded or Failed"
    Apr 23 11:48:32.919: INFO: Pod "pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.596128ms
    Apr 23 11:48:34.931: INFO: Pod "pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4": Phase="Running", Reason="", readiness=true. Elapsed: 2.02193905s
    Apr 23 11:48:36.928: INFO: Pod "pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4": Phase="Running", Reason="", readiness=false. Elapsed: 4.018777684s
    Apr 23 11:48:38.926: INFO: Pod "pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017261744s
    STEP: Saw pod success 04/23/23 11:48:38.926
    Apr 23 11:48:38.927: INFO: Pod "pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4" satisfied condition "Succeeded or Failed"
    Apr 23 11:48:38.932: INFO: Trying to get logs from node eingavuivie7-3 pod pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4 container test-container: <nil>
    STEP: delete the pod 04/23/23 11:48:38.945
    Apr 23 11:48:38.964: INFO: Waiting for pod pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4 to disappear
    Apr 23 11:48:38.978: INFO: Pod pod-26a5aaad-7bc0-4537-b0be-1a29f1bfe7b4 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:48:38.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-5804" for this suite. 04/23/23 11:48:38.992
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1685
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:48:39.019
Apr 23 11:48:39.019: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 11:48:39.021
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:39.051
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:39.056
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1685
Apr 23 11:48:39.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-3608 version'
Apr 23 11:48:39.182: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Apr 23 11:48:39.182: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"26\", GitVersion:\"v1.26.4\", GitCommit:\"f89670c3aa4059d6999cb42e23ccb4f0b9a03979\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:13:53Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"26\", GitVersion:\"v1.26.4\", GitCommit:\"f89670c3aa4059d6999cb42e23ccb4f0b9a03979\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:05:35Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 11:48:39.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-3608" for this suite. 04/23/23 11:48:39.192
------------------------------
â€¢ [0.183 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1679
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1685

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:48:39.019
    Apr 23 11:48:39.019: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 11:48:39.021
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:39.051
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:39.056
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1685
    Apr 23 11:48:39.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-3608 version'
    Apr 23 11:48:39.182: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Apr 23 11:48:39.182: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"26\", GitVersion:\"v1.26.4\", GitCommit:\"f89670c3aa4059d6999cb42e23ccb4f0b9a03979\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:13:53Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"26\", GitVersion:\"v1.26.4\", GitCommit:\"f89670c3aa4059d6999cb42e23ccb4f0b9a03979\", GitTreeState:\"clean\", BuildDate:\"2023-04-12T12:05:35Z\", GoVersion:\"go1.19.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:48:39.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-3608" for this suite. 04/23/23 11:48:39.192
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2213
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:48:39.211
Apr 23 11:48:39.212: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 11:48:39.214
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:39.237
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:39.241
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2213
STEP: creating service in namespace services-9240 04/23/23 11:48:39.247
STEP: creating service affinity-clusterip-transition in namespace services-9240 04/23/23 11:48:39.247
STEP: creating replication controller affinity-clusterip-transition in namespace services-9240 04/23/23 11:48:39.263
I0423 11:48:39.289528      13 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-9240, replica count: 3
I0423 11:48:42.340969      13 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:48:45.341885      13 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 23 11:48:45.362: INFO: Creating new exec pod
Apr 23 11:48:45.375: INFO: Waiting up to 5m0s for pod "execpod-affinityccsqb" in namespace "services-9240" to be "running"
Apr 23 11:48:45.383: INFO: Pod "execpod-affinityccsqb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.46708ms
Apr 23 11:48:47.397: INFO: Pod "execpod-affinityccsqb": Phase="Running", Reason="", readiness=true. Elapsed: 2.021835694s
Apr 23 11:48:47.398: INFO: Pod "execpod-affinityccsqb" satisfied condition "running"
Apr 23 11:48:48.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9240 exec execpod-affinityccsqb -- /bin/sh -x -c nc -v -z -w 2 affinity-clusterip-transition 80'
Apr 23 11:48:48.755: INFO: stderr: "+ nc -v -z -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Apr 23 11:48:48.755: INFO: stdout: ""
Apr 23 11:48:48.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9240 exec execpod-affinityccsqb -- /bin/sh -x -c nc -v -z -w 2 10.233.36.34 80'
Apr 23 11:48:49.008: INFO: stderr: "+ nc -v -z -w 2 10.233.36.34 80\nConnection to 10.233.36.34 80 port [tcp/http] succeeded!\n"
Apr 23 11:48:49.008: INFO: stdout: ""
Apr 23 11:48:49.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9240 exec execpod-affinityccsqb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.36.34:80/ ; done'
Apr 23 11:48:49.560: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n"
Apr 23 11:48:49.560: INFO: stdout: "\naffinity-clusterip-transition-rmmdq\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-s9szk\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-rmmdq\naffinity-clusterip-transition-s9szk\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-s9szk\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-rmmdq\naffinity-clusterip-transition-rmmdq\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-rmmdq\naffinity-clusterip-transition-s9szk\naffinity-clusterip-transition-s9szk"
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-rmmdq
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-s9szk
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-rmmdq
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-s9szk
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-s9szk
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-rmmdq
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-rmmdq
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-rmmdq
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-s9szk
Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-s9szk
Apr 23 11:48:49.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9240 exec execpod-affinityccsqb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.36.34:80/ ; done'
Apr 23 11:48:50.382: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n"
Apr 23 11:48:50.382: INFO: stdout: "\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q"
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
Apr 23 11:48:50.382: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-9240, will wait for the garbage collector to delete the pods 04/23/23 11:48:50.404
Apr 23 11:48:50.479: INFO: Deleting ReplicationController affinity-clusterip-transition took: 12.261592ms
Apr 23 11:48:50.683: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 203.585382ms
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 11:48:53.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-9240" for this suite. 04/23/23 11:48:53.138
------------------------------
â€¢ [SLOW TEST] [13.946 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2213

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:48:39.211
    Apr 23 11:48:39.212: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 11:48:39.214
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:39.237
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:39.241
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2213
    STEP: creating service in namespace services-9240 04/23/23 11:48:39.247
    STEP: creating service affinity-clusterip-transition in namespace services-9240 04/23/23 11:48:39.247
    STEP: creating replication controller affinity-clusterip-transition in namespace services-9240 04/23/23 11:48:39.263
    I0423 11:48:39.289528      13 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-9240, replica count: 3
    I0423 11:48:42.340969      13 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:48:45.341885      13 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 23 11:48:45.362: INFO: Creating new exec pod
    Apr 23 11:48:45.375: INFO: Waiting up to 5m0s for pod "execpod-affinityccsqb" in namespace "services-9240" to be "running"
    Apr 23 11:48:45.383: INFO: Pod "execpod-affinityccsqb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.46708ms
    Apr 23 11:48:47.397: INFO: Pod "execpod-affinityccsqb": Phase="Running", Reason="", readiness=true. Elapsed: 2.021835694s
    Apr 23 11:48:47.398: INFO: Pod "execpod-affinityccsqb" satisfied condition "running"
    Apr 23 11:48:48.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9240 exec execpod-affinityccsqb -- /bin/sh -x -c nc -v -z -w 2 affinity-clusterip-transition 80'
    Apr 23 11:48:48.755: INFO: stderr: "+ nc -v -z -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Apr 23 11:48:48.755: INFO: stdout: ""
    Apr 23 11:48:48.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9240 exec execpod-affinityccsqb -- /bin/sh -x -c nc -v -z -w 2 10.233.36.34 80'
    Apr 23 11:48:49.008: INFO: stderr: "+ nc -v -z -w 2 10.233.36.34 80\nConnection to 10.233.36.34 80 port [tcp/http] succeeded!\n"
    Apr 23 11:48:49.008: INFO: stdout: ""
    Apr 23 11:48:49.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9240 exec execpod-affinityccsqb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.36.34:80/ ; done'
    Apr 23 11:48:49.560: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n"
    Apr 23 11:48:49.560: INFO: stdout: "\naffinity-clusterip-transition-rmmdq\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-s9szk\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-rmmdq\naffinity-clusterip-transition-s9szk\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-s9szk\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-rmmdq\naffinity-clusterip-transition-rmmdq\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-rmmdq\naffinity-clusterip-transition-s9szk\naffinity-clusterip-transition-s9szk"
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-rmmdq
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-s9szk
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-rmmdq
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-s9szk
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-s9szk
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-rmmdq
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-rmmdq
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-rmmdq
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-s9szk
    Apr 23 11:48:49.560: INFO: Received response from host: affinity-clusterip-transition-s9szk
    Apr 23 11:48:49.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9240 exec execpod-affinityccsqb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.36.34:80/ ; done'
    Apr 23 11:48:50.382: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.36.34:80/\n"
    Apr 23 11:48:50.382: INFO: stdout: "\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q\naffinity-clusterip-transition-lrh4q"
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Received response from host: affinity-clusterip-transition-lrh4q
    Apr 23 11:48:50.382: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-9240, will wait for the garbage collector to delete the pods 04/23/23 11:48:50.404
    Apr 23 11:48:50.479: INFO: Deleting ReplicationController affinity-clusterip-transition took: 12.261592ms
    Apr 23 11:48:50.683: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 203.585382ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:48:53.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-9240" for this suite. 04/23/23 11:48:53.138
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:48:53.165
Apr 23 11:48:53.165: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubelet-test 04/23/23 11:48:53.169
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:53.196
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:53.199
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Apr 23 11:48:53.221: INFO: Waiting up to 5m0s for pod "busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e" in namespace "kubelet-test-8148" to be "running and ready"
Apr 23 11:48:53.245: INFO: Pod "busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e": Phase="Pending", Reason="", readiness=false. Elapsed: 22.835338ms
Apr 23 11:48:53.245: INFO: The phase of Pod busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:48:55.261: INFO: Pod "busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038815721s
Apr 23 11:48:55.261: INFO: The phase of Pod busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:48:57.254: INFO: Pod "busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e": Phase="Running", Reason="", readiness=true. Elapsed: 4.031540359s
Apr 23 11:48:57.254: INFO: The phase of Pod busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e is Running (Ready = true)
Apr 23 11:48:57.254: INFO: Pod "busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/node/init/init.go:32
Apr 23 11:48:57.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Kubelet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Kubelet
  tear down framework | framework.go:193
STEP: Destroying namespace "kubelet-test-8148" for this suite. 04/23/23 11:48:57.279
------------------------------
â€¢ [4.125 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:48:53.165
    Apr 23 11:48:53.165: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubelet-test 04/23/23 11:48:53.169
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:53.196
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:53.199
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Apr 23 11:48:53.221: INFO: Waiting up to 5m0s for pod "busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e" in namespace "kubelet-test-8148" to be "running and ready"
    Apr 23 11:48:53.245: INFO: Pod "busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e": Phase="Pending", Reason="", readiness=false. Elapsed: 22.835338ms
    Apr 23 11:48:53.245: INFO: The phase of Pod busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:48:55.261: INFO: Pod "busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038815721s
    Apr 23 11:48:55.261: INFO: The phase of Pod busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:48:57.254: INFO: Pod "busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e": Phase="Running", Reason="", readiness=true. Elapsed: 4.031540359s
    Apr 23 11:48:57.254: INFO: The phase of Pod busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e is Running (Ready = true)
    Apr 23 11:48:57.254: INFO: Pod "busybox-scheduling-ce4871b4-72db-4daa-88bf-33aa9918ca2e" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:48:57.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Kubelet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Kubelet
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubelet-test-8148" for this suite. 04/23/23 11:48:57.279
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:48:57.299
Apr 23 11:48:57.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename discovery 04/23/23 11:48:57.301
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:57.326
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:57.331
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 04/23/23 11:48:57.339
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Apr 23 11:48:58.139: INFO: Checking APIGroup: apiregistration.k8s.io
Apr 23 11:48:58.142: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Apr 23 11:48:58.142: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Apr 23 11:48:58.142: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Apr 23 11:48:58.142: INFO: Checking APIGroup: apps
Apr 23 11:48:58.144: INFO: PreferredVersion.GroupVersion: apps/v1
Apr 23 11:48:58.144: INFO: Versions found [{apps/v1 v1}]
Apr 23 11:48:58.144: INFO: apps/v1 matches apps/v1
Apr 23 11:48:58.144: INFO: Checking APIGroup: events.k8s.io
Apr 23 11:48:58.146: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Apr 23 11:48:58.146: INFO: Versions found [{events.k8s.io/v1 v1}]
Apr 23 11:48:58.146: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Apr 23 11:48:58.146: INFO: Checking APIGroup: authentication.k8s.io
Apr 23 11:48:58.169: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Apr 23 11:48:58.169: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Apr 23 11:48:58.170: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Apr 23 11:48:58.170: INFO: Checking APIGroup: authorization.k8s.io
Apr 23 11:48:58.173: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Apr 23 11:48:58.173: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Apr 23 11:48:58.173: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Apr 23 11:48:58.173: INFO: Checking APIGroup: autoscaling
Apr 23 11:48:58.181: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Apr 23 11:48:58.181: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
Apr 23 11:48:58.181: INFO: autoscaling/v2 matches autoscaling/v2
Apr 23 11:48:58.181: INFO: Checking APIGroup: batch
Apr 23 11:48:58.185: INFO: PreferredVersion.GroupVersion: batch/v1
Apr 23 11:48:58.185: INFO: Versions found [{batch/v1 v1}]
Apr 23 11:48:58.185: INFO: batch/v1 matches batch/v1
Apr 23 11:48:58.185: INFO: Checking APIGroup: certificates.k8s.io
Apr 23 11:48:58.189: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Apr 23 11:48:58.189: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Apr 23 11:48:58.189: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Apr 23 11:48:58.189: INFO: Checking APIGroup: networking.k8s.io
Apr 23 11:48:58.192: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Apr 23 11:48:58.192: INFO: Versions found [{networking.k8s.io/v1 v1}]
Apr 23 11:48:58.192: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Apr 23 11:48:58.192: INFO: Checking APIGroup: policy
Apr 23 11:48:58.193: INFO: PreferredVersion.GroupVersion: policy/v1
Apr 23 11:48:58.194: INFO: Versions found [{policy/v1 v1}]
Apr 23 11:48:58.194: INFO: policy/v1 matches policy/v1
Apr 23 11:48:58.194: INFO: Checking APIGroup: rbac.authorization.k8s.io
Apr 23 11:48:58.198: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Apr 23 11:48:58.198: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Apr 23 11:48:58.198: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Apr 23 11:48:58.198: INFO: Checking APIGroup: storage.k8s.io
Apr 23 11:48:58.200: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Apr 23 11:48:58.200: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Apr 23 11:48:58.200: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Apr 23 11:48:58.200: INFO: Checking APIGroup: admissionregistration.k8s.io
Apr 23 11:48:58.203: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Apr 23 11:48:58.203: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Apr 23 11:48:58.203: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Apr 23 11:48:58.203: INFO: Checking APIGroup: apiextensions.k8s.io
Apr 23 11:48:58.205: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Apr 23 11:48:58.205: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Apr 23 11:48:58.205: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Apr 23 11:48:58.205: INFO: Checking APIGroup: scheduling.k8s.io
Apr 23 11:48:58.207: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Apr 23 11:48:58.207: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Apr 23 11:48:58.208: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Apr 23 11:48:58.208: INFO: Checking APIGroup: coordination.k8s.io
Apr 23 11:48:58.209: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Apr 23 11:48:58.209: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Apr 23 11:48:58.209: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Apr 23 11:48:58.209: INFO: Checking APIGroup: node.k8s.io
Apr 23 11:48:58.211: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Apr 23 11:48:58.211: INFO: Versions found [{node.k8s.io/v1 v1}]
Apr 23 11:48:58.211: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Apr 23 11:48:58.211: INFO: Checking APIGroup: discovery.k8s.io
Apr 23 11:48:58.213: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Apr 23 11:48:58.213: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Apr 23 11:48:58.213: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Apr 23 11:48:58.213: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Apr 23 11:48:58.216: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta3
Apr 23 11:48:58.216: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta3 v1beta3} {flowcontrol.apiserver.k8s.io/v1beta2 v1beta2}]
Apr 23 11:48:58.216: INFO: flowcontrol.apiserver.k8s.io/v1beta3 matches flowcontrol.apiserver.k8s.io/v1beta3
Apr 23 11:48:58.216: INFO: Checking APIGroup: cilium.io
Apr 23 11:48:58.218: INFO: PreferredVersion.GroupVersion: cilium.io/v2
Apr 23 11:48:58.218: INFO: Versions found [{cilium.io/v2 v2} {cilium.io/v2alpha1 v2alpha1}]
Apr 23 11:48:58.218: INFO: cilium.io/v2 matches cilium.io/v2
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/node/init/init.go:32
Apr 23 11:48:58.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Discovery
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Discovery
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Discovery
  tear down framework | framework.go:193
STEP: Destroying namespace "discovery-4860" for this suite. 04/23/23 11:48:58.23
------------------------------
â€¢ [0.942 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:48:57.299
    Apr 23 11:48:57.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename discovery 04/23/23 11:48:57.301
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:57.326
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:57.331
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 04/23/23 11:48:57.339
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Apr 23 11:48:58.139: INFO: Checking APIGroup: apiregistration.k8s.io
    Apr 23 11:48:58.142: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Apr 23 11:48:58.142: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Apr 23 11:48:58.142: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Apr 23 11:48:58.142: INFO: Checking APIGroup: apps
    Apr 23 11:48:58.144: INFO: PreferredVersion.GroupVersion: apps/v1
    Apr 23 11:48:58.144: INFO: Versions found [{apps/v1 v1}]
    Apr 23 11:48:58.144: INFO: apps/v1 matches apps/v1
    Apr 23 11:48:58.144: INFO: Checking APIGroup: events.k8s.io
    Apr 23 11:48:58.146: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Apr 23 11:48:58.146: INFO: Versions found [{events.k8s.io/v1 v1}]
    Apr 23 11:48:58.146: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Apr 23 11:48:58.146: INFO: Checking APIGroup: authentication.k8s.io
    Apr 23 11:48:58.169: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Apr 23 11:48:58.169: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Apr 23 11:48:58.170: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Apr 23 11:48:58.170: INFO: Checking APIGroup: authorization.k8s.io
    Apr 23 11:48:58.173: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Apr 23 11:48:58.173: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Apr 23 11:48:58.173: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Apr 23 11:48:58.173: INFO: Checking APIGroup: autoscaling
    Apr 23 11:48:58.181: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Apr 23 11:48:58.181: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
    Apr 23 11:48:58.181: INFO: autoscaling/v2 matches autoscaling/v2
    Apr 23 11:48:58.181: INFO: Checking APIGroup: batch
    Apr 23 11:48:58.185: INFO: PreferredVersion.GroupVersion: batch/v1
    Apr 23 11:48:58.185: INFO: Versions found [{batch/v1 v1}]
    Apr 23 11:48:58.185: INFO: batch/v1 matches batch/v1
    Apr 23 11:48:58.185: INFO: Checking APIGroup: certificates.k8s.io
    Apr 23 11:48:58.189: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Apr 23 11:48:58.189: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Apr 23 11:48:58.189: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Apr 23 11:48:58.189: INFO: Checking APIGroup: networking.k8s.io
    Apr 23 11:48:58.192: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Apr 23 11:48:58.192: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Apr 23 11:48:58.192: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Apr 23 11:48:58.192: INFO: Checking APIGroup: policy
    Apr 23 11:48:58.193: INFO: PreferredVersion.GroupVersion: policy/v1
    Apr 23 11:48:58.194: INFO: Versions found [{policy/v1 v1}]
    Apr 23 11:48:58.194: INFO: policy/v1 matches policy/v1
    Apr 23 11:48:58.194: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Apr 23 11:48:58.198: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Apr 23 11:48:58.198: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Apr 23 11:48:58.198: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Apr 23 11:48:58.198: INFO: Checking APIGroup: storage.k8s.io
    Apr 23 11:48:58.200: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Apr 23 11:48:58.200: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Apr 23 11:48:58.200: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Apr 23 11:48:58.200: INFO: Checking APIGroup: admissionregistration.k8s.io
    Apr 23 11:48:58.203: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Apr 23 11:48:58.203: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Apr 23 11:48:58.203: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Apr 23 11:48:58.203: INFO: Checking APIGroup: apiextensions.k8s.io
    Apr 23 11:48:58.205: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Apr 23 11:48:58.205: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Apr 23 11:48:58.205: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Apr 23 11:48:58.205: INFO: Checking APIGroup: scheduling.k8s.io
    Apr 23 11:48:58.207: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Apr 23 11:48:58.207: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Apr 23 11:48:58.208: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Apr 23 11:48:58.208: INFO: Checking APIGroup: coordination.k8s.io
    Apr 23 11:48:58.209: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Apr 23 11:48:58.209: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Apr 23 11:48:58.209: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Apr 23 11:48:58.209: INFO: Checking APIGroup: node.k8s.io
    Apr 23 11:48:58.211: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Apr 23 11:48:58.211: INFO: Versions found [{node.k8s.io/v1 v1}]
    Apr 23 11:48:58.211: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Apr 23 11:48:58.211: INFO: Checking APIGroup: discovery.k8s.io
    Apr 23 11:48:58.213: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Apr 23 11:48:58.213: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Apr 23 11:48:58.213: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Apr 23 11:48:58.213: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Apr 23 11:48:58.216: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta3
    Apr 23 11:48:58.216: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta3 v1beta3} {flowcontrol.apiserver.k8s.io/v1beta2 v1beta2}]
    Apr 23 11:48:58.216: INFO: flowcontrol.apiserver.k8s.io/v1beta3 matches flowcontrol.apiserver.k8s.io/v1beta3
    Apr 23 11:48:58.216: INFO: Checking APIGroup: cilium.io
    Apr 23 11:48:58.218: INFO: PreferredVersion.GroupVersion: cilium.io/v2
    Apr 23 11:48:58.218: INFO: Versions found [{cilium.io/v2 v2} {cilium.io/v2alpha1 v2alpha1}]
    Apr 23 11:48:58.218: INFO: cilium.io/v2 matches cilium.io/v2
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:48:58.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Discovery
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Discovery
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Discovery
      tear down framework | framework.go:193
    STEP: Destroying namespace "discovery-4860" for this suite. 04/23/23 11:48:58.23
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:119
[BeforeEach] [sig-storage] Projected secret
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:48:58.255
Apr 23 11:48:58.256: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:48:58.26
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:58.293
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:58.298
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:119
STEP: Creating secret with name projected-secret-test-e48a0faa-5d78-42a6-a7ff-85825a249855 04/23/23 11:48:58.303
STEP: Creating a pod to test consume secrets 04/23/23 11:48:58.313
Apr 23 11:48:58.334: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e" in namespace "projected-8622" to be "Succeeded or Failed"
Apr 23 11:48:58.343: INFO: Pod "pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.964858ms
Apr 23 11:49:00.355: INFO: Pod "pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021243761s
Apr 23 11:49:02.353: INFO: Pod "pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019379061s
STEP: Saw pod success 04/23/23 11:49:02.353
Apr 23 11:49:02.354: INFO: Pod "pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e" satisfied condition "Succeeded or Failed"
Apr 23 11:49:02.361: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e container secret-volume-test: <nil>
STEP: delete the pod 04/23/23 11:49:02.376
Apr 23 11:49:02.406: INFO: Waiting for pod pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e to disappear
Apr 23 11:49:02.412: INFO: Pod pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/node/init/init.go:32
Apr 23 11:49:02.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected secret
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected secret
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-8622" for this suite. 04/23/23 11:49:02.428
------------------------------
â€¢ [4.191 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:119

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:48:58.255
    Apr 23 11:48:58.256: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:48:58.26
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:48:58.293
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:48:58.298
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:119
    STEP: Creating secret with name projected-secret-test-e48a0faa-5d78-42a6-a7ff-85825a249855 04/23/23 11:48:58.303
    STEP: Creating a pod to test consume secrets 04/23/23 11:48:58.313
    Apr 23 11:48:58.334: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e" in namespace "projected-8622" to be "Succeeded or Failed"
    Apr 23 11:48:58.343: INFO: Pod "pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.964858ms
    Apr 23 11:49:00.355: INFO: Pod "pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021243761s
    Apr 23 11:49:02.353: INFO: Pod "pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019379061s
    STEP: Saw pod success 04/23/23 11:49:02.353
    Apr 23 11:49:02.354: INFO: Pod "pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e" satisfied condition "Succeeded or Failed"
    Apr 23 11:49:02.361: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e container secret-volume-test: <nil>
    STEP: delete the pod 04/23/23 11:49:02.376
    Apr 23 11:49:02.406: INFO: Waiting for pod pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e to disappear
    Apr 23 11:49:02.412: INFO: Pod pod-projected-secrets-a40e86bb-0c22-4b14-8df1-2c060869b86e no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:49:02.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected secret
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected secret
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-8622" for this suite. 04/23/23 11:49:02.428
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:90
[BeforeEach] [sig-node] Downward API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:49:02.458
Apr 23 11:49:02.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 11:49:02.461
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:49:02.494
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:49:02.504
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:31
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:90
STEP: Creating a pod to test downward api env vars 04/23/23 11:49:02.51
Apr 23 11:49:02.552: INFO: Waiting up to 5m0s for pod "downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48" in namespace "downward-api-7256" to be "Succeeded or Failed"
Apr 23 11:49:02.606: INFO: Pod "downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48": Phase="Pending", Reason="", readiness=false. Elapsed: 54.082048ms
Apr 23 11:49:04.618: INFO: Pod "downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065408076s
Apr 23 11:49:06.613: INFO: Pod "downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060955026s
STEP: Saw pod success 04/23/23 11:49:06.614
Apr 23 11:49:06.614: INFO: Pod "downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48" satisfied condition "Succeeded or Failed"
Apr 23 11:49:06.618: INFO: Trying to get logs from node eingavuivie7-3 pod downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48 container dapi-container: <nil>
STEP: delete the pod 04/23/23 11:49:06.635
Apr 23 11:49:06.662: INFO: Waiting for pod downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48 to disappear
Apr 23 11:49:06.666: INFO: Pod downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/node/init/init.go:32
Apr 23 11:49:06.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Downward API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Downward API
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-7256" for this suite. 04/23/23 11:49:06.681
------------------------------
â€¢ [4.237 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:49:02.458
    Apr 23 11:49:02.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 11:49:02.461
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:49:02.494
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:49:02.504
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:90
    STEP: Creating a pod to test downward api env vars 04/23/23 11:49:02.51
    Apr 23 11:49:02.552: INFO: Waiting up to 5m0s for pod "downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48" in namespace "downward-api-7256" to be "Succeeded or Failed"
    Apr 23 11:49:02.606: INFO: Pod "downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48": Phase="Pending", Reason="", readiness=false. Elapsed: 54.082048ms
    Apr 23 11:49:04.618: INFO: Pod "downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065408076s
    Apr 23 11:49:06.613: INFO: Pod "downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060955026s
    STEP: Saw pod success 04/23/23 11:49:06.614
    Apr 23 11:49:06.614: INFO: Pod "downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48" satisfied condition "Succeeded or Failed"
    Apr 23 11:49:06.618: INFO: Trying to get logs from node eingavuivie7-3 pod downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48 container dapi-container: <nil>
    STEP: delete the pod 04/23/23 11:49:06.635
    Apr 23 11:49:06.662: INFO: Waiting for pod downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48 to disappear
    Apr 23 11:49:06.666: INFO: Pod downward-api-c4e66ba3-0d19-440f-aeeb-236b5c16aa48 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:49:06.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Downward API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Downward API
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-7256" for this suite. 04/23/23 11:49:06.681
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1477
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:49:06.71
Apr 23 11:49:06.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 11:49:06.714
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:49:06.74
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:49:06.746
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1477
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1057 04/23/23 11:49:06.752
STEP: changing the ExternalName service to type=NodePort 04/23/23 11:49:06.759
STEP: creating replication controller externalname-service in namespace services-1057 04/23/23 11:49:06.821
I0423 11:49:06.835864      13 runners.go:193] Created replication controller with name: externalname-service, namespace: services-1057, replica count: 2
I0423 11:49:09.887143      13 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 23 11:49:09.888: INFO: Creating new exec pod
Apr 23 11:49:09.906: INFO: Waiting up to 5m0s for pod "execpodp2k78" in namespace "services-1057" to be "running"
Apr 23 11:49:09.913: INFO: Pod "execpodp2k78": Phase="Pending", Reason="", readiness=false. Elapsed: 6.629737ms
Apr 23 11:49:11.921: INFO: Pod "execpodp2k78": Phase="Running", Reason="", readiness=true. Elapsed: 2.01528309s
Apr 23 11:49:11.921: INFO: Pod "execpodp2k78" satisfied condition "running"
Apr 23 11:49:12.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1057 exec execpodp2k78 -- /bin/sh -x -c nc -v -z -w 2 externalname-service 80'
Apr 23 11:49:13.266: INFO: stderr: "+ nc -v -z -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 23 11:49:13.266: INFO: stdout: ""
Apr 23 11:49:13.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1057 exec execpodp2k78 -- /bin/sh -x -c nc -v -z -w 2 10.233.32.238 80'
Apr 23 11:49:13.619: INFO: stderr: "+ nc -v -z -w 2 10.233.32.238 80\nConnection to 10.233.32.238 80 port [tcp/http] succeeded!\n"
Apr 23 11:49:13.620: INFO: stdout: ""
Apr 23 11:49:13.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1057 exec execpodp2k78 -- /bin/sh -x -c nc -v -z -w 2 192.168.121.198 30759'
Apr 23 11:49:13.975: INFO: stderr: "+ nc -v -z -w 2 192.168.121.198 30759\nConnection to 192.168.121.198 30759 port [tcp/*] succeeded!\n"
Apr 23 11:49:13.975: INFO: stdout: ""
Apr 23 11:49:13.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1057 exec execpodp2k78 -- /bin/sh -x -c nc -v -z -w 2 192.168.121.214 30759'
Apr 23 11:49:14.263: INFO: stderr: "+ nc -v -z -w 2 192.168.121.214 30759\nConnection to 192.168.121.214 30759 port [tcp/*] succeeded!\n"
Apr 23 11:49:14.263: INFO: stdout: ""
Apr 23 11:49:14.264: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 11:49:14.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-1057" for this suite. 04/23/23 11:49:14.34
------------------------------
â€¢ [SLOW TEST] [7.649 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1477

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:49:06.71
    Apr 23 11:49:06.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 11:49:06.714
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:49:06.74
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:49:06.746
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1477
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-1057 04/23/23 11:49:06.752
    STEP: changing the ExternalName service to type=NodePort 04/23/23 11:49:06.759
    STEP: creating replication controller externalname-service in namespace services-1057 04/23/23 11:49:06.821
    I0423 11:49:06.835864      13 runners.go:193] Created replication controller with name: externalname-service, namespace: services-1057, replica count: 2
    I0423 11:49:09.887143      13 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 23 11:49:09.888: INFO: Creating new exec pod
    Apr 23 11:49:09.906: INFO: Waiting up to 5m0s for pod "execpodp2k78" in namespace "services-1057" to be "running"
    Apr 23 11:49:09.913: INFO: Pod "execpodp2k78": Phase="Pending", Reason="", readiness=false. Elapsed: 6.629737ms
    Apr 23 11:49:11.921: INFO: Pod "execpodp2k78": Phase="Running", Reason="", readiness=true. Elapsed: 2.01528309s
    Apr 23 11:49:11.921: INFO: Pod "execpodp2k78" satisfied condition "running"
    Apr 23 11:49:12.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1057 exec execpodp2k78 -- /bin/sh -x -c nc -v -z -w 2 externalname-service 80'
    Apr 23 11:49:13.266: INFO: stderr: "+ nc -v -z -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 23 11:49:13.266: INFO: stdout: ""
    Apr 23 11:49:13.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1057 exec execpodp2k78 -- /bin/sh -x -c nc -v -z -w 2 10.233.32.238 80'
    Apr 23 11:49:13.619: INFO: stderr: "+ nc -v -z -w 2 10.233.32.238 80\nConnection to 10.233.32.238 80 port [tcp/http] succeeded!\n"
    Apr 23 11:49:13.620: INFO: stdout: ""
    Apr 23 11:49:13.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1057 exec execpodp2k78 -- /bin/sh -x -c nc -v -z -w 2 192.168.121.198 30759'
    Apr 23 11:49:13.975: INFO: stderr: "+ nc -v -z -w 2 192.168.121.198 30759\nConnection to 192.168.121.198 30759 port [tcp/*] succeeded!\n"
    Apr 23 11:49:13.975: INFO: stdout: ""
    Apr 23 11:49:13.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1057 exec execpodp2k78 -- /bin/sh -x -c nc -v -z -w 2 192.168.121.214 30759'
    Apr 23 11:49:14.263: INFO: stderr: "+ nc -v -z -w 2 192.168.121.214 30759\nConnection to 192.168.121.214 30759 port [tcp/*] succeeded!\n"
    Apr 23 11:49:14.263: INFO: stdout: ""
    Apr 23 11:49:14.264: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:49:14.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-1057" for this suite. 04/23/23 11:49:14.34
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:46
[BeforeEach] [sig-storage] Projected secret
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:49:14.36
Apr 23 11:49:14.360: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:49:14.372
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:49:14.402
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:49:14.409
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:46
STEP: Creating projection with secret that has name projected-secret-test-2e853ceb-c115-4e27-85e7-8b1f2da54ea3 04/23/23 11:49:14.417
STEP: Creating a pod to test consume secrets 04/23/23 11:49:14.427
Apr 23 11:49:14.444: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe" in namespace "projected-5476" to be "Succeeded or Failed"
Apr 23 11:49:14.454: INFO: Pod "pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe": Phase="Pending", Reason="", readiness=false. Elapsed: 9.251204ms
Apr 23 11:49:16.463: INFO: Pod "pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018151189s
Apr 23 11:49:18.463: INFO: Pod "pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017946251s
Apr 23 11:49:20.468: INFO: Pod "pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023129363s
STEP: Saw pod success 04/23/23 11:49:20.468
Apr 23 11:49:20.468: INFO: Pod "pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe" satisfied condition "Succeeded or Failed"
Apr 23 11:49:20.482: INFO: Trying to get logs from node eingavuivie7-2 pod pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe container projected-secret-volume-test: <nil>
STEP: delete the pod 04/23/23 11:49:20.53
Apr 23 11:49:20.602: INFO: Waiting for pod pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe to disappear
Apr 23 11:49:20.626: INFO: Pod pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/node/init/init.go:32
Apr 23 11:49:20.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected secret
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected secret
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-5476" for this suite. 04/23/23 11:49:20.681
------------------------------
â€¢ [SLOW TEST] [6.368 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:49:14.36
    Apr 23 11:49:14.360: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:49:14.372
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:49:14.402
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:49:14.409
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:46
    STEP: Creating projection with secret that has name projected-secret-test-2e853ceb-c115-4e27-85e7-8b1f2da54ea3 04/23/23 11:49:14.417
    STEP: Creating a pod to test consume secrets 04/23/23 11:49:14.427
    Apr 23 11:49:14.444: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe" in namespace "projected-5476" to be "Succeeded or Failed"
    Apr 23 11:49:14.454: INFO: Pod "pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe": Phase="Pending", Reason="", readiness=false. Elapsed: 9.251204ms
    Apr 23 11:49:16.463: INFO: Pod "pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018151189s
    Apr 23 11:49:18.463: INFO: Pod "pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017946251s
    Apr 23 11:49:20.468: INFO: Pod "pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023129363s
    STEP: Saw pod success 04/23/23 11:49:20.468
    Apr 23 11:49:20.468: INFO: Pod "pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe" satisfied condition "Succeeded or Failed"
    Apr 23 11:49:20.482: INFO: Trying to get logs from node eingavuivie7-2 pod pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/23/23 11:49:20.53
    Apr 23 11:49:20.602: INFO: Waiting for pod pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe to disappear
    Apr 23 11:49:20.626: INFO: Pod pod-projected-secrets-ed38ee07-6e67-4f1d-8a03-722016a03bfe no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:49:20.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected secret
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected secret
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-5476" for this suite. 04/23/23 11:49:20.681
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2250
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:49:20.728
Apr 23 11:49:20.728: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 11:49:20.736
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:49:20.791
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:49:20.83
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2250
STEP: creating service in namespace services-6858 04/23/23 11:49:20.836
STEP: creating service affinity-nodeport-transition in namespace services-6858 04/23/23 11:49:20.836
STEP: creating replication controller affinity-nodeport-transition in namespace services-6858 04/23/23 11:49:20.901
I0423 11:49:20.955834      13 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-6858, replica count: 3
I0423 11:49:24.006774      13 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 23 11:49:24.026: INFO: Creating new exec pod
Apr 23 11:49:24.034: INFO: Waiting up to 5m0s for pod "execpod-affinityjgs88" in namespace "services-6858" to be "running"
Apr 23 11:49:24.047: INFO: Pod "execpod-affinityjgs88": Phase="Pending", Reason="", readiness=false. Elapsed: 13.457144ms
Apr 23 11:49:26.057: INFO: Pod "execpod-affinityjgs88": Phase="Running", Reason="", readiness=true. Elapsed: 2.022757223s
Apr 23 11:49:26.057: INFO: Pod "execpod-affinityjgs88" satisfied condition "running"
Apr 23 11:49:27.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6858 exec execpod-affinityjgs88 -- /bin/sh -x -c nc -v -z -w 2 affinity-nodeport-transition 80'
Apr 23 11:49:27.485: INFO: stderr: "+ nc -v -z -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Apr 23 11:49:27.485: INFO: stdout: ""
Apr 23 11:49:27.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6858 exec execpod-affinityjgs88 -- /bin/sh -x -c nc -v -z -w 2 10.233.18.255 80'
Apr 23 11:49:27.859: INFO: stderr: "+ nc -v -z -w 2 10.233.18.255 80\nConnection to 10.233.18.255 80 port [tcp/http] succeeded!\n"
Apr 23 11:49:27.859: INFO: stdout: ""
Apr 23 11:49:27.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6858 exec execpod-affinityjgs88 -- /bin/sh -x -c nc -v -z -w 2 192.168.121.214 32273'
Apr 23 11:49:28.310: INFO: stderr: "+ nc -v -z -w 2 192.168.121.214 32273\nConnection to 192.168.121.214 32273 port [tcp/*] succeeded!\n"
Apr 23 11:49:28.310: INFO: stdout: ""
Apr 23 11:49:28.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6858 exec execpod-affinityjgs88 -- /bin/sh -x -c nc -v -z -w 2 192.168.121.198 32273'
Apr 23 11:49:28.623: INFO: stderr: "+ nc -v -z -w 2 192.168.121.198 32273\nConnection to 192.168.121.198 32273 port [tcp/*] succeeded!\n"
Apr 23 11:49:28.623: INFO: stdout: ""
Apr 23 11:49:28.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6858 exec execpod-affinityjgs88 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.130:32273/ ; done'
Apr 23 11:49:29.218: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n"
Apr 23 11:49:29.218: INFO: stdout: "\naffinity-nodeport-transition-zz5sh\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zz5sh\naffinity-nodeport-transition-8vldx\naffinity-nodeport-transition-8vldx\naffinity-nodeport-transition-8vldx\naffinity-nodeport-transition-zz5sh\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-8vldx\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zz5sh\naffinity-nodeport-transition-zz5sh\naffinity-nodeport-transition-8vldx\naffinity-nodeport-transition-8vldx\naffinity-nodeport-transition-zs2c9"
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zz5sh
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zz5sh
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-8vldx
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-8vldx
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-8vldx
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zz5sh
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-8vldx
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zz5sh
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zz5sh
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-8vldx
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-8vldx
Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:29.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6858 exec execpod-affinityjgs88 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.130:32273/ ; done'
Apr 23 11:49:30.217: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n"
Apr 23 11:49:30.217: INFO: stdout: "\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9"
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
Apr 23 11:49:30.217: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-6858, will wait for the garbage collector to delete the pods 04/23/23 11:49:30.253
Apr 23 11:49:30.337: INFO: Deleting ReplicationController affinity-nodeport-transition took: 28.96523ms
Apr 23 11:49:30.437: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.249655ms
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 11:49:33.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-6858" for this suite. 04/23/23 11:49:33.145
------------------------------
â€¢ [SLOW TEST] [12.433 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:49:20.728
    Apr 23 11:49:20.728: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 11:49:20.736
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:49:20.791
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:49:20.83
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2250
    STEP: creating service in namespace services-6858 04/23/23 11:49:20.836
    STEP: creating service affinity-nodeport-transition in namespace services-6858 04/23/23 11:49:20.836
    STEP: creating replication controller affinity-nodeport-transition in namespace services-6858 04/23/23 11:49:20.901
    I0423 11:49:20.955834      13 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-6858, replica count: 3
    I0423 11:49:24.006774      13 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 23 11:49:24.026: INFO: Creating new exec pod
    Apr 23 11:49:24.034: INFO: Waiting up to 5m0s for pod "execpod-affinityjgs88" in namespace "services-6858" to be "running"
    Apr 23 11:49:24.047: INFO: Pod "execpod-affinityjgs88": Phase="Pending", Reason="", readiness=false. Elapsed: 13.457144ms
    Apr 23 11:49:26.057: INFO: Pod "execpod-affinityjgs88": Phase="Running", Reason="", readiness=true. Elapsed: 2.022757223s
    Apr 23 11:49:26.057: INFO: Pod "execpod-affinityjgs88" satisfied condition "running"
    Apr 23 11:49:27.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6858 exec execpod-affinityjgs88 -- /bin/sh -x -c nc -v -z -w 2 affinity-nodeport-transition 80'
    Apr 23 11:49:27.485: INFO: stderr: "+ nc -v -z -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Apr 23 11:49:27.485: INFO: stdout: ""
    Apr 23 11:49:27.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6858 exec execpod-affinityjgs88 -- /bin/sh -x -c nc -v -z -w 2 10.233.18.255 80'
    Apr 23 11:49:27.859: INFO: stderr: "+ nc -v -z -w 2 10.233.18.255 80\nConnection to 10.233.18.255 80 port [tcp/http] succeeded!\n"
    Apr 23 11:49:27.859: INFO: stdout: ""
    Apr 23 11:49:27.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6858 exec execpod-affinityjgs88 -- /bin/sh -x -c nc -v -z -w 2 192.168.121.214 32273'
    Apr 23 11:49:28.310: INFO: stderr: "+ nc -v -z -w 2 192.168.121.214 32273\nConnection to 192.168.121.214 32273 port [tcp/*] succeeded!\n"
    Apr 23 11:49:28.310: INFO: stdout: ""
    Apr 23 11:49:28.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6858 exec execpod-affinityjgs88 -- /bin/sh -x -c nc -v -z -w 2 192.168.121.198 32273'
    Apr 23 11:49:28.623: INFO: stderr: "+ nc -v -z -w 2 192.168.121.198 32273\nConnection to 192.168.121.198 32273 port [tcp/*] succeeded!\n"
    Apr 23 11:49:28.623: INFO: stdout: ""
    Apr 23 11:49:28.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6858 exec execpod-affinityjgs88 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.130:32273/ ; done'
    Apr 23 11:49:29.218: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n"
    Apr 23 11:49:29.218: INFO: stdout: "\naffinity-nodeport-transition-zz5sh\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zz5sh\naffinity-nodeport-transition-8vldx\naffinity-nodeport-transition-8vldx\naffinity-nodeport-transition-8vldx\naffinity-nodeport-transition-zz5sh\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-8vldx\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zz5sh\naffinity-nodeport-transition-zz5sh\naffinity-nodeport-transition-8vldx\naffinity-nodeport-transition-8vldx\naffinity-nodeport-transition-zs2c9"
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zz5sh
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zz5sh
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-8vldx
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-8vldx
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-8vldx
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zz5sh
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-8vldx
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zz5sh
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zz5sh
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-8vldx
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-8vldx
    Apr 23 11:49:29.218: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:29.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6858 exec execpod-affinityjgs88 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.130:32273/ ; done'
    Apr 23 11:49:30.217: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:32273/\n"
    Apr 23 11:49:30.217: INFO: stdout: "\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9\naffinity-nodeport-transition-zs2c9"
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Received response from host: affinity-nodeport-transition-zs2c9
    Apr 23 11:49:30.217: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-6858, will wait for the garbage collector to delete the pods 04/23/23 11:49:30.253
    Apr 23 11:49:30.337: INFO: Deleting ReplicationController affinity-nodeport-transition took: 28.96523ms
    Apr 23 11:49:30.437: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.249655ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:49:33.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-6858" for this suite. 04/23/23 11:49:33.145
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:49:33.169
Apr 23 11:49:33.170: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename gc 04/23/23 11:49:33.184
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:49:33.21
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:49:33.215
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:31
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Apr 23 11:49:33.357: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"8b763f7c-9690-4e56-b6ba-b4388af1b900", Controller:(*bool)(0xc0031e89ae), BlockOwnerDeletion:(*bool)(0xc0031e89af)}}
Apr 23 11:49:33.371: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"fc53387c-cc5c-4548-bc04-a04f4e6b28ce", Controller:(*bool)(0xc0031e901e), BlockOwnerDeletion:(*bool)(0xc0031e901f)}}
Apr 23 11:49:33.386: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b4379c54-fab7-4828-96fd-0510c86d4ecb", Controller:(*bool)(0xc0031e9366), BlockOwnerDeletion:(*bool)(0xc0031e9367)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/node/init/init.go:32
Apr 23 11:49:38.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  tear down framework | framework.go:193
STEP: Destroying namespace "gc-6305" for this suite. 04/23/23 11:49:38.441
------------------------------
â€¢ [SLOW TEST] [5.297 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:49:33.169
    Apr 23 11:49:33.170: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename gc 04/23/23 11:49:33.184
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:49:33.21
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:49:33.215
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:31
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Apr 23 11:49:33.357: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"8b763f7c-9690-4e56-b6ba-b4388af1b900", Controller:(*bool)(0xc0031e89ae), BlockOwnerDeletion:(*bool)(0xc0031e89af)}}
    Apr 23 11:49:33.371: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"fc53387c-cc5c-4548-bc04-a04f4e6b28ce", Controller:(*bool)(0xc0031e901e), BlockOwnerDeletion:(*bool)(0xc0031e901f)}}
    Apr 23 11:49:33.386: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b4379c54-fab7-4828-96fd-0510c86d4ecb", Controller:(*bool)(0xc0031e9366), BlockOwnerDeletion:(*bool)(0xc0031e9367)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:49:38.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      tear down framework | framework.go:193
    STEP: Destroying namespace "gc-6305" for this suite. 04/23/23 11:49:38.441
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:49:38.466
Apr 23 11:49:38.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pod-network-test 04/23/23 11:49:38.477
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:49:38.542
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:49:38.553
[BeforeEach] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:31
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-8971 04/23/23 11:49:38.566
STEP: creating a selector 04/23/23 11:49:38.566
STEP: Creating the service pods in kubernetes 04/23/23 11:49:38.566
Apr 23 11:49:38.567: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 23 11:49:38.676: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-8971" to be "running and ready"
Apr 23 11:49:38.690: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 13.954696ms
Apr 23 11:49:38.690: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:49:40.702: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026211053s
Apr 23 11:49:40.702: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:49:42.698: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.022525919s
Apr 23 11:49:42.699: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:49:44.699: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.022874097s
Apr 23 11:49:44.699: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:49:46.700: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.024033034s
Apr 23 11:49:46.700: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:49:48.702: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.02576732s
Apr 23 11:49:48.702: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:49:50.700: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.02381839s
Apr 23 11:49:50.700: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:49:52.699: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.023290581s
Apr 23 11:49:52.699: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:49:54.704: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.028398938s
Apr 23 11:49:54.705: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:49:56.699: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.022604775s
Apr 23 11:49:56.699: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:49:58.699: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.022838417s
Apr 23 11:49:58.699: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:50:00.696: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.020267737s
Apr 23 11:50:00.696: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 23 11:50:00.696: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 23 11:50:00.702: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-8971" to be "running and ready"
Apr 23 11:50:00.707: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.434324ms
Apr 23 11:50:00.707: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 23 11:50:00.707: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 23 11:50:00.714: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-8971" to be "running and ready"
Apr 23 11:50:00.721: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 6.592877ms
Apr 23 11:50:00.721: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 23 11:50:00.721: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/23/23 11:50:00.729
Apr 23 11:50:00.743: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-8971" to be "running"
Apr 23 11:50:00.754: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.684932ms
Apr 23 11:50:02.768: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.024670457s
Apr 23 11:50:02.768: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 23 11:50:02.778: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 23 11:50:02.779: INFO: Breadth first check of 10.233.65.108 on host 192.168.121.130...
Apr 23 11:50:02.788: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.64.218:9080/dial?request=hostname&protocol=http&host=10.233.65.108&port=8083&tries=1'] Namespace:pod-network-test-8971 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 11:50:02.788: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:50:02.792: INFO: ExecWithOptions: Clientset creation
Apr 23 11:50:02.792: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-8971/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.64.218%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.65.108%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 23 11:50:03.011: INFO: Waiting for responses: map[]
Apr 23 11:50:03.011: INFO: reached 10.233.65.108 after 0/1 tries
Apr 23 11:50:03.011: INFO: Breadth first check of 10.233.66.120 on host 192.168.121.214...
Apr 23 11:50:03.021: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.64.218:9080/dial?request=hostname&protocol=http&host=10.233.66.120&port=8083&tries=1'] Namespace:pod-network-test-8971 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 11:50:03.021: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:50:03.023: INFO: ExecWithOptions: Clientset creation
Apr 23 11:50:03.023: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-8971/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.64.218%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.66.120%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 23 11:50:03.160: INFO: Waiting for responses: map[]
Apr 23 11:50:03.160: INFO: reached 10.233.66.120 after 0/1 tries
Apr 23 11:50:03.160: INFO: Breadth first check of 10.233.64.78 on host 192.168.121.198...
Apr 23 11:50:03.166: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.64.218:9080/dial?request=hostname&protocol=http&host=10.233.64.78&port=8083&tries=1'] Namespace:pod-network-test-8971 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 11:50:03.166: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:50:03.168: INFO: ExecWithOptions: Clientset creation
Apr 23 11:50:03.168: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-8971/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.64.218%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.64.78%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 23 11:50:03.300: INFO: Waiting for responses: map[]
Apr 23 11:50:03.300: INFO: reached 10.233.64.78 after 0/1 tries
Apr 23 11:50:03.300: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/node/init/init.go:32
Apr 23 11:50:03.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Networking
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Networking
  tear down framework | framework.go:193
STEP: Destroying namespace "pod-network-test-8971" for this suite. 04/23/23 11:50:03.312
------------------------------
â€¢ [SLOW TEST] [24.861 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:49:38.466
    Apr 23 11:49:38.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pod-network-test 04/23/23 11:49:38.477
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:49:38.542
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:49:38.553
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:31
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-8971 04/23/23 11:49:38.566
    STEP: creating a selector 04/23/23 11:49:38.566
    STEP: Creating the service pods in kubernetes 04/23/23 11:49:38.566
    Apr 23 11:49:38.567: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 23 11:49:38.676: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-8971" to be "running and ready"
    Apr 23 11:49:38.690: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 13.954696ms
    Apr 23 11:49:38.690: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:49:40.702: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026211053s
    Apr 23 11:49:40.702: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:49:42.698: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.022525919s
    Apr 23 11:49:42.699: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:49:44.699: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.022874097s
    Apr 23 11:49:44.699: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:49:46.700: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.024033034s
    Apr 23 11:49:46.700: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:49:48.702: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.02576732s
    Apr 23 11:49:48.702: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:49:50.700: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.02381839s
    Apr 23 11:49:50.700: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:49:52.699: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.023290581s
    Apr 23 11:49:52.699: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:49:54.704: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.028398938s
    Apr 23 11:49:54.705: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:49:56.699: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.022604775s
    Apr 23 11:49:56.699: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:49:58.699: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.022838417s
    Apr 23 11:49:58.699: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:50:00.696: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.020267737s
    Apr 23 11:50:00.696: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 23 11:50:00.696: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 23 11:50:00.702: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-8971" to be "running and ready"
    Apr 23 11:50:00.707: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.434324ms
    Apr 23 11:50:00.707: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 23 11:50:00.707: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 23 11:50:00.714: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-8971" to be "running and ready"
    Apr 23 11:50:00.721: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 6.592877ms
    Apr 23 11:50:00.721: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 23 11:50:00.721: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/23/23 11:50:00.729
    Apr 23 11:50:00.743: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-8971" to be "running"
    Apr 23 11:50:00.754: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.684932ms
    Apr 23 11:50:02.768: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.024670457s
    Apr 23 11:50:02.768: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 23 11:50:02.778: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 23 11:50:02.779: INFO: Breadth first check of 10.233.65.108 on host 192.168.121.130...
    Apr 23 11:50:02.788: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.64.218:9080/dial?request=hostname&protocol=http&host=10.233.65.108&port=8083&tries=1'] Namespace:pod-network-test-8971 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 11:50:02.788: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:50:02.792: INFO: ExecWithOptions: Clientset creation
    Apr 23 11:50:02.792: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-8971/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.64.218%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.65.108%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 23 11:50:03.011: INFO: Waiting for responses: map[]
    Apr 23 11:50:03.011: INFO: reached 10.233.65.108 after 0/1 tries
    Apr 23 11:50:03.011: INFO: Breadth first check of 10.233.66.120 on host 192.168.121.214...
    Apr 23 11:50:03.021: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.64.218:9080/dial?request=hostname&protocol=http&host=10.233.66.120&port=8083&tries=1'] Namespace:pod-network-test-8971 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 11:50:03.021: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:50:03.023: INFO: ExecWithOptions: Clientset creation
    Apr 23 11:50:03.023: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-8971/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.64.218%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.66.120%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 23 11:50:03.160: INFO: Waiting for responses: map[]
    Apr 23 11:50:03.160: INFO: reached 10.233.66.120 after 0/1 tries
    Apr 23 11:50:03.160: INFO: Breadth first check of 10.233.64.78 on host 192.168.121.198...
    Apr 23 11:50:03.166: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.64.218:9080/dial?request=hostname&protocol=http&host=10.233.64.78&port=8083&tries=1'] Namespace:pod-network-test-8971 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 11:50:03.166: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:50:03.168: INFO: ExecWithOptions: Clientset creation
    Apr 23 11:50:03.168: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-8971/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.64.218%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.64.78%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 23 11:50:03.300: INFO: Waiting for responses: map[]
    Apr 23 11:50:03.300: INFO: reached 10.233.64.78 after 0/1 tries
    Apr 23 11:50:03.300: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:50:03.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Networking
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Networking
      tear down framework | framework.go:193
    STEP: Destroying namespace "pod-network-test-8971" for this suite. 04/23/23 11:50:03.312
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:277
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:50:03.34
Apr 23 11:50:03.340: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 11:50:03.342
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:50:03.388
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:50:03.4
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 11:50:03.43
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 11:50:04.163
STEP: Deploying the webhook pod 04/23/23 11:50:04.175
STEP: Wait for the deployment to be ready 04/23/23 11:50:04.214
Apr 23 11:50:04.244: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/23/23 11:50:06.271
STEP: Verifying the service has paired with the endpoint 04/23/23 11:50:06.29
Apr 23 11:50:07.292: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:277
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/23/23 11:50:07.3
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/23/23 11:50:07.33
STEP: Creating a dummy validating-webhook-configuration object 04/23/23 11:50:07.38
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 04/23/23 11:50:07.398
STEP: Creating a dummy mutating-webhook-configuration object 04/23/23 11:50:07.41
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 04/23/23 11:50:07.431
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:50:07.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-4426" for this suite. 04/23/23 11:50:07.621
STEP: Destroying namespace "webhook-4426-markers" for this suite. 04/23/23 11:50:07.645
------------------------------
â€¢ [4.335 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:277

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:50:03.34
    Apr 23 11:50:03.340: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 11:50:03.342
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:50:03.388
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:50:03.4
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 11:50:03.43
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 11:50:04.163
    STEP: Deploying the webhook pod 04/23/23 11:50:04.175
    STEP: Wait for the deployment to be ready 04/23/23 11:50:04.214
    Apr 23 11:50:04.244: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/23/23 11:50:06.271
    STEP: Verifying the service has paired with the endpoint 04/23/23 11:50:06.29
    Apr 23 11:50:07.292: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:277
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/23/23 11:50:07.3
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/23/23 11:50:07.33
    STEP: Creating a dummy validating-webhook-configuration object 04/23/23 11:50:07.38
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 04/23/23 11:50:07.398
    STEP: Creating a dummy mutating-webhook-configuration object 04/23/23 11:50:07.41
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 04/23/23 11:50:07.431
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:50:07.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-4426" for this suite. 04/23/23 11:50:07.621
    STEP: Destroying namespace "webhook-4426-markers" for this suite. 04/23/23 11:50:07.645
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:50:07.706
Apr 23 11:50:07.706: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename proxy 04/23/23 11:50:07.72
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:50:07.77
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:50:07.78
[BeforeEach] version v1
  test/e2e/framework/metrics/init/init.go:31
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 04/23/23 11:50:07.81
STEP: creating replication controller proxy-service-h5rg6 in namespace proxy-157 04/23/23 11:50:07.811
I0423 11:50:07.827871      13 runners.go:193] Created replication controller with name: proxy-service-h5rg6, namespace: proxy-157, replica count: 1
I0423 11:50:08.879145      13 runners.go:193] proxy-service-h5rg6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:50:09.881986      13 runners.go:193] proxy-service-h5rg6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0423 11:50:10.882419      13 runners.go:193] proxy-service-h5rg6 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 23 11:50:10.895: INFO: setup took 3.101940271s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 04/23/23 11:50:10.896
Apr 23 11:50:10.923: INFO: (0) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 25.623228ms)
Apr 23 11:50:10.923: INFO: (0) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 24.874997ms)
Apr 23 11:50:10.928: INFO: (0) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 30.62827ms)
Apr 23 11:50:10.933: INFO: (0) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 35.872942ms)
Apr 23 11:50:10.938: INFO: (0) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 40.967836ms)
Apr 23 11:50:10.939: INFO: (0) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 42.189862ms)
Apr 23 11:50:10.941: INFO: (0) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 44.293035ms)
Apr 23 11:50:10.941: INFO: (0) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 44.273157ms)
Apr 23 11:50:10.942: INFO: (0) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 44.695599ms)
Apr 23 11:50:10.942: INFO: (0) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 44.499805ms)
Apr 23 11:50:10.942: INFO: (0) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 45.252738ms)
Apr 23 11:50:10.943: INFO: (0) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 45.201116ms)
Apr 23 11:50:10.943: INFO: (0) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 45.749527ms)
Apr 23 11:50:10.943: INFO: (0) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 46.572541ms)
Apr 23 11:50:10.947: INFO: (0) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 50.004007ms)
Apr 23 11:50:10.952: INFO: (0) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 54.416255ms)
Apr 23 11:50:10.967: INFO: (1) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 13.107395ms)
Apr 23 11:50:10.967: INFO: (1) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 13.282596ms)
Apr 23 11:50:10.968: INFO: (1) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 15.298563ms)
Apr 23 11:50:10.970: INFO: (1) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 16.57882ms)
Apr 23 11:50:10.970: INFO: (1) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 17.092187ms)
Apr 23 11:50:10.977: INFO: (1) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 24.008764ms)
Apr 23 11:50:10.978: INFO: (1) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 24.874138ms)
Apr 23 11:50:10.978: INFO: (1) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 25.610419ms)
Apr 23 11:50:10.978: INFO: (1) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 25.513152ms)
Apr 23 11:50:10.982: INFO: (1) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 28.466704ms)
Apr 23 11:50:10.985: INFO: (1) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 31.199101ms)
Apr 23 11:50:10.991: INFO: (1) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 37.63301ms)
Apr 23 11:50:10.996: INFO: (1) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 42.980445ms)
Apr 23 11:50:10.999: INFO: (1) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 45.727031ms)
Apr 23 11:50:11.000: INFO: (1) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 46.300882ms)
Apr 23 11:50:11.000: INFO: (1) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 46.236675ms)
Apr 23 11:50:11.024: INFO: (2) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 22.289996ms)
Apr 23 11:50:11.024: INFO: (2) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 23.134034ms)
Apr 23 11:50:11.058: INFO: (2) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 56.248569ms)
Apr 23 11:50:11.064: INFO: (2) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 64.060691ms)
Apr 23 11:50:11.083: INFO: (2) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 81.976073ms)
Apr 23 11:50:11.083: INFO: (2) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 80.337989ms)
Apr 23 11:50:11.083: INFO: (2) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 80.170632ms)
Apr 23 11:50:11.083: INFO: (2) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 80.173441ms)
Apr 23 11:50:11.085: INFO: (2) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 81.969448ms)
Apr 23 11:50:11.092: INFO: (2) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 90.785294ms)
Apr 23 11:50:11.094: INFO: (2) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 91.934446ms)
Apr 23 11:50:11.094: INFO: (2) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 91.933052ms)
Apr 23 11:50:11.094: INFO: (2) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 93.93698ms)
Apr 23 11:50:11.094: INFO: (2) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 93.172999ms)
Apr 23 11:50:11.094: INFO: (2) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 93.583937ms)
Apr 23 11:50:11.096: INFO: (2) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 94.858699ms)
Apr 23 11:50:11.144: INFO: (3) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 39.613344ms)
Apr 23 11:50:11.151: INFO: (3) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 53.915978ms)
Apr 23 11:50:11.152: INFO: (3) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 45.555981ms)
Apr 23 11:50:11.152: INFO: (3) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 47.574887ms)
Apr 23 11:50:11.152: INFO: (3) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 46.377444ms)
Apr 23 11:50:11.152: INFO: (3) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 47.167278ms)
Apr 23 11:50:11.155: INFO: (3) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 48.75353ms)
Apr 23 11:50:11.155: INFO: (3) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 48.674668ms)
Apr 23 11:50:11.155: INFO: (3) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 50.097076ms)
Apr 23 11:50:11.155: INFO: (3) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 49.781526ms)
Apr 23 11:50:11.156: INFO: (3) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 50.271708ms)
Apr 23 11:50:11.157: INFO: (3) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 50.757902ms)
Apr 23 11:50:11.157: INFO: (3) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 52.473096ms)
Apr 23 11:50:11.159: INFO: (3) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 53.615828ms)
Apr 23 11:50:11.159: INFO: (3) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 53.482596ms)
Apr 23 11:50:11.159: INFO: (3) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 54.687422ms)
Apr 23 11:50:11.172: INFO: (4) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 12.744438ms)
Apr 23 11:50:11.173: INFO: (4) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 12.821031ms)
Apr 23 11:50:11.181: INFO: (4) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 21.393256ms)
Apr 23 11:50:11.189: INFO: (4) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 28.905714ms)
Apr 23 11:50:11.190: INFO: (4) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 30.921252ms)
Apr 23 11:50:11.191: INFO: (4) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 30.406716ms)
Apr 23 11:50:11.191: INFO: (4) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 31.193667ms)
Apr 23 11:50:11.193: INFO: (4) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 33.673224ms)
Apr 23 11:50:11.196: INFO: (4) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 35.403344ms)
Apr 23 11:50:11.196: INFO: (4) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 35.826991ms)
Apr 23 11:50:11.196: INFO: (4) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 35.747459ms)
Apr 23 11:50:11.196: INFO: (4) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 35.341884ms)
Apr 23 11:50:11.196: INFO: (4) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 35.836283ms)
Apr 23 11:50:11.197: INFO: (4) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 36.630333ms)
Apr 23 11:50:11.197: INFO: (4) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 37.017933ms)
Apr 23 11:50:11.199: INFO: (4) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 38.629782ms)
Apr 23 11:50:11.214: INFO: (5) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 14.809022ms)
Apr 23 11:50:11.215: INFO: (5) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 16.03581ms)
Apr 23 11:50:11.215: INFO: (5) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 16.230083ms)
Apr 23 11:50:11.217: INFO: (5) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 17.277691ms)
Apr 23 11:50:11.217: INFO: (5) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 17.874112ms)
Apr 23 11:50:11.217: INFO: (5) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 17.485367ms)
Apr 23 11:50:11.224: INFO: (5) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 24.86981ms)
Apr 23 11:50:11.226: INFO: (5) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 26.502619ms)
Apr 23 11:50:11.227: INFO: (5) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 27.249262ms)
Apr 23 11:50:11.228: INFO: (5) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 27.984497ms)
Apr 23 11:50:11.229: INFO: (5) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 28.916344ms)
Apr 23 11:50:11.229: INFO: (5) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 29.175736ms)
Apr 23 11:50:11.229: INFO: (5) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 29.097934ms)
Apr 23 11:50:11.229: INFO: (5) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 29.514983ms)
Apr 23 11:50:11.229: INFO: (5) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 29.9534ms)
Apr 23 11:50:11.231: INFO: (5) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 31.441992ms)
Apr 23 11:50:11.254: INFO: (6) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 22.282793ms)
Apr 23 11:50:11.256: INFO: (6) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 23.785186ms)
Apr 23 11:50:11.256: INFO: (6) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 24.204208ms)
Apr 23 11:50:11.256: INFO: (6) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 23.999046ms)
Apr 23 11:50:11.257: INFO: (6) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 25.363873ms)
Apr 23 11:50:11.258: INFO: (6) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 27.128614ms)
Apr 23 11:50:11.260: INFO: (6) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 27.601027ms)
Apr 23 11:50:11.261: INFO: (6) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 28.392752ms)
Apr 23 11:50:11.261: INFO: (6) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 28.581704ms)
Apr 23 11:50:11.261: INFO: (6) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 28.224512ms)
Apr 23 11:50:11.261: INFO: (6) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 28.61789ms)
Apr 23 11:50:11.262: INFO: (6) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 29.058217ms)
Apr 23 11:50:11.262: INFO: (6) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 29.388389ms)
Apr 23 11:50:11.263: INFO: (6) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 30.555619ms)
Apr 23 11:50:11.263: INFO: (6) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 30.499953ms)
Apr 23 11:50:11.263: INFO: (6) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 31.065149ms)
Apr 23 11:50:11.276: INFO: (7) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 13.309768ms)
Apr 23 11:50:11.277: INFO: (7) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 13.994222ms)
Apr 23 11:50:11.277: INFO: (7) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 14.253087ms)
Apr 23 11:50:11.277: INFO: (7) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 13.018864ms)
Apr 23 11:50:11.277: INFO: (7) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 13.483408ms)
Apr 23 11:50:11.278: INFO: (7) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 13.583152ms)
Apr 23 11:50:11.299: INFO: (7) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 34.880295ms)
Apr 23 11:50:11.299: INFO: (7) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 34.839735ms)
Apr 23 11:50:11.306: INFO: (7) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 42.442103ms)
Apr 23 11:50:11.306: INFO: (7) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 41.218653ms)
Apr 23 11:50:11.306: INFO: (7) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 42.300206ms)
Apr 23 11:50:11.306: INFO: (7) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 41.4592ms)
Apr 23 11:50:11.306: INFO: (7) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 41.321569ms)
Apr 23 11:50:11.306: INFO: (7) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 41.558274ms)
Apr 23 11:50:11.306: INFO: (7) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 42.41273ms)
Apr 23 11:50:11.321: INFO: (7) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 55.695418ms)
Apr 23 11:50:11.332: INFO: (8) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 9.860597ms)
Apr 23 11:50:11.333: INFO: (8) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 11.720225ms)
Apr 23 11:50:11.333: INFO: (8) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 10.979645ms)
Apr 23 11:50:11.360: INFO: (8) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 35.958713ms)
Apr 23 11:50:11.361: INFO: (8) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 38.425995ms)
Apr 23 11:50:11.361: INFO: (8) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 37.255729ms)
Apr 23 11:50:11.363: INFO: (8) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 38.601469ms)
Apr 23 11:50:11.364: INFO: (8) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 40.347563ms)
Apr 23 11:50:11.365: INFO: (8) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 41.897542ms)
Apr 23 11:50:11.373: INFO: (8) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 50.134867ms)
Apr 23 11:50:11.392: INFO: (8) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 69.036229ms)
Apr 23 11:50:11.402: INFO: (8) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 77.456599ms)
Apr 23 11:50:11.402: INFO: (8) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 78.458255ms)
Apr 23 11:50:11.403: INFO: (8) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 79.162912ms)
Apr 23 11:50:11.403: INFO: (8) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 81.180894ms)
Apr 23 11:50:11.405: INFO: (8) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 83.493188ms)
Apr 23 11:50:11.428: INFO: (9) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 23.073909ms)
Apr 23 11:50:11.428: INFO: (9) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 22.160641ms)
Apr 23 11:50:11.429: INFO: (9) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 22.039321ms)
Apr 23 11:50:11.430: INFO: (9) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 23.326306ms)
Apr 23 11:50:11.430: INFO: (9) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 24.333671ms)
Apr 23 11:50:11.440: INFO: (9) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 34.654628ms)
Apr 23 11:50:11.441: INFO: (9) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 34.739832ms)
Apr 23 11:50:11.441: INFO: (9) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 34.660379ms)
Apr 23 11:50:11.441: INFO: (9) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 35.726045ms)
Apr 23 11:50:11.441: INFO: (9) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 33.906084ms)
Apr 23 11:50:11.442: INFO: (9) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 34.897581ms)
Apr 23 11:50:11.442: INFO: (9) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 34.885988ms)
Apr 23 11:50:11.443: INFO: (9) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 36.381517ms)
Apr 23 11:50:11.444: INFO: (9) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 37.942942ms)
Apr 23 11:50:11.444: INFO: (9) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 38.271085ms)
Apr 23 11:50:11.445: INFO: (9) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 38.614891ms)
Apr 23 11:50:11.468: INFO: (10) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 21.679832ms)
Apr 23 11:50:11.468: INFO: (10) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 22.098439ms)
Apr 23 11:50:11.475: INFO: (10) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 27.517774ms)
Apr 23 11:50:11.475: INFO: (10) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 28.754008ms)
Apr 23 11:50:11.486: INFO: (10) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 39.81136ms)
Apr 23 11:50:11.493: INFO: (10) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 45.238889ms)
Apr 23 11:50:11.493: INFO: (10) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 46.514194ms)
Apr 23 11:50:11.494: INFO: (10) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 48.47769ms)
Apr 23 11:50:11.495: INFO: (10) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 47.831268ms)
Apr 23 11:50:11.515: INFO: (10) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 68.0101ms)
Apr 23 11:50:11.516: INFO: (10) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 69.641777ms)
Apr 23 11:50:11.517: INFO: (10) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 68.830962ms)
Apr 23 11:50:11.518: INFO: (10) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 70.98215ms)
Apr 23 11:50:11.548: INFO: (10) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 101.151214ms)
Apr 23 11:50:11.555: INFO: (10) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 107.580771ms)
Apr 23 11:50:11.562: INFO: (10) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 116.387852ms)
Apr 23 11:50:11.579: INFO: (11) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 16.41098ms)
Apr 23 11:50:11.579: INFO: (11) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 16.884602ms)
Apr 23 11:50:11.593: INFO: (11) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 29.726805ms)
Apr 23 11:50:11.594: INFO: (11) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 29.28784ms)
Apr 23 11:50:11.594: INFO: (11) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 31.662763ms)
Apr 23 11:50:11.594: INFO: (11) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 31.409337ms)
Apr 23 11:50:11.601: INFO: (11) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 37.432719ms)
Apr 23 11:50:11.601: INFO: (11) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 38.134395ms)
Apr 23 11:50:11.601: INFO: (11) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 38.340009ms)
Apr 23 11:50:11.602: INFO: (11) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 38.86511ms)
Apr 23 11:50:11.618: INFO: (11) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 55.100235ms)
Apr 23 11:50:11.618: INFO: (11) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 54.722107ms)
Apr 23 11:50:11.618: INFO: (11) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 53.894237ms)
Apr 23 11:50:11.618: INFO: (11) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 54.145606ms)
Apr 23 11:50:11.625: INFO: (11) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 60.879337ms)
Apr 23 11:50:11.625: INFO: (11) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 61.595089ms)
Apr 23 11:50:11.640: INFO: (12) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 14.677067ms)
Apr 23 11:50:11.640: INFO: (12) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 14.594603ms)
Apr 23 11:50:11.646: INFO: (12) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 21.230639ms)
Apr 23 11:50:11.648: INFO: (12) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 22.070814ms)
Apr 23 11:50:11.649: INFO: (12) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 23.547793ms)
Apr 23 11:50:11.649: INFO: (12) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 23.675401ms)
Apr 23 11:50:11.652: INFO: (12) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 26.081032ms)
Apr 23 11:50:11.652: INFO: (12) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 26.830283ms)
Apr 23 11:50:11.654: INFO: (12) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 28.125431ms)
Apr 23 11:50:11.656: INFO: (12) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 31.217689ms)
Apr 23 11:50:11.657: INFO: (12) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 31.295962ms)
Apr 23 11:50:11.657: INFO: (12) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 31.218565ms)
Apr 23 11:50:11.659: INFO: (12) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 32.945463ms)
Apr 23 11:50:11.659: INFO: (12) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 33.091939ms)
Apr 23 11:50:11.659: INFO: (12) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 33.814539ms)
Apr 23 11:50:11.659: INFO: (12) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 33.724015ms)
Apr 23 11:50:11.675: INFO: (13) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 14.436567ms)
Apr 23 11:50:11.678: INFO: (13) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 16.142578ms)
Apr 23 11:50:11.679: INFO: (13) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 18.690728ms)
Apr 23 11:50:11.679: INFO: (13) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 17.127025ms)
Apr 23 11:50:11.685: INFO: (13) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 23.83505ms)
Apr 23 11:50:11.686: INFO: (13) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 25.240792ms)
Apr 23 11:50:11.687: INFO: (13) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 27.969445ms)
Apr 23 11:50:11.689: INFO: (13) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 27.148441ms)
Apr 23 11:50:11.689: INFO: (13) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 29.225412ms)
Apr 23 11:50:11.690: INFO: (13) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 30.642628ms)
Apr 23 11:50:11.691: INFO: (13) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 30.672742ms)
Apr 23 11:50:11.691: INFO: (13) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 29.722433ms)
Apr 23 11:50:11.691: INFO: (13) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 29.956503ms)
Apr 23 11:50:11.691: INFO: (13) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 30.395186ms)
Apr 23 11:50:11.691: INFO: (13) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 30.567977ms)
Apr 23 11:50:11.701: INFO: (13) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 40.404642ms)
Apr 23 11:50:11.728: INFO: (14) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 25.942096ms)
Apr 23 11:50:11.728: INFO: (14) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 26.182392ms)
Apr 23 11:50:11.728: INFO: (14) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 26.050433ms)
Apr 23 11:50:11.760: INFO: (14) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 57.703233ms)
Apr 23 11:50:11.762: INFO: (14) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 59.029861ms)
Apr 23 11:50:11.763: INFO: (14) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 59.346223ms)
Apr 23 11:50:11.763: INFO: (14) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 62.254387ms)
Apr 23 11:50:11.763: INFO: (14) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 60.216184ms)
Apr 23 11:50:11.772: INFO: (14) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 69.760888ms)
Apr 23 11:50:11.775: INFO: (14) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 71.980043ms)
Apr 23 11:50:11.782: INFO: (14) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 79.770163ms)
Apr 23 11:50:11.782: INFO: (14) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 78.364334ms)
Apr 23 11:50:11.784: INFO: (14) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 82.316622ms)
Apr 23 11:50:11.784: INFO: (14) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 80.84046ms)
Apr 23 11:50:11.786: INFO: (14) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 84.055349ms)
Apr 23 11:50:11.793: INFO: (14) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 90.819252ms)
Apr 23 11:50:11.813: INFO: (15) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 18.598486ms)
Apr 23 11:50:11.813: INFO: (15) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 19.751508ms)
Apr 23 11:50:11.821: INFO: (15) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 26.850747ms)
Apr 23 11:50:11.823: INFO: (15) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 27.140553ms)
Apr 23 11:50:11.826: INFO: (15) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 30.992499ms)
Apr 23 11:50:11.826: INFO: (15) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 32.475537ms)
Apr 23 11:50:11.826: INFO: (15) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 29.755437ms)
Apr 23 11:50:11.827: INFO: (15) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 33.302556ms)
Apr 23 11:50:11.827: INFO: (15) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 33.150135ms)
Apr 23 11:50:11.864: INFO: (15) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 69.468857ms)
Apr 23 11:50:11.864: INFO: (15) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 69.874578ms)
Apr 23 11:50:11.864: INFO: (15) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 69.097236ms)
Apr 23 11:50:11.864: INFO: (15) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 70.113773ms)
Apr 23 11:50:11.865: INFO: (15) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 69.391178ms)
Apr 23 11:50:11.868: INFO: (15) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 71.478563ms)
Apr 23 11:50:11.873: INFO: (15) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 77.148419ms)
Apr 23 11:50:11.889: INFO: (16) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 15.706793ms)
Apr 23 11:50:11.891: INFO: (16) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 18.504127ms)
Apr 23 11:50:11.891: INFO: (16) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 17.408238ms)
Apr 23 11:50:11.894: INFO: (16) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 20.041587ms)
Apr 23 11:50:11.894: INFO: (16) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 19.205016ms)
Apr 23 11:50:11.894: INFO: (16) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 20.272561ms)
Apr 23 11:50:11.898: INFO: (16) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 24.068189ms)
Apr 23 11:50:11.901: INFO: (16) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 25.948491ms)
Apr 23 11:50:11.904: INFO: (16) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 28.549021ms)
Apr 23 11:50:11.908: INFO: (16) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 33.727866ms)
Apr 23 11:50:11.919: INFO: (16) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 45.855617ms)
Apr 23 11:50:11.919: INFO: (16) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 44.658542ms)
Apr 23 11:50:11.919: INFO: (16) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 46.219252ms)
Apr 23 11:50:11.919: INFO: (16) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 45.402139ms)
Apr 23 11:50:11.919: INFO: (16) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 45.785121ms)
Apr 23 11:50:11.919: INFO: (16) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 44.325218ms)
Apr 23 11:50:11.930: INFO: (17) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 9.313911ms)
Apr 23 11:50:11.932: INFO: (17) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 12.471275ms)
Apr 23 11:50:11.951: INFO: (17) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 28.174107ms)
Apr 23 11:50:11.951: INFO: (17) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 30.49644ms)
Apr 23 11:50:11.951: INFO: (17) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 28.772027ms)
Apr 23 11:50:11.951: INFO: (17) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 28.412618ms)
Apr 23 11:50:11.951: INFO: (17) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 31.209899ms)
Apr 23 11:50:11.952: INFO: (17) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 32.318714ms)
Apr 23 11:50:11.952: INFO: (17) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 30.913736ms)
Apr 23 11:50:11.953: INFO: (17) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 30.834658ms)
Apr 23 11:50:11.953: INFO: (17) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 31.546649ms)
Apr 23 11:50:11.953: INFO: (17) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 32.949456ms)
Apr 23 11:50:11.954: INFO: (17) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 31.594289ms)
Apr 23 11:50:11.954: INFO: (17) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 34.760017ms)
Apr 23 11:50:11.957: INFO: (17) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 35.058536ms)
Apr 23 11:50:11.958: INFO: (17) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 38.31297ms)
Apr 23 11:50:11.968: INFO: (18) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 9.904555ms)
Apr 23 11:50:11.978: INFO: (18) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 18.867202ms)
Apr 23 11:50:11.979: INFO: (18) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 19.250457ms)
Apr 23 11:50:11.980: INFO: (18) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 21.029507ms)
Apr 23 11:50:11.980: INFO: (18) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 19.776816ms)
Apr 23 11:50:11.981: INFO: (18) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 20.435853ms)
Apr 23 11:50:11.981: INFO: (18) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 22.120187ms)
Apr 23 11:50:11.983: INFO: (18) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 21.436814ms)
Apr 23 11:50:11.983: INFO: (18) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 22.945976ms)
Apr 23 11:50:11.985: INFO: (18) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 25.740915ms)
Apr 23 11:50:11.987: INFO: (18) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 28.652873ms)
Apr 23 11:50:11.989: INFO: (18) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 28.548595ms)
Apr 23 11:50:11.990: INFO: (18) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 29.013971ms)
Apr 23 11:50:11.993: INFO: (18) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 33.761794ms)
Apr 23 11:50:11.999: INFO: (18) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 39.851228ms)
Apr 23 11:50:12.004: INFO: (18) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 43.716271ms)
Apr 23 11:50:12.032: INFO: (19) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 28.01475ms)
Apr 23 11:50:12.037: INFO: (19) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 33.277375ms)
Apr 23 11:50:12.039: INFO: (19) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 33.660703ms)
Apr 23 11:50:12.040: INFO: (19) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 35.168575ms)
Apr 23 11:50:12.040: INFO: (19) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 35.573381ms)
Apr 23 11:50:12.045: INFO: (19) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 39.374198ms)
Apr 23 11:50:12.046: INFO: (19) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 40.866143ms)
Apr 23 11:50:12.048: INFO: (19) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 42.854562ms)
Apr 23 11:50:12.048: INFO: (19) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 41.867194ms)
Apr 23 11:50:12.050: INFO: (19) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 44.230116ms)
Apr 23 11:50:12.050: INFO: (19) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 43.804557ms)
Apr 23 11:50:12.050: INFO: (19) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 44.268055ms)
Apr 23 11:50:12.051: INFO: (19) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 46.2929ms)
Apr 23 11:50:12.052: INFO: (19) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 47.070101ms)
Apr 23 11:50:12.067: INFO: (19) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 61.360057ms)
Apr 23 11:50:12.067: INFO: (19) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 60.686673ms)
STEP: deleting ReplicationController proxy-service-h5rg6 in namespace proxy-157, will wait for the garbage collector to delete the pods 04/23/23 11:50:12.068
Apr 23 11:50:12.146: INFO: Deleting ReplicationController proxy-service-h5rg6 took: 16.633631ms
Apr 23 11:50:12.247: INFO: Terminating ReplicationController proxy-service-h5rg6 pods took: 101.137924ms
[AfterEach] version v1
  test/e2e/framework/node/init/init.go:32
Apr 23 11:50:14.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] version v1
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] version v1
  dump namespaces | framework.go:196
[DeferCleanup (Each)] version v1
  tear down framework | framework.go:193
STEP: Destroying namespace "proxy-157" for this suite. 04/23/23 11:50:14.87
------------------------------
â€¢ [SLOW TEST] [7.186 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:50:07.706
    Apr 23 11:50:07.706: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename proxy 04/23/23 11:50:07.72
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:50:07.77
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:50:07.78
    [BeforeEach] version v1
      test/e2e/framework/metrics/init/init.go:31
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 04/23/23 11:50:07.81
    STEP: creating replication controller proxy-service-h5rg6 in namespace proxy-157 04/23/23 11:50:07.811
    I0423 11:50:07.827871      13 runners.go:193] Created replication controller with name: proxy-service-h5rg6, namespace: proxy-157, replica count: 1
    I0423 11:50:08.879145      13 runners.go:193] proxy-service-h5rg6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:50:09.881986      13 runners.go:193] proxy-service-h5rg6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0423 11:50:10.882419      13 runners.go:193] proxy-service-h5rg6 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 23 11:50:10.895: INFO: setup took 3.101940271s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 04/23/23 11:50:10.896
    Apr 23 11:50:10.923: INFO: (0) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 25.623228ms)
    Apr 23 11:50:10.923: INFO: (0) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 24.874997ms)
    Apr 23 11:50:10.928: INFO: (0) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 30.62827ms)
    Apr 23 11:50:10.933: INFO: (0) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 35.872942ms)
    Apr 23 11:50:10.938: INFO: (0) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 40.967836ms)
    Apr 23 11:50:10.939: INFO: (0) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 42.189862ms)
    Apr 23 11:50:10.941: INFO: (0) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 44.293035ms)
    Apr 23 11:50:10.941: INFO: (0) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 44.273157ms)
    Apr 23 11:50:10.942: INFO: (0) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 44.695599ms)
    Apr 23 11:50:10.942: INFO: (0) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 44.499805ms)
    Apr 23 11:50:10.942: INFO: (0) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 45.252738ms)
    Apr 23 11:50:10.943: INFO: (0) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 45.201116ms)
    Apr 23 11:50:10.943: INFO: (0) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 45.749527ms)
    Apr 23 11:50:10.943: INFO: (0) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 46.572541ms)
    Apr 23 11:50:10.947: INFO: (0) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 50.004007ms)
    Apr 23 11:50:10.952: INFO: (0) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 54.416255ms)
    Apr 23 11:50:10.967: INFO: (1) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 13.107395ms)
    Apr 23 11:50:10.967: INFO: (1) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 13.282596ms)
    Apr 23 11:50:10.968: INFO: (1) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 15.298563ms)
    Apr 23 11:50:10.970: INFO: (1) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 16.57882ms)
    Apr 23 11:50:10.970: INFO: (1) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 17.092187ms)
    Apr 23 11:50:10.977: INFO: (1) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 24.008764ms)
    Apr 23 11:50:10.978: INFO: (1) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 24.874138ms)
    Apr 23 11:50:10.978: INFO: (1) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 25.610419ms)
    Apr 23 11:50:10.978: INFO: (1) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 25.513152ms)
    Apr 23 11:50:10.982: INFO: (1) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 28.466704ms)
    Apr 23 11:50:10.985: INFO: (1) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 31.199101ms)
    Apr 23 11:50:10.991: INFO: (1) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 37.63301ms)
    Apr 23 11:50:10.996: INFO: (1) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 42.980445ms)
    Apr 23 11:50:10.999: INFO: (1) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 45.727031ms)
    Apr 23 11:50:11.000: INFO: (1) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 46.300882ms)
    Apr 23 11:50:11.000: INFO: (1) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 46.236675ms)
    Apr 23 11:50:11.024: INFO: (2) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 22.289996ms)
    Apr 23 11:50:11.024: INFO: (2) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 23.134034ms)
    Apr 23 11:50:11.058: INFO: (2) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 56.248569ms)
    Apr 23 11:50:11.064: INFO: (2) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 64.060691ms)
    Apr 23 11:50:11.083: INFO: (2) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 81.976073ms)
    Apr 23 11:50:11.083: INFO: (2) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 80.337989ms)
    Apr 23 11:50:11.083: INFO: (2) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 80.170632ms)
    Apr 23 11:50:11.083: INFO: (2) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 80.173441ms)
    Apr 23 11:50:11.085: INFO: (2) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 81.969448ms)
    Apr 23 11:50:11.092: INFO: (2) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 90.785294ms)
    Apr 23 11:50:11.094: INFO: (2) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 91.934446ms)
    Apr 23 11:50:11.094: INFO: (2) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 91.933052ms)
    Apr 23 11:50:11.094: INFO: (2) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 93.93698ms)
    Apr 23 11:50:11.094: INFO: (2) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 93.172999ms)
    Apr 23 11:50:11.094: INFO: (2) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 93.583937ms)
    Apr 23 11:50:11.096: INFO: (2) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 94.858699ms)
    Apr 23 11:50:11.144: INFO: (3) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 39.613344ms)
    Apr 23 11:50:11.151: INFO: (3) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 53.915978ms)
    Apr 23 11:50:11.152: INFO: (3) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 45.555981ms)
    Apr 23 11:50:11.152: INFO: (3) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 47.574887ms)
    Apr 23 11:50:11.152: INFO: (3) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 46.377444ms)
    Apr 23 11:50:11.152: INFO: (3) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 47.167278ms)
    Apr 23 11:50:11.155: INFO: (3) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 48.75353ms)
    Apr 23 11:50:11.155: INFO: (3) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 48.674668ms)
    Apr 23 11:50:11.155: INFO: (3) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 50.097076ms)
    Apr 23 11:50:11.155: INFO: (3) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 49.781526ms)
    Apr 23 11:50:11.156: INFO: (3) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 50.271708ms)
    Apr 23 11:50:11.157: INFO: (3) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 50.757902ms)
    Apr 23 11:50:11.157: INFO: (3) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 52.473096ms)
    Apr 23 11:50:11.159: INFO: (3) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 53.615828ms)
    Apr 23 11:50:11.159: INFO: (3) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 53.482596ms)
    Apr 23 11:50:11.159: INFO: (3) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 54.687422ms)
    Apr 23 11:50:11.172: INFO: (4) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 12.744438ms)
    Apr 23 11:50:11.173: INFO: (4) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 12.821031ms)
    Apr 23 11:50:11.181: INFO: (4) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 21.393256ms)
    Apr 23 11:50:11.189: INFO: (4) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 28.905714ms)
    Apr 23 11:50:11.190: INFO: (4) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 30.921252ms)
    Apr 23 11:50:11.191: INFO: (4) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 30.406716ms)
    Apr 23 11:50:11.191: INFO: (4) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 31.193667ms)
    Apr 23 11:50:11.193: INFO: (4) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 33.673224ms)
    Apr 23 11:50:11.196: INFO: (4) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 35.403344ms)
    Apr 23 11:50:11.196: INFO: (4) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 35.826991ms)
    Apr 23 11:50:11.196: INFO: (4) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 35.747459ms)
    Apr 23 11:50:11.196: INFO: (4) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 35.341884ms)
    Apr 23 11:50:11.196: INFO: (4) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 35.836283ms)
    Apr 23 11:50:11.197: INFO: (4) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 36.630333ms)
    Apr 23 11:50:11.197: INFO: (4) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 37.017933ms)
    Apr 23 11:50:11.199: INFO: (4) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 38.629782ms)
    Apr 23 11:50:11.214: INFO: (5) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 14.809022ms)
    Apr 23 11:50:11.215: INFO: (5) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 16.03581ms)
    Apr 23 11:50:11.215: INFO: (5) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 16.230083ms)
    Apr 23 11:50:11.217: INFO: (5) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 17.277691ms)
    Apr 23 11:50:11.217: INFO: (5) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 17.874112ms)
    Apr 23 11:50:11.217: INFO: (5) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 17.485367ms)
    Apr 23 11:50:11.224: INFO: (5) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 24.86981ms)
    Apr 23 11:50:11.226: INFO: (5) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 26.502619ms)
    Apr 23 11:50:11.227: INFO: (5) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 27.249262ms)
    Apr 23 11:50:11.228: INFO: (5) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 27.984497ms)
    Apr 23 11:50:11.229: INFO: (5) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 28.916344ms)
    Apr 23 11:50:11.229: INFO: (5) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 29.175736ms)
    Apr 23 11:50:11.229: INFO: (5) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 29.097934ms)
    Apr 23 11:50:11.229: INFO: (5) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 29.514983ms)
    Apr 23 11:50:11.229: INFO: (5) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 29.9534ms)
    Apr 23 11:50:11.231: INFO: (5) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 31.441992ms)
    Apr 23 11:50:11.254: INFO: (6) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 22.282793ms)
    Apr 23 11:50:11.256: INFO: (6) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 23.785186ms)
    Apr 23 11:50:11.256: INFO: (6) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 24.204208ms)
    Apr 23 11:50:11.256: INFO: (6) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 23.999046ms)
    Apr 23 11:50:11.257: INFO: (6) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 25.363873ms)
    Apr 23 11:50:11.258: INFO: (6) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 27.128614ms)
    Apr 23 11:50:11.260: INFO: (6) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 27.601027ms)
    Apr 23 11:50:11.261: INFO: (6) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 28.392752ms)
    Apr 23 11:50:11.261: INFO: (6) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 28.581704ms)
    Apr 23 11:50:11.261: INFO: (6) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 28.224512ms)
    Apr 23 11:50:11.261: INFO: (6) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 28.61789ms)
    Apr 23 11:50:11.262: INFO: (6) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 29.058217ms)
    Apr 23 11:50:11.262: INFO: (6) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 29.388389ms)
    Apr 23 11:50:11.263: INFO: (6) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 30.555619ms)
    Apr 23 11:50:11.263: INFO: (6) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 30.499953ms)
    Apr 23 11:50:11.263: INFO: (6) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 31.065149ms)
    Apr 23 11:50:11.276: INFO: (7) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 13.309768ms)
    Apr 23 11:50:11.277: INFO: (7) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 13.994222ms)
    Apr 23 11:50:11.277: INFO: (7) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 14.253087ms)
    Apr 23 11:50:11.277: INFO: (7) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 13.018864ms)
    Apr 23 11:50:11.277: INFO: (7) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 13.483408ms)
    Apr 23 11:50:11.278: INFO: (7) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 13.583152ms)
    Apr 23 11:50:11.299: INFO: (7) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 34.880295ms)
    Apr 23 11:50:11.299: INFO: (7) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 34.839735ms)
    Apr 23 11:50:11.306: INFO: (7) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 42.442103ms)
    Apr 23 11:50:11.306: INFO: (7) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 41.218653ms)
    Apr 23 11:50:11.306: INFO: (7) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 42.300206ms)
    Apr 23 11:50:11.306: INFO: (7) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 41.4592ms)
    Apr 23 11:50:11.306: INFO: (7) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 41.321569ms)
    Apr 23 11:50:11.306: INFO: (7) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 41.558274ms)
    Apr 23 11:50:11.306: INFO: (7) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 42.41273ms)
    Apr 23 11:50:11.321: INFO: (7) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 55.695418ms)
    Apr 23 11:50:11.332: INFO: (8) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 9.860597ms)
    Apr 23 11:50:11.333: INFO: (8) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 11.720225ms)
    Apr 23 11:50:11.333: INFO: (8) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 10.979645ms)
    Apr 23 11:50:11.360: INFO: (8) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 35.958713ms)
    Apr 23 11:50:11.361: INFO: (8) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 38.425995ms)
    Apr 23 11:50:11.361: INFO: (8) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 37.255729ms)
    Apr 23 11:50:11.363: INFO: (8) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 38.601469ms)
    Apr 23 11:50:11.364: INFO: (8) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 40.347563ms)
    Apr 23 11:50:11.365: INFO: (8) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 41.897542ms)
    Apr 23 11:50:11.373: INFO: (8) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 50.134867ms)
    Apr 23 11:50:11.392: INFO: (8) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 69.036229ms)
    Apr 23 11:50:11.402: INFO: (8) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 77.456599ms)
    Apr 23 11:50:11.402: INFO: (8) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 78.458255ms)
    Apr 23 11:50:11.403: INFO: (8) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 79.162912ms)
    Apr 23 11:50:11.403: INFO: (8) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 81.180894ms)
    Apr 23 11:50:11.405: INFO: (8) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 83.493188ms)
    Apr 23 11:50:11.428: INFO: (9) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 23.073909ms)
    Apr 23 11:50:11.428: INFO: (9) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 22.160641ms)
    Apr 23 11:50:11.429: INFO: (9) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 22.039321ms)
    Apr 23 11:50:11.430: INFO: (9) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 23.326306ms)
    Apr 23 11:50:11.430: INFO: (9) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 24.333671ms)
    Apr 23 11:50:11.440: INFO: (9) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 34.654628ms)
    Apr 23 11:50:11.441: INFO: (9) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 34.739832ms)
    Apr 23 11:50:11.441: INFO: (9) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 34.660379ms)
    Apr 23 11:50:11.441: INFO: (9) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 35.726045ms)
    Apr 23 11:50:11.441: INFO: (9) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 33.906084ms)
    Apr 23 11:50:11.442: INFO: (9) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 34.897581ms)
    Apr 23 11:50:11.442: INFO: (9) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 34.885988ms)
    Apr 23 11:50:11.443: INFO: (9) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 36.381517ms)
    Apr 23 11:50:11.444: INFO: (9) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 37.942942ms)
    Apr 23 11:50:11.444: INFO: (9) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 38.271085ms)
    Apr 23 11:50:11.445: INFO: (9) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 38.614891ms)
    Apr 23 11:50:11.468: INFO: (10) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 21.679832ms)
    Apr 23 11:50:11.468: INFO: (10) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 22.098439ms)
    Apr 23 11:50:11.475: INFO: (10) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 27.517774ms)
    Apr 23 11:50:11.475: INFO: (10) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 28.754008ms)
    Apr 23 11:50:11.486: INFO: (10) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 39.81136ms)
    Apr 23 11:50:11.493: INFO: (10) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 45.238889ms)
    Apr 23 11:50:11.493: INFO: (10) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 46.514194ms)
    Apr 23 11:50:11.494: INFO: (10) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 48.47769ms)
    Apr 23 11:50:11.495: INFO: (10) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 47.831268ms)
    Apr 23 11:50:11.515: INFO: (10) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 68.0101ms)
    Apr 23 11:50:11.516: INFO: (10) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 69.641777ms)
    Apr 23 11:50:11.517: INFO: (10) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 68.830962ms)
    Apr 23 11:50:11.518: INFO: (10) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 70.98215ms)
    Apr 23 11:50:11.548: INFO: (10) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 101.151214ms)
    Apr 23 11:50:11.555: INFO: (10) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 107.580771ms)
    Apr 23 11:50:11.562: INFO: (10) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 116.387852ms)
    Apr 23 11:50:11.579: INFO: (11) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 16.41098ms)
    Apr 23 11:50:11.579: INFO: (11) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 16.884602ms)
    Apr 23 11:50:11.593: INFO: (11) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 29.726805ms)
    Apr 23 11:50:11.594: INFO: (11) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 29.28784ms)
    Apr 23 11:50:11.594: INFO: (11) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 31.662763ms)
    Apr 23 11:50:11.594: INFO: (11) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 31.409337ms)
    Apr 23 11:50:11.601: INFO: (11) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 37.432719ms)
    Apr 23 11:50:11.601: INFO: (11) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 38.134395ms)
    Apr 23 11:50:11.601: INFO: (11) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 38.340009ms)
    Apr 23 11:50:11.602: INFO: (11) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 38.86511ms)
    Apr 23 11:50:11.618: INFO: (11) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 55.100235ms)
    Apr 23 11:50:11.618: INFO: (11) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 54.722107ms)
    Apr 23 11:50:11.618: INFO: (11) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 53.894237ms)
    Apr 23 11:50:11.618: INFO: (11) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 54.145606ms)
    Apr 23 11:50:11.625: INFO: (11) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 60.879337ms)
    Apr 23 11:50:11.625: INFO: (11) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 61.595089ms)
    Apr 23 11:50:11.640: INFO: (12) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 14.677067ms)
    Apr 23 11:50:11.640: INFO: (12) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 14.594603ms)
    Apr 23 11:50:11.646: INFO: (12) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 21.230639ms)
    Apr 23 11:50:11.648: INFO: (12) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 22.070814ms)
    Apr 23 11:50:11.649: INFO: (12) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 23.547793ms)
    Apr 23 11:50:11.649: INFO: (12) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 23.675401ms)
    Apr 23 11:50:11.652: INFO: (12) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 26.081032ms)
    Apr 23 11:50:11.652: INFO: (12) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 26.830283ms)
    Apr 23 11:50:11.654: INFO: (12) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 28.125431ms)
    Apr 23 11:50:11.656: INFO: (12) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 31.217689ms)
    Apr 23 11:50:11.657: INFO: (12) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 31.295962ms)
    Apr 23 11:50:11.657: INFO: (12) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 31.218565ms)
    Apr 23 11:50:11.659: INFO: (12) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 32.945463ms)
    Apr 23 11:50:11.659: INFO: (12) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 33.091939ms)
    Apr 23 11:50:11.659: INFO: (12) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 33.814539ms)
    Apr 23 11:50:11.659: INFO: (12) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 33.724015ms)
    Apr 23 11:50:11.675: INFO: (13) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 14.436567ms)
    Apr 23 11:50:11.678: INFO: (13) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 16.142578ms)
    Apr 23 11:50:11.679: INFO: (13) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 18.690728ms)
    Apr 23 11:50:11.679: INFO: (13) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 17.127025ms)
    Apr 23 11:50:11.685: INFO: (13) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 23.83505ms)
    Apr 23 11:50:11.686: INFO: (13) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 25.240792ms)
    Apr 23 11:50:11.687: INFO: (13) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 27.969445ms)
    Apr 23 11:50:11.689: INFO: (13) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 27.148441ms)
    Apr 23 11:50:11.689: INFO: (13) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 29.225412ms)
    Apr 23 11:50:11.690: INFO: (13) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 30.642628ms)
    Apr 23 11:50:11.691: INFO: (13) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 30.672742ms)
    Apr 23 11:50:11.691: INFO: (13) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 29.722433ms)
    Apr 23 11:50:11.691: INFO: (13) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 29.956503ms)
    Apr 23 11:50:11.691: INFO: (13) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 30.395186ms)
    Apr 23 11:50:11.691: INFO: (13) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 30.567977ms)
    Apr 23 11:50:11.701: INFO: (13) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 40.404642ms)
    Apr 23 11:50:11.728: INFO: (14) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 25.942096ms)
    Apr 23 11:50:11.728: INFO: (14) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 26.182392ms)
    Apr 23 11:50:11.728: INFO: (14) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 26.050433ms)
    Apr 23 11:50:11.760: INFO: (14) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 57.703233ms)
    Apr 23 11:50:11.762: INFO: (14) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 59.029861ms)
    Apr 23 11:50:11.763: INFO: (14) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 59.346223ms)
    Apr 23 11:50:11.763: INFO: (14) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 62.254387ms)
    Apr 23 11:50:11.763: INFO: (14) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 60.216184ms)
    Apr 23 11:50:11.772: INFO: (14) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 69.760888ms)
    Apr 23 11:50:11.775: INFO: (14) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 71.980043ms)
    Apr 23 11:50:11.782: INFO: (14) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 79.770163ms)
    Apr 23 11:50:11.782: INFO: (14) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 78.364334ms)
    Apr 23 11:50:11.784: INFO: (14) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 82.316622ms)
    Apr 23 11:50:11.784: INFO: (14) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 80.84046ms)
    Apr 23 11:50:11.786: INFO: (14) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 84.055349ms)
    Apr 23 11:50:11.793: INFO: (14) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 90.819252ms)
    Apr 23 11:50:11.813: INFO: (15) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 18.598486ms)
    Apr 23 11:50:11.813: INFO: (15) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 19.751508ms)
    Apr 23 11:50:11.821: INFO: (15) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 26.850747ms)
    Apr 23 11:50:11.823: INFO: (15) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 27.140553ms)
    Apr 23 11:50:11.826: INFO: (15) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 30.992499ms)
    Apr 23 11:50:11.826: INFO: (15) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 32.475537ms)
    Apr 23 11:50:11.826: INFO: (15) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 29.755437ms)
    Apr 23 11:50:11.827: INFO: (15) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 33.302556ms)
    Apr 23 11:50:11.827: INFO: (15) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 33.150135ms)
    Apr 23 11:50:11.864: INFO: (15) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 69.468857ms)
    Apr 23 11:50:11.864: INFO: (15) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 69.874578ms)
    Apr 23 11:50:11.864: INFO: (15) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 69.097236ms)
    Apr 23 11:50:11.864: INFO: (15) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 70.113773ms)
    Apr 23 11:50:11.865: INFO: (15) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 69.391178ms)
    Apr 23 11:50:11.868: INFO: (15) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 71.478563ms)
    Apr 23 11:50:11.873: INFO: (15) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 77.148419ms)
    Apr 23 11:50:11.889: INFO: (16) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 15.706793ms)
    Apr 23 11:50:11.891: INFO: (16) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 18.504127ms)
    Apr 23 11:50:11.891: INFO: (16) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 17.408238ms)
    Apr 23 11:50:11.894: INFO: (16) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 20.041587ms)
    Apr 23 11:50:11.894: INFO: (16) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 19.205016ms)
    Apr 23 11:50:11.894: INFO: (16) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 20.272561ms)
    Apr 23 11:50:11.898: INFO: (16) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 24.068189ms)
    Apr 23 11:50:11.901: INFO: (16) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 25.948491ms)
    Apr 23 11:50:11.904: INFO: (16) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 28.549021ms)
    Apr 23 11:50:11.908: INFO: (16) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 33.727866ms)
    Apr 23 11:50:11.919: INFO: (16) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 45.855617ms)
    Apr 23 11:50:11.919: INFO: (16) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 44.658542ms)
    Apr 23 11:50:11.919: INFO: (16) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 46.219252ms)
    Apr 23 11:50:11.919: INFO: (16) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 45.402139ms)
    Apr 23 11:50:11.919: INFO: (16) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 45.785121ms)
    Apr 23 11:50:11.919: INFO: (16) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 44.325218ms)
    Apr 23 11:50:11.930: INFO: (17) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 9.313911ms)
    Apr 23 11:50:11.932: INFO: (17) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 12.471275ms)
    Apr 23 11:50:11.951: INFO: (17) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 28.174107ms)
    Apr 23 11:50:11.951: INFO: (17) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 30.49644ms)
    Apr 23 11:50:11.951: INFO: (17) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 28.772027ms)
    Apr 23 11:50:11.951: INFO: (17) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 28.412618ms)
    Apr 23 11:50:11.951: INFO: (17) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 31.209899ms)
    Apr 23 11:50:11.952: INFO: (17) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 32.318714ms)
    Apr 23 11:50:11.952: INFO: (17) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 30.913736ms)
    Apr 23 11:50:11.953: INFO: (17) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 30.834658ms)
    Apr 23 11:50:11.953: INFO: (17) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 31.546649ms)
    Apr 23 11:50:11.953: INFO: (17) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 32.949456ms)
    Apr 23 11:50:11.954: INFO: (17) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 31.594289ms)
    Apr 23 11:50:11.954: INFO: (17) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 34.760017ms)
    Apr 23 11:50:11.957: INFO: (17) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 35.058536ms)
    Apr 23 11:50:11.958: INFO: (17) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 38.31297ms)
    Apr 23 11:50:11.968: INFO: (18) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 9.904555ms)
    Apr 23 11:50:11.978: INFO: (18) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 18.867202ms)
    Apr 23 11:50:11.979: INFO: (18) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 19.250457ms)
    Apr 23 11:50:11.980: INFO: (18) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 21.029507ms)
    Apr 23 11:50:11.980: INFO: (18) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 19.776816ms)
    Apr 23 11:50:11.981: INFO: (18) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 20.435853ms)
    Apr 23 11:50:11.981: INFO: (18) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 22.120187ms)
    Apr 23 11:50:11.983: INFO: (18) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 21.436814ms)
    Apr 23 11:50:11.983: INFO: (18) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 22.945976ms)
    Apr 23 11:50:11.985: INFO: (18) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 25.740915ms)
    Apr 23 11:50:11.987: INFO: (18) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 28.652873ms)
    Apr 23 11:50:11.989: INFO: (18) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 28.548595ms)
    Apr 23 11:50:11.990: INFO: (18) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 29.013971ms)
    Apr 23 11:50:11.993: INFO: (18) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 33.761794ms)
    Apr 23 11:50:11.999: INFO: (18) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 39.851228ms)
    Apr 23 11:50:12.004: INFO: (18) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 43.716271ms)
    Apr 23 11:50:12.032: INFO: (19) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:460/proxy/: tls baz (200; 28.01475ms)
    Apr 23 11:50:12.037: INFO: (19) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname2/proxy/: bar (200; 33.277375ms)
    Apr 23 11:50:12.039: INFO: (19) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname1/proxy/: foo (200; 33.660703ms)
    Apr 23 11:50:12.040: INFO: (19) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 35.168575ms)
    Apr 23 11:50:12.040: INFO: (19) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname1/proxy/: tls baz (200; 35.573381ms)
    Apr 23 11:50:12.045: INFO: (19) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">test</... (200; 39.374198ms)
    Apr 23 11:50:12.046: INFO: (19) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:443/proxy/tlsrewriteme... (200; 40.866143ms)
    Apr 23 11:50:12.048: INFO: (19) /api/v1/namespaces/proxy-157/services/http:proxy-service-h5rg6:portname2/proxy/: bar (200; 42.854562ms)
    Apr 23 11:50:12.048: INFO: (19) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 41.867194ms)
    Apr 23 11:50:12.050: INFO: (19) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:1080/proxy/rewriteme">t... (200; 44.230116ms)
    Apr 23 11:50:12.050: INFO: (19) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62:160/proxy/: foo (200; 43.804557ms)
    Apr 23 11:50:12.050: INFO: (19) /api/v1/namespaces/proxy-157/pods/https:proxy-service-h5rg6-4cg62:462/proxy/: tls qux (200; 44.268055ms)
    Apr 23 11:50:12.051: INFO: (19) /api/v1/namespaces/proxy-157/services/proxy-service-h5rg6:portname1/proxy/: foo (200; 46.2929ms)
    Apr 23 11:50:12.052: INFO: (19) /api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/: <a href="/api/v1/namespaces/proxy-157/pods/proxy-service-h5rg6-4cg62/proxy/rewriteme">test</a> (200; 47.070101ms)
    Apr 23 11:50:12.067: INFO: (19) /api/v1/namespaces/proxy-157/services/https:proxy-service-h5rg6:tlsportname2/proxy/: tls qux (200; 61.360057ms)
    Apr 23 11:50:12.067: INFO: (19) /api/v1/namespaces/proxy-157/pods/http:proxy-service-h5rg6-4cg62:162/proxy/: bar (200; 60.686673ms)
    STEP: deleting ReplicationController proxy-service-h5rg6 in namespace proxy-157, will wait for the garbage collector to delete the pods 04/23/23 11:50:12.068
    Apr 23 11:50:12.146: INFO: Deleting ReplicationController proxy-service-h5rg6 took: 16.633631ms
    Apr 23 11:50:12.247: INFO: Terminating ReplicationController proxy-service-h5rg6 pods took: 101.137924ms
    [AfterEach] version v1
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:50:14.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] version v1
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] version v1
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] version v1
      tear down framework | framework.go:193
    STEP: Destroying namespace "proxy-157" for this suite. 04/23/23 11:50:14.87
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:357
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:50:14.906
Apr 23 11:50:14.906: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 11:50:14.913
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:50:14.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:50:14.992
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:357
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 04/23/23 11:50:15.079
Apr 23 11:50:15.080: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:50:18.848: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:50:29.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-6889" for this suite. 04/23/23 11:50:29.515
------------------------------
â€¢ [SLOW TEST] [14.628 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:357

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:50:14.906
    Apr 23 11:50:14.906: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 11:50:14.913
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:50:14.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:50:14.992
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:357
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 04/23/23 11:50:15.079
    Apr 23 11:50:15.080: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:50:18.848: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:50:29.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-6889" for this suite. 04/23/23 11:50:29.515
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:50:29.532
Apr 23 11:50:29.533: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename replicaset 04/23/23 11:50:29.541
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:50:29.576
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:50:29.581
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:31
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 04/23/23 11:50:29.587
Apr 23 11:50:29.608: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 23 11:50:34.620: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/23/23 11:50:34.62
STEP: getting scale subresource 04/23/23 11:50:34.62
STEP: updating a scale subresource 04/23/23 11:50:34.629
STEP: verifying the replicaset Spec.Replicas was modified 04/23/23 11:50:34.643
STEP: Patch a scale subresource 04/23/23 11:50:34.658
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/node/init/init.go:32
Apr 23 11:50:34.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  tear down framework | framework.go:193
STEP: Destroying namespace "replicaset-1357" for this suite. 04/23/23 11:50:34.693
------------------------------
â€¢ [SLOW TEST] [5.175 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:50:29.532
    Apr 23 11:50:29.533: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename replicaset 04/23/23 11:50:29.541
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:50:29.576
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:50:29.581
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:31
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 04/23/23 11:50:29.587
    Apr 23 11:50:29.608: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 23 11:50:34.620: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/23/23 11:50:34.62
    STEP: getting scale subresource 04/23/23 11:50:34.62
    STEP: updating a scale subresource 04/23/23 11:50:34.629
    STEP: verifying the replicaset Spec.Replicas was modified 04/23/23 11:50:34.643
    STEP: Patch a scale subresource 04/23/23 11:50:34.658
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:50:34.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "replicaset-1357" for this suite. 04/23/23 11:50:34.693
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:52
[BeforeEach] [sig-node] Container Runtime
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:50:34.711
Apr 23 11:50:34.711: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-runtime 04/23/23 11:50:34.714
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:50:34.832
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:50:34.836
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:31
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:52
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 04/23/23 11:50:34.872
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 04/23/23 11:50:52.077
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 04/23/23 11:50:52.086
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 04/23/23 11:50:52.099
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 04/23/23 11:50:52.099
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 04/23/23 11:50:52.148
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 04/23/23 11:50:55.197
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 04/23/23 11:50:57.224
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 04/23/23 11:50:57.24
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 04/23/23 11:50:57.24
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 04/23/23 11:50:57.294
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 04/23/23 11:50:58.32
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 04/23/23 11:51:01.358
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 04/23/23 11:51:01.375
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 04/23/23 11:51:01.375
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/node/init/init.go:32
Apr 23 11:51:01.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Runtime
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Runtime
  tear down framework | framework.go:193
STEP: Destroying namespace "container-runtime-3411" for this suite. 04/23/23 11:51:01.436
------------------------------
â€¢ [SLOW TEST] [26.741 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:44
    when starting a container that exits
    test/e2e/common/node/runtime.go:45
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:50:34.711
    Apr 23 11:50:34.711: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-runtime 04/23/23 11:50:34.714
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:50:34.832
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:50:34.836
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:31
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:52
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 04/23/23 11:50:34.872
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 04/23/23 11:50:52.077
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 04/23/23 11:50:52.086
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 04/23/23 11:50:52.099
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 04/23/23 11:50:52.099
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 04/23/23 11:50:52.148
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 04/23/23 11:50:55.197
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 04/23/23 11:50:57.224
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 04/23/23 11:50:57.24
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 04/23/23 11:50:57.24
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 04/23/23 11:50:57.294
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 04/23/23 11:50:58.32
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 04/23/23 11:51:01.358
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 04/23/23 11:51:01.375
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 04/23/23 11:51:01.375
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:51:01.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Runtime
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Runtime
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-runtime-3411" for this suite. 04/23/23 11:51:01.436
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1302
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:51:01.453
Apr 23 11:51:01.453: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 11:51:01.459
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:51:01.495
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:51:01.501
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1302
STEP: creating service nodeport-test with type=NodePort in namespace services-1736 04/23/23 11:51:01.512
STEP: creating replication controller nodeport-test in namespace services-1736 04/23/23 11:51:01.543
I0423 11:51:01.563396      13 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-1736, replica count: 2
I0423 11:51:04.614264      13 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 23 11:51:04.614: INFO: Creating new exec pod
Apr 23 11:51:04.657: INFO: Waiting up to 5m0s for pod "execpodx8gjg" in namespace "services-1736" to be "running"
Apr 23 11:51:04.690: INFO: Pod "execpodx8gjg": Phase="Pending", Reason="", readiness=false. Elapsed: 32.180596ms
Apr 23 11:51:06.700: INFO: Pod "execpodx8gjg": Phase="Running", Reason="", readiness=true. Elapsed: 2.042589576s
Apr 23 11:51:06.700: INFO: Pod "execpodx8gjg" satisfied condition "running"
Apr 23 11:51:07.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1736 exec execpodx8gjg -- /bin/sh -x -c nc -v -z -w 2 nodeport-test 80'
Apr 23 11:51:08.129: INFO: stderr: "+ nc -v -z -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr 23 11:51:08.129: INFO: stdout: ""
Apr 23 11:51:08.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1736 exec execpodx8gjg -- /bin/sh -x -c nc -v -z -w 2 10.233.18.23 80'
Apr 23 11:51:08.400: INFO: stderr: "+ nc -v -z -w 2 10.233.18.23 80\nConnection to 10.233.18.23 80 port [tcp/http] succeeded!\n"
Apr 23 11:51:08.400: INFO: stdout: ""
Apr 23 11:51:08.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1736 exec execpodx8gjg -- /bin/sh -x -c nc -v -z -w 2 192.168.121.198 30661'
Apr 23 11:51:08.663: INFO: stderr: "+ nc -v -z -w 2 192.168.121.198 30661\nConnection to 192.168.121.198 30661 port [tcp/*] succeeded!\n"
Apr 23 11:51:08.663: INFO: stdout: ""
Apr 23 11:51:08.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1736 exec execpodx8gjg -- /bin/sh -x -c nc -v -z -w 2 192.168.121.130 30661'
Apr 23 11:51:08.901: INFO: stderr: "+ nc -v -z -w 2 192.168.121.130 30661\nConnection to 192.168.121.130 30661 port [tcp/*] succeeded!\n"
Apr 23 11:51:08.901: INFO: stdout: ""
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 11:51:08.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-1736" for this suite. 04/23/23 11:51:08.911
------------------------------
â€¢ [SLOW TEST] [7.471 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1302

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:51:01.453
    Apr 23 11:51:01.453: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 11:51:01.459
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:51:01.495
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:51:01.501
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1302
    STEP: creating service nodeport-test with type=NodePort in namespace services-1736 04/23/23 11:51:01.512
    STEP: creating replication controller nodeport-test in namespace services-1736 04/23/23 11:51:01.543
    I0423 11:51:01.563396      13 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-1736, replica count: 2
    I0423 11:51:04.614264      13 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 23 11:51:04.614: INFO: Creating new exec pod
    Apr 23 11:51:04.657: INFO: Waiting up to 5m0s for pod "execpodx8gjg" in namespace "services-1736" to be "running"
    Apr 23 11:51:04.690: INFO: Pod "execpodx8gjg": Phase="Pending", Reason="", readiness=false. Elapsed: 32.180596ms
    Apr 23 11:51:06.700: INFO: Pod "execpodx8gjg": Phase="Running", Reason="", readiness=true. Elapsed: 2.042589576s
    Apr 23 11:51:06.700: INFO: Pod "execpodx8gjg" satisfied condition "running"
    Apr 23 11:51:07.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1736 exec execpodx8gjg -- /bin/sh -x -c nc -v -z -w 2 nodeport-test 80'
    Apr 23 11:51:08.129: INFO: stderr: "+ nc -v -z -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Apr 23 11:51:08.129: INFO: stdout: ""
    Apr 23 11:51:08.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1736 exec execpodx8gjg -- /bin/sh -x -c nc -v -z -w 2 10.233.18.23 80'
    Apr 23 11:51:08.400: INFO: stderr: "+ nc -v -z -w 2 10.233.18.23 80\nConnection to 10.233.18.23 80 port [tcp/http] succeeded!\n"
    Apr 23 11:51:08.400: INFO: stdout: ""
    Apr 23 11:51:08.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1736 exec execpodx8gjg -- /bin/sh -x -c nc -v -z -w 2 192.168.121.198 30661'
    Apr 23 11:51:08.663: INFO: stderr: "+ nc -v -z -w 2 192.168.121.198 30661\nConnection to 192.168.121.198 30661 port [tcp/*] succeeded!\n"
    Apr 23 11:51:08.663: INFO: stdout: ""
    Apr 23 11:51:08.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-1736 exec execpodx8gjg -- /bin/sh -x -c nc -v -z -w 2 192.168.121.130 30661'
    Apr 23 11:51:08.901: INFO: stderr: "+ nc -v -z -w 2 192.168.121.130 30661\nConnection to 192.168.121.130 30661 port [tcp/*] succeeded!\n"
    Apr 23 11:51:08.901: INFO: stdout: ""
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:51:08.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-1736" for this suite. 04/23/23 11:51:08.911
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:157
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:51:08.925
Apr 23 11:51:08.925: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 11:51:08.939
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:51:08.984
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:51:08.989
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:157
STEP: Creating a pod to test emptydir volume type on node default medium 04/23/23 11:51:08.995
Apr 23 11:51:09.009: INFO: Waiting up to 5m0s for pod "pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d" in namespace "emptydir-1506" to be "Succeeded or Failed"
Apr 23 11:51:09.016: INFO: Pod "pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.339909ms
Apr 23 11:51:11.026: INFO: Pod "pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016749002s
Apr 23 11:51:13.023: INFO: Pod "pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013090828s
Apr 23 11:51:15.037: INFO: Pod "pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027245506s
STEP: Saw pod success 04/23/23 11:51:15.037
Apr 23 11:51:15.037: INFO: Pod "pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d" satisfied condition "Succeeded or Failed"
Apr 23 11:51:15.049: INFO: Trying to get logs from node eingavuivie7-3 pod pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d container test-container: <nil>
STEP: delete the pod 04/23/23 11:51:15.108
Apr 23 11:51:15.185: INFO: Waiting for pod pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d to disappear
Apr 23 11:51:15.222: INFO: Pod pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 11:51:15.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-1506" for this suite. 04/23/23 11:51:15.248
------------------------------
â€¢ [SLOW TEST] [6.346 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:51:08.925
    Apr 23 11:51:08.925: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 11:51:08.939
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:51:08.984
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:51:08.989
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:157
    STEP: Creating a pod to test emptydir volume type on node default medium 04/23/23 11:51:08.995
    Apr 23 11:51:09.009: INFO: Waiting up to 5m0s for pod "pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d" in namespace "emptydir-1506" to be "Succeeded or Failed"
    Apr 23 11:51:09.016: INFO: Pod "pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.339909ms
    Apr 23 11:51:11.026: INFO: Pod "pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016749002s
    Apr 23 11:51:13.023: INFO: Pod "pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013090828s
    Apr 23 11:51:15.037: INFO: Pod "pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.027245506s
    STEP: Saw pod success 04/23/23 11:51:15.037
    Apr 23 11:51:15.037: INFO: Pod "pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d" satisfied condition "Succeeded or Failed"
    Apr 23 11:51:15.049: INFO: Trying to get logs from node eingavuivie7-3 pod pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d container test-container: <nil>
    STEP: delete the pod 04/23/23 11:51:15.108
    Apr 23 11:51:15.185: INFO: Waiting for pod pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d to disappear
    Apr 23 11:51:15.222: INFO: Pod pod-bb4f1f17-ddab-485c-9549-a3703d4dd90d no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:51:15.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-1506" for this suite. 04/23/23 11:51:15.248
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:207
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:51:15.273
Apr 23 11:51:15.273: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:51:15.275
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:51:15.377
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:51:15.382
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:207
STEP: Creating a pod to test downward API volume plugin 04/23/23 11:51:15.388
Apr 23 11:51:15.433: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e" in namespace "projected-5649" to be "Succeeded or Failed"
Apr 23 11:51:15.440: INFO: Pod "downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.585788ms
Apr 23 11:51:17.448: INFO: Pod "downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014458303s
Apr 23 11:51:19.448: INFO: Pod "downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015184877s
STEP: Saw pod success 04/23/23 11:51:19.449
Apr 23 11:51:19.449: INFO: Pod "downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e" satisfied condition "Succeeded or Failed"
Apr 23 11:51:19.472: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e container client-container: <nil>
STEP: delete the pod 04/23/23 11:51:19.597
Apr 23 11:51:19.628: INFO: Waiting for pod downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e to disappear
Apr 23 11:51:19.634: INFO: Pod downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Apr 23 11:51:19.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-5649" for this suite. 04/23/23 11:51:19.642
------------------------------
â€¢ [4.382 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:51:15.273
    Apr 23 11:51:15.273: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:51:15.275
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:51:15.377
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:51:15.382
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:207
    STEP: Creating a pod to test downward API volume plugin 04/23/23 11:51:15.388
    Apr 23 11:51:15.433: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e" in namespace "projected-5649" to be "Succeeded or Failed"
    Apr 23 11:51:15.440: INFO: Pod "downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.585788ms
    Apr 23 11:51:17.448: INFO: Pod "downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014458303s
    Apr 23 11:51:19.448: INFO: Pod "downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015184877s
    STEP: Saw pod success 04/23/23 11:51:19.449
    Apr 23 11:51:19.449: INFO: Pod "downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e" satisfied condition "Succeeded or Failed"
    Apr 23 11:51:19.472: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e container client-container: <nil>
    STEP: delete the pod 04/23/23 11:51:19.597
    Apr 23 11:51:19.628: INFO: Waiting for pod downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e to disappear
    Apr 23 11:51:19.634: INFO: Pod downwardapi-volume-1c2c0952-2f16-4221-9ca6-60e12edb9f9e no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:51:19.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-5649" for this suite. 04/23/23 11:51:19.642
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:108
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:51:19.661
Apr 23 11:51:19.661: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-probe 04/23/23 11:51:19.663
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:51:19.706
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:51:19.713
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:108
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Apr 23 11:52:19.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-7278" for this suite. 04/23/23 11:52:19.773
------------------------------
â€¢ [SLOW TEST] [60.128 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:51:19.661
    Apr 23 11:51:19.661: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-probe 04/23/23 11:51:19.663
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:51:19.706
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:51:19.713
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:108
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:52:19.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-7278" for this suite. 04/23/23 11:52:19.773
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:52:19.794
Apr 23 11:52:19.794: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename custom-resource-definition 04/23/23 11:52:19.802
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:52:19.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:52:19.845
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Apr 23 11:52:19.856: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:52:23.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "custom-resource-definition-24" for this suite. 04/23/23 11:52:23.399
------------------------------
â€¢ [3.615 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:52:19.794
    Apr 23 11:52:19.794: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename custom-resource-definition 04/23/23 11:52:19.802
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:52:19.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:52:19.845
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Apr 23 11:52:19.856: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:52:23.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "custom-resource-definition-24" for this suite. 04/23/23 11:52:23.399
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:52:23.429
Apr 23 11:52:23.429: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename endpointslicemirroring 04/23/23 11:52:23.442
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:52:23.497
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:52:23.508
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 04/23/23 11:52:23.528
Apr 23 11:52:23.545: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 04/23/23 11:52:25.552
Apr 23 11:52:25.578: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint 04/23/23 11:52:27.586
Apr 23 11:52:27.606: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/node/init/init.go:32
Apr 23 11:52:29.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] EndpointSliceMirroring
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] EndpointSliceMirroring
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] EndpointSliceMirroring
  tear down framework | framework.go:193
STEP: Destroying namespace "endpointslicemirroring-3636" for this suite. 04/23/23 11:52:29.63
------------------------------
â€¢ [SLOW TEST] [6.231 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:52:23.429
    Apr 23 11:52:23.429: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename endpointslicemirroring 04/23/23 11:52:23.442
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:52:23.497
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:52:23.508
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 04/23/23 11:52:23.528
    Apr 23 11:52:23.545: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 04/23/23 11:52:25.552
    Apr 23 11:52:25.578: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
    STEP: mirroring deletion of a custom Endpoint 04/23/23 11:52:27.586
    Apr 23 11:52:27.606: INFO: Waiting for 0 EndpointSlices to exist, got 1
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:52:29.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] EndpointSliceMirroring
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] EndpointSliceMirroring
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] EndpointSliceMirroring
      tear down framework | framework.go:193
    STEP: Destroying namespace "endpointslicemirroring-3636" for this suite. 04/23/23 11:52:29.63
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1652
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:52:29.67
Apr 23 11:52:29.671: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 11:52:29.686
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:52:29.72
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:52:29.733
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1652
STEP: creating Agnhost RC 04/23/23 11:52:29.744
Apr 23 11:52:29.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-644 create -f -'
Apr 23 11:52:31.602: INFO: stderr: ""
Apr 23 11:52:31.602: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/23/23 11:52:31.602
Apr 23 11:52:32.615: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 23 11:52:32.616: INFO: Found 0 / 1
Apr 23 11:52:33.612: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 23 11:52:33.612: INFO: Found 1 / 1
Apr 23 11:52:33.612: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 04/23/23 11:52:33.612
Apr 23 11:52:33.620: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 23 11:52:33.620: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 23 11:52:33.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-644 patch pod agnhost-primary-bfpvs -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 23 11:52:33.889: INFO: stderr: ""
Apr 23 11:52:33.889: INFO: stdout: "pod/agnhost-primary-bfpvs patched\n"
STEP: checking annotations 04/23/23 11:52:33.889
Apr 23 11:52:33.896: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 23 11:52:33.897: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 11:52:33.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-644" for this suite. 04/23/23 11:52:33.911
------------------------------
â€¢ [4.254 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1646
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1652

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:52:29.67
    Apr 23 11:52:29.671: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 11:52:29.686
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:52:29.72
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:52:29.733
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1652
    STEP: creating Agnhost RC 04/23/23 11:52:29.744
    Apr 23 11:52:29.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-644 create -f -'
    Apr 23 11:52:31.602: INFO: stderr: ""
    Apr 23 11:52:31.602: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/23/23 11:52:31.602
    Apr 23 11:52:32.615: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 23 11:52:32.616: INFO: Found 0 / 1
    Apr 23 11:52:33.612: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 23 11:52:33.612: INFO: Found 1 / 1
    Apr 23 11:52:33.612: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 04/23/23 11:52:33.612
    Apr 23 11:52:33.620: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 23 11:52:33.620: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 23 11:52:33.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-644 patch pod agnhost-primary-bfpvs -p {"metadata":{"annotations":{"x":"y"}}}'
    Apr 23 11:52:33.889: INFO: stderr: ""
    Apr 23 11:52:33.889: INFO: stdout: "pod/agnhost-primary-bfpvs patched\n"
    STEP: checking annotations 04/23/23 11:52:33.889
    Apr 23 11:52:33.896: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 23 11:52:33.897: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:52:33.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-644" for this suite. 04/23/23 11:52:33.911
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:331
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:52:33.927
Apr 23 11:52:33.927: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename sched-pred 04/23/23 11:52:33.936
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:52:33.973
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:52:33.977
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:97
Apr 23 11:52:33.981: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 23 11:52:33.999: INFO: Waiting for terminating namespaces to be deleted...
Apr 23 11:52:34.008: INFO: 
Logging pods the apiserver thinks is on node eingavuivie7-1 before test
Apr 23 11:52:34.025: INFO: cilium-node-init-j475c from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.025: INFO: 	Container node-init ready: true, restart count 0
Apr 23 11:52:34.025: INFO: cilium-tcvk2 from kube-system started at 2023-04-23 10:44:39 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.025: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 23 11:52:34.025: INFO: kube-addon-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.026: INFO: 	Container kube-addon-manager ready: true, restart count 0
Apr 23 11:52:34.026: INFO: kube-apiserver-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.026: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 23 11:52:34.026: INFO: kube-controller-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.026: INFO: 	Container kube-controller-manager ready: true, restart count 0
Apr 23 11:52:34.026: INFO: kube-proxy-qx9mz from kube-system started at 2023-04-23 10:40:00 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.026: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 11:52:34.026: INFO: kube-scheduler-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:29 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.026: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 23 11:52:34.026: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-tdgvz from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 11:52:34.026: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 11:52:34.026: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 23 11:52:34.026: INFO: 
Logging pods the apiserver thinks is on node eingavuivie7-2 before test
Apr 23 11:52:34.048: INFO: cilium-cw5l6 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.048: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 23 11:52:34.048: INFO: cilium-node-init-tpqk9 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.048: INFO: 	Container node-init ready: true, restart count 0
Apr 23 11:52:34.048: INFO: coredns-787d4945fb-v7bjj from kube-system started at 2023-04-23 10:46:03 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.048: INFO: 	Container coredns ready: true, restart count 0
Apr 23 11:52:34.048: INFO: kube-addon-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.048: INFO: 	Container kube-addon-manager ready: true, restart count 0
Apr 23 11:52:34.048: INFO: kube-apiserver-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.048: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 23 11:52:34.049: INFO: kube-controller-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.049: INFO: 	Container kube-controller-manager ready: true, restart count 0
Apr 23 11:52:34.049: INFO: kube-proxy-hzwld from kube-system started at 2023-04-23 10:40:58 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.049: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 11:52:34.049: INFO: kube-scheduler-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.049: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 23 11:52:34.049: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-ntx29 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 11:52:34.049: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 11:52:34.049: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 23 11:52:34.049: INFO: 
Logging pods the apiserver thinks is on node eingavuivie7-3 before test
Apr 23 11:52:34.067: INFO: cilium-node-init-btj27 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.067: INFO: 	Container node-init ready: true, restart count 0
Apr 23 11:52:34.067: INFO: cilium-operator-968f66564-jmvk7 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.067: INFO: 	Container cilium-operator ready: true, restart count 0
Apr 23 11:52:34.067: INFO: cilium-vpc26 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.067: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 23 11:52:34.067: INFO: coredns-787d4945fb-8tms9 from kube-system started at 2023-04-23 10:45:47 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.067: INFO: 	Container coredns ready: true, restart count 0
Apr 23 11:52:34.067: INFO: kube-proxy-lsxv6 from kube-system started at 2023-04-23 10:41:59 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.067: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 11:52:34.067: INFO: agnhost-primary-bfpvs from kubectl-644 started at 2023-04-23 11:52:31 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.067: INFO: 	Container agnhost-primary ready: true, restart count 0
Apr 23 11:52:34.067: INFO: sonobuoy from sonobuoy started at 2023-04-23 11:11:26 +0000 UTC (1 container statuses recorded)
Apr 23 11:52:34.067: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 23 11:52:34.067: INFO: sonobuoy-e2e-job-27be2b9757534547 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 11:52:34.067: INFO: 	Container e2e ready: true, restart count 0
Apr 23 11:52:34.067: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 11:52:34.067: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-k7sgm from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 11:52:34.067: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 11:52:34.067: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:331
STEP: verifying the node has the label node eingavuivie7-1 04/23/23 11:52:34.118
STEP: verifying the node has the label node eingavuivie7-2 04/23/23 11:52:34.144
STEP: verifying the node has the label node eingavuivie7-3 04/23/23 11:52:34.176
Apr 23 11:52:34.239: INFO: Pod cilium-cw5l6 requesting resource cpu=0m on Node eingavuivie7-2
Apr 23 11:52:34.239: INFO: Pod cilium-node-init-btj27 requesting resource cpu=100m on Node eingavuivie7-3
Apr 23 11:52:34.239: INFO: Pod cilium-node-init-j475c requesting resource cpu=100m on Node eingavuivie7-1
Apr 23 11:52:34.239: INFO: Pod cilium-node-init-tpqk9 requesting resource cpu=100m on Node eingavuivie7-2
Apr 23 11:52:34.239: INFO: Pod cilium-operator-968f66564-jmvk7 requesting resource cpu=0m on Node eingavuivie7-3
Apr 23 11:52:34.240: INFO: Pod cilium-tcvk2 requesting resource cpu=0m on Node eingavuivie7-1
Apr 23 11:52:34.240: INFO: Pod cilium-vpc26 requesting resource cpu=0m on Node eingavuivie7-3
Apr 23 11:52:34.240: INFO: Pod coredns-787d4945fb-8tms9 requesting resource cpu=100m on Node eingavuivie7-3
Apr 23 11:52:34.241: INFO: Pod coredns-787d4945fb-v7bjj requesting resource cpu=100m on Node eingavuivie7-2
Apr 23 11:52:34.241: INFO: Pod kube-addon-manager-eingavuivie7-1 requesting resource cpu=5m on Node eingavuivie7-1
Apr 23 11:52:34.241: INFO: Pod kube-addon-manager-eingavuivie7-2 requesting resource cpu=5m on Node eingavuivie7-2
Apr 23 11:52:34.242: INFO: Pod kube-apiserver-eingavuivie7-1 requesting resource cpu=250m on Node eingavuivie7-1
Apr 23 11:52:34.242: INFO: Pod kube-apiserver-eingavuivie7-2 requesting resource cpu=250m on Node eingavuivie7-2
Apr 23 11:52:34.242: INFO: Pod kube-controller-manager-eingavuivie7-1 requesting resource cpu=200m on Node eingavuivie7-1
Apr 23 11:52:34.242: INFO: Pod kube-controller-manager-eingavuivie7-2 requesting resource cpu=200m on Node eingavuivie7-2
Apr 23 11:52:34.242: INFO: Pod kube-proxy-hzwld requesting resource cpu=0m on Node eingavuivie7-2
Apr 23 11:52:34.243: INFO: Pod kube-proxy-lsxv6 requesting resource cpu=0m on Node eingavuivie7-3
Apr 23 11:52:34.243: INFO: Pod kube-proxy-qx9mz requesting resource cpu=0m on Node eingavuivie7-1
Apr 23 11:52:34.243: INFO: Pod kube-scheduler-eingavuivie7-1 requesting resource cpu=100m on Node eingavuivie7-1
Apr 23 11:52:34.243: INFO: Pod kube-scheduler-eingavuivie7-2 requesting resource cpu=100m on Node eingavuivie7-2
Apr 23 11:52:34.243: INFO: Pod agnhost-primary-bfpvs requesting resource cpu=0m on Node eingavuivie7-3
Apr 23 11:52:34.243: INFO: Pod sonobuoy requesting resource cpu=0m on Node eingavuivie7-3
Apr 23 11:52:34.243: INFO: Pod sonobuoy-e2e-job-27be2b9757534547 requesting resource cpu=0m on Node eingavuivie7-3
Apr 23 11:52:34.243: INFO: Pod sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-k7sgm requesting resource cpu=0m on Node eingavuivie7-3
Apr 23 11:52:34.243: INFO: Pod sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-ntx29 requesting resource cpu=0m on Node eingavuivie7-2
Apr 23 11:52:34.243: INFO: Pod sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-tdgvz requesting resource cpu=0m on Node eingavuivie7-1
STEP: Starting Pods to consume most of the cluster CPU. 04/23/23 11:52:34.243
Apr 23 11:52:34.244: INFO: Creating a pod which consumes cpu=661m on Node eingavuivie7-1
Apr 23 11:52:34.269: INFO: Creating a pod which consumes cpu=591m on Node eingavuivie7-2
Apr 23 11:52:34.283: INFO: Creating a pod which consumes cpu=980m on Node eingavuivie7-3
Apr 23 11:52:34.315: INFO: Waiting up to 5m0s for pod "filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912" in namespace "sched-pred-4176" to be "running"
Apr 23 11:52:34.328: INFO: Pod "filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912": Phase="Pending", Reason="", readiness=false. Elapsed: 12.721453ms
Apr 23 11:52:36.663: INFO: Pod "filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912": Phase="Pending", Reason="", readiness=false. Elapsed: 2.348152744s
Apr 23 11:52:38.336: INFO: Pod "filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912": Phase="Running", Reason="", readiness=true. Elapsed: 4.02138416s
Apr 23 11:52:38.337: INFO: Pod "filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912" satisfied condition "running"
Apr 23 11:52:38.337: INFO: Waiting up to 5m0s for pod "filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb" in namespace "sched-pred-4176" to be "running"
Apr 23 11:52:38.342: INFO: Pod "filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb": Phase="Running", Reason="", readiness=true. Elapsed: 4.841903ms
Apr 23 11:52:38.342: INFO: Pod "filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb" satisfied condition "running"
Apr 23 11:52:38.342: INFO: Waiting up to 5m0s for pod "filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a" in namespace "sched-pred-4176" to be "running"
Apr 23 11:52:38.352: INFO: Pod "filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a": Phase="Running", Reason="", readiness=true. Elapsed: 10.01668ms
Apr 23 11:52:38.352: INFO: Pod "filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 04/23/23 11:52:38.353
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a.17588e25edf80fbc], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4176/filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a to eingavuivie7-3] 04/23/23 11:52:38.36
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a.17588e2625440c3a], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] 04/23/23 11:52:38.361
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a.17588e263f90b73b], Reason = [Created], Message = [Created container filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a] 04/23/23 11:52:38.361
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a.17588e26480cca31], Reason = [Started], Message = [Started container filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a] 04/23/23 11:52:38.362
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912.17588e25eb62c95b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4176/filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912 to eingavuivie7-1] 04/23/23 11:52:38.362
STEP: Considering event: 
Type = [Warning], Name = [filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912.17588e262f385bf7], Reason = [FailedMount], Message = [MountVolume.SetUp failed for volume "kube-api-access-5k466" : failed to sync configmap cache: timed out waiting for the condition] 04/23/23 11:52:38.362
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912.17588e2694ffde03], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] 04/23/23 11:52:38.362
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912.17588e26a3d3d4d4], Reason = [Created], Message = [Created container filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912] 04/23/23 11:52:38.362
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912.17588e26a6fa3328], Reason = [Started], Message = [Started container filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912] 04/23/23 11:52:38.362
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb.17588e25eb6754d9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4176/filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb to eingavuivie7-2] 04/23/23 11:52:38.362
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb.17588e261cf68cc6], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] 04/23/23 11:52:38.363
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb.17588e262a72d9c3], Reason = [Created], Message = [Created container filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb] 04/23/23 11:52:38.363
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb.17588e262ebe781a], Reason = [Started], Message = [Started container filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb] 04/23/23 11:52:38.363
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.17588e26dbde2d07], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod..] 04/23/23 11:52:38.384
STEP: removing the label node off the node eingavuivie7-1 04/23/23 11:52:39.381
STEP: verifying the node doesn't have the label node 04/23/23 11:52:39.4
STEP: removing the label node off the node eingavuivie7-2 04/23/23 11:52:39.412
STEP: verifying the node doesn't have the label node 04/23/23 11:52:39.447
STEP: removing the label node off the node eingavuivie7-3 04/23/23 11:52:39.461
STEP: verifying the node doesn't have the label node 04/23/23 11:52:39.559
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:52:39.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:88
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-pred-4176" for this suite. 04/23/23 11:52:40.092
------------------------------
â€¢ [SLOW TEST] [6.191 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:331

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:52:33.927
    Apr 23 11:52:33.927: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename sched-pred 04/23/23 11:52:33.936
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:52:33.973
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:52:33.977
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:97
    Apr 23 11:52:33.981: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 23 11:52:33.999: INFO: Waiting for terminating namespaces to be deleted...
    Apr 23 11:52:34.008: INFO: 
    Logging pods the apiserver thinks is on node eingavuivie7-1 before test
    Apr 23 11:52:34.025: INFO: cilium-node-init-j475c from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.025: INFO: 	Container node-init ready: true, restart count 0
    Apr 23 11:52:34.025: INFO: cilium-tcvk2 from kube-system started at 2023-04-23 10:44:39 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.025: INFO: 	Container cilium-agent ready: true, restart count 0
    Apr 23 11:52:34.025: INFO: kube-addon-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.026: INFO: 	Container kube-addon-manager ready: true, restart count 0
    Apr 23 11:52:34.026: INFO: kube-apiserver-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.026: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 23 11:52:34.026: INFO: kube-controller-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.026: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Apr 23 11:52:34.026: INFO: kube-proxy-qx9mz from kube-system started at 2023-04-23 10:40:00 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.026: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 23 11:52:34.026: INFO: kube-scheduler-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:29 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.026: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 23 11:52:34.026: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-tdgvz from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 11:52:34.026: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 11:52:34.026: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 23 11:52:34.026: INFO: 
    Logging pods the apiserver thinks is on node eingavuivie7-2 before test
    Apr 23 11:52:34.048: INFO: cilium-cw5l6 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.048: INFO: 	Container cilium-agent ready: true, restart count 0
    Apr 23 11:52:34.048: INFO: cilium-node-init-tpqk9 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.048: INFO: 	Container node-init ready: true, restart count 0
    Apr 23 11:52:34.048: INFO: coredns-787d4945fb-v7bjj from kube-system started at 2023-04-23 10:46:03 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.048: INFO: 	Container coredns ready: true, restart count 0
    Apr 23 11:52:34.048: INFO: kube-addon-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.048: INFO: 	Container kube-addon-manager ready: true, restart count 0
    Apr 23 11:52:34.048: INFO: kube-apiserver-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.048: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 23 11:52:34.049: INFO: kube-controller-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.049: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Apr 23 11:52:34.049: INFO: kube-proxy-hzwld from kube-system started at 2023-04-23 10:40:58 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.049: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 23 11:52:34.049: INFO: kube-scheduler-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.049: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 23 11:52:34.049: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-ntx29 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 11:52:34.049: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 11:52:34.049: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 23 11:52:34.049: INFO: 
    Logging pods the apiserver thinks is on node eingavuivie7-3 before test
    Apr 23 11:52:34.067: INFO: cilium-node-init-btj27 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.067: INFO: 	Container node-init ready: true, restart count 0
    Apr 23 11:52:34.067: INFO: cilium-operator-968f66564-jmvk7 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.067: INFO: 	Container cilium-operator ready: true, restart count 0
    Apr 23 11:52:34.067: INFO: cilium-vpc26 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.067: INFO: 	Container cilium-agent ready: true, restart count 0
    Apr 23 11:52:34.067: INFO: coredns-787d4945fb-8tms9 from kube-system started at 2023-04-23 10:45:47 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.067: INFO: 	Container coredns ready: true, restart count 0
    Apr 23 11:52:34.067: INFO: kube-proxy-lsxv6 from kube-system started at 2023-04-23 10:41:59 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.067: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 23 11:52:34.067: INFO: agnhost-primary-bfpvs from kubectl-644 started at 2023-04-23 11:52:31 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.067: INFO: 	Container agnhost-primary ready: true, restart count 0
    Apr 23 11:52:34.067: INFO: sonobuoy from sonobuoy started at 2023-04-23 11:11:26 +0000 UTC (1 container statuses recorded)
    Apr 23 11:52:34.067: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 23 11:52:34.067: INFO: sonobuoy-e2e-job-27be2b9757534547 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 11:52:34.067: INFO: 	Container e2e ready: true, restart count 0
    Apr 23 11:52:34.067: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 11:52:34.067: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-k7sgm from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 11:52:34.067: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 11:52:34.067: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:331
    STEP: verifying the node has the label node eingavuivie7-1 04/23/23 11:52:34.118
    STEP: verifying the node has the label node eingavuivie7-2 04/23/23 11:52:34.144
    STEP: verifying the node has the label node eingavuivie7-3 04/23/23 11:52:34.176
    Apr 23 11:52:34.239: INFO: Pod cilium-cw5l6 requesting resource cpu=0m on Node eingavuivie7-2
    Apr 23 11:52:34.239: INFO: Pod cilium-node-init-btj27 requesting resource cpu=100m on Node eingavuivie7-3
    Apr 23 11:52:34.239: INFO: Pod cilium-node-init-j475c requesting resource cpu=100m on Node eingavuivie7-1
    Apr 23 11:52:34.239: INFO: Pod cilium-node-init-tpqk9 requesting resource cpu=100m on Node eingavuivie7-2
    Apr 23 11:52:34.239: INFO: Pod cilium-operator-968f66564-jmvk7 requesting resource cpu=0m on Node eingavuivie7-3
    Apr 23 11:52:34.240: INFO: Pod cilium-tcvk2 requesting resource cpu=0m on Node eingavuivie7-1
    Apr 23 11:52:34.240: INFO: Pod cilium-vpc26 requesting resource cpu=0m on Node eingavuivie7-3
    Apr 23 11:52:34.240: INFO: Pod coredns-787d4945fb-8tms9 requesting resource cpu=100m on Node eingavuivie7-3
    Apr 23 11:52:34.241: INFO: Pod coredns-787d4945fb-v7bjj requesting resource cpu=100m on Node eingavuivie7-2
    Apr 23 11:52:34.241: INFO: Pod kube-addon-manager-eingavuivie7-1 requesting resource cpu=5m on Node eingavuivie7-1
    Apr 23 11:52:34.241: INFO: Pod kube-addon-manager-eingavuivie7-2 requesting resource cpu=5m on Node eingavuivie7-2
    Apr 23 11:52:34.242: INFO: Pod kube-apiserver-eingavuivie7-1 requesting resource cpu=250m on Node eingavuivie7-1
    Apr 23 11:52:34.242: INFO: Pod kube-apiserver-eingavuivie7-2 requesting resource cpu=250m on Node eingavuivie7-2
    Apr 23 11:52:34.242: INFO: Pod kube-controller-manager-eingavuivie7-1 requesting resource cpu=200m on Node eingavuivie7-1
    Apr 23 11:52:34.242: INFO: Pod kube-controller-manager-eingavuivie7-2 requesting resource cpu=200m on Node eingavuivie7-2
    Apr 23 11:52:34.242: INFO: Pod kube-proxy-hzwld requesting resource cpu=0m on Node eingavuivie7-2
    Apr 23 11:52:34.243: INFO: Pod kube-proxy-lsxv6 requesting resource cpu=0m on Node eingavuivie7-3
    Apr 23 11:52:34.243: INFO: Pod kube-proxy-qx9mz requesting resource cpu=0m on Node eingavuivie7-1
    Apr 23 11:52:34.243: INFO: Pod kube-scheduler-eingavuivie7-1 requesting resource cpu=100m on Node eingavuivie7-1
    Apr 23 11:52:34.243: INFO: Pod kube-scheduler-eingavuivie7-2 requesting resource cpu=100m on Node eingavuivie7-2
    Apr 23 11:52:34.243: INFO: Pod agnhost-primary-bfpvs requesting resource cpu=0m on Node eingavuivie7-3
    Apr 23 11:52:34.243: INFO: Pod sonobuoy requesting resource cpu=0m on Node eingavuivie7-3
    Apr 23 11:52:34.243: INFO: Pod sonobuoy-e2e-job-27be2b9757534547 requesting resource cpu=0m on Node eingavuivie7-3
    Apr 23 11:52:34.243: INFO: Pod sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-k7sgm requesting resource cpu=0m on Node eingavuivie7-3
    Apr 23 11:52:34.243: INFO: Pod sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-ntx29 requesting resource cpu=0m on Node eingavuivie7-2
    Apr 23 11:52:34.243: INFO: Pod sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-tdgvz requesting resource cpu=0m on Node eingavuivie7-1
    STEP: Starting Pods to consume most of the cluster CPU. 04/23/23 11:52:34.243
    Apr 23 11:52:34.244: INFO: Creating a pod which consumes cpu=661m on Node eingavuivie7-1
    Apr 23 11:52:34.269: INFO: Creating a pod which consumes cpu=591m on Node eingavuivie7-2
    Apr 23 11:52:34.283: INFO: Creating a pod which consumes cpu=980m on Node eingavuivie7-3
    Apr 23 11:52:34.315: INFO: Waiting up to 5m0s for pod "filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912" in namespace "sched-pred-4176" to be "running"
    Apr 23 11:52:34.328: INFO: Pod "filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912": Phase="Pending", Reason="", readiness=false. Elapsed: 12.721453ms
    Apr 23 11:52:36.663: INFO: Pod "filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912": Phase="Pending", Reason="", readiness=false. Elapsed: 2.348152744s
    Apr 23 11:52:38.336: INFO: Pod "filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912": Phase="Running", Reason="", readiness=true. Elapsed: 4.02138416s
    Apr 23 11:52:38.337: INFO: Pod "filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912" satisfied condition "running"
    Apr 23 11:52:38.337: INFO: Waiting up to 5m0s for pod "filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb" in namespace "sched-pred-4176" to be "running"
    Apr 23 11:52:38.342: INFO: Pod "filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb": Phase="Running", Reason="", readiness=true. Elapsed: 4.841903ms
    Apr 23 11:52:38.342: INFO: Pod "filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb" satisfied condition "running"
    Apr 23 11:52:38.342: INFO: Waiting up to 5m0s for pod "filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a" in namespace "sched-pred-4176" to be "running"
    Apr 23 11:52:38.352: INFO: Pod "filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a": Phase="Running", Reason="", readiness=true. Elapsed: 10.01668ms
    Apr 23 11:52:38.352: INFO: Pod "filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 04/23/23 11:52:38.353
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a.17588e25edf80fbc], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4176/filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a to eingavuivie7-3] 04/23/23 11:52:38.36
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a.17588e2625440c3a], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] 04/23/23 11:52:38.361
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a.17588e263f90b73b], Reason = [Created], Message = [Created container filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a] 04/23/23 11:52:38.361
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a.17588e26480cca31], Reason = [Started], Message = [Started container filler-pod-cbd50949-08a6-41a3-9ee4-61166d3b224a] 04/23/23 11:52:38.362
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912.17588e25eb62c95b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4176/filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912 to eingavuivie7-1] 04/23/23 11:52:38.362
    STEP: Considering event: 
    Type = [Warning], Name = [filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912.17588e262f385bf7], Reason = [FailedMount], Message = [MountVolume.SetUp failed for volume "kube-api-access-5k466" : failed to sync configmap cache: timed out waiting for the condition] 04/23/23 11:52:38.362
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912.17588e2694ffde03], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] 04/23/23 11:52:38.362
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912.17588e26a3d3d4d4], Reason = [Created], Message = [Created container filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912] 04/23/23 11:52:38.362
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912.17588e26a6fa3328], Reason = [Started], Message = [Started container filler-pod-e44d8141-154f-4f4b-bd81-522e6318d912] 04/23/23 11:52:38.362
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb.17588e25eb6754d9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4176/filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb to eingavuivie7-2] 04/23/23 11:52:38.362
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb.17588e261cf68cc6], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] 04/23/23 11:52:38.363
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb.17588e262a72d9c3], Reason = [Created], Message = [Created container filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb] 04/23/23 11:52:38.363
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb.17588e262ebe781a], Reason = [Started], Message = [Started container filler-pod-f9b8e045-a64c-4034-b1d2-c8c6049d1fcb] 04/23/23 11:52:38.363
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.17588e26dbde2d07], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod..] 04/23/23 11:52:38.384
    STEP: removing the label node off the node eingavuivie7-1 04/23/23 11:52:39.381
    STEP: verifying the node doesn't have the label node 04/23/23 11:52:39.4
    STEP: removing the label node off the node eingavuivie7-2 04/23/23 11:52:39.412
    STEP: verifying the node doesn't have the label node 04/23/23 11:52:39.447
    STEP: removing the label node off the node eingavuivie7-3 04/23/23 11:52:39.461
    STEP: verifying the node doesn't have the label node 04/23/23 11:52:39.559
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:52:39.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:88
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-pred-4176" for this suite. 04/23/23 11:52:40.092
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:68
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:52:40.37
Apr 23 11:52:40.380: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:52:40.382
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:52:40.45
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:52:40.453
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:68
STEP: Creating a pod to test downward API volume plugin 04/23/23 11:52:40.55
Apr 23 11:52:40.573: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e" in namespace "projected-3167" to be "Succeeded or Failed"
Apr 23 11:52:40.583: INFO: Pod "downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.559031ms
Apr 23 11:52:42.603: INFO: Pod "downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030022551s
Apr 23 11:52:44.592: INFO: Pod "downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e": Phase="Running", Reason="", readiness=false. Elapsed: 4.018649188s
Apr 23 11:52:46.603: INFO: Pod "downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030132889s
STEP: Saw pod success 04/23/23 11:52:46.603
Apr 23 11:52:46.604: INFO: Pod "downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e" satisfied condition "Succeeded or Failed"
Apr 23 11:52:46.610: INFO: Trying to get logs from node eingavuivie7-1 pod downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e container client-container: <nil>
STEP: delete the pod 04/23/23 11:52:47.06
Apr 23 11:52:47.125: INFO: Waiting for pod downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e to disappear
Apr 23 11:52:47.139: INFO: Pod downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Apr 23 11:52:47.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-3167" for this suite. 04/23/23 11:52:47.157
------------------------------
â€¢ [SLOW TEST] [6.806 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:52:40.37
    Apr 23 11:52:40.380: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:52:40.382
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:52:40.45
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:52:40.453
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:68
    STEP: Creating a pod to test downward API volume plugin 04/23/23 11:52:40.55
    Apr 23 11:52:40.573: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e" in namespace "projected-3167" to be "Succeeded or Failed"
    Apr 23 11:52:40.583: INFO: Pod "downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.559031ms
    Apr 23 11:52:42.603: INFO: Pod "downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030022551s
    Apr 23 11:52:44.592: INFO: Pod "downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e": Phase="Running", Reason="", readiness=false. Elapsed: 4.018649188s
    Apr 23 11:52:46.603: INFO: Pod "downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030132889s
    STEP: Saw pod success 04/23/23 11:52:46.603
    Apr 23 11:52:46.604: INFO: Pod "downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e" satisfied condition "Succeeded or Failed"
    Apr 23 11:52:46.610: INFO: Trying to get logs from node eingavuivie7-1 pod downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e container client-container: <nil>
    STEP: delete the pod 04/23/23 11:52:47.06
    Apr 23 11:52:47.125: INFO: Waiting for pod downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e to disappear
    Apr 23 11:52:47.139: INFO: Pod downwardapi-volume-91cfb514-49ff-4908-ae26-bb0c3079410e no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:52:47.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-3167" for this suite. 04/23/23 11:52:47.157
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:347
[BeforeEach] [sig-apps] DisruptionController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:52:47.178
Apr 23 11:52:47.179: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename disruption 04/23/23 11:52:47.181
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:52:47.22
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:52:47.227
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:72
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:347
STEP: Creating a pdb that targets all three pods in a test replica set 04/23/23 11:52:47.234
STEP: Waiting for the pdb to be processed 04/23/23 11:52:47.253
STEP: First trying to evict a pod which shouldn't be evictable 04/23/23 11:52:49.289
STEP: Waiting for all pods to be running 04/23/23 11:52:49.291
Apr 23 11:52:49.302: INFO: pods: 0 < 3
STEP: locating a running pod 04/23/23 11:52:51.319
STEP: Updating the pdb to allow a pod to be evicted 04/23/23 11:52:51.336
STEP: Waiting for the pdb to be processed 04/23/23 11:52:51.35
STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/23/23 11:52:53.378
STEP: Waiting for all pods to be running 04/23/23 11:52:53.378
STEP: Waiting for the pdb to observed all healthy pods 04/23/23 11:52:53.386
STEP: Patching the pdb to disallow a pod to be evicted 04/23/23 11:52:53.432
STEP: Waiting for the pdb to be processed 04/23/23 11:52:53.478
STEP: Waiting for all pods to be running 04/23/23 11:52:55.501
STEP: locating a running pod 04/23/23 11:52:55.509
STEP: Deleting the pdb to allow a pod to be evicted 04/23/23 11:52:55.537
STEP: Waiting for the pdb to be deleted 04/23/23 11:52:55.548
STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/23/23 11:52:55.557
STEP: Waiting for all pods to be running 04/23/23 11:52:55.557
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/node/init/init.go:32
Apr 23 11:52:55.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] DisruptionController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] DisruptionController
  tear down framework | framework.go:193
STEP: Destroying namespace "disruption-5027" for this suite. 04/23/23 11:52:55.618
------------------------------
â€¢ [SLOW TEST] [8.460 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:347

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:52:47.178
    Apr 23 11:52:47.179: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename disruption 04/23/23 11:52:47.181
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:52:47.22
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:52:47.227
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:72
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:347
    STEP: Creating a pdb that targets all three pods in a test replica set 04/23/23 11:52:47.234
    STEP: Waiting for the pdb to be processed 04/23/23 11:52:47.253
    STEP: First trying to evict a pod which shouldn't be evictable 04/23/23 11:52:49.289
    STEP: Waiting for all pods to be running 04/23/23 11:52:49.291
    Apr 23 11:52:49.302: INFO: pods: 0 < 3
    STEP: locating a running pod 04/23/23 11:52:51.319
    STEP: Updating the pdb to allow a pod to be evicted 04/23/23 11:52:51.336
    STEP: Waiting for the pdb to be processed 04/23/23 11:52:51.35
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/23/23 11:52:53.378
    STEP: Waiting for all pods to be running 04/23/23 11:52:53.378
    STEP: Waiting for the pdb to observed all healthy pods 04/23/23 11:52:53.386
    STEP: Patching the pdb to disallow a pod to be evicted 04/23/23 11:52:53.432
    STEP: Waiting for the pdb to be processed 04/23/23 11:52:53.478
    STEP: Waiting for all pods to be running 04/23/23 11:52:55.501
    STEP: locating a running pod 04/23/23 11:52:55.509
    STEP: Deleting the pdb to allow a pod to be evicted 04/23/23 11:52:55.537
    STEP: Waiting for the pdb to be deleted 04/23/23 11:52:55.548
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/23/23 11:52:55.557
    STEP: Waiting for all pods to be running 04/23/23 11:52:55.557
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:52:55.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      tear down framework | framework.go:193
    STEP: Destroying namespace "disruption-5027" for this suite. 04/23/23 11:52:55.618
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:240
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:52:55.644
Apr 23 11:52:55.644: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 11:52:55.649
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:52:55.689
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:52:55.697
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:240
STEP: Creating configMap with name cm-test-opt-del-561d5833-d6d6-48c1-a7fa-3622ff03a84c 04/23/23 11:52:55.713
STEP: Creating configMap with name cm-test-opt-upd-0e7c9742-50ad-47c3-8c35-67419c892a95 04/23/23 11:52:55.734
STEP: Creating the pod 04/23/23 11:52:55.742
Apr 23 11:52:55.764: INFO: Waiting up to 5m0s for pod "pod-configmaps-035dc131-8167-4063-899a-fce4623b16e9" in namespace "configmap-9657" to be "running and ready"
Apr 23 11:52:55.772: INFO: Pod "pod-configmaps-035dc131-8167-4063-899a-fce4623b16e9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.40784ms
Apr 23 11:52:55.772: INFO: The phase of Pod pod-configmaps-035dc131-8167-4063-899a-fce4623b16e9 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:52:57.780: INFO: Pod "pod-configmaps-035dc131-8167-4063-899a-fce4623b16e9": Phase="Running", Reason="", readiness=true. Elapsed: 2.016779872s
Apr 23 11:52:57.781: INFO: The phase of Pod pod-configmaps-035dc131-8167-4063-899a-fce4623b16e9 is Running (Ready = true)
Apr 23 11:52:57.781: INFO: Pod "pod-configmaps-035dc131-8167-4063-899a-fce4623b16e9" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-561d5833-d6d6-48c1-a7fa-3622ff03a84c 04/23/23 11:52:57.847
STEP: Updating configmap cm-test-opt-upd-0e7c9742-50ad-47c3-8c35-67419c892a95 04/23/23 11:52:57.86
STEP: Creating configMap with name cm-test-opt-create-d0b98b54-b0d3-4334-80f0-808f4994c488 04/23/23 11:52:57.874
STEP: waiting to observe update in volume 04/23/23 11:52:57.895
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 11:52:59.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-9657" for this suite. 04/23/23 11:52:59.987
------------------------------
â€¢ [4.354 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:240

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:52:55.644
    Apr 23 11:52:55.644: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 11:52:55.649
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:52:55.689
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:52:55.697
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:240
    STEP: Creating configMap with name cm-test-opt-del-561d5833-d6d6-48c1-a7fa-3622ff03a84c 04/23/23 11:52:55.713
    STEP: Creating configMap with name cm-test-opt-upd-0e7c9742-50ad-47c3-8c35-67419c892a95 04/23/23 11:52:55.734
    STEP: Creating the pod 04/23/23 11:52:55.742
    Apr 23 11:52:55.764: INFO: Waiting up to 5m0s for pod "pod-configmaps-035dc131-8167-4063-899a-fce4623b16e9" in namespace "configmap-9657" to be "running and ready"
    Apr 23 11:52:55.772: INFO: Pod "pod-configmaps-035dc131-8167-4063-899a-fce4623b16e9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.40784ms
    Apr 23 11:52:55.772: INFO: The phase of Pod pod-configmaps-035dc131-8167-4063-899a-fce4623b16e9 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:52:57.780: INFO: Pod "pod-configmaps-035dc131-8167-4063-899a-fce4623b16e9": Phase="Running", Reason="", readiness=true. Elapsed: 2.016779872s
    Apr 23 11:52:57.781: INFO: The phase of Pod pod-configmaps-035dc131-8167-4063-899a-fce4623b16e9 is Running (Ready = true)
    Apr 23 11:52:57.781: INFO: Pod "pod-configmaps-035dc131-8167-4063-899a-fce4623b16e9" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-561d5833-d6d6-48c1-a7fa-3622ff03a84c 04/23/23 11:52:57.847
    STEP: Updating configmap cm-test-opt-upd-0e7c9742-50ad-47c3-8c35-67419c892a95 04/23/23 11:52:57.86
    STEP: Creating configMap with name cm-test-opt-create-d0b98b54-b0d3-4334-80f0-808f4994c488 04/23/23 11:52:57.874
    STEP: waiting to observe update in volume 04/23/23 11:52:57.895
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:52:59.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-9657" for this suite. 04/23/23 11:52:59.987
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:53:00.004
Apr 23 11:53:00.005: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename custom-resource-definition 04/23/23 11:53:00.007
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:53:00.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:53:00.051
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Apr 23 11:53:00.055: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:53:01.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "custom-resource-definition-4144" for this suite. 04/23/23 11:53:01.119
------------------------------
â€¢ [1.131 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:53:00.004
    Apr 23 11:53:00.005: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename custom-resource-definition 04/23/23 11:53:00.007
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:53:00.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:53:00.051
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Apr 23 11:53:00.055: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:53:01.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "custom-resource-definition-4144" for this suite. 04/23/23 11:53:01.119
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:308
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:53:01.137
Apr 23 11:53:01.138: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 11:53:01.15
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:53:01.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:53:01.188
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 11:53:01.219
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 11:53:02.35
STEP: Deploying the webhook pod 04/23/23 11:53:02.367
STEP: Wait for the deployment to be ready 04/23/23 11:53:02.389
Apr 23 11:53:02.413: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 23 11:53:04.438: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 11, 53, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 53, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 53, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 53, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/23/23 11:53:06.446
STEP: Verifying the service has paired with the endpoint 04/23/23 11:53:06.467
Apr 23 11:53:07.468: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:308
STEP: Registering the crd webhook via the AdmissionRegistration API 04/23/23 11:53:07.493
STEP: Creating a custom resource definition that should be denied by the webhook 04/23/23 11:53:07.539
Apr 23 11:53:07.539: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:53:07.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-5561" for this suite. 04/23/23 11:53:07.678
STEP: Destroying namespace "webhook-5561-markers" for this suite. 04/23/23 11:53:07.691
------------------------------
â€¢ [SLOW TEST] [6.572 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:53:01.137
    Apr 23 11:53:01.138: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 11:53:01.15
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:53:01.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:53:01.188
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 11:53:01.219
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 11:53:02.35
    STEP: Deploying the webhook pod 04/23/23 11:53:02.367
    STEP: Wait for the deployment to be ready 04/23/23 11:53:02.389
    Apr 23 11:53:02.413: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 23 11:53:04.438: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 11, 53, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 53, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 11, 53, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 11, 53, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/23/23 11:53:06.446
    STEP: Verifying the service has paired with the endpoint 04/23/23 11:53:06.467
    Apr 23 11:53:07.468: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:308
    STEP: Registering the crd webhook via the AdmissionRegistration API 04/23/23 11:53:07.493
    STEP: Creating a custom resource definition that should be denied by the webhook 04/23/23 11:53:07.539
    Apr 23 11:53:07.539: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:53:07.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-5561" for this suite. 04/23/23 11:53:07.678
    STEP: Destroying namespace "webhook-5561-markers" for this suite. 04/23/23 11:53:07.691
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:53:07.746
Apr 23 11:53:07.746: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pod-network-test 04/23/23 11:53:07.751
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:53:07.833
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:53:07.842
[BeforeEach] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:31
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-9081 04/23/23 11:53:07.848
STEP: creating a selector 04/23/23 11:53:07.848
STEP: Creating the service pods in kubernetes 04/23/23 11:53:07.848
Apr 23 11:53:07.849: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 23 11:53:07.925: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9081" to be "running and ready"
Apr 23 11:53:07.944: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.091901ms
Apr 23 11:53:07.944: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:53:09.960: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034311339s
Apr 23 11:53:09.960: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:53:11.954: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.028030144s
Apr 23 11:53:11.954: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:53:13.959: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.033018493s
Apr 23 11:53:13.959: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:53:15.957: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.031338371s
Apr 23 11:53:15.957: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:53:17.955: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.029210953s
Apr 23 11:53:17.955: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 11:53:19.964: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.038033688s
Apr 23 11:53:19.964: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 23 11:53:19.964: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 23 11:53:19.972: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9081" to be "running and ready"
Apr 23 11:53:19.979: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 6.82086ms
Apr 23 11:53:19.979: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 23 11:53:19.979: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 23 11:53:19.989: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9081" to be "running and ready"
Apr 23 11:53:19.996: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 6.655101ms
Apr 23 11:53:19.996: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 23 11:53:19.996: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/23/23 11:53:20.002
Apr 23 11:53:20.027: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9081" to be "running"
Apr 23 11:53:20.051: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 23.366894ms
Apr 23 11:53:22.060: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.032149224s
Apr 23 11:53:22.060: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 23 11:53:22.067: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-9081" to be "running"
Apr 23 11:53:22.072: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 5.052127ms
Apr 23 11:53:22.072: INFO: Pod "host-test-container-pod" satisfied condition "running"
Apr 23 11:53:22.081: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 23 11:53:22.081: INFO: Going to poll 10.233.65.143 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 23 11:53:22.088: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.65.143:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9081 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 11:53:22.088: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:53:22.090: INFO: ExecWithOptions: Clientset creation
Apr 23 11:53:22.090: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9081/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.65.143%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 23 11:53:22.242: INFO: Found all 1 expected endpoints: [netserver-0]
Apr 23 11:53:22.242: INFO: Going to poll 10.233.66.173 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 23 11:53:22.248: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.66.173:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9081 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 11:53:22.248: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:53:22.250: INFO: ExecWithOptions: Clientset creation
Apr 23 11:53:22.250: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9081/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.66.173%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 23 11:53:22.358: INFO: Found all 1 expected endpoints: [netserver-1]
Apr 23 11:53:22.358: INFO: Going to poll 10.233.64.79 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 23 11:53:22.365: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.64.79:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9081 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 11:53:22.365: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:53:22.367: INFO: ExecWithOptions: Clientset creation
Apr 23 11:53:22.367: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9081/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.64.79%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 23 11:53:22.517: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/node/init/init.go:32
Apr 23 11:53:22.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Networking
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Networking
  tear down framework | framework.go:193
STEP: Destroying namespace "pod-network-test-9081" for this suite. 04/23/23 11:53:22.528
------------------------------
â€¢ [SLOW TEST] [14.837 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:53:07.746
    Apr 23 11:53:07.746: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pod-network-test 04/23/23 11:53:07.751
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:53:07.833
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:53:07.842
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:31
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-9081 04/23/23 11:53:07.848
    STEP: creating a selector 04/23/23 11:53:07.848
    STEP: Creating the service pods in kubernetes 04/23/23 11:53:07.848
    Apr 23 11:53:07.849: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 23 11:53:07.925: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9081" to be "running and ready"
    Apr 23 11:53:07.944: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.091901ms
    Apr 23 11:53:07.944: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:53:09.960: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034311339s
    Apr 23 11:53:09.960: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:53:11.954: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.028030144s
    Apr 23 11:53:11.954: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:53:13.959: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.033018493s
    Apr 23 11:53:13.959: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:53:15.957: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.031338371s
    Apr 23 11:53:15.957: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:53:17.955: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.029210953s
    Apr 23 11:53:17.955: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 11:53:19.964: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.038033688s
    Apr 23 11:53:19.964: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 23 11:53:19.964: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 23 11:53:19.972: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9081" to be "running and ready"
    Apr 23 11:53:19.979: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 6.82086ms
    Apr 23 11:53:19.979: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 23 11:53:19.979: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 23 11:53:19.989: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9081" to be "running and ready"
    Apr 23 11:53:19.996: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 6.655101ms
    Apr 23 11:53:19.996: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 23 11:53:19.996: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/23/23 11:53:20.002
    Apr 23 11:53:20.027: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9081" to be "running"
    Apr 23 11:53:20.051: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 23.366894ms
    Apr 23 11:53:22.060: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.032149224s
    Apr 23 11:53:22.060: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 23 11:53:22.067: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-9081" to be "running"
    Apr 23 11:53:22.072: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 5.052127ms
    Apr 23 11:53:22.072: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Apr 23 11:53:22.081: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 23 11:53:22.081: INFO: Going to poll 10.233.65.143 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Apr 23 11:53:22.088: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.65.143:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9081 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 11:53:22.088: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:53:22.090: INFO: ExecWithOptions: Clientset creation
    Apr 23 11:53:22.090: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9081/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.65.143%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 23 11:53:22.242: INFO: Found all 1 expected endpoints: [netserver-0]
    Apr 23 11:53:22.242: INFO: Going to poll 10.233.66.173 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Apr 23 11:53:22.248: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.66.173:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9081 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 11:53:22.248: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:53:22.250: INFO: ExecWithOptions: Clientset creation
    Apr 23 11:53:22.250: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9081/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.66.173%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 23 11:53:22.358: INFO: Found all 1 expected endpoints: [netserver-1]
    Apr 23 11:53:22.358: INFO: Going to poll 10.233.64.79 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Apr 23 11:53:22.365: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.64.79:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9081 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 11:53:22.365: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:53:22.367: INFO: ExecWithOptions: Clientset creation
    Apr 23 11:53:22.367: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9081/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.64.79%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 23 11:53:22.517: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:53:22.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Networking
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Networking
      tear down framework | framework.go:193
    STEP: Destroying namespace "pod-network-test-9081" for this suite. 04/23/23 11:53:22.528
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:89
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:53:22.583
Apr 23 11:53:22.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:53:22.586
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:53:22.616
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:53:22.622
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:89
STEP: Creating configMap with name projected-configmap-test-volume-map-2cad6573-729e-47a6-a824-41a5efcbe677 04/23/23 11:53:22.628
STEP: Creating a pod to test consume configMaps 04/23/23 11:53:22.638
Apr 23 11:53:22.653: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386" in namespace "projected-466" to be "Succeeded or Failed"
Apr 23 11:53:22.661: INFO: Pod "pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386": Phase="Pending", Reason="", readiness=false. Elapsed: 7.559303ms
Apr 23 11:53:24.671: INFO: Pod "pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018134108s
Apr 23 11:53:26.669: INFO: Pod "pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016470332s
STEP: Saw pod success 04/23/23 11:53:26.671
Apr 23 11:53:26.671: INFO: Pod "pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386" satisfied condition "Succeeded or Failed"
Apr 23 11:53:26.678: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386 container agnhost-container: <nil>
STEP: delete the pod 04/23/23 11:53:26.694
Apr 23 11:53:26.717: INFO: Waiting for pod pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386 to disappear
Apr 23 11:53:26.724: INFO: Pod pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Apr 23 11:53:26.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-466" for this suite. 04/23/23 11:53:26.739
------------------------------
â€¢ [4.171 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:53:22.583
    Apr 23 11:53:22.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:53:22.586
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:53:22.616
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:53:22.622
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:89
    STEP: Creating configMap with name projected-configmap-test-volume-map-2cad6573-729e-47a6-a824-41a5efcbe677 04/23/23 11:53:22.628
    STEP: Creating a pod to test consume configMaps 04/23/23 11:53:22.638
    Apr 23 11:53:22.653: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386" in namespace "projected-466" to be "Succeeded or Failed"
    Apr 23 11:53:22.661: INFO: Pod "pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386": Phase="Pending", Reason="", readiness=false. Elapsed: 7.559303ms
    Apr 23 11:53:24.671: INFO: Pod "pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018134108s
    Apr 23 11:53:26.669: INFO: Pod "pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016470332s
    STEP: Saw pod success 04/23/23 11:53:26.671
    Apr 23 11:53:26.671: INFO: Pod "pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386" satisfied condition "Succeeded or Failed"
    Apr 23 11:53:26.678: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386 container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 11:53:26.694
    Apr 23 11:53:26.717: INFO: Waiting for pod pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386 to disappear
    Apr 23 11:53:26.724: INFO: Pod pod-projected-configmaps-9a47a59a-bad0-4e09-9151-c99aef704386 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:53:26.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-466" for this suite. 04/23/23 11:53:26.739
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:587
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:53:26.755
Apr 23 11:53:26.755: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename statefulset 04/23/23 11:53:26.759
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:53:26.795
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:53:26.802
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-5592 04/23/23 11:53:26.809
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:587
STEP: Initializing watcher for selector baz=blah,foo=bar 04/23/23 11:53:26.834
STEP: Creating stateful set ss in namespace statefulset-5592 04/23/23 11:53:26.843
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5592 04/23/23 11:53:26.863
Apr 23 11:53:26.871: INFO: Found 0 stateful pods, waiting for 1
Apr 23 11:53:36.882: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 04/23/23 11:53:36.883
Apr 23 11:53:36.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 23 11:53:37.196: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 23 11:53:37.196: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 23 11:53:37.197: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 23 11:53:37.204: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 23 11:53:47.211: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 11:53:47.211: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 11:53:47.238: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999623s
Apr 23 11:53:48.248: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.992974452s
Apr 23 11:53:49.256: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.98285482s
Apr 23 11:53:50.262: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.974593212s
Apr 23 11:53:51.269: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.968893266s
Apr 23 11:53:52.280: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.961621388s
Apr 23 11:53:53.290: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.950491352s
Apr 23 11:53:54.299: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.940616172s
Apr 23 11:53:55.304: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.932042077s
Apr 23 11:53:56.313: INFO: Verifying statefulset ss doesn't scale past 1 for another 925.559731ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5592 04/23/23 11:53:57.313
Apr 23 11:53:57.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 23 11:53:57.768: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 23 11:53:57.768: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 23 11:53:57.768: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 23 11:53:57.774: INFO: Found 1 stateful pods, waiting for 3
Apr 23 11:54:07.794: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 11:54:07.795: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 11:54:07.795: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 04/23/23 11:54:07.795
STEP: Scale down will halt with unhealthy stateful pod 04/23/23 11:54:07.796
Apr 23 11:54:07.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 23 11:54:08.139: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 23 11:54:08.139: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 23 11:54:08.139: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 23 11:54:08.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 23 11:54:08.429: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 23 11:54:08.429: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 23 11:54:08.430: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 23 11:54:08.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 23 11:54:08.721: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 23 11:54:08.721: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 23 11:54:08.721: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 23 11:54:08.721: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 11:54:08.728: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 23 11:54:18.756: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 11:54:18.756: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 11:54:18.756: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 11:54:18.795: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999939s
Apr 23 11:54:19.803: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.980937201s
Apr 23 11:54:20.814: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.972667444s
Apr 23 11:54:21.821: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.962114126s
Apr 23 11:54:22.829: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.955226792s
Apr 23 11:54:23.838: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.947406921s
Apr 23 11:54:24.846: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.938022768s
Apr 23 11:54:25.859: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.929765093s
Apr 23 11:54:26.870: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.917307139s
Apr 23 11:54:27.878: INFO: Verifying statefulset ss doesn't scale past 3 for another 906.244032ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5592 04/23/23 11:54:28.878
Apr 23 11:54:28.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 23 11:54:29.138: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 23 11:54:29.138: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 23 11:54:29.138: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 23 11:54:29.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 23 11:54:29.424: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 23 11:54:29.424: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 23 11:54:29.424: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 23 11:54:29.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 23 11:54:29.896: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 23 11:54:29.896: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 23 11:54:29.896: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 23 11:54:29.896: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 04/23/23 11:54:39.957
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Apr 23 11:54:39.957: INFO: Deleting all statefulset in ns statefulset-5592
Apr 23 11:54:39.964: INFO: Scaling statefulset ss to 0
Apr 23 11:54:39.987: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 11:54:39.993: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Apr 23 11:54:40.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-5592" for this suite. 04/23/23 11:54:40.027
------------------------------
â€¢ [SLOW TEST] [73.285 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:587

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:53:26.755
    Apr 23 11:53:26.755: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename statefulset 04/23/23 11:53:26.759
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:53:26.795
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:53:26.802
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-5592 04/23/23 11:53:26.809
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:587
    STEP: Initializing watcher for selector baz=blah,foo=bar 04/23/23 11:53:26.834
    STEP: Creating stateful set ss in namespace statefulset-5592 04/23/23 11:53:26.843
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5592 04/23/23 11:53:26.863
    Apr 23 11:53:26.871: INFO: Found 0 stateful pods, waiting for 1
    Apr 23 11:53:36.882: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 04/23/23 11:53:36.883
    Apr 23 11:53:36.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 23 11:53:37.196: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 23 11:53:37.196: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 23 11:53:37.197: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 23 11:53:37.204: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Apr 23 11:53:47.211: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 23 11:53:47.211: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 23 11:53:47.238: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999623s
    Apr 23 11:53:48.248: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.992974452s
    Apr 23 11:53:49.256: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.98285482s
    Apr 23 11:53:50.262: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.974593212s
    Apr 23 11:53:51.269: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.968893266s
    Apr 23 11:53:52.280: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.961621388s
    Apr 23 11:53:53.290: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.950491352s
    Apr 23 11:53:54.299: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.940616172s
    Apr 23 11:53:55.304: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.932042077s
    Apr 23 11:53:56.313: INFO: Verifying statefulset ss doesn't scale past 1 for another 925.559731ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5592 04/23/23 11:53:57.313
    Apr 23 11:53:57.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 23 11:53:57.768: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 23 11:53:57.768: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 23 11:53:57.768: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 23 11:53:57.774: INFO: Found 1 stateful pods, waiting for 3
    Apr 23 11:54:07.794: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 23 11:54:07.795: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 23 11:54:07.795: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 04/23/23 11:54:07.795
    STEP: Scale down will halt with unhealthy stateful pod 04/23/23 11:54:07.796
    Apr 23 11:54:07.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 23 11:54:08.139: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 23 11:54:08.139: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 23 11:54:08.139: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 23 11:54:08.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 23 11:54:08.429: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 23 11:54:08.429: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 23 11:54:08.430: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 23 11:54:08.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 23 11:54:08.721: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 23 11:54:08.721: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 23 11:54:08.721: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 23 11:54:08.721: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 23 11:54:08.728: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Apr 23 11:54:18.756: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 23 11:54:18.756: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Apr 23 11:54:18.756: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Apr 23 11:54:18.795: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999939s
    Apr 23 11:54:19.803: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.980937201s
    Apr 23 11:54:20.814: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.972667444s
    Apr 23 11:54:21.821: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.962114126s
    Apr 23 11:54:22.829: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.955226792s
    Apr 23 11:54:23.838: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.947406921s
    Apr 23 11:54:24.846: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.938022768s
    Apr 23 11:54:25.859: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.929765093s
    Apr 23 11:54:26.870: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.917307139s
    Apr 23 11:54:27.878: INFO: Verifying statefulset ss doesn't scale past 3 for another 906.244032ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5592 04/23/23 11:54:28.878
    Apr 23 11:54:28.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 23 11:54:29.138: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 23 11:54:29.138: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 23 11:54:29.138: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 23 11:54:29.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 23 11:54:29.424: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 23 11:54:29.424: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 23 11:54:29.424: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 23 11:54:29.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-5592 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 23 11:54:29.896: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 23 11:54:29.896: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 23 11:54:29.896: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 23 11:54:29.896: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 04/23/23 11:54:39.957
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Apr 23 11:54:39.957: INFO: Deleting all statefulset in ns statefulset-5592
    Apr 23 11:54:39.964: INFO: Scaling statefulset ss to 0
    Apr 23 11:54:39.987: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 23 11:54:39.993: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:54:40.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-5592" for this suite. 04/23/23 11:54:40.027
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:47
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:54:40.042
Apr 23 11:54:40.042: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:54:40.046
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:54:40.092
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:54:40.099
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:47
STEP: Creating configMap with name projected-configmap-test-volume-c7eb3634-b2e7-4560-bede-1cc721ba61e6 04/23/23 11:54:40.104
STEP: Creating a pod to test consume configMaps 04/23/23 11:54:40.112
Apr 23 11:54:40.128: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62" in namespace "projected-3604" to be "Succeeded or Failed"
Apr 23 11:54:40.137: INFO: Pod "pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62": Phase="Pending", Reason="", readiness=false. Elapsed: 8.843662ms
Apr 23 11:54:42.144: INFO: Pod "pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016139732s
Apr 23 11:54:44.146: INFO: Pod "pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017843781s
STEP: Saw pod success 04/23/23 11:54:44.146
Apr 23 11:54:44.147: INFO: Pod "pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62" satisfied condition "Succeeded or Failed"
Apr 23 11:54:44.154: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62 container agnhost-container: <nil>
STEP: delete the pod 04/23/23 11:54:44.166
Apr 23 11:54:44.186: INFO: Waiting for pod pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62 to disappear
Apr 23 11:54:44.195: INFO: Pod pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Apr 23 11:54:44.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-3604" for this suite. 04/23/23 11:54:44.21
------------------------------
â€¢ [4.180 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:47

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:54:40.042
    Apr 23 11:54:40.042: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:54:40.046
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:54:40.092
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:54:40.099
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:47
    STEP: Creating configMap with name projected-configmap-test-volume-c7eb3634-b2e7-4560-bede-1cc721ba61e6 04/23/23 11:54:40.104
    STEP: Creating a pod to test consume configMaps 04/23/23 11:54:40.112
    Apr 23 11:54:40.128: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62" in namespace "projected-3604" to be "Succeeded or Failed"
    Apr 23 11:54:40.137: INFO: Pod "pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62": Phase="Pending", Reason="", readiness=false. Elapsed: 8.843662ms
    Apr 23 11:54:42.144: INFO: Pod "pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016139732s
    Apr 23 11:54:44.146: INFO: Pod "pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017843781s
    STEP: Saw pod success 04/23/23 11:54:44.146
    Apr 23 11:54:44.147: INFO: Pod "pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62" satisfied condition "Succeeded or Failed"
    Apr 23 11:54:44.154: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62 container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 11:54:44.166
    Apr 23 11:54:44.186: INFO: Waiting for pod pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62 to disappear
    Apr 23 11:54:44.195: INFO: Pod pod-projected-configmaps-ae181f30-48bf-44fe-9725-7f0df5537e62 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:54:44.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-3604" for this suite. 04/23/23 11:54:44.21
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:54:44.225
Apr 23 11:54:44.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename conformance-tests 04/23/23 11:54:44.226
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:54:44.311
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:54:44.315
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/metrics/init/init.go:31
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 04/23/23 11:54:44.32
Apr 23 11:54:44.320: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/node/init/init.go:32
Apr 23 11:54:44.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-architecture] Conformance Tests
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-architecture] Conformance Tests
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-architecture] Conformance Tests
  tear down framework | framework.go:193
STEP: Destroying namespace "conformance-tests-5758" for this suite. 04/23/23 11:54:44.338
------------------------------
â€¢ [0.124 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:54:44.225
    Apr 23 11:54:44.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename conformance-tests 04/23/23 11:54:44.226
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:54:44.311
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:54:44.315
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/metrics/init/init.go:31
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 04/23/23 11:54:44.32
    Apr 23 11:54:44.320: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:54:44.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-architecture] Conformance Tests
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-architecture] Conformance Tests
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-architecture] Conformance Tests
      tear down framework | framework.go:193
    STEP: Destroying namespace "conformance-tests-5758" for this suite. 04/23/23 11:54:44.338
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:261
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:54:44.353
Apr 23 11:54:44.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:54:44.357
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:54:44.388
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:54:44.393
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:261
STEP: Creating a pod to test downward API volume plugin 04/23/23 11:54:44.398
Apr 23 11:54:44.423: INFO: Waiting up to 5m0s for pod "downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7" in namespace "projected-3624" to be "Succeeded or Failed"
Apr 23 11:54:44.430: INFO: Pod "downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.816069ms
Apr 23 11:54:46.453: INFO: Pod "downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030325026s
Apr 23 11:54:48.436: INFO: Pod "downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012948803s
STEP: Saw pod success 04/23/23 11:54:48.436
Apr 23 11:54:48.437: INFO: Pod "downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7" satisfied condition "Succeeded or Failed"
Apr 23 11:54:48.443: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7 container client-container: <nil>
STEP: delete the pod 04/23/23 11:54:48.46
Apr 23 11:54:48.506: INFO: Waiting for pod downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7 to disappear
Apr 23 11:54:48.518: INFO: Pod downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Apr 23 11:54:48.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-3624" for this suite. 04/23/23 11:54:48.526
------------------------------
â€¢ [4.190 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:261

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:54:44.353
    Apr 23 11:54:44.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:54:44.357
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:54:44.388
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:54:44.393
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:261
    STEP: Creating a pod to test downward API volume plugin 04/23/23 11:54:44.398
    Apr 23 11:54:44.423: INFO: Waiting up to 5m0s for pod "downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7" in namespace "projected-3624" to be "Succeeded or Failed"
    Apr 23 11:54:44.430: INFO: Pod "downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.816069ms
    Apr 23 11:54:46.453: INFO: Pod "downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030325026s
    Apr 23 11:54:48.436: INFO: Pod "downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012948803s
    STEP: Saw pod success 04/23/23 11:54:48.436
    Apr 23 11:54:48.437: INFO: Pod "downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7" satisfied condition "Succeeded or Failed"
    Apr 23 11:54:48.443: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7 container client-container: <nil>
    STEP: delete the pod 04/23/23 11:54:48.46
    Apr 23 11:54:48.506: INFO: Waiting for pod downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7 to disappear
    Apr 23 11:54:48.518: INFO: Pod downwardapi-volume-322b0d88-0413-4fe2-b294-d233332247e7 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:54:48.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-3624" for this suite. 04/23/23 11:54:48.526
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:54:48.558
Apr 23 11:54:48.558: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename certificates 04/23/23 11:54:48.56
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:54:48.604
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:54:48.61
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 04/23/23 11:54:49.756
STEP: getting /apis/certificates.k8s.io 04/23/23 11:54:49.764
STEP: getting /apis/certificates.k8s.io/v1 04/23/23 11:54:49.767
STEP: creating 04/23/23 11:54:49.77
STEP: getting 04/23/23 11:54:49.813
STEP: listing 04/23/23 11:54:49.822
STEP: watching 04/23/23 11:54:49.829
Apr 23 11:54:49.829: INFO: starting watch
STEP: patching 04/23/23 11:54:49.831
STEP: updating 04/23/23 11:54:49.842
Apr 23 11:54:49.859: INFO: waiting for watch events with expected annotations
Apr 23 11:54:49.859: INFO: saw patched and updated annotations
STEP: getting /approval 04/23/23 11:54:49.859
STEP: patching /approval 04/23/23 11:54:49.866
STEP: updating /approval 04/23/23 11:54:49.879
STEP: getting /status 04/23/23 11:54:49.911
STEP: patching /status 04/23/23 11:54:49.936
STEP: updating /status 04/23/23 11:54:49.953
STEP: deleting 04/23/23 11:54:49.97
STEP: deleting a collection 04/23/23 11:54:50.02
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:54:50.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "certificates-4086" for this suite. 04/23/23 11:54:50.078
------------------------------
â€¢ [1.534 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:54:48.558
    Apr 23 11:54:48.558: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename certificates 04/23/23 11:54:48.56
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:54:48.604
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:54:48.61
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 04/23/23 11:54:49.756
    STEP: getting /apis/certificates.k8s.io 04/23/23 11:54:49.764
    STEP: getting /apis/certificates.k8s.io/v1 04/23/23 11:54:49.767
    STEP: creating 04/23/23 11:54:49.77
    STEP: getting 04/23/23 11:54:49.813
    STEP: listing 04/23/23 11:54:49.822
    STEP: watching 04/23/23 11:54:49.829
    Apr 23 11:54:49.829: INFO: starting watch
    STEP: patching 04/23/23 11:54:49.831
    STEP: updating 04/23/23 11:54:49.842
    Apr 23 11:54:49.859: INFO: waiting for watch events with expected annotations
    Apr 23 11:54:49.859: INFO: saw patched and updated annotations
    STEP: getting /approval 04/23/23 11:54:49.859
    STEP: patching /approval 04/23/23 11:54:49.866
    STEP: updating /approval 04/23/23 11:54:49.879
    STEP: getting /status 04/23/23 11:54:49.911
    STEP: patching /status 04/23/23 11:54:49.936
    STEP: updating /status 04/23/23 11:54:49.953
    STEP: deleting 04/23/23 11:54:49.97
    STEP: deleting a collection 04/23/23 11:54:50.02
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:54:50.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "certificates-4086" for this suite. 04/23/23 11:54:50.078
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:504
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:54:50.094
Apr 23 11:54:50.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 11:54:50.101
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:54:50.144
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:54:50.15
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:504
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 11:54:50.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-4256" for this suite. 04/23/23 11:54:50.248
------------------------------
â€¢ [0.167 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:504

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:54:50.094
    Apr 23 11:54:50.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 11:54:50.101
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:54:50.144
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:54:50.15
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:504
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:54:50.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-4256" for this suite. 04/23/23 11:54:50.248
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:442
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:54:50.266
Apr 23 11:54:50.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 11:54:50.27
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:54:50.312
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:54:50.317
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:442
STEP: set up a multi version CRD 04/23/23 11:54:50.323
Apr 23 11:54:50.325: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: mark a version not serverd 04/23/23 11:54:55.989
STEP: check the unserved version gets removed 04/23/23 11:54:56.037
STEP: check the other version is not changed 04/23/23 11:54:59.126
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:55:04.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-2142" for this suite. 04/23/23 11:55:04.213
------------------------------
â€¢ [SLOW TEST] [13.960 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:442

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:54:50.266
    Apr 23 11:54:50.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 11:54:50.27
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:54:50.312
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:54:50.317
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:442
    STEP: set up a multi version CRD 04/23/23 11:54:50.323
    Apr 23 11:54:50.325: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: mark a version not serverd 04/23/23 11:54:55.989
    STEP: check the unserved version gets removed 04/23/23 11:54:56.037
    STEP: check the other version is not changed 04/23/23 11:54:59.126
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:55:04.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-2142" for this suite. 04/23/23 11:55:04.213
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:124
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:55:04.23
Apr 23 11:55:04.230: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 11:55:04.235
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:04.261
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:04.269
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:124
STEP: Creating projection with configMap that has name projected-configmap-test-upd-7d45d3d7-3490-4c48-bc5c-247066cf8226 04/23/23 11:55:04.284
STEP: Creating the pod 04/23/23 11:55:04.295
Apr 23 11:55:04.309: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d75b1ddc-a46e-44c5-b0d7-dd365661b3e0" in namespace "projected-3016" to be "running and ready"
Apr 23 11:55:04.315: INFO: Pod "pod-projected-configmaps-d75b1ddc-a46e-44c5-b0d7-dd365661b3e0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.914325ms
Apr 23 11:55:04.315: INFO: The phase of Pod pod-projected-configmaps-d75b1ddc-a46e-44c5-b0d7-dd365661b3e0 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:55:06.323: INFO: Pod "pod-projected-configmaps-d75b1ddc-a46e-44c5-b0d7-dd365661b3e0": Phase="Running", Reason="", readiness=true. Elapsed: 2.013646592s
Apr 23 11:55:06.323: INFO: The phase of Pod pod-projected-configmaps-d75b1ddc-a46e-44c5-b0d7-dd365661b3e0 is Running (Ready = true)
Apr 23 11:55:06.323: INFO: Pod "pod-projected-configmaps-d75b1ddc-a46e-44c5-b0d7-dd365661b3e0" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-7d45d3d7-3490-4c48-bc5c-247066cf8226 04/23/23 11:55:06.354
STEP: waiting to observe update in volume 04/23/23 11:55:06.366
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Apr 23 11:55:08.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-3016" for this suite. 04/23/23 11:55:08.408
------------------------------
â€¢ [4.190 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:55:04.23
    Apr 23 11:55:04.230: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 11:55:04.235
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:04.261
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:04.269
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:124
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-7d45d3d7-3490-4c48-bc5c-247066cf8226 04/23/23 11:55:04.284
    STEP: Creating the pod 04/23/23 11:55:04.295
    Apr 23 11:55:04.309: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d75b1ddc-a46e-44c5-b0d7-dd365661b3e0" in namespace "projected-3016" to be "running and ready"
    Apr 23 11:55:04.315: INFO: Pod "pod-projected-configmaps-d75b1ddc-a46e-44c5-b0d7-dd365661b3e0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.914325ms
    Apr 23 11:55:04.315: INFO: The phase of Pod pod-projected-configmaps-d75b1ddc-a46e-44c5-b0d7-dd365661b3e0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:55:06.323: INFO: Pod "pod-projected-configmaps-d75b1ddc-a46e-44c5-b0d7-dd365661b3e0": Phase="Running", Reason="", readiness=true. Elapsed: 2.013646592s
    Apr 23 11:55:06.323: INFO: The phase of Pod pod-projected-configmaps-d75b1ddc-a46e-44c5-b0d7-dd365661b3e0 is Running (Ready = true)
    Apr 23 11:55:06.323: INFO: Pod "pod-projected-configmaps-d75b1ddc-a46e-44c5-b0d7-dd365661b3e0" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-7d45d3d7-3490-4c48-bc5c-247066cf8226 04/23/23 11:55:06.354
    STEP: waiting to observe update in volume 04/23/23 11:55:06.366
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:55:08.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-3016" for this suite. 04/23/23 11:55:08.408
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:55:08.425
Apr 23 11:55:08.425: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename crd-webhook 04/23/23 11:55:08.428
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:08.476
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:08.479
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 04/23/23 11:55:08.483
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/23/23 11:55:09.646
STEP: Deploying the custom resource conversion webhook pod 04/23/23 11:55:09.656
STEP: Wait for the deployment to be ready 04/23/23 11:55:09.687
Apr 23 11:55:09.717: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/23/23 11:55:11.736
STEP: Verifying the service has paired with the endpoint 04/23/23 11:55:11.755
Apr 23 11:55:12.756: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Apr 23 11:55:12.765: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Creating a v1 custom resource 04/23/23 11:55:15.612
STEP: v2 custom resource should be converted 04/23/23 11:55:15.628
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:55:16.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-webhook-304" for this suite. 04/23/23 11:55:16.284
------------------------------
â€¢ [SLOW TEST] [7.873 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:55:08.425
    Apr 23 11:55:08.425: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename crd-webhook 04/23/23 11:55:08.428
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:08.476
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:08.479
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 04/23/23 11:55:08.483
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/23/23 11:55:09.646
    STEP: Deploying the custom resource conversion webhook pod 04/23/23 11:55:09.656
    STEP: Wait for the deployment to be ready 04/23/23 11:55:09.687
    Apr 23 11:55:09.717: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/23/23 11:55:11.736
    STEP: Verifying the service has paired with the endpoint 04/23/23 11:55:11.755
    Apr 23 11:55:12.756: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Apr 23 11:55:12.765: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Creating a v1 custom resource 04/23/23 11:55:15.612
    STEP: v2 custom resource should be converted 04/23/23 11:55:15.628
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:55:16.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-webhook-304" for this suite. 04/23/23 11:55:16.284
  << End Captured GinkgoWriter Output
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:466
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:55:16.299
Apr 23 11:55:16.300: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename sched-pred 04/23/23 11:55:16.306
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:16.34
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:16.358
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:97
Apr 23 11:55:16.366: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 23 11:55:16.386: INFO: Waiting for terminating namespaces to be deleted...
Apr 23 11:55:16.394: INFO: 
Logging pods the apiserver thinks is on node eingavuivie7-1 before test
Apr 23 11:55:16.408: INFO: cilium-node-init-j475c from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.409: INFO: 	Container node-init ready: true, restart count 0
Apr 23 11:55:16.409: INFO: cilium-tcvk2 from kube-system started at 2023-04-23 10:44:39 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.410: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 23 11:55:16.410: INFO: kube-addon-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.410: INFO: 	Container kube-addon-manager ready: true, restart count 0
Apr 23 11:55:16.410: INFO: kube-apiserver-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.410: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 23 11:55:16.410: INFO: kube-controller-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.410: INFO: 	Container kube-controller-manager ready: true, restart count 0
Apr 23 11:55:16.410: INFO: kube-proxy-qx9mz from kube-system started at 2023-04-23 10:40:00 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.410: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 11:55:16.410: INFO: kube-scheduler-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:29 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.411: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 23 11:55:16.411: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-tdgvz from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 11:55:16.411: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 11:55:16.411: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 23 11:55:16.411: INFO: 
Logging pods the apiserver thinks is on node eingavuivie7-2 before test
Apr 23 11:55:16.477: INFO: cilium-cw5l6 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.477: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 23 11:55:16.477: INFO: cilium-node-init-tpqk9 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.477: INFO: 	Container node-init ready: true, restart count 0
Apr 23 11:55:16.478: INFO: coredns-787d4945fb-v7bjj from kube-system started at 2023-04-23 10:46:03 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.478: INFO: 	Container coredns ready: true, restart count 0
Apr 23 11:55:16.478: INFO: kube-addon-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.478: INFO: 	Container kube-addon-manager ready: true, restart count 0
Apr 23 11:55:16.478: INFO: kube-apiserver-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.478: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 23 11:55:16.478: INFO: kube-controller-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.478: INFO: 	Container kube-controller-manager ready: true, restart count 0
Apr 23 11:55:16.478: INFO: kube-proxy-hzwld from kube-system started at 2023-04-23 10:40:58 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.478: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 11:55:16.478: INFO: kube-scheduler-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.479: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 23 11:55:16.479: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-ntx29 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 11:55:16.479: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 11:55:16.479: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 23 11:55:16.479: INFO: 
Logging pods the apiserver thinks is on node eingavuivie7-3 before test
Apr 23 11:55:16.511: INFO: cilium-node-init-btj27 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.511: INFO: 	Container node-init ready: true, restart count 0
Apr 23 11:55:16.511: INFO: cilium-operator-968f66564-jmvk7 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.511: INFO: 	Container cilium-operator ready: true, restart count 0
Apr 23 11:55:16.511: INFO: cilium-vpc26 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.511: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 23 11:55:16.511: INFO: coredns-787d4945fb-8tms9 from kube-system started at 2023-04-23 10:45:47 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.511: INFO: 	Container coredns ready: true, restart count 0
Apr 23 11:55:16.511: INFO: kube-proxy-lsxv6 from kube-system started at 2023-04-23 10:41:59 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.511: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 11:55:16.512: INFO: sonobuoy from sonobuoy started at 2023-04-23 11:11:26 +0000 UTC (1 container statuses recorded)
Apr 23 11:55:16.512: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 23 11:55:16.512: INFO: sonobuoy-e2e-job-27be2b9757534547 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 11:55:16.512: INFO: 	Container e2e ready: true, restart count 0
Apr 23 11:55:16.512: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 11:55:16.512: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-k7sgm from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 11:55:16.512: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 11:55:16.512: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:466
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/23/23 11:55:16.513
Apr 23 11:55:16.547: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-7489" to be "running"
Apr 23 11:55:16.598: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 50.236953ms
Apr 23 11:55:18.606: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.058134743s
Apr 23 11:55:18.606: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/23/23 11:55:18.612
STEP: Trying to apply a random label on the found node. 04/23/23 11:55:18.633
STEP: verifying the node has the label kubernetes.io/e2e-4e8c7196-1045-4f59-93ff-e2e368cdef34 42 04/23/23 11:55:18.651
STEP: Trying to relaunch the pod, now with labels. 04/23/23 11:55:18.667
Apr 23 11:55:18.679: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-7489" to be "not pending"
Apr 23 11:55:18.695: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 16.031003ms
Apr 23 11:55:20.710: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.030404552s
Apr 23 11:55:20.710: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-4e8c7196-1045-4f59-93ff-e2e368cdef34 off the node eingavuivie7-3 04/23/23 11:55:20.717
STEP: verifying the node doesn't have the label kubernetes.io/e2e-4e8c7196-1045-4f59-93ff-e2e368cdef34 04/23/23 11:55:20.824
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:55:20.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:88
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-pred-7489" for this suite. 04/23/23 11:55:20.869
------------------------------
â€¢ [4.587 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:466

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:55:16.299
    Apr 23 11:55:16.300: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename sched-pred 04/23/23 11:55:16.306
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:16.34
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:16.358
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:97
    Apr 23 11:55:16.366: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 23 11:55:16.386: INFO: Waiting for terminating namespaces to be deleted...
    Apr 23 11:55:16.394: INFO: 
    Logging pods the apiserver thinks is on node eingavuivie7-1 before test
    Apr 23 11:55:16.408: INFO: cilium-node-init-j475c from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.409: INFO: 	Container node-init ready: true, restart count 0
    Apr 23 11:55:16.409: INFO: cilium-tcvk2 from kube-system started at 2023-04-23 10:44:39 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.410: INFO: 	Container cilium-agent ready: true, restart count 0
    Apr 23 11:55:16.410: INFO: kube-addon-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.410: INFO: 	Container kube-addon-manager ready: true, restart count 0
    Apr 23 11:55:16.410: INFO: kube-apiserver-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.410: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 23 11:55:16.410: INFO: kube-controller-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.410: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Apr 23 11:55:16.410: INFO: kube-proxy-qx9mz from kube-system started at 2023-04-23 10:40:00 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.410: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 23 11:55:16.410: INFO: kube-scheduler-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:29 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.411: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 23 11:55:16.411: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-tdgvz from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 11:55:16.411: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 11:55:16.411: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 23 11:55:16.411: INFO: 
    Logging pods the apiserver thinks is on node eingavuivie7-2 before test
    Apr 23 11:55:16.477: INFO: cilium-cw5l6 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.477: INFO: 	Container cilium-agent ready: true, restart count 0
    Apr 23 11:55:16.477: INFO: cilium-node-init-tpqk9 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.477: INFO: 	Container node-init ready: true, restart count 0
    Apr 23 11:55:16.478: INFO: coredns-787d4945fb-v7bjj from kube-system started at 2023-04-23 10:46:03 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.478: INFO: 	Container coredns ready: true, restart count 0
    Apr 23 11:55:16.478: INFO: kube-addon-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.478: INFO: 	Container kube-addon-manager ready: true, restart count 0
    Apr 23 11:55:16.478: INFO: kube-apiserver-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.478: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 23 11:55:16.478: INFO: kube-controller-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.478: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Apr 23 11:55:16.478: INFO: kube-proxy-hzwld from kube-system started at 2023-04-23 10:40:58 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.478: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 23 11:55:16.478: INFO: kube-scheduler-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.479: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 23 11:55:16.479: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-ntx29 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 11:55:16.479: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 11:55:16.479: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 23 11:55:16.479: INFO: 
    Logging pods the apiserver thinks is on node eingavuivie7-3 before test
    Apr 23 11:55:16.511: INFO: cilium-node-init-btj27 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.511: INFO: 	Container node-init ready: true, restart count 0
    Apr 23 11:55:16.511: INFO: cilium-operator-968f66564-jmvk7 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.511: INFO: 	Container cilium-operator ready: true, restart count 0
    Apr 23 11:55:16.511: INFO: cilium-vpc26 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.511: INFO: 	Container cilium-agent ready: true, restart count 0
    Apr 23 11:55:16.511: INFO: coredns-787d4945fb-8tms9 from kube-system started at 2023-04-23 10:45:47 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.511: INFO: 	Container coredns ready: true, restart count 0
    Apr 23 11:55:16.511: INFO: kube-proxy-lsxv6 from kube-system started at 2023-04-23 10:41:59 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.511: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 23 11:55:16.512: INFO: sonobuoy from sonobuoy started at 2023-04-23 11:11:26 +0000 UTC (1 container statuses recorded)
    Apr 23 11:55:16.512: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 23 11:55:16.512: INFO: sonobuoy-e2e-job-27be2b9757534547 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 11:55:16.512: INFO: 	Container e2e ready: true, restart count 0
    Apr 23 11:55:16.512: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 11:55:16.512: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-k7sgm from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 11:55:16.512: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 11:55:16.512: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:466
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/23/23 11:55:16.513
    Apr 23 11:55:16.547: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-7489" to be "running"
    Apr 23 11:55:16.598: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 50.236953ms
    Apr 23 11:55:18.606: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.058134743s
    Apr 23 11:55:18.606: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/23/23 11:55:18.612
    STEP: Trying to apply a random label on the found node. 04/23/23 11:55:18.633
    STEP: verifying the node has the label kubernetes.io/e2e-4e8c7196-1045-4f59-93ff-e2e368cdef34 42 04/23/23 11:55:18.651
    STEP: Trying to relaunch the pod, now with labels. 04/23/23 11:55:18.667
    Apr 23 11:55:18.679: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-7489" to be "not pending"
    Apr 23 11:55:18.695: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 16.031003ms
    Apr 23 11:55:20.710: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.030404552s
    Apr 23 11:55:20.710: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-4e8c7196-1045-4f59-93ff-e2e368cdef34 off the node eingavuivie7-3 04/23/23 11:55:20.717
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-4e8c7196-1045-4f59-93ff-e2e368cdef34 04/23/23 11:55:20.824
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:55:20.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:88
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-pred-7489" for this suite. 04/23/23 11:55:20.869
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:536
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:55:20.904
Apr 23 11:55:20.904: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pods 04/23/23 11:55:20.907
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:20.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:20.943
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:536
Apr 23 11:55:20.951: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: creating the pod 04/23/23 11:55:20.953
STEP: submitting the pod to kubernetes 04/23/23 11:55:20.954
Apr 23 11:55:20.973: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c" in namespace "pods-5090" to be "running and ready"
Apr 23 11:55:20.994: INFO: Pod "pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.863163ms
Apr 23 11:55:21.004: INFO: The phase of Pod pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:55:23.014: INFO: Pod "pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040026322s
Apr 23 11:55:23.014: INFO: The phase of Pod pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:55:25.016: INFO: Pod "pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c": Phase="Running", Reason="", readiness=true. Elapsed: 4.041959981s
Apr 23 11:55:25.016: INFO: The phase of Pod pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c is Running (Ready = true)
Apr 23 11:55:25.016: INFO: Pod "pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Apr 23 11:55:25.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-5090" for this suite. 04/23/23 11:55:25.135
------------------------------
â€¢ [4.245 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:536

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:55:20.904
    Apr 23 11:55:20.904: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pods 04/23/23 11:55:20.907
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:20.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:20.943
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:536
    Apr 23 11:55:20.951: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: creating the pod 04/23/23 11:55:20.953
    STEP: submitting the pod to kubernetes 04/23/23 11:55:20.954
    Apr 23 11:55:20.973: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c" in namespace "pods-5090" to be "running and ready"
    Apr 23 11:55:20.994: INFO: Pod "pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.863163ms
    Apr 23 11:55:21.004: INFO: The phase of Pod pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:55:23.014: INFO: Pod "pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040026322s
    Apr 23 11:55:23.014: INFO: The phase of Pod pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:55:25.016: INFO: Pod "pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c": Phase="Running", Reason="", readiness=true. Elapsed: 4.041959981s
    Apr 23 11:55:25.016: INFO: The phase of Pod pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c is Running (Ready = true)
    Apr 23 11:55:25.016: INFO: Pod "pod-exec-websocket-67de3776-fbf6-4b0b-8e21-00ab07bd337c" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:55:25.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-5090" for this suite. 04/23/23 11:55:25.135
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3428
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:55:25.153
Apr 23 11:55:25.153: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 11:55:25.155
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:25.188
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:25.194
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3428
STEP: creating a Service 04/23/23 11:55:25.206
STEP: watching for the Service to be added 04/23/23 11:55:25.229
Apr 23 11:55:25.235: INFO: Found Service test-service-swpcw in namespace services-3202 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Apr 23 11:55:25.236: INFO: Service test-service-swpcw created
STEP: Getting /status 04/23/23 11:55:25.236
Apr 23 11:55:25.245: INFO: Service test-service-swpcw has LoadBalancer: {[]}
STEP: patching the ServiceStatus 04/23/23 11:55:25.245
STEP: watching for the Service to be patched 04/23/23 11:55:25.264
Apr 23 11:55:25.270: INFO: observed Service test-service-swpcw in namespace services-3202 with annotations: map[] & LoadBalancer: {[]}
Apr 23 11:55:25.270: INFO: Found Service test-service-swpcw in namespace services-3202 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Apr 23 11:55:25.271: INFO: Service test-service-swpcw has service status patched
STEP: updating the ServiceStatus 04/23/23 11:55:25.271
Apr 23 11:55:25.289: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 04/23/23 11:55:25.29
Apr 23 11:55:25.298: INFO: Observed Service test-service-swpcw in namespace services-3202 with annotations: map[] & Conditions: {[]}
Apr 23 11:55:25.298: INFO: Observed event: &Service{ObjectMeta:{test-service-swpcw  services-3202  0974a7e8-69b4-4592-9279-f6da5f5de9a0 22132 0 2023-04-23 11:55:25 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-04-23 11:55:25 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-04-23 11:55:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.233.37.240,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.233.37.240],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Apr 23 11:55:25.299: INFO: Found Service test-service-swpcw in namespace services-3202 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 23 11:55:25.299: INFO: Service test-service-swpcw has service status updated
STEP: patching the service 04/23/23 11:55:25.299
STEP: watching for the Service to be patched 04/23/23 11:55:25.321
Apr 23 11:55:25.324: INFO: observed Service test-service-swpcw in namespace services-3202 with labels: map[test-service-static:true]
Apr 23 11:55:25.324: INFO: observed Service test-service-swpcw in namespace services-3202 with labels: map[test-service-static:true]
Apr 23 11:55:25.324: INFO: observed Service test-service-swpcw in namespace services-3202 with labels: map[test-service-static:true]
Apr 23 11:55:25.324: INFO: Found Service test-service-swpcw in namespace services-3202 with labels: map[test-service:patched test-service-static:true]
Apr 23 11:55:25.324: INFO: Service test-service-swpcw patched
STEP: deleting the service 04/23/23 11:55:25.324
STEP: watching for the Service to be deleted 04/23/23 11:55:25.363
Apr 23 11:55:25.367: INFO: Observed event: ADDED
Apr 23 11:55:25.367: INFO: Observed event: MODIFIED
Apr 23 11:55:25.367: INFO: Observed event: MODIFIED
Apr 23 11:55:25.368: INFO: Observed event: MODIFIED
Apr 23 11:55:25.368: INFO: Found Service test-service-swpcw in namespace services-3202 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Apr 23 11:55:25.368: INFO: Service test-service-swpcw deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 11:55:25.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-3202" for this suite. 04/23/23 11:55:25.378
------------------------------
â€¢ [0.251 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3428

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:55:25.153
    Apr 23 11:55:25.153: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 11:55:25.155
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:25.188
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:25.194
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3428
    STEP: creating a Service 04/23/23 11:55:25.206
    STEP: watching for the Service to be added 04/23/23 11:55:25.229
    Apr 23 11:55:25.235: INFO: Found Service test-service-swpcw in namespace services-3202 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Apr 23 11:55:25.236: INFO: Service test-service-swpcw created
    STEP: Getting /status 04/23/23 11:55:25.236
    Apr 23 11:55:25.245: INFO: Service test-service-swpcw has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 04/23/23 11:55:25.245
    STEP: watching for the Service to be patched 04/23/23 11:55:25.264
    Apr 23 11:55:25.270: INFO: observed Service test-service-swpcw in namespace services-3202 with annotations: map[] & LoadBalancer: {[]}
    Apr 23 11:55:25.270: INFO: Found Service test-service-swpcw in namespace services-3202 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Apr 23 11:55:25.271: INFO: Service test-service-swpcw has service status patched
    STEP: updating the ServiceStatus 04/23/23 11:55:25.271
    Apr 23 11:55:25.289: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 04/23/23 11:55:25.29
    Apr 23 11:55:25.298: INFO: Observed Service test-service-swpcw in namespace services-3202 with annotations: map[] & Conditions: {[]}
    Apr 23 11:55:25.298: INFO: Observed event: &Service{ObjectMeta:{test-service-swpcw  services-3202  0974a7e8-69b4-4592-9279-f6da5f5de9a0 22132 0 2023-04-23 11:55:25 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-04-23 11:55:25 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-04-23 11:55:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.233.37.240,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.233.37.240],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Apr 23 11:55:25.299: INFO: Found Service test-service-swpcw in namespace services-3202 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 23 11:55:25.299: INFO: Service test-service-swpcw has service status updated
    STEP: patching the service 04/23/23 11:55:25.299
    STEP: watching for the Service to be patched 04/23/23 11:55:25.321
    Apr 23 11:55:25.324: INFO: observed Service test-service-swpcw in namespace services-3202 with labels: map[test-service-static:true]
    Apr 23 11:55:25.324: INFO: observed Service test-service-swpcw in namespace services-3202 with labels: map[test-service-static:true]
    Apr 23 11:55:25.324: INFO: observed Service test-service-swpcw in namespace services-3202 with labels: map[test-service-static:true]
    Apr 23 11:55:25.324: INFO: Found Service test-service-swpcw in namespace services-3202 with labels: map[test-service:patched test-service-static:true]
    Apr 23 11:55:25.324: INFO: Service test-service-swpcw patched
    STEP: deleting the service 04/23/23 11:55:25.324
    STEP: watching for the Service to be deleted 04/23/23 11:55:25.363
    Apr 23 11:55:25.367: INFO: Observed event: ADDED
    Apr 23 11:55:25.367: INFO: Observed event: MODIFIED
    Apr 23 11:55:25.367: INFO: Observed event: MODIFIED
    Apr 23 11:55:25.368: INFO: Observed event: MODIFIED
    Apr 23 11:55:25.368: INFO: Found Service test-service-swpcw in namespace services-3202 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Apr 23 11:55:25.368: INFO: Service test-service-swpcw deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:55:25.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-3202" for this suite. 04/23/23 11:55:25.378
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:323
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:55:25.41
Apr 23 11:55:25.410: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 11:55:25.415
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:25.448
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:25.462
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 11:55:25.503
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 11:55:26.571
STEP: Deploying the webhook pod 04/23/23 11:55:26.611
STEP: Wait for the deployment to be ready 04/23/23 11:55:26.662
Apr 23 11:55:26.678: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/23/23 11:55:28.705
STEP: Verifying the service has paired with the endpoint 04/23/23 11:55:28.738
Apr 23 11:55:29.739: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:323
Apr 23 11:55:29.746: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8337-crds.webhook.example.com via the AdmissionRegistration API 04/23/23 11:55:30.265
STEP: Creating a custom resource while v1 is storage version 04/23/23 11:55:30.306
STEP: Patching Custom Resource Definition to set v2 as storage 04/23/23 11:55:32.593
STEP: Patching the custom resource while v2 is storage version 04/23/23 11:55:32.707
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:55:33.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-3815" for this suite. 04/23/23 11:55:33.523
STEP: Destroying namespace "webhook-3815-markers" for this suite. 04/23/23 11:55:33.539
------------------------------
â€¢ [SLOW TEST] [8.148 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:323

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:55:25.41
    Apr 23 11:55:25.410: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 11:55:25.415
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:25.448
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:25.462
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 11:55:25.503
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 11:55:26.571
    STEP: Deploying the webhook pod 04/23/23 11:55:26.611
    STEP: Wait for the deployment to be ready 04/23/23 11:55:26.662
    Apr 23 11:55:26.678: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/23/23 11:55:28.705
    STEP: Verifying the service has paired with the endpoint 04/23/23 11:55:28.738
    Apr 23 11:55:29.739: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:323
    Apr 23 11:55:29.746: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8337-crds.webhook.example.com via the AdmissionRegistration API 04/23/23 11:55:30.265
    STEP: Creating a custom resource while v1 is storage version 04/23/23 11:55:30.306
    STEP: Patching Custom Resource Definition to set v2 as storage 04/23/23 11:55:32.593
    STEP: Patching the custom resource while v2 is storage version 04/23/23 11:55:32.707
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:55:33.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-3815" for this suite. 04/23/23 11:55:33.523
    STEP: Destroying namespace "webhook-3815-markers" for this suite. 04/23/23 11:55:33.539
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:79
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:55:33.599
Apr 23 11:55:33.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename secrets 04/23/23 11:55:33.607
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:33.629
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:33.642
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:79
STEP: Creating secret with name secret-test-map-5fad8f14-5adf-418c-a0ef-3e5e5a717a60 04/23/23 11:55:33.647
STEP: Creating a pod to test consume secrets 04/23/23 11:55:33.66
Apr 23 11:55:33.677: INFO: Waiting up to 5m0s for pod "pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9" in namespace "secrets-6890" to be "Succeeded or Failed"
Apr 23 11:55:33.693: INFO: Pod "pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9": Phase="Pending", Reason="", readiness=false. Elapsed: 15.121726ms
Apr 23 11:55:35.701: INFO: Pod "pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023082165s
Apr 23 11:55:37.702: INFO: Pod "pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024087659s
STEP: Saw pod success 04/23/23 11:55:37.702
Apr 23 11:55:37.702: INFO: Pod "pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9" satisfied condition "Succeeded or Failed"
Apr 23 11:55:37.708: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9 container secret-volume-test: <nil>
STEP: delete the pod 04/23/23 11:55:37.723
Apr 23 11:55:37.749: INFO: Waiting for pod pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9 to disappear
Apr 23 11:55:37.755: INFO: Pod pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Apr 23 11:55:37.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-6890" for this suite. 04/23/23 11:55:37.762
------------------------------
â€¢ [4.177 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:79

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:55:33.599
    Apr 23 11:55:33.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename secrets 04/23/23 11:55:33.607
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:33.629
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:33.642
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:79
    STEP: Creating secret with name secret-test-map-5fad8f14-5adf-418c-a0ef-3e5e5a717a60 04/23/23 11:55:33.647
    STEP: Creating a pod to test consume secrets 04/23/23 11:55:33.66
    Apr 23 11:55:33.677: INFO: Waiting up to 5m0s for pod "pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9" in namespace "secrets-6890" to be "Succeeded or Failed"
    Apr 23 11:55:33.693: INFO: Pod "pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9": Phase="Pending", Reason="", readiness=false. Elapsed: 15.121726ms
    Apr 23 11:55:35.701: INFO: Pod "pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023082165s
    Apr 23 11:55:37.702: INFO: Pod "pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024087659s
    STEP: Saw pod success 04/23/23 11:55:37.702
    Apr 23 11:55:37.702: INFO: Pod "pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9" satisfied condition "Succeeded or Failed"
    Apr 23 11:55:37.708: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9 container secret-volume-test: <nil>
    STEP: delete the pod 04/23/23 11:55:37.723
    Apr 23 11:55:37.749: INFO: Waiting for pod pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9 to disappear
    Apr 23 11:55:37.755: INFO: Pod pod-secrets-5a72f0b4-fe89-4149-8d7e-74528e2179a9 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:55:37.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-6890" for this suite. 04/23/23 11:55:37.762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:204
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:55:37.782
Apr 23 11:55:37.782: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pods 04/23/23 11:55:37.785
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:37.812
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:37.82
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:204
STEP: creating pod 04/23/23 11:55:37.827
Apr 23 11:55:37.843: INFO: Waiting up to 5m0s for pod "pod-hostip-14aba774-5da4-4a7c-b3d1-939362ba5ad9" in namespace "pods-2620" to be "running and ready"
Apr 23 11:55:37.855: INFO: Pod "pod-hostip-14aba774-5da4-4a7c-b3d1-939362ba5ad9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.731431ms
Apr 23 11:55:37.855: INFO: The phase of Pod pod-hostip-14aba774-5da4-4a7c-b3d1-939362ba5ad9 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:55:39.861: INFO: Pod "pod-hostip-14aba774-5da4-4a7c-b3d1-939362ba5ad9": Phase="Running", Reason="", readiness=true. Elapsed: 2.018674537s
Apr 23 11:55:39.862: INFO: The phase of Pod pod-hostip-14aba774-5da4-4a7c-b3d1-939362ba5ad9 is Running (Ready = true)
Apr 23 11:55:39.862: INFO: Pod "pod-hostip-14aba774-5da4-4a7c-b3d1-939362ba5ad9" satisfied condition "running and ready"
Apr 23 11:55:39.879: INFO: Pod pod-hostip-14aba774-5da4-4a7c-b3d1-939362ba5ad9 has hostIP: 192.168.121.198
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Apr 23 11:55:39.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-2620" for this suite. 04/23/23 11:55:39.895
------------------------------
â€¢ [2.128 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:55:37.782
    Apr 23 11:55:37.782: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pods 04/23/23 11:55:37.785
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:37.812
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:37.82
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:204
    STEP: creating pod 04/23/23 11:55:37.827
    Apr 23 11:55:37.843: INFO: Waiting up to 5m0s for pod "pod-hostip-14aba774-5da4-4a7c-b3d1-939362ba5ad9" in namespace "pods-2620" to be "running and ready"
    Apr 23 11:55:37.855: INFO: Pod "pod-hostip-14aba774-5da4-4a7c-b3d1-939362ba5ad9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.731431ms
    Apr 23 11:55:37.855: INFO: The phase of Pod pod-hostip-14aba774-5da4-4a7c-b3d1-939362ba5ad9 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:55:39.861: INFO: Pod "pod-hostip-14aba774-5da4-4a7c-b3d1-939362ba5ad9": Phase="Running", Reason="", readiness=true. Elapsed: 2.018674537s
    Apr 23 11:55:39.862: INFO: The phase of Pod pod-hostip-14aba774-5da4-4a7c-b3d1-939362ba5ad9 is Running (Ready = true)
    Apr 23 11:55:39.862: INFO: Pod "pod-hostip-14aba774-5da4-4a7c-b3d1-939362ba5ad9" satisfied condition "running and ready"
    Apr 23 11:55:39.879: INFO: Pod pod-hostip-14aba774-5da4-4a7c-b3d1-939362ba5ad9 has hostIP: 192.168.121.198
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:55:39.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-2620" for this suite. 04/23/23 11:55:39.895
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:275
[BeforeEach] [sig-auth] ServiceAccounts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:55:39.913
Apr 23 11:55:39.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename svcaccounts 04/23/23 11:55:39.919
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:39.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:40
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:31
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:275
STEP: Creating a pod to test service account token:  04/23/23 11:55:40.011
Apr 23 11:55:40.027: INFO: Waiting up to 5m0s for pod "test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221" in namespace "svcaccounts-8182" to be "Succeeded or Failed"
Apr 23 11:55:40.040: INFO: Pod "test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221": Phase="Pending", Reason="", readiness=false. Elapsed: 12.129719ms
Apr 23 11:55:42.048: INFO: Pod "test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020893173s
Apr 23 11:55:44.048: INFO: Pod "test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020430008s
Apr 23 11:55:46.049: INFO: Pod "test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021457836s
STEP: Saw pod success 04/23/23 11:55:46.049
Apr 23 11:55:46.050: INFO: Pod "test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221" satisfied condition "Succeeded or Failed"
Apr 23 11:55:46.057: INFO: Trying to get logs from node eingavuivie7-1 pod test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221 container agnhost-container: <nil>
STEP: delete the pod 04/23/23 11:55:46.1
Apr 23 11:55:46.132: INFO: Waiting for pod test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221 to disappear
Apr 23 11:55:46.140: INFO: Pod test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/node/init/init.go:32
Apr 23 11:55:46.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  tear down framework | framework.go:193
STEP: Destroying namespace "svcaccounts-8182" for this suite. 04/23/23 11:55:46.153
------------------------------
â€¢ [SLOW TEST] [6.259 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:55:39.913
    Apr 23 11:55:39.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename svcaccounts 04/23/23 11:55:39.919
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:39.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:40
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:31
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:275
    STEP: Creating a pod to test service account token:  04/23/23 11:55:40.011
    Apr 23 11:55:40.027: INFO: Waiting up to 5m0s for pod "test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221" in namespace "svcaccounts-8182" to be "Succeeded or Failed"
    Apr 23 11:55:40.040: INFO: Pod "test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221": Phase="Pending", Reason="", readiness=false. Elapsed: 12.129719ms
    Apr 23 11:55:42.048: INFO: Pod "test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020893173s
    Apr 23 11:55:44.048: INFO: Pod "test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020430008s
    Apr 23 11:55:46.049: INFO: Pod "test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021457836s
    STEP: Saw pod success 04/23/23 11:55:46.049
    Apr 23 11:55:46.050: INFO: Pod "test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221" satisfied condition "Succeeded or Failed"
    Apr 23 11:55:46.057: INFO: Trying to get logs from node eingavuivie7-1 pod test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221 container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 11:55:46.1
    Apr 23 11:55:46.132: INFO: Waiting for pod test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221 to disappear
    Apr 23 11:55:46.140: INFO: Pod test-pod-800e9a7e-9d62-43a8-9b9e-12624fac3221 no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:55:46.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      tear down framework | framework.go:193
    STEP: Destroying namespace "svcaccounts-8182" for this suite. 04/23/23 11:55:46.153
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:46
[BeforeEach] [sig-node] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:55:46.178
Apr 23 11:55:46.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename secrets 04/23/23 11:55:46.189
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:46.224
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:46.261
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:46
STEP: Creating secret with name secret-test-e0063f10-5893-429f-8137-a434781e5088 04/23/23 11:55:46.271
STEP: Creating a pod to test consume secrets 04/23/23 11:55:46.284
Apr 23 11:55:46.314: INFO: Waiting up to 5m0s for pod "pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199" in namespace "secrets-256" to be "Succeeded or Failed"
Apr 23 11:55:46.331: INFO: Pod "pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199": Phase="Pending", Reason="", readiness=false. Elapsed: 17.061053ms
Apr 23 11:55:48.340: INFO: Pod "pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026194796s
Apr 23 11:55:50.341: INFO: Pod "pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026822681s
STEP: Saw pod success 04/23/23 11:55:50.341
Apr 23 11:55:50.341: INFO: Pod "pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199" satisfied condition "Succeeded or Failed"
Apr 23 11:55:50.345: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199 container secret-env-test: <nil>
STEP: delete the pod 04/23/23 11:55:50.358
Apr 23 11:55:50.375: INFO: Waiting for pod pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199 to disappear
Apr 23 11:55:50.383: INFO: Pod pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/node/init/init.go:32
Apr 23 11:55:50.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-256" for this suite. 04/23/23 11:55:50.392
------------------------------
â€¢ [4.225 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:55:46.178
    Apr 23 11:55:46.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename secrets 04/23/23 11:55:46.189
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:46.224
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:46.261
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:46
    STEP: Creating secret with name secret-test-e0063f10-5893-429f-8137-a434781e5088 04/23/23 11:55:46.271
    STEP: Creating a pod to test consume secrets 04/23/23 11:55:46.284
    Apr 23 11:55:46.314: INFO: Waiting up to 5m0s for pod "pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199" in namespace "secrets-256" to be "Succeeded or Failed"
    Apr 23 11:55:46.331: INFO: Pod "pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199": Phase="Pending", Reason="", readiness=false. Elapsed: 17.061053ms
    Apr 23 11:55:48.340: INFO: Pod "pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026194796s
    Apr 23 11:55:50.341: INFO: Pod "pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026822681s
    STEP: Saw pod success 04/23/23 11:55:50.341
    Apr 23 11:55:50.341: INFO: Pod "pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199" satisfied condition "Succeeded or Failed"
    Apr 23 11:55:50.345: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199 container secret-env-test: <nil>
    STEP: delete the pod 04/23/23 11:55:50.358
    Apr 23 11:55:50.375: INFO: Waiting for pod pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199 to disappear
    Apr 23 11:55:50.383: INFO: Pod pod-secrets-840f4564-8e9b-4a8d-a489-2d5833be3199 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:55:50.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-256" for this suite. 04/23/23 11:55:50.392
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:55:50.403
Apr 23 11:55:50.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename ephemeral-containers-test 04/23/23 11:55:50.407
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:50.432
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:50.437
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 04/23/23 11:55:50.442
Apr 23 11:55:50.456: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6461" to be "running and ready"
Apr 23 11:55:50.478: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 22.142926ms
Apr 23 11:55:50.478: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:55:52.492: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.03569292s
Apr 23 11:55:52.492: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Apr 23 11:55:52.492: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 04/23/23 11:55:52.499
Apr 23 11:55:52.526: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6461" to be "container debugger running"
Apr 23 11:55:52.533: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.873261ms
Apr 23 11:55:54.546: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.019944238s
Apr 23 11:55:56.541: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.015152986s
Apr 23 11:55:56.541: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 04/23/23 11:55:56.541
Apr 23 11:55:56.542: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-6461 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 11:55:56.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:55:56.543: INFO: ExecWithOptions: Clientset creation
Apr 23 11:55:56.544: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-6461/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Apr 23 11:55:56.668: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:55:56.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Ephemeral Containers [NodeConformance]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Ephemeral Containers [NodeConformance]
  tear down framework | framework.go:193
STEP: Destroying namespace "ephemeral-containers-test-6461" for this suite. 04/23/23 11:55:56.691
------------------------------
â€¢ [SLOW TEST] [6.300 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:55:50.403
    Apr 23 11:55:50.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename ephemeral-containers-test 04/23/23 11:55:50.407
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:50.432
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:50.437
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 04/23/23 11:55:50.442
    Apr 23 11:55:50.456: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6461" to be "running and ready"
    Apr 23 11:55:50.478: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 22.142926ms
    Apr 23 11:55:50.478: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:55:52.492: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.03569292s
    Apr 23 11:55:52.492: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Apr 23 11:55:52.492: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 04/23/23 11:55:52.499
    Apr 23 11:55:52.526: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6461" to be "container debugger running"
    Apr 23 11:55:52.533: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.873261ms
    Apr 23 11:55:54.546: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.019944238s
    Apr 23 11:55:56.541: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.015152986s
    Apr 23 11:55:56.541: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 04/23/23 11:55:56.541
    Apr 23 11:55:56.542: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-6461 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 11:55:56.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:55:56.543: INFO: ExecWithOptions: Clientset creation
    Apr 23 11:55:56.544: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/ephemeral-containers-test-6461/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Apr 23 11:55:56.668: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:55:56.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Ephemeral Containers [NodeConformance]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Ephemeral Containers [NodeConformance]
      tear down framework | framework.go:193
    STEP: Destroying namespace "ephemeral-containers-test-6461" for this suite. 04/23/23 11:55:56.691
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:194
[BeforeEach] [sig-apps] Daemon set [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:55:56.709
Apr 23 11:55:56.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename daemonsets 04/23/23 11:55:56.712
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:56.741
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:56.748
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:146
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:194
Apr 23 11:55:56.799: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 04/23/23 11:55:56.813
Apr 23 11:55:56.824: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:55:56.824: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 04/23/23 11:55:56.824
Apr 23 11:55:56.876: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:55:56.877: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:55:57.888: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:55:57.888: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:55:58.886: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:55:58.886: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:55:59.892: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 23 11:55:59.892: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 04/23/23 11:55:59.897
Apr 23 11:55:59.948: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 23 11:55:59.948: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Apr 23 11:56:00.966: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:56:00.966: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 04/23/23 11:56:00.966
Apr 23 11:56:00.989: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:56:00.989: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:56:02.016: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:56:02.016: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:56:02.996: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:56:02.997: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:56:03.997: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:56:03.997: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 11:56:04.997: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 23 11:56:04.997: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:111
STEP: Deleting DaemonSet "daemon-set" 04/23/23 11:56:05.009
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9046, will wait for the garbage collector to delete the pods 04/23/23 11:56:05.009
Apr 23 11:56:05.077: INFO: Deleting DaemonSet.extensions daemon-set took: 12.266968ms
Apr 23 11:56:05.177: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.281326ms
Apr 23 11:56:07.690: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 11:56:07.690: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 23 11:56:07.700: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22548"},"items":null}

Apr 23 11:56:07.709: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22548"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:56:07.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "daemonsets-9046" for this suite. 04/23/23 11:56:07.79
------------------------------
â€¢ [SLOW TEST] [11.104 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:55:56.709
    Apr 23 11:55:56.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename daemonsets 04/23/23 11:55:56.712
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:55:56.741
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:55:56.748
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:146
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:194
    Apr 23 11:55:56.799: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 04/23/23 11:55:56.813
    Apr 23 11:55:56.824: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:55:56.824: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 04/23/23 11:55:56.824
    Apr 23 11:55:56.876: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:55:56.877: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:55:57.888: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:55:57.888: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:55:58.886: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:55:58.886: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:55:59.892: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 23 11:55:59.892: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 04/23/23 11:55:59.897
    Apr 23 11:55:59.948: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 23 11:55:59.948: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Apr 23 11:56:00.966: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:56:00.966: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 04/23/23 11:56:00.966
    Apr 23 11:56:00.989: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:56:00.989: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:56:02.016: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:56:02.016: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:56:02.996: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:56:02.997: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:56:03.997: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:56:03.997: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 11:56:04.997: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 23 11:56:04.997: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:111
    STEP: Deleting DaemonSet "daemon-set" 04/23/23 11:56:05.009
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9046, will wait for the garbage collector to delete the pods 04/23/23 11:56:05.009
    Apr 23 11:56:05.077: INFO: Deleting DaemonSet.extensions daemon-set took: 12.266968ms
    Apr 23 11:56:05.177: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.281326ms
    Apr 23 11:56:07.690: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 11:56:07.690: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 23 11:56:07.700: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22548"},"items":null}

    Apr 23 11:56:07.709: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22548"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:56:07.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "daemonsets-9046" for this suite. 04/23/23 11:56:07.79
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3219
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:56:07.831
Apr 23 11:56:07.831: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 11:56:07.834
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:07.875
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:07.888
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3219
STEP: fetching services 04/23/23 11:56:07.905
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 11:56:07.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-4758" for this suite. 04/23/23 11:56:07.935
------------------------------
â€¢ [0.132 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3219

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:56:07.831
    Apr 23 11:56:07.831: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 11:56:07.834
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:07.875
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:07.888
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3219
    STEP: fetching services 04/23/23 11:56:07.905
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:56:07.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-4758" for this suite. 04/23/23 11:56:07.935
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:56:07.965
Apr 23 11:56:07.965: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename controllerrevisions 04/23/23 11:56:07.97
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:08.075
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:08.095
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-zpbp8-daemon-set" 04/23/23 11:56:08.177
STEP: Check that daemon pods launch on every node of the cluster. 04/23/23 11:56:08.191
Apr 23 11:56:08.228: INFO: Number of nodes with available pods controlled by daemonset e2e-zpbp8-daemon-set: 0
Apr 23 11:56:08.228: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 11:56:09.265: INFO: Number of nodes with available pods controlled by daemonset e2e-zpbp8-daemon-set: 0
Apr 23 11:56:09.266: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 11:56:10.262: INFO: Number of nodes with available pods controlled by daemonset e2e-zpbp8-daemon-set: 0
Apr 23 11:56:10.262: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 11:56:11.246: INFO: Number of nodes with available pods controlled by daemonset e2e-zpbp8-daemon-set: 3
Apr 23 11:56:11.246: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-zpbp8-daemon-set
STEP: Confirm DaemonSet "e2e-zpbp8-daemon-set" successfully created with "daemonset-name=e2e-zpbp8-daemon-set" label 04/23/23 11:56:11.254
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-zpbp8-daemon-set" 04/23/23 11:56:11.269
Apr 23 11:56:11.276: INFO: Located ControllerRevision: "e2e-zpbp8-daemon-set-77cc6cb5f7"
STEP: Patching ControllerRevision "e2e-zpbp8-daemon-set-77cc6cb5f7" 04/23/23 11:56:11.282
Apr 23 11:56:11.295: INFO: e2e-zpbp8-daemon-set-77cc6cb5f7 has been patched
STEP: Create a new ControllerRevision 04/23/23 11:56:11.296
Apr 23 11:56:11.307: INFO: Created ControllerRevision: e2e-zpbp8-daemon-set-7c558cf757
STEP: Confirm that there are two ControllerRevisions 04/23/23 11:56:11.307
Apr 23 11:56:11.307: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 23 11:56:11.314: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-zpbp8-daemon-set-77cc6cb5f7" 04/23/23 11:56:11.314
STEP: Confirm that there is only one ControllerRevision 04/23/23 11:56:11.334
Apr 23 11:56:11.334: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 23 11:56:11.339: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-zpbp8-daemon-set-7c558cf757" 04/23/23 11:56:11.357
Apr 23 11:56:11.396: INFO: e2e-zpbp8-daemon-set-7c558cf757 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 04/23/23 11:56:11.396
W0423 11:56:11.411706      13 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 04/23/23 11:56:11.411
Apr 23 11:56:11.412: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 23 11:56:12.448: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 23 11:56:12.454: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-zpbp8-daemon-set-7c558cf757=updated" 04/23/23 11:56:12.454
STEP: Confirm that there is only one ControllerRevision 04/23/23 11:56:12.512
Apr 23 11:56:12.512: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 23 11:56:12.522: INFO: Found 1 ControllerRevisions
Apr 23 11:56:12.532: INFO: ControllerRevision "e2e-zpbp8-daemon-set-579d767c6d" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-zpbp8-daemon-set" 04/23/23 11:56:12.541
STEP: deleting DaemonSet.extensions e2e-zpbp8-daemon-set in namespace controllerrevisions-2513, will wait for the garbage collector to delete the pods 04/23/23 11:56:12.541
Apr 23 11:56:12.625: INFO: Deleting DaemonSet.extensions e2e-zpbp8-daemon-set took: 16.90955ms
Apr 23 11:56:12.726: INFO: Terminating DaemonSet.extensions e2e-zpbp8-daemon-set pods took: 101.121662ms
Apr 23 11:56:14.533: INFO: Number of nodes with available pods controlled by daemonset e2e-zpbp8-daemon-set: 0
Apr 23 11:56:14.533: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-zpbp8-daemon-set
Apr 23 11:56:14.540: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22664"},"items":null}

Apr 23 11:56:14.585: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22665"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:56:14.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ControllerRevision [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ControllerRevision [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "controllerrevisions-2513" for this suite. 04/23/23 11:56:14.647
------------------------------
â€¢ [SLOW TEST] [6.698 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:56:07.965
    Apr 23 11:56:07.965: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename controllerrevisions 04/23/23 11:56:07.97
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:08.075
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:08.095
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-zpbp8-daemon-set" 04/23/23 11:56:08.177
    STEP: Check that daemon pods launch on every node of the cluster. 04/23/23 11:56:08.191
    Apr 23 11:56:08.228: INFO: Number of nodes with available pods controlled by daemonset e2e-zpbp8-daemon-set: 0
    Apr 23 11:56:08.228: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 11:56:09.265: INFO: Number of nodes with available pods controlled by daemonset e2e-zpbp8-daemon-set: 0
    Apr 23 11:56:09.266: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 11:56:10.262: INFO: Number of nodes with available pods controlled by daemonset e2e-zpbp8-daemon-set: 0
    Apr 23 11:56:10.262: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 11:56:11.246: INFO: Number of nodes with available pods controlled by daemonset e2e-zpbp8-daemon-set: 3
    Apr 23 11:56:11.246: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-zpbp8-daemon-set
    STEP: Confirm DaemonSet "e2e-zpbp8-daemon-set" successfully created with "daemonset-name=e2e-zpbp8-daemon-set" label 04/23/23 11:56:11.254
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-zpbp8-daemon-set" 04/23/23 11:56:11.269
    Apr 23 11:56:11.276: INFO: Located ControllerRevision: "e2e-zpbp8-daemon-set-77cc6cb5f7"
    STEP: Patching ControllerRevision "e2e-zpbp8-daemon-set-77cc6cb5f7" 04/23/23 11:56:11.282
    Apr 23 11:56:11.295: INFO: e2e-zpbp8-daemon-set-77cc6cb5f7 has been patched
    STEP: Create a new ControllerRevision 04/23/23 11:56:11.296
    Apr 23 11:56:11.307: INFO: Created ControllerRevision: e2e-zpbp8-daemon-set-7c558cf757
    STEP: Confirm that there are two ControllerRevisions 04/23/23 11:56:11.307
    Apr 23 11:56:11.307: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 23 11:56:11.314: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-zpbp8-daemon-set-77cc6cb5f7" 04/23/23 11:56:11.314
    STEP: Confirm that there is only one ControllerRevision 04/23/23 11:56:11.334
    Apr 23 11:56:11.334: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 23 11:56:11.339: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-zpbp8-daemon-set-7c558cf757" 04/23/23 11:56:11.357
    Apr 23 11:56:11.396: INFO: e2e-zpbp8-daemon-set-7c558cf757 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 04/23/23 11:56:11.396
    W0423 11:56:11.411706      13 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 04/23/23 11:56:11.411
    Apr 23 11:56:11.412: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 23 11:56:12.448: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 23 11:56:12.454: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-zpbp8-daemon-set-7c558cf757=updated" 04/23/23 11:56:12.454
    STEP: Confirm that there is only one ControllerRevision 04/23/23 11:56:12.512
    Apr 23 11:56:12.512: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 23 11:56:12.522: INFO: Found 1 ControllerRevisions
    Apr 23 11:56:12.532: INFO: ControllerRevision "e2e-zpbp8-daemon-set-579d767c6d" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-zpbp8-daemon-set" 04/23/23 11:56:12.541
    STEP: deleting DaemonSet.extensions e2e-zpbp8-daemon-set in namespace controllerrevisions-2513, will wait for the garbage collector to delete the pods 04/23/23 11:56:12.541
    Apr 23 11:56:12.625: INFO: Deleting DaemonSet.extensions e2e-zpbp8-daemon-set took: 16.90955ms
    Apr 23 11:56:12.726: INFO: Terminating DaemonSet.extensions e2e-zpbp8-daemon-set pods took: 101.121662ms
    Apr 23 11:56:14.533: INFO: Number of nodes with available pods controlled by daemonset e2e-zpbp8-daemon-set: 0
    Apr 23 11:56:14.533: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-zpbp8-daemon-set
    Apr 23 11:56:14.540: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22664"},"items":null}

    Apr 23 11:56:14.585: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22665"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:56:14.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ControllerRevision [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ControllerRevision [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "controllerrevisions-2513" for this suite. 04/23/23 11:56:14.647
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:56:14.67
Apr 23 11:56:14.670: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename prestop 04/23/23 11:56:14.673
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:14.706
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:14.712
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-4768 04/23/23 11:56:14.719
STEP: Waiting for pods to come up. 04/23/23 11:56:14.741
Apr 23 11:56:14.742: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-4768" to be "running"
Apr 23 11:56:14.753: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 10.419704ms
Apr 23 11:56:16.761: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018561001s
Apr 23 11:56:18.759: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 4.016378445s
Apr 23 11:56:18.759: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-4768 04/23/23 11:56:18.766
Apr 23 11:56:18.779: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-4768" to be "running"
Apr 23 11:56:18.797: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 18.233558ms
Apr 23 11:56:20.807: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028312299s
Apr 23 11:56:22.808: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 4.028916429s
Apr 23 11:56:22.808: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 04/23/23 11:56:22.808
Apr 23 11:56:27.846: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 04/23/23 11:56:27.847
[AfterEach] [sig-node] PreStop
  test/e2e/framework/node/init/init.go:32
Apr 23 11:56:27.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] PreStop
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] PreStop
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] PreStop
  tear down framework | framework.go:193
STEP: Destroying namespace "prestop-4768" for this suite. 04/23/23 11:56:27.912
------------------------------
â€¢ [SLOW TEST] [13.274 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:56:14.67
    Apr 23 11:56:14.670: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename prestop 04/23/23 11:56:14.673
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:14.706
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:14.712
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-4768 04/23/23 11:56:14.719
    STEP: Waiting for pods to come up. 04/23/23 11:56:14.741
    Apr 23 11:56:14.742: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-4768" to be "running"
    Apr 23 11:56:14.753: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 10.419704ms
    Apr 23 11:56:16.761: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018561001s
    Apr 23 11:56:18.759: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 4.016378445s
    Apr 23 11:56:18.759: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-4768 04/23/23 11:56:18.766
    Apr 23 11:56:18.779: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-4768" to be "running"
    Apr 23 11:56:18.797: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 18.233558ms
    Apr 23 11:56:20.807: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028312299s
    Apr 23 11:56:22.808: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 4.028916429s
    Apr 23 11:56:22.808: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 04/23/23 11:56:22.808
    Apr 23 11:56:27.846: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 04/23/23 11:56:27.847
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:56:27.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] PreStop
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] PreStop
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] PreStop
      tear down framework | framework.go:193
    STEP: Destroying namespace "prestop-4768" for this suite. 04/23/23 11:56:27.912
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:56:27.955
Apr 23 11:56:27.956: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename dns 04/23/23 11:56:27.96
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:28.031
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:28.035
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 04/23/23 11:56:28.041
Apr 23 11:56:28.060: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7197  c29b282f-edf4-4615-a4e0-e5dc50d0155a 22753 0 2023-04-23 11:56:28 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-04-23 11:56:28 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t4gwc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t4gwc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 11:56:28.061: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-7197" to be "running and ready"
Apr 23 11:56:28.070: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 8.413626ms
Apr 23 11:56:28.070: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:56:30.080: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01855336s
Apr 23 11:56:30.080: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Apr 23 11:56:32.076: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 4.014691093s
Apr 23 11:56:32.076: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Apr 23 11:56:32.076: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 04/23/23 11:56:32.077
Apr 23 11:56:32.077: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7197 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 11:56:32.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:56:32.078: INFO: ExecWithOptions: Clientset creation
Apr 23 11:56:32.078: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-7197/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 04/23/23 11:56:32.276
Apr 23 11:56:32.277: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7197 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 11:56:32.277: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 11:56:32.278: INFO: ExecWithOptions: Clientset creation
Apr 23 11:56:32.278: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-7197/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 23 11:56:32.453: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Apr 23 11:56:32.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-7197" for this suite. 04/23/23 11:56:32.528
------------------------------
â€¢ [4.596 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:56:27.955
    Apr 23 11:56:27.956: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename dns 04/23/23 11:56:27.96
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:28.031
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:28.035
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 04/23/23 11:56:28.041
    Apr 23 11:56:28.060: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7197  c29b282f-edf4-4615-a4e0-e5dc50d0155a 22753 0 2023-04-23 11:56:28 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-04-23 11:56:28 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t4gwc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t4gwc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 11:56:28.061: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-7197" to be "running and ready"
    Apr 23 11:56:28.070: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 8.413626ms
    Apr 23 11:56:28.070: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:56:30.080: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01855336s
    Apr 23 11:56:30.080: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 11:56:32.076: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 4.014691093s
    Apr 23 11:56:32.076: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Apr 23 11:56:32.076: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 04/23/23 11:56:32.077
    Apr 23 11:56:32.077: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7197 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 11:56:32.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:56:32.078: INFO: ExecWithOptions: Clientset creation
    Apr 23 11:56:32.078: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-7197/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 04/23/23 11:56:32.276
    Apr 23 11:56:32.277: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7197 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 11:56:32.277: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 11:56:32.278: INFO: ExecWithOptions: Clientset creation
    Apr 23 11:56:32.278: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-7197/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 23 11:56:32.453: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:56:32.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-7197" for this suite. 04/23/23 11:56:32.528
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:777
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:56:32.554
Apr 23 11:56:32.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 11:56:32.557
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:32.599
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:32.603
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:777
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 11:56:32.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-3836" for this suite. 04/23/23 11:56:32.657
------------------------------
â€¢ [0.125 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:777

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:56:32.554
    Apr 23 11:56:32.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 11:56:32.557
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:32.599
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:32.603
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:777
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:56:32.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-3836" for this suite. 04/23/23 11:56:32.657
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:140
[BeforeEach] [sig-node] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:56:32.681
Apr 23 11:56:32.682: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename secrets 04/23/23 11:56:32.691
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:32.734
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:32.749
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:140
STEP: Creating projection with secret that has name secret-emptykey-test-5e3e0663-91b4-4e0f-b05d-e06fbc2e1333 04/23/23 11:56:32.754
[AfterEach] [sig-node] Secrets
  test/e2e/framework/node/init/init.go:32
Apr 23 11:56:32.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-1589" for this suite. 04/23/23 11:56:32.773
------------------------------
â€¢ [0.120 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:56:32.681
    Apr 23 11:56:32.682: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename secrets 04/23/23 11:56:32.691
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:32.734
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:32.749
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:140
    STEP: Creating projection with secret that has name secret-emptykey-test-5e3e0663-91b4-4e0f-b05d-e06fbc2e1333 04/23/23 11:56:32.754
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:56:32.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-1589" for this suite. 04/23/23 11:56:32.773
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:739
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:56:32.814
Apr 23 11:56:32.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename statefulset 04/23/23 11:56:32.816
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:32.847
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:32.852
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-4763 04/23/23 11:56:32.859
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:739
STEP: Looking for a node to schedule stateful set and pod 04/23/23 11:56:32.871
STEP: Creating pod with conflicting port in namespace statefulset-4763 04/23/23 11:56:32.884
STEP: Waiting until pod test-pod will start running in namespace statefulset-4763 04/23/23 11:56:32.925
Apr 23 11:56:32.926: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-4763" to be "running"
Apr 23 11:56:32.934: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.748316ms
Apr 23 11:56:34.954: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027950915s
Apr 23 11:56:36.943: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.017112773s
Apr 23 11:56:36.943: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-4763 04/23/23 11:56:36.944
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4763 04/23/23 11:56:36.955
Apr 23 11:56:36.989: INFO: Observed stateful pod in namespace: statefulset-4763, name: ss-0, uid: cad9164a-1c68-4194-971b-e331462cda72, status phase: Pending. Waiting for statefulset controller to delete.
Apr 23 11:56:37.020: INFO: Observed stateful pod in namespace: statefulset-4763, name: ss-0, uid: cad9164a-1c68-4194-971b-e331462cda72, status phase: Failed. Waiting for statefulset controller to delete.
Apr 23 11:56:37.039: INFO: Observed stateful pod in namespace: statefulset-4763, name: ss-0, uid: cad9164a-1c68-4194-971b-e331462cda72, status phase: Failed. Waiting for statefulset controller to delete.
Apr 23 11:56:37.050: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4763
STEP: Removing pod with conflicting port in namespace statefulset-4763 04/23/23 11:56:37.05
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4763 and will be in running state 04/23/23 11:56:37.102
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Apr 23 11:56:41.146: INFO: Deleting all statefulset in ns statefulset-4763
Apr 23 11:56:41.167: INFO: Scaling statefulset ss to 0
Apr 23 11:56:51.252: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 11:56:51.257: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Apr 23 11:56:51.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-4763" for this suite. 04/23/23 11:56:51.294
------------------------------
â€¢ [SLOW TEST] [18.493 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:56:32.814
    Apr 23 11:56:32.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename statefulset 04/23/23 11:56:32.816
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:32.847
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:32.852
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-4763 04/23/23 11:56:32.859
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:739
    STEP: Looking for a node to schedule stateful set and pod 04/23/23 11:56:32.871
    STEP: Creating pod with conflicting port in namespace statefulset-4763 04/23/23 11:56:32.884
    STEP: Waiting until pod test-pod will start running in namespace statefulset-4763 04/23/23 11:56:32.925
    Apr 23 11:56:32.926: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-4763" to be "running"
    Apr 23 11:56:32.934: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.748316ms
    Apr 23 11:56:34.954: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027950915s
    Apr 23 11:56:36.943: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.017112773s
    Apr 23 11:56:36.943: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-4763 04/23/23 11:56:36.944
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4763 04/23/23 11:56:36.955
    Apr 23 11:56:36.989: INFO: Observed stateful pod in namespace: statefulset-4763, name: ss-0, uid: cad9164a-1c68-4194-971b-e331462cda72, status phase: Pending. Waiting for statefulset controller to delete.
    Apr 23 11:56:37.020: INFO: Observed stateful pod in namespace: statefulset-4763, name: ss-0, uid: cad9164a-1c68-4194-971b-e331462cda72, status phase: Failed. Waiting for statefulset controller to delete.
    Apr 23 11:56:37.039: INFO: Observed stateful pod in namespace: statefulset-4763, name: ss-0, uid: cad9164a-1c68-4194-971b-e331462cda72, status phase: Failed. Waiting for statefulset controller to delete.
    Apr 23 11:56:37.050: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4763
    STEP: Removing pod with conflicting port in namespace statefulset-4763 04/23/23 11:56:37.05
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4763 and will be in running state 04/23/23 11:56:37.102
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Apr 23 11:56:41.146: INFO: Deleting all statefulset in ns statefulset-4763
    Apr 23 11:56:41.167: INFO: Scaling statefulset ss to 0
    Apr 23 11:56:51.252: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 23 11:56:51.257: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:56:51.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-4763" for this suite. 04/23/23 11:56:51.294
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:117
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:56:51.318
Apr 23 11:56:51.319: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 11:56:51.321
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:51.349
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:51.36
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:117
STEP: Creating a pod to test emptydir 0777 on tmpfs 04/23/23 11:56:51.366
Apr 23 11:56:51.383: INFO: Waiting up to 5m0s for pod "pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51" in namespace "emptydir-4244" to be "Succeeded or Failed"
Apr 23 11:56:51.390: INFO: Pod "pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51": Phase="Pending", Reason="", readiness=false. Elapsed: 7.606982ms
Apr 23 11:56:53.402: INFO: Pod "pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019391s
Apr 23 11:56:55.397: INFO: Pod "pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014460648s
STEP: Saw pod success 04/23/23 11:56:55.398
Apr 23 11:56:55.398: INFO: Pod "pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51" satisfied condition "Succeeded or Failed"
Apr 23 11:56:55.407: INFO: Trying to get logs from node eingavuivie7-3 pod pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51 container test-container: <nil>
STEP: delete the pod 04/23/23 11:56:55.465
Apr 23 11:56:55.528: INFO: Waiting for pod pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51 to disappear
Apr 23 11:56:55.538: INFO: Pod pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 11:56:55.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-4244" for this suite. 04/23/23 11:56:55.552
------------------------------
â€¢ [4.255 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:56:51.318
    Apr 23 11:56:51.319: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 11:56:51.321
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:51.349
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:51.36
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:117
    STEP: Creating a pod to test emptydir 0777 on tmpfs 04/23/23 11:56:51.366
    Apr 23 11:56:51.383: INFO: Waiting up to 5m0s for pod "pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51" in namespace "emptydir-4244" to be "Succeeded or Failed"
    Apr 23 11:56:51.390: INFO: Pod "pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51": Phase="Pending", Reason="", readiness=false. Elapsed: 7.606982ms
    Apr 23 11:56:53.402: INFO: Pod "pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019391s
    Apr 23 11:56:55.397: INFO: Pod "pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014460648s
    STEP: Saw pod success 04/23/23 11:56:55.398
    Apr 23 11:56:55.398: INFO: Pod "pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51" satisfied condition "Succeeded or Failed"
    Apr 23 11:56:55.407: INFO: Trying to get logs from node eingavuivie7-3 pod pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51 container test-container: <nil>
    STEP: delete the pod 04/23/23 11:56:55.465
    Apr 23 11:56:55.528: INFO: Waiting for pod pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51 to disappear
    Apr 23 11:56:55.538: INFO: Pod pod-f01a2fa5-03bc-4ca8-9711-1c6a8da30f51 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:56:55.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-4244" for this suite. 04/23/23 11:56:55.552
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:317
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:56:55.592
Apr 23 11:56:55.594: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename statefulset 04/23/23 11:56:55.607
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:55.637
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:55.647
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-3754 04/23/23 11:56:55.654
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:317
STEP: Creating a new StatefulSet 04/23/23 11:56:55.666
Apr 23 11:56:55.695: INFO: Found 0 stateful pods, waiting for 3
Apr 23 11:57:05.703: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 11:57:05.704: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 11:57:05.704: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 04/23/23 11:57:05.723
Apr 23 11:57:05.751: INFO: Updating stateful set ss2
STEP: Creating a new revision 04/23/23 11:57:05.751
STEP: Not applying an update when the partition is greater than the number of replicas 04/23/23 11:57:15.779
STEP: Performing a canary update 04/23/23 11:57:15.779
Apr 23 11:57:15.810: INFO: Updating stateful set ss2
Apr 23 11:57:15.834: INFO: Waiting for Pod statefulset-3754/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
STEP: Restoring Pods to the correct revision when they are deleted 04/23/23 11:57:25.852
Apr 23 11:57:25.980: INFO: Found 2 stateful pods, waiting for 3
Apr 23 11:57:35.995: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 11:57:35.995: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 11:57:35.995: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 04/23/23 11:57:36.015
Apr 23 11:57:36.048: INFO: Updating stateful set ss2
Apr 23 11:57:36.134: INFO: Waiting for Pod statefulset-3754/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
Apr 23 11:57:46.182: INFO: Updating stateful set ss2
Apr 23 11:57:46.212: INFO: Waiting for StatefulSet statefulset-3754/ss2 to complete update
Apr 23 11:57:46.212: INFO: Waiting for Pod statefulset-3754/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
Apr 23 11:57:56.237: INFO: Waiting for StatefulSet statefulset-3754/ss2 to complete update
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Apr 23 11:58:06.228: INFO: Deleting all statefulset in ns statefulset-3754
Apr 23 11:58:06.234: INFO: Scaling statefulset ss2 to 0
Apr 23 11:58:16.272: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 11:58:16.280: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Apr 23 11:58:16.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-3754" for this suite. 04/23/23 11:58:16.338
------------------------------
â€¢ [SLOW TEST] [80.780 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:317

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:56:55.592
    Apr 23 11:56:55.594: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename statefulset 04/23/23 11:56:55.607
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:56:55.637
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:56:55.647
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-3754 04/23/23 11:56:55.654
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:317
    STEP: Creating a new StatefulSet 04/23/23 11:56:55.666
    Apr 23 11:56:55.695: INFO: Found 0 stateful pods, waiting for 3
    Apr 23 11:57:05.703: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 23 11:57:05.704: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 23 11:57:05.704: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 04/23/23 11:57:05.723
    Apr 23 11:57:05.751: INFO: Updating stateful set ss2
    STEP: Creating a new revision 04/23/23 11:57:05.751
    STEP: Not applying an update when the partition is greater than the number of replicas 04/23/23 11:57:15.779
    STEP: Performing a canary update 04/23/23 11:57:15.779
    Apr 23 11:57:15.810: INFO: Updating stateful set ss2
    Apr 23 11:57:15.834: INFO: Waiting for Pod statefulset-3754/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
    STEP: Restoring Pods to the correct revision when they are deleted 04/23/23 11:57:25.852
    Apr 23 11:57:25.980: INFO: Found 2 stateful pods, waiting for 3
    Apr 23 11:57:35.995: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 23 11:57:35.995: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 23 11:57:35.995: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 04/23/23 11:57:36.015
    Apr 23 11:57:36.048: INFO: Updating stateful set ss2
    Apr 23 11:57:36.134: INFO: Waiting for Pod statefulset-3754/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
    Apr 23 11:57:46.182: INFO: Updating stateful set ss2
    Apr 23 11:57:46.212: INFO: Waiting for StatefulSet statefulset-3754/ss2 to complete update
    Apr 23 11:57:46.212: INFO: Waiting for Pod statefulset-3754/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
    Apr 23 11:57:56.237: INFO: Waiting for StatefulSet statefulset-3754/ss2 to complete update
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Apr 23 11:58:06.228: INFO: Deleting all statefulset in ns statefulset-3754
    Apr 23 11:58:06.234: INFO: Scaling statefulset ss2 to 0
    Apr 23 11:58:16.272: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 23 11:58:16.280: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:58:16.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-3754" for this suite. 04/23/23 11:58:16.338
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:508
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:58:16.375
Apr 23 11:58:16.375: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 11:58:16.381
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:58:16.471
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:58:16.478
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 11:58:16.538
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 11:58:17.102
STEP: Deploying the webhook pod 04/23/23 11:58:17.118
STEP: Wait for the deployment to be ready 04/23/23 11:58:17.141
Apr 23 11:58:17.159: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/23/23 11:58:19.177
STEP: Verifying the service has paired with the endpoint 04/23/23 11:58:19.192
Apr 23 11:58:20.193: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:508
STEP: Creating a mutating webhook configuration 04/23/23 11:58:20.199
STEP: Updating a mutating webhook configuration's rules to not include the create operation 04/23/23 11:58:20.246
STEP: Creating a configMap that should not be mutated 04/23/23 11:58:20.259
STEP: Patching a mutating webhook configuration's rules to include the create operation 04/23/23 11:58:20.282
STEP: Creating a configMap that should be mutated 04/23/23 11:58:20.298
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 11:58:20.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-8687" for this suite. 04/23/23 11:58:20.464
STEP: Destroying namespace "webhook-8687-markers" for this suite. 04/23/23 11:58:20.507
------------------------------
â€¢ [4.156 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:508

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:58:16.375
    Apr 23 11:58:16.375: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 11:58:16.381
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:58:16.471
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:58:16.478
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 11:58:16.538
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 11:58:17.102
    STEP: Deploying the webhook pod 04/23/23 11:58:17.118
    STEP: Wait for the deployment to be ready 04/23/23 11:58:17.141
    Apr 23 11:58:17.159: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/23/23 11:58:19.177
    STEP: Verifying the service has paired with the endpoint 04/23/23 11:58:19.192
    Apr 23 11:58:20.193: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:508
    STEP: Creating a mutating webhook configuration 04/23/23 11:58:20.199
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 04/23/23 11:58:20.246
    STEP: Creating a configMap that should not be mutated 04/23/23 11:58:20.259
    STEP: Patching a mutating webhook configuration's rules to include the create operation 04/23/23 11:58:20.282
    STEP: Creating a configMap that should be mutated 04/23/23 11:58:20.298
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:58:20.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-8687" for this suite. 04/23/23 11:58:20.464
    STEP: Destroying namespace "webhook-8687-markers" for this suite. 04/23/23 11:58:20.507
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:74
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:58:20.538
Apr 23 11:58:20.538: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 11:58:20.544
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:58:20.61
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:58:20.62
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:74
STEP: Creating configMap with name configmap-test-volume-6a90df7b-0a72-4497-8977-817f46bb9e2c 04/23/23 11:58:20.626
STEP: Creating a pod to test consume configMaps 04/23/23 11:58:20.634
Apr 23 11:58:20.652: INFO: Waiting up to 5m0s for pod "pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde" in namespace "configmap-9193" to be "Succeeded or Failed"
Apr 23 11:58:20.678: INFO: Pod "pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde": Phase="Pending", Reason="", readiness=false. Elapsed: 25.314123ms
Apr 23 11:58:22.688: INFO: Pod "pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035802893s
Apr 23 11:58:24.687: INFO: Pod "pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034899047s
Apr 23 11:58:26.688: INFO: Pod "pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035228839s
STEP: Saw pod success 04/23/23 11:58:26.688
Apr 23 11:58:26.688: INFO: Pod "pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde" satisfied condition "Succeeded or Failed"
Apr 23 11:58:26.696: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde container agnhost-container: <nil>
STEP: delete the pod 04/23/23 11:58:26.737
Apr 23 11:58:26.754: INFO: Waiting for pod pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde to disappear
Apr 23 11:58:26.763: INFO: Pod pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 11:58:26.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-9193" for this suite. 04/23/23 11:58:26.773
------------------------------
â€¢ [SLOW TEST] [6.251 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:74

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:58:20.538
    Apr 23 11:58:20.538: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 11:58:20.544
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:58:20.61
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:58:20.62
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:74
    STEP: Creating configMap with name configmap-test-volume-6a90df7b-0a72-4497-8977-817f46bb9e2c 04/23/23 11:58:20.626
    STEP: Creating a pod to test consume configMaps 04/23/23 11:58:20.634
    Apr 23 11:58:20.652: INFO: Waiting up to 5m0s for pod "pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde" in namespace "configmap-9193" to be "Succeeded or Failed"
    Apr 23 11:58:20.678: INFO: Pod "pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde": Phase="Pending", Reason="", readiness=false. Elapsed: 25.314123ms
    Apr 23 11:58:22.688: INFO: Pod "pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035802893s
    Apr 23 11:58:24.687: INFO: Pod "pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034899047s
    Apr 23 11:58:26.688: INFO: Pod "pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035228839s
    STEP: Saw pod success 04/23/23 11:58:26.688
    Apr 23 11:58:26.688: INFO: Pod "pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde" satisfied condition "Succeeded or Failed"
    Apr 23 11:58:26.696: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 11:58:26.737
    Apr 23 11:58:26.754: INFO: Waiting for pod pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde to disappear
    Apr 23 11:58:26.763: INFO: Pod pod-configmaps-aba1136b-a8a3-4658-82b5-8e4c86d21dde no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:58:26.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-9193" for this suite. 04/23/23 11:58:26.773
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:207
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:58:26.803
Apr 23 11:58:26.803: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 11:58:26.807
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:58:26.84
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:58:26.846
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:207
STEP: Creating a pod to test emptydir 0666 on node default medium 04/23/23 11:58:26.852
Apr 23 11:58:26.871: INFO: Waiting up to 5m0s for pod "pod-107b8fdd-da5f-410d-bee8-01b63d88d04e" in namespace "emptydir-7957" to be "Succeeded or Failed"
Apr 23 11:58:26.885: INFO: Pod "pod-107b8fdd-da5f-410d-bee8-01b63d88d04e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.845734ms
Apr 23 11:58:28.894: INFO: Pod "pod-107b8fdd-da5f-410d-bee8-01b63d88d04e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022455845s
Apr 23 11:58:30.893: INFO: Pod "pod-107b8fdd-da5f-410d-bee8-01b63d88d04e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020954706s
Apr 23 11:58:32.896: INFO: Pod "pod-107b8fdd-da5f-410d-bee8-01b63d88d04e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024188965s
STEP: Saw pod success 04/23/23 11:58:32.896
Apr 23 11:58:32.897: INFO: Pod "pod-107b8fdd-da5f-410d-bee8-01b63d88d04e" satisfied condition "Succeeded or Failed"
Apr 23 11:58:32.905: INFO: Trying to get logs from node eingavuivie7-3 pod pod-107b8fdd-da5f-410d-bee8-01b63d88d04e container test-container: <nil>
STEP: delete the pod 04/23/23 11:58:32.922
Apr 23 11:58:32.943: INFO: Waiting for pod pod-107b8fdd-da5f-410d-bee8-01b63d88d04e to disappear
Apr 23 11:58:32.951: INFO: Pod pod-107b8fdd-da5f-410d-bee8-01b63d88d04e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 11:58:32.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-7957" for this suite. 04/23/23 11:58:32.961
------------------------------
â€¢ [SLOW TEST] [6.172 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:58:26.803
    Apr 23 11:58:26.803: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 11:58:26.807
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:58:26.84
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:58:26.846
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:207
    STEP: Creating a pod to test emptydir 0666 on node default medium 04/23/23 11:58:26.852
    Apr 23 11:58:26.871: INFO: Waiting up to 5m0s for pod "pod-107b8fdd-da5f-410d-bee8-01b63d88d04e" in namespace "emptydir-7957" to be "Succeeded or Failed"
    Apr 23 11:58:26.885: INFO: Pod "pod-107b8fdd-da5f-410d-bee8-01b63d88d04e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.845734ms
    Apr 23 11:58:28.894: INFO: Pod "pod-107b8fdd-da5f-410d-bee8-01b63d88d04e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022455845s
    Apr 23 11:58:30.893: INFO: Pod "pod-107b8fdd-da5f-410d-bee8-01b63d88d04e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020954706s
    Apr 23 11:58:32.896: INFO: Pod "pod-107b8fdd-da5f-410d-bee8-01b63d88d04e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024188965s
    STEP: Saw pod success 04/23/23 11:58:32.896
    Apr 23 11:58:32.897: INFO: Pod "pod-107b8fdd-da5f-410d-bee8-01b63d88d04e" satisfied condition "Succeeded or Failed"
    Apr 23 11:58:32.905: INFO: Trying to get logs from node eingavuivie7-3 pod pod-107b8fdd-da5f-410d-bee8-01b63d88d04e container test-container: <nil>
    STEP: delete the pod 04/23/23 11:58:32.922
    Apr 23 11:58:32.943: INFO: Waiting for pod pod-107b8fdd-da5f-410d-bee8-01b63d88d04e to disappear
    Apr 23 11:58:32.951: INFO: Pod pod-107b8fdd-da5f-410d-bee8-01b63d88d04e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:58:32.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-7957" for this suite. 04/23/23 11:58:32.961
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:58:32.979
Apr 23 11:58:32.979: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename watch 04/23/23 11:58:32.982
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:58:33.064
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:58:33.071
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:31
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 04/23/23 11:58:33.076
STEP: starting a background goroutine to produce watch events 04/23/23 11:58:33.083
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 04/23/23 11:58:33.083
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/node/init/init.go:32
Apr 23 11:58:35.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  tear down framework | framework.go:193
STEP: Destroying namespace "watch-8273" for this suite. 04/23/23 11:58:35.842
------------------------------
â€¢ [2.918 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:58:32.979
    Apr 23 11:58:32.979: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename watch 04/23/23 11:58:32.982
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:58:33.064
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:58:33.071
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:31
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 04/23/23 11:58:33.076
    STEP: starting a background goroutine to produce watch events 04/23/23 11:58:33.083
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 04/23/23 11:58:33.083
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/node/init/init.go:32
    Apr 23 11:58:35.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      tear down framework | framework.go:193
    STEP: Destroying namespace "watch-8273" for this suite. 04/23/23 11:58:35.842
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:225
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 11:58:35.901
Apr 23 11:58:35.902: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename var-expansion 04/23/23 11:58:35.903
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:58:35.935
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:58:35.94
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:225
STEP: creating the pod with failed condition 04/23/23 11:58:35.947
Apr 23 11:58:35.969: INFO: Waiting up to 2m0s for pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5" in namespace "var-expansion-7454" to be "running"
Apr 23 11:58:35.979: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.23704ms
Apr 23 11:58:37.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019810174s
Apr 23 11:58:39.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01896626s
Apr 23 11:58:41.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019121847s
Apr 23 11:58:43.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019010735s
Apr 23 11:58:45.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.019406172s
Apr 23 11:58:47.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.019900065s
Apr 23 11:58:49.986: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.017279579s
Apr 23 11:58:51.990: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.020911289s
Apr 23 11:58:53.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.018152061s
Apr 23 11:58:55.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.019332346s
Apr 23 11:58:57.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.020655435s
Apr 23 11:58:59.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.018553577s
Apr 23 11:59:01.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.018836173s
Apr 23 11:59:03.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.018833393s
Apr 23 11:59:05.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.020467814s
Apr 23 11:59:07.986: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.017511501s
Apr 23 11:59:09.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.017967946s
Apr 23 11:59:11.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.018407386s
Apr 23 11:59:13.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.019161779s
Apr 23 11:59:15.994: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.025127346s
Apr 23 11:59:17.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.018483518s
Apr 23 11:59:19.990: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.021090576s
Apr 23 11:59:21.990: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.021566066s
Apr 23 11:59:23.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.020371551s
Apr 23 11:59:25.986: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.01693026s
Apr 23 11:59:27.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.018526648s
Apr 23 11:59:29.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.018962474s
Apr 23 11:59:31.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.018305262s
Apr 23 11:59:33.986: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.017489424s
Apr 23 11:59:35.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.017828841s
Apr 23 11:59:37.986: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.017641339s
Apr 23 11:59:39.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.017692513s
Apr 23 11:59:41.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.018207768s
Apr 23 11:59:43.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.02051903s
Apr 23 11:59:45.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.018829193s
Apr 23 11:59:47.991: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.022409468s
Apr 23 11:59:49.995: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.026304249s
Apr 23 11:59:51.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.018335187s
Apr 23 11:59:53.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.017801032s
Apr 23 11:59:55.996: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.027539533s
Apr 23 11:59:57.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.019336334s
Apr 23 11:59:59.990: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.020889704s
Apr 23 12:00:01.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.019450143s
Apr 23 12:00:03.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.019978929s
Apr 23 12:00:05.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.018703983s
Apr 23 12:00:07.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.019838503s
Apr 23 12:00:09.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.018426979s
Apr 23 12:00:11.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.018963757s
Apr 23 12:00:13.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.019781619s
Apr 23 12:00:15.994: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.024720094s
Apr 23 12:00:17.990: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.021248515s
Apr 23 12:00:19.990: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.021017502s
Apr 23 12:00:21.992: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.023554777s
Apr 23 12:00:23.986: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.017478487s
Apr 23 12:00:25.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.020092794s
Apr 23 12:00:27.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.019195654s
Apr 23 12:00:29.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.019619796s
Apr 23 12:00:31.990: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.020789526s
Apr 23 12:00:34.002: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.032872974s
Apr 23 12:00:35.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.018993809s
Apr 23 12:00:35.997: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.02834926s
STEP: updating the pod 04/23/23 12:00:35.997
Apr 23 12:00:36.523: INFO: Successfully updated pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5"
STEP: waiting for pod running 04/23/23 12:00:36.524
Apr 23 12:00:36.526: INFO: Waiting up to 2m0s for pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5" in namespace "var-expansion-7454" to be "running"
Apr 23 12:00:36.534: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.231451ms
Apr 23 12:00:38.574: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Running", Reason="", readiness=true. Elapsed: 2.048484217s
Apr 23 12:00:38.574: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5" satisfied condition "running"
STEP: deleting the pod gracefully 04/23/23 12:00:38.575
Apr 23 12:00:38.575: INFO: Deleting pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5" in namespace "var-expansion-7454"
Apr 23 12:00:38.592: INFO: Wait up to 5m0s for pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Apr 23 12:01:10.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-7454" for this suite. 04/23/23 12:01:10.63
------------------------------
â€¢ [SLOW TEST] [154.743 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 11:58:35.901
    Apr 23 11:58:35.902: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename var-expansion 04/23/23 11:58:35.903
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 11:58:35.935
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 11:58:35.94
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:225
    STEP: creating the pod with failed condition 04/23/23 11:58:35.947
    Apr 23 11:58:35.969: INFO: Waiting up to 2m0s for pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5" in namespace "var-expansion-7454" to be "running"
    Apr 23 11:58:35.979: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.23704ms
    Apr 23 11:58:37.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019810174s
    Apr 23 11:58:39.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01896626s
    Apr 23 11:58:41.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019121847s
    Apr 23 11:58:43.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019010735s
    Apr 23 11:58:45.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.019406172s
    Apr 23 11:58:47.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.019900065s
    Apr 23 11:58:49.986: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.017279579s
    Apr 23 11:58:51.990: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.020911289s
    Apr 23 11:58:53.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.018152061s
    Apr 23 11:58:55.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.019332346s
    Apr 23 11:58:57.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.020655435s
    Apr 23 11:58:59.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.018553577s
    Apr 23 11:59:01.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.018836173s
    Apr 23 11:59:03.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.018833393s
    Apr 23 11:59:05.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.020467814s
    Apr 23 11:59:07.986: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.017511501s
    Apr 23 11:59:09.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.017967946s
    Apr 23 11:59:11.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.018407386s
    Apr 23 11:59:13.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.019161779s
    Apr 23 11:59:15.994: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.025127346s
    Apr 23 11:59:17.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.018483518s
    Apr 23 11:59:19.990: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.021090576s
    Apr 23 11:59:21.990: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.021566066s
    Apr 23 11:59:23.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.020371551s
    Apr 23 11:59:25.986: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.01693026s
    Apr 23 11:59:27.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.018526648s
    Apr 23 11:59:29.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.018962474s
    Apr 23 11:59:31.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.018305262s
    Apr 23 11:59:33.986: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.017489424s
    Apr 23 11:59:35.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.017828841s
    Apr 23 11:59:37.986: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.017641339s
    Apr 23 11:59:39.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.017692513s
    Apr 23 11:59:41.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.018207768s
    Apr 23 11:59:43.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.02051903s
    Apr 23 11:59:45.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.018829193s
    Apr 23 11:59:47.991: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.022409468s
    Apr 23 11:59:49.995: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.026304249s
    Apr 23 11:59:51.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.018335187s
    Apr 23 11:59:53.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.017801032s
    Apr 23 11:59:55.996: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.027539533s
    Apr 23 11:59:57.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.019336334s
    Apr 23 11:59:59.990: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.020889704s
    Apr 23 12:00:01.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.019450143s
    Apr 23 12:00:03.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.019978929s
    Apr 23 12:00:05.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.018703983s
    Apr 23 12:00:07.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.019838503s
    Apr 23 12:00:09.987: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.018426979s
    Apr 23 12:00:11.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.018963757s
    Apr 23 12:00:13.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.019781619s
    Apr 23 12:00:15.994: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.024720094s
    Apr 23 12:00:17.990: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.021248515s
    Apr 23 12:00:19.990: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.021017502s
    Apr 23 12:00:21.992: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.023554777s
    Apr 23 12:00:23.986: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.017478487s
    Apr 23 12:00:25.989: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.020092794s
    Apr 23 12:00:27.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.019195654s
    Apr 23 12:00:29.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.019619796s
    Apr 23 12:00:31.990: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.020789526s
    Apr 23 12:00:34.002: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.032872974s
    Apr 23 12:00:35.988: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.018993809s
    Apr 23 12:00:35.997: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.02834926s
    STEP: updating the pod 04/23/23 12:00:35.997
    Apr 23 12:00:36.523: INFO: Successfully updated pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5"
    STEP: waiting for pod running 04/23/23 12:00:36.524
    Apr 23 12:00:36.526: INFO: Waiting up to 2m0s for pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5" in namespace "var-expansion-7454" to be "running"
    Apr 23 12:00:36.534: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.231451ms
    Apr 23 12:00:38.574: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5": Phase="Running", Reason="", readiness=true. Elapsed: 2.048484217s
    Apr 23 12:00:38.574: INFO: Pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5" satisfied condition "running"
    STEP: deleting the pod gracefully 04/23/23 12:00:38.575
    Apr 23 12:00:38.575: INFO: Deleting pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5" in namespace "var-expansion-7454"
    Apr 23 12:00:38.592: INFO: Wait up to 5m0s for pod "var-expansion-e87f82b7-b770-4094-ad6e-e51d0c3821f5" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:01:10.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-7454" for this suite. 04/23/23 12:01:10.63
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:186
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:01:10.654
Apr 23 12:01:10.654: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename var-expansion 04/23/23 12:01:10.659
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:01:10.699
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:01:10.703
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:186
Apr 23 12:01:10.722: INFO: Waiting up to 2m0s for pod "var-expansion-20525fe8-cc57-4ac9-b128-6add5c33acb6" in namespace "var-expansion-7786" to be "container 0 failed with reason CreateContainerConfigError"
Apr 23 12:01:10.729: INFO: Pod "var-expansion-20525fe8-cc57-4ac9-b128-6add5c33acb6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.249237ms
Apr 23 12:01:12.738: INFO: Pod "var-expansion-20525fe8-cc57-4ac9-b128-6add5c33acb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016234983s
Apr 23 12:01:12.738: INFO: Pod "var-expansion-20525fe8-cc57-4ac9-b128-6add5c33acb6" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Apr 23 12:01:12.738: INFO: Deleting pod "var-expansion-20525fe8-cc57-4ac9-b128-6add5c33acb6" in namespace "var-expansion-7786"
Apr 23 12:01:12.752: INFO: Wait up to 5m0s for pod "var-expansion-20525fe8-cc57-4ac9-b128-6add5c33acb6" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Apr 23 12:01:14.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-7786" for this suite. 04/23/23 12:01:14.777
------------------------------
â€¢ [4.138 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:01:10.654
    Apr 23 12:01:10.654: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename var-expansion 04/23/23 12:01:10.659
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:01:10.699
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:01:10.703
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:186
    Apr 23 12:01:10.722: INFO: Waiting up to 2m0s for pod "var-expansion-20525fe8-cc57-4ac9-b128-6add5c33acb6" in namespace "var-expansion-7786" to be "container 0 failed with reason CreateContainerConfigError"
    Apr 23 12:01:10.729: INFO: Pod "var-expansion-20525fe8-cc57-4ac9-b128-6add5c33acb6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.249237ms
    Apr 23 12:01:12.738: INFO: Pod "var-expansion-20525fe8-cc57-4ac9-b128-6add5c33acb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016234983s
    Apr 23 12:01:12.738: INFO: Pod "var-expansion-20525fe8-cc57-4ac9-b128-6add5c33acb6" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Apr 23 12:01:12.738: INFO: Deleting pod "var-expansion-20525fe8-cc57-4ac9-b128-6add5c33acb6" in namespace "var-expansion-7786"
    Apr 23 12:01:12.752: INFO: Wait up to 5m0s for pod "var-expansion-20525fe8-cc57-4ac9-b128-6add5c33acb6" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:01:14.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-7786" for this suite. 04/23/23 12:01:14.777
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:01:14.798
Apr 23 12:01:14.798: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename subpath 04/23/23 12:01:14.8
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:01:14.833
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:01:14.843
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/23/23 12:01:14.848
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-spcx 04/23/23 12:01:14.871
STEP: Creating a pod to test atomic-volume-subpath 04/23/23 12:01:14.871
Apr 23 12:01:14.890: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-spcx" in namespace "subpath-1066" to be "Succeeded or Failed"
Apr 23 12:01:14.907: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Pending", Reason="", readiness=false. Elapsed: 17.019374ms
Apr 23 12:01:16.916: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02636833s
Apr 23 12:01:18.913: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 4.022954805s
Apr 23 12:01:20.918: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 6.027839214s
Apr 23 12:01:22.916: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 8.026570154s
Apr 23 12:01:24.917: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 10.027081506s
Apr 23 12:01:26.918: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 12.028304941s
Apr 23 12:01:28.921: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 14.031327211s
Apr 23 12:01:30.915: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 16.025057497s
Apr 23 12:01:32.917: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 18.026842946s
Apr 23 12:01:34.914: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 20.023949663s
Apr 23 12:01:36.921: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 22.03152605s
Apr 23 12:01:38.916: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=false. Elapsed: 24.02638979s
Apr 23 12:01:40.916: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.026192812s
STEP: Saw pod success 04/23/23 12:01:40.916
Apr 23 12:01:40.917: INFO: Pod "pod-subpath-test-configmap-spcx" satisfied condition "Succeeded or Failed"
Apr 23 12:01:40.926: INFO: Trying to get logs from node eingavuivie7-3 pod pod-subpath-test-configmap-spcx container test-container-subpath-configmap-spcx: <nil>
STEP: delete the pod 04/23/23 12:01:40.998
Apr 23 12:01:41.027: INFO: Waiting for pod pod-subpath-test-configmap-spcx to disappear
Apr 23 12:01:41.044: INFO: Pod pod-subpath-test-configmap-spcx no longer exists
STEP: Deleting pod pod-subpath-test-configmap-spcx 04/23/23 12:01:41.044
Apr 23 12:01:41.045: INFO: Deleting pod "pod-subpath-test-configmap-spcx" in namespace "subpath-1066"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/node/init/init.go:32
Apr 23 12:01:41.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Subpath
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Subpath
  tear down framework | framework.go:193
STEP: Destroying namespace "subpath-1066" for this suite. 04/23/23 12:01:41.075
------------------------------
â€¢ [SLOW TEST] [26.303 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:01:14.798
    Apr 23 12:01:14.798: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename subpath 04/23/23 12:01:14.8
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:01:14.833
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:01:14.843
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/23/23 12:01:14.848
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-spcx 04/23/23 12:01:14.871
    STEP: Creating a pod to test atomic-volume-subpath 04/23/23 12:01:14.871
    Apr 23 12:01:14.890: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-spcx" in namespace "subpath-1066" to be "Succeeded or Failed"
    Apr 23 12:01:14.907: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Pending", Reason="", readiness=false. Elapsed: 17.019374ms
    Apr 23 12:01:16.916: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02636833s
    Apr 23 12:01:18.913: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 4.022954805s
    Apr 23 12:01:20.918: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 6.027839214s
    Apr 23 12:01:22.916: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 8.026570154s
    Apr 23 12:01:24.917: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 10.027081506s
    Apr 23 12:01:26.918: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 12.028304941s
    Apr 23 12:01:28.921: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 14.031327211s
    Apr 23 12:01:30.915: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 16.025057497s
    Apr 23 12:01:32.917: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 18.026842946s
    Apr 23 12:01:34.914: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 20.023949663s
    Apr 23 12:01:36.921: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=true. Elapsed: 22.03152605s
    Apr 23 12:01:38.916: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Running", Reason="", readiness=false. Elapsed: 24.02638979s
    Apr 23 12:01:40.916: INFO: Pod "pod-subpath-test-configmap-spcx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.026192812s
    STEP: Saw pod success 04/23/23 12:01:40.916
    Apr 23 12:01:40.917: INFO: Pod "pod-subpath-test-configmap-spcx" satisfied condition "Succeeded or Failed"
    Apr 23 12:01:40.926: INFO: Trying to get logs from node eingavuivie7-3 pod pod-subpath-test-configmap-spcx container test-container-subpath-configmap-spcx: <nil>
    STEP: delete the pod 04/23/23 12:01:40.998
    Apr 23 12:01:41.027: INFO: Waiting for pod pod-subpath-test-configmap-spcx to disappear
    Apr 23 12:01:41.044: INFO: Pod pod-subpath-test-configmap-spcx no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-spcx 04/23/23 12:01:41.044
    Apr 23 12:01:41.045: INFO: Deleting pod "pod-subpath-test-configmap-spcx" in namespace "subpath-1066"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:01:41.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Subpath
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Subpath
      tear down framework | framework.go:193
    STEP: Destroying namespace "subpath-1066" for this suite. 04/23/23 12:01:41.075
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:443
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:01:41.12
Apr 23 12:01:41.121: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename sched-pred 04/23/23 12:01:41.124
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:01:41.152
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:01:41.159
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:97
Apr 23 12:01:41.173: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 23 12:01:41.199: INFO: Waiting for terminating namespaces to be deleted...
Apr 23 12:01:41.205: INFO: 
Logging pods the apiserver thinks is on node eingavuivie7-1 before test
Apr 23 12:01:41.222: INFO: cilium-node-init-j475c from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.222: INFO: 	Container node-init ready: true, restart count 0
Apr 23 12:01:41.222: INFO: cilium-tcvk2 from kube-system started at 2023-04-23 10:44:39 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.222: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 23 12:01:41.222: INFO: kube-addon-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.222: INFO: 	Container kube-addon-manager ready: true, restart count 0
Apr 23 12:01:41.222: INFO: kube-apiserver-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.222: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 23 12:01:41.222: INFO: kube-controller-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.222: INFO: 	Container kube-controller-manager ready: true, restart count 0
Apr 23 12:01:41.222: INFO: kube-proxy-qx9mz from kube-system started at 2023-04-23 10:40:00 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.222: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 12:01:41.222: INFO: kube-scheduler-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:29 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.223: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 23 12:01:41.223: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-tdgvz from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 12:01:41.223: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 12:01:41.223: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 23 12:01:41.223: INFO: 
Logging pods the apiserver thinks is on node eingavuivie7-2 before test
Apr 23 12:01:41.243: INFO: cilium-cw5l6 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.244: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 23 12:01:41.244: INFO: cilium-node-init-tpqk9 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.244: INFO: 	Container node-init ready: true, restart count 0
Apr 23 12:01:41.244: INFO: coredns-787d4945fb-v7bjj from kube-system started at 2023-04-23 10:46:03 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.244: INFO: 	Container coredns ready: true, restart count 0
Apr 23 12:01:41.244: INFO: kube-addon-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.244: INFO: 	Container kube-addon-manager ready: true, restart count 0
Apr 23 12:01:41.244: INFO: kube-apiserver-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.244: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 23 12:01:41.244: INFO: kube-controller-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.244: INFO: 	Container kube-controller-manager ready: true, restart count 0
Apr 23 12:01:41.244: INFO: kube-proxy-hzwld from kube-system started at 2023-04-23 10:40:58 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.244: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 12:01:41.244: INFO: kube-scheduler-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.244: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 23 12:01:41.244: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-ntx29 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 12:01:41.244: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 12:01:41.244: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 23 12:01:41.244: INFO: 
Logging pods the apiserver thinks is on node eingavuivie7-3 before test
Apr 23 12:01:41.258: INFO: cilium-node-init-btj27 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.258: INFO: 	Container node-init ready: true, restart count 0
Apr 23 12:01:41.258: INFO: cilium-operator-968f66564-jmvk7 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.259: INFO: 	Container cilium-operator ready: true, restart count 0
Apr 23 12:01:41.259: INFO: cilium-vpc26 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.259: INFO: 	Container cilium-agent ready: true, restart count 0
Apr 23 12:01:41.259: INFO: coredns-787d4945fb-8tms9 from kube-system started at 2023-04-23 10:45:47 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.259: INFO: 	Container coredns ready: true, restart count 0
Apr 23 12:01:41.259: INFO: kube-proxy-lsxv6 from kube-system started at 2023-04-23 10:41:59 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.260: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 23 12:01:41.260: INFO: sonobuoy from sonobuoy started at 2023-04-23 11:11:26 +0000 UTC (1 container statuses recorded)
Apr 23 12:01:41.260: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 23 12:01:41.260: INFO: sonobuoy-e2e-job-27be2b9757534547 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 12:01:41.260: INFO: 	Container e2e ready: true, restart count 0
Apr 23 12:01:41.261: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 12:01:41.261: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-k7sgm from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
Apr 23 12:01:41.261: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 23 12:01:41.261: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:443
STEP: Trying to schedule Pod with nonempty NodeSelector. 04/23/23 12:01:41.262
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.17588ea5463b1cf0], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling..] 04/23/23 12:01:41.333
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:01:42.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:88
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-pred-6914" for this suite. 04/23/23 12:01:42.344
------------------------------
â€¢ [1.241 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:01:41.12
    Apr 23 12:01:41.121: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename sched-pred 04/23/23 12:01:41.124
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:01:41.152
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:01:41.159
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:97
    Apr 23 12:01:41.173: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 23 12:01:41.199: INFO: Waiting for terminating namespaces to be deleted...
    Apr 23 12:01:41.205: INFO: 
    Logging pods the apiserver thinks is on node eingavuivie7-1 before test
    Apr 23 12:01:41.222: INFO: cilium-node-init-j475c from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.222: INFO: 	Container node-init ready: true, restart count 0
    Apr 23 12:01:41.222: INFO: cilium-tcvk2 from kube-system started at 2023-04-23 10:44:39 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.222: INFO: 	Container cilium-agent ready: true, restart count 0
    Apr 23 12:01:41.222: INFO: kube-addon-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.222: INFO: 	Container kube-addon-manager ready: true, restart count 0
    Apr 23 12:01:41.222: INFO: kube-apiserver-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.222: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 23 12:01:41.222: INFO: kube-controller-manager-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:47 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.222: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Apr 23 12:01:41.222: INFO: kube-proxy-qx9mz from kube-system started at 2023-04-23 10:40:00 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.222: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 23 12:01:41.222: INFO: kube-scheduler-eingavuivie7-1 from kube-system started at 2023-04-23 10:39:29 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.223: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 23 12:01:41.223: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-tdgvz from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 12:01:41.223: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 12:01:41.223: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 23 12:01:41.223: INFO: 
    Logging pods the apiserver thinks is on node eingavuivie7-2 before test
    Apr 23 12:01:41.243: INFO: cilium-cw5l6 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.244: INFO: 	Container cilium-agent ready: true, restart count 0
    Apr 23 12:01:41.244: INFO: cilium-node-init-tpqk9 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.244: INFO: 	Container node-init ready: true, restart count 0
    Apr 23 12:01:41.244: INFO: coredns-787d4945fb-v7bjj from kube-system started at 2023-04-23 10:46:03 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.244: INFO: 	Container coredns ready: true, restart count 0
    Apr 23 12:01:41.244: INFO: kube-addon-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:43:19 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.244: INFO: 	Container kube-addon-manager ready: true, restart count 0
    Apr 23 12:01:41.244: INFO: kube-apiserver-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.244: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 23 12:01:41.244: INFO: kube-controller-manager-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.244: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Apr 23 12:01:41.244: INFO: kube-proxy-hzwld from kube-system started at 2023-04-23 10:40:58 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.244: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 23 12:01:41.244: INFO: kube-scheduler-eingavuivie7-2 from kube-system started at 2023-04-23 10:41:04 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.244: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 23 12:01:41.244: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-ntx29 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 12:01:41.244: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 12:01:41.244: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 23 12:01:41.244: INFO: 
    Logging pods the apiserver thinks is on node eingavuivie7-3 before test
    Apr 23 12:01:41.258: INFO: cilium-node-init-btj27 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.258: INFO: 	Container node-init ready: true, restart count 0
    Apr 23 12:01:41.258: INFO: cilium-operator-968f66564-jmvk7 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.259: INFO: 	Container cilium-operator ready: true, restart count 0
    Apr 23 12:01:41.259: INFO: cilium-vpc26 from kube-system started at 2023-04-23 10:44:40 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.259: INFO: 	Container cilium-agent ready: true, restart count 0
    Apr 23 12:01:41.259: INFO: coredns-787d4945fb-8tms9 from kube-system started at 2023-04-23 10:45:47 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.259: INFO: 	Container coredns ready: true, restart count 0
    Apr 23 12:01:41.259: INFO: kube-proxy-lsxv6 from kube-system started at 2023-04-23 10:41:59 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.260: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 23 12:01:41.260: INFO: sonobuoy from sonobuoy started at 2023-04-23 11:11:26 +0000 UTC (1 container statuses recorded)
    Apr 23 12:01:41.260: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 23 12:01:41.260: INFO: sonobuoy-e2e-job-27be2b9757534547 from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 12:01:41.260: INFO: 	Container e2e ready: true, restart count 0
    Apr 23 12:01:41.261: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 12:01:41.261: INFO: sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-k7sgm from sonobuoy started at 2023-04-23 11:11:37 +0000 UTC (2 container statuses recorded)
    Apr 23 12:01:41.261: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 23 12:01:41.261: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:443
    STEP: Trying to schedule Pod with nonempty NodeSelector. 04/23/23 12:01:41.262
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.17588ea5463b1cf0], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling..] 04/23/23 12:01:41.333
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:01:42.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:88
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPredicates [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-pred-6914" for this suite. 04/23/23 12:01:42.344
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:01:42.362
Apr 23 12:01:42.362: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename replicaset 04/23/23 12:01:42.363
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:01:42.393
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:01:42.397
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:31
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Apr 23 12:01:42.424: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 23 12:01:47.434: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/23/23 12:01:47.435
STEP: Scaling up "test-rs" replicaset  04/23/23 12:01:47.435
Apr 23 12:01:47.468: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 04/23/23 12:01:47.468
W0423 12:01:47.525776      13 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 23 12:01:47.528: INFO: observed ReplicaSet test-rs in namespace replicaset-2763 with ReadyReplicas 1, AvailableReplicas 1
Apr 23 12:01:47.589: INFO: observed ReplicaSet test-rs in namespace replicaset-2763 with ReadyReplicas 1, AvailableReplicas 1
Apr 23 12:01:47.635: INFO: observed ReplicaSet test-rs in namespace replicaset-2763 with ReadyReplicas 1, AvailableReplicas 1
Apr 23 12:01:47.687: INFO: observed ReplicaSet test-rs in namespace replicaset-2763 with ReadyReplicas 1, AvailableReplicas 1
Apr 23 12:01:49.986: INFO: observed ReplicaSet test-rs in namespace replicaset-2763 with ReadyReplicas 2, AvailableReplicas 2
Apr 23 12:01:50.205: INFO: observed Replicaset test-rs in namespace replicaset-2763 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/node/init/init.go:32
Apr 23 12:01:50.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  tear down framework | framework.go:193
STEP: Destroying namespace "replicaset-2763" for this suite. 04/23/23 12:01:50.213
------------------------------
â€¢ [SLOW TEST] [7.867 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:01:42.362
    Apr 23 12:01:42.362: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename replicaset 04/23/23 12:01:42.363
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:01:42.393
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:01:42.397
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:31
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Apr 23 12:01:42.424: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 23 12:01:47.434: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/23/23 12:01:47.435
    STEP: Scaling up "test-rs" replicaset  04/23/23 12:01:47.435
    Apr 23 12:01:47.468: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 04/23/23 12:01:47.468
    W0423 12:01:47.525776      13 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 23 12:01:47.528: INFO: observed ReplicaSet test-rs in namespace replicaset-2763 with ReadyReplicas 1, AvailableReplicas 1
    Apr 23 12:01:47.589: INFO: observed ReplicaSet test-rs in namespace replicaset-2763 with ReadyReplicas 1, AvailableReplicas 1
    Apr 23 12:01:47.635: INFO: observed ReplicaSet test-rs in namespace replicaset-2763 with ReadyReplicas 1, AvailableReplicas 1
    Apr 23 12:01:47.687: INFO: observed ReplicaSet test-rs in namespace replicaset-2763 with ReadyReplicas 1, AvailableReplicas 1
    Apr 23 12:01:49.986: INFO: observed ReplicaSet test-rs in namespace replicaset-2763 with ReadyReplicas 2, AvailableReplicas 2
    Apr 23 12:01:50.205: INFO: observed Replicaset test-rs in namespace replicaset-2763 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:01:50.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "replicaset-2763" for this suite. 04/23/23 12:01:50.213
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:814
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:01:50.23
Apr 23 12:01:50.230: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename sched-preemption 04/23/23 12:01:50.234
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:01:50.262
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:01:50.268
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:97
Apr 23 12:01:50.290: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 23 12:02:50.365: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:02:50.377
Apr 23 12:02:50.378: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename sched-preemption-path 04/23/23 12:02:50.383
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:02:50.413
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:02:50.418
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:771
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:814
Apr 23 12:02:50.451: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Apr 23 12:02:50.458: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/node/init/init.go:32
Apr 23 12:02:50.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:787
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:02:50.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:84
[DeferCleanup (Each)] PriorityClass endpoints
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] PriorityClass endpoints
  dump namespaces | framework.go:196
[DeferCleanup (Each)] PriorityClass endpoints
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-preemption-path-2346" for this suite. 04/23/23 12:02:50.663
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-preemption-4882" for this suite. 04/23/23 12:02:50.678
------------------------------
â€¢ [SLOW TEST] [60.460 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:764
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:814

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:01:50.23
    Apr 23 12:01:50.230: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename sched-preemption 04/23/23 12:01:50.234
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:01:50.262
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:01:50.268
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:97
    Apr 23 12:01:50.290: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 23 12:02:50.365: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:02:50.377
    Apr 23 12:02:50.378: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename sched-preemption-path 04/23/23 12:02:50.383
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:02:50.413
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:02:50.418
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:771
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:814
    Apr 23 12:02:50.451: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Apr 23 12:02:50.458: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:02:50.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:787
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:02:50.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:84
    [DeferCleanup (Each)] PriorityClass endpoints
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] PriorityClass endpoints
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] PriorityClass endpoints
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-preemption-path-2346" for this suite. 04/23/23 12:02:50.663
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-preemption-4882" for this suite. 04/23/23 12:02:50.678
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:306
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:02:50.695
Apr 23 12:02:50.695: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename statefulset 04/23/23 12:02:50.699
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:02:50.725
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:02:50.73
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-582 04/23/23 12:02:50.734
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:306
STEP: Creating a new StatefulSet 04/23/23 12:02:50.756
Apr 23 12:02:50.783: INFO: Found 0 stateful pods, waiting for 3
Apr 23 12:03:00.806: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 12:03:00.806: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 12:03:00.806: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 12:03:00.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-582 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 23 12:03:01.153: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 23 12:03:01.153: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 23 12:03:01.153: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 04/23/23 12:03:11.182
Apr 23 12:03:11.210: INFO: Updating stateful set ss2
STEP: Creating a new revision 04/23/23 12:03:11.21
STEP: Updating Pods in reverse ordinal order 04/23/23 12:03:21.245
Apr 23 12:03:21.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-582 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 23 12:03:21.606: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 23 12:03:21.606: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 23 12:03:21.606: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision 04/23/23 12:03:31.649
Apr 23 12:03:31.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-582 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 23 12:03:32.073: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 23 12:03:32.073: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 23 12:03:32.073: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 23 12:03:42.154: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 04/23/23 12:03:52.199
Apr 23 12:03:52.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-582 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 23 12:03:52.603: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 23 12:03:52.603: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 23 12:03:52.603: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Apr 23 12:04:02.648: INFO: Deleting all statefulset in ns statefulset-582
Apr 23 12:04:02.655: INFO: Scaling statefulset ss2 to 0
Apr 23 12:04:12.685: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 12:04:12.691: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Apr 23 12:04:12.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-582" for this suite. 04/23/23 12:04:12.741
------------------------------
â€¢ [SLOW TEST] [82.085 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:306

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:02:50.695
    Apr 23 12:02:50.695: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename statefulset 04/23/23 12:02:50.699
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:02:50.725
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:02:50.73
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-582 04/23/23 12:02:50.734
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:306
    STEP: Creating a new StatefulSet 04/23/23 12:02:50.756
    Apr 23 12:02:50.783: INFO: Found 0 stateful pods, waiting for 3
    Apr 23 12:03:00.806: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 23 12:03:00.806: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 23 12:03:00.806: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Apr 23 12:03:00.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-582 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 23 12:03:01.153: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 23 12:03:01.153: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 23 12:03:01.153: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 04/23/23 12:03:11.182
    Apr 23 12:03:11.210: INFO: Updating stateful set ss2
    STEP: Creating a new revision 04/23/23 12:03:11.21
    STEP: Updating Pods in reverse ordinal order 04/23/23 12:03:21.245
    Apr 23 12:03:21.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-582 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 23 12:03:21.606: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 23 12:03:21.606: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 23 12:03:21.606: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    STEP: Rolling back to a previous revision 04/23/23 12:03:31.649
    Apr 23 12:03:31.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-582 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 23 12:03:32.073: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 23 12:03:32.073: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 23 12:03:32.073: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 23 12:03:42.154: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 04/23/23 12:03:52.199
    Apr 23 12:03:52.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-582 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 23 12:03:52.603: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 23 12:03:52.603: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 23 12:03:52.603: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Apr 23 12:04:02.648: INFO: Deleting all statefulset in ns statefulset-582
    Apr 23 12:04:02.655: INFO: Scaling statefulset ss2 to 0
    Apr 23 12:04:12.685: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 23 12:04:12.691: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:04:12.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-582" for this suite. 04/23/23 12:04:12.741
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2228
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:04:12.79
Apr 23 12:04:12.791: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 12:04:12.796
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:04:12.828
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:04:12.837
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2228
STEP: creating service in namespace services-4127 04/23/23 12:04:12.848
STEP: creating service affinity-nodeport in namespace services-4127 04/23/23 12:04:12.848
STEP: creating replication controller affinity-nodeport in namespace services-4127 04/23/23 12:04:12.89
I0423 12:04:12.918464      13 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-4127, replica count: 3
I0423 12:04:15.990280      13 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 23 12:04:16.012: INFO: Creating new exec pod
Apr 23 12:04:16.028: INFO: Waiting up to 5m0s for pod "execpod-affinitywrsbr" in namespace "services-4127" to be "running"
Apr 23 12:04:16.039: INFO: Pod "execpod-affinitywrsbr": Phase="Pending", Reason="", readiness=false. Elapsed: 10.842217ms
Apr 23 12:04:18.048: INFO: Pod "execpod-affinitywrsbr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019834179s
Apr 23 12:04:20.051: INFO: Pod "execpod-affinitywrsbr": Phase="Running", Reason="", readiness=true. Elapsed: 4.022861217s
Apr 23 12:04:20.051: INFO: Pod "execpod-affinitywrsbr" satisfied condition "running"
Apr 23 12:04:21.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-4127 exec execpod-affinitywrsbr -- /bin/sh -x -c nc -v -z -w 2 affinity-nodeport 80'
Apr 23 12:04:21.333: INFO: stderr: "+ nc -v -z -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Apr 23 12:04:21.334: INFO: stdout: ""
Apr 23 12:04:21.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-4127 exec execpod-affinitywrsbr -- /bin/sh -x -c nc -v -z -w 2 10.233.7.12 80'
Apr 23 12:04:21.775: INFO: stderr: "+ nc -v -z -w 2 10.233.7.12 80\nConnection to 10.233.7.12 80 port [tcp/http] succeeded!\n"
Apr 23 12:04:21.775: INFO: stdout: ""
Apr 23 12:04:21.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-4127 exec execpod-affinitywrsbr -- /bin/sh -x -c nc -v -z -w 2 192.168.121.130 30630'
Apr 23 12:04:22.054: INFO: stderr: "+ nc -v -z -w 2 192.168.121.130 30630\nConnection to 192.168.121.130 30630 port [tcp/*] succeeded!\n"
Apr 23 12:04:22.054: INFO: stdout: ""
Apr 23 12:04:22.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-4127 exec execpod-affinitywrsbr -- /bin/sh -x -c nc -v -z -w 2 192.168.121.198 30630'
Apr 23 12:04:22.365: INFO: stderr: "+ nc -v -z -w 2 192.168.121.198 30630\nConnection to 192.168.121.198 30630 port [tcp/*] succeeded!\n"
Apr 23 12:04:22.365: INFO: stdout: ""
Apr 23 12:04:22.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-4127 exec execpod-affinitywrsbr -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.130:30630/ ; done'
Apr 23 12:04:22.869: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n"
Apr 23 12:04:22.870: INFO: stdout: "\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp"
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
Apr 23 12:04:22.870: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-4127, will wait for the garbage collector to delete the pods 04/23/23 12:04:22.915
Apr 23 12:04:23.021: INFO: Deleting ReplicationController affinity-nodeport took: 25.340637ms
Apr 23 12:04:23.121: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.841303ms
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 12:04:25.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-4127" for this suite. 04/23/23 12:04:25.417
------------------------------
â€¢ [SLOW TEST] [12.646 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2228

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:04:12.79
    Apr 23 12:04:12.791: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 12:04:12.796
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:04:12.828
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:04:12.837
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2228
    STEP: creating service in namespace services-4127 04/23/23 12:04:12.848
    STEP: creating service affinity-nodeport in namespace services-4127 04/23/23 12:04:12.848
    STEP: creating replication controller affinity-nodeport in namespace services-4127 04/23/23 12:04:12.89
    I0423 12:04:12.918464      13 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-4127, replica count: 3
    I0423 12:04:15.990280      13 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 23 12:04:16.012: INFO: Creating new exec pod
    Apr 23 12:04:16.028: INFO: Waiting up to 5m0s for pod "execpod-affinitywrsbr" in namespace "services-4127" to be "running"
    Apr 23 12:04:16.039: INFO: Pod "execpod-affinitywrsbr": Phase="Pending", Reason="", readiness=false. Elapsed: 10.842217ms
    Apr 23 12:04:18.048: INFO: Pod "execpod-affinitywrsbr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019834179s
    Apr 23 12:04:20.051: INFO: Pod "execpod-affinitywrsbr": Phase="Running", Reason="", readiness=true. Elapsed: 4.022861217s
    Apr 23 12:04:20.051: INFO: Pod "execpod-affinitywrsbr" satisfied condition "running"
    Apr 23 12:04:21.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-4127 exec execpod-affinitywrsbr -- /bin/sh -x -c nc -v -z -w 2 affinity-nodeport 80'
    Apr 23 12:04:21.333: INFO: stderr: "+ nc -v -z -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Apr 23 12:04:21.334: INFO: stdout: ""
    Apr 23 12:04:21.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-4127 exec execpod-affinitywrsbr -- /bin/sh -x -c nc -v -z -w 2 10.233.7.12 80'
    Apr 23 12:04:21.775: INFO: stderr: "+ nc -v -z -w 2 10.233.7.12 80\nConnection to 10.233.7.12 80 port [tcp/http] succeeded!\n"
    Apr 23 12:04:21.775: INFO: stdout: ""
    Apr 23 12:04:21.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-4127 exec execpod-affinitywrsbr -- /bin/sh -x -c nc -v -z -w 2 192.168.121.130 30630'
    Apr 23 12:04:22.054: INFO: stderr: "+ nc -v -z -w 2 192.168.121.130 30630\nConnection to 192.168.121.130 30630 port [tcp/*] succeeded!\n"
    Apr 23 12:04:22.054: INFO: stdout: ""
    Apr 23 12:04:22.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-4127 exec execpod-affinitywrsbr -- /bin/sh -x -c nc -v -z -w 2 192.168.121.198 30630'
    Apr 23 12:04:22.365: INFO: stderr: "+ nc -v -z -w 2 192.168.121.198 30630\nConnection to 192.168.121.198 30630 port [tcp/*] succeeded!\n"
    Apr 23 12:04:22.365: INFO: stdout: ""
    Apr 23 12:04:22.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-4127 exec execpod-affinitywrsbr -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.130:30630/ ; done'
    Apr 23 12:04:22.869: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.130:30630/\n"
    Apr 23 12:04:22.870: INFO: stdout: "\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp\naffinity-nodeport-dt8cp"
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Received response from host: affinity-nodeport-dt8cp
    Apr 23 12:04:22.870: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-4127, will wait for the garbage collector to delete the pods 04/23/23 12:04:22.915
    Apr 23 12:04:23.021: INFO: Deleting ReplicationController affinity-nodeport took: 25.340637ms
    Apr 23 12:04:23.121: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.841303ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:04:25.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-4127" for this suite. 04/23/23 12:04:25.417
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:153
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:04:25.436
Apr 23 12:04:25.436: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 12:04:25.439
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:04:25.495
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:04:25.5
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:153
Apr 23 12:04:25.520: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/23/23 12:04:28.692
Apr 23 12:04:28.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9599 --namespace=crd-publish-openapi-9599 create -f -'
Apr 23 12:04:30.703: INFO: stderr: ""
Apr 23 12:04:30.703: INFO: stdout: "e2e-test-crd-publish-openapi-9705-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 23 12:04:30.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9599 --namespace=crd-publish-openapi-9599 delete e2e-test-crd-publish-openapi-9705-crds test-cr'
Apr 23 12:04:30.931: INFO: stderr: ""
Apr 23 12:04:30.931: INFO: stdout: "e2e-test-crd-publish-openapi-9705-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Apr 23 12:04:30.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9599 --namespace=crd-publish-openapi-9599 apply -f -'
Apr 23 12:04:31.548: INFO: stderr: ""
Apr 23 12:04:31.548: INFO: stdout: "e2e-test-crd-publish-openapi-9705-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 23 12:04:31.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9599 --namespace=crd-publish-openapi-9599 delete e2e-test-crd-publish-openapi-9705-crds test-cr'
Apr 23 12:04:32.017: INFO: stderr: ""
Apr 23 12:04:32.017: INFO: stdout: "e2e-test-crd-publish-openapi-9705-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 04/23/23 12:04:32.017
Apr 23 12:04:32.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9599 explain e2e-test-crd-publish-openapi-9705-crds'
Apr 23 12:04:33.626: INFO: stderr: ""
Apr 23 12:04:33.626: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9705-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:04:36.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-9599" for this suite. 04/23/23 12:04:36.358
------------------------------
â€¢ [SLOW TEST] [10.939 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:04:25.436
    Apr 23 12:04:25.436: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 12:04:25.439
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:04:25.495
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:04:25.5
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:153
    Apr 23 12:04:25.520: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/23/23 12:04:28.692
    Apr 23 12:04:28.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9599 --namespace=crd-publish-openapi-9599 create -f -'
    Apr 23 12:04:30.703: INFO: stderr: ""
    Apr 23 12:04:30.703: INFO: stdout: "e2e-test-crd-publish-openapi-9705-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Apr 23 12:04:30.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9599 --namespace=crd-publish-openapi-9599 delete e2e-test-crd-publish-openapi-9705-crds test-cr'
    Apr 23 12:04:30.931: INFO: stderr: ""
    Apr 23 12:04:30.931: INFO: stdout: "e2e-test-crd-publish-openapi-9705-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Apr 23 12:04:30.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9599 --namespace=crd-publish-openapi-9599 apply -f -'
    Apr 23 12:04:31.548: INFO: stderr: ""
    Apr 23 12:04:31.548: INFO: stdout: "e2e-test-crd-publish-openapi-9705-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Apr 23 12:04:31.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9599 --namespace=crd-publish-openapi-9599 delete e2e-test-crd-publish-openapi-9705-crds test-cr'
    Apr 23 12:04:32.017: INFO: stderr: ""
    Apr 23 12:04:32.017: INFO: stdout: "e2e-test-crd-publish-openapi-9705-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 04/23/23 12:04:32.017
    Apr 23 12:04:32.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9599 explain e2e-test-crd-publish-openapi-9705-crds'
    Apr 23 12:04:33.626: INFO: stderr: ""
    Apr 23 12:04:33.626: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9705-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:04:36.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-9599" for this suite. 04/23/23 12:04:36.358
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:04:36.381
Apr 23 12:04:36.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pod-network-test 04/23/23 12:04:36.384
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:04:36.425
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:04:36.434
[BeforeEach] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:31
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-7719 04/23/23 12:04:36.44
STEP: creating a selector 04/23/23 12:04:36.441
STEP: Creating the service pods in kubernetes 04/23/23 12:04:36.441
Apr 23 12:04:36.441: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 23 12:04:36.562: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7719" to be "running and ready"
Apr 23 12:04:36.588: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 26.51998ms
Apr 23 12:04:36.589: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:04:38.596: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.034180385s
Apr 23 12:04:38.597: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 12:04:40.602: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.040481854s
Apr 23 12:04:40.603: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 12:04:42.604: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.041728496s
Apr 23 12:04:42.604: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 12:04:44.599: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.037450347s
Apr 23 12:04:44.600: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 12:04:46.597: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.035230464s
Apr 23 12:04:46.598: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 23 12:04:48.601: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.039152862s
Apr 23 12:04:48.601: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 23 12:04:48.601: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 23 12:04:48.610: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7719" to be "running and ready"
Apr 23 12:04:48.618: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 7.925726ms
Apr 23 12:04:48.618: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Apr 23 12:04:50.625: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.014805376s
Apr 23 12:04:50.625: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Apr 23 12:04:52.629: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.019094176s
Apr 23 12:04:52.629: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Apr 23 12:04:54.632: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.02266045s
Apr 23 12:04:54.633: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Apr 23 12:04:56.627: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.017563025s
Apr 23 12:04:56.628: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Apr 23 12:04:58.628: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.018154931s
Apr 23 12:04:58.628: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 23 12:04:58.628: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 23 12:04:58.635: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-7719" to be "running and ready"
Apr 23 12:04:58.641: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 5.07313ms
Apr 23 12:04:58.641: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 23 12:04:58.641: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/23/23 12:04:58.647
Apr 23 12:04:58.664: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7719" to be "running"
Apr 23 12:04:58.677: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.177296ms
Apr 23 12:05:00.689: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.024069367s
Apr 23 12:05:00.689: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 23 12:05:00.699: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 23 12:05:00.699: INFO: Breadth first check of 10.233.65.171 on host 192.168.121.130...
Apr 23 12:05:00.710: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.64.60:9080/dial?request=hostname&protocol=udp&host=10.233.65.171&port=8081&tries=1'] Namespace:pod-network-test-7719 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:05:00.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:05:00.711: INFO: ExecWithOptions: Clientset creation
Apr 23 12:05:00.711: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-7719/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.64.60%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.65.171%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 23 12:05:00.867: INFO: Waiting for responses: map[]
Apr 23 12:05:00.867: INFO: reached 10.233.65.171 after 0/1 tries
Apr 23 12:05:00.867: INFO: Breadth first check of 10.233.66.208 on host 192.168.121.214...
Apr 23 12:05:00.876: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.64.60:9080/dial?request=hostname&protocol=udp&host=10.233.66.208&port=8081&tries=1'] Namespace:pod-network-test-7719 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:05:00.876: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:05:00.878: INFO: ExecWithOptions: Clientset creation
Apr 23 12:05:00.878: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-7719/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.64.60%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.66.208%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 23 12:05:00.990: INFO: Waiting for responses: map[]
Apr 23 12:05:00.990: INFO: reached 10.233.66.208 after 0/1 tries
Apr 23 12:05:00.990: INFO: Breadth first check of 10.233.64.46 on host 192.168.121.198...
Apr 23 12:05:00.997: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.64.60:9080/dial?request=hostname&protocol=udp&host=10.233.64.46&port=8081&tries=1'] Namespace:pod-network-test-7719 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:05:00.997: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:05:00.998: INFO: ExecWithOptions: Clientset creation
Apr 23 12:05:00.998: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-7719/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.64.60%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.64.46%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 23 12:05:01.113: INFO: Waiting for responses: map[]
Apr 23 12:05:01.113: INFO: reached 10.233.64.46 after 0/1 tries
Apr 23 12:05:01.113: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/node/init/init.go:32
Apr 23 12:05:01.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Networking
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Networking
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Networking
  tear down framework | framework.go:193
STEP: Destroying namespace "pod-network-test-7719" for this suite. 04/23/23 12:05:01.125
------------------------------
â€¢ [SLOW TEST] [24.756 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:04:36.381
    Apr 23 12:04:36.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pod-network-test 04/23/23 12:04:36.384
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:04:36.425
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:04:36.434
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:31
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-7719 04/23/23 12:04:36.44
    STEP: creating a selector 04/23/23 12:04:36.441
    STEP: Creating the service pods in kubernetes 04/23/23 12:04:36.441
    Apr 23 12:04:36.441: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 23 12:04:36.562: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7719" to be "running and ready"
    Apr 23 12:04:36.588: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 26.51998ms
    Apr 23 12:04:36.589: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:04:38.596: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.034180385s
    Apr 23 12:04:38.597: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 12:04:40.602: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.040481854s
    Apr 23 12:04:40.603: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 12:04:42.604: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.041728496s
    Apr 23 12:04:42.604: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 12:04:44.599: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.037450347s
    Apr 23 12:04:44.600: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 12:04:46.597: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.035230464s
    Apr 23 12:04:46.598: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 23 12:04:48.601: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.039152862s
    Apr 23 12:04:48.601: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 23 12:04:48.601: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 23 12:04:48.610: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7719" to be "running and ready"
    Apr 23 12:04:48.618: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 7.925726ms
    Apr 23 12:04:48.618: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Apr 23 12:04:50.625: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.014805376s
    Apr 23 12:04:50.625: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Apr 23 12:04:52.629: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.019094176s
    Apr 23 12:04:52.629: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Apr 23 12:04:54.632: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.02266045s
    Apr 23 12:04:54.633: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Apr 23 12:04:56.627: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.017563025s
    Apr 23 12:04:56.628: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Apr 23 12:04:58.628: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.018154931s
    Apr 23 12:04:58.628: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 23 12:04:58.628: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 23 12:04:58.635: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-7719" to be "running and ready"
    Apr 23 12:04:58.641: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 5.07313ms
    Apr 23 12:04:58.641: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 23 12:04:58.641: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/23/23 12:04:58.647
    Apr 23 12:04:58.664: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7719" to be "running"
    Apr 23 12:04:58.677: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.177296ms
    Apr 23 12:05:00.689: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.024069367s
    Apr 23 12:05:00.689: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 23 12:05:00.699: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 23 12:05:00.699: INFO: Breadth first check of 10.233.65.171 on host 192.168.121.130...
    Apr 23 12:05:00.710: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.64.60:9080/dial?request=hostname&protocol=udp&host=10.233.65.171&port=8081&tries=1'] Namespace:pod-network-test-7719 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:05:00.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:05:00.711: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:05:00.711: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-7719/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.64.60%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.65.171%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 23 12:05:00.867: INFO: Waiting for responses: map[]
    Apr 23 12:05:00.867: INFO: reached 10.233.65.171 after 0/1 tries
    Apr 23 12:05:00.867: INFO: Breadth first check of 10.233.66.208 on host 192.168.121.214...
    Apr 23 12:05:00.876: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.64.60:9080/dial?request=hostname&protocol=udp&host=10.233.66.208&port=8081&tries=1'] Namespace:pod-network-test-7719 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:05:00.876: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:05:00.878: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:05:00.878: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-7719/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.64.60%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.66.208%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 23 12:05:00.990: INFO: Waiting for responses: map[]
    Apr 23 12:05:00.990: INFO: reached 10.233.66.208 after 0/1 tries
    Apr 23 12:05:00.990: INFO: Breadth first check of 10.233.64.46 on host 192.168.121.198...
    Apr 23 12:05:00.997: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.64.60:9080/dial?request=hostname&protocol=udp&host=10.233.64.46&port=8081&tries=1'] Namespace:pod-network-test-7719 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:05:00.997: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:05:00.998: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:05:00.998: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-7719/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.64.60%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.64.46%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 23 12:05:01.113: INFO: Waiting for responses: map[]
    Apr 23 12:05:01.113: INFO: reached 10.233.64.46 after 0/1 tries
    Apr 23 12:05:01.113: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:05:01.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Networking
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Networking
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Networking
      tear down framework | framework.go:193
    STEP: Destroying namespace "pod-network-test-7719" for this suite. 04/23/23 12:05:01.125
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:197
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:05:01.15
Apr 23 12:05:01.150: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 12:05:01.152
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:05:01.197
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:05:01.202
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 12:05:01.25
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:05:02.024
STEP: Deploying the webhook pod 04/23/23 12:05:02.036
STEP: Wait for the deployment to be ready 04/23/23 12:05:02.066
Apr 23 12:05:02.088: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/23/23 12:05:04.116
STEP: Verifying the service has paired with the endpoint 04/23/23 12:05:04.168
Apr 23 12:05:05.168: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:197
STEP: Registering the webhook via the AdmissionRegistration API 04/23/23 12:05:05.178
STEP: create a pod that should be denied by the webhook 04/23/23 12:05:05.213
STEP: create a pod that causes the webhook to hang 04/23/23 12:05:05.247
STEP: create a configmap that should be denied by the webhook 04/23/23 12:05:15.262
STEP: create a configmap that should be admitted by the webhook 04/23/23 12:05:15.317
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 04/23/23 12:05:15.333
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 04/23/23 12:05:15.358
STEP: create a namespace that bypass the webhook 04/23/23 12:05:15.374
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 04/23/23 12:05:15.402
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:05:15.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-774" for this suite. 04/23/23 12:05:15.624
STEP: Destroying namespace "webhook-774-markers" for this suite. 04/23/23 12:05:15.644
------------------------------
â€¢ [SLOW TEST] [14.509 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:197

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:05:01.15
    Apr 23 12:05:01.150: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 12:05:01.152
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:05:01.197
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:05:01.202
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 12:05:01.25
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:05:02.024
    STEP: Deploying the webhook pod 04/23/23 12:05:02.036
    STEP: Wait for the deployment to be ready 04/23/23 12:05:02.066
    Apr 23 12:05:02.088: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/23/23 12:05:04.116
    STEP: Verifying the service has paired with the endpoint 04/23/23 12:05:04.168
    Apr 23 12:05:05.168: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:197
    STEP: Registering the webhook via the AdmissionRegistration API 04/23/23 12:05:05.178
    STEP: create a pod that should be denied by the webhook 04/23/23 12:05:05.213
    STEP: create a pod that causes the webhook to hang 04/23/23 12:05:05.247
    STEP: create a configmap that should be denied by the webhook 04/23/23 12:05:15.262
    STEP: create a configmap that should be admitted by the webhook 04/23/23 12:05:15.317
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 04/23/23 12:05:15.333
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 04/23/23 12:05:15.358
    STEP: create a namespace that bypass the webhook 04/23/23 12:05:15.374
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 04/23/23 12:05:15.402
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:05:15.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-774" for this suite. 04/23/23 12:05:15.624
    STEP: Destroying namespace "webhook-774-markers" for this suite. 04/23/23 12:05:15.644
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:05:15.663
Apr 23 12:05:15.663: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename events 04/23/23 12:05:15.672
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:05:15.716
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:05:15.724
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 04/23/23 12:05:15.732
STEP: get a list of Events with a label in the current namespace 04/23/23 12:05:15.766
STEP: delete a list of events 04/23/23 12:05:15.777
Apr 23 12:05:15.778: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 04/23/23 12:05:15.827
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/node/init/init.go:32
Apr 23 12:05:15.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-instrumentation] Events API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-instrumentation] Events API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-instrumentation] Events API
  tear down framework | framework.go:193
STEP: Destroying namespace "events-2224" for this suite. 04/23/23 12:05:15.861
------------------------------
â€¢ [0.216 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:05:15.663
    Apr 23 12:05:15.663: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename events 04/23/23 12:05:15.672
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:05:15.716
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:05:15.724
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 04/23/23 12:05:15.732
    STEP: get a list of Events with a label in the current namespace 04/23/23 12:05:15.766
    STEP: delete a list of events 04/23/23 12:05:15.777
    Apr 23 12:05:15.778: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 04/23/23 12:05:15.827
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:05:15.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-instrumentation] Events API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-instrumentation] Events API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-instrumentation] Events API
      tear down framework | framework.go:193
    STEP: Destroying namespace "events-2224" for this suite. 04/23/23 12:05:15.861
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:908
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:05:15.885
Apr 23 12:05:15.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename statefulset 04/23/23 12:05:15.898
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:05:15.931
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:05:15.941
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-9183 04/23/23 12:05:15.947
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:908
Apr 23 12:05:16.035: INFO: Found 0 stateful pods, waiting for 1
Apr 23 12:05:26.051: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 04/23/23 12:05:26.074
W0423 12:05:26.098342      13 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 23 12:05:26.113: INFO: Found 1 stateful pods, waiting for 2
Apr 23 12:05:36.124: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 12:05:36.124: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 04/23/23 12:05:36.136
STEP: Delete all of the StatefulSets 04/23/23 12:05:36.144
STEP: Verify that StatefulSets have been deleted 04/23/23 12:05:36.165
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Apr 23 12:05:36.178: INFO: Deleting all statefulset in ns statefulset-9183
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Apr 23 12:05:36.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-9183" for this suite. 04/23/23 12:05:36.226
------------------------------
â€¢ [SLOW TEST] [20.364 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:908

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:05:15.885
    Apr 23 12:05:15.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename statefulset 04/23/23 12:05:15.898
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:05:15.931
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:05:15.941
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-9183 04/23/23 12:05:15.947
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:908
    Apr 23 12:05:16.035: INFO: Found 0 stateful pods, waiting for 1
    Apr 23 12:05:26.051: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 04/23/23 12:05:26.074
    W0423 12:05:26.098342      13 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 23 12:05:26.113: INFO: Found 1 stateful pods, waiting for 2
    Apr 23 12:05:36.124: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 23 12:05:36.124: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 04/23/23 12:05:36.136
    STEP: Delete all of the StatefulSets 04/23/23 12:05:36.144
    STEP: Verify that StatefulSets have been deleted 04/23/23 12:05:36.165
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Apr 23 12:05:36.178: INFO: Deleting all statefulset in ns statefulset-9183
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:05:36.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-9183" for this suite. 04/23/23 12:05:36.226
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1787
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:05:36.271
Apr 23 12:05:36.271: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 12:05:36.291
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:05:36.361
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:05:36.368
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1787
STEP: starting the proxy server 04/23/23 12:05:36.379
Apr 23 12:05:36.379: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8367 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 04/23/23 12:05:36.577
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 12:05:36.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-8367" for this suite. 04/23/23 12:05:36.623
------------------------------
â€¢ [0.388 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1780
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1787

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:05:36.271
    Apr 23 12:05:36.271: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 12:05:36.291
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:05:36.361
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:05:36.368
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1787
    STEP: starting the proxy server 04/23/23 12:05:36.379
    Apr 23 12:05:36.379: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-8367 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 04/23/23 12:05:36.577
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:05:36.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-8367" for this suite. 04/23/23 12:05:36.623
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:297
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:05:36.661
Apr 23 12:05:36.661: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename var-expansion 04/23/23 12:05:36.668
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:05:36.702
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:05:36.708
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:297
STEP: creating the pod 04/23/23 12:05:36.714
STEP: waiting for pod running 04/23/23 12:05:36.732
Apr 23 12:05:36.733: INFO: Waiting up to 2m0s for pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3" in namespace "var-expansion-3452" to be "running"
Apr 23 12:05:36.741: INFO: Pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.982789ms
Apr 23 12:05:38.748: INFO: Pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015235518s
Apr 23 12:05:40.754: INFO: Pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3": Phase="Running", Reason="", readiness=true. Elapsed: 4.02091692s
Apr 23 12:05:40.754: INFO: Pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3" satisfied condition "running"
STEP: creating a file in subpath 04/23/23 12:05:40.754
Apr 23 12:05:40.766: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3452 PodName:var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:05:40.767: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:05:40.769: INFO: ExecWithOptions: Clientset creation
Apr 23 12:05:40.769: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-3452/pods/var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 04/23/23 12:05:40.9
Apr 23 12:05:40.909: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3452 PodName:var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:05:40.909: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:05:40.910: INFO: ExecWithOptions: Clientset creation
Apr 23 12:05:40.910: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-3452/pods/var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 04/23/23 12:05:41.032
Apr 23 12:05:41.559: INFO: Successfully updated pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3"
STEP: waiting for annotated pod running 04/23/23 12:05:41.559
Apr 23 12:05:41.559: INFO: Waiting up to 2m0s for pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3" in namespace "var-expansion-3452" to be "running"
Apr 23 12:05:41.571: INFO: Pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3": Phase="Running", Reason="", readiness=true. Elapsed: 12.33168ms
Apr 23 12:05:41.571: INFO: Pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3" satisfied condition "running"
STEP: deleting the pod gracefully 04/23/23 12:05:41.572
Apr 23 12:05:41.572: INFO: Deleting pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3" in namespace "var-expansion-3452"
Apr 23 12:05:41.586: INFO: Wait up to 5m0s for pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Apr 23 12:06:13.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-3452" for this suite. 04/23/23 12:06:13.618
------------------------------
â€¢ [SLOW TEST] [36.969 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:297

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:05:36.661
    Apr 23 12:05:36.661: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename var-expansion 04/23/23 12:05:36.668
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:05:36.702
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:05:36.708
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:297
    STEP: creating the pod 04/23/23 12:05:36.714
    STEP: waiting for pod running 04/23/23 12:05:36.732
    Apr 23 12:05:36.733: INFO: Waiting up to 2m0s for pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3" in namespace "var-expansion-3452" to be "running"
    Apr 23 12:05:36.741: INFO: Pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.982789ms
    Apr 23 12:05:38.748: INFO: Pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015235518s
    Apr 23 12:05:40.754: INFO: Pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3": Phase="Running", Reason="", readiness=true. Elapsed: 4.02091692s
    Apr 23 12:05:40.754: INFO: Pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3" satisfied condition "running"
    STEP: creating a file in subpath 04/23/23 12:05:40.754
    Apr 23 12:05:40.766: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3452 PodName:var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:05:40.767: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:05:40.769: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:05:40.769: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-3452/pods/var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 04/23/23 12:05:40.9
    Apr 23 12:05:40.909: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3452 PodName:var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:05:40.909: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:05:40.910: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:05:40.910: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-3452/pods/var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 04/23/23 12:05:41.032
    Apr 23 12:05:41.559: INFO: Successfully updated pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3"
    STEP: waiting for annotated pod running 04/23/23 12:05:41.559
    Apr 23 12:05:41.559: INFO: Waiting up to 2m0s for pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3" in namespace "var-expansion-3452" to be "running"
    Apr 23 12:05:41.571: INFO: Pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3": Phase="Running", Reason="", readiness=true. Elapsed: 12.33168ms
    Apr 23 12:05:41.571: INFO: Pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3" satisfied condition "running"
    STEP: deleting the pod gracefully 04/23/23 12:05:41.572
    Apr 23 12:05:41.572: INFO: Deleting pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3" in namespace "var-expansion-3452"
    Apr 23 12:05:41.586: INFO: Wait up to 5m0s for pod "var-expansion-3b86e493-f43f-4953-b1dc-51386c7ce0f3" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:06:13.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-3452" for this suite. 04/23/23 12:06:13.618
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:161
[BeforeEach] [sig-auth] ServiceAccounts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:06:13.633
Apr 23 12:06:13.634: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename svcaccounts 04/23/23 12:06:13.641
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:13.673
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:13.678
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:31
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:161
Apr 23 12:06:13.715: INFO: created pod pod-service-account-defaultsa
Apr 23 12:06:13.715: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 23 12:06:13.733: INFO: created pod pod-service-account-mountsa
Apr 23 12:06:13.733: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 23 12:06:13.768: INFO: created pod pod-service-account-nomountsa
Apr 23 12:06:13.768: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 23 12:06:13.786: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 23 12:06:13.786: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 23 12:06:13.797: INFO: created pod pod-service-account-mountsa-mountspec
Apr 23 12:06:13.797: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 23 12:06:13.818: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 23 12:06:13.818: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 23 12:06:13.857: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 23 12:06:13.857: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 23 12:06:13.901: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 23 12:06:13.901: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 23 12:06:13.922: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 23 12:06:13.922: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/node/init/init.go:32
Apr 23 12:06:13.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  tear down framework | framework.go:193
STEP: Destroying namespace "svcaccounts-3238" for this suite. 04/23/23 12:06:13.946
------------------------------
â€¢ [0.375 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:06:13.633
    Apr 23 12:06:13.634: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename svcaccounts 04/23/23 12:06:13.641
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:13.673
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:13.678
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:31
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:161
    Apr 23 12:06:13.715: INFO: created pod pod-service-account-defaultsa
    Apr 23 12:06:13.715: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Apr 23 12:06:13.733: INFO: created pod pod-service-account-mountsa
    Apr 23 12:06:13.733: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Apr 23 12:06:13.768: INFO: created pod pod-service-account-nomountsa
    Apr 23 12:06:13.768: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Apr 23 12:06:13.786: INFO: created pod pod-service-account-defaultsa-mountspec
    Apr 23 12:06:13.786: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Apr 23 12:06:13.797: INFO: created pod pod-service-account-mountsa-mountspec
    Apr 23 12:06:13.797: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Apr 23 12:06:13.818: INFO: created pod pod-service-account-nomountsa-mountspec
    Apr 23 12:06:13.818: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Apr 23 12:06:13.857: INFO: created pod pod-service-account-defaultsa-nomountspec
    Apr 23 12:06:13.857: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Apr 23 12:06:13.901: INFO: created pod pod-service-account-mountsa-nomountspec
    Apr 23 12:06:13.901: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Apr 23 12:06:13.922: INFO: created pod pod-service-account-nomountsa-nomountspec
    Apr 23 12:06:13.922: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:06:13.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      tear down framework | framework.go:193
    STEP: Destroying namespace "svcaccounts-3238" for this suite. 04/23/23 12:06:13.946
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:06:14.025
Apr 23 12:06:14.025: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename watch 04/23/23 12:06:14.028
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:14.195
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:14.201
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:31
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 04/23/23 12:06:14.206
STEP: creating a new configmap 04/23/23 12:06:14.208
STEP: modifying the configmap once 04/23/23 12:06:14.215
STEP: changing the label value of the configmap 04/23/23 12:06:14.235
STEP: Expecting to observe a delete notification for the watched object 04/23/23 12:06:14.26
Apr 23 12:06:14.261: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4107  6382d36c-69fa-4db2-b489-3ed8c6498d2d 25982 0 2023-04-23 12:06:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-23 12:06:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 23 12:06:14.261: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4107  6382d36c-69fa-4db2-b489-3ed8c6498d2d 25983 0 2023-04-23 12:06:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-23 12:06:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 23 12:06:14.262: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4107  6382d36c-69fa-4db2-b489-3ed8c6498d2d 25984 0 2023-04-23 12:06:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-23 12:06:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 04/23/23 12:06:14.262
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 04/23/23 12:06:14.279
STEP: changing the label value of the configmap back 04/23/23 12:06:24.28
STEP: modifying the configmap a third time 04/23/23 12:06:24.303
STEP: deleting the configmap 04/23/23 12:06:24.318
STEP: Expecting to observe an add notification for the watched object when the label value was restored 04/23/23 12:06:24.332
Apr 23 12:06:24.332: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4107  6382d36c-69fa-4db2-b489-3ed8c6498d2d 26067 0 2023-04-23 12:06:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-23 12:06:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 23 12:06:24.333: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4107  6382d36c-69fa-4db2-b489-3ed8c6498d2d 26068 0 2023-04-23 12:06:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-23 12:06:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 23 12:06:24.333: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4107  6382d36c-69fa-4db2-b489-3ed8c6498d2d 26069 0 2023-04-23 12:06:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-23 12:06:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/node/init/init.go:32
Apr 23 12:06:24.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  tear down framework | framework.go:193
STEP: Destroying namespace "watch-4107" for this suite. 04/23/23 12:06:24.347
------------------------------
â€¢ [SLOW TEST] [10.332 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:06:14.025
    Apr 23 12:06:14.025: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename watch 04/23/23 12:06:14.028
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:14.195
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:14.201
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:31
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 04/23/23 12:06:14.206
    STEP: creating a new configmap 04/23/23 12:06:14.208
    STEP: modifying the configmap once 04/23/23 12:06:14.215
    STEP: changing the label value of the configmap 04/23/23 12:06:14.235
    STEP: Expecting to observe a delete notification for the watched object 04/23/23 12:06:14.26
    Apr 23 12:06:14.261: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4107  6382d36c-69fa-4db2-b489-3ed8c6498d2d 25982 0 2023-04-23 12:06:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-23 12:06:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 23 12:06:14.261: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4107  6382d36c-69fa-4db2-b489-3ed8c6498d2d 25983 0 2023-04-23 12:06:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-23 12:06:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 23 12:06:14.262: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4107  6382d36c-69fa-4db2-b489-3ed8c6498d2d 25984 0 2023-04-23 12:06:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-23 12:06:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 04/23/23 12:06:14.262
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 04/23/23 12:06:14.279
    STEP: changing the label value of the configmap back 04/23/23 12:06:24.28
    STEP: modifying the configmap a third time 04/23/23 12:06:24.303
    STEP: deleting the configmap 04/23/23 12:06:24.318
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 04/23/23 12:06:24.332
    Apr 23 12:06:24.332: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4107  6382d36c-69fa-4db2-b489-3ed8c6498d2d 26067 0 2023-04-23 12:06:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-23 12:06:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 23 12:06:24.333: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4107  6382d36c-69fa-4db2-b489-3ed8c6498d2d 26068 0 2023-04-23 12:06:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-23 12:06:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 23 12:06:24.333: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-4107  6382d36c-69fa-4db2-b489-3ed8c6498d2d 26069 0 2023-04-23 12:06:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-23 12:06:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:06:24.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      tear down framework | framework.go:193
    STEP: Destroying namespace "watch-4107" for this suite. 04/23/23 12:06:24.347
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:943
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:06:24.36
Apr 23 12:06:24.361: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename resourcequota 04/23/23 12:06:24.364
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:24.394
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:24.398
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:943
STEP: Creating a ResourceQuota 04/23/23 12:06:24.405
STEP: Getting a ResourceQuota 04/23/23 12:06:24.415
STEP: Listing all ResourceQuotas with LabelSelector 04/23/23 12:06:24.424
STEP: Patching the ResourceQuota 04/23/23 12:06:24.431
STEP: Deleting a Collection of ResourceQuotas 04/23/23 12:06:24.446
STEP: Verifying the deleted ResourceQuota 04/23/23 12:06:24.465
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Apr 23 12:06:24.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-8107" for this suite. 04/23/23 12:06:24.479
------------------------------
â€¢ [0.131 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:943

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:06:24.36
    Apr 23 12:06:24.361: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename resourcequota 04/23/23 12:06:24.364
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:24.394
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:24.398
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:943
    STEP: Creating a ResourceQuota 04/23/23 12:06:24.405
    STEP: Getting a ResourceQuota 04/23/23 12:06:24.415
    STEP: Listing all ResourceQuotas with LabelSelector 04/23/23 12:06:24.424
    STEP: Patching the ResourceQuota 04/23/23 12:06:24.431
    STEP: Deleting a Collection of ResourceQuotas 04/23/23 12:06:24.446
    STEP: Verifying the deleted ResourceQuota 04/23/23 12:06:24.465
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:06:24.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-8107" for this suite. 04/23/23 12:06:24.479
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:53
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:06:24.492
Apr 23 12:06:24.493: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 12:06:24.495
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:24.528
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:24.54
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:53
STEP: Creating a pod to test downward API volume plugin 04/23/23 12:06:24.555
Apr 23 12:06:24.582: INFO: Waiting up to 5m0s for pod "downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682" in namespace "downward-api-3040" to be "Succeeded or Failed"
Apr 23 12:06:24.591: INFO: Pod "downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682": Phase="Pending", Reason="", readiness=false. Elapsed: 9.361738ms
Apr 23 12:06:26.602: INFO: Pod "downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019816661s
Apr 23 12:06:28.602: INFO: Pod "downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019729494s
STEP: Saw pod success 04/23/23 12:06:28.602
Apr 23 12:06:28.603: INFO: Pod "downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682" satisfied condition "Succeeded or Failed"
Apr 23 12:06:28.609: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682 container client-container: <nil>
STEP: delete the pod 04/23/23 12:06:28.648
Apr 23 12:06:28.674: INFO: Waiting for pod downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682 to disappear
Apr 23 12:06:28.679: INFO: Pod downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Apr 23 12:06:28.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-3040" for this suite. 04/23/23 12:06:28.689
------------------------------
â€¢ [4.209 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:06:24.492
    Apr 23 12:06:24.493: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 12:06:24.495
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:24.528
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:24.54
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:53
    STEP: Creating a pod to test downward API volume plugin 04/23/23 12:06:24.555
    Apr 23 12:06:24.582: INFO: Waiting up to 5m0s for pod "downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682" in namespace "downward-api-3040" to be "Succeeded or Failed"
    Apr 23 12:06:24.591: INFO: Pod "downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682": Phase="Pending", Reason="", readiness=false. Elapsed: 9.361738ms
    Apr 23 12:06:26.602: INFO: Pod "downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019816661s
    Apr 23 12:06:28.602: INFO: Pod "downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019729494s
    STEP: Saw pod success 04/23/23 12:06:28.602
    Apr 23 12:06:28.603: INFO: Pod "downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682" satisfied condition "Succeeded or Failed"
    Apr 23 12:06:28.609: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682 container client-container: <nil>
    STEP: delete the pod 04/23/23 12:06:28.648
    Apr 23 12:06:28.674: INFO: Waiting for pod downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682 to disappear
    Apr 23 12:06:28.679: INFO: Pod downwardapi-volume-80ce78c0-9401-40fa-bd37-a2da4e634682 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:06:28.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-3040" for this suite. 04/23/23 12:06:28.689
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:824
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:06:28.715
Apr 23 12:06:28.715: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 12:06:28.717
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:28.749
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:28.755
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:824
STEP: validating api versions 04/23/23 12:06:28.761
Apr 23 12:06:28.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-2824 api-versions'
Apr 23 12:06:28.973: INFO: stderr: ""
Apr 23 12:06:28.973: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncilium.io/v2\ncilium.io/v2alpha1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta2\nflowcontrol.apiserver.k8s.io/v1beta3\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 12:06:28.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-2824" for this suite. 04/23/23 12:06:28.984
------------------------------
â€¢ [0.285 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:818
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:824

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:06:28.715
    Apr 23 12:06:28.715: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 12:06:28.717
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:28.749
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:28.755
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:824
    STEP: validating api versions 04/23/23 12:06:28.761
    Apr 23 12:06:28.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-2824 api-versions'
    Apr 23 12:06:28.973: INFO: stderr: ""
    Apr 23 12:06:28.973: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncilium.io/v2\ncilium.io/v2alpha1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta2\nflowcontrol.apiserver.k8s.io/v1beta3\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:06:28.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-2824" for this suite. 04/23/23 12:06:28.984
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:299
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:06:29.002
Apr 23 12:06:29.003: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename namespaces 04/23/23 12:06:29.005
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:29.034
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:29.041
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:31
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:299
STEP: Read namespace status 04/23/23 12:06:29.047
Apr 23 12:06:29.066: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 04/23/23 12:06:29.066
Apr 23 12:06:29.077: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 04/23/23 12:06:29.078
Apr 23 12:06:29.095: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:06:29.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "namespaces-7553" for this suite. 04/23/23 12:06:29.107
------------------------------
â€¢ [0.120 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:299

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:06:29.002
    Apr 23 12:06:29.003: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename namespaces 04/23/23 12:06:29.005
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:29.034
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:29.041
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:299
    STEP: Read namespace status 04/23/23 12:06:29.047
    Apr 23 12:06:29.066: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 04/23/23 12:06:29.066
    Apr 23 12:06:29.077: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 04/23/23 12:06:29.078
    Apr 23 12:06:29.095: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:06:29.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "namespaces-7553" for this suite. 04/23/23 12:06:29.107
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:216
[BeforeEach] [sig-node] Container Runtime
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:06:29.133
Apr 23 12:06:29.133: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-runtime 04/23/23 12:06:29.135
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:29.171
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:29.176
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:31
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:216
STEP: create the container 04/23/23 12:06:29.183
STEP: wait for the container to reach Failed 04/23/23 12:06:29.203
STEP: get the container status 04/23/23 12:06:35.273
STEP: the container should be terminated 04/23/23 12:06:35.283
STEP: the termination message should be set 04/23/23 12:06:35.283
Apr 23 12:06:35.283: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 04/23/23 12:06:35.283
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/node/init/init.go:32
Apr 23 12:06:35.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Runtime
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Runtime
  tear down framework | framework.go:193
STEP: Destroying namespace "container-runtime-9252" for this suite. 04/23/23 12:06:35.352
------------------------------
â€¢ [SLOW TEST] [6.234 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:44
    on terminated container
    test/e2e/common/node/runtime.go:137
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:06:29.133
    Apr 23 12:06:29.133: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-runtime 04/23/23 12:06:29.135
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:29.171
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:29.176
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:31
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:216
    STEP: create the container 04/23/23 12:06:29.183
    STEP: wait for the container to reach Failed 04/23/23 12:06:29.203
    STEP: get the container status 04/23/23 12:06:35.273
    STEP: the container should be terminated 04/23/23 12:06:35.283
    STEP: the termination message should be set 04/23/23 12:06:35.283
    Apr 23 12:06:35.283: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 04/23/23 12:06:35.283
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:06:35.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Runtime
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Runtime
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-runtime-9252" for this suite. 04/23/23 12:06:35.352
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:06:35.367
Apr 23 12:06:35.368: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename deployment 04/23/23 12:06:35.373
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:35.404
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:35.408
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Apr 23 12:06:35.427: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 23 12:06:40.443: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/23/23 12:06:40.443
Apr 23 12:06:40.444: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 04/23/23 12:06:40.474
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 23 12:06:44.537: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-6895  7de997d4-86ee-4f5c-9523-9c6a643523e7 26251 1 2023-04-23 12:06:40 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-23 12:06:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:06:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c01b18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-23 12:06:40 +0000 UTC,LastTransitionTime:2023-04-23 12:06:40 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-7698ff6f6b" has successfully progressed.,LastUpdateTime:2023-04-23 12:06:42 +0000 UTC,LastTransitionTime:2023-04-23 12:06:40 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 23 12:06:44.547: INFO: New ReplicaSet "test-cleanup-deployment-7698ff6f6b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-7698ff6f6b  deployment-6895  de1887ff-69dd-4c89-90de-6f233397b444 26240 1 2023-04-23 12:06:40 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:7698ff6f6b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 7de997d4-86ee-4f5c-9523-9c6a643523e7 0xc003c01ef7 0xc003c01ef8}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:06:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7de997d4-86ee-4f5c-9523-9c6a643523e7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:06:42 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7698ff6f6b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:7698ff6f6b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c01fa8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 23 12:06:44.558: INFO: Pod "test-cleanup-deployment-7698ff6f6b-ktsgr" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-7698ff6f6b-ktsgr test-cleanup-deployment-7698ff6f6b- deployment-6895  9c0deeba-ecd3-4239-b741-4a754638a9eb 26239 0 2023-04-23 12:06:40 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:7698ff6f6b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-7698ff6f6b de1887ff-69dd-4c89-90de-6f233397b444 0xc000be40c7 0xc000be40c8}] [] [{kube-controller-manager Update v1 2023-04-23 12:06:40 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"de1887ff-69dd-4c89-90de-6f233397b444\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:06:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jvjdx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jvjdx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:06:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:06:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:06:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:06:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.7,StartTime:2023-04-23 12:06:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:06:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:cri-o://16f0ac607828b18b8c4427c5ffde0ee440016790b08f9ab3fd12f26e592846ee,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Apr 23 12:06:44.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-6895" for this suite. 04/23/23 12:06:44.574
------------------------------
â€¢ [SLOW TEST] [9.225 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:06:35.367
    Apr 23 12:06:35.368: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename deployment 04/23/23 12:06:35.373
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:35.404
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:35.408
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Apr 23 12:06:35.427: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Apr 23 12:06:40.443: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/23/23 12:06:40.443
    Apr 23 12:06:40.444: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 04/23/23 12:06:40.474
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 23 12:06:44.537: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-6895  7de997d4-86ee-4f5c-9523-9c6a643523e7 26251 1 2023-04-23 12:06:40 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-23 12:06:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:06:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c01b18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-23 12:06:40 +0000 UTC,LastTransitionTime:2023-04-23 12:06:40 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-7698ff6f6b" has successfully progressed.,LastUpdateTime:2023-04-23 12:06:42 +0000 UTC,LastTransitionTime:2023-04-23 12:06:40 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 23 12:06:44.547: INFO: New ReplicaSet "test-cleanup-deployment-7698ff6f6b" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-7698ff6f6b  deployment-6895  de1887ff-69dd-4c89-90de-6f233397b444 26240 1 2023-04-23 12:06:40 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:7698ff6f6b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 7de997d4-86ee-4f5c-9523-9c6a643523e7 0xc003c01ef7 0xc003c01ef8}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:06:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7de997d4-86ee-4f5c-9523-9c6a643523e7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:06:42 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7698ff6f6b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:7698ff6f6b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c01fa8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 23 12:06:44.558: INFO: Pod "test-cleanup-deployment-7698ff6f6b-ktsgr" is available:
    &Pod{ObjectMeta:{test-cleanup-deployment-7698ff6f6b-ktsgr test-cleanup-deployment-7698ff6f6b- deployment-6895  9c0deeba-ecd3-4239-b741-4a754638a9eb 26239 0 2023-04-23 12:06:40 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:7698ff6f6b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-7698ff6f6b de1887ff-69dd-4c89-90de-6f233397b444 0xc000be40c7 0xc000be40c8}] [] [{kube-controller-manager Update v1 2023-04-23 12:06:40 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"de1887ff-69dd-4c89-90de-6f233397b444\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:06:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jvjdx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jvjdx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:06:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:06:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:06:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:06:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.7,StartTime:2023-04-23 12:06:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:06:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:cri-o://16f0ac607828b18b8c4427c5ffde0ee440016790b08f9ab3fd12f26e592846ee,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:06:44.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-6895" for this suite. 04/23/23 12:06:44.574
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:160
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:06:44.599
Apr 23 12:06:44.599: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename resourcequota 04/23/23 12:06:44.602
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:44.627
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:44.634
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:160
STEP: Discovering how many secrets are in namespace by default 04/23/23 12:06:44.64
STEP: Counting existing ResourceQuota 04/23/23 12:06:49.646
STEP: Creating a ResourceQuota 04/23/23 12:06:54.656
STEP: Ensuring resource quota status is calculated 04/23/23 12:06:54.667
STEP: Creating a Secret 04/23/23 12:06:56.675
STEP: Ensuring resource quota status captures secret creation 04/23/23 12:06:56.694
STEP: Deleting a secret 04/23/23 12:06:58.706
STEP: Ensuring resource quota status released usage 04/23/23 12:06:58.725
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Apr 23 12:07:00.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-7349" for this suite. 04/23/23 12:07:00.746
------------------------------
â€¢ [SLOW TEST] [16.163 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:06:44.599
    Apr 23 12:06:44.599: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename resourcequota 04/23/23 12:06:44.602
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:06:44.627
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:06:44.634
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:160
    STEP: Discovering how many secrets are in namespace by default 04/23/23 12:06:44.64
    STEP: Counting existing ResourceQuota 04/23/23 12:06:49.646
    STEP: Creating a ResourceQuota 04/23/23 12:06:54.656
    STEP: Ensuring resource quota status is calculated 04/23/23 12:06:54.667
    STEP: Creating a Secret 04/23/23 12:06:56.675
    STEP: Ensuring resource quota status captures secret creation 04/23/23 12:06:56.694
    STEP: Deleting a secret 04/23/23 12:06:58.706
    STEP: Ensuring resource quota status released usage 04/23/23 12:06:58.725
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:07:00.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-7349" for this suite. 04/23/23 12:07:00.746
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:07:00.769
Apr 23 12:07:00.769: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename custom-resource-definition 04/23/23 12:07:00.772
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:07:00.807
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:07:00.817
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Apr 23 12:07:00.825: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:07:01.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "custom-resource-definition-6615" for this suite. 04/23/23 12:07:01.568
------------------------------
â€¢ [0.813 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:07:00.769
    Apr 23 12:07:00.769: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename custom-resource-definition 04/23/23 12:07:00.772
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:07:00.807
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:07:00.817
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Apr 23 12:07:00.825: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:07:01.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "custom-resource-definition-6615" for this suite. 04/23/23 12:07:01.568
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:194
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:07:01.624
Apr 23 12:07:01.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 12:07:01.628
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:07:01.663
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:07:01.668
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:194
Apr 23 12:07:01.677: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/23/23 12:07:05.617
Apr 23 12:07:05.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-2612 --namespace=crd-publish-openapi-2612 create -f -'
Apr 23 12:07:08.202: INFO: stderr: ""
Apr 23 12:07:08.202: INFO: stdout: "e2e-test-crd-publish-openapi-3386-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 23 12:07:08.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-2612 --namespace=crd-publish-openapi-2612 delete e2e-test-crd-publish-openapi-3386-crds test-cr'
Apr 23 12:07:08.397: INFO: stderr: ""
Apr 23 12:07:08.397: INFO: stdout: "e2e-test-crd-publish-openapi-3386-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Apr 23 12:07:08.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-2612 --namespace=crd-publish-openapi-2612 apply -f -'
Apr 23 12:07:10.028: INFO: stderr: ""
Apr 23 12:07:10.029: INFO: stdout: "e2e-test-crd-publish-openapi-3386-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 23 12:07:10.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-2612 --namespace=crd-publish-openapi-2612 delete e2e-test-crd-publish-openapi-3386-crds test-cr'
Apr 23 12:07:10.319: INFO: stderr: ""
Apr 23 12:07:10.319: INFO: stdout: "e2e-test-crd-publish-openapi-3386-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 04/23/23 12:07:10.319
Apr 23 12:07:10.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-2612 explain e2e-test-crd-publish-openapi-3386-crds'
Apr 23 12:07:10.828: INFO: stderr: ""
Apr 23 12:07:10.828: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3386-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:07:13.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-2612" for this suite. 04/23/23 12:07:13.996
------------------------------
â€¢ [SLOW TEST] [12.392 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:07:01.624
    Apr 23 12:07:01.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 12:07:01.628
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:07:01.663
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:07:01.668
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:194
    Apr 23 12:07:01.677: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/23/23 12:07:05.617
    Apr 23 12:07:05.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-2612 --namespace=crd-publish-openapi-2612 create -f -'
    Apr 23 12:07:08.202: INFO: stderr: ""
    Apr 23 12:07:08.202: INFO: stdout: "e2e-test-crd-publish-openapi-3386-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Apr 23 12:07:08.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-2612 --namespace=crd-publish-openapi-2612 delete e2e-test-crd-publish-openapi-3386-crds test-cr'
    Apr 23 12:07:08.397: INFO: stderr: ""
    Apr 23 12:07:08.397: INFO: stdout: "e2e-test-crd-publish-openapi-3386-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Apr 23 12:07:08.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-2612 --namespace=crd-publish-openapi-2612 apply -f -'
    Apr 23 12:07:10.028: INFO: stderr: ""
    Apr 23 12:07:10.029: INFO: stdout: "e2e-test-crd-publish-openapi-3386-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Apr 23 12:07:10.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-2612 --namespace=crd-publish-openapi-2612 delete e2e-test-crd-publish-openapi-3386-crds test-cr'
    Apr 23 12:07:10.319: INFO: stderr: ""
    Apr 23 12:07:10.319: INFO: stdout: "e2e-test-crd-publish-openapi-3386-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 04/23/23 12:07:10.319
    Apr 23 12:07:10.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-2612 explain e2e-test-crd-publish-openapi-3386-crds'
    Apr 23 12:07:10.828: INFO: stderr: ""
    Apr 23 12:07:10.828: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3386-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:07:13.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-2612" for this suite. 04/23/23 12:07:13.996
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1276
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:07:14.017
Apr 23 12:07:14.017: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 12:07:14.02
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:07:14.051
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:07:14.059
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1276
Apr 23 12:07:14.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5091 create -f -'
Apr 23 12:07:16.372: INFO: stderr: ""
Apr 23 12:07:16.372: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Apr 23 12:07:16.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5091 create -f -'
Apr 23 12:07:17.002: INFO: stderr: ""
Apr 23 12:07:17.002: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/23/23 12:07:17.002
Apr 23 12:07:18.015: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 23 12:07:18.016: INFO: Found 0 / 1
Apr 23 12:07:19.020: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 23 12:07:19.020: INFO: Found 1 / 1
Apr 23 12:07:19.020: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 23 12:07:19.038: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 23 12:07:19.038: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 23 12:07:19.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5091 describe pod agnhost-primary-5wpk7'
Apr 23 12:07:19.343: INFO: stderr: ""
Apr 23 12:07:19.343: INFO: stdout: "Name:             agnhost-primary-5wpk7\nNamespace:        kubectl-5091\nPriority:         0\nService Account:  default\nNode:             eingavuivie7-3/192.168.121.198\nStart Time:       Sun, 23 Apr 2023 12:07:16 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.233.64.201\nIPs:\n  IP:           10.233.64.201\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   cri-o://5c976282cc932026e34651e41620af933202726f97bf03d0a433276c2fc2cf0d\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.43\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sun, 23 Apr 2023 12:07:17 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-xjlds (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-xjlds:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-5091/agnhost-primary-5wpk7 to eingavuivie7-3\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.43\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Apr 23 12:07:19.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5091 describe rc agnhost-primary'
Apr 23 12:07:19.697: INFO: stderr: ""
Apr 23 12:07:19.697: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5091\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.43\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-5wpk7\n"
Apr 23 12:07:19.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5091 describe service agnhost-primary'
Apr 23 12:07:20.029: INFO: stderr: ""
Apr 23 12:07:20.029: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5091\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.233.39.145\nIPs:               10.233.39.145\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.233.64.201:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 23 12:07:20.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5091 describe node eingavuivie7-1'
Apr 23 12:07:20.260: INFO: stderr: ""
Apr 23 12:07:20.261: INFO: stdout: "Name:               eingavuivie7-1\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=eingavuivie7-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sun, 23 Apr 2023 10:39:41 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  eingavuivie7-1\n  AcquireTime:     <unset>\n  RenewTime:       Sun, 23 Apr 2023 12:07:19 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sun, 23 Apr 2023 10:46:03 +0000   Sun, 23 Apr 2023 10:46:03 +0000   CiliumIsUp                   Cilium is running on this node\n  MemoryPressure       False   Sun, 23 Apr 2023 12:03:16 +0000   Sun, 23 Apr 2023 10:39:31 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sun, 23 Apr 2023 12:03:16 +0000   Sun, 23 Apr 2023 10:39:31 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sun, 23 Apr 2023 12:03:16 +0000   Sun, 23 Apr 2023 10:39:31 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sun, 23 Apr 2023 12:03:16 +0000   Sun, 23 Apr 2023 10:41:30 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.121.130\n  Hostname:    eingavuivie7-1\nCapacity:\n  cpu:                2\n  ephemeral-storage:  122749536Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8140196Ki\n  pods:               110\nAllocatable:\n  cpu:                1600m\n  ephemeral-storage:  119410748528\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3290532Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 8bf3fea7a9df46cc87fac902f33b06ab\n  System UUID:                8bf3fea7-a9df-46cc-87fa-c902f33b06ab\n  Boot ID:                    c3a3a9c1-ae71-43b1-b5e6-56ec1f16cc54\n  Kernel Version:             5.19.0-40-generic\n  OS Image:                   Ubuntu 22.04.2 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  cri-o://1.26.0\n  Kubelet Version:            v1.26.4\n  Kube-Proxy Version:         v1.26.4\nPodCIDR:                      10.233.64.0/24\nPodCIDRs:                     10.233.64.0/24\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 cilium-node-init-j475c                                     100m (6%)     0 (0%)      100Mi (3%)       0 (0%)         82m\n  kube-system                 cilium-tcvk2                                               100m (6%)     0 (0%)      100Mi (3%)       0 (0%)         82m\n  kube-system                 kube-addon-manager-eingavuivie7-1                          5m (0%)       0 (0%)      50Mi (1%)        0 (0%)         84m\n  kube-system                 kube-apiserver-eingavuivie7-1                              250m (15%)    0 (0%)      0 (0%)           0 (0%)         87m\n  kube-system                 kube-controller-manager-eingavuivie7-1                     200m (12%)    0 (0%)      0 (0%)           0 (0%)         87m\n  kube-system                 kube-proxy-qx9mz                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         87m\n  kube-system                 kube-scheduler-eingavuivie7-1                              100m (6%)     0 (0%)      0 (0%)           0 (0%)         87m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-tdgvz    0 (0%)        0 (0%)      0 (0%)           0 (0%)         55m\n  svcaccounts-3238            pod-service-account-nomountsa-mountspec                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         67s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                755m (47%)  0 (0%)\n  memory             250Mi (7%)  0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
Apr 23 12:07:20.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5091 describe namespace kubectl-5091'
Apr 23 12:07:20.514: INFO: stderr: ""
Apr 23 12:07:20.514: INFO: stdout: "Name:         kubectl-5091\nLabels:       e2e-framework=kubectl\n              e2e-run=1de117d5-5b32-4f50-b9f3-5af11d500051\n              kubernetes.io/metadata.name=kubectl-5091\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 12:07:20.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-5091" for this suite. 04/23/23 12:07:20.522
------------------------------
â€¢ [SLOW TEST] [6.514 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1270
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:07:14.017
    Apr 23 12:07:14.017: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 12:07:14.02
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:07:14.051
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:07:14.059
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1276
    Apr 23 12:07:14.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5091 create -f -'
    Apr 23 12:07:16.372: INFO: stderr: ""
    Apr 23 12:07:16.372: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Apr 23 12:07:16.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5091 create -f -'
    Apr 23 12:07:17.002: INFO: stderr: ""
    Apr 23 12:07:17.002: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/23/23 12:07:17.002
    Apr 23 12:07:18.015: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 23 12:07:18.016: INFO: Found 0 / 1
    Apr 23 12:07:19.020: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 23 12:07:19.020: INFO: Found 1 / 1
    Apr 23 12:07:19.020: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Apr 23 12:07:19.038: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 23 12:07:19.038: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 23 12:07:19.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5091 describe pod agnhost-primary-5wpk7'
    Apr 23 12:07:19.343: INFO: stderr: ""
    Apr 23 12:07:19.343: INFO: stdout: "Name:             agnhost-primary-5wpk7\nNamespace:        kubectl-5091\nPriority:         0\nService Account:  default\nNode:             eingavuivie7-3/192.168.121.198\nStart Time:       Sun, 23 Apr 2023 12:07:16 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.233.64.201\nIPs:\n  IP:           10.233.64.201\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   cri-o://5c976282cc932026e34651e41620af933202726f97bf03d0a433276c2fc2cf0d\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.43\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sun, 23 Apr 2023 12:07:17 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-xjlds (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-xjlds:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-5091/agnhost-primary-5wpk7 to eingavuivie7-3\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.43\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
    Apr 23 12:07:19.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5091 describe rc agnhost-primary'
    Apr 23 12:07:19.697: INFO: stderr: ""
    Apr 23 12:07:19.697: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5091\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.43\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-5wpk7\n"
    Apr 23 12:07:19.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5091 describe service agnhost-primary'
    Apr 23 12:07:20.029: INFO: stderr: ""
    Apr 23 12:07:20.029: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5091\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.233.39.145\nIPs:               10.233.39.145\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.233.64.201:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Apr 23 12:07:20.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5091 describe node eingavuivie7-1'
    Apr 23 12:07:20.260: INFO: stderr: ""
    Apr 23 12:07:20.261: INFO: stdout: "Name:               eingavuivie7-1\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=eingavuivie7-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sun, 23 Apr 2023 10:39:41 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  eingavuivie7-1\n  AcquireTime:     <unset>\n  RenewTime:       Sun, 23 Apr 2023 12:07:19 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sun, 23 Apr 2023 10:46:03 +0000   Sun, 23 Apr 2023 10:46:03 +0000   CiliumIsUp                   Cilium is running on this node\n  MemoryPressure       False   Sun, 23 Apr 2023 12:03:16 +0000   Sun, 23 Apr 2023 10:39:31 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sun, 23 Apr 2023 12:03:16 +0000   Sun, 23 Apr 2023 10:39:31 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sun, 23 Apr 2023 12:03:16 +0000   Sun, 23 Apr 2023 10:39:31 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sun, 23 Apr 2023 12:03:16 +0000   Sun, 23 Apr 2023 10:41:30 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.121.130\n  Hostname:    eingavuivie7-1\nCapacity:\n  cpu:                2\n  ephemeral-storage:  122749536Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8140196Ki\n  pods:               110\nAllocatable:\n  cpu:                1600m\n  ephemeral-storage:  119410748528\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3290532Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 8bf3fea7a9df46cc87fac902f33b06ab\n  System UUID:                8bf3fea7-a9df-46cc-87fa-c902f33b06ab\n  Boot ID:                    c3a3a9c1-ae71-43b1-b5e6-56ec1f16cc54\n  Kernel Version:             5.19.0-40-generic\n  OS Image:                   Ubuntu 22.04.2 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  cri-o://1.26.0\n  Kubelet Version:            v1.26.4\n  Kube-Proxy Version:         v1.26.4\nPodCIDR:                      10.233.64.0/24\nPodCIDRs:                     10.233.64.0/24\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 cilium-node-init-j475c                                     100m (6%)     0 (0%)      100Mi (3%)       0 (0%)         82m\n  kube-system                 cilium-tcvk2                                               100m (6%)     0 (0%)      100Mi (3%)       0 (0%)         82m\n  kube-system                 kube-addon-manager-eingavuivie7-1                          5m (0%)       0 (0%)      50Mi (1%)        0 (0%)         84m\n  kube-system                 kube-apiserver-eingavuivie7-1                              250m (15%)    0 (0%)      0 (0%)           0 (0%)         87m\n  kube-system                 kube-controller-manager-eingavuivie7-1                     200m (12%)    0 (0%)      0 (0%)           0 (0%)         87m\n  kube-system                 kube-proxy-qx9mz                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         87m\n  kube-system                 kube-scheduler-eingavuivie7-1                              100m (6%)     0 (0%)      0 (0%)           0 (0%)         87m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-6b9d47a404de437e-tdgvz    0 (0%)        0 (0%)      0 (0%)           0 (0%)         55m\n  svcaccounts-3238            pod-service-account-nomountsa-mountspec                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         67s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                755m (47%)  0 (0%)\n  memory             250Mi (7%)  0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
    Apr 23 12:07:20.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5091 describe namespace kubectl-5091'
    Apr 23 12:07:20.514: INFO: stderr: ""
    Apr 23 12:07:20.514: INFO: stdout: "Name:         kubectl-5091\nLabels:       e2e-framework=kubectl\n              e2e-run=1de117d5-5b32-4f50-b9f3-5af11d500051\n              kubernetes.io/metadata.name=kubectl-5091\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:07:20.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-5091" for this suite. 04/23/23 12:07:20.522
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:264
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:07:20.534
Apr 23 12:07:20.534: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 12:07:20.539
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:07:20.585
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:07:20.589
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 12:07:20.617
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:07:21.502
STEP: Deploying the webhook pod 04/23/23 12:07:21.517
STEP: Wait for the deployment to be ready 04/23/23 12:07:21.535
Apr 23 12:07:21.563: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 23 12:07:23.592: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 7, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 7, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 7, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 7, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/23/23 12:07:25.607
STEP: Verifying the service has paired with the endpoint 04/23/23 12:07:25.642
Apr 23 12:07:26.643: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:264
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 04/23/23 12:07:26.65
STEP: create a pod that should be updated by the webhook 04/23/23 12:07:26.702
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:07:26.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-7134" for this suite. 04/23/23 12:07:26.917
STEP: Destroying namespace "webhook-7134-markers" for this suite. 04/23/23 12:07:26.944
------------------------------
â€¢ [SLOW TEST] [6.521 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:264

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:07:20.534
    Apr 23 12:07:20.534: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 12:07:20.539
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:07:20.585
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:07:20.589
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 12:07:20.617
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:07:21.502
    STEP: Deploying the webhook pod 04/23/23 12:07:21.517
    STEP: Wait for the deployment to be ready 04/23/23 12:07:21.535
    Apr 23 12:07:21.563: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 23 12:07:23.592: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 7, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 7, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 7, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 7, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/23/23 12:07:25.607
    STEP: Verifying the service has paired with the endpoint 04/23/23 12:07:25.642
    Apr 23 12:07:26.643: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:264
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 04/23/23 12:07:26.65
    STEP: create a pod that should be updated by the webhook 04/23/23 12:07:26.702
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:07:26.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-7134" for this suite. 04/23/23 12:07:26.917
    STEP: Destroying namespace "webhook-7134-markers" for this suite. 04/23/23 12:07:26.944
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:97
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:07:27.066
Apr 23 12:07:27.066: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 12:07:27.07
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:07:27.191
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:07:27.204
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:97
STEP: Creating a pod to test emptydir 0644 on tmpfs 04/23/23 12:07:27.21
Apr 23 12:07:27.251: INFO: Waiting up to 5m0s for pod "pod-51c88d42-949d-4839-a8ef-12faf0770b08" in namespace "emptydir-2367" to be "Succeeded or Failed"
Apr 23 12:07:27.263: INFO: Pod "pod-51c88d42-949d-4839-a8ef-12faf0770b08": Phase="Pending", Reason="", readiness=false. Elapsed: 11.946822ms
Apr 23 12:07:29.272: INFO: Pod "pod-51c88d42-949d-4839-a8ef-12faf0770b08": Phase="Running", Reason="", readiness=true. Elapsed: 2.02134283s
Apr 23 12:07:31.273: INFO: Pod "pod-51c88d42-949d-4839-a8ef-12faf0770b08": Phase="Running", Reason="", readiness=false. Elapsed: 4.021552169s
Apr 23 12:07:33.274: INFO: Pod "pod-51c88d42-949d-4839-a8ef-12faf0770b08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022859922s
STEP: Saw pod success 04/23/23 12:07:33.274
Apr 23 12:07:33.274: INFO: Pod "pod-51c88d42-949d-4839-a8ef-12faf0770b08" satisfied condition "Succeeded or Failed"
Apr 23 12:07:33.280: INFO: Trying to get logs from node eingavuivie7-2 pod pod-51c88d42-949d-4839-a8ef-12faf0770b08 container test-container: <nil>
STEP: delete the pod 04/23/23 12:07:33.325
Apr 23 12:07:33.349: INFO: Waiting for pod pod-51c88d42-949d-4839-a8ef-12faf0770b08 to disappear
Apr 23 12:07:33.358: INFO: Pod pod-51c88d42-949d-4839-a8ef-12faf0770b08 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 12:07:33.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-2367" for this suite. 04/23/23 12:07:33.375
------------------------------
â€¢ [SLOW TEST] [6.329 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:07:27.066
    Apr 23 12:07:27.066: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 12:07:27.07
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:07:27.191
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:07:27.204
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:97
    STEP: Creating a pod to test emptydir 0644 on tmpfs 04/23/23 12:07:27.21
    Apr 23 12:07:27.251: INFO: Waiting up to 5m0s for pod "pod-51c88d42-949d-4839-a8ef-12faf0770b08" in namespace "emptydir-2367" to be "Succeeded or Failed"
    Apr 23 12:07:27.263: INFO: Pod "pod-51c88d42-949d-4839-a8ef-12faf0770b08": Phase="Pending", Reason="", readiness=false. Elapsed: 11.946822ms
    Apr 23 12:07:29.272: INFO: Pod "pod-51c88d42-949d-4839-a8ef-12faf0770b08": Phase="Running", Reason="", readiness=true. Elapsed: 2.02134283s
    Apr 23 12:07:31.273: INFO: Pod "pod-51c88d42-949d-4839-a8ef-12faf0770b08": Phase="Running", Reason="", readiness=false. Elapsed: 4.021552169s
    Apr 23 12:07:33.274: INFO: Pod "pod-51c88d42-949d-4839-a8ef-12faf0770b08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022859922s
    STEP: Saw pod success 04/23/23 12:07:33.274
    Apr 23 12:07:33.274: INFO: Pod "pod-51c88d42-949d-4839-a8ef-12faf0770b08" satisfied condition "Succeeded or Failed"
    Apr 23 12:07:33.280: INFO: Trying to get logs from node eingavuivie7-2 pod pod-51c88d42-949d-4839-a8ef-12faf0770b08 container test-container: <nil>
    STEP: delete the pod 04/23/23 12:07:33.325
    Apr 23 12:07:33.349: INFO: Waiting for pod pod-51c88d42-949d-4839-a8ef-12faf0770b08 to disappear
    Apr 23 12:07:33.358: INFO: Pod pod-51c88d42-949d-4839-a8ef-12faf0770b08 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:07:33.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-2367" for this suite. 04/23/23 12:07:33.375
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:215
[BeforeEach] [sig-storage] Projected secret
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:07:33.414
Apr 23 12:07:33.415: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 12:07:33.418
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:07:33.445
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:07:33.452
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:31
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:215
STEP: Creating secret with name s-test-opt-del-d8ef9e26-2ff0-402b-a7f2-da31ac7bf829 04/23/23 12:07:33.466
STEP: Creating secret with name s-test-opt-upd-ae595101-8eef-43c6-95c4-d67cfb6974bf 04/23/23 12:07:33.475
STEP: Creating the pod 04/23/23 12:07:33.497
Apr 23 12:07:33.528: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd" in namespace "projected-3160" to be "running and ready"
Apr 23 12:07:33.538: INFO: Pod "pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.914046ms
Apr 23 12:07:33.538: INFO: The phase of Pod pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:07:35.545: INFO: Pod "pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01690937s
Apr 23 12:07:35.545: INFO: The phase of Pod pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:07:37.547: INFO: Pod "pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd": Phase="Running", Reason="", readiness=true. Elapsed: 4.018556503s
Apr 23 12:07:37.547: INFO: The phase of Pod pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd is Running (Ready = true)
Apr 23 12:07:37.547: INFO: Pod "pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-d8ef9e26-2ff0-402b-a7f2-da31ac7bf829 04/23/23 12:07:37.704
STEP: Updating secret s-test-opt-upd-ae595101-8eef-43c6-95c4-d67cfb6974bf 04/23/23 12:07:37.723
STEP: Creating secret with name s-test-opt-create-708d2bdd-acd4-425c-8651-6629e8ba9904 04/23/23 12:07:37.735
STEP: waiting to observe update in volume 04/23/23 12:07:37.745
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/node/init/init.go:32
Apr 23 12:08:56.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected secret
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected secret
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-3160" for this suite. 04/23/23 12:08:56.762
------------------------------
â€¢ [SLOW TEST] [83.366 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:07:33.414
    Apr 23 12:07:33.415: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 12:07:33.418
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:07:33.445
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:07:33.452
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:31
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:215
    STEP: Creating secret with name s-test-opt-del-d8ef9e26-2ff0-402b-a7f2-da31ac7bf829 04/23/23 12:07:33.466
    STEP: Creating secret with name s-test-opt-upd-ae595101-8eef-43c6-95c4-d67cfb6974bf 04/23/23 12:07:33.475
    STEP: Creating the pod 04/23/23 12:07:33.497
    Apr 23 12:07:33.528: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd" in namespace "projected-3160" to be "running and ready"
    Apr 23 12:07:33.538: INFO: Pod "pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.914046ms
    Apr 23 12:07:33.538: INFO: The phase of Pod pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:07:35.545: INFO: Pod "pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01690937s
    Apr 23 12:07:35.545: INFO: The phase of Pod pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:07:37.547: INFO: Pod "pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd": Phase="Running", Reason="", readiness=true. Elapsed: 4.018556503s
    Apr 23 12:07:37.547: INFO: The phase of Pod pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd is Running (Ready = true)
    Apr 23 12:07:37.547: INFO: Pod "pod-projected-secrets-bcc754a6-cac7-4050-b810-ea1e9ca466dd" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-d8ef9e26-2ff0-402b-a7f2-da31ac7bf829 04/23/23 12:07:37.704
    STEP: Updating secret s-test-opt-upd-ae595101-8eef-43c6-95c4-d67cfb6974bf 04/23/23 12:07:37.723
    STEP: Creating secret with name s-test-opt-create-708d2bdd-acd4-425c-8651-6629e8ba9904 04/23/23 12:07:37.735
    STEP: waiting to observe update in volume 04/23/23 12:07:37.745
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:08:56.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected secret
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected secret
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-3160" for this suite. 04/23/23 12:08:56.762
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:08:56.788
Apr 23 12:08:56.789: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename dns 04/23/23 12:08:56.793
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:08:56.82
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:08:56.827
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 04/23/23 12:08:56.835
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-549 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-549;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-549 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-549;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-549.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-549.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-549.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-549.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-549.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-549.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-549.svc;check="$$(dig +notcp +noall +answer +search 223.6.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.6.223_udp@PTR;check="$$(dig +tcp +noall +answer +search 223.6.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.6.223_tcp@PTR;sleep 1; done
 04/23/23 12:08:56.892
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-549 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-549;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-549 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-549;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-549.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-549.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-549.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-549.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-549.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-549.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-549.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-549.svc;check="$$(dig +notcp +noall +answer +search 223.6.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.6.223_udp@PTR;check="$$(dig +tcp +noall +answer +search 223.6.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.6.223_tcp@PTR;sleep 1; done
 04/23/23 12:08:56.893
STEP: creating a pod to probe DNS 04/23/23 12:08:56.893
STEP: submitting the pod to kubernetes 04/23/23 12:08:56.893
Apr 23 12:08:56.918: INFO: Waiting up to 15m0s for pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f" in namespace "dns-549" to be "running"
Apr 23 12:08:56.932: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.412394ms
Apr 23 12:08:58.941: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022074071s
Apr 23 12:09:00.944: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02532588s
Apr 23 12:09:02.948: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.029708636s
Apr 23 12:09:04.946: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.027000425s
Apr 23 12:09:06.969: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.050932447s
Apr 23 12:09:08.959: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.040320116s
Apr 23 12:09:10.950: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.031145752s
Apr 23 12:09:12.943: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.024900397s
Apr 23 12:09:14.942: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.023840621s
Apr 23 12:09:16.941: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.022936203s
Apr 23 12:09:19.030: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.111409181s
Apr 23 12:09:20.941: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.022204538s
Apr 23 12:09:22.942: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.023623503s
Apr 23 12:09:24.944: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 28.025178888s
Apr 23 12:09:26.953: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 30.034483143s
Apr 23 12:09:28.944: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 32.025270155s
Apr 23 12:09:30.943: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 34.024514458s
Apr 23 12:09:32.952: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 36.033275515s
Apr 23 12:09:34.941: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 38.02233313s
Apr 23 12:09:36.952: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 40.033128133s
Apr 23 12:09:38.944: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 42.025143396s
Apr 23 12:09:40.954: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Running", Reason="", readiness=true. Elapsed: 44.035511948s
Apr 23 12:09:40.954: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f" satisfied condition "running"
STEP: retrieving the pod 04/23/23 12:09:40.955
STEP: looking for the results for each expected name from probers 04/23/23 12:09:40.969
Apr 23 12:09:41.073: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.091: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.190: INFO: Unable to read wheezy_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.201: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.229: INFO: Unable to read wheezy_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.238: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.258: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.294: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.411: INFO: Unable to read jessie_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.447: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.466: INFO: Unable to read jessie_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.474: INFO: Unable to read jessie_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.484: INFO: Unable to read jessie_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.496: INFO: Unable to read jessie_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.508: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.536: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.569: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.729: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:41.753: INFO: Lookups using dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-549 wheezy_tcp@dns-test-service.dns-549 wheezy_udp@dns-test-service.dns-549.svc wheezy_tcp@dns-test-service.dns-549.svc wheezy_udp@_http._tcp.dns-test-service.dns-549.svc wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-549 jessie_tcp@dns-test-service.dns-549 jessie_udp@dns-test-service.dns-549.svc jessie_tcp@dns-test-service.dns-549.svc jessie_udp@_http._tcp.dns-test-service.dns-549.svc jessie_tcp@_http._tcp.dns-test-service.dns-549.svc jessie_udp@_http._tcp.test-service-2.dns-549.svc jessie_tcp@_http._tcp.test-service-2.dns-549.svc]

Apr 23 12:09:46.772: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:46.786: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:46.798: INFO: Unable to read wheezy_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:46.808: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:46.826: INFO: Unable to read wheezy_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:46.836: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:46.848: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:46.877: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:46.937: INFO: Unable to read jessie_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:46.945: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:46.954: INFO: Unable to read jessie_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:46.963: INFO: Unable to read jessie_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:46.970: INFO: Unable to read jessie_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:46.981: INFO: Unable to read jessie_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:46.991: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:47.014: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:47.062: INFO: Lookups using dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-549 wheezy_tcp@dns-test-service.dns-549 wheezy_udp@dns-test-service.dns-549.svc wheezy_tcp@dns-test-service.dns-549.svc wheezy_udp@_http._tcp.dns-test-service.dns-549.svc wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-549 jessie_tcp@dns-test-service.dns-549 jessie_udp@dns-test-service.dns-549.svc jessie_tcp@dns-test-service.dns-549.svc jessie_udp@_http._tcp.dns-test-service.dns-549.svc jessie_tcp@_http._tcp.dns-test-service.dns-549.svc]

Apr 23 12:09:51.771: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:51.786: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:51.802: INFO: Unable to read wheezy_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:51.817: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:51.826: INFO: Unable to read wheezy_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:51.836: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:51.849: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:51.862: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:51.953: INFO: Unable to read jessie_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:51.971: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:51.988: INFO: Unable to read jessie_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:51.999: INFO: Unable to read jessie_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:52.012: INFO: Unable to read jessie_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:52.026: INFO: Unable to read jessie_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:52.038: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:52.046: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:52.080: INFO: Lookups using dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-549 wheezy_tcp@dns-test-service.dns-549 wheezy_udp@dns-test-service.dns-549.svc wheezy_tcp@dns-test-service.dns-549.svc wheezy_udp@_http._tcp.dns-test-service.dns-549.svc wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-549 jessie_tcp@dns-test-service.dns-549 jessie_udp@dns-test-service.dns-549.svc jessie_tcp@dns-test-service.dns-549.svc jessie_udp@_http._tcp.dns-test-service.dns-549.svc jessie_tcp@_http._tcp.dns-test-service.dns-549.svc]

Apr 23 12:09:56.765: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.776: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.785: INFO: Unable to read wheezy_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.799: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.817: INFO: Unable to read wheezy_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.827: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.838: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.846: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.893: INFO: Unable to read jessie_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.901: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.914: INFO: Unable to read jessie_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.924: INFO: Unable to read jessie_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.932: INFO: Unable to read jessie_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.940: INFO: Unable to read jessie_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.948: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:56.957: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
Apr 23 12:09:57.023: INFO: Lookups using dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-549 wheezy_tcp@dns-test-service.dns-549 wheezy_udp@dns-test-service.dns-549.svc wheezy_tcp@dns-test-service.dns-549.svc wheezy_udp@_http._tcp.dns-test-service.dns-549.svc wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-549 jessie_tcp@dns-test-service.dns-549 jessie_udp@dns-test-service.dns-549.svc jessie_tcp@dns-test-service.dns-549.svc jessie_udp@_http._tcp.dns-test-service.dns-549.svc jessie_tcp@_http._tcp.dns-test-service.dns-549.svc]

Apr 23 12:10:01.966: INFO: DNS probes using dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f succeeded

STEP: deleting the pod 04/23/23 12:10:01.966
STEP: deleting the test service 04/23/23 12:10:02.01
STEP: deleting the test headless service 04/23/23 12:10:02.201
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Apr 23 12:10:02.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-549" for this suite. 04/23/23 12:10:02.269
------------------------------
â€¢ [SLOW TEST] [65.504 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:08:56.788
    Apr 23 12:08:56.789: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename dns 04/23/23 12:08:56.793
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:08:56.82
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:08:56.827
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 04/23/23 12:08:56.835
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-549 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-549;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-549 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-549;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-549.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-549.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-549.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-549.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-549.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-549.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-549.svc;check="$$(dig +notcp +noall +answer +search 223.6.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.6.223_udp@PTR;check="$$(dig +tcp +noall +answer +search 223.6.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.6.223_tcp@PTR;sleep 1; done
     04/23/23 12:08:56.892
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-549 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-549;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-549 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-549;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-549.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-549.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-549.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-549.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-549.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-549.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-549.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-549.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-549.svc;check="$$(dig +notcp +noall +answer +search 223.6.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.6.223_udp@PTR;check="$$(dig +tcp +noall +answer +search 223.6.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.6.223_tcp@PTR;sleep 1; done
     04/23/23 12:08:56.893
    STEP: creating a pod to probe DNS 04/23/23 12:08:56.893
    STEP: submitting the pod to kubernetes 04/23/23 12:08:56.893
    Apr 23 12:08:56.918: INFO: Waiting up to 15m0s for pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f" in namespace "dns-549" to be "running"
    Apr 23 12:08:56.932: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.412394ms
    Apr 23 12:08:58.941: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022074071s
    Apr 23 12:09:00.944: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02532588s
    Apr 23 12:09:02.948: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.029708636s
    Apr 23 12:09:04.946: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.027000425s
    Apr 23 12:09:06.969: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.050932447s
    Apr 23 12:09:08.959: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.040320116s
    Apr 23 12:09:10.950: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.031145752s
    Apr 23 12:09:12.943: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.024900397s
    Apr 23 12:09:14.942: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.023840621s
    Apr 23 12:09:16.941: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.022936203s
    Apr 23 12:09:19.030: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.111409181s
    Apr 23 12:09:20.941: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.022204538s
    Apr 23 12:09:22.942: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.023623503s
    Apr 23 12:09:24.944: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 28.025178888s
    Apr 23 12:09:26.953: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 30.034483143s
    Apr 23 12:09:28.944: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 32.025270155s
    Apr 23 12:09:30.943: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 34.024514458s
    Apr 23 12:09:32.952: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 36.033275515s
    Apr 23 12:09:34.941: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 38.02233313s
    Apr 23 12:09:36.952: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 40.033128133s
    Apr 23 12:09:38.944: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Pending", Reason="", readiness=false. Elapsed: 42.025143396s
    Apr 23 12:09:40.954: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f": Phase="Running", Reason="", readiness=true. Elapsed: 44.035511948s
    Apr 23 12:09:40.954: INFO: Pod "dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f" satisfied condition "running"
    STEP: retrieving the pod 04/23/23 12:09:40.955
    STEP: looking for the results for each expected name from probers 04/23/23 12:09:40.969
    Apr 23 12:09:41.073: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.091: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.190: INFO: Unable to read wheezy_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.201: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.229: INFO: Unable to read wheezy_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.238: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.258: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.294: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.411: INFO: Unable to read jessie_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.447: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.466: INFO: Unable to read jessie_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.474: INFO: Unable to read jessie_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.484: INFO: Unable to read jessie_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.496: INFO: Unable to read jessie_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.508: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.536: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.569: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.729: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:41.753: INFO: Lookups using dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-549 wheezy_tcp@dns-test-service.dns-549 wheezy_udp@dns-test-service.dns-549.svc wheezy_tcp@dns-test-service.dns-549.svc wheezy_udp@_http._tcp.dns-test-service.dns-549.svc wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-549 jessie_tcp@dns-test-service.dns-549 jessie_udp@dns-test-service.dns-549.svc jessie_tcp@dns-test-service.dns-549.svc jessie_udp@_http._tcp.dns-test-service.dns-549.svc jessie_tcp@_http._tcp.dns-test-service.dns-549.svc jessie_udp@_http._tcp.test-service-2.dns-549.svc jessie_tcp@_http._tcp.test-service-2.dns-549.svc]

    Apr 23 12:09:46.772: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:46.786: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:46.798: INFO: Unable to read wheezy_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:46.808: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:46.826: INFO: Unable to read wheezy_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:46.836: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:46.848: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:46.877: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:46.937: INFO: Unable to read jessie_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:46.945: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:46.954: INFO: Unable to read jessie_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:46.963: INFO: Unable to read jessie_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:46.970: INFO: Unable to read jessie_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:46.981: INFO: Unable to read jessie_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:46.991: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:47.014: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:47.062: INFO: Lookups using dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-549 wheezy_tcp@dns-test-service.dns-549 wheezy_udp@dns-test-service.dns-549.svc wheezy_tcp@dns-test-service.dns-549.svc wheezy_udp@_http._tcp.dns-test-service.dns-549.svc wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-549 jessie_tcp@dns-test-service.dns-549 jessie_udp@dns-test-service.dns-549.svc jessie_tcp@dns-test-service.dns-549.svc jessie_udp@_http._tcp.dns-test-service.dns-549.svc jessie_tcp@_http._tcp.dns-test-service.dns-549.svc]

    Apr 23 12:09:51.771: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:51.786: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:51.802: INFO: Unable to read wheezy_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:51.817: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:51.826: INFO: Unable to read wheezy_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:51.836: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:51.849: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:51.862: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:51.953: INFO: Unable to read jessie_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:51.971: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:51.988: INFO: Unable to read jessie_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:51.999: INFO: Unable to read jessie_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:52.012: INFO: Unable to read jessie_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:52.026: INFO: Unable to read jessie_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:52.038: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:52.046: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:52.080: INFO: Lookups using dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-549 wheezy_tcp@dns-test-service.dns-549 wheezy_udp@dns-test-service.dns-549.svc wheezy_tcp@dns-test-service.dns-549.svc wheezy_udp@_http._tcp.dns-test-service.dns-549.svc wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-549 jessie_tcp@dns-test-service.dns-549 jessie_udp@dns-test-service.dns-549.svc jessie_tcp@dns-test-service.dns-549.svc jessie_udp@_http._tcp.dns-test-service.dns-549.svc jessie_tcp@_http._tcp.dns-test-service.dns-549.svc]

    Apr 23 12:09:56.765: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.776: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.785: INFO: Unable to read wheezy_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.799: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.817: INFO: Unable to read wheezy_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.827: INFO: Unable to read wheezy_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.838: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.846: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.893: INFO: Unable to read jessie_udp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.901: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.914: INFO: Unable to read jessie_udp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.924: INFO: Unable to read jessie_tcp@dns-test-service.dns-549 from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.932: INFO: Unable to read jessie_udp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.940: INFO: Unable to read jessie_tcp@dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.948: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:56.957: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-549.svc from pod dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f: the server could not find the requested resource (get pods dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f)
    Apr 23 12:09:57.023: INFO: Lookups using dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-549 wheezy_tcp@dns-test-service.dns-549 wheezy_udp@dns-test-service.dns-549.svc wheezy_tcp@dns-test-service.dns-549.svc wheezy_udp@_http._tcp.dns-test-service.dns-549.svc wheezy_tcp@_http._tcp.dns-test-service.dns-549.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-549 jessie_tcp@dns-test-service.dns-549 jessie_udp@dns-test-service.dns-549.svc jessie_tcp@dns-test-service.dns-549.svc jessie_udp@_http._tcp.dns-test-service.dns-549.svc jessie_tcp@_http._tcp.dns-test-service.dns-549.svc]

    Apr 23 12:10:01.966: INFO: DNS probes using dns-549/dns-test-fb47729e-94bc-4c71-9a19-8f56d182996f succeeded

    STEP: deleting the pod 04/23/23 12:10:01.966
    STEP: deleting the test service 04/23/23 12:10:02.01
    STEP: deleting the test headless service 04/23/23 12:10:02.201
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:10:02.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-549" for this suite. 04/23/23 12:10:02.269
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:221
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:10:02.297
Apr 23 12:10:02.298: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 12:10:02.301
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:10:02.374
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:10:02.384
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:221
STEP: Creating a pod to test downward API volume plugin 04/23/23 12:10:02.392
Apr 23 12:10:02.435: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e" in namespace "downward-api-2623" to be "Succeeded or Failed"
Apr 23 12:10:02.453: INFO: Pod "downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e": Phase="Pending", Reason="", readiness=false. Elapsed: 18.048764ms
Apr 23 12:10:04.461: INFO: Pod "downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026523738s
Apr 23 12:10:06.462: INFO: Pod "downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026821204s
STEP: Saw pod success 04/23/23 12:10:06.462
Apr 23 12:10:06.463: INFO: Pod "downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e" satisfied condition "Succeeded or Failed"
Apr 23 12:10:06.472: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e container client-container: <nil>
STEP: delete the pod 04/23/23 12:10:06.489
Apr 23 12:10:06.518: INFO: Waiting for pod downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e to disappear
Apr 23 12:10:06.522: INFO: Pod downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Apr 23 12:10:06.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-2623" for this suite. 04/23/23 12:10:06.531
------------------------------
â€¢ [4.246 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:10:02.297
    Apr 23 12:10:02.298: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 12:10:02.301
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:10:02.374
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:10:02.384
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:221
    STEP: Creating a pod to test downward API volume plugin 04/23/23 12:10:02.392
    Apr 23 12:10:02.435: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e" in namespace "downward-api-2623" to be "Succeeded or Failed"
    Apr 23 12:10:02.453: INFO: Pod "downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e": Phase="Pending", Reason="", readiness=false. Elapsed: 18.048764ms
    Apr 23 12:10:04.461: INFO: Pod "downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026523738s
    Apr 23 12:10:06.462: INFO: Pod "downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026821204s
    STEP: Saw pod success 04/23/23 12:10:06.462
    Apr 23 12:10:06.463: INFO: Pod "downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e" satisfied condition "Succeeded or Failed"
    Apr 23 12:10:06.472: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e container client-container: <nil>
    STEP: delete the pod 04/23/23 12:10:06.489
    Apr 23 12:10:06.518: INFO: Waiting for pod downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e to disappear
    Apr 23 12:10:06.522: INFO: Pod downwardapi-volume-6026119d-d4b2-4e0c-b454-da7cc903319e no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:10:06.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-2623" for this suite. 04/23/23 12:10:06.531
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes
  should support CSIVolumeSource in Pod API [Conformance]
  test/e2e/storage/csi_inline.go:131
[BeforeEach] [sig-storage] CSIInlineVolumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:10:06.558
Apr 23 12:10:06.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename csiinlinevolumes 04/23/23 12:10:06.561
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:10:06.602
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:10:06.61
[BeforeEach] [sig-storage] CSIInlineVolumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support CSIVolumeSource in Pod API [Conformance]
  test/e2e/storage/csi_inline.go:131
STEP: creating 04/23/23 12:10:06.616
STEP: getting 04/23/23 12:10:06.669
STEP: listing in namespace 04/23/23 12:10:06.676
STEP: patching 04/23/23 12:10:06.685
STEP: deleting 04/23/23 12:10:06.706
[AfterEach] [sig-storage] CSIInlineVolumes
  test/e2e/framework/node/init/init.go:32
Apr 23 12:10:06.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
  tear down framework | framework.go:193
STEP: Destroying namespace "csiinlinevolumes-1802" for this suite. 04/23/23 12:10:06.738
------------------------------
â€¢ [0.192 seconds]
[sig-storage] CSIInlineVolumes
test/e2e/storage/utils/framework.go:23
  should support CSIVolumeSource in Pod API [Conformance]
  test/e2e/storage/csi_inline.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIInlineVolumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:10:06.558
    Apr 23 12:10:06.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename csiinlinevolumes 04/23/23 12:10:06.561
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:10:06.602
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:10:06.61
    [BeforeEach] [sig-storage] CSIInlineVolumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support CSIVolumeSource in Pod API [Conformance]
      test/e2e/storage/csi_inline.go:131
    STEP: creating 04/23/23 12:10:06.616
    STEP: getting 04/23/23 12:10:06.669
    STEP: listing in namespace 04/23/23 12:10:06.676
    STEP: patching 04/23/23 12:10:06.685
    STEP: deleting 04/23/23 12:10:06.706
    [AfterEach] [sig-storage] CSIInlineVolumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:10:06.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "csiinlinevolumes-1802" for this suite. 04/23/23 12:10:06.738
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes
  should support ephemeral VolumeLifecycleMode in CSIDriver API [Conformance]
  test/e2e/storage/csi_inline.go:46
[BeforeEach] [sig-storage] CSIInlineVolumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:10:06.755
Apr 23 12:10:06.755: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename csiinlinevolumes 04/23/23 12:10:06.757
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:10:06.797
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:10:06.802
[BeforeEach] [sig-storage] CSIInlineVolumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support ephemeral VolumeLifecycleMode in CSIDriver API [Conformance]
  test/e2e/storage/csi_inline.go:46
STEP: creating 04/23/23 12:10:06.809
STEP: getting 04/23/23 12:10:06.843
STEP: listing 04/23/23 12:10:06.857
STEP: deleting 04/23/23 12:10:06.867
[AfterEach] [sig-storage] CSIInlineVolumes
  test/e2e/framework/node/init/init.go:32
Apr 23 12:10:06.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
  tear down framework | framework.go:193
STEP: Destroying namespace "csiinlinevolumes-9421" for this suite. 04/23/23 12:10:06.922
------------------------------
â€¢ [0.180 seconds]
[sig-storage] CSIInlineVolumes
test/e2e/storage/utils/framework.go:23
  should support ephemeral VolumeLifecycleMode in CSIDriver API [Conformance]
  test/e2e/storage/csi_inline.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIInlineVolumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:10:06.755
    Apr 23 12:10:06.755: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename csiinlinevolumes 04/23/23 12:10:06.757
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:10:06.797
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:10:06.802
    [BeforeEach] [sig-storage] CSIInlineVolumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support ephemeral VolumeLifecycleMode in CSIDriver API [Conformance]
      test/e2e/storage/csi_inline.go:46
    STEP: creating 04/23/23 12:10:06.809
    STEP: getting 04/23/23 12:10:06.843
    STEP: listing 04/23/23 12:10:06.857
    STEP: deleting 04/23/23 12:10:06.867
    [AfterEach] [sig-storage] CSIInlineVolumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:10:06.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] CSIInlineVolumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "csiinlinevolumes-9421" for this suite. 04/23/23 12:10:06.922
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:848
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:10:06.942
Apr 23 12:10:06.942: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 12:10:06.944
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:10:06.966
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:10:06.971
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:848
STEP: creating service multi-endpoint-test in namespace services-8224 04/23/23 12:10:06.977
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8224 to expose endpoints map[] 04/23/23 12:10:06.998
Apr 23 12:10:07.028: INFO: successfully validated that service multi-endpoint-test in namespace services-8224 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-8224 04/23/23 12:10:07.028
Apr 23 12:10:07.053: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-8224" to be "running and ready"
Apr 23 12:10:07.080: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 26.639755ms
Apr 23 12:10:07.080: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:10:09.094: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040492473s
Apr 23 12:10:09.094: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:10:11.089: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.035875341s
Apr 23 12:10:11.090: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 23 12:10:11.090: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8224 to expose endpoints map[pod1:[100]] 04/23/23 12:10:11.096
Apr 23 12:10:11.121: INFO: successfully validated that service multi-endpoint-test in namespace services-8224 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-8224 04/23/23 12:10:11.122
Apr 23 12:10:11.134: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-8224" to be "running and ready"
Apr 23 12:10:11.170: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 35.740654ms
Apr 23 12:10:11.170: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:10:13.179: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044825329s
Apr 23 12:10:13.179: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:10:15.177: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.043310871s
Apr 23 12:10:15.178: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 23 12:10:15.178: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8224 to expose endpoints map[pod1:[100] pod2:[101]] 04/23/23 12:10:15.185
Apr 23 12:10:15.232: INFO: successfully validated that service multi-endpoint-test in namespace services-8224 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 04/23/23 12:10:15.233
Apr 23 12:10:15.233: INFO: Creating new exec pod
Apr 23 12:10:15.244: INFO: Waiting up to 5m0s for pod "execpod464xw" in namespace "services-8224" to be "running"
Apr 23 12:10:15.254: INFO: Pod "execpod464xw": Phase="Pending", Reason="", readiness=false. Elapsed: 9.180543ms
Apr 23 12:10:17.263: INFO: Pod "execpod464xw": Phase="Running", Reason="", readiness=true. Elapsed: 2.018802024s
Apr 23 12:10:17.263: INFO: Pod "execpod464xw" satisfied condition "running"
Apr 23 12:10:18.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-8224 exec execpod464xw -- /bin/sh -x -c nc -v -z -w 2 multi-endpoint-test 80'
Apr 23 12:10:18.640: INFO: stderr: "+ nc -v -z -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Apr 23 12:10:18.640: INFO: stdout: ""
Apr 23 12:10:18.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-8224 exec execpod464xw -- /bin/sh -x -c nc -v -z -w 2 10.233.43.13 80'
Apr 23 12:10:18.890: INFO: stderr: "+ nc -v -z -w 2 10.233.43.13 80\nConnection to 10.233.43.13 80 port [tcp/http] succeeded!\n"
Apr 23 12:10:18.890: INFO: stdout: ""
Apr 23 12:10:18.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-8224 exec execpod464xw -- /bin/sh -x -c nc -v -z -w 2 multi-endpoint-test 81'
Apr 23 12:10:19.173: INFO: stderr: "+ nc -v -z -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Apr 23 12:10:19.173: INFO: stdout: ""
Apr 23 12:10:19.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-8224 exec execpod464xw -- /bin/sh -x -c nc -v -z -w 2 10.233.43.13 81'
Apr 23 12:10:19.755: INFO: stderr: "+ nc -v -z -w 2 10.233.43.13 81\nConnection to 10.233.43.13 81 port [tcp/*] succeeded!\n"
Apr 23 12:10:19.755: INFO: stdout: ""
STEP: Deleting pod pod1 in namespace services-8224 04/23/23 12:10:19.755
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8224 to expose endpoints map[pod2:[101]] 04/23/23 12:10:19.793
Apr 23 12:10:19.844: INFO: successfully validated that service multi-endpoint-test in namespace services-8224 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-8224 04/23/23 12:10:19.844
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8224 to expose endpoints map[] 04/23/23 12:10:19.983
Apr 23 12:10:20.053: INFO: successfully validated that service multi-endpoint-test in namespace services-8224 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 12:10:20.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-8224" for this suite. 04/23/23 12:10:20.156
------------------------------
â€¢ [SLOW TEST] [13.251 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:848

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:10:06.942
    Apr 23 12:10:06.942: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 12:10:06.944
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:10:06.966
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:10:06.971
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:848
    STEP: creating service multi-endpoint-test in namespace services-8224 04/23/23 12:10:06.977
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8224 to expose endpoints map[] 04/23/23 12:10:06.998
    Apr 23 12:10:07.028: INFO: successfully validated that service multi-endpoint-test in namespace services-8224 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-8224 04/23/23 12:10:07.028
    Apr 23 12:10:07.053: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-8224" to be "running and ready"
    Apr 23 12:10:07.080: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 26.639755ms
    Apr 23 12:10:07.080: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:10:09.094: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040492473s
    Apr 23 12:10:09.094: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:10:11.089: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.035875341s
    Apr 23 12:10:11.090: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 23 12:10:11.090: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8224 to expose endpoints map[pod1:[100]] 04/23/23 12:10:11.096
    Apr 23 12:10:11.121: INFO: successfully validated that service multi-endpoint-test in namespace services-8224 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-8224 04/23/23 12:10:11.122
    Apr 23 12:10:11.134: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-8224" to be "running and ready"
    Apr 23 12:10:11.170: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 35.740654ms
    Apr 23 12:10:11.170: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:10:13.179: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044825329s
    Apr 23 12:10:13.179: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:10:15.177: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.043310871s
    Apr 23 12:10:15.178: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 23 12:10:15.178: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8224 to expose endpoints map[pod1:[100] pod2:[101]] 04/23/23 12:10:15.185
    Apr 23 12:10:15.232: INFO: successfully validated that service multi-endpoint-test in namespace services-8224 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 04/23/23 12:10:15.233
    Apr 23 12:10:15.233: INFO: Creating new exec pod
    Apr 23 12:10:15.244: INFO: Waiting up to 5m0s for pod "execpod464xw" in namespace "services-8224" to be "running"
    Apr 23 12:10:15.254: INFO: Pod "execpod464xw": Phase="Pending", Reason="", readiness=false. Elapsed: 9.180543ms
    Apr 23 12:10:17.263: INFO: Pod "execpod464xw": Phase="Running", Reason="", readiness=true. Elapsed: 2.018802024s
    Apr 23 12:10:17.263: INFO: Pod "execpod464xw" satisfied condition "running"
    Apr 23 12:10:18.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-8224 exec execpod464xw -- /bin/sh -x -c nc -v -z -w 2 multi-endpoint-test 80'
    Apr 23 12:10:18.640: INFO: stderr: "+ nc -v -z -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Apr 23 12:10:18.640: INFO: stdout: ""
    Apr 23 12:10:18.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-8224 exec execpod464xw -- /bin/sh -x -c nc -v -z -w 2 10.233.43.13 80'
    Apr 23 12:10:18.890: INFO: stderr: "+ nc -v -z -w 2 10.233.43.13 80\nConnection to 10.233.43.13 80 port [tcp/http] succeeded!\n"
    Apr 23 12:10:18.890: INFO: stdout: ""
    Apr 23 12:10:18.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-8224 exec execpod464xw -- /bin/sh -x -c nc -v -z -w 2 multi-endpoint-test 81'
    Apr 23 12:10:19.173: INFO: stderr: "+ nc -v -z -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Apr 23 12:10:19.173: INFO: stdout: ""
    Apr 23 12:10:19.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-8224 exec execpod464xw -- /bin/sh -x -c nc -v -z -w 2 10.233.43.13 81'
    Apr 23 12:10:19.755: INFO: stderr: "+ nc -v -z -w 2 10.233.43.13 81\nConnection to 10.233.43.13 81 port [tcp/*] succeeded!\n"
    Apr 23 12:10:19.755: INFO: stdout: ""
    STEP: Deleting pod pod1 in namespace services-8224 04/23/23 12:10:19.755
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8224 to expose endpoints map[pod2:[101]] 04/23/23 12:10:19.793
    Apr 23 12:10:19.844: INFO: successfully validated that service multi-endpoint-test in namespace services-8224 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-8224 04/23/23 12:10:19.844
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8224 to expose endpoints map[] 04/23/23 12:10:19.983
    Apr 23 12:10:20.053: INFO: successfully validated that service multi-endpoint-test in namespace services-8224 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:10:20.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-8224" for this suite. 04/23/23 12:10:20.156
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:455
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:10:20.197
Apr 23 12:10:20.197: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename taint-multiple-pods 04/23/23 12:10:20.204
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:10:20.243
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:10:20.249
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:383
Apr 23 12:10:20.258: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 23 12:11:20.342: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:455
Apr 23 12:11:20.353: INFO: Starting informer...
STEP: Starting pods... 04/23/23 12:11:20.354
Apr 23 12:11:20.598: INFO: Pod1 is running on eingavuivie7-3. Tainting Node
Apr 23 12:11:20.824: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-5556" to be "running"
Apr 23 12:11:20.834: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.856287ms
Apr 23 12:11:22.850: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025229885s
Apr 23 12:11:24.846: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 4.021178283s
Apr 23 12:11:24.846: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Apr 23 12:11:24.846: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-5556" to be "running"
Apr 23 12:11:24.859: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 12.677516ms
Apr 23 12:11:24.859: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Apr 23 12:11:24.859: INFO: Pod2 is running on eingavuivie7-3. Tainting Node
STEP: Trying to apply a taint on the Node 04/23/23 12:11:24.859
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/23/23 12:11:24.905
STEP: Waiting for Pod1 and Pod2 to be deleted 04/23/23 12:11:24.93
Apr 23 12:11:30.985: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Apr 23 12:11:51.062: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/23/23 12:11:51.132
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:11:51.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "taint-multiple-pods-5556" for this suite. 04/23/23 12:11:51.167
------------------------------
â€¢ [SLOW TEST] [90.984 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:455

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:10:20.197
    Apr 23 12:10:20.197: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename taint-multiple-pods 04/23/23 12:10:20.204
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:10:20.243
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:10:20.249
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:383
    Apr 23 12:10:20.258: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 23 12:11:20.342: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:455
    Apr 23 12:11:20.353: INFO: Starting informer...
    STEP: Starting pods... 04/23/23 12:11:20.354
    Apr 23 12:11:20.598: INFO: Pod1 is running on eingavuivie7-3. Tainting Node
    Apr 23 12:11:20.824: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-5556" to be "running"
    Apr 23 12:11:20.834: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.856287ms
    Apr 23 12:11:22.850: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025229885s
    Apr 23 12:11:24.846: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 4.021178283s
    Apr 23 12:11:24.846: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Apr 23 12:11:24.846: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-5556" to be "running"
    Apr 23 12:11:24.859: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 12.677516ms
    Apr 23 12:11:24.859: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Apr 23 12:11:24.859: INFO: Pod2 is running on eingavuivie7-3. Tainting Node
    STEP: Trying to apply a taint on the Node 04/23/23 12:11:24.859
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/23/23 12:11:24.905
    STEP: Waiting for Pod1 and Pod2 to be deleted 04/23/23 12:11:24.93
    Apr 23 12:11:30.985: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Apr 23 12:11:51.062: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/23/23 12:11:51.132
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:11:51.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "taint-multiple-pods-5556" for this suite. 04/23/23 12:11:51.167
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:57
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:11:51.189
Apr 23 12:11:51.189: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename secrets 04/23/23 12:11:51.196
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:11:51.234
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:11:51.239
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:57
STEP: Creating secret with name secret-test-11cf33b0-f91c-438f-b08f-f2d7fc744744 04/23/23 12:11:51.246
STEP: Creating a pod to test consume secrets 04/23/23 12:11:51.257
Apr 23 12:11:51.278: INFO: Waiting up to 5m0s for pod "pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651" in namespace "secrets-2287" to be "Succeeded or Failed"
Apr 23 12:11:51.289: INFO: Pod "pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651": Phase="Pending", Reason="", readiness=false. Elapsed: 10.787054ms
Apr 23 12:11:53.296: INFO: Pod "pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017872241s
Apr 23 12:11:55.298: INFO: Pod "pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019739935s
STEP: Saw pod success 04/23/23 12:11:55.298
Apr 23 12:11:55.299: INFO: Pod "pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651" satisfied condition "Succeeded or Failed"
Apr 23 12:11:55.306: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651 container secret-volume-test: <nil>
STEP: delete the pod 04/23/23 12:11:55.34
Apr 23 12:11:55.362: INFO: Waiting for pod pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651 to disappear
Apr 23 12:11:55.369: INFO: Pod pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Apr 23 12:11:55.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-2287" for this suite. 04/23/23 12:11:55.38
------------------------------
â€¢ [4.213 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:11:51.189
    Apr 23 12:11:51.189: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename secrets 04/23/23 12:11:51.196
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:11:51.234
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:11:51.239
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:57
    STEP: Creating secret with name secret-test-11cf33b0-f91c-438f-b08f-f2d7fc744744 04/23/23 12:11:51.246
    STEP: Creating a pod to test consume secrets 04/23/23 12:11:51.257
    Apr 23 12:11:51.278: INFO: Waiting up to 5m0s for pod "pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651" in namespace "secrets-2287" to be "Succeeded or Failed"
    Apr 23 12:11:51.289: INFO: Pod "pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651": Phase="Pending", Reason="", readiness=false. Elapsed: 10.787054ms
    Apr 23 12:11:53.296: INFO: Pod "pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017872241s
    Apr 23 12:11:55.298: INFO: Pod "pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019739935s
    STEP: Saw pod success 04/23/23 12:11:55.298
    Apr 23 12:11:55.299: INFO: Pod "pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651" satisfied condition "Succeeded or Failed"
    Apr 23 12:11:55.306: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651 container secret-volume-test: <nil>
    STEP: delete the pod 04/23/23 12:11:55.34
    Apr 23 12:11:55.362: INFO: Waiting for pod pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651 to disappear
    Apr 23 12:11:55.369: INFO: Pod pod-secrets-c412f38f-8d6f-42dc-9e5b-0b4055676651 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:11:55.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-2287" for this suite. 04/23/23 12:11:55.38
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:309
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:11:55.41
Apr 23 12:11:55.411: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 12:11:55.415
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:11:55.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:11:55.457
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:309
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 04/23/23 12:11:55.467
Apr 23 12:11:55.470: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 04/23/23 12:12:05.585
Apr 23 12:12:05.586: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:12:08.234: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:12:20.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-9767" for this suite. 04/23/23 12:12:20.437
------------------------------
â€¢ [SLOW TEST] [25.103 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:11:55.41
    Apr 23 12:11:55.411: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 12:11:55.415
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:11:55.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:11:55.457
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:309
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 04/23/23 12:11:55.467
    Apr 23 12:11:55.470: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 04/23/23 12:12:05.585
    Apr 23 12:12:05.586: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:12:08.234: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:12:20.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-9767" for this suite. 04/23/23 12:12:20.437
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:352
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:12:20.519
Apr 23 12:12:20.519: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 12:12:20.534
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:12:20.593
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:12:20.602
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:326
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:352
STEP: creating a replication controller 04/23/23 12:12:20.616
Apr 23 12:12:20.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 create -f -'
Apr 23 12:12:22.221: INFO: stderr: ""
Apr 23 12:12:22.221: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/23/23 12:12:22.221
Apr 23 12:12:22.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 23 12:12:22.466: INFO: stderr: ""
Apr 23 12:12:22.466: INFO: stdout: "update-demo-nautilus-25lq2 update-demo-nautilus-8q7wk "
Apr 23 12:12:22.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 23 12:12:22.735: INFO: stderr: ""
Apr 23 12:12:22.735: INFO: stdout: ""
Apr 23 12:12:22.735: INFO: update-demo-nautilus-25lq2 is created but not running
Apr 23 12:12:27.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 23 12:12:28.004: INFO: stderr: ""
Apr 23 12:12:28.004: INFO: stdout: "update-demo-nautilus-25lq2 update-demo-nautilus-8q7wk "
Apr 23 12:12:28.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 23 12:12:28.196: INFO: stderr: ""
Apr 23 12:12:28.196: INFO: stdout: "true"
Apr 23 12:12:28.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 23 12:12:28.400: INFO: stderr: ""
Apr 23 12:12:28.400: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Apr 23 12:12:28.400: INFO: validating pod update-demo-nautilus-25lq2
Apr 23 12:12:28.430: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 12:12:28.431: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 12:12:28.431: INFO: update-demo-nautilus-25lq2 is verified up and running
Apr 23 12:12:28.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-8q7wk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 23 12:12:28.643: INFO: stderr: ""
Apr 23 12:12:28.643: INFO: stdout: "true"
Apr 23 12:12:28.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-8q7wk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 23 12:12:28.807: INFO: stderr: ""
Apr 23 12:12:28.807: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Apr 23 12:12:28.807: INFO: validating pod update-demo-nautilus-8q7wk
Apr 23 12:12:28.826: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 12:12:28.826: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 12:12:28.826: INFO: update-demo-nautilus-8q7wk is verified up and running
STEP: scaling down the replication controller 04/23/23 12:12:28.827
Apr 23 12:12:28.847: INFO: scanned /root for discovery docs: <nil>
Apr 23 12:12:28.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Apr 23 12:12:30.136: INFO: stderr: ""
Apr 23 12:12:30.136: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/23/23 12:12:30.136
Apr 23 12:12:30.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 23 12:12:30.427: INFO: stderr: ""
Apr 23 12:12:30.427: INFO: stdout: "update-demo-nautilus-25lq2 "
Apr 23 12:12:30.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 23 12:12:30.668: INFO: stderr: ""
Apr 23 12:12:30.668: INFO: stdout: "true"
Apr 23 12:12:30.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 23 12:12:30.832: INFO: stderr: ""
Apr 23 12:12:30.832: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Apr 23 12:12:30.832: INFO: validating pod update-demo-nautilus-25lq2
Apr 23 12:12:30.843: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 12:12:30.843: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 12:12:30.843: INFO: update-demo-nautilus-25lq2 is verified up and running
STEP: scaling up the replication controller 04/23/23 12:12:30.843
Apr 23 12:12:30.858: INFO: scanned /root for discovery docs: <nil>
Apr 23 12:12:30.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Apr 23 12:12:32.248: INFO: stderr: ""
Apr 23 12:12:32.248: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/23/23 12:12:32.248
Apr 23 12:12:32.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 23 12:12:32.734: INFO: stderr: ""
Apr 23 12:12:32.735: INFO: stdout: "update-demo-nautilus-25lq2 update-demo-nautilus-7tsps "
Apr 23 12:12:32.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 23 12:12:32.918: INFO: stderr: ""
Apr 23 12:12:32.919: INFO: stdout: "true"
Apr 23 12:12:32.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 23 12:12:33.051: INFO: stderr: ""
Apr 23 12:12:33.051: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Apr 23 12:12:33.051: INFO: validating pod update-demo-nautilus-25lq2
Apr 23 12:12:33.061: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 12:12:33.061: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 12:12:33.061: INFO: update-demo-nautilus-25lq2 is verified up and running
Apr 23 12:12:33.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-7tsps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 23 12:12:33.214: INFO: stderr: ""
Apr 23 12:12:33.214: INFO: stdout: ""
Apr 23 12:12:33.214: INFO: update-demo-nautilus-7tsps is created but not running
Apr 23 12:12:38.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 23 12:12:38.464: INFO: stderr: ""
Apr 23 12:12:38.464: INFO: stdout: "update-demo-nautilus-25lq2 update-demo-nautilus-7tsps "
Apr 23 12:12:38.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 23 12:12:38.625: INFO: stderr: ""
Apr 23 12:12:38.625: INFO: stdout: "true"
Apr 23 12:12:38.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 23 12:12:38.784: INFO: stderr: ""
Apr 23 12:12:38.784: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Apr 23 12:12:38.784: INFO: validating pod update-demo-nautilus-25lq2
Apr 23 12:12:38.797: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 12:12:38.797: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 12:12:38.797: INFO: update-demo-nautilus-25lq2 is verified up and running
Apr 23 12:12:38.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-7tsps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 23 12:12:39.011: INFO: stderr: ""
Apr 23 12:12:39.011: INFO: stdout: "true"
Apr 23 12:12:39.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-7tsps -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 23 12:12:39.163: INFO: stderr: ""
Apr 23 12:12:39.164: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
Apr 23 12:12:39.164: INFO: validating pod update-demo-nautilus-7tsps
Apr 23 12:12:39.181: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 23 12:12:39.181: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 23 12:12:39.181: INFO: update-demo-nautilus-7tsps is verified up and running
STEP: using delete to clean up resources 04/23/23 12:12:39.181
Apr 23 12:12:39.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 delete --grace-period=0 --force -f -'
Apr 23 12:12:39.336: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 12:12:39.336: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 23 12:12:39.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get rc,svc -l name=update-demo --no-headers'
Apr 23 12:12:39.678: INFO: stderr: "No resources found in kubectl-741 namespace.\n"
Apr 23 12:12:39.678: INFO: stdout: ""
Apr 23 12:12:39.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 23 12:12:39.958: INFO: stderr: ""
Apr 23 12:12:39.958: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 12:12:39.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-741" for this suite. 04/23/23 12:12:39.98
------------------------------
â€¢ [SLOW TEST] [19.480 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:324
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:12:20.519
    Apr 23 12:12:20.519: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 12:12:20.534
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:12:20.593
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:12:20.602
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:326
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:352
    STEP: creating a replication controller 04/23/23 12:12:20.616
    Apr 23 12:12:20.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 create -f -'
    Apr 23 12:12:22.221: INFO: stderr: ""
    Apr 23 12:12:22.221: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/23/23 12:12:22.221
    Apr 23 12:12:22.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 23 12:12:22.466: INFO: stderr: ""
    Apr 23 12:12:22.466: INFO: stdout: "update-demo-nautilus-25lq2 update-demo-nautilus-8q7wk "
    Apr 23 12:12:22.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 23 12:12:22.735: INFO: stderr: ""
    Apr 23 12:12:22.735: INFO: stdout: ""
    Apr 23 12:12:22.735: INFO: update-demo-nautilus-25lq2 is created but not running
    Apr 23 12:12:27.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 23 12:12:28.004: INFO: stderr: ""
    Apr 23 12:12:28.004: INFO: stdout: "update-demo-nautilus-25lq2 update-demo-nautilus-8q7wk "
    Apr 23 12:12:28.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 23 12:12:28.196: INFO: stderr: ""
    Apr 23 12:12:28.196: INFO: stdout: "true"
    Apr 23 12:12:28.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 23 12:12:28.400: INFO: stderr: ""
    Apr 23 12:12:28.400: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Apr 23 12:12:28.400: INFO: validating pod update-demo-nautilus-25lq2
    Apr 23 12:12:28.430: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 23 12:12:28.431: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 23 12:12:28.431: INFO: update-demo-nautilus-25lq2 is verified up and running
    Apr 23 12:12:28.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-8q7wk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 23 12:12:28.643: INFO: stderr: ""
    Apr 23 12:12:28.643: INFO: stdout: "true"
    Apr 23 12:12:28.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-8q7wk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 23 12:12:28.807: INFO: stderr: ""
    Apr 23 12:12:28.807: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Apr 23 12:12:28.807: INFO: validating pod update-demo-nautilus-8q7wk
    Apr 23 12:12:28.826: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 23 12:12:28.826: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 23 12:12:28.826: INFO: update-demo-nautilus-8q7wk is verified up and running
    STEP: scaling down the replication controller 04/23/23 12:12:28.827
    Apr 23 12:12:28.847: INFO: scanned /root for discovery docs: <nil>
    Apr 23 12:12:28.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Apr 23 12:12:30.136: INFO: stderr: ""
    Apr 23 12:12:30.136: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/23/23 12:12:30.136
    Apr 23 12:12:30.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 23 12:12:30.427: INFO: stderr: ""
    Apr 23 12:12:30.427: INFO: stdout: "update-demo-nautilus-25lq2 "
    Apr 23 12:12:30.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 23 12:12:30.668: INFO: stderr: ""
    Apr 23 12:12:30.668: INFO: stdout: "true"
    Apr 23 12:12:30.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 23 12:12:30.832: INFO: stderr: ""
    Apr 23 12:12:30.832: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Apr 23 12:12:30.832: INFO: validating pod update-demo-nautilus-25lq2
    Apr 23 12:12:30.843: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 23 12:12:30.843: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 23 12:12:30.843: INFO: update-demo-nautilus-25lq2 is verified up and running
    STEP: scaling up the replication controller 04/23/23 12:12:30.843
    Apr 23 12:12:30.858: INFO: scanned /root for discovery docs: <nil>
    Apr 23 12:12:30.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Apr 23 12:12:32.248: INFO: stderr: ""
    Apr 23 12:12:32.248: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/23/23 12:12:32.248
    Apr 23 12:12:32.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 23 12:12:32.734: INFO: stderr: ""
    Apr 23 12:12:32.735: INFO: stdout: "update-demo-nautilus-25lq2 update-demo-nautilus-7tsps "
    Apr 23 12:12:32.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 23 12:12:32.918: INFO: stderr: ""
    Apr 23 12:12:32.919: INFO: stdout: "true"
    Apr 23 12:12:32.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 23 12:12:33.051: INFO: stderr: ""
    Apr 23 12:12:33.051: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Apr 23 12:12:33.051: INFO: validating pod update-demo-nautilus-25lq2
    Apr 23 12:12:33.061: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 23 12:12:33.061: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 23 12:12:33.061: INFO: update-demo-nautilus-25lq2 is verified up and running
    Apr 23 12:12:33.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-7tsps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 23 12:12:33.214: INFO: stderr: ""
    Apr 23 12:12:33.214: INFO: stdout: ""
    Apr 23 12:12:33.214: INFO: update-demo-nautilus-7tsps is created but not running
    Apr 23 12:12:38.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 23 12:12:38.464: INFO: stderr: ""
    Apr 23 12:12:38.464: INFO: stdout: "update-demo-nautilus-25lq2 update-demo-nautilus-7tsps "
    Apr 23 12:12:38.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 23 12:12:38.625: INFO: stderr: ""
    Apr 23 12:12:38.625: INFO: stdout: "true"
    Apr 23 12:12:38.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-25lq2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 23 12:12:38.784: INFO: stderr: ""
    Apr 23 12:12:38.784: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Apr 23 12:12:38.784: INFO: validating pod update-demo-nautilus-25lq2
    Apr 23 12:12:38.797: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 23 12:12:38.797: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 23 12:12:38.797: INFO: update-demo-nautilus-25lq2 is verified up and running
    Apr 23 12:12:38.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-7tsps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 23 12:12:39.011: INFO: stderr: ""
    Apr 23 12:12:39.011: INFO: stdout: "true"
    Apr 23 12:12:39.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods update-demo-nautilus-7tsps -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 23 12:12:39.163: INFO: stderr: ""
    Apr 23 12:12:39.164: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
    Apr 23 12:12:39.164: INFO: validating pod update-demo-nautilus-7tsps
    Apr 23 12:12:39.181: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 23 12:12:39.181: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 23 12:12:39.181: INFO: update-demo-nautilus-7tsps is verified up and running
    STEP: using delete to clean up resources 04/23/23 12:12:39.181
    Apr 23 12:12:39.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 delete --grace-period=0 --force -f -'
    Apr 23 12:12:39.336: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 23 12:12:39.336: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Apr 23 12:12:39.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get rc,svc -l name=update-demo --no-headers'
    Apr 23 12:12:39.678: INFO: stderr: "No resources found in kubectl-741 namespace.\n"
    Apr 23 12:12:39.678: INFO: stdout: ""
    Apr 23 12:12:39.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-741 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 23 12:12:39.958: INFO: stderr: ""
    Apr 23 12:12:39.958: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:12:39.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-741" for this suite. 04/23/23 12:12:39.98
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:209
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:12:40.008
Apr 23 12:12:40.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 12:12:40.011
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:12:40.053
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:12:40.061
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 12:12:40.109
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:12:41.361
STEP: Deploying the webhook pod 04/23/23 12:12:41.381
STEP: Wait for the deployment to be ready 04/23/23 12:12:41.415
Apr 23 12:12:41.450: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 23 12:12:43.498: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 12, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 12, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 12, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 12, 41, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/23/23 12:12:45.506
STEP: Verifying the service has paired with the endpoint 04/23/23 12:12:45.551
Apr 23 12:12:46.553: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:209
STEP: Registering the webhook via the AdmissionRegistration API 04/23/23 12:12:46.566
STEP: create a pod 04/23/23 12:12:46.636
Apr 23 12:12:46.649: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-494" to be "running"
Apr 23 12:12:46.659: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 9.697235ms
Apr 23 12:12:48.668: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.019071605s
Apr 23 12:12:48.668: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 04/23/23 12:12:48.668
Apr 23 12:12:48.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=webhook-494 attach --namespace=webhook-494 to-be-attached-pod -i -c=container1'
Apr 23 12:12:48.860: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:12:48.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-494" for this suite. 04/23/23 12:12:49.128
STEP: Destroying namespace "webhook-494-markers" for this suite. 04/23/23 12:12:49.142
------------------------------
â€¢ [SLOW TEST] [9.162 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:209

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:12:40.008
    Apr 23 12:12:40.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 12:12:40.011
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:12:40.053
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:12:40.061
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 12:12:40.109
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:12:41.361
    STEP: Deploying the webhook pod 04/23/23 12:12:41.381
    STEP: Wait for the deployment to be ready 04/23/23 12:12:41.415
    Apr 23 12:12:41.450: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 23 12:12:43.498: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 12, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 12, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 12, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 12, 41, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/23/23 12:12:45.506
    STEP: Verifying the service has paired with the endpoint 04/23/23 12:12:45.551
    Apr 23 12:12:46.553: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:209
    STEP: Registering the webhook via the AdmissionRegistration API 04/23/23 12:12:46.566
    STEP: create a pod 04/23/23 12:12:46.636
    Apr 23 12:12:46.649: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-494" to be "running"
    Apr 23 12:12:46.659: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 9.697235ms
    Apr 23 12:12:48.668: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.019071605s
    Apr 23 12:12:48.668: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 04/23/23 12:12:48.668
    Apr 23 12:12:48.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=webhook-494 attach --namespace=webhook-494 to-be-attached-pod -i -c=container1'
    Apr 23 12:12:48.860: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:12:48.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-494" for this suite. 04/23/23 12:12:49.128
    STEP: Destroying namespace "webhook-494-markers" for this suite. 04/23/23 12:12:49.142
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:12:49.172
Apr 23 12:12:49.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubelet-test 04/23/23 12:12:49.193
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:12:49.231
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:12:49.238
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Apr 23 12:12:49.267: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsf4708c7c-7e38-42bc-ac8b-5da1fec338a0" in namespace "kubelet-test-8638" to be "running and ready"
Apr 23 12:12:49.273: INFO: Pod "busybox-readonly-fsf4708c7c-7e38-42bc-ac8b-5da1fec338a0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.279968ms
Apr 23 12:12:49.275: INFO: The phase of Pod busybox-readonly-fsf4708c7c-7e38-42bc-ac8b-5da1fec338a0 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:12:51.283: INFO: Pod "busybox-readonly-fsf4708c7c-7e38-42bc-ac8b-5da1fec338a0": Phase="Running", Reason="", readiness=true. Elapsed: 2.016475782s
Apr 23 12:12:51.284: INFO: The phase of Pod busybox-readonly-fsf4708c7c-7e38-42bc-ac8b-5da1fec338a0 is Running (Ready = true)
Apr 23 12:12:51.284: INFO: Pod "busybox-readonly-fsf4708c7c-7e38-42bc-ac8b-5da1fec338a0" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/node/init/init.go:32
Apr 23 12:12:51.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Kubelet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Kubelet
  tear down framework | framework.go:193
STEP: Destroying namespace "kubelet-test-8638" for this suite. 04/23/23 12:12:51.321
------------------------------
â€¢ [2.163 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:12:49.172
    Apr 23 12:12:49.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubelet-test 04/23/23 12:12:49.193
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:12:49.231
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:12:49.238
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Apr 23 12:12:49.267: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsf4708c7c-7e38-42bc-ac8b-5da1fec338a0" in namespace "kubelet-test-8638" to be "running and ready"
    Apr 23 12:12:49.273: INFO: Pod "busybox-readonly-fsf4708c7c-7e38-42bc-ac8b-5da1fec338a0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.279968ms
    Apr 23 12:12:49.275: INFO: The phase of Pod busybox-readonly-fsf4708c7c-7e38-42bc-ac8b-5da1fec338a0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:12:51.283: INFO: Pod "busybox-readonly-fsf4708c7c-7e38-42bc-ac8b-5da1fec338a0": Phase="Running", Reason="", readiness=true. Elapsed: 2.016475782s
    Apr 23 12:12:51.284: INFO: The phase of Pod busybox-readonly-fsf4708c7c-7e38-42bc-ac8b-5da1fec338a0 is Running (Ready = true)
    Apr 23 12:12:51.284: INFO: Pod "busybox-readonly-fsf4708c7c-7e38-42bc-ac8b-5da1fec338a0" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:12:51.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Kubelet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Kubelet
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubelet-test-8638" for this suite. 04/23/23 12:12:51.321
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:293
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:12:51.339
Apr 23 12:12:51.339: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename taint-single-pod 04/23/23 12:12:51.347
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:12:51.381
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:12:51.392
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:170
Apr 23 12:12:51.398: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 23 12:13:51.450: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:293
Apr 23 12:13:51.491: INFO: Starting informer...
STEP: Starting pod... 04/23/23 12:13:51.492
Apr 23 12:13:51.729: INFO: Pod is running on eingavuivie7-3. Tainting Node
STEP: Trying to apply a taint on the Node 04/23/23 12:13:51.729
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/23/23 12:13:51.774
STEP: Waiting short time to make sure Pod is queued for deletion 04/23/23 12:13:51.783
Apr 23 12:13:51.784: INFO: Pod wasn't evicted. Proceeding
Apr 23 12:13:51.784: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/23/23 12:13:51.813
STEP: Waiting some time to make sure that toleration time passed. 04/23/23 12:13:51.822
Apr 23 12:15:06.824: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:15:06.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "taint-single-pod-3579" for this suite. 04/23/23 12:15:06.84
------------------------------
â€¢ [SLOW TEST] [135.515 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:12:51.339
    Apr 23 12:12:51.339: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename taint-single-pod 04/23/23 12:12:51.347
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:12:51.381
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:12:51.392
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:170
    Apr 23 12:12:51.398: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 23 12:13:51.450: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:293
    Apr 23 12:13:51.491: INFO: Starting informer...
    STEP: Starting pod... 04/23/23 12:13:51.492
    Apr 23 12:13:51.729: INFO: Pod is running on eingavuivie7-3. Tainting Node
    STEP: Trying to apply a taint on the Node 04/23/23 12:13:51.729
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/23/23 12:13:51.774
    STEP: Waiting short time to make sure Pod is queued for deletion 04/23/23 12:13:51.783
    Apr 23 12:13:51.784: INFO: Pod wasn't evicted. Proceeding
    Apr 23 12:13:51.784: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/23/23 12:13:51.813
    STEP: Waiting some time to make sure that toleration time passed. 04/23/23 12:13:51.822
    Apr 23 12:15:06.824: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:15:06.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "taint-single-pod-3579" for this suite. 04/23/23 12:15:06.84
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:164
[BeforeEach] [sig-node] Security Context
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:15:06.87
Apr 23 12:15:06.871: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename security-context 04/23/23 12:15:06.875
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:15:06.922
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:15:06.928
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:31
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:164
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/23/23 12:15:06.933
Apr 23 12:15:06.960: INFO: Waiting up to 5m0s for pod "security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce" in namespace "security-context-5178" to be "Succeeded or Failed"
Apr 23 12:15:06.971: INFO: Pod "security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce": Phase="Pending", Reason="", readiness=false. Elapsed: 10.845894ms
Apr 23 12:15:08.980: INFO: Pod "security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01982349s
Apr 23 12:15:10.981: INFO: Pod "security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020638042s
Apr 23 12:15:12.983: INFO: Pod "security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022565772s
STEP: Saw pod success 04/23/23 12:15:12.983
Apr 23 12:15:12.984: INFO: Pod "security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce" satisfied condition "Succeeded or Failed"
Apr 23 12:15:12.992: INFO: Trying to get logs from node eingavuivie7-3 pod security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce container test-container: <nil>
STEP: delete the pod 04/23/23 12:15:13.021
Apr 23 12:15:13.044: INFO: Waiting for pod security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce to disappear
Apr 23 12:15:13.050: INFO: Pod security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/node/init/init.go:32
Apr 23 12:15:13.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Security Context
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Security Context
  tear down framework | framework.go:193
STEP: Destroying namespace "security-context-5178" for this suite. 04/23/23 12:15:13.061
------------------------------
â€¢ [SLOW TEST] [6.208 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:164

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:15:06.87
    Apr 23 12:15:06.871: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename security-context 04/23/23 12:15:06.875
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:15:06.922
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:15:06.928
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:31
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:164
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/23/23 12:15:06.933
    Apr 23 12:15:06.960: INFO: Waiting up to 5m0s for pod "security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce" in namespace "security-context-5178" to be "Succeeded or Failed"
    Apr 23 12:15:06.971: INFO: Pod "security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce": Phase="Pending", Reason="", readiness=false. Elapsed: 10.845894ms
    Apr 23 12:15:08.980: INFO: Pod "security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01982349s
    Apr 23 12:15:10.981: INFO: Pod "security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020638042s
    Apr 23 12:15:12.983: INFO: Pod "security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022565772s
    STEP: Saw pod success 04/23/23 12:15:12.983
    Apr 23 12:15:12.984: INFO: Pod "security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce" satisfied condition "Succeeded or Failed"
    Apr 23 12:15:12.992: INFO: Trying to get logs from node eingavuivie7-3 pod security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce container test-container: <nil>
    STEP: delete the pod 04/23/23 12:15:13.021
    Apr 23 12:15:13.044: INFO: Waiting for pod security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce to disappear
    Apr 23 12:15:13.050: INFO: Pod security-context-b43ab3cb-e2d7-456a-8eac-185ddefb61ce no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:15:13.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Security Context
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Security Context
      tear down framework | framework.go:193
    STEP: Destroying namespace "security-context-5178" for this suite. 04/23/23 12:15:13.061
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:44
[BeforeEach] [sig-node] Downward API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:15:13.088
Apr 23 12:15:13.089: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 12:15:13.092
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:15:13.123
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:15:13.128
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:31
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:44
STEP: Creating a pod to test downward api env vars 04/23/23 12:15:13.135
Apr 23 12:15:13.172: INFO: Waiting up to 5m0s for pod "downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042" in namespace "downward-api-3942" to be "Succeeded or Failed"
Apr 23 12:15:13.188: INFO: Pod "downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042": Phase="Pending", Reason="", readiness=false. Elapsed: 15.108234ms
Apr 23 12:15:15.197: INFO: Pod "downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024091795s
Apr 23 12:15:17.195: INFO: Pod "downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022334141s
STEP: Saw pod success 04/23/23 12:15:17.195
Apr 23 12:15:17.195: INFO: Pod "downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042" satisfied condition "Succeeded or Failed"
Apr 23 12:15:17.202: INFO: Trying to get logs from node eingavuivie7-3 pod downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042 container dapi-container: <nil>
STEP: delete the pod 04/23/23 12:15:17.223
Apr 23 12:15:17.247: INFO: Waiting for pod downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042 to disappear
Apr 23 12:15:17.253: INFO: Pod downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/node/init/init.go:32
Apr 23 12:15:17.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Downward API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Downward API
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-3942" for this suite. 04/23/23 12:15:17.27
------------------------------
â€¢ [4.196 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:15:13.088
    Apr 23 12:15:13.089: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 12:15:13.092
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:15:13.123
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:15:13.128
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:44
    STEP: Creating a pod to test downward api env vars 04/23/23 12:15:13.135
    Apr 23 12:15:13.172: INFO: Waiting up to 5m0s for pod "downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042" in namespace "downward-api-3942" to be "Succeeded or Failed"
    Apr 23 12:15:13.188: INFO: Pod "downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042": Phase="Pending", Reason="", readiness=false. Elapsed: 15.108234ms
    Apr 23 12:15:15.197: INFO: Pod "downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024091795s
    Apr 23 12:15:17.195: INFO: Pod "downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022334141s
    STEP: Saw pod success 04/23/23 12:15:17.195
    Apr 23 12:15:17.195: INFO: Pod "downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042" satisfied condition "Succeeded or Failed"
    Apr 23 12:15:17.202: INFO: Trying to get logs from node eingavuivie7-3 pod downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042 container dapi-container: <nil>
    STEP: delete the pod 04/23/23 12:15:17.223
    Apr 23 12:15:17.247: INFO: Waiting for pod downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042 to disappear
    Apr 23 12:15:17.253: INFO: Pod downward-api-f07d488d-4ab7-4be6-88f8-cc6e9fb2e042 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:15:17.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Downward API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Downward API
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-3942" for this suite. 04/23/23 12:15:17.27
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:15:17.287
Apr 23 12:15:17.287: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename podtemplate 04/23/23 12:15:17.29
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:15:17.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:15:17.332
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/metrics/init/init.go:31
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 04/23/23 12:15:17.341
STEP: Replace a pod template 04/23/23 12:15:17.356
Apr 23 12:15:17.376: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/node/init/init.go:32
Apr 23 12:15:17.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] PodTemplates
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] PodTemplates
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] PodTemplates
  tear down framework | framework.go:193
STEP: Destroying namespace "podtemplate-7997" for this suite. 04/23/23 12:15:17.386
------------------------------
â€¢ [0.111 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:15:17.287
    Apr 23 12:15:17.287: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename podtemplate 04/23/23 12:15:17.29
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:15:17.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:15:17.332
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/metrics/init/init.go:31
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 04/23/23 12:15:17.341
    STEP: Replace a pod template 04/23/23 12:15:17.356
    Apr 23 12:15:17.376: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:15:17.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] PodTemplates
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] PodTemplates
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] PodTemplates
      tear down framework | framework.go:193
    STEP: Destroying namespace "podtemplate-7997" for this suite. 04/23/23 12:15:17.386
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply a finalizer to a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:394
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:15:17.398
Apr 23 12:15:17.399: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename namespaces 04/23/23 12:15:17.401
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:15:17.44
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:15:17.444
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:31
[It] should apply a finalizer to a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:394
STEP: Creating namespace "e2e-ns-xfr58" 04/23/23 12:15:17.451
Apr 23 12:15:17.478: INFO: Namespace "e2e-ns-xfr58-1513" has []v1.FinalizerName{"kubernetes"}
STEP: Adding e2e finalizer to namespace "e2e-ns-xfr58-1513" 04/23/23 12:15:17.478
Apr 23 12:15:17.514: INFO: Namespace "e2e-ns-xfr58-1513" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
STEP: Removing e2e finalizer from namespace "e2e-ns-xfr58-1513" 04/23/23 12:15:17.514
Apr 23 12:15:17.534: INFO: Namespace "e2e-ns-xfr58-1513" has []v1.FinalizerName{"kubernetes"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:15:17.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "namespaces-6831" for this suite. 04/23/23 12:15:17.541
STEP: Destroying namespace "e2e-ns-xfr58-1513" for this suite. 04/23/23 12:15:17.556
------------------------------
â€¢ [0.174 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply a finalizer to a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:394

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:15:17.398
    Apr 23 12:15:17.399: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename namespaces 04/23/23 12:15:17.401
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:15:17.44
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:15:17.444
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [It] should apply a finalizer to a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:394
    STEP: Creating namespace "e2e-ns-xfr58" 04/23/23 12:15:17.451
    Apr 23 12:15:17.478: INFO: Namespace "e2e-ns-xfr58-1513" has []v1.FinalizerName{"kubernetes"}
    STEP: Adding e2e finalizer to namespace "e2e-ns-xfr58-1513" 04/23/23 12:15:17.478
    Apr 23 12:15:17.514: INFO: Namespace "e2e-ns-xfr58-1513" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
    STEP: Removing e2e finalizer from namespace "e2e-ns-xfr58-1513" 04/23/23 12:15:17.514
    Apr 23 12:15:17.534: INFO: Namespace "e2e-ns-xfr58-1513" has []v1.FinalizerName{"kubernetes"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:15:17.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "namespaces-6831" for this suite. 04/23/23 12:15:17.541
    STEP: Destroying namespace "e2e-ns-xfr58-1513" for this suite. 04/23/23 12:15:17.556
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:15:17.578
Apr 23 12:15:17.578: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename cronjob 04/23/23 12:15:17.585
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:15:17.617
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:15:17.622
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:31
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 04/23/23 12:15:17.626
STEP: creating 04/23/23 12:15:17.626
STEP: getting 04/23/23 12:15:17.639
STEP: listing 04/23/23 12:15:17.645
STEP: watching 04/23/23 12:15:17.656
Apr 23 12:15:17.656: INFO: starting watch
STEP: cluster-wide listing 04/23/23 12:15:17.663
STEP: cluster-wide watching 04/23/23 12:15:17.669
Apr 23 12:15:17.670: INFO: starting watch
STEP: patching 04/23/23 12:15:17.672
STEP: updating 04/23/23 12:15:17.686
Apr 23 12:15:17.706: INFO: waiting for watch events with expected annotations
Apr 23 12:15:17.706: INFO: saw patched and updated annotations
STEP: patching /status 04/23/23 12:15:17.706
STEP: updating /status 04/23/23 12:15:17.721
STEP: get /status 04/23/23 12:15:17.738
STEP: deleting 04/23/23 12:15:17.754
STEP: deleting a collection 04/23/23 12:15:17.798
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/node/init/init.go:32
Apr 23 12:15:17.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] CronJob
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] CronJob
  tear down framework | framework.go:193
STEP: Destroying namespace "cronjob-8272" for this suite. 04/23/23 12:15:17.835
------------------------------
â€¢ [0.271 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:15:17.578
    Apr 23 12:15:17.578: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename cronjob 04/23/23 12:15:17.585
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:15:17.617
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:15:17.622
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:31
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 04/23/23 12:15:17.626
    STEP: creating 04/23/23 12:15:17.626
    STEP: getting 04/23/23 12:15:17.639
    STEP: listing 04/23/23 12:15:17.645
    STEP: watching 04/23/23 12:15:17.656
    Apr 23 12:15:17.656: INFO: starting watch
    STEP: cluster-wide listing 04/23/23 12:15:17.663
    STEP: cluster-wide watching 04/23/23 12:15:17.669
    Apr 23 12:15:17.670: INFO: starting watch
    STEP: patching 04/23/23 12:15:17.672
    STEP: updating 04/23/23 12:15:17.686
    Apr 23 12:15:17.706: INFO: waiting for watch events with expected annotations
    Apr 23 12:15:17.706: INFO: saw patched and updated annotations
    STEP: patching /status 04/23/23 12:15:17.706
    STEP: updating /status 04/23/23 12:15:17.721
    STEP: get /status 04/23/23 12:15:17.738
    STEP: deleting 04/23/23 12:15:17.754
    STEP: deleting a collection 04/23/23 12:15:17.798
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:15:17.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] CronJob
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] CronJob
      tear down framework | framework.go:193
    STEP: Destroying namespace "cronjob-8272" for this suite. 04/23/23 12:15:17.835
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:130
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:15:17.859
Apr 23 12:15:17.860: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename sched-preemption 04/23/23 12:15:17.866
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:15:17.909
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:15:17.916
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:97
Apr 23 12:15:17.959: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 23 12:16:18.030: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:130
STEP: Create pods that use 4/5 of node resources. 04/23/23 12:16:18.038
Apr 23 12:16:18.102: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr 23 12:16:18.139: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr 23 12:16:18.214: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr 23 12:16:18.250: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Apr 23 12:16:18.358: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Apr 23 12:16:18.416: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 04/23/23 12:16:18.416
Apr 23 12:16:18.417: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-9781" to be "running"
Apr 23 12:16:18.446: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 29.197174ms
Apr 23 12:16:20.453: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.035921766s
Apr 23 12:16:20.453: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Apr 23 12:16:20.453: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-9781" to be "running"
Apr 23 12:16:20.549: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 95.578754ms
Apr 23 12:16:20.549: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 23 12:16:20.549: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-9781" to be "running"
Apr 23 12:16:20.567: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 17.010379ms
Apr 23 12:16:20.567: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 23 12:16:20.567: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-9781" to be "running"
Apr 23 12:16:20.575: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.572003ms
Apr 23 12:16:20.576: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 23 12:16:20.576: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-9781" to be "running"
Apr 23 12:16:20.581: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 5.643143ms
Apr 23 12:16:22.589: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.013203066s
Apr 23 12:16:22.589: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 23 12:16:22.589: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-9781" to be "running"
Apr 23 12:16:22.595: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.990618ms
Apr 23 12:16:22.595: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 04/23/23 12:16:22.595
Apr 23 12:16:22.613: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-9781" to be "running"
Apr 23 12:16:22.638: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 24.934325ms
Apr 23 12:16:24.654: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040865856s
Apr 23 12:16:26.648: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.034414444s
Apr 23 12:16:26.648: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:16:26.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:84
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-preemption-9781" for this suite. 04/23/23 12:16:26.799
------------------------------
â€¢ [SLOW TEST] [68.954 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:15:17.859
    Apr 23 12:15:17.860: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename sched-preemption 04/23/23 12:15:17.866
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:15:17.909
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:15:17.916
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:97
    Apr 23 12:15:17.959: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 23 12:16:18.030: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:130
    STEP: Create pods that use 4/5 of node resources. 04/23/23 12:16:18.038
    Apr 23 12:16:18.102: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Apr 23 12:16:18.139: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Apr 23 12:16:18.214: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Apr 23 12:16:18.250: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Apr 23 12:16:18.358: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Apr 23 12:16:18.416: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 04/23/23 12:16:18.416
    Apr 23 12:16:18.417: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-9781" to be "running"
    Apr 23 12:16:18.446: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 29.197174ms
    Apr 23 12:16:20.453: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.035921766s
    Apr 23 12:16:20.453: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Apr 23 12:16:20.453: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-9781" to be "running"
    Apr 23 12:16:20.549: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 95.578754ms
    Apr 23 12:16:20.549: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 23 12:16:20.549: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-9781" to be "running"
    Apr 23 12:16:20.567: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 17.010379ms
    Apr 23 12:16:20.567: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 23 12:16:20.567: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-9781" to be "running"
    Apr 23 12:16:20.575: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.572003ms
    Apr 23 12:16:20.576: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 23 12:16:20.576: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-9781" to be "running"
    Apr 23 12:16:20.581: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 5.643143ms
    Apr 23 12:16:22.589: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.013203066s
    Apr 23 12:16:22.589: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 23 12:16:22.589: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-9781" to be "running"
    Apr 23 12:16:22.595: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.990618ms
    Apr 23 12:16:22.595: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 04/23/23 12:16:22.595
    Apr 23 12:16:22.613: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-9781" to be "running"
    Apr 23 12:16:22.638: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 24.934325ms
    Apr 23 12:16:24.654: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040865856s
    Apr 23 12:16:26.648: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.034414444s
    Apr 23 12:16:26.648: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:16:26.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:84
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-preemption-9781" for this suite. 04/23/23 12:16:26.799
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:221
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:16:26.825
Apr 23 12:16:26.826: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 12:16:26.83
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:16:26.87
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:16:26.879
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 12:16:26.93
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:16:28.135
STEP: Deploying the webhook pod 04/23/23 12:16:28.15
STEP: Wait for the deployment to be ready 04/23/23 12:16:28.176
Apr 23 12:16:28.192: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/23/23 12:16:30.214
STEP: Verifying the service has paired with the endpoint 04/23/23 12:16:30.233
Apr 23 12:16:31.234: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:221
Apr 23 12:16:31.245: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Registering the custom resource webhook via the AdmissionRegistration API 04/23/23 12:16:31.77
STEP: Creating a custom resource that should be denied by the webhook 04/23/23 12:16:31.82
STEP: Creating a custom resource whose deletion would be denied by the webhook 04/23/23 12:16:34.025
STEP: Updating the custom resource with disallowed data should be denied 04/23/23 12:16:34.045
STEP: Deleting the custom resource should be denied 04/23/23 12:16:34.108
STEP: Remove the offending key and value from the custom resource data 04/23/23 12:16:34.146
STEP: Deleting the updated custom resource should be successful 04/23/23 12:16:34.179
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:16:34.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-911" for this suite. 04/23/23 12:16:34.927
STEP: Destroying namespace "webhook-911-markers" for this suite. 04/23/23 12:16:34.96
------------------------------
â€¢ [SLOW TEST] [8.184 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:16:26.825
    Apr 23 12:16:26.826: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 12:16:26.83
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:16:26.87
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:16:26.879
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 12:16:26.93
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:16:28.135
    STEP: Deploying the webhook pod 04/23/23 12:16:28.15
    STEP: Wait for the deployment to be ready 04/23/23 12:16:28.176
    Apr 23 12:16:28.192: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/23/23 12:16:30.214
    STEP: Verifying the service has paired with the endpoint 04/23/23 12:16:30.233
    Apr 23 12:16:31.234: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:221
    Apr 23 12:16:31.245: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 04/23/23 12:16:31.77
    STEP: Creating a custom resource that should be denied by the webhook 04/23/23 12:16:31.82
    STEP: Creating a custom resource whose deletion would be denied by the webhook 04/23/23 12:16:34.025
    STEP: Updating the custom resource with disallowed data should be denied 04/23/23 12:16:34.045
    STEP: Deleting the custom resource should be denied 04/23/23 12:16:34.108
    STEP: Remove the offending key and value from the custom resource data 04/23/23 12:16:34.146
    STEP: Deleting the updated custom resource should be successful 04/23/23 12:16:34.179
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:16:34.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-911" for this suite. 04/23/23 12:16:34.927
    STEP: Destroying namespace "webhook-911-markers" for this suite. 04/23/23 12:16:34.96
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:366
[BeforeEach] [sig-apps] Job
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:16:35.013
Apr 23 12:16:35.013: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename job 04/23/23 12:16:35.018
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:16:35.095
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:16:35.116
[BeforeEach] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:31
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:366
STEP: Creating Indexed job 04/23/23 12:16:35.142
STEP: Ensuring job reaches completions 04/23/23 12:16:35.18
STEP: Ensuring pods with index for job exist 04/23/23 12:16:47.19
[AfterEach] [sig-apps] Job
  test/e2e/framework/node/init/init.go:32
Apr 23 12:16:47.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Job
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Job
  tear down framework | framework.go:193
STEP: Destroying namespace "job-8202" for this suite. 04/23/23 12:16:47.21
------------------------------
â€¢ [SLOW TEST] [12.209 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:366

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:16:35.013
    Apr 23 12:16:35.013: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename job 04/23/23 12:16:35.018
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:16:35.095
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:16:35.116
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:31
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:366
    STEP: Creating Indexed job 04/23/23 12:16:35.142
    STEP: Ensuring job reaches completions 04/23/23 12:16:35.18
    STEP: Ensuring pods with index for job exist 04/23/23 12:16:47.19
    [AfterEach] [sig-apps] Job
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:16:47.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Job
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Job
      tear down framework | framework.go:193
    STEP: Destroying namespace "job-8202" for this suite. 04/23/23 12:16:47.21
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:16:47.235
Apr 23 12:16:47.235: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename dns 04/23/23 12:16:47.237
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:16:47.28
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:16:47.286
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 04/23/23 12:16:47.293
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 04/23/23 12:16:47.293
STEP: creating a pod to probe DNS 04/23/23 12:16:47.294
STEP: submitting the pod to kubernetes 04/23/23 12:16:47.294
Apr 23 12:16:47.309: INFO: Waiting up to 15m0s for pod "dns-test-8115ec90-44da-43fb-adae-0758845b2aef" in namespace "dns-6258" to be "running"
Apr 23 12:16:47.318: INFO: Pod "dns-test-8115ec90-44da-43fb-adae-0758845b2aef": Phase="Pending", Reason="", readiness=false. Elapsed: 8.622268ms
Apr 23 12:16:49.326: INFO: Pod "dns-test-8115ec90-44da-43fb-adae-0758845b2aef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016631581s
Apr 23 12:16:51.327: INFO: Pod "dns-test-8115ec90-44da-43fb-adae-0758845b2aef": Phase="Running", Reason="", readiness=true. Elapsed: 4.017100454s
Apr 23 12:16:51.327: INFO: Pod "dns-test-8115ec90-44da-43fb-adae-0758845b2aef" satisfied condition "running"
STEP: retrieving the pod 04/23/23 12:16:51.327
STEP: looking for the results for each expected name from probers 04/23/23 12:16:51.335
Apr 23 12:16:51.394: INFO: DNS probes using dns-6258/dns-test-8115ec90-44da-43fb-adae-0758845b2aef succeeded

STEP: deleting the pod 04/23/23 12:16:51.395
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Apr 23 12:16:51.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-6258" for this suite. 04/23/23 12:16:51.443
------------------------------
â€¢ [4.230 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:16:47.235
    Apr 23 12:16:47.235: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename dns 04/23/23 12:16:47.237
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:16:47.28
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:16:47.286
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     04/23/23 12:16:47.293
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     04/23/23 12:16:47.293
    STEP: creating a pod to probe DNS 04/23/23 12:16:47.294
    STEP: submitting the pod to kubernetes 04/23/23 12:16:47.294
    Apr 23 12:16:47.309: INFO: Waiting up to 15m0s for pod "dns-test-8115ec90-44da-43fb-adae-0758845b2aef" in namespace "dns-6258" to be "running"
    Apr 23 12:16:47.318: INFO: Pod "dns-test-8115ec90-44da-43fb-adae-0758845b2aef": Phase="Pending", Reason="", readiness=false. Elapsed: 8.622268ms
    Apr 23 12:16:49.326: INFO: Pod "dns-test-8115ec90-44da-43fb-adae-0758845b2aef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016631581s
    Apr 23 12:16:51.327: INFO: Pod "dns-test-8115ec90-44da-43fb-adae-0758845b2aef": Phase="Running", Reason="", readiness=true. Elapsed: 4.017100454s
    Apr 23 12:16:51.327: INFO: Pod "dns-test-8115ec90-44da-43fb-adae-0758845b2aef" satisfied condition "running"
    STEP: retrieving the pod 04/23/23 12:16:51.327
    STEP: looking for the results for each expected name from probers 04/23/23 12:16:51.335
    Apr 23 12:16:51.394: INFO: DNS probes using dns-6258/dns-test-8115ec90-44da-43fb-adae-0758845b2aef succeeded

    STEP: deleting the pod 04/23/23 12:16:51.395
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:16:51.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-6258" for this suite. 04/23/23 12:16:51.443
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:66
[BeforeEach] [sig-network] EndpointSlice
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:16:51.465
Apr 23 12:16:51.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename endpointslice 04/23/23 12:16:51.469
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:16:51.532
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:16:51.54
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:52
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:66
Apr 23 12:16:51.577: INFO: Endpoints addresses: [192.168.121.130 192.168.121.214] , ports: [6443]
Apr 23 12:16:51.577: INFO: EndpointSlices addresses: [192.168.121.130 192.168.121.214] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/node/init/init.go:32
Apr 23 12:16:51.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] EndpointSlice
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] EndpointSlice
  tear down framework | framework.go:193
STEP: Destroying namespace "endpointslice-9079" for this suite. 04/23/23 12:16:51.608
------------------------------
â€¢ [0.154 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:16:51.465
    Apr 23 12:16:51.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename endpointslice 04/23/23 12:16:51.469
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:16:51.532
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:16:51.54
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:52
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:66
    Apr 23 12:16:51.577: INFO: Endpoints addresses: [192.168.121.130 192.168.121.214] , ports: [6443]
    Apr 23 12:16:51.577: INFO: EndpointSlices addresses: [192.168.121.130 192.168.121.214] , ports: [6443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:16:51.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      tear down framework | framework.go:193
    STEP: Destroying namespace "endpointslice-9079" for this suite. 04/23/23 12:16:51.608
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:99
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:16:51.623
Apr 23 12:16:51.624: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename secrets 04/23/23 12:16:51.627
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:16:51.669
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:16:51.68
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:99
STEP: Creating secret with name secret-test-b3447c88-d4ef-4412-a844-8629bc6b2551 04/23/23 12:16:51.734
STEP: Creating a pod to test consume secrets 04/23/23 12:16:51.742
Apr 23 12:16:51.755: INFO: Waiting up to 5m0s for pod "pod-secrets-1bd6be69-1300-469c-88b0-34af61749522" in namespace "secrets-1222" to be "Succeeded or Failed"
Apr 23 12:16:51.765: INFO: Pod "pod-secrets-1bd6be69-1300-469c-88b0-34af61749522": Phase="Pending", Reason="", readiness=false. Elapsed: 9.354598ms
Apr 23 12:16:53.774: INFO: Pod "pod-secrets-1bd6be69-1300-469c-88b0-34af61749522": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018603435s
Apr 23 12:16:55.776: INFO: Pod "pod-secrets-1bd6be69-1300-469c-88b0-34af61749522": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020478094s
Apr 23 12:16:57.780: INFO: Pod "pod-secrets-1bd6be69-1300-469c-88b0-34af61749522": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025060163s
STEP: Saw pod success 04/23/23 12:16:57.78
Apr 23 12:16:57.781: INFO: Pod "pod-secrets-1bd6be69-1300-469c-88b0-34af61749522" satisfied condition "Succeeded or Failed"
Apr 23 12:16:57.789: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-1bd6be69-1300-469c-88b0-34af61749522 container secret-volume-test: <nil>
STEP: delete the pod 04/23/23 12:16:57.825
Apr 23 12:16:57.852: INFO: Waiting for pod pod-secrets-1bd6be69-1300-469c-88b0-34af61749522 to disappear
Apr 23 12:16:57.857: INFO: Pod pod-secrets-1bd6be69-1300-469c-88b0-34af61749522 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Apr 23 12:16:57.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-1222" for this suite. 04/23/23 12:16:57.866
STEP: Destroying namespace "secret-namespace-4615" for this suite. 04/23/23 12:16:57.879
------------------------------
â€¢ [SLOW TEST] [6.270 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:99

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:16:51.623
    Apr 23 12:16:51.624: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename secrets 04/23/23 12:16:51.627
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:16:51.669
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:16:51.68
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:99
    STEP: Creating secret with name secret-test-b3447c88-d4ef-4412-a844-8629bc6b2551 04/23/23 12:16:51.734
    STEP: Creating a pod to test consume secrets 04/23/23 12:16:51.742
    Apr 23 12:16:51.755: INFO: Waiting up to 5m0s for pod "pod-secrets-1bd6be69-1300-469c-88b0-34af61749522" in namespace "secrets-1222" to be "Succeeded or Failed"
    Apr 23 12:16:51.765: INFO: Pod "pod-secrets-1bd6be69-1300-469c-88b0-34af61749522": Phase="Pending", Reason="", readiness=false. Elapsed: 9.354598ms
    Apr 23 12:16:53.774: INFO: Pod "pod-secrets-1bd6be69-1300-469c-88b0-34af61749522": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018603435s
    Apr 23 12:16:55.776: INFO: Pod "pod-secrets-1bd6be69-1300-469c-88b0-34af61749522": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020478094s
    Apr 23 12:16:57.780: INFO: Pod "pod-secrets-1bd6be69-1300-469c-88b0-34af61749522": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025060163s
    STEP: Saw pod success 04/23/23 12:16:57.78
    Apr 23 12:16:57.781: INFO: Pod "pod-secrets-1bd6be69-1300-469c-88b0-34af61749522" satisfied condition "Succeeded or Failed"
    Apr 23 12:16:57.789: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-1bd6be69-1300-469c-88b0-34af61749522 container secret-volume-test: <nil>
    STEP: delete the pod 04/23/23 12:16:57.825
    Apr 23 12:16:57.852: INFO: Waiting for pod pod-secrets-1bd6be69-1300-469c-88b0-34af61749522 to disappear
    Apr 23 12:16:57.857: INFO: Pod pod-secrets-1bd6be69-1300-469c-88b0-34af61749522 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:16:57.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-1222" for this suite. 04/23/23 12:16:57.866
    STEP: Destroying namespace "secret-namespace-4615" for this suite. 04/23/23 12:16:57.879
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:486
[BeforeEach] [sig-node] Security Context
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:16:57.894
Apr 23 12:16:57.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename security-context-test 04/23/23 12:16:57.903
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:16:57.96
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:16:57.965
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:50
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:486
Apr 23 12:16:57.990: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-3cff0e7e-4d1f-45dc-b6fd-0d52f75cbaa4" in namespace "security-context-test-5787" to be "Succeeded or Failed"
Apr 23 12:16:58.005: INFO: Pod "busybox-readonly-false-3cff0e7e-4d1f-45dc-b6fd-0d52f75cbaa4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.162511ms
Apr 23 12:17:00.017: INFO: Pod "busybox-readonly-false-3cff0e7e-4d1f-45dc-b6fd-0d52f75cbaa4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026719902s
Apr 23 12:17:02.018: INFO: Pod "busybox-readonly-false-3cff0e7e-4d1f-45dc-b6fd-0d52f75cbaa4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028352301s
Apr 23 12:17:02.018: INFO: Pod "busybox-readonly-false-3cff0e7e-4d1f-45dc-b6fd-0d52f75cbaa4" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/node/init/init.go:32
Apr 23 12:17:02.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Security Context
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Security Context
  tear down framework | framework.go:193
STEP: Destroying namespace "security-context-test-5787" for this suite. 04/23/23 12:17:02.041
------------------------------
â€¢ [4.174 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:430
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:486

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:16:57.894
    Apr 23 12:16:57.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename security-context-test 04/23/23 12:16:57.903
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:16:57.96
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:16:57.965
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:50
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:486
    Apr 23 12:16:57.990: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-3cff0e7e-4d1f-45dc-b6fd-0d52f75cbaa4" in namespace "security-context-test-5787" to be "Succeeded or Failed"
    Apr 23 12:16:58.005: INFO: Pod "busybox-readonly-false-3cff0e7e-4d1f-45dc-b6fd-0d52f75cbaa4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.162511ms
    Apr 23 12:17:00.017: INFO: Pod "busybox-readonly-false-3cff0e7e-4d1f-45dc-b6fd-0d52f75cbaa4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026719902s
    Apr 23 12:17:02.018: INFO: Pod "busybox-readonly-false-3cff0e7e-4d1f-45dc-b6fd-0d52f75cbaa4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028352301s
    Apr 23 12:17:02.018: INFO: Pod "busybox-readonly-false-3cff0e7e-4d1f-45dc-b6fd-0d52f75cbaa4" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:17:02.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Security Context
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Security Context
      tear down framework | framework.go:193
    STEP: Destroying namespace "security-context-test-5787" for this suite. 04/23/23 12:17:02.041
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:130
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:17:02.076
Apr 23 12:17:02.076: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 12:17:02.082
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:17:02.121
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:17:02.13
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:130
STEP: Creating the pod 04/23/23 12:17:02.134
Apr 23 12:17:02.150: INFO: Waiting up to 5m0s for pod "labelsupdate16626816-e92c-46cf-987a-c702608d12fe" in namespace "downward-api-339" to be "running and ready"
Apr 23 12:17:02.175: INFO: Pod "labelsupdate16626816-e92c-46cf-987a-c702608d12fe": Phase="Pending", Reason="", readiness=false. Elapsed: 24.837457ms
Apr 23 12:17:02.176: INFO: The phase of Pod labelsupdate16626816-e92c-46cf-987a-c702608d12fe is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:17:04.186: INFO: Pod "labelsupdate16626816-e92c-46cf-987a-c702608d12fe": Phase="Running", Reason="", readiness=true. Elapsed: 2.035126199s
Apr 23 12:17:04.186: INFO: The phase of Pod labelsupdate16626816-e92c-46cf-987a-c702608d12fe is Running (Ready = true)
Apr 23 12:17:04.186: INFO: Pod "labelsupdate16626816-e92c-46cf-987a-c702608d12fe" satisfied condition "running and ready"
Apr 23 12:17:04.731: INFO: Successfully updated pod "labelsupdate16626816-e92c-46cf-987a-c702608d12fe"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Apr 23 12:17:06.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-339" for this suite. 04/23/23 12:17:06.77
------------------------------
â€¢ [4.704 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:17:02.076
    Apr 23 12:17:02.076: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 12:17:02.082
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:17:02.121
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:17:02.13
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:130
    STEP: Creating the pod 04/23/23 12:17:02.134
    Apr 23 12:17:02.150: INFO: Waiting up to 5m0s for pod "labelsupdate16626816-e92c-46cf-987a-c702608d12fe" in namespace "downward-api-339" to be "running and ready"
    Apr 23 12:17:02.175: INFO: Pod "labelsupdate16626816-e92c-46cf-987a-c702608d12fe": Phase="Pending", Reason="", readiness=false. Elapsed: 24.837457ms
    Apr 23 12:17:02.176: INFO: The phase of Pod labelsupdate16626816-e92c-46cf-987a-c702608d12fe is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:17:04.186: INFO: Pod "labelsupdate16626816-e92c-46cf-987a-c702608d12fe": Phase="Running", Reason="", readiness=true. Elapsed: 2.035126199s
    Apr 23 12:17:04.186: INFO: The phase of Pod labelsupdate16626816-e92c-46cf-987a-c702608d12fe is Running (Ready = true)
    Apr 23 12:17:04.186: INFO: Pod "labelsupdate16626816-e92c-46cf-987a-c702608d12fe" satisfied condition "running and ready"
    Apr 23 12:17:04.731: INFO: Successfully updated pod "labelsupdate16626816-e92c-46cf-987a-c702608d12fe"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:17:06.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-339" for this suite. 04/23/23 12:17:06.77
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:224
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:17:06.784
Apr 23 12:17:06.784: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename sched-preemption 04/23/23 12:17:06.786
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:17:06.81
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:17:06.815
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:97
Apr 23 12:17:06.858: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 23 12:18:06.932: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:224
STEP: Create pods that use 4/5 of node resources. 04/23/23 12:18:06.942
Apr 23 12:18:06.993: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr 23 12:18:07.016: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr 23 12:18:07.120: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr 23 12:18:07.151: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Apr 23 12:18:07.210: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Apr 23 12:18:07.229: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 04/23/23 12:18:07.232
Apr 23 12:18:07.234: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-4004" to be "running"
Apr 23 12:18:07.249: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 14.535429ms
Apr 23 12:18:09.261: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026619418s
Apr 23 12:18:11.259: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.02452791s
Apr 23 12:18:11.259: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Apr 23 12:18:11.259: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-4004" to be "running"
Apr 23 12:18:11.267: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.968511ms
Apr 23 12:18:11.267: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 23 12:18:11.267: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-4004" to be "running"
Apr 23 12:18:11.273: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.296948ms
Apr 23 12:18:11.273: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 23 12:18:11.273: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-4004" to be "running"
Apr 23 12:18:11.280: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.23226ms
Apr 23 12:18:11.280: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 23 12:18:11.280: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-4004" to be "running"
Apr 23 12:18:11.291: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.354079ms
Apr 23 12:18:11.291: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 23 12:18:11.291: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-4004" to be "running"
Apr 23 12:18:11.297: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.941033ms
Apr 23 12:18:11.297: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 04/23/23 12:18:11.297
Apr 23 12:18:11.322: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Apr 23 12:18:11.367: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 44.832998ms
Apr 23 12:18:13.377: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054381836s
Apr 23 12:18:15.379: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057147655s
Apr 23 12:18:17.377: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.054477684s
Apr 23 12:18:17.377: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:18:17.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:84
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "sched-preemption-4004" for this suite. 04/23/23 12:18:17.626
------------------------------
â€¢ [SLOW TEST] [70.857 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:17:06.784
    Apr 23 12:17:06.784: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename sched-preemption 04/23/23 12:17:06.786
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:17:06.81
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:17:06.815
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:97
    Apr 23 12:17:06.858: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 23 12:18:06.932: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:224
    STEP: Create pods that use 4/5 of node resources. 04/23/23 12:18:06.942
    Apr 23 12:18:06.993: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Apr 23 12:18:07.016: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Apr 23 12:18:07.120: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Apr 23 12:18:07.151: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Apr 23 12:18:07.210: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Apr 23 12:18:07.229: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 04/23/23 12:18:07.232
    Apr 23 12:18:07.234: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-4004" to be "running"
    Apr 23 12:18:07.249: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 14.535429ms
    Apr 23 12:18:09.261: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026619418s
    Apr 23 12:18:11.259: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.02452791s
    Apr 23 12:18:11.259: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Apr 23 12:18:11.259: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-4004" to be "running"
    Apr 23 12:18:11.267: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.968511ms
    Apr 23 12:18:11.267: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 23 12:18:11.267: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-4004" to be "running"
    Apr 23 12:18:11.273: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.296948ms
    Apr 23 12:18:11.273: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 23 12:18:11.273: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-4004" to be "running"
    Apr 23 12:18:11.280: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.23226ms
    Apr 23 12:18:11.280: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 23 12:18:11.280: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-4004" to be "running"
    Apr 23 12:18:11.291: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.354079ms
    Apr 23 12:18:11.291: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 23 12:18:11.291: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-4004" to be "running"
    Apr 23 12:18:11.297: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.941033ms
    Apr 23 12:18:11.297: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 04/23/23 12:18:11.297
    Apr 23 12:18:11.322: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Apr 23 12:18:11.367: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 44.832998ms
    Apr 23 12:18:13.377: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054381836s
    Apr 23 12:18:15.379: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057147655s
    Apr 23 12:18:17.377: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.054477684s
    Apr 23 12:18:17.377: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:18:17.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:84
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] SchedulerPreemption [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sched-preemption-4004" for this suite. 04/23/23 12:18:17.626
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:84
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:18:17.646
Apr 23 12:18:17.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 12:18:17.65
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:18:17.687
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:18:17.696
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:84
STEP: Creating a pod to test downward API volume plugin 04/23/23 12:18:17.703
Apr 23 12:18:17.720: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1" in namespace "downward-api-9946" to be "Succeeded or Failed"
Apr 23 12:18:17.728: INFO: Pod "downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.248995ms
Apr 23 12:18:19.738: INFO: Pod "downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1": Phase="Running", Reason="", readiness=true. Elapsed: 2.017583268s
Apr 23 12:18:21.737: INFO: Pod "downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016474723s
STEP: Saw pod success 04/23/23 12:18:21.737
Apr 23 12:18:21.738: INFO: Pod "downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1" satisfied condition "Succeeded or Failed"
Apr 23 12:18:21.745: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1 container client-container: <nil>
STEP: delete the pod 04/23/23 12:18:21.761
Apr 23 12:18:21.793: INFO: Waiting for pod downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1 to disappear
Apr 23 12:18:21.800: INFO: Pod downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Apr 23 12:18:21.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-9946" for this suite. 04/23/23 12:18:21.818
------------------------------
â€¢ [4.186 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:84

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:18:17.646
    Apr 23 12:18:17.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 12:18:17.65
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:18:17.687
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:18:17.696
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:84
    STEP: Creating a pod to test downward API volume plugin 04/23/23 12:18:17.703
    Apr 23 12:18:17.720: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1" in namespace "downward-api-9946" to be "Succeeded or Failed"
    Apr 23 12:18:17.728: INFO: Pod "downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.248995ms
    Apr 23 12:18:19.738: INFO: Pod "downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1": Phase="Running", Reason="", readiness=true. Elapsed: 2.017583268s
    Apr 23 12:18:21.737: INFO: Pod "downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016474723s
    STEP: Saw pod success 04/23/23 12:18:21.737
    Apr 23 12:18:21.738: INFO: Pod "downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1" satisfied condition "Succeeded or Failed"
    Apr 23 12:18:21.745: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1 container client-container: <nil>
    STEP: delete the pod 04/23/23 12:18:21.761
    Apr 23 12:18:21.793: INFO: Waiting for pod downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1 to disappear
    Apr 23 12:18:21.800: INFO: Pod downwardapi-volume-fd84dd4d-e057-4603-b60c-b01840733aa1 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:18:21.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-9946" for this suite. 04/23/23 12:18:21.818
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:117
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:18:21.846
Apr 23 12:18:21.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 12:18:21.861
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:18:21.9
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:18:21.908
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 12:18:21.952
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:18:22.914
STEP: Deploying the webhook pod 04/23/23 12:18:22.923
STEP: Wait for the deployment to be ready 04/23/23 12:18:22.981
Apr 23 12:18:23.014: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 23 12:18:25.098: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 18, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 18, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 18, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 18, 22, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/23/23 12:18:27.108
STEP: Verifying the service has paired with the endpoint 04/23/23 12:18:27.137
Apr 23 12:18:28.138: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:117
STEP: fetching the /apis discovery document 04/23/23 12:18:28.15
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 04/23/23 12:18:28.152
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 04/23/23 12:18:28.152
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 04/23/23 12:18:28.152
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 04/23/23 12:18:28.155
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 04/23/23 12:18:28.156
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 04/23/23 12:18:28.16
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:18:28.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-7220" for this suite. 04/23/23 12:18:28.304
STEP: Destroying namespace "webhook-7220-markers" for this suite. 04/23/23 12:18:28.318
------------------------------
â€¢ [SLOW TEST] [6.544 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:18:21.846
    Apr 23 12:18:21.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 12:18:21.861
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:18:21.9
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:18:21.908
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 12:18:21.952
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:18:22.914
    STEP: Deploying the webhook pod 04/23/23 12:18:22.923
    STEP: Wait for the deployment to be ready 04/23/23 12:18:22.981
    Apr 23 12:18:23.014: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 23 12:18:25.098: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 18, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 18, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 18, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 18, 22, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/23/23 12:18:27.108
    STEP: Verifying the service has paired with the endpoint 04/23/23 12:18:27.137
    Apr 23 12:18:28.138: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:117
    STEP: fetching the /apis discovery document 04/23/23 12:18:28.15
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 04/23/23 12:18:28.152
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 04/23/23 12:18:28.152
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 04/23/23 12:18:28.152
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 04/23/23 12:18:28.155
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 04/23/23 12:18:28.156
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 04/23/23 12:18:28.16
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:18:28.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-7220" for this suite. 04/23/23 12:18:28.304
    STEP: Destroying namespace "webhook-7220-markers" for this suite. 04/23/23 12:18:28.318
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:18:28.41
Apr 23 12:18:28.410: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename replicaset 04/23/23 12:18:28.425
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:18:28.453
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:18:28.458
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:31
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 04/23/23 12:18:28.573
STEP: Verify that the required pods have come up. 04/23/23 12:18:28.612
Apr 23 12:18:28.622: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 23 12:18:33.633: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/23/23 12:18:33.634
STEP: Getting /status 04/23/23 12:18:33.634
Apr 23 12:18:33.645: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 04/23/23 12:18:33.645
Apr 23 12:18:33.673: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 04/23/23 12:18:33.673
Apr 23 12:18:33.679: INFO: Observed &ReplicaSet event: ADDED
Apr 23 12:18:33.679: INFO: Observed &ReplicaSet event: MODIFIED
Apr 23 12:18:33.682: INFO: Observed &ReplicaSet event: MODIFIED
Apr 23 12:18:33.683: INFO: Observed &ReplicaSet event: MODIFIED
Apr 23 12:18:33.683: INFO: Found replicaset test-rs in namespace replicaset-4991 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 23 12:18:33.683: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 04/23/23 12:18:33.683
Apr 23 12:18:33.683: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 23 12:18:33.713: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 04/23/23 12:18:33.713
Apr 23 12:18:33.717: INFO: Observed &ReplicaSet event: ADDED
Apr 23 12:18:33.718: INFO: Observed &ReplicaSet event: MODIFIED
Apr 23 12:18:33.718: INFO: Observed &ReplicaSet event: MODIFIED
Apr 23 12:18:33.718: INFO: Observed &ReplicaSet event: MODIFIED
Apr 23 12:18:33.718: INFO: Observed replicaset test-rs in namespace replicaset-4991 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 23 12:18:33.719: INFO: Observed &ReplicaSet event: MODIFIED
Apr 23 12:18:33.719: INFO: Found replicaset test-rs in namespace replicaset-4991 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Apr 23 12:18:33.719: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/node/init/init.go:32
Apr 23 12:18:33.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  tear down framework | framework.go:193
STEP: Destroying namespace "replicaset-4991" for this suite. 04/23/23 12:18:33.733
------------------------------
â€¢ [SLOW TEST] [5.344 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:18:28.41
    Apr 23 12:18:28.410: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename replicaset 04/23/23 12:18:28.425
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:18:28.453
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:18:28.458
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:31
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 04/23/23 12:18:28.573
    STEP: Verify that the required pods have come up. 04/23/23 12:18:28.612
    Apr 23 12:18:28.622: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 23 12:18:33.633: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/23/23 12:18:33.634
    STEP: Getting /status 04/23/23 12:18:33.634
    Apr 23 12:18:33.645: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 04/23/23 12:18:33.645
    Apr 23 12:18:33.673: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 04/23/23 12:18:33.673
    Apr 23 12:18:33.679: INFO: Observed &ReplicaSet event: ADDED
    Apr 23 12:18:33.679: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 23 12:18:33.682: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 23 12:18:33.683: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 23 12:18:33.683: INFO: Found replicaset test-rs in namespace replicaset-4991 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 23 12:18:33.683: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 04/23/23 12:18:33.683
    Apr 23 12:18:33.683: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 23 12:18:33.713: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 04/23/23 12:18:33.713
    Apr 23 12:18:33.717: INFO: Observed &ReplicaSet event: ADDED
    Apr 23 12:18:33.718: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 23 12:18:33.718: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 23 12:18:33.718: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 23 12:18:33.718: INFO: Observed replicaset test-rs in namespace replicaset-4991 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 23 12:18:33.719: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 23 12:18:33.719: INFO: Found replicaset test-rs in namespace replicaset-4991 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Apr 23 12:18:33.719: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:18:33.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "replicaset-4991" for this suite. 04/23/23 12:18:33.733
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:67
[BeforeEach] [sig-apps] ReplicationController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:18:33.783
Apr 23 12:18:33.784: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename replication-controller 04/23/23 12:18:33.79
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:18:33.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:18:33.873
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:57
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:67
STEP: Creating replication controller my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a 04/23/23 12:18:33.877
Apr 23 12:18:33.909: INFO: Pod name my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a: Found 0 pods out of 1
Apr 23 12:18:38.921: INFO: Pod name my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a: Found 1 pods out of 1
Apr 23 12:18:38.921: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a" are running
Apr 23 12:18:38.921: INFO: Waiting up to 5m0s for pod "my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a-sbfz2" in namespace "replication-controller-9337" to be "running"
Apr 23 12:18:38.933: INFO: Pod "my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a-sbfz2": Phase="Running", Reason="", readiness=true. Elapsed: 11.880434ms
Apr 23 12:18:38.933: INFO: Pod "my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a-sbfz2" satisfied condition "running"
Apr 23 12:18:38.933: INFO: Pod "my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a-sbfz2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:18:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:18:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:18:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:18:33 +0000 UTC Reason: Message:}])
Apr 23 12:18:38.934: INFO: Trying to dial the pod
Apr 23 12:18:43.965: INFO: Controller my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a: Got expected result from replica 1 [my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a-sbfz2]: "my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a-sbfz2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/node/init/init.go:32
Apr 23 12:18:43.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicationController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicationController
  tear down framework | framework.go:193
STEP: Destroying namespace "replication-controller-9337" for this suite. 04/23/23 12:18:43.974
------------------------------
â€¢ [SLOW TEST] [10.203 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:18:33.783
    Apr 23 12:18:33.784: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename replication-controller 04/23/23 12:18:33.79
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:18:33.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:18:33.873
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:57
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:67
    STEP: Creating replication controller my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a 04/23/23 12:18:33.877
    Apr 23 12:18:33.909: INFO: Pod name my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a: Found 0 pods out of 1
    Apr 23 12:18:38.921: INFO: Pod name my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a: Found 1 pods out of 1
    Apr 23 12:18:38.921: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a" are running
    Apr 23 12:18:38.921: INFO: Waiting up to 5m0s for pod "my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a-sbfz2" in namespace "replication-controller-9337" to be "running"
    Apr 23 12:18:38.933: INFO: Pod "my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a-sbfz2": Phase="Running", Reason="", readiness=true. Elapsed: 11.880434ms
    Apr 23 12:18:38.933: INFO: Pod "my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a-sbfz2" satisfied condition "running"
    Apr 23 12:18:38.933: INFO: Pod "my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a-sbfz2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:18:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:18:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:18:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:18:33 +0000 UTC Reason: Message:}])
    Apr 23 12:18:38.934: INFO: Trying to dial the pod
    Apr 23 12:18:43.965: INFO: Controller my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a: Got expected result from replica 1 [my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a-sbfz2]: "my-hostname-basic-6296583c-7bd2-4aa1-9c01-534eafe0bd7a-sbfz2", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:18:43.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      tear down framework | framework.go:193
    STEP: Destroying namespace "replication-controller-9337" for this suite. 04/23/23 12:18:43.974
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:18:43.987
Apr 23 12:18:43.987: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename subpath 04/23/23 12:18:43.99
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:18:44.025
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:18:44.031
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/23/23 12:18:44.039
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-857c 04/23/23 12:18:44.072
STEP: Creating a pod to test atomic-volume-subpath 04/23/23 12:18:44.072
Apr 23 12:18:44.090: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-857c" in namespace "subpath-2814" to be "Succeeded or Failed"
Apr 23 12:18:44.103: INFO: Pod "pod-subpath-test-secret-857c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.000092ms
Apr 23 12:18:46.110: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 2.019871927s
Apr 23 12:18:48.118: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 4.02856584s
Apr 23 12:18:50.113: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 6.023832329s
Apr 23 12:18:52.111: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 8.020878983s
Apr 23 12:18:54.116: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 10.025975832s
Apr 23 12:18:56.113: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 12.023359557s
Apr 23 12:18:58.116: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 14.02654281s
Apr 23 12:19:00.115: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 16.025856408s
Apr 23 12:19:02.115: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 18.024940746s
Apr 23 12:19:04.115: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 20.025353603s
Apr 23 12:19:06.112: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=false. Elapsed: 22.022606235s
Apr 23 12:19:08.112: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=false. Elapsed: 24.022201067s
Apr 23 12:19:10.113: INFO: Pod "pod-subpath-test-secret-857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.022969105s
STEP: Saw pod success 04/23/23 12:19:10.113
Apr 23 12:19:10.114: INFO: Pod "pod-subpath-test-secret-857c" satisfied condition "Succeeded or Failed"
Apr 23 12:19:10.122: INFO: Trying to get logs from node eingavuivie7-3 pod pod-subpath-test-secret-857c container test-container-subpath-secret-857c: <nil>
STEP: delete the pod 04/23/23 12:19:10.141
Apr 23 12:19:10.169: INFO: Waiting for pod pod-subpath-test-secret-857c to disappear
Apr 23 12:19:10.174: INFO: Pod pod-subpath-test-secret-857c no longer exists
STEP: Deleting pod pod-subpath-test-secret-857c 04/23/23 12:19:10.175
Apr 23 12:19:10.175: INFO: Deleting pod "pod-subpath-test-secret-857c" in namespace "subpath-2814"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/node/init/init.go:32
Apr 23 12:19:10.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Subpath
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Subpath
  tear down framework | framework.go:193
STEP: Destroying namespace "subpath-2814" for this suite. 04/23/23 12:19:10.194
------------------------------
â€¢ [SLOW TEST] [26.221 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:18:43.987
    Apr 23 12:18:43.987: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename subpath 04/23/23 12:18:43.99
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:18:44.025
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:18:44.031
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/23/23 12:18:44.039
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-857c 04/23/23 12:18:44.072
    STEP: Creating a pod to test atomic-volume-subpath 04/23/23 12:18:44.072
    Apr 23 12:18:44.090: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-857c" in namespace "subpath-2814" to be "Succeeded or Failed"
    Apr 23 12:18:44.103: INFO: Pod "pod-subpath-test-secret-857c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.000092ms
    Apr 23 12:18:46.110: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 2.019871927s
    Apr 23 12:18:48.118: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 4.02856584s
    Apr 23 12:18:50.113: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 6.023832329s
    Apr 23 12:18:52.111: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 8.020878983s
    Apr 23 12:18:54.116: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 10.025975832s
    Apr 23 12:18:56.113: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 12.023359557s
    Apr 23 12:18:58.116: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 14.02654281s
    Apr 23 12:19:00.115: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 16.025856408s
    Apr 23 12:19:02.115: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 18.024940746s
    Apr 23 12:19:04.115: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=true. Elapsed: 20.025353603s
    Apr 23 12:19:06.112: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=false. Elapsed: 22.022606235s
    Apr 23 12:19:08.112: INFO: Pod "pod-subpath-test-secret-857c": Phase="Running", Reason="", readiness=false. Elapsed: 24.022201067s
    Apr 23 12:19:10.113: INFO: Pod "pod-subpath-test-secret-857c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.022969105s
    STEP: Saw pod success 04/23/23 12:19:10.113
    Apr 23 12:19:10.114: INFO: Pod "pod-subpath-test-secret-857c" satisfied condition "Succeeded or Failed"
    Apr 23 12:19:10.122: INFO: Trying to get logs from node eingavuivie7-3 pod pod-subpath-test-secret-857c container test-container-subpath-secret-857c: <nil>
    STEP: delete the pod 04/23/23 12:19:10.141
    Apr 23 12:19:10.169: INFO: Waiting for pod pod-subpath-test-secret-857c to disappear
    Apr 23 12:19:10.174: INFO: Pod pod-subpath-test-secret-857c no longer exists
    STEP: Deleting pod pod-subpath-test-secret-857c 04/23/23 12:19:10.175
    Apr 23 12:19:10.175: INFO: Deleting pod "pod-subpath-test-secret-857c" in namespace "subpath-2814"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:19:10.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Subpath
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Subpath
      tear down framework | framework.go:193
    STEP: Destroying namespace "subpath-2814" for this suite. 04/23/23 12:19:10.194
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:232
[BeforeEach] [sig-node] Container Runtime
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:19:10.213
Apr 23 12:19:10.213: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-runtime 04/23/23 12:19:10.219
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:10.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:10.255
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:31
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:232
STEP: create the container 04/23/23 12:19:10.259
STEP: wait for the container to reach Succeeded 04/23/23 12:19:10.278
STEP: get the container status 04/23/23 12:19:14.328
STEP: the container should be terminated 04/23/23 12:19:14.335
STEP: the termination message should be set 04/23/23 12:19:14.335
Apr 23 12:19:14.335: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 04/23/23 12:19:14.335
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/node/init/init.go:32
Apr 23 12:19:14.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Runtime
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Runtime
  tear down framework | framework.go:193
STEP: Destroying namespace "container-runtime-2293" for this suite. 04/23/23 12:19:14.367
------------------------------
â€¢ [4.171 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:44
    on terminated container
    test/e2e/common/node/runtime.go:137
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:232

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:19:10.213
    Apr 23 12:19:10.213: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-runtime 04/23/23 12:19:10.219
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:10.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:10.255
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:31
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:232
    STEP: create the container 04/23/23 12:19:10.259
    STEP: wait for the container to reach Succeeded 04/23/23 12:19:10.278
    STEP: get the container status 04/23/23 12:19:14.328
    STEP: the container should be terminated 04/23/23 12:19:14.335
    STEP: the termination message should be set 04/23/23 12:19:14.335
    Apr 23 12:19:14.335: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 04/23/23 12:19:14.335
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:19:14.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Runtime
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Runtime
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-runtime-2293" for this suite. 04/23/23 12:19:14.367
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:19:14.388
Apr 23 12:19:14.388: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename watch 04/23/23 12:19:14.39
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:14.417
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:14.421
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:31
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 04/23/23 12:19:14.425
STEP: creating a new configmap 04/23/23 12:19:14.428
STEP: modifying the configmap once 04/23/23 12:19:14.437
STEP: closing the watch once it receives two notifications 04/23/23 12:19:14.454
Apr 23 12:19:14.455: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2007  a792f20b-df1e-4c55-a83f-550fc672b010 29781 0 2023-04-23 12:19:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 23 12:19:14.456: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2007  a792f20b-df1e-4c55-a83f-550fc672b010 29782 0 2023-04-23 12:19:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 04/23/23 12:19:14.456
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 04/23/23 12:19:14.473
STEP: deleting the configmap 04/23/23 12:19:14.477
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 04/23/23 12:19:14.493
Apr 23 12:19:14.494: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2007  a792f20b-df1e-4c55-a83f-550fc672b010 29783 0 2023-04-23 12:19:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 23 12:19:14.494: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2007  a792f20b-df1e-4c55-a83f-550fc672b010 29784 0 2023-04-23 12:19:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/node/init/init.go:32
Apr 23 12:19:14.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  tear down framework | framework.go:193
STEP: Destroying namespace "watch-2007" for this suite. 04/23/23 12:19:14.502
------------------------------
â€¢ [0.124 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:19:14.388
    Apr 23 12:19:14.388: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename watch 04/23/23 12:19:14.39
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:14.417
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:14.421
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:31
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 04/23/23 12:19:14.425
    STEP: creating a new configmap 04/23/23 12:19:14.428
    STEP: modifying the configmap once 04/23/23 12:19:14.437
    STEP: closing the watch once it receives two notifications 04/23/23 12:19:14.454
    Apr 23 12:19:14.455: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2007  a792f20b-df1e-4c55-a83f-550fc672b010 29781 0 2023-04-23 12:19:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 23 12:19:14.456: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2007  a792f20b-df1e-4c55-a83f-550fc672b010 29782 0 2023-04-23 12:19:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 04/23/23 12:19:14.456
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 04/23/23 12:19:14.473
    STEP: deleting the configmap 04/23/23 12:19:14.477
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 04/23/23 12:19:14.493
    Apr 23 12:19:14.494: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2007  a792f20b-df1e-4c55-a83f-550fc672b010 29783 0 2023-04-23 12:19:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 23 12:19:14.494: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2007  a792f20b-df1e-4c55-a83f-550fc672b010 29784 0 2023-04-23 12:19:14 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:19:14.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      tear down framework | framework.go:193
    STEP: Destroying namespace "watch-2007" for this suite. 04/23/23 12:19:14.502
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:294
[BeforeEach] [sig-apps] Daemon set [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:19:14.527
Apr 23 12:19:14.528: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename daemonsets 04/23/23 12:19:14.529
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:14.58
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:14.584
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:146
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:294
STEP: Creating a simple DaemonSet "daemon-set" 04/23/23 12:19:14.639
STEP: Check that daemon pods launch on every node of the cluster. 04/23/23 12:19:14.653
Apr 23 12:19:14.690: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 12:19:14.690: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:19:15.718: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 12:19:15.718: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:19:16.733: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 23 12:19:16.733: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:19:17.726: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 23 12:19:17.726: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 04/23/23 12:19:17.734
Apr 23 12:19:17.783: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 12:19:17.783: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:19:18.826: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 12:19:18.826: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:19:19.802: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 12:19:19.802: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:19:20.810: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 23 12:19:20.810: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 04/23/23 12:19:20.81
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:111
STEP: Deleting DaemonSet "daemon-set" 04/23/23 12:19:20.826
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2979, will wait for the garbage collector to delete the pods 04/23/23 12:19:20.827
Apr 23 12:19:20.910: INFO: Deleting DaemonSet.extensions daemon-set took: 19.173555ms
Apr 23 12:19:21.011: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.017059ms
Apr 23 12:19:23.418: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 12:19:23.419: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 23 12:19:23.432: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29910"},"items":null}

Apr 23 12:19:23.437: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29910"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:19:23.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "daemonsets-2979" for this suite. 04/23/23 12:19:23.523
------------------------------
â€¢ [SLOW TEST] [9.010 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:294

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:19:14.527
    Apr 23 12:19:14.528: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename daemonsets 04/23/23 12:19:14.529
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:14.58
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:14.584
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:146
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:294
    STEP: Creating a simple DaemonSet "daemon-set" 04/23/23 12:19:14.639
    STEP: Check that daemon pods launch on every node of the cluster. 04/23/23 12:19:14.653
    Apr 23 12:19:14.690: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 12:19:14.690: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:19:15.718: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 12:19:15.718: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:19:16.733: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 23 12:19:16.733: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:19:17.726: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 23 12:19:17.726: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 04/23/23 12:19:17.734
    Apr 23 12:19:17.783: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 12:19:17.783: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:19:18.826: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 12:19:18.826: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:19:19.802: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 12:19:19.802: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:19:20.810: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 23 12:19:20.810: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 04/23/23 12:19:20.81
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:111
    STEP: Deleting DaemonSet "daemon-set" 04/23/23 12:19:20.826
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2979, will wait for the garbage collector to delete the pods 04/23/23 12:19:20.827
    Apr 23 12:19:20.910: INFO: Deleting DaemonSet.extensions daemon-set took: 19.173555ms
    Apr 23 12:19:21.011: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.017059ms
    Apr 23 12:19:23.418: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 12:19:23.419: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 23 12:19:23.432: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29910"},"items":null}

    Apr 23 12:19:23.437: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29910"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:19:23.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "daemonsets-2979" for this suite. 04/23/23 12:19:23.523
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:19:23.56
Apr 23 12:19:23.560: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename events 04/23/23 12:19:23.562
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:23.614
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:23.62
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 04/23/23 12:19:23.628
STEP: listing events in all namespaces 04/23/23 12:19:23.642
STEP: listing events in test namespace 04/23/23 12:19:23.651
STEP: listing events with field selection filtering on source 04/23/23 12:19:23.656
STEP: listing events with field selection filtering on reportingController 04/23/23 12:19:23.66
STEP: getting the test event 04/23/23 12:19:23.666
STEP: patching the test event 04/23/23 12:19:23.672
STEP: getting the test event 04/23/23 12:19:23.688
STEP: updating the test event 04/23/23 12:19:23.694
STEP: getting the test event 04/23/23 12:19:23.705
STEP: deleting the test event 04/23/23 12:19:23.711
STEP: listing events in all namespaces 04/23/23 12:19:23.73
STEP: listing events in test namespace 04/23/23 12:19:23.739
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/node/init/init.go:32
Apr 23 12:19:23.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-instrumentation] Events API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-instrumentation] Events API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-instrumentation] Events API
  tear down framework | framework.go:193
STEP: Destroying namespace "events-7393" for this suite. 04/23/23 12:19:23.754
------------------------------
â€¢ [0.206 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:19:23.56
    Apr 23 12:19:23.560: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename events 04/23/23 12:19:23.562
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:23.614
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:23.62
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 04/23/23 12:19:23.628
    STEP: listing events in all namespaces 04/23/23 12:19:23.642
    STEP: listing events in test namespace 04/23/23 12:19:23.651
    STEP: listing events with field selection filtering on source 04/23/23 12:19:23.656
    STEP: listing events with field selection filtering on reportingController 04/23/23 12:19:23.66
    STEP: getting the test event 04/23/23 12:19:23.666
    STEP: patching the test event 04/23/23 12:19:23.672
    STEP: getting the test event 04/23/23 12:19:23.688
    STEP: updating the test event 04/23/23 12:19:23.694
    STEP: getting the test event 04/23/23 12:19:23.705
    STEP: deleting the test event 04/23/23 12:19:23.711
    STEP: listing events in all namespaces 04/23/23 12:19:23.73
    STEP: listing events in test namespace 04/23/23 12:19:23.739
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:19:23.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-instrumentation] Events API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-instrumentation] Events API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-instrumentation] Events API
      tear down framework | framework.go:193
    STEP: Destroying namespace "events-7393" for this suite. 04/23/23 12:19:23.754
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:141
[BeforeEach] [sig-apps] DisruptionController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:19:23.774
Apr 23 12:19:23.774: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename disruption 04/23/23 12:19:23.778
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:23.811
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:23.816
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:72
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:141
STEP: Waiting for the pdb to be processed 04/23/23 12:19:23.838
STEP: Waiting for all pods to be running 04/23/23 12:19:23.925
Apr 23 12:19:23.950: INFO: running pods: 0 < 3
Apr 23 12:19:25.958: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/node/init/init.go:32
Apr 23 12:19:27.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] DisruptionController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] DisruptionController
  tear down framework | framework.go:193
STEP: Destroying namespace "disruption-1106" for this suite. 04/23/23 12:19:27.975
------------------------------
â€¢ [4.217 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:141

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:19:23.774
    Apr 23 12:19:23.774: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename disruption 04/23/23 12:19:23.778
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:23.811
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:23.816
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:72
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:141
    STEP: Waiting for the pdb to be processed 04/23/23 12:19:23.838
    STEP: Waiting for all pods to be running 04/23/23 12:19:23.925
    Apr 23 12:19:23.950: INFO: running pods: 0 < 3
    Apr 23 12:19:25.958: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:19:27.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      tear down framework | framework.go:193
    STEP: Destroying namespace "disruption-1106" for this suite. 04/23/23 12:19:27.975
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:187
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:19:27.993
Apr 23 12:19:27.993: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 12:19:27.998
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:28.022
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:28.027
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:187
STEP: Creating a pod to test emptydir 0777 on node default medium 04/23/23 12:19:28.033
Apr 23 12:19:28.057: INFO: Waiting up to 5m0s for pod "pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d" in namespace "emptydir-5237" to be "Succeeded or Failed"
Apr 23 12:19:28.083: INFO: Pod "pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d": Phase="Pending", Reason="", readiness=false. Elapsed: 25.847081ms
Apr 23 12:19:30.093: INFO: Pod "pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036721619s
Apr 23 12:19:32.092: INFO: Pod "pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035077772s
STEP: Saw pod success 04/23/23 12:19:32.092
Apr 23 12:19:32.093: INFO: Pod "pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d" satisfied condition "Succeeded or Failed"
Apr 23 12:19:32.105: INFO: Trying to get logs from node eingavuivie7-3 pod pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d container test-container: <nil>
STEP: delete the pod 04/23/23 12:19:32.124
Apr 23 12:19:32.143: INFO: Waiting for pod pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d to disappear
Apr 23 12:19:32.149: INFO: Pod pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 12:19:32.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-5237" for this suite. 04/23/23 12:19:32.157
------------------------------
â€¢ [4.177 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:187

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:19:27.993
    Apr 23 12:19:27.993: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 12:19:27.998
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:28.022
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:28.027
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:187
    STEP: Creating a pod to test emptydir 0777 on node default medium 04/23/23 12:19:28.033
    Apr 23 12:19:28.057: INFO: Waiting up to 5m0s for pod "pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d" in namespace "emptydir-5237" to be "Succeeded or Failed"
    Apr 23 12:19:28.083: INFO: Pod "pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d": Phase="Pending", Reason="", readiness=false. Elapsed: 25.847081ms
    Apr 23 12:19:30.093: INFO: Pod "pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036721619s
    Apr 23 12:19:32.092: INFO: Pod "pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035077772s
    STEP: Saw pod success 04/23/23 12:19:32.092
    Apr 23 12:19:32.093: INFO: Pod "pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d" satisfied condition "Succeeded or Failed"
    Apr 23 12:19:32.105: INFO: Trying to get logs from node eingavuivie7-3 pod pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d container test-container: <nil>
    STEP: delete the pod 04/23/23 12:19:32.124
    Apr 23 12:19:32.143: INFO: Waiting for pod pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d to disappear
    Apr 23 12:19:32.149: INFO: Pod pod-9e30fba3-343c-4ffb-9ae2-32d13aa70d2d no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:19:32.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-5237" for this suite. 04/23/23 12:19:32.157
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:137
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:19:32.172
Apr 23 12:19:32.172: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 12:19:32.189
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:32.218
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:32.225
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:137
STEP: Creating a pod to test emptydir 0666 on tmpfs 04/23/23 12:19:32.232
Apr 23 12:19:32.250: INFO: Waiting up to 5m0s for pod "pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132" in namespace "emptydir-3087" to be "Succeeded or Failed"
Apr 23 12:19:32.256: INFO: Pod "pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132": Phase="Pending", Reason="", readiness=false. Elapsed: 5.641057ms
Apr 23 12:19:34.268: INFO: Pod "pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018539135s
Apr 23 12:19:36.265: INFO: Pod "pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132": Phase="Running", Reason="", readiness=false. Elapsed: 4.01514838s
Apr 23 12:19:38.265: INFO: Pod "pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132": Phase="Running", Reason="", readiness=false. Elapsed: 6.014933395s
Apr 23 12:19:40.274: INFO: Pod "pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.02460421s
STEP: Saw pod success 04/23/23 12:19:40.275
Apr 23 12:19:40.275: INFO: Pod "pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132" satisfied condition "Succeeded or Failed"
Apr 23 12:19:40.283: INFO: Trying to get logs from node eingavuivie7-3 pod pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132 container test-container: <nil>
STEP: delete the pod 04/23/23 12:19:40.311
Apr 23 12:19:40.340: INFO: Waiting for pod pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132 to disappear
Apr 23 12:19:40.348: INFO: Pod pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 12:19:40.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-3087" for this suite. 04/23/23 12:19:40.359
------------------------------
â€¢ [SLOW TEST] [8.207 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:19:32.172
    Apr 23 12:19:32.172: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 12:19:32.189
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:32.218
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:32.225
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:137
    STEP: Creating a pod to test emptydir 0666 on tmpfs 04/23/23 12:19:32.232
    Apr 23 12:19:32.250: INFO: Waiting up to 5m0s for pod "pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132" in namespace "emptydir-3087" to be "Succeeded or Failed"
    Apr 23 12:19:32.256: INFO: Pod "pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132": Phase="Pending", Reason="", readiness=false. Elapsed: 5.641057ms
    Apr 23 12:19:34.268: INFO: Pod "pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018539135s
    Apr 23 12:19:36.265: INFO: Pod "pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132": Phase="Running", Reason="", readiness=false. Elapsed: 4.01514838s
    Apr 23 12:19:38.265: INFO: Pod "pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132": Phase="Running", Reason="", readiness=false. Elapsed: 6.014933395s
    Apr 23 12:19:40.274: INFO: Pod "pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.02460421s
    STEP: Saw pod success 04/23/23 12:19:40.275
    Apr 23 12:19:40.275: INFO: Pod "pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132" satisfied condition "Succeeded or Failed"
    Apr 23 12:19:40.283: INFO: Trying to get logs from node eingavuivie7-3 pod pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132 container test-container: <nil>
    STEP: delete the pod 04/23/23 12:19:40.311
    Apr 23 12:19:40.340: INFO: Waiting for pod pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132 to disappear
    Apr 23 12:19:40.348: INFO: Pod pod-ec4d20e9-4b09-40c5-9b5e-dc14d829f132 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:19:40.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-3087" for this suite. 04/23/23 12:19:40.359
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:19:40.38
Apr 23 12:19:40.380: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename watch 04/23/23 12:19:40.387
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:40.426
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:40.44
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:31
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 04/23/23 12:19:40.466
STEP: creating a watch on configmaps with label B 04/23/23 12:19:40.469
STEP: creating a watch on configmaps with label A or B 04/23/23 12:19:40.478
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 04/23/23 12:19:40.482
Apr 23 12:19:40.526: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30122 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 23 12:19:40.527: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30122 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 04/23/23 12:19:40.527
Apr 23 12:19:40.553: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30123 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 23 12:19:40.554: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30123 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 04/23/23 12:19:40.554
Apr 23 12:19:40.610: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30124 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 23 12:19:40.610: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30124 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 04/23/23 12:19:40.611
Apr 23 12:19:40.654: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30125 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 23 12:19:40.654: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30125 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 04/23/23 12:19:40.655
Apr 23 12:19:40.665: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5504  8ea887aa-36b7-4d1b-80c8-b018b85f90f4 30126 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 23 12:19:40.665: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5504  8ea887aa-36b7-4d1b-80c8-b018b85f90f4 30126 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 04/23/23 12:19:50.666
Apr 23 12:19:50.683: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5504  8ea887aa-36b7-4d1b-80c8-b018b85f90f4 30158 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 23 12:19:50.684: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5504  8ea887aa-36b7-4d1b-80c8-b018b85f90f4 30158 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/node/init/init.go:32
Apr 23 12:20:00.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Watchers
  tear down framework | framework.go:193
STEP: Destroying namespace "watch-5504" for this suite. 04/23/23 12:20:00.695
------------------------------
â€¢ [SLOW TEST] [20.329 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:19:40.38
    Apr 23 12:19:40.380: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename watch 04/23/23 12:19:40.387
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:19:40.426
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:19:40.44
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:31
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 04/23/23 12:19:40.466
    STEP: creating a watch on configmaps with label B 04/23/23 12:19:40.469
    STEP: creating a watch on configmaps with label A or B 04/23/23 12:19:40.478
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 04/23/23 12:19:40.482
    Apr 23 12:19:40.526: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30122 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 23 12:19:40.527: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30122 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 04/23/23 12:19:40.527
    Apr 23 12:19:40.553: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30123 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 23 12:19:40.554: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30123 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 04/23/23 12:19:40.554
    Apr 23 12:19:40.610: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30124 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 23 12:19:40.610: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30124 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 04/23/23 12:19:40.611
    Apr 23 12:19:40.654: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30125 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 23 12:19:40.654: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5504  49271787-a6bf-43ea-a55e-25a030c6834d 30125 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 04/23/23 12:19:40.655
    Apr 23 12:19:40.665: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5504  8ea887aa-36b7-4d1b-80c8-b018b85f90f4 30126 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 23 12:19:40.665: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5504  8ea887aa-36b7-4d1b-80c8-b018b85f90f4 30126 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 04/23/23 12:19:50.666
    Apr 23 12:19:50.683: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5504  8ea887aa-36b7-4d1b-80c8-b018b85f90f4 30158 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 23 12:19:50.684: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5504  8ea887aa-36b7-4d1b-80c8-b018b85f90f4 30158 0 2023-04-23 12:19:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-23 12:19:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:20:00.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Watchers
      tear down framework | framework.go:193
    STEP: Destroying namespace "watch-5504" for this suite. 04/23/23 12:20:00.695
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:167
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:20:00.718
Apr 23 12:20:00.718: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 12:20:00.722
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:00.753
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:00.757
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:167
STEP: Creating a pod to test emptydir 0644 on node default medium 04/23/23 12:20:00.762
Apr 23 12:20:00.786: INFO: Waiting up to 5m0s for pod "pod-dd618e37-772c-4738-b61c-2477bc9dd6f0" in namespace "emptydir-4940" to be "Succeeded or Failed"
Apr 23 12:20:00.792: INFO: Pod "pod-dd618e37-772c-4738-b61c-2477bc9dd6f0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.673306ms
Apr 23 12:20:02.800: INFO: Pod "pod-dd618e37-772c-4738-b61c-2477bc9dd6f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01342396s
Apr 23 12:20:04.806: INFO: Pod "pod-dd618e37-772c-4738-b61c-2477bc9dd6f0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019313125s
Apr 23 12:20:06.798: INFO: Pod "pod-dd618e37-772c-4738-b61c-2477bc9dd6f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011975888s
STEP: Saw pod success 04/23/23 12:20:06.798
Apr 23 12:20:06.799: INFO: Pod "pod-dd618e37-772c-4738-b61c-2477bc9dd6f0" satisfied condition "Succeeded or Failed"
Apr 23 12:20:06.805: INFO: Trying to get logs from node eingavuivie7-3 pod pod-dd618e37-772c-4738-b61c-2477bc9dd6f0 container test-container: <nil>
STEP: delete the pod 04/23/23 12:20:06.822
Apr 23 12:20:06.853: INFO: Waiting for pod pod-dd618e37-772c-4738-b61c-2477bc9dd6f0 to disappear
Apr 23 12:20:06.861: INFO: Pod pod-dd618e37-772c-4738-b61c-2477bc9dd6f0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 12:20:06.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-4940" for this suite. 04/23/23 12:20:06.875
------------------------------
â€¢ [SLOW TEST] [6.170 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:167

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:20:00.718
    Apr 23 12:20:00.718: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 12:20:00.722
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:00.753
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:00.757
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:167
    STEP: Creating a pod to test emptydir 0644 on node default medium 04/23/23 12:20:00.762
    Apr 23 12:20:00.786: INFO: Waiting up to 5m0s for pod "pod-dd618e37-772c-4738-b61c-2477bc9dd6f0" in namespace "emptydir-4940" to be "Succeeded or Failed"
    Apr 23 12:20:00.792: INFO: Pod "pod-dd618e37-772c-4738-b61c-2477bc9dd6f0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.673306ms
    Apr 23 12:20:02.800: INFO: Pod "pod-dd618e37-772c-4738-b61c-2477bc9dd6f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01342396s
    Apr 23 12:20:04.806: INFO: Pod "pod-dd618e37-772c-4738-b61c-2477bc9dd6f0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019313125s
    Apr 23 12:20:06.798: INFO: Pod "pod-dd618e37-772c-4738-b61c-2477bc9dd6f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011975888s
    STEP: Saw pod success 04/23/23 12:20:06.798
    Apr 23 12:20:06.799: INFO: Pod "pod-dd618e37-772c-4738-b61c-2477bc9dd6f0" satisfied condition "Succeeded or Failed"
    Apr 23 12:20:06.805: INFO: Trying to get logs from node eingavuivie7-3 pod pod-dd618e37-772c-4738-b61c-2477bc9dd6f0 container test-container: <nil>
    STEP: delete the pod 04/23/23 12:20:06.822
    Apr 23 12:20:06.853: INFO: Waiting for pod pod-dd618e37-772c-4738-b61c-2477bc9dd6f0 to disappear
    Apr 23 12:20:06.861: INFO: Pod pod-dd618e37-772c-4738-b61c-2477bc9dd6f0 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:20:06.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-4940" for this suite. 04/23/23 12:20:06.875
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:20:06.897
Apr 23 12:20:06.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename ingressclass 04/23/23 12:20:06.9
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:06.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:06.943
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 04/23/23 12:20:06.948
STEP: getting /apis/networking.k8s.io 04/23/23 12:20:06.953
STEP: getting /apis/networking.k8s.iov1 04/23/23 12:20:06.956
STEP: creating 04/23/23 12:20:06.958
STEP: getting 04/23/23 12:20:06.998
STEP: listing 04/23/23 12:20:07.007
STEP: watching 04/23/23 12:20:07.015
Apr 23 12:20:07.016: INFO: starting watch
STEP: patching 04/23/23 12:20:07.017
STEP: updating 04/23/23 12:20:07.03
Apr 23 12:20:07.044: INFO: waiting for watch events with expected annotations
Apr 23 12:20:07.044: INFO: saw patched and updated annotations
STEP: deleting 04/23/23 12:20:07.044
STEP: deleting a collection 04/23/23 12:20:07.073
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/node/init/init.go:32
Apr 23 12:20:07.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] IngressClass API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] IngressClass API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] IngressClass API
  tear down framework | framework.go:193
STEP: Destroying namespace "ingressclass-7655" for this suite. 04/23/23 12:20:07.121
------------------------------
â€¢ [0.241 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:20:06.897
    Apr 23 12:20:06.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename ingressclass 04/23/23 12:20:06.9
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:06.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:06.943
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 04/23/23 12:20:06.948
    STEP: getting /apis/networking.k8s.io 04/23/23 12:20:06.953
    STEP: getting /apis/networking.k8s.iov1 04/23/23 12:20:06.956
    STEP: creating 04/23/23 12:20:06.958
    STEP: getting 04/23/23 12:20:06.998
    STEP: listing 04/23/23 12:20:07.007
    STEP: watching 04/23/23 12:20:07.015
    Apr 23 12:20:07.016: INFO: starting watch
    STEP: patching 04/23/23 12:20:07.017
    STEP: updating 04/23/23 12:20:07.03
    Apr 23 12:20:07.044: INFO: waiting for watch events with expected annotations
    Apr 23 12:20:07.044: INFO: saw patched and updated annotations
    STEP: deleting 04/23/23 12:20:07.044
    STEP: deleting a collection 04/23/23 12:20:07.073
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:20:07.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] IngressClass API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] IngressClass API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] IngressClass API
      tear down framework | framework.go:193
    STEP: Destroying namespace "ingressclass-7655" for this suite. 04/23/23 12:20:07.121
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:20:07.14
Apr 23 12:20:07.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename runtimeclass 04/23/23 12:20:07.145
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:07.186
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:07.196
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:31
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Apr 23 12:20:07.239: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-6674 to be scheduled
Apr 23 12:20:07.253: INFO: 1 pods are not scheduled: [runtimeclass-6674/test-runtimeclass-runtimeclass-6674-preconfigured-handler-tvrcx(c31c0279-f14d-4fc8-9778-34bdadcae0e7)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/node/init/init.go:32
Apr 23 12:20:09.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] RuntimeClass
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] RuntimeClass
  tear down framework | framework.go:193
STEP: Destroying namespace "runtimeclass-6674" for this suite. 04/23/23 12:20:09.297
------------------------------
â€¢ [2.174 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:20:07.14
    Apr 23 12:20:07.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename runtimeclass 04/23/23 12:20:07.145
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:07.186
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:07.196
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:31
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Apr 23 12:20:07.239: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-6674 to be scheduled
    Apr 23 12:20:07.253: INFO: 1 pods are not scheduled: [runtimeclass-6674/test-runtimeclass-runtimeclass-6674-preconfigured-handler-tvrcx(c31c0279-f14d-4fc8-9778-34bdadcae0e7)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:20:09.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      tear down framework | framework.go:193
    STEP: Destroying namespace "runtimeclass-6674" for this suite. 04/23/23 12:20:09.297
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:169
[BeforeEach] [sig-node] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:20:09.326
Apr 23 12:20:09.326: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 12:20:09.331
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:09.377
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:09.383
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:169
STEP: creating a ConfigMap 04/23/23 12:20:09.407
STEP: fetching the ConfigMap 04/23/23 12:20:09.423
STEP: patching the ConfigMap 04/23/23 12:20:09.437
STEP: listing all ConfigMaps in all namespaces with a label selector 04/23/23 12:20:09.456
STEP: deleting the ConfigMap by collection with a label selector 04/23/23 12:20:09.465
STEP: listing all ConfigMaps in test namespace 04/23/23 12:20:09.507
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 12:20:09.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-9161" for this suite. 04/23/23 12:20:09.529
------------------------------
â€¢ [0.222 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:169

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:20:09.326
    Apr 23 12:20:09.326: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 12:20:09.331
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:09.377
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:09.383
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:169
    STEP: creating a ConfigMap 04/23/23 12:20:09.407
    STEP: fetching the ConfigMap 04/23/23 12:20:09.423
    STEP: patching the ConfigMap 04/23/23 12:20:09.437
    STEP: listing all ConfigMaps in all namespaces with a label selector 04/23/23 12:20:09.456
    STEP: deleting the ConfigMap by collection with a label selector 04/23/23 12:20:09.465
    STEP: listing all ConfigMaps in test namespace 04/23/23 12:20:09.507
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:20:09.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-9161" for this suite. 04/23/23 12:20:09.529
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:268
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:20:09.548
Apr 23 12:20:09.548: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename namespaces 04/23/23 12:20:09.55
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:09.623
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:09.63
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:31
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:268
STEP: creating a Namespace 04/23/23 12:20:09.641
STEP: patching the Namespace 04/23/23 12:20:09.684
STEP: get the Namespace and ensuring it has the label 04/23/23 12:20:09.711
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:20:09.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "namespaces-2080" for this suite. 04/23/23 12:20:09.733
STEP: Destroying namespace "nspatchtest-336cdf57-6ee2-49f9-abb8-757a8626ad21-7573" for this suite. 04/23/23 12:20:09.752
------------------------------
â€¢ [0.216 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:20:09.548
    Apr 23 12:20:09.548: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename namespaces 04/23/23 12:20:09.55
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:09.623
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:09.63
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:268
    STEP: creating a Namespace 04/23/23 12:20:09.641
    STEP: patching the Namespace 04/23/23 12:20:09.684
    STEP: get the Namespace and ensuring it has the label 04/23/23 12:20:09.711
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:20:09.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "namespaces-2080" for this suite. 04/23/23 12:20:09.733
    STEP: Destroying namespace "nspatchtest-336cdf57-6ee2-49f9-abb8-757a8626ad21-7573" for this suite. 04/23/23 12:20:09.752
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:20:09.768
Apr 23 12:20:09.769: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename subpath 04/23/23 12:20:09.77
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:09.806
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:09.812
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/23/23 12:20:09.823
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-mqws 04/23/23 12:20:09.85
STEP: Creating a pod to test atomic-volume-subpath 04/23/23 12:20:09.85
Apr 23 12:20:09.888: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-mqws" in namespace "subpath-7296" to be "Succeeded or Failed"
Apr 23 12:20:09.894: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Pending", Reason="", readiness=false. Elapsed: 6.475903ms
Apr 23 12:20:11.917: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028989007s
Apr 23 12:20:13.905: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 4.016813971s
Apr 23 12:20:15.904: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 6.015684466s
Apr 23 12:20:17.903: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 8.015024546s
Apr 23 12:20:19.904: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 10.016070703s
Apr 23 12:20:21.902: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 12.014160524s
Apr 23 12:20:23.902: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 14.01381487s
Apr 23 12:20:25.903: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 16.014803283s
Apr 23 12:20:27.905: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 18.017019851s
Apr 23 12:20:29.904: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 20.016469822s
Apr 23 12:20:31.903: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 22.015332967s
Apr 23 12:20:33.914: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=false. Elapsed: 24.026290389s
Apr 23 12:20:35.902: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.014054352s
STEP: Saw pod success 04/23/23 12:20:35.902
Apr 23 12:20:35.902: INFO: Pod "pod-subpath-test-projected-mqws" satisfied condition "Succeeded or Failed"
Apr 23 12:20:35.915: INFO: Trying to get logs from node eingavuivie7-3 pod pod-subpath-test-projected-mqws container test-container-subpath-projected-mqws: <nil>
STEP: delete the pod 04/23/23 12:20:35.929
Apr 23 12:20:35.957: INFO: Waiting for pod pod-subpath-test-projected-mqws to disappear
Apr 23 12:20:35.965: INFO: Pod pod-subpath-test-projected-mqws no longer exists
STEP: Deleting pod pod-subpath-test-projected-mqws 04/23/23 12:20:35.965
Apr 23 12:20:35.965: INFO: Deleting pod "pod-subpath-test-projected-mqws" in namespace "subpath-7296"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/node/init/init.go:32
Apr 23 12:20:35.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Subpath
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Subpath
  tear down framework | framework.go:193
STEP: Destroying namespace "subpath-7296" for this suite. 04/23/23 12:20:35.988
------------------------------
â€¢ [SLOW TEST] [26.242 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:20:09.768
    Apr 23 12:20:09.769: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename subpath 04/23/23 12:20:09.77
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:09.806
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:09.812
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/23/23 12:20:09.823
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-mqws 04/23/23 12:20:09.85
    STEP: Creating a pod to test atomic-volume-subpath 04/23/23 12:20:09.85
    Apr 23 12:20:09.888: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-mqws" in namespace "subpath-7296" to be "Succeeded or Failed"
    Apr 23 12:20:09.894: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Pending", Reason="", readiness=false. Elapsed: 6.475903ms
    Apr 23 12:20:11.917: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028989007s
    Apr 23 12:20:13.905: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 4.016813971s
    Apr 23 12:20:15.904: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 6.015684466s
    Apr 23 12:20:17.903: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 8.015024546s
    Apr 23 12:20:19.904: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 10.016070703s
    Apr 23 12:20:21.902: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 12.014160524s
    Apr 23 12:20:23.902: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 14.01381487s
    Apr 23 12:20:25.903: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 16.014803283s
    Apr 23 12:20:27.905: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 18.017019851s
    Apr 23 12:20:29.904: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 20.016469822s
    Apr 23 12:20:31.903: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=true. Elapsed: 22.015332967s
    Apr 23 12:20:33.914: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Running", Reason="", readiness=false. Elapsed: 24.026290389s
    Apr 23 12:20:35.902: INFO: Pod "pod-subpath-test-projected-mqws": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.014054352s
    STEP: Saw pod success 04/23/23 12:20:35.902
    Apr 23 12:20:35.902: INFO: Pod "pod-subpath-test-projected-mqws" satisfied condition "Succeeded or Failed"
    Apr 23 12:20:35.915: INFO: Trying to get logs from node eingavuivie7-3 pod pod-subpath-test-projected-mqws container test-container-subpath-projected-mqws: <nil>
    STEP: delete the pod 04/23/23 12:20:35.929
    Apr 23 12:20:35.957: INFO: Waiting for pod pod-subpath-test-projected-mqws to disappear
    Apr 23 12:20:35.965: INFO: Pod pod-subpath-test-projected-mqws no longer exists
    STEP: Deleting pod pod-subpath-test-projected-mqws 04/23/23 12:20:35.965
    Apr 23 12:20:35.965: INFO: Deleting pod "pod-subpath-test-projected-mqws" in namespace "subpath-7296"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:20:35.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Subpath
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Subpath
      tear down framework | framework.go:193
    STEP: Destroying namespace "subpath-7296" for this suite. 04/23/23 12:20:35.988
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:20:36.012
Apr 23 12:20:36.012: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pods 04/23/23 12:20:36.015
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:36.055
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:36.059
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 04/23/23 12:20:36.064
STEP: submitting the pod to kubernetes 04/23/23 12:20:36.064
STEP: verifying QOS class is set on the pod 04/23/23 12:20:36.091
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/node/init/init.go:32
Apr 23 12:20:36.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods Extended
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods Extended
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods Extended
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-9639" for this suite. 04/23/23 12:20:36.113
------------------------------
â€¢ [0.124 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:20:36.012
    Apr 23 12:20:36.012: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pods 04/23/23 12:20:36.015
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:36.055
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:36.059
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 04/23/23 12:20:36.064
    STEP: submitting the pod to kubernetes 04/23/23 12:20:36.064
    STEP: verifying QOS class is set on the pod 04/23/23 12:20:36.091
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:20:36.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods Extended
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods Extended
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods Extended
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-9639" for this suite. 04/23/23 12:20:36.113
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:239
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:20:36.143
Apr 23 12:20:36.143: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 12:20:36.146
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:36.171
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:36.174
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 12:20:36.202
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:20:36.762
STEP: Deploying the webhook pod 04/23/23 12:20:36.775
STEP: Wait for the deployment to be ready 04/23/23 12:20:36.799
Apr 23 12:20:36.830: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/23/23 12:20:38.849
STEP: Verifying the service has paired with the endpoint 04/23/23 12:20:38.883
Apr 23 12:20:39.884: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:239
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 04/23/23 12:20:39.893
STEP: create a namespace for the webhook 04/23/23 12:20:39.931
STEP: create a configmap should be unconditionally rejected by the webhook 04/23/23 12:20:39.955
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:20:40.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-2908" for this suite. 04/23/23 12:20:40.232
STEP: Destroying namespace "webhook-2908-markers" for this suite. 04/23/23 12:20:40.297
------------------------------
â€¢ [4.182 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:20:36.143
    Apr 23 12:20:36.143: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 12:20:36.146
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:36.171
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:36.174
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 12:20:36.202
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:20:36.762
    STEP: Deploying the webhook pod 04/23/23 12:20:36.775
    STEP: Wait for the deployment to be ready 04/23/23 12:20:36.799
    Apr 23 12:20:36.830: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/23/23 12:20:38.849
    STEP: Verifying the service has paired with the endpoint 04/23/23 12:20:38.883
    Apr 23 12:20:39.884: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:239
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 04/23/23 12:20:39.893
    STEP: create a namespace for the webhook 04/23/23 12:20:39.931
    STEP: create a configmap should be unconditionally rejected by the webhook 04/23/23 12:20:39.955
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:20:40.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-2908" for this suite. 04/23/23 12:20:40.232
    STEP: Destroying namespace "webhook-2908-markers" for this suite. 04/23/23 12:20:40.297
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:174
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:20:40.333
Apr 23 12:20:40.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 12:20:40.338
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:40.384
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:40.388
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:174
STEP: Creating configMap with name cm-test-opt-del-70e6dcb0-7d22-479c-8f34-348008516d03 04/23/23 12:20:40.409
STEP: Creating configMap with name cm-test-opt-upd-ee3a5a0e-5dfe-469e-8f2e-a3c9939f13f2 04/23/23 12:20:40.431
STEP: Creating the pod 04/23/23 12:20:40.453
Apr 23 12:20:40.531: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c" in namespace "projected-2620" to be "running and ready"
Apr 23 12:20:40.579: INFO: Pod "pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c": Phase="Pending", Reason="", readiness=false. Elapsed: 47.812288ms
Apr 23 12:20:40.579: INFO: The phase of Pod pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:20:42.598: INFO: Pod "pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067296723s
Apr 23 12:20:42.598: INFO: The phase of Pod pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:20:44.588: INFO: Pod "pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c": Phase="Running", Reason="", readiness=true. Elapsed: 4.056584078s
Apr 23 12:20:44.588: INFO: The phase of Pod pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c is Running (Ready = true)
Apr 23 12:20:44.588: INFO: Pod "pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-70e6dcb0-7d22-479c-8f34-348008516d03 04/23/23 12:20:44.633
STEP: Updating configmap cm-test-opt-upd-ee3a5a0e-5dfe-469e-8f2e-a3c9939f13f2 04/23/23 12:20:44.641
STEP: Creating configMap with name cm-test-opt-create-88524898-23cc-4cfe-a2cf-e8479228fb4d 04/23/23 12:20:44.65
STEP: waiting to observe update in volume 04/23/23 12:20:44.657
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Apr 23 12:21:51.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-2620" for this suite. 04/23/23 12:21:51.683
------------------------------
â€¢ [SLOW TEST] [71.365 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:20:40.333
    Apr 23 12:20:40.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 12:20:40.338
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:20:40.384
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:20:40.388
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:174
    STEP: Creating configMap with name cm-test-opt-del-70e6dcb0-7d22-479c-8f34-348008516d03 04/23/23 12:20:40.409
    STEP: Creating configMap with name cm-test-opt-upd-ee3a5a0e-5dfe-469e-8f2e-a3c9939f13f2 04/23/23 12:20:40.431
    STEP: Creating the pod 04/23/23 12:20:40.453
    Apr 23 12:20:40.531: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c" in namespace "projected-2620" to be "running and ready"
    Apr 23 12:20:40.579: INFO: Pod "pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c": Phase="Pending", Reason="", readiness=false. Elapsed: 47.812288ms
    Apr 23 12:20:40.579: INFO: The phase of Pod pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:20:42.598: INFO: Pod "pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067296723s
    Apr 23 12:20:42.598: INFO: The phase of Pod pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:20:44.588: INFO: Pod "pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c": Phase="Running", Reason="", readiness=true. Elapsed: 4.056584078s
    Apr 23 12:20:44.588: INFO: The phase of Pod pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c is Running (Ready = true)
    Apr 23 12:20:44.588: INFO: Pod "pod-projected-configmaps-952500d8-722e-4ab2-bc15-c58e9c5bdf2c" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-70e6dcb0-7d22-479c-8f34-348008516d03 04/23/23 12:20:44.633
    STEP: Updating configmap cm-test-opt-upd-ee3a5a0e-5dfe-469e-8f2e-a3c9939f13f2 04/23/23 12:20:44.641
    STEP: Creating configMap with name cm-test-opt-create-88524898-23cc-4cfe-a2cf-e8479228fb4d 04/23/23 12:20:44.65
    STEP: waiting to observe update in volume 04/23/23 12:20:44.657
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:21:51.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-2620" for this suite. 04/23/23 12:21:51.683
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:697
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:21:51.707
Apr 23 12:21:51.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename statefulset 04/23/23 12:21:51.712
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:21:51.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:21:51.749
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-6407 04/23/23 12:21:51.757
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:697
STEP: Creating stateful set ss in namespace statefulset-6407 04/23/23 12:21:51.771
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6407 04/23/23 12:21:51.788
Apr 23 12:21:51.795: INFO: Found 0 stateful pods, waiting for 1
Apr 23 12:22:01.804: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 04/23/23 12:22:01.804
Apr 23 12:22:01.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-6407 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 23 12:22:02.157: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 23 12:22:02.157: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 23 12:22:02.157: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 23 12:22:02.166: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 23 12:22:12.175: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 12:22:12.176: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 12:22:12.227: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr 23 12:22:12.227: INFO: ss-0  eingavuivie7-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:21:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:21:51 +0000 UTC  }]
Apr 23 12:22:12.227: INFO: 
Apr 23 12:22:12.227: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 23 12:22:13.241: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.97247903s
Apr 23 12:22:14.273: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.958297596s
Apr 23 12:22:15.281: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.925941986s
Apr 23 12:22:16.290: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.918606444s
Apr 23 12:22:17.297: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.909294057s
Apr 23 12:22:18.305: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.902542549s
Apr 23 12:22:19.316: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.894537885s
Apr 23 12:22:20.325: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.883731393s
Apr 23 12:22:21.337: INFO: Verifying statefulset ss doesn't scale past 3 for another 874.525112ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6407 04/23/23 12:22:22.338
Apr 23 12:22:22.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-6407 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 23 12:22:22.699: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 23 12:22:22.699: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 23 12:22:22.699: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 23 12:22:22.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-6407 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 23 12:22:23.035: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 23 12:22:23.035: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 23 12:22:23.035: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 23 12:22:23.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-6407 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 23 12:22:23.337: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 23 12:22:23.337: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 23 12:22:23.337: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 23 12:22:23.347: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 12:22:23.347: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 23 12:22:23.347: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 04/23/23 12:22:23.347
Apr 23 12:22:23.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-6407 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 23 12:22:23.743: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 23 12:22:23.743: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 23 12:22:23.743: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 23 12:22:23.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-6407 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 23 12:22:24.066: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 23 12:22:24.066: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 23 12:22:24.066: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 23 12:22:24.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-6407 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 23 12:22:24.429: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 23 12:22:24.429: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 23 12:22:24.429: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 23 12:22:24.429: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 12:22:24.437: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 23 12:22:34.455: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 12:22:34.455: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 12:22:34.455: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 23 12:22:34.488: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr 23 12:22:34.488: INFO: ss-0  eingavuivie7-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:21:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:21:51 +0000 UTC  }]
Apr 23 12:22:34.488: INFO: ss-1  eingavuivie7-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:12 +0000 UTC  }]
Apr 23 12:22:34.488: INFO: ss-2  eingavuivie7-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:12 +0000 UTC  }]
Apr 23 12:22:34.488: INFO: 
Apr 23 12:22:34.488: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 23 12:22:35.538: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Apr 23 12:22:35.538: INFO: ss-0  eingavuivie7-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:21:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:21:51 +0000 UTC  }]
Apr 23 12:22:35.538: INFO: 
Apr 23 12:22:35.538: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 23 12:22:36.550: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.934120642s
Apr 23 12:22:37.556: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.922442591s
Apr 23 12:22:38.579: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.915490558s
Apr 23 12:22:39.585: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.893890238s
Apr 23 12:22:40.597: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.886989097s
Apr 23 12:22:41.604: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.875221134s
Apr 23 12:22:42.623: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.867816038s
Apr 23 12:22:43.632: INFO: Verifying statefulset ss doesn't scale past 0 for another 849.341211ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6407 04/23/23 12:22:44.633
Apr 23 12:22:44.652: INFO: Scaling statefulset ss to 0
Apr 23 12:22:44.682: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Apr 23 12:22:44.689: INFO: Deleting all statefulset in ns statefulset-6407
Apr 23 12:22:44.699: INFO: Scaling statefulset ss to 0
Apr 23 12:22:44.727: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 12:22:44.735: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Apr 23 12:22:44.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-6407" for this suite. 04/23/23 12:22:44.795
------------------------------
â€¢ [SLOW TEST] [53.105 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:697

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:21:51.707
    Apr 23 12:21:51.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename statefulset 04/23/23 12:21:51.712
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:21:51.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:21:51.749
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-6407 04/23/23 12:21:51.757
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:697
    STEP: Creating stateful set ss in namespace statefulset-6407 04/23/23 12:21:51.771
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6407 04/23/23 12:21:51.788
    Apr 23 12:21:51.795: INFO: Found 0 stateful pods, waiting for 1
    Apr 23 12:22:01.804: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 04/23/23 12:22:01.804
    Apr 23 12:22:01.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-6407 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 23 12:22:02.157: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 23 12:22:02.157: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 23 12:22:02.157: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 23 12:22:02.166: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Apr 23 12:22:12.175: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 23 12:22:12.176: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 23 12:22:12.227: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
    Apr 23 12:22:12.227: INFO: ss-0  eingavuivie7-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:21:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:21:51 +0000 UTC  }]
    Apr 23 12:22:12.227: INFO: 
    Apr 23 12:22:12.227: INFO: StatefulSet ss has not reached scale 3, at 1
    Apr 23 12:22:13.241: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.97247903s
    Apr 23 12:22:14.273: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.958297596s
    Apr 23 12:22:15.281: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.925941986s
    Apr 23 12:22:16.290: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.918606444s
    Apr 23 12:22:17.297: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.909294057s
    Apr 23 12:22:18.305: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.902542549s
    Apr 23 12:22:19.316: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.894537885s
    Apr 23 12:22:20.325: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.883731393s
    Apr 23 12:22:21.337: INFO: Verifying statefulset ss doesn't scale past 3 for another 874.525112ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6407 04/23/23 12:22:22.338
    Apr 23 12:22:22.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-6407 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 23 12:22:22.699: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 23 12:22:22.699: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 23 12:22:22.699: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 23 12:22:22.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-6407 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 23 12:22:23.035: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Apr 23 12:22:23.035: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 23 12:22:23.035: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 23 12:22:23.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-6407 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 23 12:22:23.337: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Apr 23 12:22:23.337: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 23 12:22:23.337: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 23 12:22:23.347: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 23 12:22:23.347: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 23 12:22:23.347: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 04/23/23 12:22:23.347
    Apr 23 12:22:23.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-6407 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 23 12:22:23.743: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 23 12:22:23.743: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 23 12:22:23.743: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 23 12:22:23.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-6407 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 23 12:22:24.066: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 23 12:22:24.066: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 23 12:22:24.066: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 23 12:22:24.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=statefulset-6407 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 23 12:22:24.429: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 23 12:22:24.429: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 23 12:22:24.429: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 23 12:22:24.429: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 23 12:22:24.437: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Apr 23 12:22:34.455: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 23 12:22:34.455: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Apr 23 12:22:34.455: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Apr 23 12:22:34.488: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
    Apr 23 12:22:34.488: INFO: ss-0  eingavuivie7-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:21:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:21:51 +0000 UTC  }]
    Apr 23 12:22:34.488: INFO: ss-1  eingavuivie7-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:12 +0000 UTC  }]
    Apr 23 12:22:34.488: INFO: ss-2  eingavuivie7-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:12 +0000 UTC  }]
    Apr 23 12:22:34.488: INFO: 
    Apr 23 12:22:34.488: INFO: StatefulSet ss has not reached scale 0, at 3
    Apr 23 12:22:35.538: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
    Apr 23 12:22:35.538: INFO: ss-0  eingavuivie7-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:21:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:22:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:21:51 +0000 UTC  }]
    Apr 23 12:22:35.538: INFO: 
    Apr 23 12:22:35.538: INFO: StatefulSet ss has not reached scale 0, at 1
    Apr 23 12:22:36.550: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.934120642s
    Apr 23 12:22:37.556: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.922442591s
    Apr 23 12:22:38.579: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.915490558s
    Apr 23 12:22:39.585: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.893890238s
    Apr 23 12:22:40.597: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.886989097s
    Apr 23 12:22:41.604: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.875221134s
    Apr 23 12:22:42.623: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.867816038s
    Apr 23 12:22:43.632: INFO: Verifying statefulset ss doesn't scale past 0 for another 849.341211ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6407 04/23/23 12:22:44.633
    Apr 23 12:22:44.652: INFO: Scaling statefulset ss to 0
    Apr 23 12:22:44.682: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Apr 23 12:22:44.689: INFO: Deleting all statefulset in ns statefulset-6407
    Apr 23 12:22:44.699: INFO: Scaling statefulset ss to 0
    Apr 23 12:22:44.727: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 23 12:22:44.735: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:22:44.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-6407" for this suite. 04/23/23 12:22:44.795
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:22:44.815
Apr 23 12:22:44.816: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename replicaset 04/23/23 12:22:44.826
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:22:44.867
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:22:44.875
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:31
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Apr 23 12:22:44.885: INFO: Creating ReplicaSet my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d
Apr 23 12:22:44.934: INFO: Pod name my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d: Found 0 pods out of 1
Apr 23 12:22:49.951: INFO: Pod name my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d: Found 1 pods out of 1
Apr 23 12:22:49.951: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d" is running
Apr 23 12:22:49.952: INFO: Waiting up to 5m0s for pod "my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d-cdkp7" in namespace "replicaset-744" to be "running"
Apr 23 12:22:49.962: INFO: Pod "my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d-cdkp7": Phase="Running", Reason="", readiness=true. Elapsed: 10.256263ms
Apr 23 12:22:49.962: INFO: Pod "my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d-cdkp7" satisfied condition "running"
Apr 23 12:22:49.962: INFO: Pod "my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d-cdkp7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:22:44 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:22:47 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:22:47 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:22:44 +0000 UTC Reason: Message:}])
Apr 23 12:22:49.962: INFO: Trying to dial the pod
Apr 23 12:22:54.995: INFO: Controller my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d: Got expected result from replica 1 [my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d-cdkp7]: "my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d-cdkp7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/node/init/init.go:32
Apr 23 12:22:54.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  tear down framework | framework.go:193
STEP: Destroying namespace "replicaset-744" for this suite. 04/23/23 12:22:55.01
------------------------------
â€¢ [SLOW TEST] [10.215 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:22:44.815
    Apr 23 12:22:44.816: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename replicaset 04/23/23 12:22:44.826
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:22:44.867
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:22:44.875
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:31
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Apr 23 12:22:44.885: INFO: Creating ReplicaSet my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d
    Apr 23 12:22:44.934: INFO: Pod name my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d: Found 0 pods out of 1
    Apr 23 12:22:49.951: INFO: Pod name my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d: Found 1 pods out of 1
    Apr 23 12:22:49.951: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d" is running
    Apr 23 12:22:49.952: INFO: Waiting up to 5m0s for pod "my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d-cdkp7" in namespace "replicaset-744" to be "running"
    Apr 23 12:22:49.962: INFO: Pod "my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d-cdkp7": Phase="Running", Reason="", readiness=true. Elapsed: 10.256263ms
    Apr 23 12:22:49.962: INFO: Pod "my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d-cdkp7" satisfied condition "running"
    Apr 23 12:22:49.962: INFO: Pod "my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d-cdkp7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:22:44 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:22:47 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:22:47 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-23 12:22:44 +0000 UTC Reason: Message:}])
    Apr 23 12:22:49.962: INFO: Trying to dial the pod
    Apr 23 12:22:54.995: INFO: Controller my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d: Got expected result from replica 1 [my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d-cdkp7]: "my-hostname-basic-6838deae-68c8-4c48-89fd-d0181145489d-cdkp7", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:22:54.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "replicaset-744" for this suite. 04/23/23 12:22:55.01
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:22:55.032
Apr 23 12:22:55.033: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename csistoragecapacity 04/23/23 12:22:55.036
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:22:55.078
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:22:55.087
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/metrics/init/init.go:31
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 04/23/23 12:22:55.098
STEP: getting /apis/storage.k8s.io 04/23/23 12:22:55.106
STEP: getting /apis/storage.k8s.io/v1 04/23/23 12:22:55.108
STEP: creating 04/23/23 12:22:55.113
STEP: watching 04/23/23 12:22:55.17
Apr 23 12:22:55.171: INFO: starting watch
STEP: getting 04/23/23 12:22:55.189
STEP: listing in namespace 04/23/23 12:22:55.195
STEP: listing across namespaces 04/23/23 12:22:55.202
STEP: patching 04/23/23 12:22:55.21
STEP: updating 04/23/23 12:22:55.223
Apr 23 12:22:55.236: INFO: waiting for watch events with expected annotations in namespace
Apr 23 12:22:55.236: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 04/23/23 12:22:55.237
STEP: deleting a collection 04/23/23 12:22:55.276
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/node/init/init.go:32
Apr 23 12:22:55.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] CSIStorageCapacity
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] CSIStorageCapacity
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] CSIStorageCapacity
  tear down framework | framework.go:193
STEP: Destroying namespace "csistoragecapacity-6481" for this suite. 04/23/23 12:22:55.352
------------------------------
â€¢ [0.349 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:22:55.032
    Apr 23 12:22:55.033: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename csistoragecapacity 04/23/23 12:22:55.036
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:22:55.078
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:22:55.087
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/metrics/init/init.go:31
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 04/23/23 12:22:55.098
    STEP: getting /apis/storage.k8s.io 04/23/23 12:22:55.106
    STEP: getting /apis/storage.k8s.io/v1 04/23/23 12:22:55.108
    STEP: creating 04/23/23 12:22:55.113
    STEP: watching 04/23/23 12:22:55.17
    Apr 23 12:22:55.171: INFO: starting watch
    STEP: getting 04/23/23 12:22:55.189
    STEP: listing in namespace 04/23/23 12:22:55.195
    STEP: listing across namespaces 04/23/23 12:22:55.202
    STEP: patching 04/23/23 12:22:55.21
    STEP: updating 04/23/23 12:22:55.223
    Apr 23 12:22:55.236: INFO: waiting for watch events with expected annotations in namespace
    Apr 23 12:22:55.236: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 04/23/23 12:22:55.237
    STEP: deleting a collection 04/23/23 12:22:55.276
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:22:55.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] CSIStorageCapacity
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] CSIStorageCapacity
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] CSIStorageCapacity
      tear down framework | framework.go:193
    STEP: Destroying namespace "csistoragecapacity-6481" for this suite. 04/23/23 12:22:55.352
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:823
[BeforeEach] [sig-apps] Daemon set [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:22:55.381
Apr 23 12:22:55.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename daemonsets 04/23/23 12:22:55.383
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:22:55.417
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:22:55.425
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:146
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:823
STEP: Creating simple DaemonSet "daemon-set" 04/23/23 12:22:55.535
STEP: Check that daemon pods launch on every node of the cluster. 04/23/23 12:22:55.549
Apr 23 12:22:55.571: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 12:22:55.571: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:22:56.627: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 12:22:56.627: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:22:57.588: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 12:22:57.588: INFO: Node eingavuivie7-3 is running 0 daemon pod, expected 1
Apr 23 12:22:58.595: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 23 12:22:58.595: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 04/23/23 12:22:58.602
STEP: DeleteCollection of the DaemonSets 04/23/23 12:22:58.609
STEP: Verify that ReplicaSets have been deleted 04/23/23 12:22:58.63
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:111
Apr 23 12:22:58.677: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"31116"},"items":null}

Apr 23 12:22:58.686: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"31116"},"items":[{"metadata":{"name":"daemon-set-h9qlr","generateName":"daemon-set-","namespace":"daemonsets-1190","uid":"d10a1ea6-1a27-49d8-87c8-c5178b1d056c","resourceVersion":"31115","creationTimestamp":"2023-04-23T12:22:55Z","deletionTimestamp":"2023-04-23T12:23:28Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6cff669f8c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f5b3922d-e5f5-4091-83c7-5701a8e0164f","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-23T12:22:55Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5b3922d-e5f5-4091-83c7-5701a8e0164f\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-23T12:22:57Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.74\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-xpbnx","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-xpbnx","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"eingavuivie7-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["eingavuivie7-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:55Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:57Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:57Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:55Z"}],"hostIP":"192.168.121.130","podIP":"10.233.65.74","podIPs":[{"ip":"10.233.65.74"}],"startTime":"2023-04-23T12:22:55Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-23T12:22:56Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://beeb6f219b9c1d11cf4a01f768cf55141f1049b674f305b8f9b886932a9ed1e1","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-s6gmw","generateName":"daemon-set-","namespace":"daemonsets-1190","uid":"8dd7b267-311c-4642-a0c7-4b27888dfebe","resourceVersion":"31116","creationTimestamp":"2023-04-23T12:22:55Z","deletionTimestamp":"2023-04-23T12:23:28Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6cff669f8c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f5b3922d-e5f5-4091-83c7-5701a8e0164f","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-23T12:22:55Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5b3922d-e5f5-4091-83c7-5701a8e0164f\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-23T12:22:58Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.235\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-bkz2f","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-bkz2f","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"eingavuivie7-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["eingavuivie7-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:55Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:58Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:58Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:55Z"}],"hostIP":"192.168.121.198","podIP":"10.233.64.235","podIPs":[{"ip":"10.233.64.235"}],"startTime":"2023-04-23T12:22:55Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-23T12:22:57Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://2395a816c31641b01727a178459cc9ea1976d47dc6b0bc213df957088d8dc79f","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-smg7h","generateName":"daemon-set-","namespace":"daemonsets-1190","uid":"d08105dd-6877-446d-a313-c61ce478a5ae","resourceVersion":"31113","creationTimestamp":"2023-04-23T12:22:55Z","deletionTimestamp":"2023-04-23T12:23:28Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6cff669f8c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f5b3922d-e5f5-4091-83c7-5701a8e0164f","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-23T12:22:55Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5b3922d-e5f5-4091-83c7-5701a8e0164f\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-23T12:22:57Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-vdgxq","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-vdgxq","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"eingavuivie7-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["eingavuivie7-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:55Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:57Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:57Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:55Z"}],"hostIP":"192.168.121.214","podIP":"10.233.66.15","podIPs":[{"ip":"10.233.66.15"}],"startTime":"2023-04-23T12:22:55Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-23T12:22:56Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://67f51677fd71072b36ece159d9df1ae9f2cc7cd6b9be96869c64c408ea0d01b3","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:22:58.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "daemonsets-1190" for this suite. 04/23/23 12:22:58.732
------------------------------
â€¢ [3.372 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:823

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:22:55.381
    Apr 23 12:22:55.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename daemonsets 04/23/23 12:22:55.383
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:22:55.417
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:22:55.425
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:146
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:823
    STEP: Creating simple DaemonSet "daemon-set" 04/23/23 12:22:55.535
    STEP: Check that daemon pods launch on every node of the cluster. 04/23/23 12:22:55.549
    Apr 23 12:22:55.571: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 12:22:55.571: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:22:56.627: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 12:22:56.627: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:22:57.588: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 12:22:57.588: INFO: Node eingavuivie7-3 is running 0 daemon pod, expected 1
    Apr 23 12:22:58.595: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 23 12:22:58.595: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 04/23/23 12:22:58.602
    STEP: DeleteCollection of the DaemonSets 04/23/23 12:22:58.609
    STEP: Verify that ReplicaSets have been deleted 04/23/23 12:22:58.63
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:111
    Apr 23 12:22:58.677: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"31116"},"items":null}

    Apr 23 12:22:58.686: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"31116"},"items":[{"metadata":{"name":"daemon-set-h9qlr","generateName":"daemon-set-","namespace":"daemonsets-1190","uid":"d10a1ea6-1a27-49d8-87c8-c5178b1d056c","resourceVersion":"31115","creationTimestamp":"2023-04-23T12:22:55Z","deletionTimestamp":"2023-04-23T12:23:28Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6cff669f8c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f5b3922d-e5f5-4091-83c7-5701a8e0164f","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-23T12:22:55Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5b3922d-e5f5-4091-83c7-5701a8e0164f\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-23T12:22:57Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.74\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-xpbnx","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-xpbnx","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"eingavuivie7-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["eingavuivie7-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:55Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:57Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:57Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:55Z"}],"hostIP":"192.168.121.130","podIP":"10.233.65.74","podIPs":[{"ip":"10.233.65.74"}],"startTime":"2023-04-23T12:22:55Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-23T12:22:56Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://beeb6f219b9c1d11cf4a01f768cf55141f1049b674f305b8f9b886932a9ed1e1","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-s6gmw","generateName":"daemon-set-","namespace":"daemonsets-1190","uid":"8dd7b267-311c-4642-a0c7-4b27888dfebe","resourceVersion":"31116","creationTimestamp":"2023-04-23T12:22:55Z","deletionTimestamp":"2023-04-23T12:23:28Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6cff669f8c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f5b3922d-e5f5-4091-83c7-5701a8e0164f","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-23T12:22:55Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5b3922d-e5f5-4091-83c7-5701a8e0164f\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-23T12:22:58Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.235\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-bkz2f","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-bkz2f","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"eingavuivie7-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["eingavuivie7-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:55Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:58Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:58Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:55Z"}],"hostIP":"192.168.121.198","podIP":"10.233.64.235","podIPs":[{"ip":"10.233.64.235"}],"startTime":"2023-04-23T12:22:55Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-23T12:22:57Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://2395a816c31641b01727a178459cc9ea1976d47dc6b0bc213df957088d8dc79f","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-smg7h","generateName":"daemon-set-","namespace":"daemonsets-1190","uid":"d08105dd-6877-446d-a313-c61ce478a5ae","resourceVersion":"31113","creationTimestamp":"2023-04-23T12:22:55Z","deletionTimestamp":"2023-04-23T12:23:28Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"6cff669f8c","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f5b3922d-e5f5-4091-83c7-5701a8e0164f","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-23T12:22:55Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f5b3922d-e5f5-4091-83c7-5701a8e0164f\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-23T12:22:57Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-vdgxq","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-vdgxq","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"eingavuivie7-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["eingavuivie7-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:55Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:57Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:57Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-23T12:22:55Z"}],"hostIP":"192.168.121.214","podIP":"10.233.66.15","podIPs":[{"ip":"10.233.66.15"}],"startTime":"2023-04-23T12:22:55Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-23T12:22:56Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"cri-o://67f51677fd71072b36ece159d9df1ae9f2cc7cd6b9be96869c64c408ea0d01b3","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:22:58.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "daemonsets-1190" for this suite. 04/23/23 12:22:58.732
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:22:58.761
Apr 23 12:22:58.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename ingress 04/23/23 12:22:58.763
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:22:58.804
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:22:58.811
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/metrics/init/init.go:31
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 04/23/23 12:22:58.815
STEP: getting /apis/networking.k8s.io 04/23/23 12:22:58.819
STEP: getting /apis/networking.k8s.iov1 04/23/23 12:22:58.821
STEP: creating 04/23/23 12:22:58.823
STEP: getting 04/23/23 12:22:58.851
STEP: listing 04/23/23 12:22:58.856
STEP: watching 04/23/23 12:22:58.861
Apr 23 12:22:58.861: INFO: starting watch
STEP: cluster-wide listing 04/23/23 12:22:58.863
STEP: cluster-wide watching 04/23/23 12:22:58.869
Apr 23 12:22:58.869: INFO: starting watch
STEP: patching 04/23/23 12:22:58.871
STEP: updating 04/23/23 12:22:58.878
Apr 23 12:22:58.893: INFO: waiting for watch events with expected annotations
Apr 23 12:22:58.893: INFO: saw patched and updated annotations
STEP: patching /status 04/23/23 12:22:58.893
STEP: updating /status 04/23/23 12:22:58.904
STEP: get /status 04/23/23 12:22:58.927
STEP: deleting 04/23/23 12:22:58.933
STEP: deleting a collection 04/23/23 12:22:58.974
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/node/init/init.go:32
Apr 23 12:22:59.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Ingress API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Ingress API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Ingress API
  tear down framework | framework.go:193
STEP: Destroying namespace "ingress-54" for this suite. 04/23/23 12:22:59.042
------------------------------
â€¢ [0.317 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:22:58.761
    Apr 23 12:22:58.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename ingress 04/23/23 12:22:58.763
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:22:58.804
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:22:58.811
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/metrics/init/init.go:31
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 04/23/23 12:22:58.815
    STEP: getting /apis/networking.k8s.io 04/23/23 12:22:58.819
    STEP: getting /apis/networking.k8s.iov1 04/23/23 12:22:58.821
    STEP: creating 04/23/23 12:22:58.823
    STEP: getting 04/23/23 12:22:58.851
    STEP: listing 04/23/23 12:22:58.856
    STEP: watching 04/23/23 12:22:58.861
    Apr 23 12:22:58.861: INFO: starting watch
    STEP: cluster-wide listing 04/23/23 12:22:58.863
    STEP: cluster-wide watching 04/23/23 12:22:58.869
    Apr 23 12:22:58.869: INFO: starting watch
    STEP: patching 04/23/23 12:22:58.871
    STEP: updating 04/23/23 12:22:58.878
    Apr 23 12:22:58.893: INFO: waiting for watch events with expected annotations
    Apr 23 12:22:58.893: INFO: saw patched and updated annotations
    STEP: patching /status 04/23/23 12:22:58.893
    STEP: updating /status 04/23/23 12:22:58.904
    STEP: get /status 04/23/23 12:22:58.927
    STEP: deleting 04/23/23 12:22:58.933
    STEP: deleting a collection 04/23/23 12:22:58.974
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:22:59.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Ingress API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Ingress API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Ingress API
      tear down framework | framework.go:193
    STEP: Destroying namespace "ingress-54" for this suite. 04/23/23 12:22:59.042
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:248
[BeforeEach] [sig-node] Container Runtime
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:22:59.079
Apr 23 12:22:59.079: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-runtime 04/23/23 12:22:59.082
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:22:59.11
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:22:59.115
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:31
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:248
STEP: create the container 04/23/23 12:22:59.121
STEP: wait for the container to reach Succeeded 04/23/23 12:22:59.151
STEP: get the container status 04/23/23 12:23:03.298
STEP: the container should be terminated 04/23/23 12:23:03.304
STEP: the termination message should be set 04/23/23 12:23:03.304
Apr 23 12:23:03.304: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 04/23/23 12:23:03.304
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/node/init/init.go:32
Apr 23 12:23:03.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Runtime
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Runtime
  tear down framework | framework.go:193
STEP: Destroying namespace "container-runtime-9817" for this suite. 04/23/23 12:23:03.343
------------------------------
â€¢ [4.276 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:44
    on terminated container
    test/e2e/common/node/runtime.go:137
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:22:59.079
    Apr 23 12:22:59.079: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-runtime 04/23/23 12:22:59.082
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:22:59.11
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:22:59.115
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:31
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:248
    STEP: create the container 04/23/23 12:22:59.121
    STEP: wait for the container to reach Succeeded 04/23/23 12:22:59.151
    STEP: get the container status 04/23/23 12:23:03.298
    STEP: the container should be terminated 04/23/23 12:23:03.304
    STEP: the termination message should be set 04/23/23 12:23:03.304
    Apr 23 12:23:03.304: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 04/23/23 12:23:03.304
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:23:03.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Runtime
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Runtime
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-runtime-9817" for this suite. 04/23/23 12:23:03.343
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:23:03.357
Apr 23 12:23:03.357: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename proxy 04/23/23 12:23:03.36
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:23:03.393
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:23:03.405
[BeforeEach] version v1
  test/e2e/framework/metrics/init/init.go:31
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Apr 23 12:23:03.411: INFO: Creating pod...
Apr 23 12:23:03.455: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-801" to be "running"
Apr 23 12:23:03.463: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 7.694646ms
Apr 23 12:23:05.474: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.018666361s
Apr 23 12:23:05.474: INFO: Pod "agnhost" satisfied condition "running"
Apr 23 12:23:05.474: INFO: Creating service...
Apr 23 12:23:05.504: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/pods/agnhost/proxy/some/path/with/DELETE
Apr 23 12:23:05.538: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 23 12:23:05.538: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/pods/agnhost/proxy/some/path/with/GET
Apr 23 12:23:05.555: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr 23 12:23:05.555: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/pods/agnhost/proxy/some/path/with/HEAD
Apr 23 12:23:05.565: INFO: http.Client request:HEAD | StatusCode:200
Apr 23 12:23:05.565: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/pods/agnhost/proxy/some/path/with/OPTIONS
Apr 23 12:23:05.576: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 23 12:23:05.576: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/pods/agnhost/proxy/some/path/with/PATCH
Apr 23 12:23:05.591: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 23 12:23:05.592: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/pods/agnhost/proxy/some/path/with/POST
Apr 23 12:23:05.610: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 23 12:23:05.610: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/pods/agnhost/proxy/some/path/with/PUT
Apr 23 12:23:05.621: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 23 12:23:05.621: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/services/test-service/proxy/some/path/with/DELETE
Apr 23 12:23:05.640: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 23 12:23:05.640: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/services/test-service/proxy/some/path/with/GET
Apr 23 12:23:05.657: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr 23 12:23:05.657: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/services/test-service/proxy/some/path/with/HEAD
Apr 23 12:23:05.669: INFO: http.Client request:HEAD | StatusCode:200
Apr 23 12:23:05.669: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/services/test-service/proxy/some/path/with/OPTIONS
Apr 23 12:23:05.681: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 23 12:23:05.681: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/services/test-service/proxy/some/path/with/PATCH
Apr 23 12:23:05.696: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 23 12:23:05.697: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/services/test-service/proxy/some/path/with/POST
Apr 23 12:23:05.719: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 23 12:23:05.719: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/services/test-service/proxy/some/path/with/PUT
Apr 23 12:23:05.735: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/node/init/init.go:32
Apr 23 12:23:05.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] version v1
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] version v1
  dump namespaces | framework.go:196
[DeferCleanup (Each)] version v1
  tear down framework | framework.go:193
STEP: Destroying namespace "proxy-801" for this suite. 04/23/23 12:23:05.754
------------------------------
â€¢ [2.412 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:23:03.357
    Apr 23 12:23:03.357: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename proxy 04/23/23 12:23:03.36
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:23:03.393
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:23:03.405
    [BeforeEach] version v1
      test/e2e/framework/metrics/init/init.go:31
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Apr 23 12:23:03.411: INFO: Creating pod...
    Apr 23 12:23:03.455: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-801" to be "running"
    Apr 23 12:23:03.463: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 7.694646ms
    Apr 23 12:23:05.474: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.018666361s
    Apr 23 12:23:05.474: INFO: Pod "agnhost" satisfied condition "running"
    Apr 23 12:23:05.474: INFO: Creating service...
    Apr 23 12:23:05.504: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/pods/agnhost/proxy/some/path/with/DELETE
    Apr 23 12:23:05.538: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 23 12:23:05.538: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/pods/agnhost/proxy/some/path/with/GET
    Apr 23 12:23:05.555: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Apr 23 12:23:05.555: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/pods/agnhost/proxy/some/path/with/HEAD
    Apr 23 12:23:05.565: INFO: http.Client request:HEAD | StatusCode:200
    Apr 23 12:23:05.565: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/pods/agnhost/proxy/some/path/with/OPTIONS
    Apr 23 12:23:05.576: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 23 12:23:05.576: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/pods/agnhost/proxy/some/path/with/PATCH
    Apr 23 12:23:05.591: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 23 12:23:05.592: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/pods/agnhost/proxy/some/path/with/POST
    Apr 23 12:23:05.610: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 23 12:23:05.610: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/pods/agnhost/proxy/some/path/with/PUT
    Apr 23 12:23:05.621: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 23 12:23:05.621: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/services/test-service/proxy/some/path/with/DELETE
    Apr 23 12:23:05.640: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 23 12:23:05.640: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/services/test-service/proxy/some/path/with/GET
    Apr 23 12:23:05.657: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Apr 23 12:23:05.657: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/services/test-service/proxy/some/path/with/HEAD
    Apr 23 12:23:05.669: INFO: http.Client request:HEAD | StatusCode:200
    Apr 23 12:23:05.669: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/services/test-service/proxy/some/path/with/OPTIONS
    Apr 23 12:23:05.681: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 23 12:23:05.681: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/services/test-service/proxy/some/path/with/PATCH
    Apr 23 12:23:05.696: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 23 12:23:05.697: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/services/test-service/proxy/some/path/with/POST
    Apr 23 12:23:05.719: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 23 12:23:05.719: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-801/services/test-service/proxy/some/path/with/PUT
    Apr 23 12:23:05.735: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:23:05.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] version v1
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] version v1
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] version v1
      tear down framework | framework.go:193
    STEP: Destroying namespace "proxy-801" for this suite. 04/23/23 12:23:05.754
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:243
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:23:05.774
Apr 23 12:23:05.775: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename namespaces 04/23/23 12:23:05.778
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:23:05.837
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:23:05.843
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:31
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:243
STEP: Creating a test namespace 04/23/23 12:23:05.848
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:23:05.876
STEP: Creating a pod in the namespace 04/23/23 12:23:05.888
STEP: Waiting for the pod to have running status 04/23/23 12:23:05.912
Apr 23 12:23:05.913: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-3240" to be "running"
Apr 23 12:23:05.924: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.021585ms
Apr 23 12:23:07.936: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022446218s
Apr 23 12:23:09.934: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.021115467s
Apr 23 12:23:09.934: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 04/23/23 12:23:09.934
STEP: Waiting for the namespace to be removed. 04/23/23 12:23:09.953
STEP: Recreating the namespace 04/23/23 12:23:21.961
STEP: Verifying there are no pods in the namespace 04/23/23 12:23:21.991
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:23:21.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "namespaces-9816" for this suite. 04/23/23 12:23:22.007
STEP: Destroying namespace "nsdeletetest-3240" for this suite. 04/23/23 12:23:22.022
Apr 23 12:23:22.033: INFO: Namespace nsdeletetest-3240 was already deleted
STEP: Destroying namespace "nsdeletetest-1696" for this suite. 04/23/23 12:23:22.033
------------------------------
â€¢ [SLOW TEST] [16.272 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:243

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:23:05.774
    Apr 23 12:23:05.775: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename namespaces 04/23/23 12:23:05.778
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:23:05.837
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:23:05.843
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:243
    STEP: Creating a test namespace 04/23/23 12:23:05.848
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:23:05.876
    STEP: Creating a pod in the namespace 04/23/23 12:23:05.888
    STEP: Waiting for the pod to have running status 04/23/23 12:23:05.912
    Apr 23 12:23:05.913: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-3240" to be "running"
    Apr 23 12:23:05.924: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.021585ms
    Apr 23 12:23:07.936: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022446218s
    Apr 23 12:23:09.934: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.021115467s
    Apr 23 12:23:09.934: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 04/23/23 12:23:09.934
    STEP: Waiting for the namespace to be removed. 04/23/23 12:23:09.953
    STEP: Recreating the namespace 04/23/23 12:23:21.961
    STEP: Verifying there are no pods in the namespace 04/23/23 12:23:21.991
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:23:21.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Namespaces [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "namespaces-9816" for this suite. 04/23/23 12:23:22.007
    STEP: Destroying namespace "nsdeletetest-3240" for this suite. 04/23/23 12:23:22.022
    Apr 23 12:23:22.033: INFO: Namespace nsdeletetest-3240 was already deleted
    STEP: Destroying namespace "nsdeletetest-1696" for this suite. 04/23/23 12:23:22.033
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:386
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:23:22.047
Apr 23 12:23:22.047: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename secrets 04/23/23 12:23:22.052
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:23:22.084
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:23:22.087
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:386
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Apr 23 12:23:22.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-8157" for this suite. 04/23/23 12:23:22.179
------------------------------
â€¢ [0.146 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:386

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:23:22.047
    Apr 23 12:23:22.047: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename secrets 04/23/23 12:23:22.052
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:23:22.084
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:23:22.087
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:386
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:23:22.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-8157" for this suite. 04/23/23 12:23:22.179
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:481
[BeforeEach] [sig-apps] Job
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:23:22.196
Apr 23 12:23:22.197: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename job 04/23/23 12:23:22.201
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:23:22.236
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:23:22.241
[BeforeEach] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:31
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:481
STEP: Creating a job 04/23/23 12:23:22.245
STEP: Ensuring active pods == parallelism 04/23/23 12:23:22.253
STEP: delete a job 04/23/23 12:23:26.268
STEP: deleting Job.batch foo in namespace job-9737, will wait for the garbage collector to delete the pods 04/23/23 12:23:26.268
Apr 23 12:23:26.336: INFO: Deleting Job.batch foo took: 10.959641ms
Apr 23 12:23:26.437: INFO: Terminating Job.batch foo pods took: 101.137657ms
STEP: Ensuring job was deleted 04/23/23 12:23:58.438
[AfterEach] [sig-apps] Job
  test/e2e/framework/node/init/init.go:32
Apr 23 12:23:58.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Job
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Job
  tear down framework | framework.go:193
STEP: Destroying namespace "job-9737" for this suite. 04/23/23 12:23:58.452
------------------------------
â€¢ [SLOW TEST] [36.267 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:23:22.196
    Apr 23 12:23:22.197: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename job 04/23/23 12:23:22.201
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:23:22.236
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:23:22.241
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:31
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:481
    STEP: Creating a job 04/23/23 12:23:22.245
    STEP: Ensuring active pods == parallelism 04/23/23 12:23:22.253
    STEP: delete a job 04/23/23 12:23:26.268
    STEP: deleting Job.batch foo in namespace job-9737, will wait for the garbage collector to delete the pods 04/23/23 12:23:26.268
    Apr 23 12:23:26.336: INFO: Deleting Job.batch foo took: 10.959641ms
    Apr 23 12:23:26.437: INFO: Terminating Job.batch foo pods took: 101.137657ms
    STEP: Ensuring job was deleted 04/23/23 12:23:58.438
    [AfterEach] [sig-apps] Job
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:23:58.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Job
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Job
      tear down framework | framework.go:193
    STEP: Destroying namespace "job-9737" for this suite. 04/23/23 12:23:58.452
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:129
[BeforeEach] [sig-node] Security Context
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:23:58.466
Apr 23 12:23:58.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename security-context 04/23/23 12:23:58.474
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:23:58.501
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:23:58.505
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:31
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:129
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/23/23 12:23:58.508
Apr 23 12:23:58.522: INFO: Waiting up to 5m0s for pod "security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee" in namespace "security-context-4337" to be "Succeeded or Failed"
Apr 23 12:23:58.550: INFO: Pod "security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee": Phase="Pending", Reason="", readiness=false. Elapsed: 27.917293ms
Apr 23 12:24:00.565: INFO: Pod "security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043001883s
Apr 23 12:24:02.561: INFO: Pod "security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038432992s
Apr 23 12:24:04.565: INFO: Pod "security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042698987s
STEP: Saw pod success 04/23/23 12:24:04.566
Apr 23 12:24:04.566: INFO: Pod "security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee" satisfied condition "Succeeded or Failed"
Apr 23 12:24:04.606: INFO: Trying to get logs from node eingavuivie7-3 pod security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee container test-container: <nil>
STEP: delete the pod 04/23/23 12:24:04.641
Apr 23 12:24:04.665: INFO: Waiting for pod security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee to disappear
Apr 23 12:24:04.671: INFO: Pod security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/node/init/init.go:32
Apr 23 12:24:04.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Security Context
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Security Context
  tear down framework | framework.go:193
STEP: Destroying namespace "security-context-4337" for this suite. 04/23/23 12:24:04.682
------------------------------
â€¢ [SLOW TEST] [6.229 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:23:58.466
    Apr 23 12:23:58.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename security-context 04/23/23 12:23:58.474
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:23:58.501
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:23:58.505
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:31
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:129
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/23/23 12:23:58.508
    Apr 23 12:23:58.522: INFO: Waiting up to 5m0s for pod "security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee" in namespace "security-context-4337" to be "Succeeded or Failed"
    Apr 23 12:23:58.550: INFO: Pod "security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee": Phase="Pending", Reason="", readiness=false. Elapsed: 27.917293ms
    Apr 23 12:24:00.565: INFO: Pod "security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043001883s
    Apr 23 12:24:02.561: INFO: Pod "security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038432992s
    Apr 23 12:24:04.565: INFO: Pod "security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042698987s
    STEP: Saw pod success 04/23/23 12:24:04.566
    Apr 23 12:24:04.566: INFO: Pod "security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee" satisfied condition "Succeeded or Failed"
    Apr 23 12:24:04.606: INFO: Trying to get logs from node eingavuivie7-3 pod security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee container test-container: <nil>
    STEP: delete the pod 04/23/23 12:24:04.641
    Apr 23 12:24:04.665: INFO: Waiting for pod security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee to disappear
    Apr 23 12:24:04.671: INFO: Pod security-context-2ee2ee7e-b6d0-47fb-8af0-bb0426d5c2ee no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:24:04.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Security Context
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Security Context
      tear down framework | framework.go:193
    STEP: Destroying namespace "security-context-4337" for this suite. 04/23/23 12:24:04.682
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:24:04.702
Apr 23 12:24:04.702: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename aggregator 04/23/23 12:24:04.704
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:24:04.74
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:24:04.745
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Apr 23 12:24:04.751: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 04/23/23 12:24:04.753
Apr 23 12:24:05.245: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr 23 12:24:07.364: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:09.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:11.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:13.371: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:15.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:17.381: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:19.371: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:21.372: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:23.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:25.371: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:27.372: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:29.378: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:31.377: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:33.372: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:35.379: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:37.370: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:39.373: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:41.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:43.379: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:45.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:47.380: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:49.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:51.373: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:53.382: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:24:55.570: INFO: Waited 163.540507ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 04/23/23 12:24:55.674
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 04/23/23 12:24:55.683
STEP: List APIServices 04/23/23 12:24:55.7
Apr 23 12:24:55.715: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/node/init/init.go:32
Apr 23 12:24:56.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Aggregator
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Aggregator
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Aggregator
  tear down framework | framework.go:193
STEP: Destroying namespace "aggregator-7859" for this suite. 04/23/23 12:24:56.045
------------------------------
â€¢ [SLOW TEST] [51.353 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:24:04.702
    Apr 23 12:24:04.702: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename aggregator 04/23/23 12:24:04.704
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:24:04.74
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:24:04.745
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Apr 23 12:24:04.751: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 04/23/23 12:24:04.753
    Apr 23 12:24:05.245: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Apr 23 12:24:07.364: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:09.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:11.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:13.371: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:15.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:17.381: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:19.371: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:21.372: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:23.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:25.371: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:27.372: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:29.378: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:31.377: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:33.372: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:35.379: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:37.370: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:39.373: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:41.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:43.379: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:45.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:47.380: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:49.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:51.373: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:53.382: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 24, 5, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-55bd96fd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:24:55.570: INFO: Waited 163.540507ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 04/23/23 12:24:55.674
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 04/23/23 12:24:55.683
    STEP: List APIServices 04/23/23 12:24:55.7
    Apr 23 12:24:55.715: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:24:56.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Aggregator
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Aggregator
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Aggregator
      tear down framework | framework.go:193
    STEP: Destroying namespace "aggregator-7859" for this suite. 04/23/23 12:24:56.045
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:24:56.06
Apr 23 12:24:56.060: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename cronjob 04/23/23 12:24:56.065
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:24:56.102
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:24:56.108
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:31
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 04/23/23 12:24:56.115
STEP: Ensuring a job is scheduled 04/23/23 12:24:56.137
STEP: Ensuring exactly one is scheduled 04/23/23 12:25:00.178
STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/23/23 12:25:00.199
STEP: Ensuring the job is replaced with a new one 04/23/23 12:25:00.209
STEP: Removing cronjob 04/23/23 12:26:00.239
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/node/init/init.go:32
Apr 23 12:26:00.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] CronJob
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] CronJob
  tear down framework | framework.go:193
STEP: Destroying namespace "cronjob-4193" for this suite. 04/23/23 12:26:00.307
------------------------------
â€¢ [SLOW TEST] [64.276 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:24:56.06
    Apr 23 12:24:56.060: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename cronjob 04/23/23 12:24:56.065
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:24:56.102
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:24:56.108
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:31
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 04/23/23 12:24:56.115
    STEP: Ensuring a job is scheduled 04/23/23 12:24:56.137
    STEP: Ensuring exactly one is scheduled 04/23/23 12:25:00.178
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/23/23 12:25:00.199
    STEP: Ensuring the job is replaced with a new one 04/23/23 12:25:00.209
    STEP: Removing cronjob 04/23/23 12:26:00.239
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:26:00.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] CronJob
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] CronJob
      tear down framework | framework.go:193
    STEP: Destroying namespace "cronjob-4193" for this suite. 04/23/23 12:26:00.307
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:353
[BeforeEach] [sig-network] EndpointSlice
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:26:00.336
Apr 23 12:26:00.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename endpointslice 04/23/23 12:26:00.343
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:26:00.387
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:26:00.395
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:52
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:353
STEP: getting /apis 04/23/23 12:26:00.406
STEP: getting /apis/discovery.k8s.io 04/23/23 12:26:00.42
STEP: getting /apis/discovery.k8s.iov1 04/23/23 12:26:00.427
STEP: creating 04/23/23 12:26:00.431
STEP: getting 04/23/23 12:26:00.5
STEP: listing 04/23/23 12:26:00.507
STEP: watching 04/23/23 12:26:00.515
Apr 23 12:26:00.515: INFO: starting watch
STEP: cluster-wide listing 04/23/23 12:26:00.518
STEP: cluster-wide watching 04/23/23 12:26:00.551
Apr 23 12:26:00.551: INFO: starting watch
STEP: patching 04/23/23 12:26:00.555
STEP: updating 04/23/23 12:26:00.569
Apr 23 12:26:00.621: INFO: waiting for watch events with expected annotations
Apr 23 12:26:00.622: INFO: saw patched and updated annotations
STEP: deleting 04/23/23 12:26:00.622
STEP: deleting a collection 04/23/23 12:26:00.655
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/node/init/init.go:32
Apr 23 12:26:00.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] EndpointSlice
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] EndpointSlice
  tear down framework | framework.go:193
STEP: Destroying namespace "endpointslice-5738" for this suite. 04/23/23 12:26:00.723
------------------------------
â€¢ [0.401 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:353

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:26:00.336
    Apr 23 12:26:00.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename endpointslice 04/23/23 12:26:00.343
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:26:00.387
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:26:00.395
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:52
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:353
    STEP: getting /apis 04/23/23 12:26:00.406
    STEP: getting /apis/discovery.k8s.io 04/23/23 12:26:00.42
    STEP: getting /apis/discovery.k8s.iov1 04/23/23 12:26:00.427
    STEP: creating 04/23/23 12:26:00.431
    STEP: getting 04/23/23 12:26:00.5
    STEP: listing 04/23/23 12:26:00.507
    STEP: watching 04/23/23 12:26:00.515
    Apr 23 12:26:00.515: INFO: starting watch
    STEP: cluster-wide listing 04/23/23 12:26:00.518
    STEP: cluster-wide watching 04/23/23 12:26:00.551
    Apr 23 12:26:00.551: INFO: starting watch
    STEP: patching 04/23/23 12:26:00.555
    STEP: updating 04/23/23 12:26:00.569
    Apr 23 12:26:00.621: INFO: waiting for watch events with expected annotations
    Apr 23 12:26:00.622: INFO: saw patched and updated annotations
    STEP: deleting 04/23/23 12:26:00.622
    STEP: deleting a collection 04/23/23 12:26:00.655
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:26:00.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      tear down framework | framework.go:193
    STEP: Destroying namespace "endpointslice-5738" for this suite. 04/23/23 12:26:00.723
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:26:00.738
Apr 23 12:26:00.738: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename subpath 04/23/23 12:26:00.742
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:26:00.769
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:26:00.774
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/23/23 12:26:00.778
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-cztb 04/23/23 12:26:00.813
STEP: Creating a pod to test atomic-volume-subpath 04/23/23 12:26:00.814
Apr 23 12:26:00.832: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-cztb" in namespace "subpath-9983" to be "Succeeded or Failed"
Apr 23 12:26:00.838: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.718493ms
Apr 23 12:26:02.848: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015070719s
Apr 23 12:26:04.846: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 4.013270683s
Apr 23 12:26:06.847: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 6.014544058s
Apr 23 12:26:08.847: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 8.014113139s
Apr 23 12:26:10.849: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 10.01678832s
Apr 23 12:26:12.848: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 12.01559453s
Apr 23 12:26:14.852: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 14.019020821s
Apr 23 12:26:16.848: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 16.015641082s
Apr 23 12:26:18.848: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 18.015031109s
Apr 23 12:26:20.848: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 20.015267103s
Apr 23 12:26:22.852: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 22.019714394s
Apr 23 12:26:24.848: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=false. Elapsed: 24.015717565s
Apr 23 12:26:26.852: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.019807457s
STEP: Saw pod success 04/23/23 12:26:26.853
Apr 23 12:26:26.853: INFO: Pod "pod-subpath-test-downwardapi-cztb" satisfied condition "Succeeded or Failed"
Apr 23 12:26:26.863: INFO: Trying to get logs from node eingavuivie7-3 pod pod-subpath-test-downwardapi-cztb container test-container-subpath-downwardapi-cztb: <nil>
STEP: delete the pod 04/23/23 12:26:26.896
Apr 23 12:26:26.943: INFO: Waiting for pod pod-subpath-test-downwardapi-cztb to disappear
Apr 23 12:26:26.953: INFO: Pod pod-subpath-test-downwardapi-cztb no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-cztb 04/23/23 12:26:26.953
Apr 23 12:26:26.954: INFO: Deleting pod "pod-subpath-test-downwardapi-cztb" in namespace "subpath-9983"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/node/init/init.go:32
Apr 23 12:26:26.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Subpath
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Subpath
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Subpath
  tear down framework | framework.go:193
STEP: Destroying namespace "subpath-9983" for this suite. 04/23/23 12:26:26.983
------------------------------
â€¢ [SLOW TEST] [26.281 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:26:00.738
    Apr 23 12:26:00.738: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename subpath 04/23/23 12:26:00.742
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:26:00.769
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:26:00.774
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/23/23 12:26:00.778
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-cztb 04/23/23 12:26:00.813
    STEP: Creating a pod to test atomic-volume-subpath 04/23/23 12:26:00.814
    Apr 23 12:26:00.832: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-cztb" in namespace "subpath-9983" to be "Succeeded or Failed"
    Apr 23 12:26:00.838: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.718493ms
    Apr 23 12:26:02.848: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015070719s
    Apr 23 12:26:04.846: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 4.013270683s
    Apr 23 12:26:06.847: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 6.014544058s
    Apr 23 12:26:08.847: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 8.014113139s
    Apr 23 12:26:10.849: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 10.01678832s
    Apr 23 12:26:12.848: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 12.01559453s
    Apr 23 12:26:14.852: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 14.019020821s
    Apr 23 12:26:16.848: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 16.015641082s
    Apr 23 12:26:18.848: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 18.015031109s
    Apr 23 12:26:20.848: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 20.015267103s
    Apr 23 12:26:22.852: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=true. Elapsed: 22.019714394s
    Apr 23 12:26:24.848: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Running", Reason="", readiness=false. Elapsed: 24.015717565s
    Apr 23 12:26:26.852: INFO: Pod "pod-subpath-test-downwardapi-cztb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.019807457s
    STEP: Saw pod success 04/23/23 12:26:26.853
    Apr 23 12:26:26.853: INFO: Pod "pod-subpath-test-downwardapi-cztb" satisfied condition "Succeeded or Failed"
    Apr 23 12:26:26.863: INFO: Trying to get logs from node eingavuivie7-3 pod pod-subpath-test-downwardapi-cztb container test-container-subpath-downwardapi-cztb: <nil>
    STEP: delete the pod 04/23/23 12:26:26.896
    Apr 23 12:26:26.943: INFO: Waiting for pod pod-subpath-test-downwardapi-cztb to disappear
    Apr 23 12:26:26.953: INFO: Pod pod-subpath-test-downwardapi-cztb no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-cztb 04/23/23 12:26:26.953
    Apr 23 12:26:26.954: INFO: Deleting pod "pod-subpath-test-downwardapi-cztb" in namespace "subpath-9983"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:26:26.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Subpath
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Subpath
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Subpath
      tear down framework | framework.go:193
    STEP: Destroying namespace "subpath-9983" for this suite. 04/23/23 12:26:26.983
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:374
[BeforeEach] [sig-apps] Daemon set [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:26:27.023
Apr 23 12:26:27.023: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename daemonsets 04/23/23 12:26:27.026
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:26:27.079
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:26:27.085
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:146
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:374
Apr 23 12:26:27.138: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 04/23/23 12:26:27.154
Apr 23 12:26:27.189: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 12:26:27.190: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:26:28.215: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 12:26:28.215: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:26:29.211: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 12:26:29.212: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 12:26:30.204: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 12:26:30.204: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 12:26:31.211: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 23 12:26:31.211: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 04/23/23 12:26:31.234
STEP: Check that daemon pods images are updated. 04/23/23 12:26:31.254
Apr 23 12:26:31.263: INFO: Wrong image for pod: daemon-set-kksvf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Apr 23 12:26:31.263: INFO: Wrong image for pod: daemon-set-s5x5n. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Apr 23 12:26:31.263: INFO: Wrong image for pod: daemon-set-tnpvl. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Apr 23 12:26:32.281: INFO: Wrong image for pod: daemon-set-kksvf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Apr 23 12:26:32.281: INFO: Wrong image for pod: daemon-set-tnpvl. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Apr 23 12:26:33.286: INFO: Wrong image for pod: daemon-set-kksvf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Apr 23 12:26:33.286: INFO: Pod daemon-set-s47r8 is not available
Apr 23 12:26:33.286: INFO: Wrong image for pod: daemon-set-tnpvl. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Apr 23 12:26:34.281: INFO: Wrong image for pod: daemon-set-tnpvl. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Apr 23 12:26:35.278: INFO: Wrong image for pod: daemon-set-tnpvl. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Apr 23 12:26:36.280: INFO: Pod daemon-set-4qd8z is not available
Apr 23 12:26:36.280: INFO: Wrong image for pod: daemon-set-tnpvl. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
Apr 23 12:26:39.282: INFO: Pod daemon-set-5h9nn is not available
STEP: Check that daemon pods are still running on every node of the cluster. 04/23/23 12:26:39.293
Apr 23 12:26:39.310: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 12:26:39.311: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 12:26:40.337: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 12:26:40.337: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
Apr 23 12:26:41.330: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 23 12:26:41.330: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:111
STEP: Deleting DaemonSet "daemon-set" 04/23/23 12:26:41.381
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2456, will wait for the garbage collector to delete the pods 04/23/23 12:26:41.381
Apr 23 12:26:41.456: INFO: Deleting DaemonSet.extensions daemon-set took: 16.97652ms
Apr 23 12:26:41.557: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.119878ms
Apr 23 12:26:43.475: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 12:26:43.475: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 23 12:26:43.521: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"32218"},"items":null}

Apr 23 12:26:43.528: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"32218"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:26:43.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "daemonsets-2456" for this suite. 04/23/23 12:26:43.571
------------------------------
â€¢ [SLOW TEST] [16.571 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:26:27.023
    Apr 23 12:26:27.023: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename daemonsets 04/23/23 12:26:27.026
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:26:27.079
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:26:27.085
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:146
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:374
    Apr 23 12:26:27.138: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 04/23/23 12:26:27.154
    Apr 23 12:26:27.189: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 12:26:27.190: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:26:28.215: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 12:26:28.215: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:26:29.211: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 12:26:29.212: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 12:26:30.204: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 12:26:30.204: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 12:26:31.211: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 23 12:26:31.211: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 04/23/23 12:26:31.234
    STEP: Check that daemon pods images are updated. 04/23/23 12:26:31.254
    Apr 23 12:26:31.263: INFO: Wrong image for pod: daemon-set-kksvf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Apr 23 12:26:31.263: INFO: Wrong image for pod: daemon-set-s5x5n. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Apr 23 12:26:31.263: INFO: Wrong image for pod: daemon-set-tnpvl. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Apr 23 12:26:32.281: INFO: Wrong image for pod: daemon-set-kksvf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Apr 23 12:26:32.281: INFO: Wrong image for pod: daemon-set-tnpvl. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Apr 23 12:26:33.286: INFO: Wrong image for pod: daemon-set-kksvf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Apr 23 12:26:33.286: INFO: Pod daemon-set-s47r8 is not available
    Apr 23 12:26:33.286: INFO: Wrong image for pod: daemon-set-tnpvl. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Apr 23 12:26:34.281: INFO: Wrong image for pod: daemon-set-tnpvl. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Apr 23 12:26:35.278: INFO: Wrong image for pod: daemon-set-tnpvl. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Apr 23 12:26:36.280: INFO: Pod daemon-set-4qd8z is not available
    Apr 23 12:26:36.280: INFO: Wrong image for pod: daemon-set-tnpvl. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
    Apr 23 12:26:39.282: INFO: Pod daemon-set-5h9nn is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 04/23/23 12:26:39.293
    Apr 23 12:26:39.310: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 12:26:39.311: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 12:26:40.337: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 12:26:40.337: INFO: Node eingavuivie7-2 is running 0 daemon pod, expected 1
    Apr 23 12:26:41.330: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 23 12:26:41.330: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:111
    STEP: Deleting DaemonSet "daemon-set" 04/23/23 12:26:41.381
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2456, will wait for the garbage collector to delete the pods 04/23/23 12:26:41.381
    Apr 23 12:26:41.456: INFO: Deleting DaemonSet.extensions daemon-set took: 16.97652ms
    Apr 23 12:26:41.557: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.119878ms
    Apr 23 12:26:43.475: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 12:26:43.475: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 23 12:26:43.521: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"32218"},"items":null}

    Apr 23 12:26:43.528: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"32218"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:26:43.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "daemonsets-2456" for this suite. 04/23/23 12:26:43.571
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:344
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:26:43.601
Apr 23 12:26:43.601: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pods 04/23/23 12:26:43.603
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:26:43.655
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:26:43.659
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:344
STEP: creating the pod 04/23/23 12:26:43.665
STEP: submitting the pod to kubernetes 04/23/23 12:26:43.666
Apr 23 12:26:43.692: INFO: Waiting up to 5m0s for pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661" in namespace "pods-9906" to be "running and ready"
Apr 23 12:26:43.700: INFO: Pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661": Phase="Pending", Reason="", readiness=false. Elapsed: 7.890392ms
Apr 23 12:26:43.700: INFO: The phase of Pod pod-update-0d1d9477-5744-4550-aec8-5abd2d927661 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:26:45.707: INFO: Pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014544032s
Apr 23 12:26:45.707: INFO: The phase of Pod pod-update-0d1d9477-5744-4550-aec8-5abd2d927661 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:26:47.708: INFO: Pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661": Phase="Running", Reason="", readiness=true. Elapsed: 4.015962279s
Apr 23 12:26:47.708: INFO: The phase of Pod pod-update-0d1d9477-5744-4550-aec8-5abd2d927661 is Running (Ready = true)
Apr 23 12:26:47.708: INFO: Pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 04/23/23 12:26:47.715
STEP: updating the pod 04/23/23 12:26:47.724
Apr 23 12:26:48.250: INFO: Successfully updated pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661"
Apr 23 12:26:48.250: INFO: Waiting up to 5m0s for pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661" in namespace "pods-9906" to be "running"
Apr 23 12:26:48.273: INFO: Pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661": Phase="Running", Reason="", readiness=true. Elapsed: 22.374633ms
Apr 23 12:26:48.273: INFO: Pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 04/23/23 12:26:48.273
Apr 23 12:26:48.280: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Apr 23 12:26:48.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-9906" for this suite. 04/23/23 12:26:48.294
------------------------------
â€¢ [4.708 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:344

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:26:43.601
    Apr 23 12:26:43.601: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pods 04/23/23 12:26:43.603
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:26:43.655
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:26:43.659
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:344
    STEP: creating the pod 04/23/23 12:26:43.665
    STEP: submitting the pod to kubernetes 04/23/23 12:26:43.666
    Apr 23 12:26:43.692: INFO: Waiting up to 5m0s for pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661" in namespace "pods-9906" to be "running and ready"
    Apr 23 12:26:43.700: INFO: Pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661": Phase="Pending", Reason="", readiness=false. Elapsed: 7.890392ms
    Apr 23 12:26:43.700: INFO: The phase of Pod pod-update-0d1d9477-5744-4550-aec8-5abd2d927661 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:26:45.707: INFO: Pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014544032s
    Apr 23 12:26:45.707: INFO: The phase of Pod pod-update-0d1d9477-5744-4550-aec8-5abd2d927661 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:26:47.708: INFO: Pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661": Phase="Running", Reason="", readiness=true. Elapsed: 4.015962279s
    Apr 23 12:26:47.708: INFO: The phase of Pod pod-update-0d1d9477-5744-4550-aec8-5abd2d927661 is Running (Ready = true)
    Apr 23 12:26:47.708: INFO: Pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 04/23/23 12:26:47.715
    STEP: updating the pod 04/23/23 12:26:47.724
    Apr 23 12:26:48.250: INFO: Successfully updated pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661"
    Apr 23 12:26:48.250: INFO: Waiting up to 5m0s for pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661" in namespace "pods-9906" to be "running"
    Apr 23 12:26:48.273: INFO: Pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661": Phase="Running", Reason="", readiness=true. Elapsed: 22.374633ms
    Apr 23 12:26:48.273: INFO: Pod "pod-update-0d1d9477-5744-4550-aec8-5abd2d927661" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 04/23/23 12:26:48.273
    Apr 23 12:26:48.280: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:26:48.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-9906" for this suite. 04/23/23 12:26:48.294
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:26:48.315
Apr 23 12:26:48.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename replicaset 04/23/23 12:26:48.322
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:26:48.353
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:26:48.36
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:31
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 04/23/23 12:26:48.366
Apr 23 12:26:48.382: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-7011" to be "running and ready"
Apr 23 12:26:48.392: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 8.996097ms
Apr 23 12:26:48.392: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:26:50.398: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.015147088s
Apr 23 12:26:50.398: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Apr 23 12:26:50.398: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 04/23/23 12:26:50.405
STEP: Then the orphan pod is adopted 04/23/23 12:26:50.414
STEP: When the matched label of one of its pods change 04/23/23 12:26:51.426
Apr 23 12:26:51.431: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 04/23/23 12:26:51.449
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/node/init/init.go:32
Apr 23 12:26:52.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  tear down framework | framework.go:193
STEP: Destroying namespace "replicaset-7011" for this suite. 04/23/23 12:26:52.471
------------------------------
â€¢ [4.188 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:26:48.315
    Apr 23 12:26:48.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename replicaset 04/23/23 12:26:48.322
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:26:48.353
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:26:48.36
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:31
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 04/23/23 12:26:48.366
    Apr 23 12:26:48.382: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-7011" to be "running and ready"
    Apr 23 12:26:48.392: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 8.996097ms
    Apr 23 12:26:48.392: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:26:50.398: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.015147088s
    Apr 23 12:26:50.398: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Apr 23 12:26:50.398: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 04/23/23 12:26:50.405
    STEP: Then the orphan pod is adopted 04/23/23 12:26:50.414
    STEP: When the matched label of one of its pods change 04/23/23 12:26:51.426
    Apr 23 12:26:51.431: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 04/23/23 12:26:51.449
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:26:52.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "replicaset-7011" for this suite. 04/23/23 12:26:52.471
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:26:52.517
Apr 23 12:26:52.518: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename replicaset 04/23/23 12:26:52.521
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:26:52.582
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:26:52.59
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:31
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 04/23/23 12:26:52.595
STEP: Verify that the required pods have come up 04/23/23 12:26:52.604
Apr 23 12:26:52.613: INFO: Pod name sample-pod: Found 0 pods out of 3
Apr 23 12:26:57.621: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 04/23/23 12:26:57.621
Apr 23 12:26:57.632: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 04/23/23 12:26:57.632
STEP: DeleteCollection of the ReplicaSets 04/23/23 12:26:57.64
STEP: After DeleteCollection verify that ReplicaSets have been deleted 04/23/23 12:26:57.656
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/node/init/init.go:32
Apr 23 12:26:57.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicaSet
  tear down framework | framework.go:193
STEP: Destroying namespace "replicaset-8101" for this suite. 04/23/23 12:26:57.673
------------------------------
â€¢ [SLOW TEST] [5.214 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:26:52.517
    Apr 23 12:26:52.518: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename replicaset 04/23/23 12:26:52.521
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:26:52.582
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:26:52.59
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:31
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 04/23/23 12:26:52.595
    STEP: Verify that the required pods have come up 04/23/23 12:26:52.604
    Apr 23 12:26:52.613: INFO: Pod name sample-pod: Found 0 pods out of 3
    Apr 23 12:26:57.621: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 04/23/23 12:26:57.621
    Apr 23 12:26:57.632: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 04/23/23 12:26:57.632
    STEP: DeleteCollection of the ReplicaSets 04/23/23 12:26:57.64
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 04/23/23 12:26:57.656
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:26:57.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicaSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "replicaset-8101" for this suite. 04/23/23 12:26:57.673
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:112
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:26:57.741
Apr 23 12:26:57.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename var-expansion 04/23/23 12:26:57.744
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:26:57.809
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:26:57.814
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:112
STEP: Creating a pod to test substitution in volume subpath 04/23/23 12:26:57.828
Apr 23 12:26:57.862: INFO: Waiting up to 5m0s for pod "var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80" in namespace "var-expansion-5917" to be "Succeeded or Failed"
Apr 23 12:26:57.873: INFO: Pod "var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80": Phase="Pending", Reason="", readiness=false. Elapsed: 10.967228ms
Apr 23 12:26:59.881: INFO: Pod "var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018613288s
Apr 23 12:27:01.883: INFO: Pod "var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020532578s
Apr 23 12:27:03.894: INFO: Pod "var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031247038s
STEP: Saw pod success 04/23/23 12:27:03.894
Apr 23 12:27:03.895: INFO: Pod "var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80" satisfied condition "Succeeded or Failed"
Apr 23 12:27:03.918: INFO: Trying to get logs from node eingavuivie7-3 pod var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80 container dapi-container: <nil>
STEP: delete the pod 04/23/23 12:27:03.942
Apr 23 12:27:03.969: INFO: Waiting for pod var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80 to disappear
Apr 23 12:27:03.974: INFO: Pod var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Apr 23 12:27:03.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-5917" for this suite. 04/23/23 12:27:03.988
------------------------------
â€¢ [SLOW TEST] [6.269 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:112

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:26:57.741
    Apr 23 12:26:57.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename var-expansion 04/23/23 12:26:57.744
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:26:57.809
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:26:57.814
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:112
    STEP: Creating a pod to test substitution in volume subpath 04/23/23 12:26:57.828
    Apr 23 12:26:57.862: INFO: Waiting up to 5m0s for pod "var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80" in namespace "var-expansion-5917" to be "Succeeded or Failed"
    Apr 23 12:26:57.873: INFO: Pod "var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80": Phase="Pending", Reason="", readiness=false. Elapsed: 10.967228ms
    Apr 23 12:26:59.881: INFO: Pod "var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018613288s
    Apr 23 12:27:01.883: INFO: Pod "var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020532578s
    Apr 23 12:27:03.894: INFO: Pod "var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031247038s
    STEP: Saw pod success 04/23/23 12:27:03.894
    Apr 23 12:27:03.895: INFO: Pod "var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80" satisfied condition "Succeeded or Failed"
    Apr 23 12:27:03.918: INFO: Trying to get logs from node eingavuivie7-3 pod var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80 container dapi-container: <nil>
    STEP: delete the pod 04/23/23 12:27:03.942
    Apr 23 12:27:03.969: INFO: Waiting for pod var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80 to disappear
    Apr 23 12:27:03.974: INFO: Pod var-expansion-8128d5b1-bd1c-450a-81b8-89e5b59e0a80 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:27:03.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-5917" for this suite. 04/23/23 12:27:03.988
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:618
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:27:04.013
Apr 23 12:27:04.013: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pods 04/23/23 12:27:04.021
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:27:04.065
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:27:04.075
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:618
Apr 23 12:27:04.087: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: creating the pod 04/23/23 12:27:04.09
STEP: submitting the pod to kubernetes 04/23/23 12:27:04.09
Apr 23 12:27:04.129: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-dd6e2ade-d818-423b-9e81-659a0138dac8" in namespace "pods-5527" to be "running and ready"
Apr 23 12:27:04.159: INFO: Pod "pod-logs-websocket-dd6e2ade-d818-423b-9e81-659a0138dac8": Phase="Pending", Reason="", readiness=false. Elapsed: 29.546175ms
Apr 23 12:27:04.159: INFO: The phase of Pod pod-logs-websocket-dd6e2ade-d818-423b-9e81-659a0138dac8 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:27:06.166: INFO: Pod "pod-logs-websocket-dd6e2ade-d818-423b-9e81-659a0138dac8": Phase="Running", Reason="", readiness=true. Elapsed: 2.036651512s
Apr 23 12:27:06.166: INFO: The phase of Pod pod-logs-websocket-dd6e2ade-d818-423b-9e81-659a0138dac8 is Running (Ready = true)
Apr 23 12:27:06.166: INFO: Pod "pod-logs-websocket-dd6e2ade-d818-423b-9e81-659a0138dac8" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Apr 23 12:27:06.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-5527" for this suite. 04/23/23 12:27:06.24
------------------------------
â€¢ [2.241 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:618

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:27:04.013
    Apr 23 12:27:04.013: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pods 04/23/23 12:27:04.021
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:27:04.065
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:27:04.075
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:618
    Apr 23 12:27:04.087: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: creating the pod 04/23/23 12:27:04.09
    STEP: submitting the pod to kubernetes 04/23/23 12:27:04.09
    Apr 23 12:27:04.129: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-dd6e2ade-d818-423b-9e81-659a0138dac8" in namespace "pods-5527" to be "running and ready"
    Apr 23 12:27:04.159: INFO: Pod "pod-logs-websocket-dd6e2ade-d818-423b-9e81-659a0138dac8": Phase="Pending", Reason="", readiness=false. Elapsed: 29.546175ms
    Apr 23 12:27:04.159: INFO: The phase of Pod pod-logs-websocket-dd6e2ade-d818-423b-9e81-659a0138dac8 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:27:06.166: INFO: Pod "pod-logs-websocket-dd6e2ade-d818-423b-9e81-659a0138dac8": Phase="Running", Reason="", readiness=true. Elapsed: 2.036651512s
    Apr 23 12:27:06.166: INFO: The phase of Pod pod-logs-websocket-dd6e2ade-d818-423b-9e81-659a0138dac8 is Running (Ready = true)
    Apr 23 12:27:06.166: INFO: Pod "pod-logs-websocket-dd6e2ade-d818-423b-9e81-659a0138dac8" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:27:06.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-5527" for this suite. 04/23/23 12:27:06.24
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:147
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:27:06.259
Apr 23 12:27:06.259: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 12:27:06.262
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:27:06.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:27:06.301
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:147
STEP: Creating a pod to test emptydir 0777 on tmpfs 04/23/23 12:27:06.31
Apr 23 12:27:06.329: INFO: Waiting up to 5m0s for pod "pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f" in namespace "emptydir-8484" to be "Succeeded or Failed"
Apr 23 12:27:06.336: INFO: Pod "pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008962ms
Apr 23 12:27:08.345: INFO: Pod "pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015563384s
Apr 23 12:27:10.345: INFO: Pod "pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015684813s
Apr 23 12:27:12.345: INFO: Pod "pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015094863s
STEP: Saw pod success 04/23/23 12:27:12.345
Apr 23 12:27:12.345: INFO: Pod "pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f" satisfied condition "Succeeded or Failed"
Apr 23 12:27:12.351: INFO: Trying to get logs from node eingavuivie7-3 pod pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f container test-container: <nil>
STEP: delete the pod 04/23/23 12:27:12.363
Apr 23 12:27:12.388: INFO: Waiting for pod pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f to disappear
Apr 23 12:27:12.394: INFO: Pod pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 12:27:12.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-8484" for this suite. 04/23/23 12:27:12.401
------------------------------
â€¢ [SLOW TEST] [6.171 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:147

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:27:06.259
    Apr 23 12:27:06.259: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 12:27:06.262
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:27:06.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:27:06.301
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:147
    STEP: Creating a pod to test emptydir 0777 on tmpfs 04/23/23 12:27:06.31
    Apr 23 12:27:06.329: INFO: Waiting up to 5m0s for pod "pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f" in namespace "emptydir-8484" to be "Succeeded or Failed"
    Apr 23 12:27:06.336: INFO: Pod "pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008962ms
    Apr 23 12:27:08.345: INFO: Pod "pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015563384s
    Apr 23 12:27:10.345: INFO: Pod "pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015684813s
    Apr 23 12:27:12.345: INFO: Pod "pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015094863s
    STEP: Saw pod success 04/23/23 12:27:12.345
    Apr 23 12:27:12.345: INFO: Pod "pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f" satisfied condition "Succeeded or Failed"
    Apr 23 12:27:12.351: INFO: Trying to get logs from node eingavuivie7-3 pod pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f container test-container: <nil>
    STEP: delete the pod 04/23/23 12:27:12.363
    Apr 23 12:27:12.388: INFO: Waiting for pod pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f to disappear
    Apr 23 12:27:12.394: INFO: Pod pod-adee46e5-ce5c-44d7-b62f-c9aad568dc7f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:27:12.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-8484" for this suite. 04/23/23 12:27:12.401
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:931
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:27:12.433
Apr 23 12:27:12.433: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 12:27:12.437
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:27:12.459
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:27:12.463
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:931
STEP: create deployment with httpd image 04/23/23 12:27:12.471
Apr 23 12:27:12.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-828 create -f -'
Apr 23 12:27:14.402: INFO: stderr: ""
Apr 23 12:27:14.402: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 04/23/23 12:27:14.402
Apr 23 12:27:14.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-828 diff -f -'
Apr 23 12:27:15.108: INFO: rc: 1
Apr 23 12:27:15.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-828 delete -f -'
Apr 23 12:27:15.470: INFO: stderr: ""
Apr 23 12:27:15.470: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 12:27:15.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-828" for this suite. 04/23/23 12:27:15.491
------------------------------
â€¢ [3.089 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:925
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:931

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:27:12.433
    Apr 23 12:27:12.433: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 12:27:12.437
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:27:12.459
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:27:12.463
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:931
    STEP: create deployment with httpd image 04/23/23 12:27:12.471
    Apr 23 12:27:12.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-828 create -f -'
    Apr 23 12:27:14.402: INFO: stderr: ""
    Apr 23 12:27:14.402: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 04/23/23 12:27:14.402
    Apr 23 12:27:14.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-828 diff -f -'
    Apr 23 12:27:15.108: INFO: rc: 1
    Apr 23 12:27:15.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-828 delete -f -'
    Apr 23 12:27:15.470: INFO: stderr: ""
    Apr 23 12:27:15.470: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:27:15.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-828" for this suite. 04/23/23 12:27:15.491
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:68
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:27:15.543
Apr 23 12:27:15.543: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 12:27:15.546
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:27:15.567
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:27:15.573
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:68
STEP: Creating a pod to test downward API volume plugin 04/23/23 12:27:15.578
Apr 23 12:27:15.600: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03" in namespace "downward-api-7399" to be "Succeeded or Failed"
Apr 23 12:27:15.608: INFO: Pod "downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03": Phase="Pending", Reason="", readiness=false. Elapsed: 7.814447ms
Apr 23 12:27:17.613: INFO: Pod "downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012967098s
Apr 23 12:27:19.617: INFO: Pod "downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017167764s
Apr 23 12:27:21.616: INFO: Pod "downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015938711s
STEP: Saw pod success 04/23/23 12:27:21.616
Apr 23 12:27:21.616: INFO: Pod "downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03" satisfied condition "Succeeded or Failed"
Apr 23 12:27:21.622: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03 container client-container: <nil>
STEP: delete the pod 04/23/23 12:27:21.677
Apr 23 12:27:21.699: INFO: Waiting for pod downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03 to disappear
Apr 23 12:27:21.703: INFO: Pod downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Apr 23 12:27:21.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-7399" for this suite. 04/23/23 12:27:21.71
------------------------------
â€¢ [SLOW TEST] [6.181 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:27:15.543
    Apr 23 12:27:15.543: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 12:27:15.546
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:27:15.567
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:27:15.573
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:68
    STEP: Creating a pod to test downward API volume plugin 04/23/23 12:27:15.578
    Apr 23 12:27:15.600: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03" in namespace "downward-api-7399" to be "Succeeded or Failed"
    Apr 23 12:27:15.608: INFO: Pod "downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03": Phase="Pending", Reason="", readiness=false. Elapsed: 7.814447ms
    Apr 23 12:27:17.613: INFO: Pod "downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012967098s
    Apr 23 12:27:19.617: INFO: Pod "downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017167764s
    Apr 23 12:27:21.616: INFO: Pod "downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015938711s
    STEP: Saw pod success 04/23/23 12:27:21.616
    Apr 23 12:27:21.616: INFO: Pod "downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03" satisfied condition "Succeeded or Failed"
    Apr 23 12:27:21.622: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03 container client-container: <nil>
    STEP: delete the pod 04/23/23 12:27:21.677
    Apr 23 12:27:21.699: INFO: Waiting for pod downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03 to disappear
    Apr 23 12:27:21.703: INFO: Pod downwardapi-volume-cfca9d1d-85c2-47d0-9f6b-52bf35803b03 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:27:21.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-7399" for this suite. 04/23/23 12:27:21.71
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:56
[BeforeEach] [sig-storage] Projected secret
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:27:21.739
Apr 23 12:27:21.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 12:27:21.744
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:27:21.771
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:27:21.776
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:56
STEP: Creating projection with secret that has name projected-secret-test-bcedb43a-2a4f-4d55-98a5-5b0f8e394a07 04/23/23 12:27:21.78
STEP: Creating a pod to test consume secrets 04/23/23 12:27:21.794
Apr 23 12:27:21.811: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b" in namespace "projected-8962" to be "Succeeded or Failed"
Apr 23 12:27:21.818: INFO: Pod "pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.261666ms
Apr 23 12:27:23.837: INFO: Pod "pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025677551s
Apr 23 12:27:25.826: INFO: Pod "pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015217829s
Apr 23 12:27:27.826: INFO: Pod "pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015155657s
STEP: Saw pod success 04/23/23 12:27:27.826
Apr 23 12:27:27.827: INFO: Pod "pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b" satisfied condition "Succeeded or Failed"
Apr 23 12:27:27.833: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b container projected-secret-volume-test: <nil>
STEP: delete the pod 04/23/23 12:27:27.846
Apr 23 12:27:27.867: INFO: Waiting for pod pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b to disappear
Apr 23 12:27:27.874: INFO: Pod pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/node/init/init.go:32
Apr 23 12:27:27.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected secret
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected secret
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-8962" for this suite. 04/23/23 12:27:27.882
------------------------------
â€¢ [SLOW TEST] [6.155 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:27:21.739
    Apr 23 12:27:21.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 12:27:21.744
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:27:21.771
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:27:21.776
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:56
    STEP: Creating projection with secret that has name projected-secret-test-bcedb43a-2a4f-4d55-98a5-5b0f8e394a07 04/23/23 12:27:21.78
    STEP: Creating a pod to test consume secrets 04/23/23 12:27:21.794
    Apr 23 12:27:21.811: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b" in namespace "projected-8962" to be "Succeeded or Failed"
    Apr 23 12:27:21.818: INFO: Pod "pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.261666ms
    Apr 23 12:27:23.837: INFO: Pod "pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025677551s
    Apr 23 12:27:25.826: INFO: Pod "pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015217829s
    Apr 23 12:27:27.826: INFO: Pod "pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015155657s
    STEP: Saw pod success 04/23/23 12:27:27.826
    Apr 23 12:27:27.827: INFO: Pod "pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b" satisfied condition "Succeeded or Failed"
    Apr 23 12:27:27.833: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/23/23 12:27:27.846
    Apr 23 12:27:27.867: INFO: Waiting for pod pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b to disappear
    Apr 23 12:27:27.874: INFO: Pod pod-projected-secrets-63d23e17-daa6-4729-884e-fbcee292e55b no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:27:27.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected secret
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected secret
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-8962" for this suite. 04/23/23 12:27:27.882
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should apply changes to a resourcequota status [Conformance]
  test/e2e/apimachinery/resource_quota.go:1010
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:27:27.899
Apr 23 12:27:27.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename resourcequota 04/23/23 12:27:27.902
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:27:27.931
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:27:27.935
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should apply changes to a resourcequota status [Conformance]
  test/e2e/apimachinery/resource_quota.go:1010
STEP: Creating resourceQuota "e2e-rq-status-ph9mp" 04/23/23 12:27:27.945
Apr 23 12:27:27.962: INFO: Resource quota "e2e-rq-status-ph9mp" reports spec: hard cpu limit of 500m
Apr 23 12:27:27.962: INFO: Resource quota "e2e-rq-status-ph9mp" reports spec: hard memory limit of 500Mi
STEP: Updating resourceQuota "e2e-rq-status-ph9mp" /status 04/23/23 12:27:27.962
STEP: Confirm /status for "e2e-rq-status-ph9mp" resourceQuota via watch 04/23/23 12:27:27.98
Apr 23 12:27:27.984: INFO: observed resourceQuota "e2e-rq-status-ph9mp" in namespace "resourcequota-6521" with hard status: v1.ResourceList(nil)
Apr 23 12:27:27.984: INFO: Found resourceQuota "e2e-rq-status-ph9mp" in namespace "resourcequota-6521" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
Apr 23 12:27:27.984: INFO: ResourceQuota "e2e-rq-status-ph9mp" /status was updated
STEP: Patching hard spec values for cpu & memory 04/23/23 12:27:27.99
Apr 23 12:27:28.002: INFO: Resource quota "e2e-rq-status-ph9mp" reports spec: hard cpu limit of 1
Apr 23 12:27:28.002: INFO: Resource quota "e2e-rq-status-ph9mp" reports spec: hard memory limit of 1Gi
STEP: Patching "e2e-rq-status-ph9mp" /status 04/23/23 12:27:28.002
STEP: Confirm /status for "e2e-rq-status-ph9mp" resourceQuota via watch 04/23/23 12:27:28.053
Apr 23 12:27:28.055: INFO: observed resourceQuota "e2e-rq-status-ph9mp" in namespace "resourcequota-6521" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
Apr 23 12:27:28.055: INFO: Found resourceQuota "e2e-rq-status-ph9mp" in namespace "resourcequota-6521" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
Apr 23 12:27:28.055: INFO: ResourceQuota "e2e-rq-status-ph9mp" /status was patched
STEP: Get "e2e-rq-status-ph9mp" /status 04/23/23 12:27:28.055
Apr 23 12:27:28.062: INFO: Resourcequota "e2e-rq-status-ph9mp" reports status: hard cpu of 1
Apr 23 12:27:28.063: INFO: Resourcequota "e2e-rq-status-ph9mp" reports status: hard memory of 1Gi
STEP: Repatching "e2e-rq-status-ph9mp" /status before checking Spec is unchanged 04/23/23 12:27:28.07
Apr 23 12:27:28.097: INFO: Resourcequota "e2e-rq-status-ph9mp" reports status: hard cpu of 2
Apr 23 12:27:28.097: INFO: Resourcequota "e2e-rq-status-ph9mp" reports status: hard memory of 2Gi
Apr 23 12:27:28.100: INFO: Found resourceQuota "e2e-rq-status-ph9mp" in namespace "resourcequota-6521" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
Apr 23 12:30:03.116: INFO: ResourceQuota "e2e-rq-status-ph9mp" Spec was unchanged and /status reset
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Apr 23 12:30:03.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-6521" for this suite. 04/23/23 12:30:03.135
------------------------------
â€¢ [SLOW TEST] [155.254 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should apply changes to a resourcequota status [Conformance]
  test/e2e/apimachinery/resource_quota.go:1010

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:27:27.899
    Apr 23 12:27:27.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename resourcequota 04/23/23 12:27:27.902
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:27:27.931
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:27:27.935
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should apply changes to a resourcequota status [Conformance]
      test/e2e/apimachinery/resource_quota.go:1010
    STEP: Creating resourceQuota "e2e-rq-status-ph9mp" 04/23/23 12:27:27.945
    Apr 23 12:27:27.962: INFO: Resource quota "e2e-rq-status-ph9mp" reports spec: hard cpu limit of 500m
    Apr 23 12:27:27.962: INFO: Resource quota "e2e-rq-status-ph9mp" reports spec: hard memory limit of 500Mi
    STEP: Updating resourceQuota "e2e-rq-status-ph9mp" /status 04/23/23 12:27:27.962
    STEP: Confirm /status for "e2e-rq-status-ph9mp" resourceQuota via watch 04/23/23 12:27:27.98
    Apr 23 12:27:27.984: INFO: observed resourceQuota "e2e-rq-status-ph9mp" in namespace "resourcequota-6521" with hard status: v1.ResourceList(nil)
    Apr 23 12:27:27.984: INFO: Found resourceQuota "e2e-rq-status-ph9mp" in namespace "resourcequota-6521" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
    Apr 23 12:27:27.984: INFO: ResourceQuota "e2e-rq-status-ph9mp" /status was updated
    STEP: Patching hard spec values for cpu & memory 04/23/23 12:27:27.99
    Apr 23 12:27:28.002: INFO: Resource quota "e2e-rq-status-ph9mp" reports spec: hard cpu limit of 1
    Apr 23 12:27:28.002: INFO: Resource quota "e2e-rq-status-ph9mp" reports spec: hard memory limit of 1Gi
    STEP: Patching "e2e-rq-status-ph9mp" /status 04/23/23 12:27:28.002
    STEP: Confirm /status for "e2e-rq-status-ph9mp" resourceQuota via watch 04/23/23 12:27:28.053
    Apr 23 12:27:28.055: INFO: observed resourceQuota "e2e-rq-status-ph9mp" in namespace "resourcequota-6521" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
    Apr 23 12:27:28.055: INFO: Found resourceQuota "e2e-rq-status-ph9mp" in namespace "resourcequota-6521" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
    Apr 23 12:27:28.055: INFO: ResourceQuota "e2e-rq-status-ph9mp" /status was patched
    STEP: Get "e2e-rq-status-ph9mp" /status 04/23/23 12:27:28.055
    Apr 23 12:27:28.062: INFO: Resourcequota "e2e-rq-status-ph9mp" reports status: hard cpu of 1
    Apr 23 12:27:28.063: INFO: Resourcequota "e2e-rq-status-ph9mp" reports status: hard memory of 1Gi
    STEP: Repatching "e2e-rq-status-ph9mp" /status before checking Spec is unchanged 04/23/23 12:27:28.07
    Apr 23 12:27:28.097: INFO: Resourcequota "e2e-rq-status-ph9mp" reports status: hard cpu of 2
    Apr 23 12:27:28.097: INFO: Resourcequota "e2e-rq-status-ph9mp" reports status: hard memory of 2Gi
    Apr 23 12:27:28.100: INFO: Found resourceQuota "e2e-rq-status-ph9mp" in namespace "resourcequota-6521" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
    Apr 23 12:30:03.116: INFO: ResourceQuota "e2e-rq-status-ph9mp" Spec was unchanged and /status reset
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:30:03.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-6521" for this suite. 04/23/23 12:30:03.135
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:99
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:30:03.158
Apr 23 12:30:03.158: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 12:30:03.165
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:30:03.198
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:30:03.203
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:99
STEP: Creating configMap with name projected-configmap-test-volume-map-b73ccd7c-c9c5-4149-9641-b41294e1a2b1 04/23/23 12:30:03.209
STEP: Creating a pod to test consume configMaps 04/23/23 12:30:03.223
Apr 23 12:30:03.256: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a" in namespace "projected-2707" to be "Succeeded or Failed"
Apr 23 12:30:03.276: INFO: Pod "pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.001153ms
Apr 23 12:30:05.284: INFO: Pod "pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a": Phase="Running", Reason="", readiness=true. Elapsed: 2.027786049s
Apr 23 12:30:07.285: INFO: Pod "pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a": Phase="Running", Reason="", readiness=false. Elapsed: 4.028873264s
Apr 23 12:30:09.289: INFO: Pod "pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032421347s
STEP: Saw pod success 04/23/23 12:30:09.289
Apr 23 12:30:09.289: INFO: Pod "pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a" satisfied condition "Succeeded or Failed"
Apr 23 12:30:09.296: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a container agnhost-container: <nil>
STEP: delete the pod 04/23/23 12:30:09.336
Apr 23 12:30:09.354: INFO: Waiting for pod pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a to disappear
Apr 23 12:30:09.367: INFO: Pod pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Apr 23 12:30:09.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-2707" for this suite. 04/23/23 12:30:09.377
------------------------------
â€¢ [SLOW TEST] [6.233 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:99

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:30:03.158
    Apr 23 12:30:03.158: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 12:30:03.165
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:30:03.198
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:30:03.203
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:99
    STEP: Creating configMap with name projected-configmap-test-volume-map-b73ccd7c-c9c5-4149-9641-b41294e1a2b1 04/23/23 12:30:03.209
    STEP: Creating a pod to test consume configMaps 04/23/23 12:30:03.223
    Apr 23 12:30:03.256: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a" in namespace "projected-2707" to be "Succeeded or Failed"
    Apr 23 12:30:03.276: INFO: Pod "pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.001153ms
    Apr 23 12:30:05.284: INFO: Pod "pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a": Phase="Running", Reason="", readiness=true. Elapsed: 2.027786049s
    Apr 23 12:30:07.285: INFO: Pod "pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a": Phase="Running", Reason="", readiness=false. Elapsed: 4.028873264s
    Apr 23 12:30:09.289: INFO: Pod "pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032421347s
    STEP: Saw pod success 04/23/23 12:30:09.289
    Apr 23 12:30:09.289: INFO: Pod "pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a" satisfied condition "Succeeded or Failed"
    Apr 23 12:30:09.296: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 12:30:09.336
    Apr 23 12:30:09.354: INFO: Waiting for pod pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a to disappear
    Apr 23 12:30:09.367: INFO: Pod pod-projected-configmaps-87a2c285-c440-4c4e-adda-fd542e69c94a no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:30:09.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-2707" for this suite. 04/23/23 12:30:09.377
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:30:09.394
Apr 23 12:30:09.394: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename deployment 04/23/23 12:30:09.398
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:30:09.432
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:30:09.437
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Apr 23 12:30:09.448: INFO: Creating simple deployment test-new-deployment
Apr 23 12:30:09.478: INFO: deployment "test-new-deployment" doesn't have the required revision set
Apr 23 12:30:11.514: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 30, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 30, 9, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 30, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 30, 9, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-7f5969cbc7\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: getting scale subresource 04/23/23 12:30:13.53
STEP: updating a scale subresource 04/23/23 12:30:13.536
STEP: verifying the deployment Spec.Replicas was modified 04/23/23 12:30:13.549
STEP: Patch a scale subresource 04/23/23 12:30:13.556
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 23 12:30:13.615: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-3243  4c1cdc72-318d-4eaa-aa71-2a8a2fe4b8c1 33129 3 2023-04-23 12:30:09 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-04-23 12:30:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:30:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e81ca8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-23 12:30:12 +0000 UTC,LastTransitionTime:2023-04-23 12:30:12 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-7f5969cbc7" has successfully progressed.,LastUpdateTime:2023-04-23 12:30:12 +0000 UTC,LastTransitionTime:2023-04-23 12:30:09 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 23 12:30:13.633: INFO: New ReplicaSet "test-new-deployment-7f5969cbc7" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-7f5969cbc7  deployment-3243  972a53c6-3ba5-4ac7-8671-fa57e5f232b7 33133 2 2023-04-23 12:30:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 4c1cdc72-318d-4eaa-aa71-2a8a2fe4b8c1 0xc0002c70d7 0xc0002c70d8}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:30:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4c1cdc72-318d-4eaa-aa71-2a8a2fe4b8c1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:30:13 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 7f5969cbc7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000be40b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 23 12:30:13.668: INFO: Pod "test-new-deployment-7f5969cbc7-b6tx6" is not available:
&Pod{ObjectMeta:{test-new-deployment-7f5969cbc7-b6tx6 test-new-deployment-7f5969cbc7- deployment-3243  454bcbba-4cb2-4d09-8463-b24c13fbf4d7 33132 0 2023-04-23 12:30:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet test-new-deployment-7f5969cbc7 972a53c6-3ba5-4ac7-8671-fa57e5f232b7 0xc0033d80d7 0xc0033d80d8}] [] [{kube-controller-manager Update v1 2023-04-23 12:30:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"972a53c6-3ba5-4ac7-8671-fa57e5f232b7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hdxwd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hdxwd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:30:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:30:13.669: INFO: Pod "test-new-deployment-7f5969cbc7-pfwsf" is available:
&Pod{ObjectMeta:{test-new-deployment-7f5969cbc7-pfwsf test-new-deployment-7f5969cbc7- deployment-3243  a4fec4e0-9a83-42f5-8903-97f157d99706 33121 0 2023-04-23 12:30:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet test-new-deployment-7f5969cbc7 972a53c6-3ba5-4ac7-8671-fa57e5f232b7 0xc0033d8250 0xc0033d8251}] [] [{kube-controller-manager Update v1 2023-04-23 12:30:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"972a53c6-3ba5-4ac7-8671-fa57e5f232b7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:30:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.130\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-txzgt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-txzgt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:30:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:30:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:30:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:30:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.130,StartTime:2023-04-23 12:30:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:30:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://c48365ab9a6c33f1c311b9e74a21a5df6bd49cfaa01f8e14fff84694939f8693,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.130,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Apr 23 12:30:13.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-3243" for this suite. 04/23/23 12:30:13.683
------------------------------
â€¢ [4.308 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:30:09.394
    Apr 23 12:30:09.394: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename deployment 04/23/23 12:30:09.398
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:30:09.432
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:30:09.437
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Apr 23 12:30:09.448: INFO: Creating simple deployment test-new-deployment
    Apr 23 12:30:09.478: INFO: deployment "test-new-deployment" doesn't have the required revision set
    Apr 23 12:30:11.514: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 30, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 30, 9, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 30, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 30, 9, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-7f5969cbc7\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: getting scale subresource 04/23/23 12:30:13.53
    STEP: updating a scale subresource 04/23/23 12:30:13.536
    STEP: verifying the deployment Spec.Replicas was modified 04/23/23 12:30:13.549
    STEP: Patch a scale subresource 04/23/23 12:30:13.556
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 23 12:30:13.615: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-3243  4c1cdc72-318d-4eaa-aa71-2a8a2fe4b8c1 33129 3 2023-04-23 12:30:09 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-04-23 12:30:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:30:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e81ca8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-23 12:30:12 +0000 UTC,LastTransitionTime:2023-04-23 12:30:12 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-7f5969cbc7" has successfully progressed.,LastUpdateTime:2023-04-23 12:30:12 +0000 UTC,LastTransitionTime:2023-04-23 12:30:09 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 23 12:30:13.633: INFO: New ReplicaSet "test-new-deployment-7f5969cbc7" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-7f5969cbc7  deployment-3243  972a53c6-3ba5-4ac7-8671-fa57e5f232b7 33133 2 2023-04-23 12:30:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 4c1cdc72-318d-4eaa-aa71-2a8a2fe4b8c1 0xc0002c70d7 0xc0002c70d8}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:30:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4c1cdc72-318d-4eaa-aa71-2a8a2fe4b8c1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:30:13 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 7f5969cbc7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000be40b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 23 12:30:13.668: INFO: Pod "test-new-deployment-7f5969cbc7-b6tx6" is not available:
    &Pod{ObjectMeta:{test-new-deployment-7f5969cbc7-b6tx6 test-new-deployment-7f5969cbc7- deployment-3243  454bcbba-4cb2-4d09-8463-b24c13fbf4d7 33132 0 2023-04-23 12:30:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet test-new-deployment-7f5969cbc7 972a53c6-3ba5-4ac7-8671-fa57e5f232b7 0xc0033d80d7 0xc0033d80d8}] [] [{kube-controller-manager Update v1 2023-04-23 12:30:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"972a53c6-3ba5-4ac7-8671-fa57e5f232b7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hdxwd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hdxwd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:30:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:30:13.669: INFO: Pod "test-new-deployment-7f5969cbc7-pfwsf" is available:
    &Pod{ObjectMeta:{test-new-deployment-7f5969cbc7-pfwsf test-new-deployment-7f5969cbc7- deployment-3243  a4fec4e0-9a83-42f5-8903-97f157d99706 33121 0 2023-04-23 12:30:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet test-new-deployment-7f5969cbc7 972a53c6-3ba5-4ac7-8671-fa57e5f232b7 0xc0033d8250 0xc0033d8251}] [] [{kube-controller-manager Update v1 2023-04-23 12:30:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"972a53c6-3ba5-4ac7-8671-fa57e5f232b7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:30:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.130\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-txzgt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-txzgt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:30:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:30:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:30:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:30:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.130,StartTime:2023-04-23 12:30:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:30:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://c48365ab9a6c33f1c311b9e74a21a5df6bd49cfaa01f8e14fff84694939f8693,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.130,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:30:13.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-3243" for this suite. 04/23/23 12:30:13.683
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:197
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:30:13.707
Apr 23 12:30:13.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 12:30:13.71
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:30:13.769
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:30:13.777
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:197
STEP: Creating a pod to test emptydir 0644 on node default medium 04/23/23 12:30:13.783
Apr 23 12:30:13.808: INFO: Waiting up to 5m0s for pod "pod-6daf55d4-def6-4987-a144-acc8bf9af605" in namespace "emptydir-5773" to be "Succeeded or Failed"
Apr 23 12:30:13.816: INFO: Pod "pod-6daf55d4-def6-4987-a144-acc8bf9af605": Phase="Pending", Reason="", readiness=false. Elapsed: 7.340396ms
Apr 23 12:30:15.829: INFO: Pod "pod-6daf55d4-def6-4987-a144-acc8bf9af605": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020634707s
Apr 23 12:30:17.824: INFO: Pod "pod-6daf55d4-def6-4987-a144-acc8bf9af605": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015259948s
Apr 23 12:30:19.845: INFO: Pod "pod-6daf55d4-def6-4987-a144-acc8bf9af605": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036346902s
STEP: Saw pod success 04/23/23 12:30:19.845
Apr 23 12:30:19.847: INFO: Pod "pod-6daf55d4-def6-4987-a144-acc8bf9af605" satisfied condition "Succeeded or Failed"
Apr 23 12:30:19.855: INFO: Trying to get logs from node eingavuivie7-3 pod pod-6daf55d4-def6-4987-a144-acc8bf9af605 container test-container: <nil>
STEP: delete the pod 04/23/23 12:30:19.871
Apr 23 12:30:19.897: INFO: Waiting for pod pod-6daf55d4-def6-4987-a144-acc8bf9af605 to disappear
Apr 23 12:30:19.903: INFO: Pod pod-6daf55d4-def6-4987-a144-acc8bf9af605 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 12:30:19.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-5773" for this suite. 04/23/23 12:30:19.914
------------------------------
â€¢ [SLOW TEST] [6.222 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:197

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:30:13.707
    Apr 23 12:30:13.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 12:30:13.71
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:30:13.769
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:30:13.777
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:197
    STEP: Creating a pod to test emptydir 0644 on node default medium 04/23/23 12:30:13.783
    Apr 23 12:30:13.808: INFO: Waiting up to 5m0s for pod "pod-6daf55d4-def6-4987-a144-acc8bf9af605" in namespace "emptydir-5773" to be "Succeeded or Failed"
    Apr 23 12:30:13.816: INFO: Pod "pod-6daf55d4-def6-4987-a144-acc8bf9af605": Phase="Pending", Reason="", readiness=false. Elapsed: 7.340396ms
    Apr 23 12:30:15.829: INFO: Pod "pod-6daf55d4-def6-4987-a144-acc8bf9af605": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020634707s
    Apr 23 12:30:17.824: INFO: Pod "pod-6daf55d4-def6-4987-a144-acc8bf9af605": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015259948s
    Apr 23 12:30:19.845: INFO: Pod "pod-6daf55d4-def6-4987-a144-acc8bf9af605": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036346902s
    STEP: Saw pod success 04/23/23 12:30:19.845
    Apr 23 12:30:19.847: INFO: Pod "pod-6daf55d4-def6-4987-a144-acc8bf9af605" satisfied condition "Succeeded or Failed"
    Apr 23 12:30:19.855: INFO: Trying to get logs from node eingavuivie7-3 pod pod-6daf55d4-def6-4987-a144-acc8bf9af605 container test-container: <nil>
    STEP: delete the pod 04/23/23 12:30:19.871
    Apr 23 12:30:19.897: INFO: Waiting for pod pod-6daf55d4-def6-4987-a144-acc8bf9af605 to disappear
    Apr 23 12:30:19.903: INFO: Pod pod-6daf55d4-def6-4987-a144-acc8bf9af605 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:30:19.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-5773" for this suite. 04/23/23 12:30:19.914
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:175
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:30:19.939
Apr 23 12:30:19.940: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 12:30:19.944
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:30:19.983
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:30:19.993
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:175
STEP: Creating configMap with name configmap-test-upd-8186e9eb-a359-4777-950b-f58ee38d56f0 04/23/23 12:30:20.015
STEP: Creating the pod 04/23/23 12:30:20.026
Apr 23 12:30:20.053: INFO: Waiting up to 5m0s for pod "pod-configmaps-17e704f5-3fbd-4857-ac3b-99f13e1bc1cd" in namespace "configmap-1359" to be "running"
Apr 23 12:30:20.068: INFO: Pod "pod-configmaps-17e704f5-3fbd-4857-ac3b-99f13e1bc1cd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.860937ms
Apr 23 12:30:22.080: INFO: Pod "pod-configmaps-17e704f5-3fbd-4857-ac3b-99f13e1bc1cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026442774s
Apr 23 12:30:24.080: INFO: Pod "pod-configmaps-17e704f5-3fbd-4857-ac3b-99f13e1bc1cd": Phase="Running", Reason="", readiness=false. Elapsed: 4.026999673s
Apr 23 12:30:24.080: INFO: Pod "pod-configmaps-17e704f5-3fbd-4857-ac3b-99f13e1bc1cd" satisfied condition "running"
STEP: Waiting for pod with text data 04/23/23 12:30:24.08
STEP: Waiting for pod with binary data 04/23/23 12:30:24.099
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 12:30:24.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-1359" for this suite. 04/23/23 12:30:24.119
------------------------------
â€¢ [4.195 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:30:19.939
    Apr 23 12:30:19.940: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 12:30:19.944
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:30:19.983
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:30:19.993
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:175
    STEP: Creating configMap with name configmap-test-upd-8186e9eb-a359-4777-950b-f58ee38d56f0 04/23/23 12:30:20.015
    STEP: Creating the pod 04/23/23 12:30:20.026
    Apr 23 12:30:20.053: INFO: Waiting up to 5m0s for pod "pod-configmaps-17e704f5-3fbd-4857-ac3b-99f13e1bc1cd" in namespace "configmap-1359" to be "running"
    Apr 23 12:30:20.068: INFO: Pod "pod-configmaps-17e704f5-3fbd-4857-ac3b-99f13e1bc1cd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.860937ms
    Apr 23 12:30:22.080: INFO: Pod "pod-configmaps-17e704f5-3fbd-4857-ac3b-99f13e1bc1cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026442774s
    Apr 23 12:30:24.080: INFO: Pod "pod-configmaps-17e704f5-3fbd-4857-ac3b-99f13e1bc1cd": Phase="Running", Reason="", readiness=false. Elapsed: 4.026999673s
    Apr 23 12:30:24.080: INFO: Pod "pod-configmaps-17e704f5-3fbd-4857-ac3b-99f13e1bc1cd" satisfied condition "running"
    STEP: Waiting for pod with text data 04/23/23 12:30:24.08
    STEP: Waiting for pod with binary data 04/23/23 12:30:24.099
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:30:24.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-1359" for this suite. 04/23/23 12:30:24.119
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:30:24.14
Apr 23 12:30:24.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename cronjob 04/23/23 12:30:24.144
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:30:24.182
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:30:24.19
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:31
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 04/23/23 12:30:24.197
STEP: Ensuring a job is scheduled 04/23/23 12:30:24.211
STEP: Ensuring exactly one is scheduled 04/23/23 12:31:00.221
STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/23/23 12:31:00.232
STEP: Ensuring no more jobs are scheduled 04/23/23 12:31:00.24
STEP: Removing cronjob 04/23/23 12:36:00.259
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/node/init/init.go:32
Apr 23 12:36:00.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] CronJob
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] CronJob
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] CronJob
  tear down framework | framework.go:193
STEP: Destroying namespace "cronjob-9898" for this suite. 04/23/23 12:36:00.298
------------------------------
â€¢ [SLOW TEST] [336.175 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:30:24.14
    Apr 23 12:30:24.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename cronjob 04/23/23 12:30:24.144
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:30:24.182
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:30:24.19
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:31
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 04/23/23 12:30:24.197
    STEP: Ensuring a job is scheduled 04/23/23 12:30:24.211
    STEP: Ensuring exactly one is scheduled 04/23/23 12:31:00.221
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/23/23 12:31:00.232
    STEP: Ensuring no more jobs are scheduled 04/23/23 12:31:00.24
    STEP: Removing cronjob 04/23/23 12:36:00.259
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:36:00.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] CronJob
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] CronJob
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] CronJob
      tear down framework | framework.go:193
    STEP: Destroying namespace "cronjob-9898" for this suite. 04/23/23 12:36:00.298
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:166
[BeforeEach] [sig-apps] Daemon set [Serial]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:36:00.315
Apr 23 12:36:00.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename daemonsets 04/23/23 12:36:00.323
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:36:00.363
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:36:00.367
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:146
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:166
STEP: Creating simple DaemonSet "daemon-set" 04/23/23 12:36:00.413
STEP: Check that daemon pods launch on every node of the cluster. 04/23/23 12:36:00.436
Apr 23 12:36:00.477: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 12:36:00.477: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:36:01.538: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 12:36:01.538: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:36:02.508: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 23 12:36:02.508: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 04/23/23 12:36:02.514
Apr 23 12:36:02.585: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 12:36:02.585: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:36:03.614: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 12:36:03.614: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:36:04.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 12:36:04.605: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:36:05.613: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 12:36:05.614: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:36:06.600: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 23 12:36:06.600: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
Apr 23 12:36:07.608: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 23 12:36:07.608: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:111
STEP: Deleting DaemonSet "daemon-set" 04/23/23 12:36:07.613
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5798, will wait for the garbage collector to delete the pods 04/23/23 12:36:07.614
Apr 23 12:36:07.681: INFO: Deleting DaemonSet.extensions daemon-set took: 10.97287ms
Apr 23 12:36:07.782: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.169684ms
Apr 23 12:36:10.193: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 23 12:36:10.193: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 23 12:36:10.198: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"34239"},"items":null}

Apr 23 12:36:10.204: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"34239"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:36:10.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
  tear down framework | framework.go:193
STEP: Destroying namespace "daemonsets-5798" for this suite. 04/23/23 12:36:10.245
------------------------------
â€¢ [SLOW TEST] [9.942 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:36:00.315
    Apr 23 12:36:00.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename daemonsets 04/23/23 12:36:00.323
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:36:00.363
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:36:00.367
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:146
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:166
    STEP: Creating simple DaemonSet "daemon-set" 04/23/23 12:36:00.413
    STEP: Check that daemon pods launch on every node of the cluster. 04/23/23 12:36:00.436
    Apr 23 12:36:00.477: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 12:36:00.477: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:36:01.538: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 12:36:01.538: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:36:02.508: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 23 12:36:02.508: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 04/23/23 12:36:02.514
    Apr 23 12:36:02.585: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 12:36:02.585: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:36:03.614: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 12:36:03.614: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:36:04.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 12:36:04.605: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:36:05.613: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 12:36:05.614: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:36:06.600: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 23 12:36:06.600: INFO: Node eingavuivie7-1 is running 0 daemon pod, expected 1
    Apr 23 12:36:07.608: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 23 12:36:07.608: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:111
    STEP: Deleting DaemonSet "daemon-set" 04/23/23 12:36:07.613
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5798, will wait for the garbage collector to delete the pods 04/23/23 12:36:07.614
    Apr 23 12:36:07.681: INFO: Deleting DaemonSet.extensions daemon-set took: 10.97287ms
    Apr 23 12:36:07.782: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.169684ms
    Apr 23 12:36:10.193: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 23 12:36:10.193: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 23 12:36:10.198: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"34239"},"items":null}

    Apr 23 12:36:10.204: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"34239"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:36:10.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Daemon set [Serial]
      tear down framework | framework.go:193
    STEP: Destroying namespace "daemonsets-5798" for this suite. 04/23/23 12:36:10.245
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:36:10.262
Apr 23 12:36:10.262: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename runtimeclass 04/23/23 12:36:10.269
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:36:10.294
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:36:10.3
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:31
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Apr 23 12:36:10.330: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-179 to be scheduled
Apr 23 12:36:10.342: INFO: 1 pods are not scheduled: [runtimeclass-179/test-runtimeclass-runtimeclass-179-preconfigured-handler-hjj7r(3266188d-b838-46a9-9a31-5dc9cfc17f3e)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/node/init/init.go:32
Apr 23 12:36:12.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] RuntimeClass
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] RuntimeClass
  tear down framework | framework.go:193
STEP: Destroying namespace "runtimeclass-179" for this suite. 04/23/23 12:36:12.372
------------------------------
â€¢ [2.121 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:36:10.262
    Apr 23 12:36:10.262: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename runtimeclass 04/23/23 12:36:10.269
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:36:10.294
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:36:10.3
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:31
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Apr 23 12:36:10.330: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-179 to be scheduled
    Apr 23 12:36:10.342: INFO: 1 pods are not scheduled: [runtimeclass-179/test-runtimeclass-runtimeclass-179-preconfigured-handler-hjj7r(3266188d-b838-46a9-9a31-5dc9cfc17f3e)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:36:12.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      tear down framework | framework.go:193
    STEP: Destroying namespace "runtimeclass-179" for this suite. 04/23/23 12:36:12.372
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:74
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:36:12.385
Apr 23 12:36:12.386: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 12:36:12.391
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:36:12.434
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:36:12.437
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:74
STEP: Creating configMap with name projected-configmap-test-volume-5464d41f-49e5-4011-b4ea-69c8e946a3ef 04/23/23 12:36:12.45
STEP: Creating a pod to test consume configMaps 04/23/23 12:36:12.461
Apr 23 12:36:12.481: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f" in namespace "projected-255" to be "Succeeded or Failed"
Apr 23 12:36:12.486: INFO: Pod "pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.862421ms
Apr 23 12:36:14.494: INFO: Pod "pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012734693s
Apr 23 12:36:16.530: INFO: Pod "pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.049104477s
Apr 23 12:36:18.506: INFO: Pod "pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024937886s
STEP: Saw pod success 04/23/23 12:36:18.506
Apr 23 12:36:18.507: INFO: Pod "pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f" satisfied condition "Succeeded or Failed"
Apr 23 12:36:18.515: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f container agnhost-container: <nil>
STEP: delete the pod 04/23/23 12:36:18.597
Apr 23 12:36:18.630: INFO: Waiting for pod pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f to disappear
Apr 23 12:36:18.646: INFO: Pod pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Apr 23 12:36:18.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-255" for this suite. 04/23/23 12:36:18.673
------------------------------
â€¢ [SLOW TEST] [6.309 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:74

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:36:12.385
    Apr 23 12:36:12.386: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 12:36:12.391
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:36:12.434
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:36:12.437
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:74
    STEP: Creating configMap with name projected-configmap-test-volume-5464d41f-49e5-4011-b4ea-69c8e946a3ef 04/23/23 12:36:12.45
    STEP: Creating a pod to test consume configMaps 04/23/23 12:36:12.461
    Apr 23 12:36:12.481: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f" in namespace "projected-255" to be "Succeeded or Failed"
    Apr 23 12:36:12.486: INFO: Pod "pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.862421ms
    Apr 23 12:36:14.494: INFO: Pod "pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012734693s
    Apr 23 12:36:16.530: INFO: Pod "pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.049104477s
    Apr 23 12:36:18.506: INFO: Pod "pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024937886s
    STEP: Saw pod success 04/23/23 12:36:18.506
    Apr 23 12:36:18.507: INFO: Pod "pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f" satisfied condition "Succeeded or Failed"
    Apr 23 12:36:18.515: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 12:36:18.597
    Apr 23 12:36:18.630: INFO: Waiting for pod pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f to disappear
    Apr 23 12:36:18.646: INFO: Pod pod-projected-configmaps-a9f1729e-85aa-478d-92d6-48874af6ac4f no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:36:18.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-255" for this suite. 04/23/23 12:36:18.673
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:690
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:36:18.707
Apr 23 12:36:18.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename resourcequota 04/23/23 12:36:18.71
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:36:18.737
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:36:18.741
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:690
STEP: Creating a ResourceQuota with terminating scope 04/23/23 12:36:18.745
STEP: Ensuring ResourceQuota status is calculated 04/23/23 12:36:18.755
STEP: Creating a ResourceQuota with not terminating scope 04/23/23 12:36:20.763
STEP: Ensuring ResourceQuota status is calculated 04/23/23 12:36:20.772
STEP: Creating a long running pod 04/23/23 12:36:22.779
STEP: Ensuring resource quota with not terminating scope captures the pod usage 04/23/23 12:36:22.8
STEP: Ensuring resource quota with terminating scope ignored the pod usage 04/23/23 12:36:24.81
STEP: Deleting the pod 04/23/23 12:36:26.819
STEP: Ensuring resource quota status released the pod usage 04/23/23 12:36:26.868
STEP: Creating a terminating pod 04/23/23 12:36:28.877
STEP: Ensuring resource quota with terminating scope captures the pod usage 04/23/23 12:36:28.899
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 04/23/23 12:36:30.907
STEP: Deleting the pod 04/23/23 12:36:32.916
STEP: Ensuring resource quota status released the pod usage 04/23/23 12:36:32.942
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Apr 23 12:36:34.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-4205" for this suite. 04/23/23 12:36:34.966
------------------------------
â€¢ [SLOW TEST] [16.284 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:690

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:36:18.707
    Apr 23 12:36:18.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename resourcequota 04/23/23 12:36:18.71
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:36:18.737
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:36:18.741
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:690
    STEP: Creating a ResourceQuota with terminating scope 04/23/23 12:36:18.745
    STEP: Ensuring ResourceQuota status is calculated 04/23/23 12:36:18.755
    STEP: Creating a ResourceQuota with not terminating scope 04/23/23 12:36:20.763
    STEP: Ensuring ResourceQuota status is calculated 04/23/23 12:36:20.772
    STEP: Creating a long running pod 04/23/23 12:36:22.779
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 04/23/23 12:36:22.8
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 04/23/23 12:36:24.81
    STEP: Deleting the pod 04/23/23 12:36:26.819
    STEP: Ensuring resource quota status released the pod usage 04/23/23 12:36:26.868
    STEP: Creating a terminating pod 04/23/23 12:36:28.877
    STEP: Ensuring resource quota with terminating scope captures the pod usage 04/23/23 12:36:28.899
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 04/23/23 12:36:30.907
    STEP: Deleting the pod 04/23/23 12:36:32.916
    STEP: Ensuring resource quota status released the pod usage 04/23/23 12:36:32.942
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:36:34.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-4205" for this suite. 04/23/23 12:36:34.966
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:448
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:36:34.999
Apr 23 12:36:34.999: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename resourcequota 04/23/23 12:36:35.001
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:36:35.05
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:36:35.055
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:448
STEP: Counting existing ResourceQuota 04/23/23 12:36:35.063
STEP: Creating a ResourceQuota 04/23/23 12:36:40.075
STEP: Ensuring resource quota status is calculated 04/23/23 12:36:40.088
STEP: Creating a ReplicaSet 04/23/23 12:36:42.097
STEP: Ensuring resource quota status captures replicaset creation 04/23/23 12:36:42.125
STEP: Deleting a ReplicaSet 04/23/23 12:36:44.133
STEP: Ensuring resource quota status released usage 04/23/23 12:36:44.155
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Apr 23 12:36:46.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-836" for this suite. 04/23/23 12:36:46.177
------------------------------
â€¢ [SLOW TEST] [11.190 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:448

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:36:34.999
    Apr 23 12:36:34.999: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename resourcequota 04/23/23 12:36:35.001
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:36:35.05
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:36:35.055
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:448
    STEP: Counting existing ResourceQuota 04/23/23 12:36:35.063
    STEP: Creating a ResourceQuota 04/23/23 12:36:40.075
    STEP: Ensuring resource quota status is calculated 04/23/23 12:36:40.088
    STEP: Creating a ReplicaSet 04/23/23 12:36:42.097
    STEP: Ensuring resource quota status captures replicaset creation 04/23/23 12:36:42.125
    STEP: Deleting a ReplicaSet 04/23/23 12:36:44.133
    STEP: Ensuring resource quota status released usage 04/23/23 12:36:44.155
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:36:46.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-836" for this suite. 04/23/23 12:36:46.177
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:392
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:36:46.207
Apr 23 12:36:46.208: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename resourcequota 04/23/23 12:36:46.215
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:36:46.245
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:36:46.251
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:392
STEP: Counting existing ResourceQuota 04/23/23 12:36:46.256
STEP: Creating a ResourceQuota 04/23/23 12:36:51.264
STEP: Ensuring resource quota status is calculated 04/23/23 12:36:51.276
STEP: Creating a ReplicationController 04/23/23 12:36:53.286
STEP: Ensuring resource quota status captures replication controller creation 04/23/23 12:36:53.307
STEP: Deleting a ReplicationController 04/23/23 12:36:55.317
STEP: Ensuring resource quota status released usage 04/23/23 12:36:55.334
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Apr 23 12:36:57.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-195" for this suite. 04/23/23 12:36:57.375
------------------------------
â€¢ [SLOW TEST] [11.180 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:36:46.207
    Apr 23 12:36:46.208: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename resourcequota 04/23/23 12:36:46.215
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:36:46.245
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:36:46.251
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:392
    STEP: Counting existing ResourceQuota 04/23/23 12:36:46.256
    STEP: Creating a ResourceQuota 04/23/23 12:36:51.264
    STEP: Ensuring resource quota status is calculated 04/23/23 12:36:51.276
    STEP: Creating a ReplicationController 04/23/23 12:36:53.286
    STEP: Ensuring resource quota status captures replication controller creation 04/23/23 12:36:53.307
    STEP: Deleting a ReplicationController 04/23/23 12:36:55.317
    STEP: Ensuring resource quota status released usage 04/23/23 12:36:55.334
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:36:57.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-195" for this suite. 04/23/23 12:36:57.375
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:73
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:36:57.389
Apr 23 12:36:57.389: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename var-expansion 04/23/23 12:36:57.394
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:36:57.434
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:36:57.438
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:73
STEP: Creating a pod to test substitution in container's command 04/23/23 12:36:57.444
Apr 23 12:36:57.464: INFO: Waiting up to 5m0s for pod "var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8" in namespace "var-expansion-1115" to be "Succeeded or Failed"
Apr 23 12:36:57.475: INFO: Pod "var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.747598ms
Apr 23 12:36:59.499: INFO: Pod "var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034126613s
Apr 23 12:37:01.483: INFO: Pod "var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018213454s
Apr 23 12:37:03.484: INFO: Pod "var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019848399s
STEP: Saw pod success 04/23/23 12:37:03.485
Apr 23 12:37:03.485: INFO: Pod "var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8" satisfied condition "Succeeded or Failed"
Apr 23 12:37:03.491: INFO: Trying to get logs from node eingavuivie7-3 pod var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8 container dapi-container: <nil>
STEP: delete the pod 04/23/23 12:37:03.657
Apr 23 12:37:03.681: INFO: Waiting for pod var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8 to disappear
Apr 23 12:37:03.695: INFO: Pod var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Apr 23 12:37:03.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-1115" for this suite. 04/23/23 12:37:03.723
------------------------------
â€¢ [SLOW TEST] [6.360 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:36:57.389
    Apr 23 12:36:57.389: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename var-expansion 04/23/23 12:36:57.394
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:36:57.434
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:36:57.438
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:73
    STEP: Creating a pod to test substitution in container's command 04/23/23 12:36:57.444
    Apr 23 12:36:57.464: INFO: Waiting up to 5m0s for pod "var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8" in namespace "var-expansion-1115" to be "Succeeded or Failed"
    Apr 23 12:36:57.475: INFO: Pod "var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.747598ms
    Apr 23 12:36:59.499: INFO: Pod "var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034126613s
    Apr 23 12:37:01.483: INFO: Pod "var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018213454s
    Apr 23 12:37:03.484: INFO: Pod "var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019848399s
    STEP: Saw pod success 04/23/23 12:37:03.485
    Apr 23 12:37:03.485: INFO: Pod "var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8" satisfied condition "Succeeded or Failed"
    Apr 23 12:37:03.491: INFO: Trying to get logs from node eingavuivie7-3 pod var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8 container dapi-container: <nil>
    STEP: delete the pod 04/23/23 12:37:03.657
    Apr 23 12:37:03.681: INFO: Waiting for pod var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8 to disappear
    Apr 23 12:37:03.695: INFO: Pod var-expansion-5695ebc7-5b40-487e-b0db-75a9d69355d8 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:37:03.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-1115" for this suite. 04/23/23 12:37:03.723
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:37:03.75
Apr 23 12:37:03.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename gc 04/23/23 12:37:03.754
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:03.773
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:03.779
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:31
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 04/23/23 12:37:03.786
STEP: Wait for the Deployment to create new ReplicaSet 04/23/23 12:37:03.795
STEP: delete the deployment 04/23/23 12:37:04.308
STEP: wait for all rs to be garbage collected 04/23/23 12:37:04.331
STEP: expected 0 rs, got 1 rs 04/23/23 12:37:04.354
STEP: expected 0 pods, got 2 pods 04/23/23 12:37:04.363
STEP: Gathering metrics 04/23/23 12:37:04.98
Apr 23 12:37:05.063: INFO: Waiting up to 5m0s for pod "kube-controller-manager-eingavuivie7-2" in namespace "kube-system" to be "running and ready"
Apr 23 12:37:05.080: INFO: Pod "kube-controller-manager-eingavuivie7-2": Phase="Running", Reason="", readiness=true. Elapsed: 17.195636ms
Apr 23 12:37:05.081: INFO: The phase of Pod kube-controller-manager-eingavuivie7-2 is Running (Ready = true)
Apr 23 12:37:05.081: INFO: Pod "kube-controller-manager-eingavuivie7-2" satisfied condition "running and ready"
Apr 23 12:37:05.247: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/node/init/init.go:32
Apr 23 12:37:05.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  tear down framework | framework.go:193
STEP: Destroying namespace "gc-7270" for this suite. 04/23/23 12:37:05.257
------------------------------
â€¢ [1.523 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:37:03.75
    Apr 23 12:37:03.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename gc 04/23/23 12:37:03.754
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:03.773
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:03.779
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:31
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 04/23/23 12:37:03.786
    STEP: Wait for the Deployment to create new ReplicaSet 04/23/23 12:37:03.795
    STEP: delete the deployment 04/23/23 12:37:04.308
    STEP: wait for all rs to be garbage collected 04/23/23 12:37:04.331
    STEP: expected 0 rs, got 1 rs 04/23/23 12:37:04.354
    STEP: expected 0 pods, got 2 pods 04/23/23 12:37:04.363
    STEP: Gathering metrics 04/23/23 12:37:04.98
    Apr 23 12:37:05.063: INFO: Waiting up to 5m0s for pod "kube-controller-manager-eingavuivie7-2" in namespace "kube-system" to be "running and ready"
    Apr 23 12:37:05.080: INFO: Pod "kube-controller-manager-eingavuivie7-2": Phase="Running", Reason="", readiness=true. Elapsed: 17.195636ms
    Apr 23 12:37:05.081: INFO: The phase of Pod kube-controller-manager-eingavuivie7-2 is Running (Ready = true)
    Apr 23 12:37:05.081: INFO: Pod "kube-controller-manager-eingavuivie7-2" satisfied condition "running and ready"
    Apr 23 12:37:05.247: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:37:05.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      tear down framework | framework.go:193
    STEP: Destroying namespace "gc-7270" for this suite. 04/23/23 12:37:05.257
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:977
[BeforeEach] [sig-apps] StatefulSet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:37:05.295
Apr 23 12:37:05.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename statefulset 04/23/23 12:37:05.298
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:05.323
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:05.328
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:98
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:113
STEP: Creating service test in namespace statefulset-710 04/23/23 12:37:05.334
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:977
STEP: Creating statefulset ss in namespace statefulset-710 04/23/23 12:37:05.355
Apr 23 12:37:05.388: INFO: Found 0 stateful pods, waiting for 1
Apr 23 12:37:15.396: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 04/23/23 12:37:15.409
STEP: Getting /status 04/23/23 12:37:15.422
Apr 23 12:37:15.431: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 04/23/23 12:37:15.431
Apr 23 12:37:15.448: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 04/23/23 12:37:15.448
Apr 23 12:37:15.454: INFO: Observed &StatefulSet event: ADDED
Apr 23 12:37:15.454: INFO: Found Statefulset ss in namespace statefulset-710 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 23 12:37:15.454: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 04/23/23 12:37:15.454
Apr 23 12:37:15.455: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 23 12:37:15.495: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 04/23/23 12:37:15.495
Apr 23 12:37:15.499: INFO: Observed &StatefulSet event: ADDED
Apr 23 12:37:15.500: INFO: Observed Statefulset ss in namespace statefulset-710 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 23 12:37:15.500: INFO: Observed &StatefulSet event: MODIFIED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:124
Apr 23 12:37:15.500: INFO: Deleting all statefulset in ns statefulset-710
Apr 23 12:37:15.506: INFO: Scaling statefulset ss to 0
Apr 23 12:37:25.544: INFO: Waiting for statefulset status.replicas updated to 0
Apr 23 12:37:25.550: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/node/init/init.go:32
Apr 23 12:37:25.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] StatefulSet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] StatefulSet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] StatefulSet
  tear down framework | framework.go:193
STEP: Destroying namespace "statefulset-710" for this suite. 04/23/23 12:37:25.615
------------------------------
â€¢ [SLOW TEST] [20.336 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:103
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:977

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:37:05.295
    Apr 23 12:37:05.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename statefulset 04/23/23 12:37:05.298
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:05.323
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:05.328
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:98
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:113
    STEP: Creating service test in namespace statefulset-710 04/23/23 12:37:05.334
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:977
    STEP: Creating statefulset ss in namespace statefulset-710 04/23/23 12:37:05.355
    Apr 23 12:37:05.388: INFO: Found 0 stateful pods, waiting for 1
    Apr 23 12:37:15.396: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 04/23/23 12:37:15.409
    STEP: Getting /status 04/23/23 12:37:15.422
    Apr 23 12:37:15.431: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 04/23/23 12:37:15.431
    Apr 23 12:37:15.448: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 04/23/23 12:37:15.448
    Apr 23 12:37:15.454: INFO: Observed &StatefulSet event: ADDED
    Apr 23 12:37:15.454: INFO: Found Statefulset ss in namespace statefulset-710 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 23 12:37:15.454: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 04/23/23 12:37:15.454
    Apr 23 12:37:15.455: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 23 12:37:15.495: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 04/23/23 12:37:15.495
    Apr 23 12:37:15.499: INFO: Observed &StatefulSet event: ADDED
    Apr 23 12:37:15.500: INFO: Observed Statefulset ss in namespace statefulset-710 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 23 12:37:15.500: INFO: Observed &StatefulSet event: MODIFIED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:124
    Apr 23 12:37:15.500: INFO: Deleting all statefulset in ns statefulset-710
    Apr 23 12:37:15.506: INFO: Scaling statefulset ss to 0
    Apr 23 12:37:25.544: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 23 12:37:25.550: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:37:25.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] StatefulSet
      tear down framework | framework.go:193
    STEP: Destroying namespace "statefulset-710" for this suite. 04/23/23 12:37:25.615
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:37:25.632
Apr 23 12:37:25.632: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename gc 04/23/23 12:37:25.641
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:25.686
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:25.691
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:31
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 04/23/23 12:37:25.698
STEP: Wait for the Deployment to create new ReplicaSet 04/23/23 12:37:25.709
STEP: delete the deployment 04/23/23 12:37:26.255
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 04/23/23 12:37:26.267
STEP: Gathering metrics 04/23/23 12:37:26.832
Apr 23 12:37:26.879: INFO: Waiting up to 5m0s for pod "kube-controller-manager-eingavuivie7-2" in namespace "kube-system" to be "running and ready"
Apr 23 12:37:26.896: INFO: Pod "kube-controller-manager-eingavuivie7-2": Phase="Running", Reason="", readiness=true. Elapsed: 16.878627ms
Apr 23 12:37:26.896: INFO: The phase of Pod kube-controller-manager-eingavuivie7-2 is Running (Ready = true)
Apr 23 12:37:26.896: INFO: Pod "kube-controller-manager-eingavuivie7-2" satisfied condition "running and ready"
Apr 23 12:37:27.004: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/node/init/init.go:32
Apr 23 12:37:27.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  tear down framework | framework.go:193
STEP: Destroying namespace "gc-5350" for this suite. 04/23/23 12:37:27.016
------------------------------
â€¢ [1.400 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:37:25.632
    Apr 23 12:37:25.632: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename gc 04/23/23 12:37:25.641
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:25.686
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:25.691
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:31
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 04/23/23 12:37:25.698
    STEP: Wait for the Deployment to create new ReplicaSet 04/23/23 12:37:25.709
    STEP: delete the deployment 04/23/23 12:37:26.255
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 04/23/23 12:37:26.267
    STEP: Gathering metrics 04/23/23 12:37:26.832
    Apr 23 12:37:26.879: INFO: Waiting up to 5m0s for pod "kube-controller-manager-eingavuivie7-2" in namespace "kube-system" to be "running and ready"
    Apr 23 12:37:26.896: INFO: Pod "kube-controller-manager-eingavuivie7-2": Phase="Running", Reason="", readiness=true. Elapsed: 16.878627ms
    Apr 23 12:37:26.896: INFO: The phase of Pod kube-controller-manager-eingavuivie7-2 is Running (Ready = true)
    Apr 23 12:37:26.896: INFO: Pod "kube-controller-manager-eingavuivie7-2" satisfied condition "running and ready"
    Apr 23 12:37:27.004: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:37:27.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      tear down framework | framework.go:193
    STEP: Destroying namespace "gc-5350" for this suite. 04/23/23 12:37:27.016
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:154
[BeforeEach] [sig-node] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:37:27.033
Apr 23 12:37:27.033: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename secrets 04/23/23 12:37:27.045
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:27.078
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:27.088
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:154
STEP: creating a secret 04/23/23 12:37:27.093
STEP: listing secrets in all namespaces to ensure that there are more than zero 04/23/23 12:37:27.105
STEP: patching the secret 04/23/23 12:37:27.113
STEP: deleting the secret using a LabelSelector 04/23/23 12:37:27.134
STEP: listing secrets in all namespaces, searching for label name and value in patch 04/23/23 12:37:27.163
[AfterEach] [sig-node] Secrets
  test/e2e/framework/node/init/init.go:32
Apr 23 12:37:27.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-8667" for this suite. 04/23/23 12:37:27.179
------------------------------
â€¢ [0.160 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:37:27.033
    Apr 23 12:37:27.033: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename secrets 04/23/23 12:37:27.045
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:27.078
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:27.088
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:154
    STEP: creating a secret 04/23/23 12:37:27.093
    STEP: listing secrets in all namespaces to ensure that there are more than zero 04/23/23 12:37:27.105
    STEP: patching the secret 04/23/23 12:37:27.113
    STEP: deleting the secret using a LabelSelector 04/23/23 12:37:27.134
    STEP: listing secrets in all namespaces, searching for label name and value in patch 04/23/23 12:37:27.163
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:37:27.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-8667" for this suite. 04/23/23 12:37:27.179
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:87
[BeforeEach] [sig-apps] DisruptionController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:37:27.199
Apr 23 12:37:27.199: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename disruption 04/23/23 12:37:27.212
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:27.263
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:27.272
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:72
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:37:27.293
Apr 23 12:37:27.294: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename disruption-2 04/23/23 12:37:27.298
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:27.346
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:27.363
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/metrics/init/init.go:31
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:87
STEP: Waiting for the pdb to be processed 04/23/23 12:37:27.382
STEP: Waiting for the pdb to be processed 04/23/23 12:37:29.42
STEP: Waiting for the pdb to be processed 04/23/23 12:37:29.444
STEP: listing a collection of PDBs across all namespaces 04/23/23 12:37:29.456
STEP: listing a collection of PDBs in namespace disruption-4177 04/23/23 12:37:29.464
STEP: deleting a collection of PDBs 04/23/23 12:37:29.475
STEP: Waiting for the PDB collection to be deleted 04/23/23 12:37:29.499
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/node/init/init.go:32
Apr 23 12:37:29.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/node/init/init.go:32
Apr 23 12:37:29.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] Listing PodDisruptionBudgets for all namespaces
  dump namespaces | framework.go:196
[DeferCleanup (Each)] Listing PodDisruptionBudgets for all namespaces
  tear down framework | framework.go:193
STEP: Destroying namespace "disruption-2-9605" for this suite. 04/23/23 12:37:29.522
[DeferCleanup (Each)] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] DisruptionController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] DisruptionController
  tear down framework | framework.go:193
STEP: Destroying namespace "disruption-4177" for this suite. 04/23/23 12:37:29.535
------------------------------
â€¢ [2.352 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:78
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:37:27.199
    Apr 23 12:37:27.199: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename disruption 04/23/23 12:37:27.212
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:27.263
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:27.272
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:72
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:37:27.293
    Apr 23 12:37:27.294: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename disruption-2 04/23/23 12:37:27.298
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:27.346
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:27.363
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/metrics/init/init.go:31
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:87
    STEP: Waiting for the pdb to be processed 04/23/23 12:37:27.382
    STEP: Waiting for the pdb to be processed 04/23/23 12:37:29.42
    STEP: Waiting for the pdb to be processed 04/23/23 12:37:29.444
    STEP: listing a collection of PDBs across all namespaces 04/23/23 12:37:29.456
    STEP: listing a collection of PDBs in namespace disruption-4177 04/23/23 12:37:29.464
    STEP: deleting a collection of PDBs 04/23/23 12:37:29.475
    STEP: Waiting for the PDB collection to be deleted 04/23/23 12:37:29.499
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:37:29.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:37:29.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] Listing PodDisruptionBudgets for all namespaces
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] Listing PodDisruptionBudgets for all namespaces
      tear down framework | framework.go:193
    STEP: Destroying namespace "disruption-2-9605" for this suite. 04/23/23 12:37:29.522
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      tear down framework | framework.go:193
    STEP: Destroying namespace "disruption-4177" for this suite. 04/23/23 12:37:29.535
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:37:29.553
Apr 23 12:37:29.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename podtemplate 04/23/23 12:37:29.557
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:29.585
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:29.591
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/metrics/init/init.go:31
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 04/23/23 12:37:29.596
Apr 23 12:37:29.607: INFO: created test-podtemplate-1
Apr 23 12:37:29.619: INFO: created test-podtemplate-2
Apr 23 12:37:29.626: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 04/23/23 12:37:29.626
STEP: delete collection of pod templates 04/23/23 12:37:29.632
Apr 23 12:37:29.633: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 04/23/23 12:37:29.663
Apr 23 12:37:29.664: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/node/init/init.go:32
Apr 23 12:37:29.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] PodTemplates
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] PodTemplates
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] PodTemplates
  tear down framework | framework.go:193
STEP: Destroying namespace "podtemplate-2538" for this suite. 04/23/23 12:37:29.679
------------------------------
â€¢ [0.140 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:37:29.553
    Apr 23 12:37:29.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename podtemplate 04/23/23 12:37:29.557
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:29.585
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:29.591
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/metrics/init/init.go:31
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 04/23/23 12:37:29.596
    Apr 23 12:37:29.607: INFO: created test-podtemplate-1
    Apr 23 12:37:29.619: INFO: created test-podtemplate-2
    Apr 23 12:37:29.626: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 04/23/23 12:37:29.626
    STEP: delete collection of pod templates 04/23/23 12:37:29.632
    Apr 23 12:37:29.633: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 04/23/23 12:37:29.663
    Apr 23 12:37:29.664: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:37:29.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] PodTemplates
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] PodTemplates
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] PodTemplates
      tear down framework | framework.go:193
    STEP: Destroying namespace "podtemplate-2538" for this suite. 04/23/23 12:37:29.679
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1250
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:37:29.697
Apr 23 12:37:29.697: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 12:37:29.7
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:29.729
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:29.736
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1250
STEP: validating cluster-info 04/23/23 12:37:29.743
Apr 23 12:37:29.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-575 cluster-info'
Apr 23 12:37:30.119: INFO: stderr: ""
Apr 23 12:37:30.119: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 12:37:30.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-575" for this suite. 04/23/23 12:37:30.13
------------------------------
â€¢ [0.447 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1244
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:37:29.697
    Apr 23 12:37:29.697: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 12:37:29.7
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:29.729
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:29.736
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1250
    STEP: validating cluster-info 04/23/23 12:37:29.743
    Apr 23 12:37:29.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-575 cluster-info'
    Apr 23 12:37:30.119: INFO: stderr: ""
    Apr 23 12:37:30.119: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:37:30.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-575" for this suite. 04/23/23 12:37:30.13
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:236
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:37:30.147
Apr 23 12:37:30.148: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 12:37:30.154
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:30.195
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:30.2
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:236
Apr 23 12:37:30.207: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/23/23 12:37:33.557
Apr 23 12:37:33.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9393 --namespace=crd-publish-openapi-9393 create -f -'
Apr 23 12:37:35.654: INFO: stderr: ""
Apr 23 12:37:35.654: INFO: stdout: "e2e-test-crd-publish-openapi-4850-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 23 12:37:35.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9393 --namespace=crd-publish-openapi-9393 delete e2e-test-crd-publish-openapi-4850-crds test-cr'
Apr 23 12:37:35.912: INFO: stderr: ""
Apr 23 12:37:35.912: INFO: stdout: "e2e-test-crd-publish-openapi-4850-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Apr 23 12:37:35.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9393 --namespace=crd-publish-openapi-9393 apply -f -'
Apr 23 12:37:37.483: INFO: stderr: ""
Apr 23 12:37:37.483: INFO: stdout: "e2e-test-crd-publish-openapi-4850-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 23 12:37:37.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9393 --namespace=crd-publish-openapi-9393 delete e2e-test-crd-publish-openapi-4850-crds test-cr'
Apr 23 12:37:37.711: INFO: stderr: ""
Apr 23 12:37:37.711: INFO: stdout: "e2e-test-crd-publish-openapi-4850-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 04/23/23 12:37:37.711
Apr 23 12:37:37.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9393 explain e2e-test-crd-publish-openapi-4850-crds'
Apr 23 12:37:38.457: INFO: stderr: ""
Apr 23 12:37:38.457: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4850-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:37:41.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-9393" for this suite. 04/23/23 12:37:41.417
------------------------------
â€¢ [SLOW TEST] [11.302 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:236

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:37:30.147
    Apr 23 12:37:30.148: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 12:37:30.154
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:30.195
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:30.2
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:236
    Apr 23 12:37:30.207: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/23/23 12:37:33.557
    Apr 23 12:37:33.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9393 --namespace=crd-publish-openapi-9393 create -f -'
    Apr 23 12:37:35.654: INFO: stderr: ""
    Apr 23 12:37:35.654: INFO: stdout: "e2e-test-crd-publish-openapi-4850-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Apr 23 12:37:35.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9393 --namespace=crd-publish-openapi-9393 delete e2e-test-crd-publish-openapi-4850-crds test-cr'
    Apr 23 12:37:35.912: INFO: stderr: ""
    Apr 23 12:37:35.912: INFO: stdout: "e2e-test-crd-publish-openapi-4850-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Apr 23 12:37:35.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9393 --namespace=crd-publish-openapi-9393 apply -f -'
    Apr 23 12:37:37.483: INFO: stderr: ""
    Apr 23 12:37:37.483: INFO: stdout: "e2e-test-crd-publish-openapi-4850-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Apr 23 12:37:37.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9393 --namespace=crd-publish-openapi-9393 delete e2e-test-crd-publish-openapi-4850-crds test-cr'
    Apr 23 12:37:37.711: INFO: stderr: ""
    Apr 23 12:37:37.711: INFO: stdout: "e2e-test-crd-publish-openapi-4850-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 04/23/23 12:37:37.711
    Apr 23 12:37:37.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-9393 explain e2e-test-crd-publish-openapi-4850-crds'
    Apr 23 12:37:38.457: INFO: stderr: ""
    Apr 23 12:37:38.457: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4850-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:37:41.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-9393" for this suite. 04/23/23 12:37:41.417
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:73
[BeforeEach] [sig-node] Containers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:37:41.452
Apr 23 12:37:41.452: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename containers 04/23/23 12:37:41.463
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:41.509
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:41.514
[BeforeEach] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:31
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:73
STEP: Creating a pod to test override command 04/23/23 12:37:41.521
Apr 23 12:37:41.550: INFO: Waiting up to 5m0s for pod "client-containers-cdf29669-c0f8-466f-9dba-c37436248a00" in namespace "containers-5857" to be "Succeeded or Failed"
Apr 23 12:37:41.556: INFO: Pod "client-containers-cdf29669-c0f8-466f-9dba-c37436248a00": Phase="Pending", Reason="", readiness=false. Elapsed: 5.659658ms
Apr 23 12:37:43.564: INFO: Pod "client-containers-cdf29669-c0f8-466f-9dba-c37436248a00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014024273s
Apr 23 12:37:45.572: INFO: Pod "client-containers-cdf29669-c0f8-466f-9dba-c37436248a00": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021302641s
Apr 23 12:37:47.564: INFO: Pod "client-containers-cdf29669-c0f8-466f-9dba-c37436248a00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013706011s
STEP: Saw pod success 04/23/23 12:37:47.564
Apr 23 12:37:47.565: INFO: Pod "client-containers-cdf29669-c0f8-466f-9dba-c37436248a00" satisfied condition "Succeeded or Failed"
Apr 23 12:37:47.570: INFO: Trying to get logs from node eingavuivie7-3 pod client-containers-cdf29669-c0f8-466f-9dba-c37436248a00 container agnhost-container: <nil>
STEP: delete the pod 04/23/23 12:37:47.733
Apr 23 12:37:47.756: INFO: Waiting for pod client-containers-cdf29669-c0f8-466f-9dba-c37436248a00 to disappear
Apr 23 12:37:47.761: INFO: Pod client-containers-cdf29669-c0f8-466f-9dba-c37436248a00 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/node/init/init.go:32
Apr 23 12:37:47.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Containers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Containers
  tear down framework | framework.go:193
STEP: Destroying namespace "containers-5857" for this suite. 04/23/23 12:37:47.77
------------------------------
â€¢ [SLOW TEST] [6.331 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:37:41.452
    Apr 23 12:37:41.452: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename containers 04/23/23 12:37:41.463
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:41.509
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:41.514
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:31
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:73
    STEP: Creating a pod to test override command 04/23/23 12:37:41.521
    Apr 23 12:37:41.550: INFO: Waiting up to 5m0s for pod "client-containers-cdf29669-c0f8-466f-9dba-c37436248a00" in namespace "containers-5857" to be "Succeeded or Failed"
    Apr 23 12:37:41.556: INFO: Pod "client-containers-cdf29669-c0f8-466f-9dba-c37436248a00": Phase="Pending", Reason="", readiness=false. Elapsed: 5.659658ms
    Apr 23 12:37:43.564: INFO: Pod "client-containers-cdf29669-c0f8-466f-9dba-c37436248a00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014024273s
    Apr 23 12:37:45.572: INFO: Pod "client-containers-cdf29669-c0f8-466f-9dba-c37436248a00": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021302641s
    Apr 23 12:37:47.564: INFO: Pod "client-containers-cdf29669-c0f8-466f-9dba-c37436248a00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013706011s
    STEP: Saw pod success 04/23/23 12:37:47.564
    Apr 23 12:37:47.565: INFO: Pod "client-containers-cdf29669-c0f8-466f-9dba-c37436248a00" satisfied condition "Succeeded or Failed"
    Apr 23 12:37:47.570: INFO: Trying to get logs from node eingavuivie7-3 pod client-containers-cdf29669-c0f8-466f-9dba-c37436248a00 container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 12:37:47.733
    Apr 23 12:37:47.756: INFO: Waiting for pod client-containers-cdf29669-c0f8-466f-9dba-c37436248a00 to disappear
    Apr 23 12:37:47.761: INFO: Pod client-containers-cdf29669-c0f8-466f-9dba-c37436248a00 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:37:47.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Containers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Containers
      tear down framework | framework.go:193
    STEP: Destroying namespace "containers-5857" for this suite. 04/23/23 12:37:47.77
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:226
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:37:47.793
Apr 23 12:37:47.793: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pods 04/23/23 12:37:47.795
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:47.821
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:47.826
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:226
STEP: creating the pod 04/23/23 12:37:47.83
STEP: setting up watch 04/23/23 12:37:47.831
STEP: submitting the pod to kubernetes 04/23/23 12:37:47.938
STEP: verifying the pod is in kubernetes 04/23/23 12:37:47.959
STEP: verifying pod creation was observed 04/23/23 12:37:47.97
Apr 23 12:37:47.970: INFO: Waiting up to 5m0s for pod "pod-submit-remove-173e98e3-153e-4a9b-8c61-82ece345b569" in namespace "pods-8846" to be "running"
Apr 23 12:37:47.987: INFO: Pod "pod-submit-remove-173e98e3-153e-4a9b-8c61-82ece345b569": Phase="Pending", Reason="", readiness=false. Elapsed: 16.57029ms
Apr 23 12:37:49.994: INFO: Pod "pod-submit-remove-173e98e3-153e-4a9b-8c61-82ece345b569": Phase="Running", Reason="", readiness=true. Elapsed: 2.023621743s
Apr 23 12:37:49.994: INFO: Pod "pod-submit-remove-173e98e3-153e-4a9b-8c61-82ece345b569" satisfied condition "running"
STEP: deleting the pod gracefully 04/23/23 12:37:50
STEP: verifying pod deletion was observed 04/23/23 12:37:50.023
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Apr 23 12:37:52.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-8846" for this suite. 04/23/23 12:37:52.805
------------------------------
â€¢ [SLOW TEST] [5.028 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:37:47.793
    Apr 23 12:37:47.793: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pods 04/23/23 12:37:47.795
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:47.821
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:47.826
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:226
    STEP: creating the pod 04/23/23 12:37:47.83
    STEP: setting up watch 04/23/23 12:37:47.831
    STEP: submitting the pod to kubernetes 04/23/23 12:37:47.938
    STEP: verifying the pod is in kubernetes 04/23/23 12:37:47.959
    STEP: verifying pod creation was observed 04/23/23 12:37:47.97
    Apr 23 12:37:47.970: INFO: Waiting up to 5m0s for pod "pod-submit-remove-173e98e3-153e-4a9b-8c61-82ece345b569" in namespace "pods-8846" to be "running"
    Apr 23 12:37:47.987: INFO: Pod "pod-submit-remove-173e98e3-153e-4a9b-8c61-82ece345b569": Phase="Pending", Reason="", readiness=false. Elapsed: 16.57029ms
    Apr 23 12:37:49.994: INFO: Pod "pod-submit-remove-173e98e3-153e-4a9b-8c61-82ece345b569": Phase="Running", Reason="", readiness=true. Elapsed: 2.023621743s
    Apr 23 12:37:49.994: INFO: Pod "pod-submit-remove-173e98e3-153e-4a9b-8c61-82ece345b569" satisfied condition "running"
    STEP: deleting the pod gracefully 04/23/23 12:37:50
    STEP: verifying pod deletion was observed 04/23/23 12:37:50.023
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:37:52.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-8846" for this suite. 04/23/23 12:37:52.805
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:44
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:37:52.827
Apr 23 12:37:52.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename var-expansion 04/23/23 12:37:52.832
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:52.929
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:52.935
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:44
STEP: Creating a pod to test env composition 04/23/23 12:37:52.94
Apr 23 12:37:52.957: INFO: Waiting up to 5m0s for pod "var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265" in namespace "var-expansion-6789" to be "Succeeded or Failed"
Apr 23 12:37:52.966: INFO: Pod "var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265": Phase="Pending", Reason="", readiness=false. Elapsed: 8.439146ms
Apr 23 12:37:54.975: INFO: Pod "var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017315458s
Apr 23 12:37:56.976: INFO: Pod "var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017949407s
STEP: Saw pod success 04/23/23 12:37:56.976
Apr 23 12:37:56.977: INFO: Pod "var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265" satisfied condition "Succeeded or Failed"
Apr 23 12:37:56.986: INFO: Trying to get logs from node eingavuivie7-3 pod var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265 container dapi-container: <nil>
STEP: delete the pod 04/23/23 12:37:57.012
Apr 23 12:37:57.061: INFO: Waiting for pod var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265 to disappear
Apr 23 12:37:57.075: INFO: Pod var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Apr 23 12:37:57.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-6789" for this suite. 04/23/23 12:37:57.088
------------------------------
â€¢ [4.279 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:37:52.827
    Apr 23 12:37:52.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename var-expansion 04/23/23 12:37:52.832
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:52.929
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:52.935
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:44
    STEP: Creating a pod to test env composition 04/23/23 12:37:52.94
    Apr 23 12:37:52.957: INFO: Waiting up to 5m0s for pod "var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265" in namespace "var-expansion-6789" to be "Succeeded or Failed"
    Apr 23 12:37:52.966: INFO: Pod "var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265": Phase="Pending", Reason="", readiness=false. Elapsed: 8.439146ms
    Apr 23 12:37:54.975: INFO: Pod "var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017315458s
    Apr 23 12:37:56.976: INFO: Pod "var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017949407s
    STEP: Saw pod success 04/23/23 12:37:56.976
    Apr 23 12:37:56.977: INFO: Pod "var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265" satisfied condition "Succeeded or Failed"
    Apr 23 12:37:56.986: INFO: Trying to get logs from node eingavuivie7-3 pod var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265 container dapi-container: <nil>
    STEP: delete the pod 04/23/23 12:37:57.012
    Apr 23 12:37:57.061: INFO: Waiting for pod var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265 to disappear
    Apr 23 12:37:57.075: INFO: Pod var-expansion-d898b867-880d-45cb-bd4a-3a83aff00265 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:37:57.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-6789" for this suite. 04/23/23 12:37:57.088
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:37:57.114
Apr 23 12:37:57.114: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename deployment 04/23/23 12:37:57.118
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:57.157
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:57.163
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Apr 23 12:37:57.170: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 23 12:37:57.189: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 23 12:38:02.200: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/23/23 12:38:02.201
Apr 23 12:38:02.201: INFO: Creating deployment "test-rolling-update-deployment"
Apr 23 12:38:02.216: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 23 12:38:02.232: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 23 12:38:04.306: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 23 12:38:04.321: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 23 12:38:04.354: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-683  e62fa51c-6eeb-4ece-9065-86cf55ca315e 35053 1 2023-04-23 12:38:02 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-04-23 12:38:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:38:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034d23f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-23 12:38:02 +0000 UTC,LastTransitionTime:2023-04-23 12:38:02 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-7549d9f46d" has successfully progressed.,LastUpdateTime:2023-04-23 12:38:03 +0000 UTC,LastTransitionTime:2023-04-23 12:38:02 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 23 12:38:04.366: INFO: New ReplicaSet "test-rolling-update-deployment-7549d9f46d" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-7549d9f46d  deployment-683  354c9eed-e9f4-4627-bd17-91f4d4bca855 35042 1 2023-04-23 12:38:02 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:7549d9f46d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment e62fa51c-6eeb-4ece-9065-86cf55ca315e 0xc0034d28f7 0xc0034d28f8}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:38:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e62fa51c-6eeb-4ece-9065-86cf55ca315e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:38:03 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 7549d9f46d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:7549d9f46d] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034d29a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 23 12:38:04.366: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 23 12:38:04.366: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-683  9804a195-8930-4019-b8a2-f63791da6ae6 35051 2 2023-04-23 12:37:57 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment e62fa51c-6eeb-4ece-9065-86cf55ca315e 0xc0034d27c7 0xc0034d27c8}] [] [{e2e.test Update apps/v1 2023-04-23 12:37:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:38:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e62fa51c-6eeb-4ece-9065-86cf55ca315e\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:38:03 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0034d2888 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 23 12:38:04.376: INFO: Pod "test-rolling-update-deployment-7549d9f46d-w2v9p" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-7549d9f46d-w2v9p test-rolling-update-deployment-7549d9f46d- deployment-683  7938b396-6ba8-4a8d-bb58-54193df5108a 35041 0 2023-04-23 12:38:02 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:7549d9f46d] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-7549d9f46d 354c9eed-e9f4-4627-bd17-91f4d4bca855 0xc0034d2e07 0xc0034d2e08}] [] [{kube-controller-manager Update v1 2023-04-23 12:38:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"354c9eed-e9f4-4627-bd17-91f4d4bca855\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:38:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qnz6f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qnz6f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:38:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:38:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:38:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:38:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.41,StartTime:2023-04-23 12:38:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:38:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:cri-o://aebba35e9f7b5c75ae12a557d2d2a6d8e84a9a9feec7af391c34ec7b04b03ada,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Apr 23 12:38:04.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-683" for this suite. 04/23/23 12:38:04.39
------------------------------
â€¢ [SLOW TEST] [7.298 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:37:57.114
    Apr 23 12:37:57.114: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename deployment 04/23/23 12:37:57.118
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:37:57.157
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:37:57.163
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Apr 23 12:37:57.170: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Apr 23 12:37:57.189: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 23 12:38:02.200: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/23/23 12:38:02.201
    Apr 23 12:38:02.201: INFO: Creating deployment "test-rolling-update-deployment"
    Apr 23 12:38:02.216: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Apr 23 12:38:02.232: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Apr 23 12:38:04.306: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Apr 23 12:38:04.321: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 23 12:38:04.354: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-683  e62fa51c-6eeb-4ece-9065-86cf55ca315e 35053 1 2023-04-23 12:38:02 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-04-23 12:38:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:38:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034d23f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-23 12:38:02 +0000 UTC,LastTransitionTime:2023-04-23 12:38:02 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-7549d9f46d" has successfully progressed.,LastUpdateTime:2023-04-23 12:38:03 +0000 UTC,LastTransitionTime:2023-04-23 12:38:02 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 23 12:38:04.366: INFO: New ReplicaSet "test-rolling-update-deployment-7549d9f46d" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-7549d9f46d  deployment-683  354c9eed-e9f4-4627-bd17-91f4d4bca855 35042 1 2023-04-23 12:38:02 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:7549d9f46d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment e62fa51c-6eeb-4ece-9065-86cf55ca315e 0xc0034d28f7 0xc0034d28f8}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:38:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e62fa51c-6eeb-4ece-9065-86cf55ca315e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:38:03 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 7549d9f46d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:7549d9f46d] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034d29a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 23 12:38:04.366: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Apr 23 12:38:04.366: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-683  9804a195-8930-4019-b8a2-f63791da6ae6 35051 2 2023-04-23 12:37:57 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment e62fa51c-6eeb-4ece-9065-86cf55ca315e 0xc0034d27c7 0xc0034d27c8}] [] [{e2e.test Update apps/v1 2023-04-23 12:37:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:38:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e62fa51c-6eeb-4ece-9065-86cf55ca315e\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:38:03 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0034d2888 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 23 12:38:04.376: INFO: Pod "test-rolling-update-deployment-7549d9f46d-w2v9p" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-7549d9f46d-w2v9p test-rolling-update-deployment-7549d9f46d- deployment-683  7938b396-6ba8-4a8d-bb58-54193df5108a 35041 0 2023-04-23 12:38:02 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:7549d9f46d] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-7549d9f46d 354c9eed-e9f4-4627-bd17-91f4d4bca855 0xc0034d2e07 0xc0034d2e08}] [] [{kube-controller-manager Update v1 2023-04-23 12:38:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"354c9eed-e9f4-4627-bd17-91f4d4bca855\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:38:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qnz6f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qnz6f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:38:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:38:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:38:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:38:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.41,StartTime:2023-04-23 12:38:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:38:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:cri-o://aebba35e9f7b5c75ae12a557d2d2a6d8e84a9a9feec7af391c34ec7b04b03ada,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:38:04.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-683" for this suite. 04/23/23 12:38:04.39
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:38:04.416
Apr 23 12:38:04.417: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir-wrapper 04/23/23 12:38:04.426
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:04.524
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:04.532
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Apr 23 12:38:04.613: INFO: Waiting up to 5m0s for pod "pod-secrets-56d43dcf-44cc-4398-a6f7-99b413d94daa" in namespace "emptydir-wrapper-1901" to be "running and ready"
Apr 23 12:38:04.642: INFO: Pod "pod-secrets-56d43dcf-44cc-4398-a6f7-99b413d94daa": Phase="Pending", Reason="", readiness=false. Elapsed: 29.291518ms
Apr 23 12:38:04.642: INFO: The phase of Pod pod-secrets-56d43dcf-44cc-4398-a6f7-99b413d94daa is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:38:06.653: INFO: Pod "pod-secrets-56d43dcf-44cc-4398-a6f7-99b413d94daa": Phase="Running", Reason="", readiness=true. Elapsed: 2.040111619s
Apr 23 12:38:06.653: INFO: The phase of Pod pod-secrets-56d43dcf-44cc-4398-a6f7-99b413d94daa is Running (Ready = true)
Apr 23 12:38:06.653: INFO: Pod "pod-secrets-56d43dcf-44cc-4398-a6f7-99b413d94daa" satisfied condition "running and ready"
STEP: Cleaning up the secret 04/23/23 12:38:06.659
STEP: Cleaning up the configmap 04/23/23 12:38:06.671
STEP: Cleaning up the pod 04/23/23 12:38:06.684
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 12:38:06.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-wrapper-1901" for this suite. 04/23/23 12:38:06.729
------------------------------
â€¢ [2.343 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:38:04.416
    Apr 23 12:38:04.417: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir-wrapper 04/23/23 12:38:04.426
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:04.524
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:04.532
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Apr 23 12:38:04.613: INFO: Waiting up to 5m0s for pod "pod-secrets-56d43dcf-44cc-4398-a6f7-99b413d94daa" in namespace "emptydir-wrapper-1901" to be "running and ready"
    Apr 23 12:38:04.642: INFO: Pod "pod-secrets-56d43dcf-44cc-4398-a6f7-99b413d94daa": Phase="Pending", Reason="", readiness=false. Elapsed: 29.291518ms
    Apr 23 12:38:04.642: INFO: The phase of Pod pod-secrets-56d43dcf-44cc-4398-a6f7-99b413d94daa is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:38:06.653: INFO: Pod "pod-secrets-56d43dcf-44cc-4398-a6f7-99b413d94daa": Phase="Running", Reason="", readiness=true. Elapsed: 2.040111619s
    Apr 23 12:38:06.653: INFO: The phase of Pod pod-secrets-56d43dcf-44cc-4398-a6f7-99b413d94daa is Running (Ready = true)
    Apr 23 12:38:06.653: INFO: Pod "pod-secrets-56d43dcf-44cc-4398-a6f7-99b413d94daa" satisfied condition "running and ready"
    STEP: Cleaning up the secret 04/23/23 12:38:06.659
    STEP: Cleaning up the configmap 04/23/23 12:38:06.671
    STEP: Cleaning up the pod 04/23/23 12:38:06.684
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:38:06.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-wrapper-1901" for this suite. 04/23/23 12:38:06.729
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:99
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:38:06.768
Apr 23 12:38:06.768: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 12:38:06.77
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:06.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:06.806
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:99
STEP: Creating configMap with name configmap-test-volume-map-fc79c449-a093-4b42-b0c6-af549f03de2b 04/23/23 12:38:06.812
STEP: Creating a pod to test consume configMaps 04/23/23 12:38:06.821
Apr 23 12:38:06.843: INFO: Waiting up to 5m0s for pod "pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42" in namespace "configmap-1316" to be "Succeeded or Failed"
Apr 23 12:38:06.861: INFO: Pod "pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42": Phase="Pending", Reason="", readiness=false. Elapsed: 18.143729ms
Apr 23 12:38:08.872: INFO: Pod "pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0294232s
Apr 23 12:38:10.878: INFO: Pod "pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035600223s
Apr 23 12:38:12.869: INFO: Pod "pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02625125s
STEP: Saw pod success 04/23/23 12:38:12.869
Apr 23 12:38:12.870: INFO: Pod "pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42" satisfied condition "Succeeded or Failed"
Apr 23 12:38:12.878: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42 container agnhost-container: <nil>
STEP: delete the pod 04/23/23 12:38:12.898
Apr 23 12:38:12.931: INFO: Waiting for pod pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42 to disappear
Apr 23 12:38:12.940: INFO: Pod pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 12:38:12.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-1316" for this suite. 04/23/23 12:38:12.964
------------------------------
â€¢ [SLOW TEST] [6.237 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:99

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:38:06.768
    Apr 23 12:38:06.768: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 12:38:06.77
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:06.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:06.806
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:99
    STEP: Creating configMap with name configmap-test-volume-map-fc79c449-a093-4b42-b0c6-af549f03de2b 04/23/23 12:38:06.812
    STEP: Creating a pod to test consume configMaps 04/23/23 12:38:06.821
    Apr 23 12:38:06.843: INFO: Waiting up to 5m0s for pod "pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42" in namespace "configmap-1316" to be "Succeeded or Failed"
    Apr 23 12:38:06.861: INFO: Pod "pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42": Phase="Pending", Reason="", readiness=false. Elapsed: 18.143729ms
    Apr 23 12:38:08.872: INFO: Pod "pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0294232s
    Apr 23 12:38:10.878: INFO: Pod "pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035600223s
    Apr 23 12:38:12.869: INFO: Pod "pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02625125s
    STEP: Saw pod success 04/23/23 12:38:12.869
    Apr 23 12:38:12.870: INFO: Pod "pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42" satisfied condition "Succeeded or Failed"
    Apr 23 12:38:12.878: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42 container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 12:38:12.898
    Apr 23 12:38:12.931: INFO: Waiting for pod pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42 to disappear
    Apr 23 12:38:12.940: INFO: Pod pod-configmaps-cbfafc88-ba7d-4e56-94e2-cce4a50dfb42 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:38:12.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-1316" for this suite. 04/23/23 12:38:12.964
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:107
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:38:13.017
Apr 23 12:38:13.017: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 12:38:13.019
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:13.084
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:13.092
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:107
STEP: Creating a pod to test emptydir 0666 on tmpfs 04/23/23 12:38:13.101
Apr 23 12:38:13.122: INFO: Waiting up to 5m0s for pod "pod-8b3d070c-bfe9-460e-93af-e05d6613b431" in namespace "emptydir-5035" to be "Succeeded or Failed"
Apr 23 12:38:13.138: INFO: Pod "pod-8b3d070c-bfe9-460e-93af-e05d6613b431": Phase="Pending", Reason="", readiness=false. Elapsed: 15.538708ms
Apr 23 12:38:15.156: INFO: Pod "pod-8b3d070c-bfe9-460e-93af-e05d6613b431": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033498736s
Apr 23 12:38:17.148: INFO: Pod "pod-8b3d070c-bfe9-460e-93af-e05d6613b431": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02542194s
Apr 23 12:38:19.148: INFO: Pod "pod-8b3d070c-bfe9-460e-93af-e05d6613b431": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02571631s
STEP: Saw pod success 04/23/23 12:38:19.148
Apr 23 12:38:19.148: INFO: Pod "pod-8b3d070c-bfe9-460e-93af-e05d6613b431" satisfied condition "Succeeded or Failed"
Apr 23 12:38:19.156: INFO: Trying to get logs from node eingavuivie7-3 pod pod-8b3d070c-bfe9-460e-93af-e05d6613b431 container test-container: <nil>
STEP: delete the pod 04/23/23 12:38:19.168
Apr 23 12:38:19.186: INFO: Waiting for pod pod-8b3d070c-bfe9-460e-93af-e05d6613b431 to disappear
Apr 23 12:38:19.200: INFO: Pod pod-8b3d070c-bfe9-460e-93af-e05d6613b431 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 12:38:19.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-5035" for this suite. 04/23/23 12:38:19.21
------------------------------
â€¢ [SLOW TEST] [6.206 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:38:13.017
    Apr 23 12:38:13.017: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 12:38:13.019
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:13.084
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:13.092
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:107
    STEP: Creating a pod to test emptydir 0666 on tmpfs 04/23/23 12:38:13.101
    Apr 23 12:38:13.122: INFO: Waiting up to 5m0s for pod "pod-8b3d070c-bfe9-460e-93af-e05d6613b431" in namespace "emptydir-5035" to be "Succeeded or Failed"
    Apr 23 12:38:13.138: INFO: Pod "pod-8b3d070c-bfe9-460e-93af-e05d6613b431": Phase="Pending", Reason="", readiness=false. Elapsed: 15.538708ms
    Apr 23 12:38:15.156: INFO: Pod "pod-8b3d070c-bfe9-460e-93af-e05d6613b431": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033498736s
    Apr 23 12:38:17.148: INFO: Pod "pod-8b3d070c-bfe9-460e-93af-e05d6613b431": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02542194s
    Apr 23 12:38:19.148: INFO: Pod "pod-8b3d070c-bfe9-460e-93af-e05d6613b431": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02571631s
    STEP: Saw pod success 04/23/23 12:38:19.148
    Apr 23 12:38:19.148: INFO: Pod "pod-8b3d070c-bfe9-460e-93af-e05d6613b431" satisfied condition "Succeeded or Failed"
    Apr 23 12:38:19.156: INFO: Trying to get logs from node eingavuivie7-3 pod pod-8b3d070c-bfe9-460e-93af-e05d6613b431 container test-container: <nil>
    STEP: delete the pod 04/23/23 12:38:19.168
    Apr 23 12:38:19.186: INFO: Waiting for pod pod-8b3d070c-bfe9-460e-93af-e05d6613b431 to disappear
    Apr 23 12:38:19.200: INFO: Pod pod-8b3d070c-bfe9-460e-93af-e05d6613b431 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:38:19.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-5035" for this suite. 04/23/23 12:38:19.21
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:84
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:38:19.226
Apr 23 12:38:19.227: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 12:38:19.228
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:19.259
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:19.264
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:84
STEP: Creating a pod to test downward API volume plugin 04/23/23 12:38:19.268
Apr 23 12:38:19.280: INFO: Waiting up to 5m0s for pod "downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed" in namespace "projected-8810" to be "Succeeded or Failed"
Apr 23 12:38:19.292: INFO: Pod "downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed": Phase="Pending", Reason="", readiness=false. Elapsed: 11.534409ms
Apr 23 12:38:21.301: INFO: Pod "downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020561337s
Apr 23 12:38:23.301: INFO: Pod "downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02034292s
STEP: Saw pod success 04/23/23 12:38:23.301
Apr 23 12:38:23.301: INFO: Pod "downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed" satisfied condition "Succeeded or Failed"
Apr 23 12:38:23.308: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed container client-container: <nil>
STEP: delete the pod 04/23/23 12:38:23.319
Apr 23 12:38:23.342: INFO: Waiting for pod downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed to disappear
Apr 23 12:38:23.353: INFO: Pod downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Apr 23 12:38:23.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-8810" for this suite. 04/23/23 12:38:23.368
------------------------------
â€¢ [4.163 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:84

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:38:19.226
    Apr 23 12:38:19.227: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 12:38:19.228
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:19.259
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:19.264
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:84
    STEP: Creating a pod to test downward API volume plugin 04/23/23 12:38:19.268
    Apr 23 12:38:19.280: INFO: Waiting up to 5m0s for pod "downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed" in namespace "projected-8810" to be "Succeeded or Failed"
    Apr 23 12:38:19.292: INFO: Pod "downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed": Phase="Pending", Reason="", readiness=false. Elapsed: 11.534409ms
    Apr 23 12:38:21.301: INFO: Pod "downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020561337s
    Apr 23 12:38:23.301: INFO: Pod "downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02034292s
    STEP: Saw pod success 04/23/23 12:38:23.301
    Apr 23 12:38:23.301: INFO: Pod "downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed" satisfied condition "Succeeded or Failed"
    Apr 23 12:38:23.308: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed container client-container: <nil>
    STEP: delete the pod 04/23/23 12:38:23.319
    Apr 23 12:38:23.342: INFO: Waiting for pod downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed to disappear
    Apr 23 12:38:23.353: INFO: Pod downwardapi-volume-def9a07e-ef21-44b7-939b-9c93794795ed no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:38:23.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-8810" for this suite. 04/23/23 12:38:23.368
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1713
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:38:23.399
Apr 23 12:38:23.399: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 12:38:23.402
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:23.447
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:23.452
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1700
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1713
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 04/23/23 12:38:23.458
Apr 23 12:38:23.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-6613 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
Apr 23 12:38:23.684: INFO: stderr: ""
Apr 23 12:38:23.684: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 04/23/23 12:38:23.684
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1704
Apr 23 12:38:23.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-6613 delete pods e2e-test-httpd-pod'
Apr 23 12:38:27.273: INFO: stderr: ""
Apr 23 12:38:27.273: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 12:38:27.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-6613" for this suite. 04/23/23 12:38:27.282
------------------------------
â€¢ [3.898 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1697
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1713

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:38:23.399
    Apr 23 12:38:23.399: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 12:38:23.402
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:23.447
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:23.452
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1700
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1713
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 04/23/23 12:38:23.458
    Apr 23 12:38:23.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-6613 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
    Apr 23 12:38:23.684: INFO: stderr: ""
    Apr 23 12:38:23.684: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 04/23/23 12:38:23.684
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1704
    Apr 23 12:38:23.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-6613 delete pods e2e-test-httpd-pod'
    Apr 23 12:38:27.273: INFO: stderr: ""
    Apr 23 12:38:27.273: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:38:27.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-6613" for this suite. 04/23/23 12:38:27.282
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:69
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:38:27.304
Apr 23 12:38:27.304: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 12:38:27.306
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:27.335
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:27.341
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:69
Apr 23 12:38:27.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 04/23/23 12:38:30.462
Apr 23 12:38:30.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 create -f -'
Apr 23 12:38:32.272: INFO: stderr: ""
Apr 23 12:38:32.272: INFO: stdout: "e2e-test-crd-publish-openapi-9046-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 23 12:38:32.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 delete e2e-test-crd-publish-openapi-9046-crds test-foo'
Apr 23 12:38:32.690: INFO: stderr: ""
Apr 23 12:38:32.690: INFO: stdout: "e2e-test-crd-publish-openapi-9046-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Apr 23 12:38:32.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 apply -f -'
Apr 23 12:38:34.015: INFO: stderr: ""
Apr 23 12:38:34.015: INFO: stdout: "e2e-test-crd-publish-openapi-9046-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 23 12:38:34.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 delete e2e-test-crd-publish-openapi-9046-crds test-foo'
Apr 23 12:38:34.229: INFO: stderr: ""
Apr 23 12:38:34.229: INFO: stdout: "e2e-test-crd-publish-openapi-9046-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 04/23/23 12:38:34.229
Apr 23 12:38:34.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 create -f -'
Apr 23 12:38:34.883: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 04/23/23 12:38:34.883
Apr 23 12:38:34.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 create -f -'
Apr 23 12:38:35.374: INFO: rc: 1
Apr 23 12:38:35.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 apply -f -'
Apr 23 12:38:36.115: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 04/23/23 12:38:36.115
Apr 23 12:38:36.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 create -f -'
Apr 23 12:38:36.802: INFO: rc: 1
Apr 23 12:38:36.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 apply -f -'
Apr 23 12:38:37.362: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 04/23/23 12:38:37.362
Apr 23 12:38:37.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 explain e2e-test-crd-publish-openapi-9046-crds'
Apr 23 12:38:38.059: INFO: stderr: ""
Apr 23 12:38:38.059: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9046-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 04/23/23 12:38:38.059
Apr 23 12:38:38.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 explain e2e-test-crd-publish-openapi-9046-crds.metadata'
Apr 23 12:38:38.770: INFO: stderr: ""
Apr 23 12:38:38.770: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9046-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Apr 23 12:38:38.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 explain e2e-test-crd-publish-openapi-9046-crds.spec'
Apr 23 12:38:39.248: INFO: stderr: ""
Apr 23 12:38:39.248: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9046-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Apr 23 12:38:39.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 explain e2e-test-crd-publish-openapi-9046-crds.spec.bars'
Apr 23 12:38:39.763: INFO: stderr: ""
Apr 23 12:38:39.763: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9046-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 04/23/23 12:38:39.763
Apr 23 12:38:39.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 explain e2e-test-crd-publish-openapi-9046-crds.spec.bars2'
Apr 23 12:38:40.379: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:38:42.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-1385" for this suite. 04/23/23 12:38:42.532
------------------------------
â€¢ [SLOW TEST] [15.290 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:38:27.304
    Apr 23 12:38:27.304: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 12:38:27.306
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:27.335
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:27.341
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:69
    Apr 23 12:38:27.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 04/23/23 12:38:30.462
    Apr 23 12:38:30.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 create -f -'
    Apr 23 12:38:32.272: INFO: stderr: ""
    Apr 23 12:38:32.272: INFO: stdout: "e2e-test-crd-publish-openapi-9046-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Apr 23 12:38:32.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 delete e2e-test-crd-publish-openapi-9046-crds test-foo'
    Apr 23 12:38:32.690: INFO: stderr: ""
    Apr 23 12:38:32.690: INFO: stdout: "e2e-test-crd-publish-openapi-9046-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Apr 23 12:38:32.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 apply -f -'
    Apr 23 12:38:34.015: INFO: stderr: ""
    Apr 23 12:38:34.015: INFO: stdout: "e2e-test-crd-publish-openapi-9046-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Apr 23 12:38:34.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 delete e2e-test-crd-publish-openapi-9046-crds test-foo'
    Apr 23 12:38:34.229: INFO: stderr: ""
    Apr 23 12:38:34.229: INFO: stdout: "e2e-test-crd-publish-openapi-9046-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 04/23/23 12:38:34.229
    Apr 23 12:38:34.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 create -f -'
    Apr 23 12:38:34.883: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 04/23/23 12:38:34.883
    Apr 23 12:38:34.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 create -f -'
    Apr 23 12:38:35.374: INFO: rc: 1
    Apr 23 12:38:35.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 apply -f -'
    Apr 23 12:38:36.115: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 04/23/23 12:38:36.115
    Apr 23 12:38:36.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 create -f -'
    Apr 23 12:38:36.802: INFO: rc: 1
    Apr 23 12:38:36.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 --namespace=crd-publish-openapi-1385 apply -f -'
    Apr 23 12:38:37.362: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 04/23/23 12:38:37.362
    Apr 23 12:38:37.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 explain e2e-test-crd-publish-openapi-9046-crds'
    Apr 23 12:38:38.059: INFO: stderr: ""
    Apr 23 12:38:38.059: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9046-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 04/23/23 12:38:38.059
    Apr 23 12:38:38.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 explain e2e-test-crd-publish-openapi-9046-crds.metadata'
    Apr 23 12:38:38.770: INFO: stderr: ""
    Apr 23 12:38:38.770: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9046-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Apr 23 12:38:38.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 explain e2e-test-crd-publish-openapi-9046-crds.spec'
    Apr 23 12:38:39.248: INFO: stderr: ""
    Apr 23 12:38:39.248: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9046-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Apr 23 12:38:39.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 explain e2e-test-crd-publish-openapi-9046-crds.spec.bars'
    Apr 23 12:38:39.763: INFO: stderr: ""
    Apr 23 12:38:39.763: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9046-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 04/23/23 12:38:39.763
    Apr 23 12:38:39.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=crd-publish-openapi-1385 explain e2e-test-crd-publish-openapi-9046-crds.spec.bars2'
    Apr 23 12:38:40.379: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:38:42.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-1385" for this suite. 04/23/23 12:38:42.532
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:38:42.599
Apr 23 12:38:42.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename dns 04/23/23 12:38:42.605
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:42.68
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:42.687
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1254.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-1254.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 04/23/23 12:38:42.694
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1254.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-1254.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 04/23/23 12:38:42.694
STEP: creating a pod to probe /etc/hosts 04/23/23 12:38:42.694
STEP: submitting the pod to kubernetes 04/23/23 12:38:42.694
Apr 23 12:38:42.709: INFO: Waiting up to 15m0s for pod "dns-test-ccaeee51-ad90-4f35-9eb1-9b5e6014a124" in namespace "dns-1254" to be "running"
Apr 23 12:38:42.716: INFO: Pod "dns-test-ccaeee51-ad90-4f35-9eb1-9b5e6014a124": Phase="Pending", Reason="", readiness=false. Elapsed: 6.511075ms
Apr 23 12:38:44.728: INFO: Pod "dns-test-ccaeee51-ad90-4f35-9eb1-9b5e6014a124": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018501223s
Apr 23 12:38:46.728: INFO: Pod "dns-test-ccaeee51-ad90-4f35-9eb1-9b5e6014a124": Phase="Running", Reason="", readiness=true. Elapsed: 4.018075732s
Apr 23 12:38:46.728: INFO: Pod "dns-test-ccaeee51-ad90-4f35-9eb1-9b5e6014a124" satisfied condition "running"
STEP: retrieving the pod 04/23/23 12:38:46.728
STEP: looking for the results for each expected name from probers 04/23/23 12:38:46.735
Apr 23 12:38:46.777: INFO: DNS probes using dns-1254/dns-test-ccaeee51-ad90-4f35-9eb1-9b5e6014a124 succeeded

STEP: deleting the pod 04/23/23 12:38:46.777
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Apr 23 12:38:46.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-1254" for this suite. 04/23/23 12:38:46.845
------------------------------
â€¢ [4.271 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:38:42.599
    Apr 23 12:38:42.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename dns 04/23/23 12:38:42.605
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:42.68
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:42.687
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1254.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-1254.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     04/23/23 12:38:42.694
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1254.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-1254.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     04/23/23 12:38:42.694
    STEP: creating a pod to probe /etc/hosts 04/23/23 12:38:42.694
    STEP: submitting the pod to kubernetes 04/23/23 12:38:42.694
    Apr 23 12:38:42.709: INFO: Waiting up to 15m0s for pod "dns-test-ccaeee51-ad90-4f35-9eb1-9b5e6014a124" in namespace "dns-1254" to be "running"
    Apr 23 12:38:42.716: INFO: Pod "dns-test-ccaeee51-ad90-4f35-9eb1-9b5e6014a124": Phase="Pending", Reason="", readiness=false. Elapsed: 6.511075ms
    Apr 23 12:38:44.728: INFO: Pod "dns-test-ccaeee51-ad90-4f35-9eb1-9b5e6014a124": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018501223s
    Apr 23 12:38:46.728: INFO: Pod "dns-test-ccaeee51-ad90-4f35-9eb1-9b5e6014a124": Phase="Running", Reason="", readiness=true. Elapsed: 4.018075732s
    Apr 23 12:38:46.728: INFO: Pod "dns-test-ccaeee51-ad90-4f35-9eb1-9b5e6014a124" satisfied condition "running"
    STEP: retrieving the pod 04/23/23 12:38:46.728
    STEP: looking for the results for each expected name from probers 04/23/23 12:38:46.735
    Apr 23 12:38:46.777: INFO: DNS probes using dns-1254/dns-test-ccaeee51-ad90-4f35-9eb1-9b5e6014a124 succeeded

    STEP: deleting the pod 04/23/23 12:38:46.777
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:38:46.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-1254" for this suite. 04/23/23 12:38:46.845
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:896
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:38:46.875
Apr 23 12:38:46.876: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pods 04/23/23 12:38:46.878
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:46.947
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:46.966
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:896
STEP: creating a Pod with a static label 04/23/23 12:38:46.996
STEP: watching for Pod to be ready 04/23/23 12:38:47.012
Apr 23 12:38:47.017: INFO: observed Pod pod-test in namespace pods-8977 in phase Pending with labels: map[test-pod-static:true] & conditions []
Apr 23 12:38:47.054: INFO: observed Pod pod-test in namespace pods-8977 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:47 +0000 UTC  }]
Apr 23 12:38:47.106: INFO: observed Pod pod-test in namespace pods-8977 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:47 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:47 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:47 +0000 UTC  }]
Apr 23 12:38:49.369: INFO: Found Pod pod-test in namespace pods-8977 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:47 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 04/23/23 12:38:49.376
STEP: getting the Pod and ensuring that it's patched 04/23/23 12:38:49.393
STEP: replacing the Pod's status Ready condition to False 04/23/23 12:38:49.404
STEP: check the Pod again to ensure its Ready conditions are False 04/23/23 12:38:49.436
STEP: deleting the Pod via a Collection with a LabelSelector 04/23/23 12:38:49.437
STEP: watching for the Pod to be deleted 04/23/23 12:38:49.454
Apr 23 12:38:49.457: INFO: observed event type MODIFIED
Apr 23 12:38:51.382: INFO: observed event type MODIFIED
Apr 23 12:38:52.749: INFO: observed event type MODIFIED
Apr 23 12:38:52.915: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Apr 23 12:38:52.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-8977" for this suite. 04/23/23 12:38:52.955
------------------------------
â€¢ [SLOW TEST] [6.100 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:896

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:38:46.875
    Apr 23 12:38:46.876: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pods 04/23/23 12:38:46.878
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:46.947
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:46.966
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:896
    STEP: creating a Pod with a static label 04/23/23 12:38:46.996
    STEP: watching for Pod to be ready 04/23/23 12:38:47.012
    Apr 23 12:38:47.017: INFO: observed Pod pod-test in namespace pods-8977 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Apr 23 12:38:47.054: INFO: observed Pod pod-test in namespace pods-8977 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:47 +0000 UTC  }]
    Apr 23 12:38:47.106: INFO: observed Pod pod-test in namespace pods-8977 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:47 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:47 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:47 +0000 UTC  }]
    Apr 23 12:38:49.369: INFO: Found Pod pod-test in namespace pods-8977 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-23 12:38:47 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 04/23/23 12:38:49.376
    STEP: getting the Pod and ensuring that it's patched 04/23/23 12:38:49.393
    STEP: replacing the Pod's status Ready condition to False 04/23/23 12:38:49.404
    STEP: check the Pod again to ensure its Ready conditions are False 04/23/23 12:38:49.436
    STEP: deleting the Pod via a Collection with a LabelSelector 04/23/23 12:38:49.437
    STEP: watching for the Pod to be deleted 04/23/23 12:38:49.454
    Apr 23 12:38:49.457: INFO: observed event type MODIFIED
    Apr 23 12:38:51.382: INFO: observed event type MODIFIED
    Apr 23 12:38:52.749: INFO: observed event type MODIFIED
    Apr 23 12:38:52.915: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:38:52.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-8977" for this suite. 04/23/23 12:38:52.955
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:67
[BeforeEach] [sig-storage] Projected secret
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:38:52.979
Apr 23 12:38:52.979: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 12:38:52.982
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:53.027
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:53.037
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:67
STEP: Creating projection with secret that has name projected-secret-test-20395cf5-330e-4027-8442-231f85fa9422 04/23/23 12:38:53.042
STEP: Creating a pod to test consume secrets 04/23/23 12:38:53.052
Apr 23 12:38:53.069: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7" in namespace "projected-4974" to be "Succeeded or Failed"
Apr 23 12:38:53.079: INFO: Pod "pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.286472ms
Apr 23 12:38:55.090: INFO: Pod "pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020178502s
Apr 23 12:38:57.089: INFO: Pod "pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019221682s
STEP: Saw pod success 04/23/23 12:38:57.089
Apr 23 12:38:57.090: INFO: Pod "pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7" satisfied condition "Succeeded or Failed"
Apr 23 12:38:57.097: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/23/23 12:38:57.122
Apr 23 12:38:57.143: INFO: Waiting for pod pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7 to disappear
Apr 23 12:38:57.148: INFO: Pod pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/node/init/init.go:32
Apr 23 12:38:57.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected secret
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected secret
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-4974" for this suite. 04/23/23 12:38:57.158
------------------------------
â€¢ [4.191 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:38:52.979
    Apr 23 12:38:52.979: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 12:38:52.982
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:53.027
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:53.037
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:67
    STEP: Creating projection with secret that has name projected-secret-test-20395cf5-330e-4027-8442-231f85fa9422 04/23/23 12:38:53.042
    STEP: Creating a pod to test consume secrets 04/23/23 12:38:53.052
    Apr 23 12:38:53.069: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7" in namespace "projected-4974" to be "Succeeded or Failed"
    Apr 23 12:38:53.079: INFO: Pod "pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.286472ms
    Apr 23 12:38:55.090: INFO: Pod "pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020178502s
    Apr 23 12:38:57.089: INFO: Pod "pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019221682s
    STEP: Saw pod success 04/23/23 12:38:57.089
    Apr 23 12:38:57.090: INFO: Pod "pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7" satisfied condition "Succeeded or Failed"
    Apr 23 12:38:57.097: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/23/23 12:38:57.122
    Apr 23 12:38:57.143: INFO: Waiting for pod pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7 to disappear
    Apr 23 12:38:57.148: INFO: Pod pod-projected-secrets-ac7af62c-b611-4388-bdfd-86108c82aed7 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:38:57.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected secret
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected secret
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-4974" for this suite. 04/23/23 12:38:57.158
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1592
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:38:57.178
Apr 23 12:38:57.178: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 12:38:57.18
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:57.206
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:57.213
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1572
STEP: creating an pod 04/23/23 12:38:57.218
Apr 23 12:38:57.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.43 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Apr 23 12:38:57.387: INFO: stderr: ""
Apr 23 12:38:57.388: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1592
STEP: Waiting for log generator to start. 04/23/23 12:38:57.388
Apr 23 12:38:57.388: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Apr 23 12:38:57.388: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-5279" to be "running and ready, or succeeded"
Apr 23 12:38:57.394: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 6.338268ms
Apr 23 12:38:57.394: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'eingavuivie7-3' to be 'Running' but was 'Pending'
Apr 23 12:38:59.414: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026200852s
Apr 23 12:38:59.428: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'eingavuivie7-3' to be 'Running' but was 'Pending'
Apr 23 12:39:01.401: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.013377431s
Apr 23 12:39:01.401: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Apr 23 12:39:01.401: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 04/23/23 12:39:01.401
Apr 23 12:39:01.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 logs logs-generator logs-generator'
Apr 23 12:39:01.809: INFO: stderr: ""
Apr 23 12:39:01.809: INFO: stdout: "I0423 12:39:00.185505       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/5wqj 447\nI0423 12:39:00.385746       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/z4x 394\nI0423 12:39:00.586239       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/n4cl 513\nI0423 12:39:00.785641       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/kjn 296\nI0423 12:39:00.986038       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/rh8 502\nI0423 12:39:01.186585       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/v2c 260\nI0423 12:39:01.386172       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/qm4t 404\nI0423 12:39:01.586505       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/fzc 227\nI0423 12:39:01.785771       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/w6qf 346\n"
STEP: limiting log lines 04/23/23 12:39:01.809
Apr 23 12:39:01.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 logs logs-generator logs-generator --tail=1'
Apr 23 12:39:02.086: INFO: stderr: ""
Apr 23 12:39:02.086: INFO: stdout: "I0423 12:39:01.985635       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/78g7 537\n"
Apr 23 12:39:02.086: INFO: got output "I0423 12:39:01.985635       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/78g7 537\n"
STEP: limiting log bytes 04/23/23 12:39:02.086
Apr 23 12:39:02.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 logs logs-generator logs-generator --limit-bytes=1'
Apr 23 12:39:02.351: INFO: stderr: ""
Apr 23 12:39:02.351: INFO: stdout: "I"
Apr 23 12:39:02.351: INFO: got output "I"
STEP: exposing timestamps 04/23/23 12:39:02.351
Apr 23 12:39:02.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 logs logs-generator logs-generator --tail=1 --timestamps'
Apr 23 12:39:02.630: INFO: stderr: ""
Apr 23 12:39:02.630: INFO: stdout: "2023-04-23T12:39:02.586077657Z I0423 12:39:02.585964       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/8n4 483\n"
Apr 23 12:39:02.631: INFO: got output "2023-04-23T12:39:02.586077657Z I0423 12:39:02.585964       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/8n4 483\n"
STEP: restricting to a time range 04/23/23 12:39:02.631
Apr 23 12:39:05.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 logs logs-generator logs-generator --since=1s'
Apr 23 12:39:05.318: INFO: stderr: ""
Apr 23 12:39:05.318: INFO: stdout: "I0423 12:39:04.386093       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/prk 480\nI0423 12:39:04.585969       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/jf95 354\nI0423 12:39:04.786310       1 logs_generator.go:76] 23 POST /api/v1/namespaces/default/pods/p5v 388\nI0423 12:39:04.985636       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/ns/pods/nn8 586\nI0423 12:39:05.186471       1 logs_generator.go:76] 25 POST /api/v1/namespaces/kube-system/pods/dvrc 496\n"
Apr 23 12:39:05.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 logs logs-generator logs-generator --since=24h'
Apr 23 12:39:05.745: INFO: stderr: ""
Apr 23 12:39:05.745: INFO: stdout: "I0423 12:39:00.185505       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/5wqj 447\nI0423 12:39:00.385746       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/z4x 394\nI0423 12:39:00.586239       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/n4cl 513\nI0423 12:39:00.785641       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/kjn 296\nI0423 12:39:00.986038       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/rh8 502\nI0423 12:39:01.186585       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/v2c 260\nI0423 12:39:01.386172       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/qm4t 404\nI0423 12:39:01.586505       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/fzc 227\nI0423 12:39:01.785771       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/w6qf 346\nI0423 12:39:01.985635       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/78g7 537\nI0423 12:39:02.186263       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/b6t 398\nI0423 12:39:02.390540       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/w2dr 395\nI0423 12:39:02.585964       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/8n4 483\nI0423 12:39:02.786331       1 logs_generator.go:76] 13 GET /api/v1/namespaces/default/pods/7b25 435\nI0423 12:39:02.985820       1 logs_generator.go:76] 14 POST /api/v1/namespaces/default/pods/9mcn 447\nI0423 12:39:03.186417       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/4zs 401\nI0423 12:39:03.385668       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/v2b 542\nI0423 12:39:03.586150       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/br2 573\nI0423 12:39:03.786495       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/mv8p 325\nI0423 12:39:03.985747       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/7b9 375\nI0423 12:39:04.186530       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/668b 301\nI0423 12:39:04.386093       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/prk 480\nI0423 12:39:04.585969       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/jf95 354\nI0423 12:39:04.786310       1 logs_generator.go:76] 23 POST /api/v1/namespaces/default/pods/p5v 388\nI0423 12:39:04.985636       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/ns/pods/nn8 586\nI0423 12:39:05.186471       1 logs_generator.go:76] 25 POST /api/v1/namespaces/kube-system/pods/dvrc 496\nI0423 12:39:05.385706       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/z9g7 381\nI0423 12:39:05.586081       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/default/pods/jk9 587\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1577
Apr 23 12:39:05.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 delete pod logs-generator'
Apr 23 12:39:07.180: INFO: stderr: ""
Apr 23 12:39:07.180: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 12:39:07.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-5279" for this suite. 04/23/23 12:39:07.188
------------------------------
â€¢ [SLOW TEST] [10.023 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1569
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1592

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:38:57.178
    Apr 23 12:38:57.178: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 12:38:57.18
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:38:57.206
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:38:57.213
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1572
    STEP: creating an pod 04/23/23 12:38:57.218
    Apr 23 12:38:57.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.43 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Apr 23 12:38:57.387: INFO: stderr: ""
    Apr 23 12:38:57.388: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1592
    STEP: Waiting for log generator to start. 04/23/23 12:38:57.388
    Apr 23 12:38:57.388: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Apr 23 12:38:57.388: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-5279" to be "running and ready, or succeeded"
    Apr 23 12:38:57.394: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 6.338268ms
    Apr 23 12:38:57.394: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'eingavuivie7-3' to be 'Running' but was 'Pending'
    Apr 23 12:38:59.414: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026200852s
    Apr 23 12:38:59.428: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'eingavuivie7-3' to be 'Running' but was 'Pending'
    Apr 23 12:39:01.401: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.013377431s
    Apr 23 12:39:01.401: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Apr 23 12:39:01.401: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 04/23/23 12:39:01.401
    Apr 23 12:39:01.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 logs logs-generator logs-generator'
    Apr 23 12:39:01.809: INFO: stderr: ""
    Apr 23 12:39:01.809: INFO: stdout: "I0423 12:39:00.185505       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/5wqj 447\nI0423 12:39:00.385746       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/z4x 394\nI0423 12:39:00.586239       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/n4cl 513\nI0423 12:39:00.785641       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/kjn 296\nI0423 12:39:00.986038       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/rh8 502\nI0423 12:39:01.186585       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/v2c 260\nI0423 12:39:01.386172       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/qm4t 404\nI0423 12:39:01.586505       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/fzc 227\nI0423 12:39:01.785771       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/w6qf 346\n"
    STEP: limiting log lines 04/23/23 12:39:01.809
    Apr 23 12:39:01.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 logs logs-generator logs-generator --tail=1'
    Apr 23 12:39:02.086: INFO: stderr: ""
    Apr 23 12:39:02.086: INFO: stdout: "I0423 12:39:01.985635       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/78g7 537\n"
    Apr 23 12:39:02.086: INFO: got output "I0423 12:39:01.985635       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/78g7 537\n"
    STEP: limiting log bytes 04/23/23 12:39:02.086
    Apr 23 12:39:02.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 logs logs-generator logs-generator --limit-bytes=1'
    Apr 23 12:39:02.351: INFO: stderr: ""
    Apr 23 12:39:02.351: INFO: stdout: "I"
    Apr 23 12:39:02.351: INFO: got output "I"
    STEP: exposing timestamps 04/23/23 12:39:02.351
    Apr 23 12:39:02.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 logs logs-generator logs-generator --tail=1 --timestamps'
    Apr 23 12:39:02.630: INFO: stderr: ""
    Apr 23 12:39:02.630: INFO: stdout: "2023-04-23T12:39:02.586077657Z I0423 12:39:02.585964       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/8n4 483\n"
    Apr 23 12:39:02.631: INFO: got output "2023-04-23T12:39:02.586077657Z I0423 12:39:02.585964       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/8n4 483\n"
    STEP: restricting to a time range 04/23/23 12:39:02.631
    Apr 23 12:39:05.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 logs logs-generator logs-generator --since=1s'
    Apr 23 12:39:05.318: INFO: stderr: ""
    Apr 23 12:39:05.318: INFO: stdout: "I0423 12:39:04.386093       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/prk 480\nI0423 12:39:04.585969       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/jf95 354\nI0423 12:39:04.786310       1 logs_generator.go:76] 23 POST /api/v1/namespaces/default/pods/p5v 388\nI0423 12:39:04.985636       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/ns/pods/nn8 586\nI0423 12:39:05.186471       1 logs_generator.go:76] 25 POST /api/v1/namespaces/kube-system/pods/dvrc 496\n"
    Apr 23 12:39:05.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 logs logs-generator logs-generator --since=24h'
    Apr 23 12:39:05.745: INFO: stderr: ""
    Apr 23 12:39:05.745: INFO: stdout: "I0423 12:39:00.185505       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/5wqj 447\nI0423 12:39:00.385746       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/z4x 394\nI0423 12:39:00.586239       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/n4cl 513\nI0423 12:39:00.785641       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/kjn 296\nI0423 12:39:00.986038       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/rh8 502\nI0423 12:39:01.186585       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/v2c 260\nI0423 12:39:01.386172       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/qm4t 404\nI0423 12:39:01.586505       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/default/pods/fzc 227\nI0423 12:39:01.785771       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/w6qf 346\nI0423 12:39:01.985635       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/78g7 537\nI0423 12:39:02.186263       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/b6t 398\nI0423 12:39:02.390540       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/w2dr 395\nI0423 12:39:02.585964       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/8n4 483\nI0423 12:39:02.786331       1 logs_generator.go:76] 13 GET /api/v1/namespaces/default/pods/7b25 435\nI0423 12:39:02.985820       1 logs_generator.go:76] 14 POST /api/v1/namespaces/default/pods/9mcn 447\nI0423 12:39:03.186417       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/4zs 401\nI0423 12:39:03.385668       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/v2b 542\nI0423 12:39:03.586150       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/br2 573\nI0423 12:39:03.786495       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/mv8p 325\nI0423 12:39:03.985747       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/7b9 375\nI0423 12:39:04.186530       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/668b 301\nI0423 12:39:04.386093       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/prk 480\nI0423 12:39:04.585969       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/jf95 354\nI0423 12:39:04.786310       1 logs_generator.go:76] 23 POST /api/v1/namespaces/default/pods/p5v 388\nI0423 12:39:04.985636       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/ns/pods/nn8 586\nI0423 12:39:05.186471       1 logs_generator.go:76] 25 POST /api/v1/namespaces/kube-system/pods/dvrc 496\nI0423 12:39:05.385706       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/z9g7 381\nI0423 12:39:05.586081       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/default/pods/jk9 587\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1577
    Apr 23 12:39:05.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5279 delete pod logs-generator'
    Apr 23 12:39:07.180: INFO: stderr: ""
    Apr 23 12:39:07.180: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:39:07.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-5279" for this suite. 04/23/23 12:39:07.188
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:394
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:39:07.203
Apr 23 12:39:07.204: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 12:39:07.205
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:39:07.227
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:39:07.232
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:394
STEP: creating all guestbook components 04/23/23 12:39:07.235
Apr 23 12:39:07.235: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Apr 23 12:39:07.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 create -f -'
Apr 23 12:39:08.798: INFO: stderr: ""
Apr 23 12:39:08.798: INFO: stdout: "service/agnhost-replica created\n"
Apr 23 12:39:08.798: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Apr 23 12:39:08.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 create -f -'
Apr 23 12:39:09.396: INFO: stderr: ""
Apr 23 12:39:09.396: INFO: stdout: "service/agnhost-primary created\n"
Apr 23 12:39:09.396: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 23 12:39:09.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 create -f -'
Apr 23 12:39:10.068: INFO: stderr: ""
Apr 23 12:39:10.068: INFO: stdout: "service/frontend created\n"
Apr 23 12:39:10.072: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.43
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Apr 23 12:39:10.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 create -f -'
Apr 23 12:39:10.857: INFO: stderr: ""
Apr 23 12:39:10.857: INFO: stdout: "deployment.apps/frontend created\n"
Apr 23 12:39:10.857: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.43
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 23 12:39:10.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 create -f -'
Apr 23 12:39:12.077: INFO: stderr: ""
Apr 23 12:39:12.077: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Apr 23 12:39:12.078: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.43
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 23 12:39:12.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 create -f -'
Apr 23 12:39:13.476: INFO: stderr: ""
Apr 23 12:39:13.476: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 04/23/23 12:39:13.476
Apr 23 12:39:13.477: INFO: Waiting for all frontend pods to be Running.
Apr 23 12:39:18.533: INFO: Waiting for frontend to serve content.
Apr 23 12:39:18.584: INFO: Trying to add a new entry to the guestbook.
Apr 23 12:39:18.610: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 04/23/23 12:39:18.625
Apr 23 12:39:18.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 delete --grace-period=0 --force -f -'
Apr 23 12:39:18.971: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 12:39:18.972: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 04/23/23 12:39:18.972
Apr 23 12:39:18.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 delete --grace-period=0 --force -f -'
Apr 23 12:39:19.216: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 12:39:19.216: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 04/23/23 12:39:19.217
Apr 23 12:39:19.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 delete --grace-period=0 --force -f -'
Apr 23 12:39:19.437: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 12:39:19.437: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 04/23/23 12:39:19.438
Apr 23 12:39:19.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 delete --grace-period=0 --force -f -'
Apr 23 12:39:19.647: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 12:39:19.647: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 04/23/23 12:39:19.647
Apr 23 12:39:19.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 delete --grace-period=0 --force -f -'
Apr 23 12:39:19.873: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 12:39:19.873: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 04/23/23 12:39:19.874
Apr 23 12:39:19.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 delete --grace-period=0 --force -f -'
Apr 23 12:39:20.158: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 23 12:39:20.159: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 12:39:20.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-5542" for this suite. 04/23/23 12:39:20.191
------------------------------
â€¢ [SLOW TEST] [13.035 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:369
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:394

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:39:07.203
    Apr 23 12:39:07.204: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 12:39:07.205
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:39:07.227
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:39:07.232
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:394
    STEP: creating all guestbook components 04/23/23 12:39:07.235
    Apr 23 12:39:07.235: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Apr 23 12:39:07.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 create -f -'
    Apr 23 12:39:08.798: INFO: stderr: ""
    Apr 23 12:39:08.798: INFO: stdout: "service/agnhost-replica created\n"
    Apr 23 12:39:08.798: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Apr 23 12:39:08.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 create -f -'
    Apr 23 12:39:09.396: INFO: stderr: ""
    Apr 23 12:39:09.396: INFO: stdout: "service/agnhost-primary created\n"
    Apr 23 12:39:09.396: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Apr 23 12:39:09.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 create -f -'
    Apr 23 12:39:10.068: INFO: stderr: ""
    Apr 23 12:39:10.068: INFO: stdout: "service/frontend created\n"
    Apr 23 12:39:10.072: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.43
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Apr 23 12:39:10.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 create -f -'
    Apr 23 12:39:10.857: INFO: stderr: ""
    Apr 23 12:39:10.857: INFO: stdout: "deployment.apps/frontend created\n"
    Apr 23 12:39:10.857: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.43
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Apr 23 12:39:10.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 create -f -'
    Apr 23 12:39:12.077: INFO: stderr: ""
    Apr 23 12:39:12.077: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Apr 23 12:39:12.078: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.43
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Apr 23 12:39:12.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 create -f -'
    Apr 23 12:39:13.476: INFO: stderr: ""
    Apr 23 12:39:13.476: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 04/23/23 12:39:13.476
    Apr 23 12:39:13.477: INFO: Waiting for all frontend pods to be Running.
    Apr 23 12:39:18.533: INFO: Waiting for frontend to serve content.
    Apr 23 12:39:18.584: INFO: Trying to add a new entry to the guestbook.
    Apr 23 12:39:18.610: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 04/23/23 12:39:18.625
    Apr 23 12:39:18.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 delete --grace-period=0 --force -f -'
    Apr 23 12:39:18.971: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 23 12:39:18.972: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 04/23/23 12:39:18.972
    Apr 23 12:39:18.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 delete --grace-period=0 --force -f -'
    Apr 23 12:39:19.216: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 23 12:39:19.216: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 04/23/23 12:39:19.217
    Apr 23 12:39:19.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 delete --grace-period=0 --force -f -'
    Apr 23 12:39:19.437: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 23 12:39:19.437: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 04/23/23 12:39:19.438
    Apr 23 12:39:19.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 delete --grace-period=0 --force -f -'
    Apr 23 12:39:19.647: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 23 12:39:19.647: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 04/23/23 12:39:19.647
    Apr 23 12:39:19.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 delete --grace-period=0 --force -f -'
    Apr 23 12:39:19.873: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 23 12:39:19.873: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 04/23/23 12:39:19.874
    Apr 23 12:39:19.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-5542 delete --grace-period=0 --force -f -'
    Apr 23 12:39:20.158: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 23 12:39:20.159: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:39:20.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-5542" for this suite. 04/23/23 12:39:20.191
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:884
[BeforeEach] [sig-api-machinery] ResourceQuota
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:39:20.31
Apr 23 12:39:20.311: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename resourcequota 04/23/23 12:39:20.315
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:39:20.351
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:39:20.36
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:31
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:884
STEP: Creating a ResourceQuota 04/23/23 12:39:20.367
STEP: Getting a ResourceQuota 04/23/23 12:39:20.387
STEP: Updating a ResourceQuota 04/23/23 12:39:20.404
STEP: Verifying a ResourceQuota was modified 04/23/23 12:39:20.424
STEP: Deleting a ResourceQuota 04/23/23 12:39:20.433
STEP: Verifying the deleted ResourceQuota 04/23/23 12:39:20.467
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/node/init/init.go:32
Apr 23 12:39:20.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
  tear down framework | framework.go:193
STEP: Destroying namespace "resourcequota-5033" for this suite. 04/23/23 12:39:20.486
------------------------------
â€¢ [0.195 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:884

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:39:20.31
    Apr 23 12:39:20.311: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename resourcequota 04/23/23 12:39:20.315
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:39:20.351
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:39:20.36
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:31
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:884
    STEP: Creating a ResourceQuota 04/23/23 12:39:20.367
    STEP: Getting a ResourceQuota 04/23/23 12:39:20.387
    STEP: Updating a ResourceQuota 04/23/23 12:39:20.404
    STEP: Verifying a ResourceQuota was modified 04/23/23 12:39:20.424
    STEP: Deleting a ResourceQuota 04/23/23 12:39:20.433
    STEP: Verifying the deleted ResourceQuota 04/23/23 12:39:20.467
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:39:20.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] ResourceQuota
      tear down framework | framework.go:193
    STEP: Destroying namespace "resourcequota-5033" for this suite. 04/23/23 12:39:20.486
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:47
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:39:20.508
Apr 23 12:39:20.514: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename secrets 04/23/23 12:39:20.522
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:39:20.693
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:39:20.697
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:47
STEP: Creating secret with name secret-test-e35eb6bf-3d15-47c8-ba6a-473c186eada7 04/23/23 12:39:20.711
STEP: Creating a pod to test consume secrets 04/23/23 12:39:20.75
Apr 23 12:39:20.782: INFO: Waiting up to 5m0s for pod "pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293" in namespace "secrets-4448" to be "Succeeded or Failed"
Apr 23 12:39:20.821: INFO: Pod "pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293": Phase="Pending", Reason="", readiness=false. Elapsed: 38.190141ms
Apr 23 12:39:23.003: INFO: Pod "pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293": Phase="Pending", Reason="", readiness=false. Elapsed: 2.220875472s
Apr 23 12:39:24.834: INFO: Pod "pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051565943s
Apr 23 12:39:26.832: INFO: Pod "pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293": Phase="Pending", Reason="", readiness=false. Elapsed: 6.049343498s
Apr 23 12:39:28.843: INFO: Pod "pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.060745416s
STEP: Saw pod success 04/23/23 12:39:28.843
Apr 23 12:39:28.844: INFO: Pod "pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293" satisfied condition "Succeeded or Failed"
Apr 23 12:39:28.852: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293 container secret-volume-test: <nil>
STEP: delete the pod 04/23/23 12:39:28.87
Apr 23 12:39:28.895: INFO: Waiting for pod pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293 to disappear
Apr 23 12:39:28.902: INFO: Pod pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Apr 23 12:39:28.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-4448" for this suite. 04/23/23 12:39:28.922
------------------------------
â€¢ [SLOW TEST] [8.437 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:47

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:39:20.508
    Apr 23 12:39:20.514: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename secrets 04/23/23 12:39:20.522
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:39:20.693
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:39:20.697
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:47
    STEP: Creating secret with name secret-test-e35eb6bf-3d15-47c8-ba6a-473c186eada7 04/23/23 12:39:20.711
    STEP: Creating a pod to test consume secrets 04/23/23 12:39:20.75
    Apr 23 12:39:20.782: INFO: Waiting up to 5m0s for pod "pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293" in namespace "secrets-4448" to be "Succeeded or Failed"
    Apr 23 12:39:20.821: INFO: Pod "pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293": Phase="Pending", Reason="", readiness=false. Elapsed: 38.190141ms
    Apr 23 12:39:23.003: INFO: Pod "pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293": Phase="Pending", Reason="", readiness=false. Elapsed: 2.220875472s
    Apr 23 12:39:24.834: INFO: Pod "pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051565943s
    Apr 23 12:39:26.832: INFO: Pod "pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293": Phase="Pending", Reason="", readiness=false. Elapsed: 6.049343498s
    Apr 23 12:39:28.843: INFO: Pod "pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.060745416s
    STEP: Saw pod success 04/23/23 12:39:28.843
    Apr 23 12:39:28.844: INFO: Pod "pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293" satisfied condition "Succeeded or Failed"
    Apr 23 12:39:28.852: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293 container secret-volume-test: <nil>
    STEP: delete the pod 04/23/23 12:39:28.87
    Apr 23 12:39:28.895: INFO: Waiting for pod pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293 to disappear
    Apr 23 12:39:28.902: INFO: Pod pod-secrets-64dbb4c2-017a-4baf-be83-242ad179f293 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:39:28.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-4448" for this suite. 04/23/23 12:39:28.922
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:39:28.951
Apr 23 12:39:28.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 04/23/23 12:39:28.956
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:39:28.997
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:39:29.011
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/metrics/init/init.go:31
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 04/23/23 12:39:29.019
STEP: Creating hostNetwork=false pod 04/23/23 12:39:29.02
Apr 23 12:39:29.042: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-9688" to be "running and ready"
Apr 23 12:39:29.056: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.872235ms
Apr 23 12:39:29.057: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:39:31.066: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02345058s
Apr 23 12:39:31.066: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:39:33.072: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.029276518s
Apr 23 12:39:33.072: INFO: The phase of Pod test-pod is Running (Ready = true)
Apr 23 12:39:33.072: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 04/23/23 12:39:33.079
Apr 23 12:39:33.092: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-9688" to be "running and ready"
Apr 23 12:39:33.103: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.562714ms
Apr 23 12:39:33.104: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:39:35.115: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022241379s
Apr 23 12:39:35.115: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:39:37.111: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.018305961s
Apr 23 12:39:37.111: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Apr 23 12:39:37.111: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 04/23/23 12:39:37.119
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 04/23/23 12:39:37.12
Apr 23 12:39:37.120: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:39:37.120: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:39:37.123: INFO: ExecWithOptions: Clientset creation
Apr 23 12:39:37.123: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 23 12:39:37.274: INFO: Exec stderr: ""
Apr 23 12:39:37.274: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:39:37.274: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:39:37.277: INFO: ExecWithOptions: Clientset creation
Apr 23 12:39:37.278: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 23 12:39:37.610: INFO: Exec stderr: ""
Apr 23 12:39:37.610: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:39:37.611: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:39:37.613: INFO: ExecWithOptions: Clientset creation
Apr 23 12:39:37.613: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 23 12:39:37.895: INFO: Exec stderr: ""
Apr 23 12:39:37.895: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:39:37.895: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:39:37.898: INFO: ExecWithOptions: Clientset creation
Apr 23 12:39:37.898: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 23 12:39:38.029: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 04/23/23 12:39:38.03
Apr 23 12:39:38.031: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:39:38.031: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:39:38.034: INFO: ExecWithOptions: Clientset creation
Apr 23 12:39:38.034: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Apr 23 12:39:38.166: INFO: Exec stderr: ""
Apr 23 12:39:38.166: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:39:38.166: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:39:38.169: INFO: ExecWithOptions: Clientset creation
Apr 23 12:39:38.170: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Apr 23 12:39:38.304: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 04/23/23 12:39:38.304
Apr 23 12:39:38.304: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:39:38.304: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:39:38.307: INFO: ExecWithOptions: Clientset creation
Apr 23 12:39:38.308: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 23 12:39:38.530: INFO: Exec stderr: ""
Apr 23 12:39:38.531: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:39:38.531: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:39:38.535: INFO: ExecWithOptions: Clientset creation
Apr 23 12:39:38.535: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 23 12:39:38.701: INFO: Exec stderr: ""
Apr 23 12:39:38.701: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:39:38.701: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:39:38.703: INFO: ExecWithOptions: Clientset creation
Apr 23 12:39:38.703: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 23 12:39:38.899: INFO: Exec stderr: ""
Apr 23 12:39:38.900: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:39:38.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:39:38.903: INFO: ExecWithOptions: Clientset creation
Apr 23 12:39:38.904: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 23 12:39:39.002: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/node/init/init.go:32
Apr 23 12:39:39.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] KubeletManagedEtcHosts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] KubeletManagedEtcHosts
  tear down framework | framework.go:193
STEP: Destroying namespace "e2e-kubelet-etc-hosts-9688" for this suite. 04/23/23 12:39:39.014
------------------------------
â€¢ [SLOW TEST] [10.096 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:39:28.951
    Apr 23 12:39:28.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 04/23/23 12:39:28.956
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:39:28.997
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:39:29.011
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/metrics/init/init.go:31
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 04/23/23 12:39:29.019
    STEP: Creating hostNetwork=false pod 04/23/23 12:39:29.02
    Apr 23 12:39:29.042: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-9688" to be "running and ready"
    Apr 23 12:39:29.056: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.872235ms
    Apr 23 12:39:29.057: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:39:31.066: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02345058s
    Apr 23 12:39:31.066: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:39:33.072: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.029276518s
    Apr 23 12:39:33.072: INFO: The phase of Pod test-pod is Running (Ready = true)
    Apr 23 12:39:33.072: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 04/23/23 12:39:33.079
    Apr 23 12:39:33.092: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-9688" to be "running and ready"
    Apr 23 12:39:33.103: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.562714ms
    Apr 23 12:39:33.104: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:39:35.115: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022241379s
    Apr 23 12:39:35.115: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:39:37.111: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.018305961s
    Apr 23 12:39:37.111: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Apr 23 12:39:37.111: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 04/23/23 12:39:37.119
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 04/23/23 12:39:37.12
    Apr 23 12:39:37.120: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:39:37.120: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:39:37.123: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:39:37.123: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 23 12:39:37.274: INFO: Exec stderr: ""
    Apr 23 12:39:37.274: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:39:37.274: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:39:37.277: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:39:37.278: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 23 12:39:37.610: INFO: Exec stderr: ""
    Apr 23 12:39:37.610: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:39:37.611: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:39:37.613: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:39:37.613: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 23 12:39:37.895: INFO: Exec stderr: ""
    Apr 23 12:39:37.895: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:39:37.895: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:39:37.898: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:39:37.898: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 23 12:39:38.029: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 04/23/23 12:39:38.03
    Apr 23 12:39:38.031: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:39:38.031: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:39:38.034: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:39:38.034: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Apr 23 12:39:38.166: INFO: Exec stderr: ""
    Apr 23 12:39:38.166: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:39:38.166: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:39:38.169: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:39:38.170: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Apr 23 12:39:38.304: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 04/23/23 12:39:38.304
    Apr 23 12:39:38.304: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:39:38.304: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:39:38.307: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:39:38.308: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 23 12:39:38.530: INFO: Exec stderr: ""
    Apr 23 12:39:38.531: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:39:38.531: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:39:38.535: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:39:38.535: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 23 12:39:38.701: INFO: Exec stderr: ""
    Apr 23 12:39:38.701: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:39:38.701: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:39:38.703: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:39:38.703: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 23 12:39:38.899: INFO: Exec stderr: ""
    Apr 23 12:39:38.900: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9688 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:39:38.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:39:38.903: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:39:38.904: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9688/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 23 12:39:39.002: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:39:39.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] KubeletManagedEtcHosts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] KubeletManagedEtcHosts
      tear down framework | framework.go:193
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-9688" for this suite. 04/23/23 12:39:39.014
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:207
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:39:39.057
Apr 23 12:39:39.057: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 12:39:39.059
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:39:39.104
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:39:39.116
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:207
STEP: Creating a pod to test downward API volume plugin 04/23/23 12:39:39.122
Apr 23 12:39:39.143: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6" in namespace "downward-api-2269" to be "Succeeded or Failed"
Apr 23 12:39:39.167: INFO: Pod "downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6": Phase="Pending", Reason="", readiness=false. Elapsed: 23.643969ms
Apr 23 12:39:41.181: INFO: Pod "downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037194161s
Apr 23 12:39:43.177: INFO: Pod "downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033417936s
Apr 23 12:39:45.176: INFO: Pod "downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032275601s
STEP: Saw pod success 04/23/23 12:39:45.176
Apr 23 12:39:45.176: INFO: Pod "downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6" satisfied condition "Succeeded or Failed"
Apr 23 12:39:45.182: INFO: Trying to get logs from node eingavuivie7-1 pod downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6 container client-container: <nil>
STEP: delete the pod 04/23/23 12:39:45.215
Apr 23 12:39:45.242: INFO: Waiting for pod downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6 to disappear
Apr 23 12:39:45.251: INFO: Pod downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Apr 23 12:39:45.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-2269" for this suite. 04/23/23 12:39:45.264
------------------------------
â€¢ [SLOW TEST] [6.223 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:39:39.057
    Apr 23 12:39:39.057: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 12:39:39.059
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:39:39.104
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:39:39.116
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:207
    STEP: Creating a pod to test downward API volume plugin 04/23/23 12:39:39.122
    Apr 23 12:39:39.143: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6" in namespace "downward-api-2269" to be "Succeeded or Failed"
    Apr 23 12:39:39.167: INFO: Pod "downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6": Phase="Pending", Reason="", readiness=false. Elapsed: 23.643969ms
    Apr 23 12:39:41.181: INFO: Pod "downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037194161s
    Apr 23 12:39:43.177: INFO: Pod "downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033417936s
    Apr 23 12:39:45.176: INFO: Pod "downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032275601s
    STEP: Saw pod success 04/23/23 12:39:45.176
    Apr 23 12:39:45.176: INFO: Pod "downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6" satisfied condition "Succeeded or Failed"
    Apr 23 12:39:45.182: INFO: Trying to get logs from node eingavuivie7-1 pod downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6 container client-container: <nil>
    STEP: delete the pod 04/23/23 12:39:45.215
    Apr 23 12:39:45.242: INFO: Waiting for pod downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6 to disappear
    Apr 23 12:39:45.251: INFO: Pod downwardapi-volume-b294bd38-7b8c-4595-a585-3b247618def6 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:39:45.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-2269" for this suite. 04/23/23 12:39:45.264
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:39:45.284
Apr 23 12:39:45.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename deployment 04/23/23 12:39:45.287
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:39:45.338
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:39:45.347
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 04/23/23 12:39:45.365
STEP: waiting for Deployment to be created 04/23/23 12:39:45.38
STEP: waiting for all Replicas to be Ready 04/23/23 12:39:45.387
Apr 23 12:39:45.389: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 23 12:39:45.389: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 23 12:39:45.414: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 23 12:39:45.414: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 23 12:39:45.501: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 23 12:39:45.501: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 23 12:39:45.562: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 23 12:39:45.562: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 23 12:39:47.904: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr 23 12:39:47.904: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr 23 12:39:48.389: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 04/23/23 12:39:48.389
W0423 12:39:48.403419      13 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 23 12:39:48.407: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 04/23/23 12:39:48.408
Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
Apr 23 12:39:48.413: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
Apr 23 12:39:48.413: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
Apr 23 12:39:48.447: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
Apr 23 12:39:48.447: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
Apr 23 12:39:48.485: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
Apr 23 12:39:48.486: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
Apr 23 12:39:48.594: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
Apr 23 12:39:48.594: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
Apr 23 12:39:48.615: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
Apr 23 12:39:48.615: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
Apr 23 12:39:50.496: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
Apr 23 12:39:50.496: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
Apr 23 12:39:50.647: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
STEP: listing Deployments 04/23/23 12:39:50.647
Apr 23 12:39:50.665: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 04/23/23 12:39:50.666
Apr 23 12:39:50.725: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 04/23/23 12:39:50.725
Apr 23 12:39:50.777: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 23 12:39:50.904: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 23 12:39:50.996: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 23 12:39:51.055: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 23 12:39:51.095: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 23 12:39:53.089: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 23 12:39:53.194: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 23 12:39:55.008: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 04/23/23 12:39:55.115
STEP: fetching the DeploymentStatus 04/23/23 12:39:55.142
Apr 23 12:39:55.170: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
Apr 23 12:39:55.171: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
Apr 23 12:39:55.171: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
Apr 23 12:39:55.171: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
Apr 23 12:39:55.171: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
Apr 23 12:39:55.172: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
Apr 23 12:39:55.172: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
Apr 23 12:39:55.172: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 3
STEP: deleting the Deployment 04/23/23 12:39:55.172
Apr 23 12:39:55.211: INFO: observed event type MODIFIED
Apr 23 12:39:55.211: INFO: observed event type MODIFIED
Apr 23 12:39:55.212: INFO: observed event type MODIFIED
Apr 23 12:39:55.212: INFO: observed event type MODIFIED
Apr 23 12:39:55.212: INFO: observed event type MODIFIED
Apr 23 12:39:55.213: INFO: observed event type MODIFIED
Apr 23 12:39:55.213: INFO: observed event type MODIFIED
Apr 23 12:39:55.213: INFO: observed event type MODIFIED
Apr 23 12:39:55.213: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 23 12:39:55.232: INFO: Log out all the ReplicaSets if there is no deployment created
Apr 23 12:39:55.260: INFO: ReplicaSet "test-deployment-7b7876f9d6":
&ReplicaSet{ObjectMeta:{test-deployment-7b7876f9d6  deployment-417  0574860d-11a7-4541-b653-6f8a425a1fdb 36115 2 2023-04-23 12:39:50 +0000 UTC <nil> <nil> map[pod-template-hash:7b7876f9d6 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment a66a3534-2783-4f72-8f02-5aecb5aabb2a 0xc00382ddf7 0xc00382ddf8}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:39:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a66a3534-2783-4f72-8f02-5aecb5aabb2a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:39:54 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7b7876f9d6,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7b7876f9d6 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00382de80 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Apr 23 12:39:55.291: INFO: pod: "test-deployment-7b7876f9d6-j8nfb":
&Pod{ObjectMeta:{test-deployment-7b7876f9d6-j8nfb test-deployment-7b7876f9d6- deployment-417  9f801c97-71f9-452d-847c-0d56bfc8ca3d 36078 0 2023-04-23 12:39:50 +0000 UTC <nil> <nil> map[pod-template-hash:7b7876f9d6 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7b7876f9d6 0574860d-11a7-4541-b653-6f8a425a1fdb 0xc003651f87 0xc003651f88}] [] [{kube-controller-manager Update v1 2023-04-23 12:39:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0574860d-11a7-4541-b653-6f8a425a1fdb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:39:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.182\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kmwdk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kmwdk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.182,StartTime:2023-04-23 12:39:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:39:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://fb516c593bb8418ce392eba654675fb8663cc5331587a6a086ae93241d7ef01c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.182,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 23 12:39:55.292: INFO: pod: "test-deployment-7b7876f9d6-kc6z5":
&Pod{ObjectMeta:{test-deployment-7b7876f9d6-kc6z5 test-deployment-7b7876f9d6- deployment-417  ab83161c-2e64-4754-89e5-617b3262bf88 36114 0 2023-04-23 12:39:53 +0000 UTC <nil> <nil> map[pod-template-hash:7b7876f9d6 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7b7876f9d6 0574860d-11a7-4541-b653-6f8a425a1fdb 0xc0046c8177 0xc0046c8178}] [] [{kube-controller-manager Update v1 2023-04-23 12:39:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0574860d-11a7-4541-b653-6f8a425a1fdb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:39:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.162\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m2scg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m2scg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:10.233.66.162,StartTime:2023-04-23 12:39:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:39:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://d9c4128b80c7e171933cab7c4226dc7b0a0df163b0836314df71546a75c352c1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.162,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 23 12:39:55.292: INFO: ReplicaSet "test-deployment-7df74c55ff":
&ReplicaSet{ObjectMeta:{test-deployment-7df74c55ff  deployment-417  dc1e34a3-1c76-439e-82f6-9a36f747aba7 36123 4 2023-04-23 12:39:48 +0000 UTC <nil> <nil> map[pod-template-hash:7df74c55ff test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment a66a3534-2783-4f72-8f02-5aecb5aabb2a 0xc00382dee7 0xc00382dee8}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:39:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a66a3534-2783-4f72-8f02-5aecb5aabb2a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:39:55 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7df74c55ff,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7df74c55ff test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.9 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00382df70 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Apr 23 12:39:55.304: INFO: pod: "test-deployment-7df74c55ff-whr2p":
&Pod{ObjectMeta:{test-deployment-7df74c55ff-whr2p test-deployment-7df74c55ff- deployment-417  750e4133-e8d6-493c-93d1-878abdff53c2 36119 0 2023-04-23 12:39:48 +0000 UTC 2023-04-23 12:39:55 +0000 UTC 0xc00007b1b8 map[pod-template-hash:7df74c55ff test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7df74c55ff dc1e34a3-1c76-439e-82f6-9a36f747aba7 0xc00007b577 0xc00007b578}] [] [{kube-controller-manager Update v1 2023-04-23 12:39:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc1e34a3-1c76-439e-82f6-9a36f747aba7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:39:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.17\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9j8xj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.9,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9j8xj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.17,StartTime:2023-04-23 12:39:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:39:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.9,ImageID:registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097,ContainerID:cri-o://3f8059662569f073b72ec93ef2f3bda63a8dd8d8cc8242ef2ee9450f38472f4d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.17,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 23 12:39:55.305: INFO: ReplicaSet "test-deployment-f4dbc4647":
&ReplicaSet{ObjectMeta:{test-deployment-f4dbc4647  deployment-417  cde384c1-5088-4dc0-92b5-f69568b03522 36023 3 2023-04-23 12:39:45 +0000 UTC <nil> <nil> map[pod-template-hash:f4dbc4647 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment a66a3534-2783-4f72-8f02-5aecb5aabb2a 0xc00382dfd7 0xc00382dfd8}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:39:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a66a3534-2783-4f72-8f02-5aecb5aabb2a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:39:50 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: f4dbc4647,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:f4dbc4647 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00007a4f0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Apr 23 12:39:55.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-417" for this suite. 04/23/23 12:39:55.346
------------------------------
â€¢ [SLOW TEST] [10.093 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:39:45.284
    Apr 23 12:39:45.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename deployment 04/23/23 12:39:45.287
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:39:45.338
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:39:45.347
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 04/23/23 12:39:45.365
    STEP: waiting for Deployment to be created 04/23/23 12:39:45.38
    STEP: waiting for all Replicas to be Ready 04/23/23 12:39:45.387
    Apr 23 12:39:45.389: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 23 12:39:45.389: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 23 12:39:45.414: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 23 12:39:45.414: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 23 12:39:45.501: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 23 12:39:45.501: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 23 12:39:45.562: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 23 12:39:45.562: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 23 12:39:47.904: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Apr 23 12:39:47.904: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Apr 23 12:39:48.389: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 04/23/23 12:39:48.389
    W0423 12:39:48.403419      13 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 23 12:39:48.407: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 04/23/23 12:39:48.408
    Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
    Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
    Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
    Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
    Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
    Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
    Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
    Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 0
    Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
    Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
    Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
    Apr 23 12:39:48.412: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
    Apr 23 12:39:48.413: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
    Apr 23 12:39:48.413: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
    Apr 23 12:39:48.447: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
    Apr 23 12:39:48.447: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
    Apr 23 12:39:48.485: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
    Apr 23 12:39:48.486: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
    Apr 23 12:39:48.594: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
    Apr 23 12:39:48.594: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
    Apr 23 12:39:48.615: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
    Apr 23 12:39:48.615: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
    Apr 23 12:39:50.496: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
    Apr 23 12:39:50.496: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
    Apr 23 12:39:50.647: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
    STEP: listing Deployments 04/23/23 12:39:50.647
    Apr 23 12:39:50.665: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 04/23/23 12:39:50.666
    Apr 23 12:39:50.725: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 04/23/23 12:39:50.725
    Apr 23 12:39:50.777: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 23 12:39:50.904: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 23 12:39:50.996: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 23 12:39:51.055: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 23 12:39:51.095: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 23 12:39:53.089: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 23 12:39:53.194: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 23 12:39:55.008: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 04/23/23 12:39:55.115
    STEP: fetching the DeploymentStatus 04/23/23 12:39:55.142
    Apr 23 12:39:55.170: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
    Apr 23 12:39:55.171: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
    Apr 23 12:39:55.171: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
    Apr 23 12:39:55.171: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
    Apr 23 12:39:55.171: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 1
    Apr 23 12:39:55.172: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
    Apr 23 12:39:55.172: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 2
    Apr 23 12:39:55.172: INFO: observed Deployment test-deployment in namespace deployment-417 with ReadyReplicas 3
    STEP: deleting the Deployment 04/23/23 12:39:55.172
    Apr 23 12:39:55.211: INFO: observed event type MODIFIED
    Apr 23 12:39:55.211: INFO: observed event type MODIFIED
    Apr 23 12:39:55.212: INFO: observed event type MODIFIED
    Apr 23 12:39:55.212: INFO: observed event type MODIFIED
    Apr 23 12:39:55.212: INFO: observed event type MODIFIED
    Apr 23 12:39:55.213: INFO: observed event type MODIFIED
    Apr 23 12:39:55.213: INFO: observed event type MODIFIED
    Apr 23 12:39:55.213: INFO: observed event type MODIFIED
    Apr 23 12:39:55.213: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 23 12:39:55.232: INFO: Log out all the ReplicaSets if there is no deployment created
    Apr 23 12:39:55.260: INFO: ReplicaSet "test-deployment-7b7876f9d6":
    &ReplicaSet{ObjectMeta:{test-deployment-7b7876f9d6  deployment-417  0574860d-11a7-4541-b653-6f8a425a1fdb 36115 2 2023-04-23 12:39:50 +0000 UTC <nil> <nil> map[pod-template-hash:7b7876f9d6 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment a66a3534-2783-4f72-8f02-5aecb5aabb2a 0xc00382ddf7 0xc00382ddf8}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:39:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a66a3534-2783-4f72-8f02-5aecb5aabb2a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:39:54 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7b7876f9d6,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7b7876f9d6 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00382de80 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Apr 23 12:39:55.291: INFO: pod: "test-deployment-7b7876f9d6-j8nfb":
    &Pod{ObjectMeta:{test-deployment-7b7876f9d6-j8nfb test-deployment-7b7876f9d6- deployment-417  9f801c97-71f9-452d-847c-0d56bfc8ca3d 36078 0 2023-04-23 12:39:50 +0000 UTC <nil> <nil> map[pod-template-hash:7b7876f9d6 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7b7876f9d6 0574860d-11a7-4541-b653-6f8a425a1fdb 0xc003651f87 0xc003651f88}] [] [{kube-controller-manager Update v1 2023-04-23 12:39:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0574860d-11a7-4541-b653-6f8a425a1fdb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:39:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.182\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kmwdk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kmwdk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.182,StartTime:2023-04-23 12:39:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:39:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://fb516c593bb8418ce392eba654675fb8663cc5331587a6a086ae93241d7ef01c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.182,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 23 12:39:55.292: INFO: pod: "test-deployment-7b7876f9d6-kc6z5":
    &Pod{ObjectMeta:{test-deployment-7b7876f9d6-kc6z5 test-deployment-7b7876f9d6- deployment-417  ab83161c-2e64-4754-89e5-617b3262bf88 36114 0 2023-04-23 12:39:53 +0000 UTC <nil> <nil> map[pod-template-hash:7b7876f9d6 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7b7876f9d6 0574860d-11a7-4541-b653-6f8a425a1fdb 0xc0046c8177 0xc0046c8178}] [] [{kube-controller-manager Update v1 2023-04-23 12:39:53 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0574860d-11a7-4541-b653-6f8a425a1fdb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:39:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.162\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m2scg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m2scg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:10.233.66.162,StartTime:2023-04-23 12:39:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:39:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://d9c4128b80c7e171933cab7c4226dc7b0a0df163b0836314df71546a75c352c1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.162,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 23 12:39:55.292: INFO: ReplicaSet "test-deployment-7df74c55ff":
    &ReplicaSet{ObjectMeta:{test-deployment-7df74c55ff  deployment-417  dc1e34a3-1c76-439e-82f6-9a36f747aba7 36123 4 2023-04-23 12:39:48 +0000 UTC <nil> <nil> map[pod-template-hash:7df74c55ff test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment a66a3534-2783-4f72-8f02-5aecb5aabb2a 0xc00382dee7 0xc00382dee8}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:39:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a66a3534-2783-4f72-8f02-5aecb5aabb2a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:39:55 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7df74c55ff,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7df74c55ff test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.9 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00382df70 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Apr 23 12:39:55.304: INFO: pod: "test-deployment-7df74c55ff-whr2p":
    &Pod{ObjectMeta:{test-deployment-7df74c55ff-whr2p test-deployment-7df74c55ff- deployment-417  750e4133-e8d6-493c-93d1-878abdff53c2 36119 0 2023-04-23 12:39:48 +0000 UTC 2023-04-23 12:39:55 +0000 UTC 0xc00007b1b8 map[pod-template-hash:7df74c55ff test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7df74c55ff dc1e34a3-1c76-439e-82f6-9a36f747aba7 0xc00007b577 0xc00007b578}] [] [{kube-controller-manager Update v1 2023-04-23 12:39:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc1e34a3-1c76-439e-82f6-9a36f747aba7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:39:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.17\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9j8xj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.9,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9j8xj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:39:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.17,StartTime:2023-04-23 12:39:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:39:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.9,ImageID:registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097,ContainerID:cri-o://3f8059662569f073b72ec93ef2f3bda63a8dd8d8cc8242ef2ee9450f38472f4d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.17,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 23 12:39:55.305: INFO: ReplicaSet "test-deployment-f4dbc4647":
    &ReplicaSet{ObjectMeta:{test-deployment-f4dbc4647  deployment-417  cde384c1-5088-4dc0-92b5-f69568b03522 36023 3 2023-04-23 12:39:45 +0000 UTC <nil> <nil> map[pod-template-hash:f4dbc4647 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment a66a3534-2783-4f72-8f02-5aecb5aabb2a 0xc00382dfd7 0xc00382dfd8}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:39:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a66a3534-2783-4f72-8f02-5aecb5aabb2a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:39:50 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: f4dbc4647,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:f4dbc4647 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00007a4f0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:39:55.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-417" for this suite. 04/23/23 12:39:55.346
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:134
[BeforeEach] [sig-node] Container Lifecycle Hook
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:39:55.379
Apr 23 12:39:55.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-lifecycle-hook 04/23/23 12:39:55.394
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:39:55.44
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:39:55.444
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:77
STEP: create the container to handle the HTTPGet hook request. 04/23/23 12:39:55.477
Apr 23 12:39:55.535: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9309" to be "running and ready"
Apr 23 12:39:55.552: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 17.136745ms
Apr 23 12:39:55.553: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:39:57.560: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024349121s
Apr 23 12:39:57.560: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:39:59.561: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.025681866s
Apr 23 12:39:59.561: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 23 12:39:59.561: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:134
STEP: create the pod with lifecycle hook 04/23/23 12:39:59.567
Apr 23 12:39:59.578: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-9309" to be "running and ready"
Apr 23 12:39:59.583: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.967444ms
Apr 23 12:39:59.583: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:40:01.607: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029010416s
Apr 23 12:40:01.607: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:40:03.594: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.015725341s
Apr 23 12:40:03.594: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Apr 23 12:40:03.594: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 04/23/23 12:40:03.599
STEP: delete the pod with lifecycle hook 04/23/23 12:40:03.683
Apr 23 12:40:03.698: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 12:40:03.707: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 23 12:40:05.708: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 23 12:40:05.722: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/node/init/init.go:32
Apr 23 12:40:05.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  tear down framework | framework.go:193
STEP: Destroying namespace "container-lifecycle-hook-9309" for this suite. 04/23/23 12:40:05.736
------------------------------
â€¢ [SLOW TEST] [10.370 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:134

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:39:55.379
    Apr 23 12:39:55.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/23/23 12:39:55.394
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:39:55.44
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:39:55.444
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:77
    STEP: create the container to handle the HTTPGet hook request. 04/23/23 12:39:55.477
    Apr 23 12:39:55.535: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9309" to be "running and ready"
    Apr 23 12:39:55.552: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 17.136745ms
    Apr 23 12:39:55.553: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:39:57.560: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024349121s
    Apr 23 12:39:57.560: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:39:59.561: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.025681866s
    Apr 23 12:39:59.561: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 23 12:39:59.561: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:134
    STEP: create the pod with lifecycle hook 04/23/23 12:39:59.567
    Apr 23 12:39:59.578: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-9309" to be "running and ready"
    Apr 23 12:39:59.583: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.967444ms
    Apr 23 12:39:59.583: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:40:01.607: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029010416s
    Apr 23 12:40:01.607: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:40:03.594: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.015725341s
    Apr 23 12:40:03.594: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Apr 23 12:40:03.594: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 04/23/23 12:40:03.599
    STEP: delete the pod with lifecycle hook 04/23/23 12:40:03.683
    Apr 23 12:40:03.698: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 23 12:40:03.707: INFO: Pod pod-with-poststart-exec-hook still exists
    Apr 23 12:40:05.708: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 23 12:40:05.722: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:40:05.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-lifecycle-hook-9309" for this suite. 04/23/23 12:40:05.736
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:235
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:40:05.752
Apr 23 12:40:05.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 12:40:05.755
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:40:05.782
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:40:05.791
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:235
STEP: Creating a pod to test downward API volume plugin 04/23/23 12:40:05.8
Apr 23 12:40:05.830: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c" in namespace "projected-2379" to be "Succeeded or Failed"
Apr 23 12:40:05.838: INFO: Pod "downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.405891ms
Apr 23 12:40:07.845: INFO: Pod "downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014702543s
Apr 23 12:40:09.850: INFO: Pod "downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019182074s
Apr 23 12:40:11.847: INFO: Pod "downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016454308s
STEP: Saw pod success 04/23/23 12:40:11.847
Apr 23 12:40:11.847: INFO: Pod "downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c" satisfied condition "Succeeded or Failed"
Apr 23 12:40:11.854: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c container client-container: <nil>
STEP: delete the pod 04/23/23 12:40:11.91
Apr 23 12:40:11.944: INFO: Waiting for pod downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c to disappear
Apr 23 12:40:11.952: INFO: Pod downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Apr 23 12:40:11.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-2379" for this suite. 04/23/23 12:40:11.962
------------------------------
â€¢ [SLOW TEST] [6.226 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:40:05.752
    Apr 23 12:40:05.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 12:40:05.755
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:40:05.782
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:40:05.791
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:235
    STEP: Creating a pod to test downward API volume plugin 04/23/23 12:40:05.8
    Apr 23 12:40:05.830: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c" in namespace "projected-2379" to be "Succeeded or Failed"
    Apr 23 12:40:05.838: INFO: Pod "downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.405891ms
    Apr 23 12:40:07.845: INFO: Pod "downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014702543s
    Apr 23 12:40:09.850: INFO: Pod "downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019182074s
    Apr 23 12:40:11.847: INFO: Pod "downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016454308s
    STEP: Saw pod success 04/23/23 12:40:11.847
    Apr 23 12:40:11.847: INFO: Pod "downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c" satisfied condition "Succeeded or Failed"
    Apr 23 12:40:11.854: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c container client-container: <nil>
    STEP: delete the pod 04/23/23 12:40:11.91
    Apr 23 12:40:11.944: INFO: Waiting for pod downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c to disappear
    Apr 23 12:40:11.952: INFO: Pod downwardapi-volume-6295c0a0-e3ab-4e17-bbba-6138ec55046c no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:40:11.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-2379" for this suite. 04/23/23 12:40:11.962
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:40:11.993
Apr 23 12:40:11.994: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename runtimeclass 04/23/23 12:40:11.998
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:40:12.034
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:40:12.039
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:31
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/node/init/init.go:32
Apr 23 12:40:12.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] RuntimeClass
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] RuntimeClass
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] RuntimeClass
  tear down framework | framework.go:193
STEP: Destroying namespace "runtimeclass-8061" for this suite. 04/23/23 12:40:12.069
------------------------------
â€¢ [0.090 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:40:11.993
    Apr 23 12:40:11.994: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename runtimeclass 04/23/23 12:40:11.998
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:40:12.034
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:40:12.039
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:31
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:40:12.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] RuntimeClass
      tear down framework | framework.go:193
    STEP: Destroying namespace "runtimeclass-8061" for this suite. 04/23/23 12:40:12.069
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:40:12.086
Apr 23 12:40:12.086: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename dns 04/23/23 12:40:12.088
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:40:12.113
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:40:12.117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 04/23/23 12:40:12.121
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8774.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local; sleep 1; done
 04/23/23 12:40:12.134
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8774.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local; sleep 1; done
 04/23/23 12:40:12.136
STEP: creating a pod to probe DNS 04/23/23 12:40:12.136
STEP: submitting the pod to kubernetes 04/23/23 12:40:12.137
Apr 23 12:40:12.157: INFO: Waiting up to 15m0s for pod "dns-test-d7a8bab1-5c91-4f1e-b92d-cce65f46a745" in namespace "dns-8774" to be "running"
Apr 23 12:40:12.175: INFO: Pod "dns-test-d7a8bab1-5c91-4f1e-b92d-cce65f46a745": Phase="Pending", Reason="", readiness=false. Elapsed: 18.495898ms
Apr 23 12:40:14.187: INFO: Pod "dns-test-d7a8bab1-5c91-4f1e-b92d-cce65f46a745": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029722885s
Apr 23 12:40:16.183: INFO: Pod "dns-test-d7a8bab1-5c91-4f1e-b92d-cce65f46a745": Phase="Running", Reason="", readiness=true. Elapsed: 4.026036182s
Apr 23 12:40:16.183: INFO: Pod "dns-test-d7a8bab1-5c91-4f1e-b92d-cce65f46a745" satisfied condition "running"
STEP: retrieving the pod 04/23/23 12:40:16.183
STEP: looking for the results for each expected name from probers 04/23/23 12:40:16.189
Apr 23 12:40:16.210: INFO: DNS probes using dns-test-d7a8bab1-5c91-4f1e-b92d-cce65f46a745 succeeded

STEP: deleting the pod 04/23/23 12:40:16.21
STEP: changing the externalName to bar.example.com 04/23/23 12:40:16.238
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8774.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local; sleep 1; done
 04/23/23 12:40:16.255
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8774.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local; sleep 1; done
 04/23/23 12:40:16.255
STEP: creating a second pod to probe DNS 04/23/23 12:40:16.255
STEP: submitting the pod to kubernetes 04/23/23 12:40:16.255
Apr 23 12:40:16.268: INFO: Waiting up to 15m0s for pod "dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836" in namespace "dns-8774" to be "running"
Apr 23 12:40:16.278: INFO: Pod "dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836": Phase="Pending", Reason="", readiness=false. Elapsed: 9.969839ms
Apr 23 12:40:18.287: INFO: Pod "dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836": Phase="Running", Reason="", readiness=true. Elapsed: 2.018967206s
Apr 23 12:40:18.288: INFO: Pod "dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836" satisfied condition "running"
STEP: retrieving the pod 04/23/23 12:40:18.288
STEP: looking for the results for each expected name from probers 04/23/23 12:40:18.294
Apr 23 12:40:18.305: INFO: File wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 23 12:40:18.315: INFO: File jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains '' instead of 'bar.example.com.'
Apr 23 12:40:18.315: INFO: Lookups using dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 failed for: [wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local]

Apr 23 12:40:23.324: INFO: File wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 23 12:40:23.330: INFO: File jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 23 12:40:23.330: INFO: Lookups using dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 failed for: [wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local]

Apr 23 12:40:28.331: INFO: File wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains '' instead of 'bar.example.com.'
Apr 23 12:40:28.347: INFO: File jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 23 12:40:28.347: INFO: Lookups using dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 failed for: [wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local]

Apr 23 12:40:33.329: INFO: File wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 23 12:40:33.335: INFO: File jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 23 12:40:33.335: INFO: Lookups using dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 failed for: [wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local]

Apr 23 12:40:38.332: INFO: File wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 23 12:40:38.340: INFO: File jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 23 12:40:38.340: INFO: Lookups using dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 failed for: [wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local]

Apr 23 12:40:43.331: INFO: File wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 23 12:40:43.341: INFO: File jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 23 12:40:43.341: INFO: Lookups using dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 failed for: [wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local]

Apr 23 12:40:48.331: INFO: DNS probes using dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 succeeded

STEP: deleting the pod 04/23/23 12:40:48.331
STEP: changing the service to type=ClusterIP 04/23/23 12:40:48.359
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8774.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local; sleep 1; done
 04/23/23 12:40:48.42
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8774.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local; sleep 1; done
 04/23/23 12:40:48.421
STEP: creating a third pod to probe DNS 04/23/23 12:40:48.421
STEP: submitting the pod to kubernetes 04/23/23 12:40:48.441
Apr 23 12:40:48.640: INFO: Waiting up to 15m0s for pod "dns-test-76453f11-722e-4342-aa94-d485af71a583" in namespace "dns-8774" to be "running"
Apr 23 12:40:48.648: INFO: Pod "dns-test-76453f11-722e-4342-aa94-d485af71a583": Phase="Pending", Reason="", readiness=false. Elapsed: 7.678441ms
Apr 23 12:40:50.657: INFO: Pod "dns-test-76453f11-722e-4342-aa94-d485af71a583": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01659582s
Apr 23 12:40:52.660: INFO: Pod "dns-test-76453f11-722e-4342-aa94-d485af71a583": Phase="Running", Reason="", readiness=true. Elapsed: 4.020032124s
Apr 23 12:40:52.661: INFO: Pod "dns-test-76453f11-722e-4342-aa94-d485af71a583" satisfied condition "running"
STEP: retrieving the pod 04/23/23 12:40:52.661
STEP: looking for the results for each expected name from probers 04/23/23 12:40:52.666
Apr 23 12:40:52.689: INFO: DNS probes using dns-test-76453f11-722e-4342-aa94-d485af71a583 succeeded

STEP: deleting the pod 04/23/23 12:40:52.689
STEP: deleting the test externalName service 04/23/23 12:40:52.722
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Apr 23 12:40:52.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-8774" for this suite. 04/23/23 12:40:52.788
------------------------------
â€¢ [SLOW TEST] [40.718 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:40:12.086
    Apr 23 12:40:12.086: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename dns 04/23/23 12:40:12.088
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:40:12.113
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:40:12.117
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 04/23/23 12:40:12.121
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8774.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local; sleep 1; done
     04/23/23 12:40:12.134
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8774.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local; sleep 1; done
     04/23/23 12:40:12.136
    STEP: creating a pod to probe DNS 04/23/23 12:40:12.136
    STEP: submitting the pod to kubernetes 04/23/23 12:40:12.137
    Apr 23 12:40:12.157: INFO: Waiting up to 15m0s for pod "dns-test-d7a8bab1-5c91-4f1e-b92d-cce65f46a745" in namespace "dns-8774" to be "running"
    Apr 23 12:40:12.175: INFO: Pod "dns-test-d7a8bab1-5c91-4f1e-b92d-cce65f46a745": Phase="Pending", Reason="", readiness=false. Elapsed: 18.495898ms
    Apr 23 12:40:14.187: INFO: Pod "dns-test-d7a8bab1-5c91-4f1e-b92d-cce65f46a745": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029722885s
    Apr 23 12:40:16.183: INFO: Pod "dns-test-d7a8bab1-5c91-4f1e-b92d-cce65f46a745": Phase="Running", Reason="", readiness=true. Elapsed: 4.026036182s
    Apr 23 12:40:16.183: INFO: Pod "dns-test-d7a8bab1-5c91-4f1e-b92d-cce65f46a745" satisfied condition "running"
    STEP: retrieving the pod 04/23/23 12:40:16.183
    STEP: looking for the results for each expected name from probers 04/23/23 12:40:16.189
    Apr 23 12:40:16.210: INFO: DNS probes using dns-test-d7a8bab1-5c91-4f1e-b92d-cce65f46a745 succeeded

    STEP: deleting the pod 04/23/23 12:40:16.21
    STEP: changing the externalName to bar.example.com 04/23/23 12:40:16.238
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8774.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local; sleep 1; done
     04/23/23 12:40:16.255
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8774.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local; sleep 1; done
     04/23/23 12:40:16.255
    STEP: creating a second pod to probe DNS 04/23/23 12:40:16.255
    STEP: submitting the pod to kubernetes 04/23/23 12:40:16.255
    Apr 23 12:40:16.268: INFO: Waiting up to 15m0s for pod "dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836" in namespace "dns-8774" to be "running"
    Apr 23 12:40:16.278: INFO: Pod "dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836": Phase="Pending", Reason="", readiness=false. Elapsed: 9.969839ms
    Apr 23 12:40:18.287: INFO: Pod "dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836": Phase="Running", Reason="", readiness=true. Elapsed: 2.018967206s
    Apr 23 12:40:18.288: INFO: Pod "dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836" satisfied condition "running"
    STEP: retrieving the pod 04/23/23 12:40:18.288
    STEP: looking for the results for each expected name from probers 04/23/23 12:40:18.294
    Apr 23 12:40:18.305: INFO: File wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 23 12:40:18.315: INFO: File jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains '' instead of 'bar.example.com.'
    Apr 23 12:40:18.315: INFO: Lookups using dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 failed for: [wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local]

    Apr 23 12:40:23.324: INFO: File wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 23 12:40:23.330: INFO: File jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 23 12:40:23.330: INFO: Lookups using dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 failed for: [wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local]

    Apr 23 12:40:28.331: INFO: File wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains '' instead of 'bar.example.com.'
    Apr 23 12:40:28.347: INFO: File jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 23 12:40:28.347: INFO: Lookups using dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 failed for: [wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local]

    Apr 23 12:40:33.329: INFO: File wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 23 12:40:33.335: INFO: File jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 23 12:40:33.335: INFO: Lookups using dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 failed for: [wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local]

    Apr 23 12:40:38.332: INFO: File wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 23 12:40:38.340: INFO: File jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 23 12:40:38.340: INFO: Lookups using dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 failed for: [wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local]

    Apr 23 12:40:43.331: INFO: File wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 23 12:40:43.341: INFO: File jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local from pod  dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 23 12:40:43.341: INFO: Lookups using dns-8774/dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 failed for: [wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local]

    Apr 23 12:40:48.331: INFO: DNS probes using dns-test-7095c4fd-d82d-41de-ab23-57d19a56e836 succeeded

    STEP: deleting the pod 04/23/23 12:40:48.331
    STEP: changing the service to type=ClusterIP 04/23/23 12:40:48.359
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8774.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8774.svc.cluster.local; sleep 1; done
     04/23/23 12:40:48.42
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8774.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8774.svc.cluster.local; sleep 1; done
     04/23/23 12:40:48.421
    STEP: creating a third pod to probe DNS 04/23/23 12:40:48.421
    STEP: submitting the pod to kubernetes 04/23/23 12:40:48.441
    Apr 23 12:40:48.640: INFO: Waiting up to 15m0s for pod "dns-test-76453f11-722e-4342-aa94-d485af71a583" in namespace "dns-8774" to be "running"
    Apr 23 12:40:48.648: INFO: Pod "dns-test-76453f11-722e-4342-aa94-d485af71a583": Phase="Pending", Reason="", readiness=false. Elapsed: 7.678441ms
    Apr 23 12:40:50.657: INFO: Pod "dns-test-76453f11-722e-4342-aa94-d485af71a583": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01659582s
    Apr 23 12:40:52.660: INFO: Pod "dns-test-76453f11-722e-4342-aa94-d485af71a583": Phase="Running", Reason="", readiness=true. Elapsed: 4.020032124s
    Apr 23 12:40:52.661: INFO: Pod "dns-test-76453f11-722e-4342-aa94-d485af71a583" satisfied condition "running"
    STEP: retrieving the pod 04/23/23 12:40:52.661
    STEP: looking for the results for each expected name from probers 04/23/23 12:40:52.666
    Apr 23 12:40:52.689: INFO: DNS probes using dns-test-76453f11-722e-4342-aa94-d485af71a583 succeeded

    STEP: deleting the pod 04/23/23 12:40:52.689
    STEP: deleting the test externalName service 04/23/23 12:40:52.722
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:40:52.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-8774" for this suite. 04/23/23 12:40:52.788
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:276
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:40:52.807
Apr 23 12:40:52.807: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 12:40:52.814
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:40:52.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:40:52.862
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:276
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 04/23/23 12:40:52.869
Apr 23 12:40:52.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:40:55.472: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:41:06.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-publish-openapi-3821" for this suite. 04/23/23 12:41:06.044
------------------------------
â€¢ [SLOW TEST] [13.251 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:40:52.807
    Apr 23 12:40:52.807: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename crd-publish-openapi 04/23/23 12:40:52.814
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:40:52.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:40:52.862
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:276
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 04/23/23 12:40:52.869
    Apr 23 12:40:52.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:40:55.472: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:41:06.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-publish-openapi-3821" for this suite. 04/23/23 12:41:06.044
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:41:06.064
Apr 23 12:41:06.064: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubelet-test 04/23/23 12:41:06.067
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:41:06.103
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:41:06.108
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 04/23/23 12:41:06.143
Apr 23 12:41:06.143: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasesd30ccb8f-dc05-4bfd-af27-2b9d9b88904e" in namespace "kubelet-test-5130" to be "completed"
Apr 23 12:41:06.160: INFO: Pod "agnhost-host-aliasesd30ccb8f-dc05-4bfd-af27-2b9d9b88904e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.827698ms
Apr 23 12:41:08.170: INFO: Pod "agnhost-host-aliasesd30ccb8f-dc05-4bfd-af27-2b9d9b88904e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02705307s
Apr 23 12:41:10.169: INFO: Pod "agnhost-host-aliasesd30ccb8f-dc05-4bfd-af27-2b9d9b88904e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025944764s
Apr 23 12:41:12.169: INFO: Pod "agnhost-host-aliasesd30ccb8f-dc05-4bfd-af27-2b9d9b88904e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025544473s
Apr 23 12:41:12.169: INFO: Pod "agnhost-host-aliasesd30ccb8f-dc05-4bfd-af27-2b9d9b88904e" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/node/init/init.go:32
Apr 23 12:41:12.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Kubelet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Kubelet
  tear down framework | framework.go:193
STEP: Destroying namespace "kubelet-test-5130" for this suite. 04/23/23 12:41:12.211
------------------------------
â€¢ [SLOW TEST] [6.159 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:41:06.064
    Apr 23 12:41:06.064: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubelet-test 04/23/23 12:41:06.067
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:41:06.103
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:41:06.108
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 04/23/23 12:41:06.143
    Apr 23 12:41:06.143: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasesd30ccb8f-dc05-4bfd-af27-2b9d9b88904e" in namespace "kubelet-test-5130" to be "completed"
    Apr 23 12:41:06.160: INFO: Pod "agnhost-host-aliasesd30ccb8f-dc05-4bfd-af27-2b9d9b88904e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.827698ms
    Apr 23 12:41:08.170: INFO: Pod "agnhost-host-aliasesd30ccb8f-dc05-4bfd-af27-2b9d9b88904e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02705307s
    Apr 23 12:41:10.169: INFO: Pod "agnhost-host-aliasesd30ccb8f-dc05-4bfd-af27-2b9d9b88904e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025944764s
    Apr 23 12:41:12.169: INFO: Pod "agnhost-host-aliasesd30ccb8f-dc05-4bfd-af27-2b9d9b88904e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025544473s
    Apr 23 12:41:12.169: INFO: Pod "agnhost-host-aliasesd30ccb8f-dc05-4bfd-af27-2b9d9b88904e" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:41:12.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Kubelet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Kubelet
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubelet-test-5130" for this suite. 04/23/23 12:41:12.211
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:334
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:41:12.224
Apr 23 12:41:12.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename init-container 04/23/23 12:41:12.233
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:41:12.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:41:12.276
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:165
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:334
STEP: creating the pod 04/23/23 12:41:12.282
Apr 23 12:41:12.283: INFO: PodSpec: initContainers in spec.initContainers
Apr 23 12:41:58.326: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-2e3fbe60-200d-4023-a5b0-109b801b8edd", GenerateName:"", Namespace:"init-container-6320", SelfLink:"", UID:"1186dbb5-c91d-4118-92cb-c19b8cc9dd0b", ResourceVersion:"36749", Generation:0, CreationTimestamp:time.Date(2023, time.April, 23, 12, 41, 12, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"282994804"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 23, 12, 41, 12, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d0b8a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 23, 12, 41, 58, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d0b8f0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-x7f59", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0010cf100), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-x7f59", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-x7f59", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-x7f59", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00396c990), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"eingavuivie7-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00461b570), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00396ca20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00396ca40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00396ca48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00396ca4c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc001300fc0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 23, 12, 41, 12, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 23, 12, 41, 12, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 23, 12, 41, 12, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 23, 12, 41, 12, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.121.198", PodIP:"10.233.64.218", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.64.218"}}, StartTime:time.Date(2023, time.April, 23, 12, 41, 12, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00461b650)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00461b6c0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:2e0f836850e09b8b7cc937681d6194537a09fbd5f6b9e08f4d646a85128e8937", ContainerID:"cri-o://e3fd76a9b32dfe0dd1f830255960f01766212ecfbd439afd150a50b526a93cf3", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0010cf1c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0010cf1a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc00396cad4)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:41:58.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  tear down framework | framework.go:193
STEP: Destroying namespace "init-container-6320" for this suite. 04/23/23 12:41:58.35
------------------------------
â€¢ [SLOW TEST] [46.148 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:41:12.224
    Apr 23 12:41:12.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename init-container 04/23/23 12:41:12.233
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:41:12.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:41:12.276
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:165
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:334
    STEP: creating the pod 04/23/23 12:41:12.282
    Apr 23 12:41:12.283: INFO: PodSpec: initContainers in spec.initContainers
    Apr 23 12:41:58.326: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-2e3fbe60-200d-4023-a5b0-109b801b8edd", GenerateName:"", Namespace:"init-container-6320", SelfLink:"", UID:"1186dbb5-c91d-4118-92cb-c19b8cc9dd0b", ResourceVersion:"36749", Generation:0, CreationTimestamp:time.Date(2023, time.April, 23, 12, 41, 12, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"282994804"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 23, 12, 41, 12, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d0b8a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 23, 12, 41, 58, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000d0b8f0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-x7f59", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0010cf100), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-x7f59", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-x7f59", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-x7f59", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00396c990), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"eingavuivie7-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00461b570), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00396ca20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00396ca40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00396ca48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00396ca4c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc001300fc0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 23, 12, 41, 12, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 23, 12, 41, 12, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 23, 12, 41, 12, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 23, 12, 41, 12, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.121.198", PodIP:"10.233.64.218", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.64.218"}}, StartTime:time.Date(2023, time.April, 23, 12, 41, 12, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00461b650)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00461b6c0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:2e0f836850e09b8b7cc937681d6194537a09fbd5f6b9e08f4d646a85128e8937", ContainerID:"cri-o://e3fd76a9b32dfe0dd1f830255960f01766212ecfbd439afd150a50b526a93cf3", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0010cf1c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0010cf1a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc00396cad4)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:41:58.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      tear down framework | framework.go:193
    STEP: Destroying namespace "init-container-6320" for this suite. 04/23/23 12:41:58.35
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:341
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:41:58.375
Apr 23 12:41:58.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 12:41:58.382
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:41:58.415
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:41:58.421
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 12:41:58.469
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:41:59.106
STEP: Deploying the webhook pod 04/23/23 12:41:59.121
STEP: Wait for the deployment to be ready 04/23/23 12:41:59.141
Apr 23 12:41:59.162: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 23 12:42:01.186: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 41, 59, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 41, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 41, 59, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 41, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/23/23 12:42:03.195
STEP: Verifying the service has paired with the endpoint 04/23/23 12:42:03.218
Apr 23 12:42:04.219: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:341
Apr 23 12:42:04.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9000-crds.webhook.example.com via the AdmissionRegistration API 04/23/23 12:42:04.78
STEP: Creating a custom resource that should be mutated by the webhook 04/23/23 12:42:04.814
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:42:07.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-4944" for this suite. 04/23/23 12:42:07.699
STEP: Destroying namespace "webhook-4944-markers" for this suite. 04/23/23 12:42:07.717
------------------------------
â€¢ [SLOW TEST] [9.379 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:341

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:41:58.375
    Apr 23 12:41:58.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 12:41:58.382
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:41:58.415
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:41:58.421
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 12:41:58.469
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:41:59.106
    STEP: Deploying the webhook pod 04/23/23 12:41:59.121
    STEP: Wait for the deployment to be ready 04/23/23 12:41:59.141
    Apr 23 12:41:59.162: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 23 12:42:01.186: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 41, 59, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 41, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 41, 59, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 41, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/23/23 12:42:03.195
    STEP: Verifying the service has paired with the endpoint 04/23/23 12:42:03.218
    Apr 23 12:42:04.219: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:341
    Apr 23 12:42:04.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9000-crds.webhook.example.com via the AdmissionRegistration API 04/23/23 12:42:04.78
    STEP: Creating a custom resource that should be mutated by the webhook 04/23/23 12:42:04.814
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:42:07.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-4944" for this suite. 04/23/23 12:42:07.699
    STEP: Destroying namespace "webhook-4944-markers" for this suite. 04/23/23 12:42:07.717
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:42:07.768
Apr 23 12:42:07.769: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename deployment 04/23/23 12:42:07.771
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:42:07.849
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:42:07.86
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Apr 23 12:42:07.872: INFO: Creating deployment "test-recreate-deployment"
Apr 23 12:42:07.883: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 23 12:42:07.920: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr 23 12:42:09.933: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 23 12:42:09.941: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 42, 7, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 42, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 42, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 42, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-795566c5cb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:42:11.949: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 23 12:42:11.970: INFO: Updating deployment test-recreate-deployment
Apr 23 12:42:11.970: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 23 12:42:12.172: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-8250  f145ff2e-759e-49f7-b339-0bb366743381 36907 2 2023-04-23 12:42:07 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-23 12:42:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:42:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b47ba8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-23 12:42:12 +0000 UTC,LastTransitionTime:2023-04-23 12:42:12 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-cff6dc657" is progressing.,LastUpdateTime:2023-04-23 12:42:12 +0000 UTC,LastTransitionTime:2023-04-23 12:42:07 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Apr 23 12:42:12.183: INFO: New ReplicaSet "test-recreate-deployment-cff6dc657" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-cff6dc657  deployment-8250  2067920f-6668-4dab-ad88-0e7bf5230e9d 36905 1 2023-04-23 12:42:12 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cff6dc657] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment f145ff2e-759e-49f7-b339-0bb366743381 0xc003d892f0 0xc003d892f1}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:42:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f145ff2e-759e-49f7-b339-0bb366743381\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:42:12 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: cff6dc657,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cff6dc657] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d89388 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 23 12:42:12.183: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 23 12:42:12.183: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-795566c5cb  deployment-8250  18ea98e9-1820-4abf-9bdc-8c557df91bb1 36894 2 2023-04-23 12:42:07 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:795566c5cb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment f145ff2e-759e-49f7-b339-0bb366743381 0xc003d891d7 0xc003d891d8}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:42:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f145ff2e-759e-49f7-b339-0bb366743381\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:42:12 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 795566c5cb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:795566c5cb] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d89288 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 23 12:42:12.192: INFO: Pod "test-recreate-deployment-cff6dc657-zn4st" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-cff6dc657-zn4st test-recreate-deployment-cff6dc657- deployment-8250  f834bca3-6dd9-4c13-8a07-4c16b83809e9 36906 0 2023-04-23 12:42:12 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cff6dc657] map[] [{apps/v1 ReplicaSet test-recreate-deployment-cff6dc657 2067920f-6668-4dab-ad88-0e7bf5230e9d 0xc003d89c00 0xc003d89c01}] [] [{kube-controller-manager Update v1 2023-04-23 12:42:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2067920f-6668-4dab-ad88-0e7bf5230e9d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:42:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m7b96,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m7b96,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:42:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:42:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:42:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:42:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:,StartTime:2023-04-23 12:42:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Apr 23 12:42:12.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-8250" for this suite. 04/23/23 12:42:12.203
------------------------------
â€¢ [4.454 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:42:07.768
    Apr 23 12:42:07.769: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename deployment 04/23/23 12:42:07.771
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:42:07.849
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:42:07.86
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Apr 23 12:42:07.872: INFO: Creating deployment "test-recreate-deployment"
    Apr 23 12:42:07.883: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Apr 23 12:42:07.920: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Apr 23 12:42:09.933: INFO: Waiting deployment "test-recreate-deployment" to complete
    Apr 23 12:42:09.941: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 42, 7, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 42, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 42, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 42, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-795566c5cb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:42:11.949: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Apr 23 12:42:11.970: INFO: Updating deployment test-recreate-deployment
    Apr 23 12:42:11.970: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 23 12:42:12.172: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-8250  f145ff2e-759e-49f7-b339-0bb366743381 36907 2 2023-04-23 12:42:07 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-23 12:42:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:42:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b47ba8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-23 12:42:12 +0000 UTC,LastTransitionTime:2023-04-23 12:42:12 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-cff6dc657" is progressing.,LastUpdateTime:2023-04-23 12:42:12 +0000 UTC,LastTransitionTime:2023-04-23 12:42:07 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Apr 23 12:42:12.183: INFO: New ReplicaSet "test-recreate-deployment-cff6dc657" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-cff6dc657  deployment-8250  2067920f-6668-4dab-ad88-0e7bf5230e9d 36905 1 2023-04-23 12:42:12 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cff6dc657] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment f145ff2e-759e-49f7-b339-0bb366743381 0xc003d892f0 0xc003d892f1}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:42:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f145ff2e-759e-49f7-b339-0bb366743381\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:42:12 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: cff6dc657,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cff6dc657] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d89388 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 23 12:42:12.183: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Apr 23 12:42:12.183: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-795566c5cb  deployment-8250  18ea98e9-1820-4abf-9bdc-8c557df91bb1 36894 2 2023-04-23 12:42:07 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:795566c5cb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment f145ff2e-759e-49f7-b339-0bb366743381 0xc003d891d7 0xc003d891d8}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:42:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f145ff2e-759e-49f7-b339-0bb366743381\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:42:12 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 795566c5cb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:795566c5cb] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d89288 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 23 12:42:12.192: INFO: Pod "test-recreate-deployment-cff6dc657-zn4st" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-cff6dc657-zn4st test-recreate-deployment-cff6dc657- deployment-8250  f834bca3-6dd9-4c13-8a07-4c16b83809e9 36906 0 2023-04-23 12:42:12 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cff6dc657] map[] [{apps/v1 ReplicaSet test-recreate-deployment-cff6dc657 2067920f-6668-4dab-ad88-0e7bf5230e9d 0xc003d89c00 0xc003d89c01}] [] [{kube-controller-manager Update v1 2023-04-23 12:42:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2067920f-6668-4dab-ad88-0e7bf5230e9d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:42:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m7b96,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m7b96,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:42:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:42:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:42:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:42:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:,StartTime:2023-04-23 12:42:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:42:12.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-8250" for this suite. 04/23/23 12:42:12.203
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:47
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:42:12.223
Apr 23 12:42:12.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 12:42:12.233
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:42:12.266
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:42:12.271
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:47
STEP: Creating configMap with name configmap-test-volume-557d1c1c-d508-4419-b53c-ee10c460e15a 04/23/23 12:42:12.279
STEP: Creating a pod to test consume configMaps 04/23/23 12:42:12.287
Apr 23 12:42:12.303: INFO: Waiting up to 5m0s for pod "pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642" in namespace "configmap-1923" to be "Succeeded or Failed"
Apr 23 12:42:12.311: INFO: Pod "pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642": Phase="Pending", Reason="", readiness=false. Elapsed: 8.005659ms
Apr 23 12:42:14.319: INFO: Pod "pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642": Phase="Running", Reason="", readiness=true. Elapsed: 2.016016051s
Apr 23 12:42:16.319: INFO: Pod "pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642": Phase="Running", Reason="", readiness=false. Elapsed: 4.015204776s
Apr 23 12:42:18.320: INFO: Pod "pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016784098s
STEP: Saw pod success 04/23/23 12:42:18.32
Apr 23 12:42:18.321: INFO: Pod "pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642" satisfied condition "Succeeded or Failed"
Apr 23 12:42:18.329: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642 container agnhost-container: <nil>
STEP: delete the pod 04/23/23 12:42:18.347
Apr 23 12:42:18.374: INFO: Waiting for pod pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642 to disappear
Apr 23 12:42:18.380: INFO: Pod pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 12:42:18.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-1923" for this suite. 04/23/23 12:42:18.39
------------------------------
â€¢ [SLOW TEST] [6.179 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:47

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:42:12.223
    Apr 23 12:42:12.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 12:42:12.233
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:42:12.266
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:42:12.271
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:47
    STEP: Creating configMap with name configmap-test-volume-557d1c1c-d508-4419-b53c-ee10c460e15a 04/23/23 12:42:12.279
    STEP: Creating a pod to test consume configMaps 04/23/23 12:42:12.287
    Apr 23 12:42:12.303: INFO: Waiting up to 5m0s for pod "pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642" in namespace "configmap-1923" to be "Succeeded or Failed"
    Apr 23 12:42:12.311: INFO: Pod "pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642": Phase="Pending", Reason="", readiness=false. Elapsed: 8.005659ms
    Apr 23 12:42:14.319: INFO: Pod "pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642": Phase="Running", Reason="", readiness=true. Elapsed: 2.016016051s
    Apr 23 12:42:16.319: INFO: Pod "pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642": Phase="Running", Reason="", readiness=false. Elapsed: 4.015204776s
    Apr 23 12:42:18.320: INFO: Pod "pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016784098s
    STEP: Saw pod success 04/23/23 12:42:18.32
    Apr 23 12:42:18.321: INFO: Pod "pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642" satisfied condition "Succeeded or Failed"
    Apr 23 12:42:18.329: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642 container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 12:42:18.347
    Apr 23 12:42:18.374: INFO: Waiting for pod pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642 to disappear
    Apr 23 12:42:18.380: INFO: Pod pod-configmaps-d1e95d75-e3e9-4d5b-ba1e-53bcdaa37642 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:42:18.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-1923" for this suite. 04/23/23 12:42:18.39
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:101
[BeforeEach] [sig-apps] ReplicationController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:42:18.406
Apr 23 12:42:18.407: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename replication-controller 04/23/23 12:42:18.412
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:42:18.439
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:42:18.444
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:57
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:101
STEP: Given a ReplicationController is created 04/23/23 12:42:18.448
STEP: When the matched label of one of its pods change 04/23/23 12:42:18.457
Apr 23 12:42:18.462: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 23 12:42:23.511: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 04/23/23 12:42:23.539
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/node/init/init.go:32
Apr 23 12:42:23.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicationController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicationController
  tear down framework | framework.go:193
STEP: Destroying namespace "replication-controller-4457" for this suite. 04/23/23 12:42:23.566
------------------------------
â€¢ [SLOW TEST] [5.175 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:42:18.406
    Apr 23 12:42:18.407: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename replication-controller 04/23/23 12:42:18.412
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:42:18.439
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:42:18.444
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:57
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:101
    STEP: Given a ReplicationController is created 04/23/23 12:42:18.448
    STEP: When the matched label of one of its pods change 04/23/23 12:42:18.457
    Apr 23 12:42:18.462: INFO: Pod name pod-release: Found 0 pods out of 1
    Apr 23 12:42:23.511: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 04/23/23 12:42:23.539
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:42:23.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      tear down framework | framework.go:193
    STEP: Destroying namespace "replication-controller-4457" for this suite. 04/23/23 12:42:23.566
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:109
[BeforeEach] [sig-storage] Projected configMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:42:23.582
Apr 23 12:42:23.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 12:42:23.585
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:42:23.632
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:42:23.637
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:109
STEP: Creating configMap with name projected-configmap-test-volume-map-d0538914-8910-4f79-a095-596745eb926f 04/23/23 12:42:23.643
STEP: Creating a pod to test consume configMaps 04/23/23 12:42:23.651
Apr 23 12:42:23.668: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df" in namespace "projected-7610" to be "Succeeded or Failed"
Apr 23 12:42:23.676: INFO: Pod "pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df": Phase="Pending", Reason="", readiness=false. Elapsed: 7.306663ms
Apr 23 12:42:25.683: INFO: Pod "pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014003048s
Apr 23 12:42:27.684: INFO: Pod "pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015699181s
Apr 23 12:42:29.683: INFO: Pod "pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014781921s
STEP: Saw pod success 04/23/23 12:42:29.683
Apr 23 12:42:29.684: INFO: Pod "pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df" satisfied condition "Succeeded or Failed"
Apr 23 12:42:29.692: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df container agnhost-container: <nil>
STEP: delete the pod 04/23/23 12:42:29.79
Apr 23 12:42:29.819: INFO: Waiting for pod pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df to disappear
Apr 23 12:42:29.830: INFO: Pod pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/node/init/init.go:32
Apr 23 12:42:29.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected configMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected configMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected configMap
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-7610" for this suite. 04/23/23 12:42:29.841
------------------------------
â€¢ [SLOW TEST] [6.279 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:42:23.582
    Apr 23 12:42:23.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 12:42:23.585
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:42:23.632
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:42:23.637
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:109
    STEP: Creating configMap with name projected-configmap-test-volume-map-d0538914-8910-4f79-a095-596745eb926f 04/23/23 12:42:23.643
    STEP: Creating a pod to test consume configMaps 04/23/23 12:42:23.651
    Apr 23 12:42:23.668: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df" in namespace "projected-7610" to be "Succeeded or Failed"
    Apr 23 12:42:23.676: INFO: Pod "pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df": Phase="Pending", Reason="", readiness=false. Elapsed: 7.306663ms
    Apr 23 12:42:25.683: INFO: Pod "pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014003048s
    Apr 23 12:42:27.684: INFO: Pod "pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015699181s
    Apr 23 12:42:29.683: INFO: Pod "pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014781921s
    STEP: Saw pod success 04/23/23 12:42:29.683
    Apr 23 12:42:29.684: INFO: Pod "pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df" satisfied condition "Succeeded or Failed"
    Apr 23 12:42:29.692: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 12:42:29.79
    Apr 23 12:42:29.819: INFO: Waiting for pod pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df to disappear
    Apr 23 12:42:29.830: INFO: Pod pod-projected-configmaps-877750dd-1c86-4412-a47e-d5742b9677df no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:42:29.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected configMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-7610" for this suite. 04/23/23 12:42:29.841
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:42:29.864
Apr 23 12:42:29.864: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename gc 04/23/23 12:42:29.869
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:42:29.91
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:42:29.915
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:31
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 04/23/23 12:42:29.934
STEP: delete the rc 04/23/23 12:42:34.961
STEP: wait for the rc to be deleted 04/23/23 12:42:35.121
Apr 23 12:42:36.963: INFO: 89 pods remaining
Apr 23 12:42:36.963: INFO: 81 pods has nil DeletionTimestamp
Apr 23 12:42:36.963: INFO: 
Apr 23 12:42:37.832: INFO: 80 pods remaining
Apr 23 12:42:37.832: INFO: 73 pods has nil DeletionTimestamp
Apr 23 12:42:37.832: INFO: 
Apr 23 12:42:39.019: INFO: 75 pods remaining
Apr 23 12:42:39.019: INFO: 61 pods has nil DeletionTimestamp
Apr 23 12:42:39.019: INFO: 
Apr 23 12:42:39.553: INFO: 62 pods remaining
Apr 23 12:42:39.553: INFO: 47 pods has nil DeletionTimestamp
Apr 23 12:42:39.553: INFO: 
Apr 23 12:42:40.627: INFO: 56 pods remaining
Apr 23 12:42:40.627: INFO: 39 pods has nil DeletionTimestamp
Apr 23 12:42:40.627: INFO: 
Apr 23 12:42:41.581: INFO: 43 pods remaining
Apr 23 12:42:41.581: INFO: 18 pods has nil DeletionTimestamp
Apr 23 12:42:41.581: INFO: 
Apr 23 12:42:42.694: INFO: 33 pods remaining
Apr 23 12:42:42.694: INFO: 3 pods has nil DeletionTimestamp
Apr 23 12:42:42.694: INFO: 
Apr 23 12:42:44.034: INFO: 24 pods remaining
Apr 23 12:42:44.034: INFO: 0 pods has nil DeletionTimestamp
Apr 23 12:42:44.034: INFO: 
Apr 23 12:42:44.926: INFO: 19 pods remaining
Apr 23 12:42:44.926: INFO: 0 pods has nil DeletionTimestamp
Apr 23 12:42:44.926: INFO: 
Apr 23 12:42:45.235: INFO: 14 pods remaining
Apr 23 12:42:45.235: INFO: 0 pods has nil DeletionTimestamp
Apr 23 12:42:45.236: INFO: 
Apr 23 12:42:46.316: INFO: 9 pods remaining
Apr 23 12:42:46.316: INFO: 0 pods has nil DeletionTimestamp
Apr 23 12:42:46.316: INFO: 
Apr 23 12:42:47.426: INFO: 1 pods remaining
Apr 23 12:42:47.426: INFO: 0 pods has nil DeletionTimestamp
Apr 23 12:42:47.427: INFO: 
STEP: Gathering metrics 04/23/23 12:42:48.212
Apr 23 12:42:48.452: INFO: Waiting up to 5m0s for pod "kube-controller-manager-eingavuivie7-2" in namespace "kube-system" to be "running and ready"
Apr 23 12:42:48.493: INFO: Pod "kube-controller-manager-eingavuivie7-2": Phase="Running", Reason="", readiness=true. Elapsed: 40.792582ms
Apr 23 12:42:48.493: INFO: The phase of Pod kube-controller-manager-eingavuivie7-2 is Running (Ready = true)
Apr 23 12:42:48.493: INFO: Pod "kube-controller-manager-eingavuivie7-2" satisfied condition "running and ready"
Apr 23 12:42:49.199: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/node/init/init.go:32
Apr 23 12:42:49.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  tear down framework | framework.go:193
STEP: Destroying namespace "gc-2402" for this suite. 04/23/23 12:42:49.225
------------------------------
â€¢ [SLOW TEST] [19.489 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:42:29.864
    Apr 23 12:42:29.864: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename gc 04/23/23 12:42:29.869
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:42:29.91
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:42:29.915
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:31
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 04/23/23 12:42:29.934
    STEP: delete the rc 04/23/23 12:42:34.961
    STEP: wait for the rc to be deleted 04/23/23 12:42:35.121
    Apr 23 12:42:36.963: INFO: 89 pods remaining
    Apr 23 12:42:36.963: INFO: 81 pods has nil DeletionTimestamp
    Apr 23 12:42:36.963: INFO: 
    Apr 23 12:42:37.832: INFO: 80 pods remaining
    Apr 23 12:42:37.832: INFO: 73 pods has nil DeletionTimestamp
    Apr 23 12:42:37.832: INFO: 
    Apr 23 12:42:39.019: INFO: 75 pods remaining
    Apr 23 12:42:39.019: INFO: 61 pods has nil DeletionTimestamp
    Apr 23 12:42:39.019: INFO: 
    Apr 23 12:42:39.553: INFO: 62 pods remaining
    Apr 23 12:42:39.553: INFO: 47 pods has nil DeletionTimestamp
    Apr 23 12:42:39.553: INFO: 
    Apr 23 12:42:40.627: INFO: 56 pods remaining
    Apr 23 12:42:40.627: INFO: 39 pods has nil DeletionTimestamp
    Apr 23 12:42:40.627: INFO: 
    Apr 23 12:42:41.581: INFO: 43 pods remaining
    Apr 23 12:42:41.581: INFO: 18 pods has nil DeletionTimestamp
    Apr 23 12:42:41.581: INFO: 
    Apr 23 12:42:42.694: INFO: 33 pods remaining
    Apr 23 12:42:42.694: INFO: 3 pods has nil DeletionTimestamp
    Apr 23 12:42:42.694: INFO: 
    Apr 23 12:42:44.034: INFO: 24 pods remaining
    Apr 23 12:42:44.034: INFO: 0 pods has nil DeletionTimestamp
    Apr 23 12:42:44.034: INFO: 
    Apr 23 12:42:44.926: INFO: 19 pods remaining
    Apr 23 12:42:44.926: INFO: 0 pods has nil DeletionTimestamp
    Apr 23 12:42:44.926: INFO: 
    Apr 23 12:42:45.235: INFO: 14 pods remaining
    Apr 23 12:42:45.235: INFO: 0 pods has nil DeletionTimestamp
    Apr 23 12:42:45.236: INFO: 
    Apr 23 12:42:46.316: INFO: 9 pods remaining
    Apr 23 12:42:46.316: INFO: 0 pods has nil DeletionTimestamp
    Apr 23 12:42:46.316: INFO: 
    Apr 23 12:42:47.426: INFO: 1 pods remaining
    Apr 23 12:42:47.426: INFO: 0 pods has nil DeletionTimestamp
    Apr 23 12:42:47.427: INFO: 
    STEP: Gathering metrics 04/23/23 12:42:48.212
    Apr 23 12:42:48.452: INFO: Waiting up to 5m0s for pod "kube-controller-manager-eingavuivie7-2" in namespace "kube-system" to be "running and ready"
    Apr 23 12:42:48.493: INFO: Pod "kube-controller-manager-eingavuivie7-2": Phase="Running", Reason="", readiness=true. Elapsed: 40.792582ms
    Apr 23 12:42:48.493: INFO: The phase of Pod kube-controller-manager-eingavuivie7-2 is Running (Ready = true)
    Apr 23 12:42:48.493: INFO: Pod "kube-controller-manager-eingavuivie7-2" satisfied condition "running and ready"
    Apr 23 12:42:49.199: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:42:49.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      tear down framework | framework.go:193
    STEP: Destroying namespace "gc-2402" for this suite. 04/23/23 12:42:49.225
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:42:49.367
Apr 23 12:42:49.368: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename hostport 04/23/23 12:42:49.398
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:42:49.751
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:42:49.756
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 04/23/23 12:42:49.9
Apr 23 12:42:49.937: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-6392" to be "running and ready"
Apr 23 12:42:49.956: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.004346ms
Apr 23 12:42:49.956: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:42:52.009: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071717847s
Apr 23 12:42:52.009: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:42:53.974: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036198497s
Apr 23 12:42:53.974: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:42:56.348: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.410736584s
Apr 23 12:42:56.348: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:42:57.989: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.05113217s
Apr 23 12:42:57.989: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:42:59.979: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.041984572s
Apr 23 12:42:59.980: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:43:01.967: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.029572961s
Apr 23 12:43:01.967: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:43:03.993: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 14.055415962s
Apr 23 12:43:03.993: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 23 12:43:03.993: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.121.214 on the node which pod1 resides and expect scheduled 04/23/23 12:43:03.993
Apr 23 12:43:04.017: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-6392" to be "running and ready"
Apr 23 12:43:04.041: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 23.797366ms
Apr 23 12:43:04.041: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:43:06.077: INFO: Pod "pod2": Phase="Running", Reason="", readiness=false. Elapsed: 2.059952671s
Apr 23 12:43:06.077: INFO: The phase of Pod pod2 is Running (Ready = false)
Apr 23 12:43:08.055: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.038223837s
Apr 23 12:43:08.056: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 23 12:43:08.056: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.121.214 but use UDP protocol on the node which pod2 resides 04/23/23 12:43:08.056
Apr 23 12:43:08.068: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-6392" to be "running and ready"
Apr 23 12:43:08.110: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 41.549973ms
Apr 23 12:43:08.110: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:43:10.118: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.05008379s
Apr 23 12:43:10.118: INFO: The phase of Pod pod3 is Running (Ready = true)
Apr 23 12:43:10.118: INFO: Pod "pod3" satisfied condition "running and ready"
Apr 23 12:43:10.164: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-6392" to be "running and ready"
Apr 23 12:43:10.181: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 17.229518ms
Apr 23 12:43:10.181: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:43:12.193: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.028956675s
Apr 23 12:43:12.193: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Apr 23 12:43:12.193: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 04/23/23 12:43:12.211
Apr 23 12:43:12.212: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.121.214 http://127.0.0.1:54323/hostname] Namespace:hostport-6392 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:43:12.212: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:43:12.217: INFO: ExecWithOptions: Clientset creation
Apr 23 12:43:12.217: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-6392/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.121.214+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.214, port: 54323 04/23/23 12:43:12.398
Apr 23 12:43:12.399: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.121.214:54323/hostname] Namespace:hostport-6392 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:43:12.399: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:43:12.401: INFO: ExecWithOptions: Clientset creation
Apr 23 12:43:12.401: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-6392/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.121.214%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.214, port: 54323 UDP 04/23/23 12:43:12.592
Apr 23 12:43:12.592: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.121.214 54323] Namespace:hostport-6392 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 23 12:43:12.593: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
Apr 23 12:43:12.594: INFO: ExecWithOptions: Clientset creation
Apr 23 12:43:12.595: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-6392/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.121.214+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/node/init/init.go:32
Apr 23 12:43:17.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] HostPort
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] HostPort
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] HostPort
  tear down framework | framework.go:193
STEP: Destroying namespace "hostport-6392" for this suite. 04/23/23 12:43:17.736
------------------------------
â€¢ [SLOW TEST] [28.383 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:42:49.367
    Apr 23 12:42:49.368: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename hostport 04/23/23 12:42:49.398
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:42:49.751
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:42:49.756
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 04/23/23 12:42:49.9
    Apr 23 12:42:49.937: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-6392" to be "running and ready"
    Apr 23 12:42:49.956: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.004346ms
    Apr 23 12:42:49.956: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:42:52.009: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071717847s
    Apr 23 12:42:52.009: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:42:53.974: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036198497s
    Apr 23 12:42:53.974: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:42:56.348: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.410736584s
    Apr 23 12:42:56.348: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:42:57.989: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.05113217s
    Apr 23 12:42:57.989: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:42:59.979: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.041984572s
    Apr 23 12:42:59.980: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:43:01.967: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.029572961s
    Apr 23 12:43:01.967: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:43:03.993: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 14.055415962s
    Apr 23 12:43:03.993: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 23 12:43:03.993: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.121.214 on the node which pod1 resides and expect scheduled 04/23/23 12:43:03.993
    Apr 23 12:43:04.017: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-6392" to be "running and ready"
    Apr 23 12:43:04.041: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 23.797366ms
    Apr 23 12:43:04.041: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:43:06.077: INFO: Pod "pod2": Phase="Running", Reason="", readiness=false. Elapsed: 2.059952671s
    Apr 23 12:43:06.077: INFO: The phase of Pod pod2 is Running (Ready = false)
    Apr 23 12:43:08.055: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.038223837s
    Apr 23 12:43:08.056: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 23 12:43:08.056: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.121.214 but use UDP protocol on the node which pod2 resides 04/23/23 12:43:08.056
    Apr 23 12:43:08.068: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-6392" to be "running and ready"
    Apr 23 12:43:08.110: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 41.549973ms
    Apr 23 12:43:08.110: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:43:10.118: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.05008379s
    Apr 23 12:43:10.118: INFO: The phase of Pod pod3 is Running (Ready = true)
    Apr 23 12:43:10.118: INFO: Pod "pod3" satisfied condition "running and ready"
    Apr 23 12:43:10.164: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-6392" to be "running and ready"
    Apr 23 12:43:10.181: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 17.229518ms
    Apr 23 12:43:10.181: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:43:12.193: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.028956675s
    Apr 23 12:43:12.193: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Apr 23 12:43:12.193: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 04/23/23 12:43:12.211
    Apr 23 12:43:12.212: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.121.214 http://127.0.0.1:54323/hostname] Namespace:hostport-6392 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:43:12.212: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:43:12.217: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:43:12.217: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-6392/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.121.214+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.214, port: 54323 04/23/23 12:43:12.398
    Apr 23 12:43:12.399: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.121.214:54323/hostname] Namespace:hostport-6392 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:43:12.399: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:43:12.401: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:43:12.401: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-6392/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.121.214%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.214, port: 54323 UDP 04/23/23 12:43:12.592
    Apr 23 12:43:12.592: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.121.214 54323] Namespace:hostport-6392 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 23 12:43:12.593: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    Apr 23 12:43:12.594: INFO: ExecWithOptions: Clientset creation
    Apr 23 12:43:12.595: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-6392/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.121.214+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:43:17.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] HostPort
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] HostPort
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] HostPort
      tear down framework | framework.go:193
    STEP: Destroying namespace "hostport-6392" for this suite. 04/23/23 12:43:17.736
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:93
[BeforeEach] [sig-node] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:43:17.754
Apr 23 12:43:17.754: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 12:43:17.761
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:43:17.796
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:43:17.799
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:93
STEP: Creating configMap configmap-5600/configmap-test-a2725a35-ed4f-4afa-869c-8a6737384cf4 04/23/23 12:43:17.804
STEP: Creating a pod to test consume configMaps 04/23/23 12:43:17.813
Apr 23 12:43:17.828: INFO: Waiting up to 5m0s for pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a" in namespace "configmap-5600" to be "Succeeded or Failed"
Apr 23 12:43:17.835: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.304348ms
Apr 23 12:43:19.842: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014144909s
Apr 23 12:43:21.843: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015043362s
Apr 23 12:43:23.843: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015629115s
Apr 23 12:43:25.844: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.015966356s
Apr 23 12:43:27.844: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.016477134s
Apr 23 12:43:29.841: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.013573695s
Apr 23 12:43:31.865: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.036749652s
Apr 23 12:43:33.843: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.015095156s
Apr 23 12:43:35.842: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 18.0144065s
Apr 23 12:43:37.844: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.01567217s
Apr 23 12:43:39.844: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 22.016188245s
Apr 23 12:43:41.842: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 24.014282965s
Apr 23 12:43:43.842: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 26.014004813s
Apr 23 12:43:45.843: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 28.015188802s
Apr 23 12:43:47.844: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 30.015884275s
Apr 23 12:43:49.846: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 32.018052088s
Apr 23 12:43:51.848: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 34.019983835s
Apr 23 12:43:53.843: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 36.015473962s
Apr 23 12:43:55.845: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 38.017028633s
Apr 23 12:43:57.848: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 40.019972858s
Apr 23 12:43:59.841: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 42.013628998s
Apr 23 12:44:01.843: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 44.015473005s
Apr 23 12:44:03.848: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 46.019870285s
Apr 23 12:44:05.842: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 48.014331376s
STEP: Saw pod success 04/23/23 12:44:05.842
Apr 23 12:44:05.843: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a" satisfied condition "Succeeded or Failed"
Apr 23 12:44:05.852: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a container env-test: <nil>
STEP: delete the pod 04/23/23 12:44:05.884
Apr 23 12:44:05.915: INFO: Waiting for pod pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a to disappear
Apr 23 12:44:05.929: INFO: Pod pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 12:44:05.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-5600" for this suite. 04/23/23 12:44:05.946
------------------------------
â€¢ [SLOW TEST] [48.213 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:43:17.754
    Apr 23 12:43:17.754: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 12:43:17.761
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:43:17.796
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:43:17.799
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:93
    STEP: Creating configMap configmap-5600/configmap-test-a2725a35-ed4f-4afa-869c-8a6737384cf4 04/23/23 12:43:17.804
    STEP: Creating a pod to test consume configMaps 04/23/23 12:43:17.813
    Apr 23 12:43:17.828: INFO: Waiting up to 5m0s for pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a" in namespace "configmap-5600" to be "Succeeded or Failed"
    Apr 23 12:43:17.835: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.304348ms
    Apr 23 12:43:19.842: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014144909s
    Apr 23 12:43:21.843: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015043362s
    Apr 23 12:43:23.843: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015629115s
    Apr 23 12:43:25.844: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.015966356s
    Apr 23 12:43:27.844: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.016477134s
    Apr 23 12:43:29.841: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.013573695s
    Apr 23 12:43:31.865: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.036749652s
    Apr 23 12:43:33.843: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.015095156s
    Apr 23 12:43:35.842: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 18.0144065s
    Apr 23 12:43:37.844: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.01567217s
    Apr 23 12:43:39.844: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 22.016188245s
    Apr 23 12:43:41.842: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 24.014282965s
    Apr 23 12:43:43.842: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 26.014004813s
    Apr 23 12:43:45.843: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 28.015188802s
    Apr 23 12:43:47.844: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 30.015884275s
    Apr 23 12:43:49.846: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 32.018052088s
    Apr 23 12:43:51.848: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 34.019983835s
    Apr 23 12:43:53.843: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 36.015473962s
    Apr 23 12:43:55.845: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 38.017028633s
    Apr 23 12:43:57.848: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 40.019972858s
    Apr 23 12:43:59.841: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 42.013628998s
    Apr 23 12:44:01.843: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 44.015473005s
    Apr 23 12:44:03.848: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Pending", Reason="", readiness=false. Elapsed: 46.019870285s
    Apr 23 12:44:05.842: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 48.014331376s
    STEP: Saw pod success 04/23/23 12:44:05.842
    Apr 23 12:44:05.843: INFO: Pod "pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a" satisfied condition "Succeeded or Failed"
    Apr 23 12:44:05.852: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a container env-test: <nil>
    STEP: delete the pod 04/23/23 12:44:05.884
    Apr 23 12:44:05.915: INFO: Waiting for pod pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a to disappear
    Apr 23 12:44:05.929: INFO: Pod pod-configmaps-1a5f0b71-c7cc-4c18-a30c-48746c27864a no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:44:05.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-5600" for this suite. 04/23/23 12:44:05.946
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:195
[BeforeEach] [sig-node] Container Runtime
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:44:05.974
Apr 23 12:44:05.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-runtime 04/23/23 12:44:05.977
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:44:06.034
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:44:06.047
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:31
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:195
STEP: create the container 04/23/23 12:44:06.055
STEP: wait for the container to reach Succeeded 04/23/23 12:44:06.09
STEP: get the container status 04/23/23 12:44:11.166
STEP: the container should be terminated 04/23/23 12:44:11.175
STEP: the termination message should be set 04/23/23 12:44:11.175
Apr 23 12:44:11.176: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 04/23/23 12:44:11.176
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/node/init/init.go:32
Apr 23 12:44:11.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Runtime
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Runtime
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Runtime
  tear down framework | framework.go:193
STEP: Destroying namespace "container-runtime-4699" for this suite. 04/23/23 12:44:11.227
------------------------------
â€¢ [SLOW TEST] [5.273 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:44
    on terminated container
    test/e2e/common/node/runtime.go:137
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:44:05.974
    Apr 23 12:44:05.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-runtime 04/23/23 12:44:05.977
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:44:06.034
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:44:06.047
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:31
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:195
    STEP: create the container 04/23/23 12:44:06.055
    STEP: wait for the container to reach Succeeded 04/23/23 12:44:06.09
    STEP: get the container status 04/23/23 12:44:11.166
    STEP: the container should be terminated 04/23/23 12:44:11.175
    STEP: the termination message should be set 04/23/23 12:44:11.175
    Apr 23 12:44:11.176: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 04/23/23 12:44:11.176
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:44:11.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Runtime
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Runtime
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Runtime
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-runtime-4699" for this suite. 04/23/23 12:44:11.227
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:413
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:44:11.267
Apr 23 12:44:11.268: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 12:44:11.275
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:44:11.303
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:44:11.311
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 12:44:11.347
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:44:12.249
STEP: Deploying the webhook pod 04/23/23 12:44:12.278
STEP: Wait for the deployment to be ready 04/23/23 12:44:12.309
Apr 23 12:44:12.329: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 23 12:44:14.501: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 44, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 44, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 44, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 44, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/23/23 12:44:16.559
STEP: Verifying the service has paired with the endpoint 04/23/23 12:44:16.629
Apr 23 12:44:17.629: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:413
STEP: Creating a validating webhook configuration 04/23/23 12:44:17.636
STEP: Creating a configMap that does not comply to the validation webhook rules 04/23/23 12:44:17.677
STEP: Updating a validating webhook configuration's rules to not include the create operation 04/23/23 12:44:17.697
STEP: Creating a configMap that does not comply to the validation webhook rules 04/23/23 12:44:17.719
STEP: Patching a validating webhook configuration's rules to include the create operation 04/23/23 12:44:17.858
STEP: Creating a configMap that does not comply to the validation webhook rules 04/23/23 12:44:17.871
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:44:17.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-4477" for this suite. 04/23/23 12:44:18.012
STEP: Destroying namespace "webhook-4477-markers" for this suite. 04/23/23 12:44:18.036
------------------------------
â€¢ [SLOW TEST] [6.807 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:44:11.267
    Apr 23 12:44:11.268: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 12:44:11.275
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:44:11.303
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:44:11.311
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 12:44:11.347
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:44:12.249
    STEP: Deploying the webhook pod 04/23/23 12:44:12.278
    STEP: Wait for the deployment to be ready 04/23/23 12:44:12.309
    Apr 23 12:44:12.329: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 23 12:44:14.501: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 44, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 44, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 44, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 44, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/23/23 12:44:16.559
    STEP: Verifying the service has paired with the endpoint 04/23/23 12:44:16.629
    Apr 23 12:44:17.629: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:413
    STEP: Creating a validating webhook configuration 04/23/23 12:44:17.636
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/23/23 12:44:17.677
    STEP: Updating a validating webhook configuration's rules to not include the create operation 04/23/23 12:44:17.697
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/23/23 12:44:17.719
    STEP: Patching a validating webhook configuration's rules to include the create operation 04/23/23 12:44:17.858
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/23/23 12:44:17.871
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:44:17.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-4477" for this suite. 04/23/23 12:44:18.012
    STEP: Destroying namespace "webhook-4477-markers" for this suite. 04/23/23 12:44:18.036
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:184
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:44:18.075
Apr 23 12:44:18.075: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-probe 04/23/23 12:44:18.082
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:44:18.131
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:44:18.138
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:184
STEP: Creating pod liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7 in namespace container-probe-8703 04/23/23 12:44:18.144
Apr 23 12:44:18.165: INFO: Waiting up to 5m0s for pod "liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7" in namespace "container-probe-8703" to be "not pending"
Apr 23 12:44:18.171: INFO: Pod "liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.471264ms
Apr 23 12:44:20.178: INFO: Pod "liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012569288s
Apr 23 12:44:22.191: INFO: Pod "liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7": Phase="Running", Reason="", readiness=true. Elapsed: 4.026132263s
Apr 23 12:44:22.192: INFO: Pod "liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7" satisfied condition "not pending"
Apr 23 12:44:22.192: INFO: Started pod liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7 in namespace container-probe-8703
STEP: checking the pod's current state and verifying that restartCount is present 04/23/23 12:44:22.192
Apr 23 12:44:22.202: INFO: Initial restart count of pod liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7 is 0
STEP: deleting the pod 04/23/23 12:48:23.382
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Apr 23 12:48:23.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-8703" for this suite. 04/23/23 12:48:23.435
------------------------------
â€¢ [SLOW TEST] [245.371 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:44:18.075
    Apr 23 12:44:18.075: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-probe 04/23/23 12:44:18.082
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:44:18.131
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:44:18.138
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:184
    STEP: Creating pod liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7 in namespace container-probe-8703 04/23/23 12:44:18.144
    Apr 23 12:44:18.165: INFO: Waiting up to 5m0s for pod "liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7" in namespace "container-probe-8703" to be "not pending"
    Apr 23 12:44:18.171: INFO: Pod "liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.471264ms
    Apr 23 12:44:20.178: INFO: Pod "liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012569288s
    Apr 23 12:44:22.191: INFO: Pod "liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7": Phase="Running", Reason="", readiness=true. Elapsed: 4.026132263s
    Apr 23 12:44:22.192: INFO: Pod "liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7" satisfied condition "not pending"
    Apr 23 12:44:22.192: INFO: Started pod liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7 in namespace container-probe-8703
    STEP: checking the pod's current state and verifying that restartCount is present 04/23/23 12:44:22.192
    Apr 23 12:44:22.202: INFO: Initial restart count of pod liveness-d4400f96-d1f2-485c-9879-d1fd854a07c7 is 0
    STEP: deleting the pod 04/23/23 12:48:23.382
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:48:23.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-8703" for this suite. 04/23/23 12:48:23.435
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:787
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:48:23.462
Apr 23 12:48:23.463: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 12:48:23.468
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:48:23.54
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:48:23.545
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:787
STEP: creating service endpoint-test2 in namespace services-9100 04/23/23 12:48:23.551
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9100 to expose endpoints map[] 04/23/23 12:48:23.571
Apr 23 12:48:23.606: INFO: successfully validated that service endpoint-test2 in namespace services-9100 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-9100 04/23/23 12:48:23.606
Apr 23 12:48:23.626: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-9100" to be "running and ready"
Apr 23 12:48:23.634: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.360087ms
Apr 23 12:48:23.634: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:48:25.642: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016357486s
Apr 23 12:48:25.642: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:48:27.642: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.015904892s
Apr 23 12:48:27.642: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 23 12:48:27.642: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9100 to expose endpoints map[pod1:[80]] 04/23/23 12:48:27.65
Apr 23 12:48:27.669: INFO: successfully validated that service endpoint-test2 in namespace services-9100 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 04/23/23 12:48:27.669
Apr 23 12:48:27.669: INFO: Creating new exec pod
Apr 23 12:48:27.679: INFO: Waiting up to 5m0s for pod "execpoddfxfz" in namespace "services-9100" to be "running"
Apr 23 12:48:27.684: INFO: Pod "execpoddfxfz": Phase="Pending", Reason="", readiness=false. Elapsed: 5.009418ms
Apr 23 12:48:29.694: INFO: Pod "execpoddfxfz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014567534s
Apr 23 12:48:31.694: INFO: Pod "execpoddfxfz": Phase="Running", Reason="", readiness=true. Elapsed: 4.015011897s
Apr 23 12:48:31.694: INFO: Pod "execpoddfxfz" satisfied condition "running"
Apr 23 12:48:32.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9100 exec execpoddfxfz -- /bin/sh -x -c nc -v -z -w 2 endpoint-test2 80'
Apr 23 12:48:33.152: INFO: stderr: "+ nc -v -z -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 23 12:48:33.152: INFO: stdout: ""
Apr 23 12:48:33.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9100 exec execpoddfxfz -- /bin/sh -x -c nc -v -z -w 2 10.233.52.163 80'
Apr 23 12:48:33.478: INFO: stderr: "+ nc -v -z -w 2 10.233.52.163 80\nConnection to 10.233.52.163 80 port [tcp/http] succeeded!\n"
Apr 23 12:48:33.478: INFO: stdout: ""
STEP: Creating pod pod2 in namespace services-9100 04/23/23 12:48:33.478
Apr 23 12:48:33.501: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-9100" to be "running and ready"
Apr 23 12:48:33.515: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.815476ms
Apr 23 12:48:33.515: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:48:35.523: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022464356s
Apr 23 12:48:35.524: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:48:37.525: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.023709723s
Apr 23 12:48:37.525: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 23 12:48:37.525: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9100 to expose endpoints map[pod1:[80] pod2:[80]] 04/23/23 12:48:37.53
Apr 23 12:48:37.549: INFO: successfully validated that service endpoint-test2 in namespace services-9100 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 04/23/23 12:48:37.549
Apr 23 12:48:38.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9100 exec execpoddfxfz -- /bin/sh -x -c nc -v -z -w 2 endpoint-test2 80'
Apr 23 12:48:38.947: INFO: stderr: "+ nc -v -z -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 23 12:48:38.947: INFO: stdout: ""
Apr 23 12:48:38.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9100 exec execpoddfxfz -- /bin/sh -x -c nc -v -z -w 2 10.233.52.163 80'
Apr 23 12:48:39.177: INFO: stderr: "+ nc -v -z -w 2 10.233.52.163 80\nConnection to 10.233.52.163 80 port [tcp/http] succeeded!\n"
Apr 23 12:48:39.177: INFO: stdout: ""
STEP: Deleting pod pod1 in namespace services-9100 04/23/23 12:48:39.177
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9100 to expose endpoints map[pod2:[80]] 04/23/23 12:48:39.205
Apr 23 12:48:39.285: INFO: successfully validated that service endpoint-test2 in namespace services-9100 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 04/23/23 12:48:39.285
Apr 23 12:48:40.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9100 exec execpoddfxfz -- /bin/sh -x -c nc -v -z -w 2 endpoint-test2 80'
Apr 23 12:48:40.608: INFO: stderr: "+ nc -v -z -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 23 12:48:40.608: INFO: stdout: ""
Apr 23 12:48:40.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9100 exec execpoddfxfz -- /bin/sh -x -c nc -v -z -w 2 10.233.52.163 80'
Apr 23 12:48:40.939: INFO: stderr: "+ nc -v -z -w 2 10.233.52.163 80\nConnection to 10.233.52.163 80 port [tcp/http] succeeded!\n"
Apr 23 12:48:40.940: INFO: stdout: ""
STEP: Deleting pod pod2 in namespace services-9100 04/23/23 12:48:40.94
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9100 to expose endpoints map[] 04/23/23 12:48:41.016
Apr 23 12:48:41.080: INFO: successfully validated that service endpoint-test2 in namespace services-9100 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 12:48:41.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-9100" for this suite. 04/23/23 12:48:41.254
------------------------------
â€¢ [SLOW TEST] [17.824 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:787

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:48:23.462
    Apr 23 12:48:23.463: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 12:48:23.468
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:48:23.54
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:48:23.545
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:787
    STEP: creating service endpoint-test2 in namespace services-9100 04/23/23 12:48:23.551
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9100 to expose endpoints map[] 04/23/23 12:48:23.571
    Apr 23 12:48:23.606: INFO: successfully validated that service endpoint-test2 in namespace services-9100 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-9100 04/23/23 12:48:23.606
    Apr 23 12:48:23.626: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-9100" to be "running and ready"
    Apr 23 12:48:23.634: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.360087ms
    Apr 23 12:48:23.634: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:48:25.642: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016357486s
    Apr 23 12:48:25.642: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:48:27.642: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.015904892s
    Apr 23 12:48:27.642: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 23 12:48:27.642: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9100 to expose endpoints map[pod1:[80]] 04/23/23 12:48:27.65
    Apr 23 12:48:27.669: INFO: successfully validated that service endpoint-test2 in namespace services-9100 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 04/23/23 12:48:27.669
    Apr 23 12:48:27.669: INFO: Creating new exec pod
    Apr 23 12:48:27.679: INFO: Waiting up to 5m0s for pod "execpoddfxfz" in namespace "services-9100" to be "running"
    Apr 23 12:48:27.684: INFO: Pod "execpoddfxfz": Phase="Pending", Reason="", readiness=false. Elapsed: 5.009418ms
    Apr 23 12:48:29.694: INFO: Pod "execpoddfxfz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014567534s
    Apr 23 12:48:31.694: INFO: Pod "execpoddfxfz": Phase="Running", Reason="", readiness=true. Elapsed: 4.015011897s
    Apr 23 12:48:31.694: INFO: Pod "execpoddfxfz" satisfied condition "running"
    Apr 23 12:48:32.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9100 exec execpoddfxfz -- /bin/sh -x -c nc -v -z -w 2 endpoint-test2 80'
    Apr 23 12:48:33.152: INFO: stderr: "+ nc -v -z -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 23 12:48:33.152: INFO: stdout: ""
    Apr 23 12:48:33.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9100 exec execpoddfxfz -- /bin/sh -x -c nc -v -z -w 2 10.233.52.163 80'
    Apr 23 12:48:33.478: INFO: stderr: "+ nc -v -z -w 2 10.233.52.163 80\nConnection to 10.233.52.163 80 port [tcp/http] succeeded!\n"
    Apr 23 12:48:33.478: INFO: stdout: ""
    STEP: Creating pod pod2 in namespace services-9100 04/23/23 12:48:33.478
    Apr 23 12:48:33.501: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-9100" to be "running and ready"
    Apr 23 12:48:33.515: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.815476ms
    Apr 23 12:48:33.515: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:48:35.523: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022464356s
    Apr 23 12:48:35.524: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:48:37.525: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.023709723s
    Apr 23 12:48:37.525: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 23 12:48:37.525: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9100 to expose endpoints map[pod1:[80] pod2:[80]] 04/23/23 12:48:37.53
    Apr 23 12:48:37.549: INFO: successfully validated that service endpoint-test2 in namespace services-9100 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 04/23/23 12:48:37.549
    Apr 23 12:48:38.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9100 exec execpoddfxfz -- /bin/sh -x -c nc -v -z -w 2 endpoint-test2 80'
    Apr 23 12:48:38.947: INFO: stderr: "+ nc -v -z -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 23 12:48:38.947: INFO: stdout: ""
    Apr 23 12:48:38.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9100 exec execpoddfxfz -- /bin/sh -x -c nc -v -z -w 2 10.233.52.163 80'
    Apr 23 12:48:39.177: INFO: stderr: "+ nc -v -z -w 2 10.233.52.163 80\nConnection to 10.233.52.163 80 port [tcp/http] succeeded!\n"
    Apr 23 12:48:39.177: INFO: stdout: ""
    STEP: Deleting pod pod1 in namespace services-9100 04/23/23 12:48:39.177
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9100 to expose endpoints map[pod2:[80]] 04/23/23 12:48:39.205
    Apr 23 12:48:39.285: INFO: successfully validated that service endpoint-test2 in namespace services-9100 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 04/23/23 12:48:39.285
    Apr 23 12:48:40.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9100 exec execpoddfxfz -- /bin/sh -x -c nc -v -z -w 2 endpoint-test2 80'
    Apr 23 12:48:40.608: INFO: stderr: "+ nc -v -z -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 23 12:48:40.608: INFO: stdout: ""
    Apr 23 12:48:40.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-9100 exec execpoddfxfz -- /bin/sh -x -c nc -v -z -w 2 10.233.52.163 80'
    Apr 23 12:48:40.939: INFO: stderr: "+ nc -v -z -w 2 10.233.52.163 80\nConnection to 10.233.52.163 80 port [tcp/http] succeeded!\n"
    Apr 23 12:48:40.940: INFO: stdout: ""
    STEP: Deleting pod pod2 in namespace services-9100 04/23/23 12:48:40.94
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9100 to expose endpoints map[] 04/23/23 12:48:41.016
    Apr 23 12:48:41.080: INFO: successfully validated that service endpoint-test2 in namespace services-9100 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:48:41.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-9100" for this suite. 04/23/23 12:48:41.254
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:458
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:48:41.29
Apr 23 12:48:41.290: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename init-container 04/23/23 12:48:41.296
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:48:41.337
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:48:41.343
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:165
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:458
STEP: creating the pod 04/23/23 12:48:41.359
Apr 23 12:48:41.360: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:48:47.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  tear down framework | framework.go:193
STEP: Destroying namespace "init-container-5498" for this suite. 04/23/23 12:48:47.671
------------------------------
â€¢ [SLOW TEST] [6.398 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:458

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:48:41.29
    Apr 23 12:48:41.290: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename init-container 04/23/23 12:48:41.296
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:48:41.337
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:48:41.343
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:165
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:458
    STEP: creating the pod 04/23/23 12:48:41.359
    Apr 23 12:48:41.360: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:48:47.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      tear down framework | framework.go:193
    STEP: Destroying namespace "init-container-5498" for this suite. 04/23/23 12:48:47.671
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:48:47.704
Apr 23 12:48:47.704: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename sysctl 04/23/23 12:48:47.71
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:48:47.748
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:48:47.753
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 04/23/23 12:48:47.756
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:48:47.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  tear down framework | framework.go:193
STEP: Destroying namespace "sysctl-4919" for this suite. 04/23/23 12:48:47.777
------------------------------
â€¢ [0.102 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:48:47.704
    Apr 23 12:48:47.704: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename sysctl 04/23/23 12:48:47.71
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:48:47.748
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:48:47.753
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 04/23/23 12:48:47.756
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:48:47.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sysctl-4919" for this suite. 04/23/23 12:48:47.777
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:507
[BeforeEach] [sig-apps] Job
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:48:47.819
Apr 23 12:48:47.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename job 04/23/23 12:48:47.821
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:48:47.847
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:48:47.851
[BeforeEach] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:31
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:507
STEP: Creating a job 04/23/23 12:48:47.855
STEP: Ensuring active pods == parallelism 04/23/23 12:48:47.867
STEP: Orphaning one of the Job's Pods 04/23/23 12:48:51.876
Apr 23 12:48:52.407: INFO: Successfully updated pod "adopt-release-bkszs"
STEP: Checking that the Job readopts the Pod 04/23/23 12:48:52.407
Apr 23 12:48:52.407: INFO: Waiting up to 15m0s for pod "adopt-release-bkszs" in namespace "job-5956" to be "adopted"
Apr 23 12:48:52.419: INFO: Pod "adopt-release-bkszs": Phase="Running", Reason="", readiness=true. Elapsed: 11.60775ms
Apr 23 12:48:54.428: INFO: Pod "adopt-release-bkszs": Phase="Running", Reason="", readiness=true. Elapsed: 2.020475551s
Apr 23 12:48:54.428: INFO: Pod "adopt-release-bkszs" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 04/23/23 12:48:54.428
Apr 23 12:48:54.954: INFO: Successfully updated pod "adopt-release-bkszs"
STEP: Checking that the Job releases the Pod 04/23/23 12:48:54.954
Apr 23 12:48:54.955: INFO: Waiting up to 15m0s for pod "adopt-release-bkszs" in namespace "job-5956" to be "released"
Apr 23 12:48:54.966: INFO: Pod "adopt-release-bkszs": Phase="Running", Reason="", readiness=true. Elapsed: 10.991814ms
Apr 23 12:48:56.976: INFO: Pod "adopt-release-bkszs": Phase="Running", Reason="", readiness=true. Elapsed: 2.020546406s
Apr 23 12:48:56.976: INFO: Pod "adopt-release-bkszs" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/node/init/init.go:32
Apr 23 12:48:56.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Job
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Job
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Job
  tear down framework | framework.go:193
STEP: Destroying namespace "job-5956" for this suite. 04/23/23 12:48:56.985
------------------------------
â€¢ [SLOW TEST] [9.181 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:48:47.819
    Apr 23 12:48:47.819: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename job 04/23/23 12:48:47.821
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:48:47.847
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:48:47.851
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:31
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:507
    STEP: Creating a job 04/23/23 12:48:47.855
    STEP: Ensuring active pods == parallelism 04/23/23 12:48:47.867
    STEP: Orphaning one of the Job's Pods 04/23/23 12:48:51.876
    Apr 23 12:48:52.407: INFO: Successfully updated pod "adopt-release-bkszs"
    STEP: Checking that the Job readopts the Pod 04/23/23 12:48:52.407
    Apr 23 12:48:52.407: INFO: Waiting up to 15m0s for pod "adopt-release-bkszs" in namespace "job-5956" to be "adopted"
    Apr 23 12:48:52.419: INFO: Pod "adopt-release-bkszs": Phase="Running", Reason="", readiness=true. Elapsed: 11.60775ms
    Apr 23 12:48:54.428: INFO: Pod "adopt-release-bkszs": Phase="Running", Reason="", readiness=true. Elapsed: 2.020475551s
    Apr 23 12:48:54.428: INFO: Pod "adopt-release-bkszs" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 04/23/23 12:48:54.428
    Apr 23 12:48:54.954: INFO: Successfully updated pod "adopt-release-bkszs"
    STEP: Checking that the Job releases the Pod 04/23/23 12:48:54.954
    Apr 23 12:48:54.955: INFO: Waiting up to 15m0s for pod "adopt-release-bkszs" in namespace "job-5956" to be "released"
    Apr 23 12:48:54.966: INFO: Pod "adopt-release-bkszs": Phase="Running", Reason="", readiness=true. Elapsed: 10.991814ms
    Apr 23 12:48:56.976: INFO: Pod "adopt-release-bkszs": Phase="Running", Reason="", readiness=true. Elapsed: 2.020546406s
    Apr 23 12:48:56.976: INFO: Pod "adopt-release-bkszs" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:48:56.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Job
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Job
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Job
      tear down framework | framework.go:193
    STEP: Destroying namespace "job-5956" for this suite. 04/23/23 12:48:56.985
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:68
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:48:57.001
Apr 23 12:48:57.001: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename secrets 04/23/23 12:48:57.004
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:48:57.039
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:48:57.043
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:68
STEP: Creating secret with name secret-test-e617d314-02cd-4fc4-9ed2-5514a8a8357e 04/23/23 12:48:57.047
STEP: Creating a pod to test consume secrets 04/23/23 12:48:57.06
Apr 23 12:48:57.108: INFO: Waiting up to 5m0s for pod "pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814" in namespace "secrets-2861" to be "Succeeded or Failed"
Apr 23 12:48:57.143: INFO: Pod "pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814": Phase="Pending", Reason="", readiness=false. Elapsed: 32.295328ms
Apr 23 12:48:59.152: INFO: Pod "pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041555678s
Apr 23 12:49:01.163: INFO: Pod "pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052299881s
Apr 23 12:49:03.158: INFO: Pod "pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.047508257s
STEP: Saw pod success 04/23/23 12:49:03.159
Apr 23 12:49:03.160: INFO: Pod "pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814" satisfied condition "Succeeded or Failed"
Apr 23 12:49:03.168: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814 container secret-volume-test: <nil>
STEP: delete the pod 04/23/23 12:49:03.207
Apr 23 12:49:03.241: INFO: Waiting for pod pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814 to disappear
Apr 23 12:49:03.249: INFO: Pod pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Apr 23 12:49:03.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-2861" for this suite. 04/23/23 12:49:03.263
------------------------------
â€¢ [SLOW TEST] [6.279 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:48:57.001
    Apr 23 12:48:57.001: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename secrets 04/23/23 12:48:57.004
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:48:57.039
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:48:57.043
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:68
    STEP: Creating secret with name secret-test-e617d314-02cd-4fc4-9ed2-5514a8a8357e 04/23/23 12:48:57.047
    STEP: Creating a pod to test consume secrets 04/23/23 12:48:57.06
    Apr 23 12:48:57.108: INFO: Waiting up to 5m0s for pod "pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814" in namespace "secrets-2861" to be "Succeeded or Failed"
    Apr 23 12:48:57.143: INFO: Pod "pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814": Phase="Pending", Reason="", readiness=false. Elapsed: 32.295328ms
    Apr 23 12:48:59.152: INFO: Pod "pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041555678s
    Apr 23 12:49:01.163: INFO: Pod "pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052299881s
    Apr 23 12:49:03.158: INFO: Pod "pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.047508257s
    STEP: Saw pod success 04/23/23 12:49:03.159
    Apr 23 12:49:03.160: INFO: Pod "pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814" satisfied condition "Succeeded or Failed"
    Apr 23 12:49:03.168: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814 container secret-volume-test: <nil>
    STEP: delete the pod 04/23/23 12:49:03.207
    Apr 23 12:49:03.241: INFO: Waiting for pod pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814 to disappear
    Apr 23 12:49:03.249: INFO: Pod pod-secrets-7ba4d74e-b3a1-4691-a184-18fc9df98814 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:49:03.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-2861" for this suite. 04/23/23 12:49:03.263
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:444
[BeforeEach] [sig-node] Pods
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:49:03.28
Apr 23 12:49:03.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename pods 04/23/23 12:49:03.285
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:03.335
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:03.342
[BeforeEach] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:194
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:444
Apr 23 12:49:03.385: INFO: Waiting up to 5m0s for pod "server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc" in namespace "pods-4917" to be "running and ready"
Apr 23 12:49:03.399: INFO: Pod "server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc": Phase="Pending", Reason="", readiness=false. Elapsed: 13.458731ms
Apr 23 12:49:03.399: INFO: The phase of Pod server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:49:05.455: INFO: Pod "server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069487101s
Apr 23 12:49:05.455: INFO: The phase of Pod server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:49:07.420: INFO: Pod "server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc": Phase="Running", Reason="", readiness=true. Elapsed: 4.034869187s
Apr 23 12:49:07.421: INFO: The phase of Pod server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc is Running (Ready = true)
Apr 23 12:49:07.421: INFO: Pod "server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc" satisfied condition "running and ready"
Apr 23 12:49:07.485: INFO: Waiting up to 5m0s for pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334" in namespace "pods-4917" to be "Succeeded or Failed"
Apr 23 12:49:07.515: INFO: Pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334": Phase="Pending", Reason="", readiness=false. Elapsed: 29.942448ms
Apr 23 12:49:09.520: INFO: Pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035347607s
Apr 23 12:49:11.521: INFO: Pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036387249s
Apr 23 12:49:13.522: INFO: Pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334": Phase="Pending", Reason="", readiness=false. Elapsed: 6.036793281s
Apr 23 12:49:15.525: INFO: Pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334": Phase="Pending", Reason="", readiness=false. Elapsed: 8.039709585s
Apr 23 12:49:17.524: INFO: Pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.038763148s
STEP: Saw pod success 04/23/23 12:49:17.524
Apr 23 12:49:17.524: INFO: Pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334" satisfied condition "Succeeded or Failed"
Apr 23 12:49:17.531: INFO: Trying to get logs from node eingavuivie7-2 pod client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334 container env3cont: <nil>
STEP: delete the pod 04/23/23 12:49:17.565
Apr 23 12:49:17.581: INFO: Waiting for pod client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334 to disappear
Apr 23 12:49:17.588: INFO: Pod client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/node/init/init.go:32
Apr 23 12:49:17.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Pods
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Pods
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Pods
  tear down framework | framework.go:193
STEP: Destroying namespace "pods-4917" for this suite. 04/23/23 12:49:17.598
------------------------------
â€¢ [SLOW TEST] [14.329 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:444

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:49:03.28
    Apr 23 12:49:03.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename pods 04/23/23 12:49:03.285
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:03.335
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:03.342
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:194
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:444
    Apr 23 12:49:03.385: INFO: Waiting up to 5m0s for pod "server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc" in namespace "pods-4917" to be "running and ready"
    Apr 23 12:49:03.399: INFO: Pod "server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc": Phase="Pending", Reason="", readiness=false. Elapsed: 13.458731ms
    Apr 23 12:49:03.399: INFO: The phase of Pod server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:49:05.455: INFO: Pod "server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069487101s
    Apr 23 12:49:05.455: INFO: The phase of Pod server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:49:07.420: INFO: Pod "server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc": Phase="Running", Reason="", readiness=true. Elapsed: 4.034869187s
    Apr 23 12:49:07.421: INFO: The phase of Pod server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc is Running (Ready = true)
    Apr 23 12:49:07.421: INFO: Pod "server-envvars-de982ba4-f821-4bec-9407-8a03cf4a23fc" satisfied condition "running and ready"
    Apr 23 12:49:07.485: INFO: Waiting up to 5m0s for pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334" in namespace "pods-4917" to be "Succeeded or Failed"
    Apr 23 12:49:07.515: INFO: Pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334": Phase="Pending", Reason="", readiness=false. Elapsed: 29.942448ms
    Apr 23 12:49:09.520: INFO: Pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035347607s
    Apr 23 12:49:11.521: INFO: Pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036387249s
    Apr 23 12:49:13.522: INFO: Pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334": Phase="Pending", Reason="", readiness=false. Elapsed: 6.036793281s
    Apr 23 12:49:15.525: INFO: Pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334": Phase="Pending", Reason="", readiness=false. Elapsed: 8.039709585s
    Apr 23 12:49:17.524: INFO: Pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.038763148s
    STEP: Saw pod success 04/23/23 12:49:17.524
    Apr 23 12:49:17.524: INFO: Pod "client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334" satisfied condition "Succeeded or Failed"
    Apr 23 12:49:17.531: INFO: Trying to get logs from node eingavuivie7-2 pod client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334 container env3cont: <nil>
    STEP: delete the pod 04/23/23 12:49:17.565
    Apr 23 12:49:17.581: INFO: Waiting for pod client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334 to disappear
    Apr 23 12:49:17.588: INFO: Pod client-envvars-77e37a4b-3fa1-41ec-8b90-7e2e0cd6f334 no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:49:17.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Pods
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Pods
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Pods
      tear down framework | framework.go:193
    STEP: Destroying namespace "pods-4917" for this suite. 04/23/23 12:49:17.598
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:49:17.611
Apr 23 12:49:17.611: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename podtemplate 04/23/23 12:49:17.615
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:17.641
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:17.645
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/metrics/init/init.go:31
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/node/init/init.go:32
Apr 23 12:49:17.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] PodTemplates
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] PodTemplates
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] PodTemplates
  tear down framework | framework.go:193
STEP: Destroying namespace "podtemplate-9991" for this suite. 04/23/23 12:49:17.744
------------------------------
â€¢ [0.143 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:49:17.611
    Apr 23 12:49:17.611: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename podtemplate 04/23/23 12:49:17.615
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:17.641
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:17.645
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/metrics/init/init.go:31
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:49:17.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] PodTemplates
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] PodTemplates
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] PodTemplates
      tear down framework | framework.go:193
    STEP: Destroying namespace "podtemplate-9991" for this suite. 04/23/23 12:49:17.744
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:162
[BeforeEach] [sig-storage] Downward API volume
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:49:17.756
Apr 23 12:49:17.756: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 12:49:17.759
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:17.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:17.79
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:44
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:162
STEP: Creating the pod 04/23/23 12:49:17.795
Apr 23 12:49:17.809: INFO: Waiting up to 5m0s for pod "annotationupdate7e16bd01-890e-423b-b918-28d22ccfdd6d" in namespace "downward-api-2752" to be "running and ready"
Apr 23 12:49:17.819: INFO: Pod "annotationupdate7e16bd01-890e-423b-b918-28d22ccfdd6d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.927874ms
Apr 23 12:49:17.819: INFO: The phase of Pod annotationupdate7e16bd01-890e-423b-b918-28d22ccfdd6d is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:49:19.826: INFO: Pod "annotationupdate7e16bd01-890e-423b-b918-28d22ccfdd6d": Phase="Running", Reason="", readiness=true. Elapsed: 2.016768933s
Apr 23 12:49:19.826: INFO: The phase of Pod annotationupdate7e16bd01-890e-423b-b918-28d22ccfdd6d is Running (Ready = true)
Apr 23 12:49:19.826: INFO: Pod "annotationupdate7e16bd01-890e-423b-b918-28d22ccfdd6d" satisfied condition "running and ready"
Apr 23 12:49:20.411: INFO: Successfully updated pod "annotationupdate7e16bd01-890e-423b-b918-28d22ccfdd6d"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/node/init/init.go:32
Apr 23 12:49:22.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Downward API volume
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Downward API volume
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Downward API volume
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-2752" for this suite. 04/23/23 12:49:22.478
------------------------------
â€¢ [4.750 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:162

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:49:17.756
    Apr 23 12:49:17.756: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 12:49:17.759
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:17.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:17.79
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:44
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:162
    STEP: Creating the pod 04/23/23 12:49:17.795
    Apr 23 12:49:17.809: INFO: Waiting up to 5m0s for pod "annotationupdate7e16bd01-890e-423b-b918-28d22ccfdd6d" in namespace "downward-api-2752" to be "running and ready"
    Apr 23 12:49:17.819: INFO: Pod "annotationupdate7e16bd01-890e-423b-b918-28d22ccfdd6d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.927874ms
    Apr 23 12:49:17.819: INFO: The phase of Pod annotationupdate7e16bd01-890e-423b-b918-28d22ccfdd6d is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:49:19.826: INFO: Pod "annotationupdate7e16bd01-890e-423b-b918-28d22ccfdd6d": Phase="Running", Reason="", readiness=true. Elapsed: 2.016768933s
    Apr 23 12:49:19.826: INFO: The phase of Pod annotationupdate7e16bd01-890e-423b-b918-28d22ccfdd6d is Running (Ready = true)
    Apr 23 12:49:19.826: INFO: Pod "annotationupdate7e16bd01-890e-423b-b918-28d22ccfdd6d" satisfied condition "running and ready"
    Apr 23 12:49:20.411: INFO: Successfully updated pod "annotationupdate7e16bd01-890e-423b-b918-28d22ccfdd6d"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:49:22.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Downward API volume
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-2752" for this suite. 04/23/23 12:49:22.478
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should update a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:810
[BeforeEach] [sig-auth] ServiceAccounts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:49:22.525
Apr 23 12:49:22.525: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename svcaccounts 04/23/23 12:49:22.53
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:22.59
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:22.594
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:31
[It] should update a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:810
STEP: Creating ServiceAccount "e2e-sa-mrtff"  04/23/23 12:49:22.599
Apr 23 12:49:22.610: INFO: AutomountServiceAccountToken: false
STEP: Updating ServiceAccount "e2e-sa-mrtff"  04/23/23 12:49:22.61
Apr 23 12:49:22.628: INFO: AutomountServiceAccountToken: true
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/node/init/init.go:32
Apr 23 12:49:22.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  tear down framework | framework.go:193
STEP: Destroying namespace "svcaccounts-8650" for this suite. 04/23/23 12:49:22.636
------------------------------
â€¢ [0.127 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should update a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:49:22.525
    Apr 23 12:49:22.525: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename svcaccounts 04/23/23 12:49:22.53
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:22.59
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:22.594
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:31
    [It] should update a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:810
    STEP: Creating ServiceAccount "e2e-sa-mrtff"  04/23/23 12:49:22.599
    Apr 23 12:49:22.610: INFO: AutomountServiceAccountToken: false
    STEP: Updating ServiceAccount "e2e-sa-mrtff"  04/23/23 12:49:22.61
    Apr 23 12:49:22.628: INFO: AutomountServiceAccountToken: true
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:49:22.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      tear down framework | framework.go:193
    STEP: Destroying namespace "svcaccounts-8650" for this suite. 04/23/23 12:49:22.636
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:423
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:49:22.669
Apr 23 12:49:22.669: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 12:49:22.672
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:22.712
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:22.718
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:423
STEP: Creating configMap with name configmap-test-volume-12b4c199-2863-4ab6-a777-3c33ca8aae36 04/23/23 12:49:22.723
STEP: Creating a pod to test consume configMaps 04/23/23 12:49:22.736
Apr 23 12:49:22.765: INFO: Waiting up to 5m0s for pod "pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4" in namespace "configmap-2821" to be "Succeeded or Failed"
Apr 23 12:49:22.786: INFO: Pod "pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.306598ms
Apr 23 12:49:24.795: INFO: Pod "pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03006661s
Apr 23 12:49:26.794: INFO: Pod "pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028976015s
Apr 23 12:49:28.805: INFO: Pod "pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039712641s
STEP: Saw pod success 04/23/23 12:49:28.805
Apr 23 12:49:28.805: INFO: Pod "pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4" satisfied condition "Succeeded or Failed"
Apr 23 12:49:28.813: INFO: Trying to get logs from node eingavuivie7-1 pod pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4 container configmap-volume-test: <nil>
STEP: delete the pod 04/23/23 12:49:28.861
Apr 23 12:49:28.884: INFO: Waiting for pod pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4 to disappear
Apr 23 12:49:28.894: INFO: Pod pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 12:49:28.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-2821" for this suite. 04/23/23 12:49:28.907
------------------------------
â€¢ [SLOW TEST] [6.264 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:423

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:49:22.669
    Apr 23 12:49:22.669: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 12:49:22.672
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:22.712
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:22.718
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:423
    STEP: Creating configMap with name configmap-test-volume-12b4c199-2863-4ab6-a777-3c33ca8aae36 04/23/23 12:49:22.723
    STEP: Creating a pod to test consume configMaps 04/23/23 12:49:22.736
    Apr 23 12:49:22.765: INFO: Waiting up to 5m0s for pod "pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4" in namespace "configmap-2821" to be "Succeeded or Failed"
    Apr 23 12:49:22.786: INFO: Pod "pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.306598ms
    Apr 23 12:49:24.795: INFO: Pod "pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03006661s
    Apr 23 12:49:26.794: INFO: Pod "pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028976015s
    Apr 23 12:49:28.805: INFO: Pod "pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039712641s
    STEP: Saw pod success 04/23/23 12:49:28.805
    Apr 23 12:49:28.805: INFO: Pod "pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4" satisfied condition "Succeeded or Failed"
    Apr 23 12:49:28.813: INFO: Trying to get logs from node eingavuivie7-1 pod pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4 container configmap-volume-test: <nil>
    STEP: delete the pod 04/23/23 12:49:28.861
    Apr 23 12:49:28.884: INFO: Waiting for pod pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4 to disappear
    Apr 23 12:49:28.894: INFO: Pod pod-configmaps-b1c73230-1c89-4934-9f8e-6f30f18feda4 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:49:28.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-2821" for this suite. 04/23/23 12:49:28.907
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:255
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:49:28.939
Apr 23 12:49:28.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename init-container 04/23/23 12:49:28.946
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:29
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:29.006
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:165
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:255
STEP: creating the pod 04/23/23 12:49:29.014
Apr 23 12:49:29.014: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:49:34.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
  tear down framework | framework.go:193
STEP: Destroying namespace "init-container-3974" for this suite. 04/23/23 12:49:34.246
------------------------------
â€¢ [SLOW TEST] [5.327 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:255

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:49:28.939
    Apr 23 12:49:28.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename init-container 04/23/23 12:49:28.946
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:29
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:29.006
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:165
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:255
    STEP: creating the pod 04/23/23 12:49:29.014
    Apr 23 12:49:29.014: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:49:34.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] InitContainer [NodeConformance]
      tear down framework | framework.go:193
    STEP: Destroying namespace "init-container-3974" for this suite. 04/23/23 12:49:34.246
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:92
[BeforeEach] [sig-apps] ReplicationController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:49:34.267
Apr 23 12:49:34.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename replication-controller 04/23/23 12:49:34.283
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:34.353
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:34.358
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:57
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:92
STEP: Given a Pod with a 'name' label pod-adoption is created 04/23/23 12:49:34.373
Apr 23 12:49:34.408: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-2047" to be "running and ready"
Apr 23 12:49:34.420: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 11.645579ms
Apr 23 12:49:34.420: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:49:36.428: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020017783s
Apr 23 12:49:36.428: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:49:38.432: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 4.024019136s
Apr 23 12:49:38.432: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Apr 23 12:49:38.432: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 04/23/23 12:49:38.442
STEP: Then the orphan pod is adopted 04/23/23 12:49:38.463
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/node/init/init.go:32
Apr 23 12:49:39.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicationController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicationController
  tear down framework | framework.go:193
STEP: Destroying namespace "replication-controller-2047" for this suite. 04/23/23 12:49:39.515
------------------------------
â€¢ [SLOW TEST] [5.270 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:49:34.267
    Apr 23 12:49:34.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename replication-controller 04/23/23 12:49:34.283
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:34.353
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:34.358
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:57
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:92
    STEP: Given a Pod with a 'name' label pod-adoption is created 04/23/23 12:49:34.373
    Apr 23 12:49:34.408: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-2047" to be "running and ready"
    Apr 23 12:49:34.420: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 11.645579ms
    Apr 23 12:49:34.420: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:49:36.428: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020017783s
    Apr 23 12:49:36.428: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:49:38.432: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 4.024019136s
    Apr 23 12:49:38.432: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Apr 23 12:49:38.432: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 04/23/23 12:49:38.442
    STEP: Then the orphan pod is adopted 04/23/23 12:49:38.463
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:49:39.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      tear down framework | framework.go:193
    STEP: Destroying namespace "replication-controller-2047" for this suite. 04/23/23 12:49:39.515
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:49:39.538
Apr 23 12:49:39.538: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename dns 04/23/23 12:49:39.543
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:39.585
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:39.589
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 04/23/23 12:49:39.595
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local;sleep 1; done
 04/23/23 12:49:39.604
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-653.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local;sleep 1; done
 04/23/23 12:49:39.604
STEP: creating a pod to probe DNS 04/23/23 12:49:39.605
STEP: submitting the pod to kubernetes 04/23/23 12:49:39.605
Apr 23 12:49:39.622: INFO: Waiting up to 15m0s for pod "dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7" in namespace "dns-653" to be "running"
Apr 23 12:49:39.627: INFO: Pod "dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.512158ms
Apr 23 12:49:41.653: INFO: Pod "dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030886433s
Apr 23 12:49:43.638: INFO: Pod "dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015616736s
Apr 23 12:49:45.636: INFO: Pod "dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7": Phase="Running", Reason="", readiness=true. Elapsed: 6.013672897s
Apr 23 12:49:45.636: INFO: Pod "dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7" satisfied condition "running"
STEP: retrieving the pod 04/23/23 12:49:45.637
STEP: looking for the results for each expected name from probers 04/23/23 12:49:45.644
Apr 23 12:49:45.661: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:45.702: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:45.718: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:45.748: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:45.757: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:45.774: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:45.784: INFO: Unable to read jessie_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:45.792: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:45.792: INFO: Lookups using dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local]

Apr 23 12:49:50.801: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:50.810: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:50.818: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:50.831: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:50.839: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:50.847: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:50.857: INFO: Unable to read jessie_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:50.870: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:50.870: INFO: Lookups using dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local]

Apr 23 12:49:55.802: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:55.810: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:55.820: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:55.827: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:55.834: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:55.840: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:55.846: INFO: Unable to read jessie_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:55.853: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:49:55.853: INFO: Lookups using dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local]

Apr 23 12:50:00.802: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:00.809: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:00.817: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:00.824: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:00.832: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:00.840: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:00.853: INFO: Unable to read jessie_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:00.878: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:00.878: INFO: Lookups using dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local]

Apr 23 12:50:05.815: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:05.826: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:05.834: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:05.843: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:05.850: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:05.863: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:05.870: INFO: Unable to read jessie_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:05.880: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:05.880: INFO: Lookups using dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local]

Apr 23 12:50:10.801: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:10.812: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:10.824: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:10.835: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:10.845: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:10.857: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:10.866: INFO: Unable to read jessie_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:10.877: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
Apr 23 12:50:10.877: INFO: Lookups using dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local]

Apr 23 12:50:15.857: INFO: DNS probes using dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7 succeeded

STEP: deleting the pod 04/23/23 12:50:15.857
STEP: deleting the test headless service 04/23/23 12:50:15.897
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Apr 23 12:50:15.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-653" for this suite. 04/23/23 12:50:15.928
------------------------------
â€¢ [SLOW TEST] [36.403 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:49:39.538
    Apr 23 12:49:39.538: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename dns 04/23/23 12:49:39.543
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:49:39.585
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:49:39.589
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 04/23/23 12:49:39.595
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local;sleep 1; done
     04/23/23 12:49:39.604
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-653.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-653.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local;sleep 1; done
     04/23/23 12:49:39.604
    STEP: creating a pod to probe DNS 04/23/23 12:49:39.605
    STEP: submitting the pod to kubernetes 04/23/23 12:49:39.605
    Apr 23 12:49:39.622: INFO: Waiting up to 15m0s for pod "dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7" in namespace "dns-653" to be "running"
    Apr 23 12:49:39.627: INFO: Pod "dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.512158ms
    Apr 23 12:49:41.653: INFO: Pod "dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030886433s
    Apr 23 12:49:43.638: INFO: Pod "dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015616736s
    Apr 23 12:49:45.636: INFO: Pod "dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7": Phase="Running", Reason="", readiness=true. Elapsed: 6.013672897s
    Apr 23 12:49:45.636: INFO: Pod "dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7" satisfied condition "running"
    STEP: retrieving the pod 04/23/23 12:49:45.637
    STEP: looking for the results for each expected name from probers 04/23/23 12:49:45.644
    Apr 23 12:49:45.661: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:45.702: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:45.718: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:45.748: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:45.757: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:45.774: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:45.784: INFO: Unable to read jessie_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:45.792: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:45.792: INFO: Lookups using dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local]

    Apr 23 12:49:50.801: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:50.810: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:50.818: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:50.831: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:50.839: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:50.847: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:50.857: INFO: Unable to read jessie_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:50.870: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:50.870: INFO: Lookups using dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local]

    Apr 23 12:49:55.802: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:55.810: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:55.820: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:55.827: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:55.834: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:55.840: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:55.846: INFO: Unable to read jessie_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:55.853: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:49:55.853: INFO: Lookups using dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local]

    Apr 23 12:50:00.802: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:00.809: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:00.817: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:00.824: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:00.832: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:00.840: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:00.853: INFO: Unable to read jessie_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:00.878: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:00.878: INFO: Lookups using dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local]

    Apr 23 12:50:05.815: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:05.826: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:05.834: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:05.843: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:05.850: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:05.863: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:05.870: INFO: Unable to read jessie_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:05.880: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:05.880: INFO: Lookups using dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local]

    Apr 23 12:50:10.801: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:10.812: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:10.824: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:10.835: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:10.845: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:10.857: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:10.866: INFO: Unable to read jessie_udp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:10.877: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local from pod dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7: the server could not find the requested resource (get pods dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7)
    Apr 23 12:50:10.877: INFO: Lookups using dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local wheezy_udp@dns-test-service-2.dns-653.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-653.svc.cluster.local jessie_udp@dns-test-service-2.dns-653.svc.cluster.local jessie_tcp@dns-test-service-2.dns-653.svc.cluster.local]

    Apr 23 12:50:15.857: INFO: DNS probes using dns-653/dns-test-35b48ea9-bc5a-4d8e-9f4a-17b01cdcfbc7 succeeded

    STEP: deleting the pod 04/23/23 12:50:15.857
    STEP: deleting the test headless service 04/23/23 12:50:15.897
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:50:15.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-653" for this suite. 04/23/23 12:50:15.928
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:162
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:50:15.942
Apr 23 12:50:15.942: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 12:50:15.947
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:50:15.987
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:50:15.992
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:162
STEP: Creating the pod 04/23/23 12:50:15.997
Apr 23 12:50:16.016: INFO: Waiting up to 5m0s for pod "annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4" in namespace "projected-6098" to be "running and ready"
Apr 23 12:50:16.047: INFO: Pod "annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4": Phase="Pending", Reason="", readiness=false. Elapsed: 30.721773ms
Apr 23 12:50:16.047: INFO: The phase of Pod annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:50:18.055: INFO: Pod "annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039138919s
Apr 23 12:50:18.055: INFO: The phase of Pod annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:50:20.060: INFO: Pod "annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4": Phase="Running", Reason="", readiness=true. Elapsed: 4.044220508s
Apr 23 12:50:20.060: INFO: The phase of Pod annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4 is Running (Ready = true)
Apr 23 12:50:20.060: INFO: Pod "annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4" satisfied condition "running and ready"
Apr 23 12:50:20.633: INFO: Successfully updated pod "annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Apr 23 12:50:24.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-6098" for this suite. 04/23/23 12:50:24.706
------------------------------
â€¢ [SLOW TEST] [8.780 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:162

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:50:15.942
    Apr 23 12:50:15.942: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 12:50:15.947
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:50:15.987
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:50:15.992
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:162
    STEP: Creating the pod 04/23/23 12:50:15.997
    Apr 23 12:50:16.016: INFO: Waiting up to 5m0s for pod "annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4" in namespace "projected-6098" to be "running and ready"
    Apr 23 12:50:16.047: INFO: Pod "annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4": Phase="Pending", Reason="", readiness=false. Elapsed: 30.721773ms
    Apr 23 12:50:16.047: INFO: The phase of Pod annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:50:18.055: INFO: Pod "annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039138919s
    Apr 23 12:50:18.055: INFO: The phase of Pod annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:50:20.060: INFO: Pod "annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4": Phase="Running", Reason="", readiness=true. Elapsed: 4.044220508s
    Apr 23 12:50:20.060: INFO: The phase of Pod annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4 is Running (Ready = true)
    Apr 23 12:50:20.060: INFO: Pod "annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4" satisfied condition "running and ready"
    Apr 23 12:50:20.633: INFO: Successfully updated pod "annotationupdate12d1f5cb-b7cb-4560-b516-d5ec42b923f4"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:50:24.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-6098" for this suite. 04/23/23 12:50:24.706
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:83
[BeforeEach] [sig-apps] ReplicationController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:50:24.724
Apr 23 12:50:24.726: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename replication-controller 04/23/23 12:50:24.729
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:50:24.773
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:50:24.778
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:57
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:83
Apr 23 12:50:24.784: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 04/23/23 12:50:24.813
STEP: Checking rc "condition-test" has the desired failure condition set 04/23/23 12:50:24.825
STEP: Scaling down rc "condition-test" to satisfy pod quota 04/23/23 12:50:25.856
Apr 23 12:50:25.879: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 04/23/23 12:50:25.879
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/node/init/init.go:32
Apr 23 12:50:26.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicationController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicationController
  tear down framework | framework.go:193
STEP: Destroying namespace "replication-controller-5774" for this suite. 04/23/23 12:50:26.915
------------------------------
â€¢ [2.202 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:50:24.724
    Apr 23 12:50:24.726: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename replication-controller 04/23/23 12:50:24.729
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:50:24.773
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:50:24.778
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:57
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:83
    Apr 23 12:50:24.784: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 04/23/23 12:50:24.813
    STEP: Checking rc "condition-test" has the desired failure condition set 04/23/23 12:50:24.825
    STEP: Scaling down rc "condition-test" to satisfy pod quota 04/23/23 12:50:25.856
    Apr 23 12:50:25.879: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 04/23/23 12:50:25.879
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:50:26.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      tear down framework | framework.go:193
    STEP: Destroying namespace "replication-controller-5774" for this suite. 04/23/23 12:50:26.915
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:291
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:50:26.934
Apr 23 12:50:26.934: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 12:50:26.936
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:50:26.983
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:50:26.992
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 12:50:27.06
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:50:27.698
STEP: Deploying the webhook pod 04/23/23 12:50:27.715
STEP: Wait for the deployment to be ready 04/23/23 12:50:27.752
Apr 23 12:50:27.770: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 23 12:50:29.837: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:50:31.845: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/23/23 12:50:33.845
STEP: Verifying the service has paired with the endpoint 04/23/23 12:50:33.864
Apr 23 12:50:34.865: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:291
Apr 23 12:50:34.875: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7621-crds.webhook.example.com via the AdmissionRegistration API 04/23/23 12:50:35.401
STEP: Creating a custom resource that should be mutated by the webhook 04/23/23 12:50:35.437
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:50:38.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-865" for this suite. 04/23/23 12:50:38.276
STEP: Destroying namespace "webhook-865-markers" for this suite. 04/23/23 12:50:38.306
------------------------------
â€¢ [SLOW TEST] [11.393 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:291

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:50:26.934
    Apr 23 12:50:26.934: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 12:50:26.936
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:50:26.983
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:50:26.992
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 12:50:27.06
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:50:27.698
    STEP: Deploying the webhook pod 04/23/23 12:50:27.715
    STEP: Wait for the deployment to be ready 04/23/23 12:50:27.752
    Apr 23 12:50:27.770: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 23 12:50:29.837: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:50:31.845: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 50, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/23/23 12:50:33.845
    STEP: Verifying the service has paired with the endpoint 04/23/23 12:50:33.864
    Apr 23 12:50:34.865: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:291
    Apr 23 12:50:34.875: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7621-crds.webhook.example.com via the AdmissionRegistration API 04/23/23 12:50:35.401
    STEP: Creating a custom resource that should be mutated by the webhook 04/23/23 12:50:35.437
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:50:38.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-865" for this suite. 04/23/23 12:50:38.276
    STEP: Destroying namespace "webhook-865-markers" for this suite. 04/23/23 12:50:38.306
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:50:38.349
Apr 23 12:50:38.349: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename sysctl 04/23/23 12:50:38.354
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:50:38.424
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:50:38.428
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 04/23/23 12:50:38.433
STEP: Watching for error events or started pod 04/23/23 12:50:38.46
STEP: Waiting for pod completion 04/23/23 12:50:42.47
Apr 23 12:50:42.470: INFO: Waiting up to 3m0s for pod "sysctl-7db0d779-373d-44a8-943e-4429d1e49b1e" in namespace "sysctl-566" to be "completed"
Apr 23 12:50:42.478: INFO: Pod "sysctl-7db0d779-373d-44a8-943e-4429d1e49b1e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.709323ms
Apr 23 12:50:44.492: INFO: Pod "sysctl-7db0d779-373d-44a8-943e-4429d1e49b1e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022357214s
Apr 23 12:50:46.488: INFO: Pod "sysctl-7db0d779-373d-44a8-943e-4429d1e49b1e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018346417s
Apr 23 12:50:46.488: INFO: Pod "sysctl-7db0d779-373d-44a8-943e-4429d1e49b1e" satisfied condition "completed"
STEP: Checking that the pod succeeded 04/23/23 12:50:46.495
STEP: Getting logs from the pod 04/23/23 12:50:46.496
STEP: Checking that the sysctl is actually updated 04/23/23 12:50:46.519
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:50:46.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  tear down framework | framework.go:193
STEP: Destroying namespace "sysctl-566" for this suite. 04/23/23 12:50:46.54
------------------------------
â€¢ [SLOW TEST] [8.219 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:50:38.349
    Apr 23 12:50:38.349: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename sysctl 04/23/23 12:50:38.354
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:50:38.424
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:50:38.428
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 04/23/23 12:50:38.433
    STEP: Watching for error events or started pod 04/23/23 12:50:38.46
    STEP: Waiting for pod completion 04/23/23 12:50:42.47
    Apr 23 12:50:42.470: INFO: Waiting up to 3m0s for pod "sysctl-7db0d779-373d-44a8-943e-4429d1e49b1e" in namespace "sysctl-566" to be "completed"
    Apr 23 12:50:42.478: INFO: Pod "sysctl-7db0d779-373d-44a8-943e-4429d1e49b1e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.709323ms
    Apr 23 12:50:44.492: INFO: Pod "sysctl-7db0d779-373d-44a8-943e-4429d1e49b1e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022357214s
    Apr 23 12:50:46.488: INFO: Pod "sysctl-7db0d779-373d-44a8-943e-4429d1e49b1e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018346417s
    Apr 23 12:50:46.488: INFO: Pod "sysctl-7db0d779-373d-44a8-943e-4429d1e49b1e" satisfied condition "completed"
    STEP: Checking that the pod succeeded 04/23/23 12:50:46.495
    STEP: Getting logs from the pod 04/23/23 12:50:46.496
    STEP: Checking that the sysctl is actually updated 04/23/23 12:50:46.519
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:50:46.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      tear down framework | framework.go:193
    STEP: Destroying namespace "sysctl-566" for this suite. 04/23/23 12:50:46.54
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:152
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:50:46.578
Apr 23 12:50:46.578: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename var-expansion 04/23/23 12:50:46.581
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:50:46.639
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:50:46.644
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:152
Apr 23 12:50:46.669: INFO: Waiting up to 2m0s for pod "var-expansion-52e45ed1-e87a-4299-b2da-2766969d6dc0" in namespace "var-expansion-9862" to be "container 0 failed with reason CreateContainerConfigError"
Apr 23 12:50:46.677: INFO: Pod "var-expansion-52e45ed1-e87a-4299-b2da-2766969d6dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.096862ms
Apr 23 12:50:48.686: INFO: Pod "var-expansion-52e45ed1-e87a-4299-b2da-2766969d6dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016799101s
Apr 23 12:50:48.686: INFO: Pod "var-expansion-52e45ed1-e87a-4299-b2da-2766969d6dc0" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Apr 23 12:50:48.686: INFO: Deleting pod "var-expansion-52e45ed1-e87a-4299-b2da-2766969d6dc0" in namespace "var-expansion-9862"
Apr 23 12:50:48.702: INFO: Wait up to 5m0s for pod "var-expansion-52e45ed1-e87a-4299-b2da-2766969d6dc0" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Apr 23 12:50:52.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-9862" for this suite. 04/23/23 12:50:52.728
------------------------------
â€¢ [SLOW TEST] [6.166 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:50:46.578
    Apr 23 12:50:46.578: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename var-expansion 04/23/23 12:50:46.581
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:50:46.639
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:50:46.644
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:152
    Apr 23 12:50:46.669: INFO: Waiting up to 2m0s for pod "var-expansion-52e45ed1-e87a-4299-b2da-2766969d6dc0" in namespace "var-expansion-9862" to be "container 0 failed with reason CreateContainerConfigError"
    Apr 23 12:50:46.677: INFO: Pod "var-expansion-52e45ed1-e87a-4299-b2da-2766969d6dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.096862ms
    Apr 23 12:50:48.686: INFO: Pod "var-expansion-52e45ed1-e87a-4299-b2da-2766969d6dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016799101s
    Apr 23 12:50:48.686: INFO: Pod "var-expansion-52e45ed1-e87a-4299-b2da-2766969d6dc0" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Apr 23 12:50:48.686: INFO: Deleting pod "var-expansion-52e45ed1-e87a-4299-b2da-2766969d6dc0" in namespace "var-expansion-9862"
    Apr 23 12:50:48.702: INFO: Wait up to 5m0s for pod "var-expansion-52e45ed1-e87a-4299-b2da-2766969d6dc0" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:50:52.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-9862" for this suite. 04/23/23 12:50:52.728
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:252
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:50:52.752
Apr 23 12:50:52.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 12:50:52.754
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:50:52.792
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:50:52.798
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 12:50:52.846
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:50:53.822
STEP: Deploying the webhook pod 04/23/23 12:50:53.836
STEP: Wait for the deployment to be ready 04/23/23 12:50:53.858
Apr 23 12:50:53.872: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Apr 23 12:50:55.896: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 50, 53, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 50, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 50, 53, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 50, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/23/23 12:50:57.909
STEP: Verifying the service has paired with the endpoint 04/23/23 12:50:57.949
Apr 23 12:50:58.950: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:252
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 04/23/23 12:50:58.965
Apr 23 12:50:59.011: INFO: Waiting for webhook configuration to be ready...
STEP: create a configmap that should be updated by the webhook 04/23/23 12:50:59.137
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:50:59.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-5469" for this suite. 04/23/23 12:50:59.336
STEP: Destroying namespace "webhook-5469-markers" for this suite. 04/23/23 12:50:59.366
------------------------------
â€¢ [SLOW TEST] [6.630 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:252

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:50:52.752
    Apr 23 12:50:52.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 12:50:52.754
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:50:52.792
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:50:52.798
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 12:50:52.846
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:50:53.822
    STEP: Deploying the webhook pod 04/23/23 12:50:53.836
    STEP: Wait for the deployment to be ready 04/23/23 12:50:53.858
    Apr 23 12:50:53.872: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Apr 23 12:50:55.896: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 50, 53, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 50, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 50, 53, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 50, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/23/23 12:50:57.909
    STEP: Verifying the service has paired with the endpoint 04/23/23 12:50:57.949
    Apr 23 12:50:58.950: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:252
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 04/23/23 12:50:58.965
    Apr 23 12:50:59.011: INFO: Waiting for webhook configuration to be ready...
    STEP: create a configmap that should be updated by the webhook 04/23/23 12:50:59.137
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:50:59.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-5469" for this suite. 04/23/23 12:50:59.336
    STEP: Destroying namespace "webhook-5469-markers" for this suite. 04/23/23 12:50:59.366
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:221
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:50:59.387
Apr 23 12:50:59.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 12:50:59.398
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:50:59.457
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:50:59.467
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:221
STEP: Creating a pod to test downward API volume plugin 04/23/23 12:50:59.494
Apr 23 12:50:59.526: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399" in namespace "projected-6466" to be "Succeeded or Failed"
Apr 23 12:50:59.555: INFO: Pod "downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399": Phase="Pending", Reason="", readiness=false. Elapsed: 28.195432ms
Apr 23 12:51:01.572: INFO: Pod "downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045693203s
Apr 23 12:51:03.562: INFO: Pod "downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03585074s
Apr 23 12:51:05.565: INFO: Pod "downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038782056s
Apr 23 12:51:07.563: INFO: Pod "downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.035952208s
STEP: Saw pod success 04/23/23 12:51:07.563
Apr 23 12:51:07.563: INFO: Pod "downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399" satisfied condition "Succeeded or Failed"
Apr 23 12:51:07.572: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399 container client-container: <nil>
STEP: delete the pod 04/23/23 12:51:07.676
Apr 23 12:51:07.695: INFO: Waiting for pod downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399 to disappear
Apr 23 12:51:07.713: INFO: Pod downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Apr 23 12:51:07.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-6466" for this suite. 04/23/23 12:51:07.753
------------------------------
â€¢ [SLOW TEST] [8.382 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:50:59.387
    Apr 23 12:50:59.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 12:50:59.398
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:50:59.457
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:50:59.467
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:221
    STEP: Creating a pod to test downward API volume plugin 04/23/23 12:50:59.494
    Apr 23 12:50:59.526: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399" in namespace "projected-6466" to be "Succeeded or Failed"
    Apr 23 12:50:59.555: INFO: Pod "downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399": Phase="Pending", Reason="", readiness=false. Elapsed: 28.195432ms
    Apr 23 12:51:01.572: INFO: Pod "downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045693203s
    Apr 23 12:51:03.562: INFO: Pod "downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03585074s
    Apr 23 12:51:05.565: INFO: Pod "downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038782056s
    Apr 23 12:51:07.563: INFO: Pod "downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.035952208s
    STEP: Saw pod success 04/23/23 12:51:07.563
    Apr 23 12:51:07.563: INFO: Pod "downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399" satisfied condition "Succeeded or Failed"
    Apr 23 12:51:07.572: INFO: Trying to get logs from node eingavuivie7-3 pod downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399 container client-container: <nil>
    STEP: delete the pod 04/23/23 12:51:07.676
    Apr 23 12:51:07.695: INFO: Waiting for pod downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399 to disappear
    Apr 23 12:51:07.713: INFO: Pod downwardapi-volume-3892eeeb-3520-47dd-851e-1c27dffc0399 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:51:07.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-6466" for this suite. 04/23/23 12:51:07.753
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:51:07.77
Apr 23 12:51:07.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename server-version 04/23/23 12:51:07.772
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:51:07.814
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:51:07.818
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/metrics/init/init.go:31
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 04/23/23 12:51:07.823
STEP: Confirm major version 04/23/23 12:51:07.825
Apr 23 12:51:07.825: INFO: Major version: 1
STEP: Confirm minor version 04/23/23 12:51:07.825
Apr 23 12:51:07.825: INFO: cleanMinorVersion: 26
Apr 23 12:51:07.825: INFO: Minor version: 26
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/node/init/init.go:32
Apr 23 12:51:07.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] server version
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] server version
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] server version
  tear down framework | framework.go:193
STEP: Destroying namespace "server-version-9126" for this suite. 04/23/23 12:51:07.833
------------------------------
â€¢ [0.076 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:51:07.77
    Apr 23 12:51:07.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename server-version 04/23/23 12:51:07.772
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:51:07.814
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:51:07.818
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/metrics/init/init.go:31
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 04/23/23 12:51:07.823
    STEP: Confirm major version 04/23/23 12:51:07.825
    Apr 23 12:51:07.825: INFO: Major version: 1
    STEP: Confirm minor version 04/23/23 12:51:07.825
    Apr 23 12:51:07.825: INFO: cleanMinorVersion: 26
    Apr 23 12:51:07.825: INFO: Minor version: 26
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:51:07.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] server version
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] server version
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] server version
      tear down framework | framework.go:193
    STEP: Destroying namespace "server-version-9126" for this suite. 04/23/23 12:51:07.833
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:51:07.858
Apr 23 12:51:07.858: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir-wrapper 04/23/23 12:51:07.865
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:51:07.901
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:51:07.907
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 04/23/23 12:51:07.914
STEP: Creating RC which spawns configmap-volume pods 04/23/23 12:51:08.709
Apr 23 12:51:08.754: INFO: Pod name wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9: Found 0 pods out of 5
Apr 23 12:51:13.771: INFO: Pod name wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/23/23 12:51:13.771
Apr 23 12:51:13.771: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:51:13.786: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv": Phase="Pending", Reason="", readiness=false. Elapsed: 14.378835ms
Apr 23 12:51:15.796: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024196837s
Apr 23 12:51:17.798: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026045253s
Apr 23 12:51:19.795: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023622276s
Apr 23 12:51:21.797: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.025063411s
Apr 23 12:51:23.806: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv": Phase="Pending", Reason="", readiness=false. Elapsed: 10.034232198s
Apr 23 12:51:25.804: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv": Phase="Running", Reason="", readiness=true. Elapsed: 12.032006049s
Apr 23 12:51:25.804: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv" satisfied condition "running"
Apr 23 12:51:25.804: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-dzhh4" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:51:25.812: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-dzhh4": Phase="Running", Reason="", readiness=true. Elapsed: 8.214467ms
Apr 23 12:51:25.812: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-dzhh4" satisfied condition "running"
Apr 23 12:51:25.812: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-jk6cr" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:51:25.821: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-jk6cr": Phase="Pending", Reason="", readiness=false. Elapsed: 8.286414ms
Apr 23 12:51:27.831: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-jk6cr": Phase="Running", Reason="", readiness=true. Elapsed: 2.018057162s
Apr 23 12:51:27.831: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-jk6cr" satisfied condition "running"
Apr 23 12:51:27.831: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-pbdxc" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:51:27.837: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-pbdxc": Phase="Running", Reason="", readiness=true. Elapsed: 5.932337ms
Apr 23 12:51:27.837: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-pbdxc" satisfied condition "running"
Apr 23 12:51:27.837: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-pxh4d" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:51:27.845: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-pxh4d": Phase="Running", Reason="", readiness=true. Elapsed: 7.784948ms
Apr 23 12:51:27.845: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-pxh4d" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9 in namespace emptydir-wrapper-2385, will wait for the garbage collector to delete the pods 04/23/23 12:51:27.845
Apr 23 12:51:27.921: INFO: Deleting ReplicationController wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9 took: 16.828962ms
Apr 23 12:51:28.022: INFO: Terminating ReplicationController wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9 pods took: 100.926721ms
STEP: Creating RC which spawns configmap-volume pods 04/23/23 12:51:31.63
Apr 23 12:51:31.657: INFO: Pod name wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900: Found 0 pods out of 5
Apr 23 12:51:36.685: INFO: Pod name wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/23/23 12:51:36.686
Apr 23 12:51:36.687: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:51:36.696: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.725755ms
Apr 23 12:51:38.714: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027223358s
Apr 23 12:51:40.707: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020292222s
Apr 23 12:51:42.707: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019637879s
Apr 23 12:51:44.721: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.033997925s
Apr 23 12:51:46.716: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.029431914s
Apr 23 12:51:48.706: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.019451134s
Apr 23 12:51:50.704: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Running", Reason="", readiness=true. Elapsed: 14.017552236s
Apr 23 12:51:50.705: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8" satisfied condition "running"
Apr 23 12:51:50.705: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-cftbh" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:51:50.713: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-cftbh": Phase="Running", Reason="", readiness=true. Elapsed: 8.091032ms
Apr 23 12:51:50.713: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-cftbh" satisfied condition "running"
Apr 23 12:51:50.713: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-jsqkp" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:51:50.722: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-jsqkp": Phase="Running", Reason="", readiness=true. Elapsed: 8.276722ms
Apr 23 12:51:50.722: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-jsqkp" satisfied condition "running"
Apr 23 12:51:50.722: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-lgmr2" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:51:50.730: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-lgmr2": Phase="Running", Reason="", readiness=true. Elapsed: 8.460815ms
Apr 23 12:51:50.730: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-lgmr2" satisfied condition "running"
Apr 23 12:51:50.730: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-md7lp" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:51:50.737: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-md7lp": Phase="Running", Reason="", readiness=true. Elapsed: 6.845375ms
Apr 23 12:51:50.737: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-md7lp" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900 in namespace emptydir-wrapper-2385, will wait for the garbage collector to delete the pods 04/23/23 12:51:50.738
Apr 23 12:51:50.814: INFO: Deleting ReplicationController wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900 took: 13.157171ms
Apr 23 12:51:51.215: INFO: Terminating ReplicationController wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900 pods took: 400.927992ms
STEP: Creating RC which spawns configmap-volume pods 04/23/23 12:51:55.225
Apr 23 12:51:55.251: INFO: Pod name wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2: Found 0 pods out of 5
Apr 23 12:52:00.281: INFO: Pod name wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/23/23 12:52:00.282
Apr 23 12:52:00.282: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-27cg2" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:52:00.289: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-27cg2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.899882ms
Apr 23 12:52:02.297: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-27cg2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014725167s
Apr 23 12:52:04.300: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-27cg2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01769938s
Apr 23 12:52:06.298: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-27cg2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015682348s
Apr 23 12:52:08.296: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-27cg2": Phase="Running", Reason="", readiness=true. Elapsed: 8.0144001s
Apr 23 12:52:08.297: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-27cg2" satisfied condition "running"
Apr 23 12:52:08.297: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-jwd9j" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:52:08.310: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-jwd9j": Phase="Running", Reason="", readiness=true. Elapsed: 13.597039ms
Apr 23 12:52:08.311: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-jwd9j" satisfied condition "running"
Apr 23 12:52:08.311: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-rzzbb" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:52:08.321: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-rzzbb": Phase="Running", Reason="", readiness=true. Elapsed: 10.273131ms
Apr 23 12:52:08.321: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-rzzbb" satisfied condition "running"
Apr 23 12:52:08.321: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-vlkq8" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:52:08.328: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-vlkq8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.105845ms
Apr 23 12:52:10.345: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-vlkq8": Phase="Running", Reason="", readiness=true. Elapsed: 2.023607292s
Apr 23 12:52:10.345: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-vlkq8" satisfied condition "running"
Apr 23 12:52:10.345: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-wt4wt" in namespace "emptydir-wrapper-2385" to be "running"
Apr 23 12:52:10.354: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-wt4wt": Phase="Running", Reason="", readiness=true. Elapsed: 8.430441ms
Apr 23 12:52:10.354: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-wt4wt" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2 in namespace emptydir-wrapper-2385, will wait for the garbage collector to delete the pods 04/23/23 12:52:10.354
Apr 23 12:52:10.431: INFO: Deleting ReplicationController wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2 took: 17.638721ms
Apr 23 12:52:10.632: INFO: Terminating ReplicationController wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2 pods took: 201.167445ms
STEP: Cleaning up the configMaps 04/23/23 12:52:18.133
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 12:52:18.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-wrapper-2385" for this suite. 04/23/23 12:52:18.87
------------------------------
â€¢ [SLOW TEST] [71.024 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:51:07.858
    Apr 23 12:51:07.858: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir-wrapper 04/23/23 12:51:07.865
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:51:07.901
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:51:07.907
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 04/23/23 12:51:07.914
    STEP: Creating RC which spawns configmap-volume pods 04/23/23 12:51:08.709
    Apr 23 12:51:08.754: INFO: Pod name wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9: Found 0 pods out of 5
    Apr 23 12:51:13.771: INFO: Pod name wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/23/23 12:51:13.771
    Apr 23 12:51:13.771: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:51:13.786: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv": Phase="Pending", Reason="", readiness=false. Elapsed: 14.378835ms
    Apr 23 12:51:15.796: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024196837s
    Apr 23 12:51:17.798: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026045253s
    Apr 23 12:51:19.795: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023622276s
    Apr 23 12:51:21.797: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.025063411s
    Apr 23 12:51:23.806: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv": Phase="Pending", Reason="", readiness=false. Elapsed: 10.034232198s
    Apr 23 12:51:25.804: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv": Phase="Running", Reason="", readiness=true. Elapsed: 12.032006049s
    Apr 23 12:51:25.804: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-249cv" satisfied condition "running"
    Apr 23 12:51:25.804: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-dzhh4" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:51:25.812: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-dzhh4": Phase="Running", Reason="", readiness=true. Elapsed: 8.214467ms
    Apr 23 12:51:25.812: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-dzhh4" satisfied condition "running"
    Apr 23 12:51:25.812: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-jk6cr" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:51:25.821: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-jk6cr": Phase="Pending", Reason="", readiness=false. Elapsed: 8.286414ms
    Apr 23 12:51:27.831: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-jk6cr": Phase="Running", Reason="", readiness=true. Elapsed: 2.018057162s
    Apr 23 12:51:27.831: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-jk6cr" satisfied condition "running"
    Apr 23 12:51:27.831: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-pbdxc" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:51:27.837: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-pbdxc": Phase="Running", Reason="", readiness=true. Elapsed: 5.932337ms
    Apr 23 12:51:27.837: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-pbdxc" satisfied condition "running"
    Apr 23 12:51:27.837: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-pxh4d" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:51:27.845: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-pxh4d": Phase="Running", Reason="", readiness=true. Elapsed: 7.784948ms
    Apr 23 12:51:27.845: INFO: Pod "wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9-pxh4d" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9 in namespace emptydir-wrapper-2385, will wait for the garbage collector to delete the pods 04/23/23 12:51:27.845
    Apr 23 12:51:27.921: INFO: Deleting ReplicationController wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9 took: 16.828962ms
    Apr 23 12:51:28.022: INFO: Terminating ReplicationController wrapped-volume-race-20c8fbe4-8725-45fa-9095-9fec8558cfe9 pods took: 100.926721ms
    STEP: Creating RC which spawns configmap-volume pods 04/23/23 12:51:31.63
    Apr 23 12:51:31.657: INFO: Pod name wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900: Found 0 pods out of 5
    Apr 23 12:51:36.685: INFO: Pod name wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/23/23 12:51:36.686
    Apr 23 12:51:36.687: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:51:36.696: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.725755ms
    Apr 23 12:51:38.714: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027223358s
    Apr 23 12:51:40.707: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020292222s
    Apr 23 12:51:42.707: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019637879s
    Apr 23 12:51:44.721: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.033997925s
    Apr 23 12:51:46.716: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.029431914s
    Apr 23 12:51:48.706: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.019451134s
    Apr 23 12:51:50.704: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8": Phase="Running", Reason="", readiness=true. Elapsed: 14.017552236s
    Apr 23 12:51:50.705: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-66mz8" satisfied condition "running"
    Apr 23 12:51:50.705: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-cftbh" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:51:50.713: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-cftbh": Phase="Running", Reason="", readiness=true. Elapsed: 8.091032ms
    Apr 23 12:51:50.713: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-cftbh" satisfied condition "running"
    Apr 23 12:51:50.713: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-jsqkp" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:51:50.722: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-jsqkp": Phase="Running", Reason="", readiness=true. Elapsed: 8.276722ms
    Apr 23 12:51:50.722: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-jsqkp" satisfied condition "running"
    Apr 23 12:51:50.722: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-lgmr2" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:51:50.730: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-lgmr2": Phase="Running", Reason="", readiness=true. Elapsed: 8.460815ms
    Apr 23 12:51:50.730: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-lgmr2" satisfied condition "running"
    Apr 23 12:51:50.730: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-md7lp" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:51:50.737: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-md7lp": Phase="Running", Reason="", readiness=true. Elapsed: 6.845375ms
    Apr 23 12:51:50.737: INFO: Pod "wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900-md7lp" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900 in namespace emptydir-wrapper-2385, will wait for the garbage collector to delete the pods 04/23/23 12:51:50.738
    Apr 23 12:51:50.814: INFO: Deleting ReplicationController wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900 took: 13.157171ms
    Apr 23 12:51:51.215: INFO: Terminating ReplicationController wrapped-volume-race-44eee2fc-323c-42f7-8d67-cc181e2d9900 pods took: 400.927992ms
    STEP: Creating RC which spawns configmap-volume pods 04/23/23 12:51:55.225
    Apr 23 12:51:55.251: INFO: Pod name wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2: Found 0 pods out of 5
    Apr 23 12:52:00.281: INFO: Pod name wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/23/23 12:52:00.282
    Apr 23 12:52:00.282: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-27cg2" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:52:00.289: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-27cg2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.899882ms
    Apr 23 12:52:02.297: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-27cg2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014725167s
    Apr 23 12:52:04.300: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-27cg2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01769938s
    Apr 23 12:52:06.298: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-27cg2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015682348s
    Apr 23 12:52:08.296: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-27cg2": Phase="Running", Reason="", readiness=true. Elapsed: 8.0144001s
    Apr 23 12:52:08.297: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-27cg2" satisfied condition "running"
    Apr 23 12:52:08.297: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-jwd9j" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:52:08.310: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-jwd9j": Phase="Running", Reason="", readiness=true. Elapsed: 13.597039ms
    Apr 23 12:52:08.311: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-jwd9j" satisfied condition "running"
    Apr 23 12:52:08.311: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-rzzbb" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:52:08.321: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-rzzbb": Phase="Running", Reason="", readiness=true. Elapsed: 10.273131ms
    Apr 23 12:52:08.321: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-rzzbb" satisfied condition "running"
    Apr 23 12:52:08.321: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-vlkq8" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:52:08.328: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-vlkq8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.105845ms
    Apr 23 12:52:10.345: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-vlkq8": Phase="Running", Reason="", readiness=true. Elapsed: 2.023607292s
    Apr 23 12:52:10.345: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-vlkq8" satisfied condition "running"
    Apr 23 12:52:10.345: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-wt4wt" in namespace "emptydir-wrapper-2385" to be "running"
    Apr 23 12:52:10.354: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-wt4wt": Phase="Running", Reason="", readiness=true. Elapsed: 8.430441ms
    Apr 23 12:52:10.354: INFO: Pod "wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2-wt4wt" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2 in namespace emptydir-wrapper-2385, will wait for the garbage collector to delete the pods 04/23/23 12:52:10.354
    Apr 23 12:52:10.431: INFO: Deleting ReplicationController wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2 took: 17.638721ms
    Apr 23 12:52:10.632: INFO: Terminating ReplicationController wrapped-volume-race-00fbda76-f519-4f3e-842e-3ac82b142fb2 pods took: 201.167445ms
    STEP: Cleaning up the configMaps 04/23/23 12:52:18.133
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:52:18.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir wrapper volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-wrapper-2385" for this suite. 04/23/23 12:52:18.87
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:347
[BeforeEach] [sig-node] Security Context
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:52:18.898
Apr 23 12:52:18.899: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename security-context-test 04/23/23 12:52:18.904
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:52:18.973
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:52:18.982
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:50
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:347
Apr 23 12:52:19.017: INFO: Waiting up to 5m0s for pod "busybox-user-65534-19fdeef0-c9cb-4b8f-b968-5156b2c9ef0d" in namespace "security-context-test-2530" to be "Succeeded or Failed"
Apr 23 12:52:19.046: INFO: Pod "busybox-user-65534-19fdeef0-c9cb-4b8f-b968-5156b2c9ef0d": Phase="Pending", Reason="", readiness=false. Elapsed: 28.13901ms
Apr 23 12:52:21.065: INFO: Pod "busybox-user-65534-19fdeef0-c9cb-4b8f-b968-5156b2c9ef0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047950915s
Apr 23 12:52:23.054: INFO: Pod "busybox-user-65534-19fdeef0-c9cb-4b8f-b968-5156b2c9ef0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036111911s
Apr 23 12:52:25.052: INFO: Pod "busybox-user-65534-19fdeef0-c9cb-4b8f-b968-5156b2c9ef0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035045092s
Apr 23 12:52:25.053: INFO: Pod "busybox-user-65534-19fdeef0-c9cb-4b8f-b968-5156b2c9ef0d" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/node/init/init.go:32
Apr 23 12:52:25.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Security Context
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Security Context
  tear down framework | framework.go:193
STEP: Destroying namespace "security-context-test-2530" for this suite. 04/23/23 12:52:25.06
------------------------------
â€¢ [SLOW TEST] [6.176 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:309
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:347

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:52:18.898
    Apr 23 12:52:18.899: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename security-context-test 04/23/23 12:52:18.904
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:52:18.973
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:52:18.982
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:50
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:347
    Apr 23 12:52:19.017: INFO: Waiting up to 5m0s for pod "busybox-user-65534-19fdeef0-c9cb-4b8f-b968-5156b2c9ef0d" in namespace "security-context-test-2530" to be "Succeeded or Failed"
    Apr 23 12:52:19.046: INFO: Pod "busybox-user-65534-19fdeef0-c9cb-4b8f-b968-5156b2c9ef0d": Phase="Pending", Reason="", readiness=false. Elapsed: 28.13901ms
    Apr 23 12:52:21.065: INFO: Pod "busybox-user-65534-19fdeef0-c9cb-4b8f-b968-5156b2c9ef0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047950915s
    Apr 23 12:52:23.054: INFO: Pod "busybox-user-65534-19fdeef0-c9cb-4b8f-b968-5156b2c9ef0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036111911s
    Apr 23 12:52:25.052: INFO: Pod "busybox-user-65534-19fdeef0-c9cb-4b8f-b968-5156b2c9ef0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035045092s
    Apr 23 12:52:25.053: INFO: Pod "busybox-user-65534-19fdeef0-c9cb-4b8f-b968-5156b2c9ef0d" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:52:25.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Security Context
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Security Context
      tear down framework | framework.go:193
    STEP: Destroying namespace "security-context-test-2530" for this suite. 04/23/23 12:52:25.06
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:52:25.075
Apr 23 12:52:25.076: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename events 04/23/23 12:52:25.079
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:52:25.107
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:52:25.112
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/metrics/init/init.go:31
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 04/23/23 12:52:25.117
STEP: listing all events in all namespaces 04/23/23 12:52:25.126
STEP: patching the test event 04/23/23 12:52:25.137
STEP: fetching the test event 04/23/23 12:52:25.148
STEP: updating the test event 04/23/23 12:52:25.155
STEP: getting the test event 04/23/23 12:52:25.174
STEP: deleting the test event 04/23/23 12:52:25.179
STEP: listing all events in all namespaces 04/23/23 12:52:25.197
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/node/init/init.go:32
Apr 23 12:52:25.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-instrumentation] Events
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-instrumentation] Events
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-instrumentation] Events
  tear down framework | framework.go:193
STEP: Destroying namespace "events-1531" for this suite. 04/23/23 12:52:25.221
------------------------------
â€¢ [0.161 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:52:25.075
    Apr 23 12:52:25.076: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename events 04/23/23 12:52:25.079
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:52:25.107
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:52:25.112
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/metrics/init/init.go:31
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 04/23/23 12:52:25.117
    STEP: listing all events in all namespaces 04/23/23 12:52:25.126
    STEP: patching the test event 04/23/23 12:52:25.137
    STEP: fetching the test event 04/23/23 12:52:25.148
    STEP: updating the test event 04/23/23 12:52:25.155
    STEP: getting the test event 04/23/23 12:52:25.174
    STEP: deleting the test event 04/23/23 12:52:25.179
    STEP: listing all events in all namespaces 04/23/23 12:52:25.197
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:52:25.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-instrumentation] Events
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-instrumentation] Events
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-instrumentation] Events
      tear down framework | framework.go:193
    STEP: Destroying namespace "events-1531" for this suite. 04/23/23 12:52:25.221
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:205
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:52:25.246
Apr 23 12:52:25.246: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename secrets 04/23/23 12:52:25.25
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:52:25.281
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:52:25.287
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:205
STEP: Creating secret with name s-test-opt-del-2e2754c6-9b7b-4d8d-825e-9a4629b29da8 04/23/23 12:52:25.305
STEP: Creating secret with name s-test-opt-upd-ee440296-5155-44e4-96ad-f5854492e709 04/23/23 12:52:25.317
STEP: Creating the pod 04/23/23 12:52:25.332
Apr 23 12:52:25.371: INFO: Waiting up to 5m0s for pod "pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011" in namespace "secrets-3731" to be "running and ready"
Apr 23 12:52:25.377: INFO: Pod "pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011": Phase="Pending", Reason="", readiness=false. Elapsed: 6.071029ms
Apr 23 12:52:25.377: INFO: The phase of Pod pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:52:27.386: INFO: Pod "pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014986878s
Apr 23 12:52:27.386: INFO: The phase of Pod pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:52:29.386: INFO: Pod "pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014956133s
Apr 23 12:52:29.386: INFO: The phase of Pod pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:52:31.387: INFO: Pod "pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011": Phase="Running", Reason="", readiness=true. Elapsed: 6.015882595s
Apr 23 12:52:31.387: INFO: The phase of Pod pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011 is Running (Ready = true)
Apr 23 12:52:31.387: INFO: Pod "pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-2e2754c6-9b7b-4d8d-825e-9a4629b29da8 04/23/23 12:52:31.806
STEP: Updating secret s-test-opt-upd-ee440296-5155-44e4-96ad-f5854492e709 04/23/23 12:52:31.82
STEP: Creating secret with name s-test-opt-create-1ab8f0cc-a7b4-46ff-a872-9e3cc1f8b135 04/23/23 12:52:31.83
STEP: waiting to observe update in volume 04/23/23 12:52:31.843
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Apr 23 12:53:44.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-3731" for this suite. 04/23/23 12:53:44.772
------------------------------
â€¢ [SLOW TEST] [79.542 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:205

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:52:25.246
    Apr 23 12:52:25.246: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename secrets 04/23/23 12:52:25.25
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:52:25.281
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:52:25.287
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:205
    STEP: Creating secret with name s-test-opt-del-2e2754c6-9b7b-4d8d-825e-9a4629b29da8 04/23/23 12:52:25.305
    STEP: Creating secret with name s-test-opt-upd-ee440296-5155-44e4-96ad-f5854492e709 04/23/23 12:52:25.317
    STEP: Creating the pod 04/23/23 12:52:25.332
    Apr 23 12:52:25.371: INFO: Waiting up to 5m0s for pod "pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011" in namespace "secrets-3731" to be "running and ready"
    Apr 23 12:52:25.377: INFO: Pod "pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011": Phase="Pending", Reason="", readiness=false. Elapsed: 6.071029ms
    Apr 23 12:52:25.377: INFO: The phase of Pod pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:52:27.386: INFO: Pod "pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014986878s
    Apr 23 12:52:27.386: INFO: The phase of Pod pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:52:29.386: INFO: Pod "pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014956133s
    Apr 23 12:52:29.386: INFO: The phase of Pod pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:52:31.387: INFO: Pod "pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011": Phase="Running", Reason="", readiness=true. Elapsed: 6.015882595s
    Apr 23 12:52:31.387: INFO: The phase of Pod pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011 is Running (Ready = true)
    Apr 23 12:52:31.387: INFO: Pod "pod-secrets-a9a0dceb-720c-4f0d-bde3-e589da8c4011" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-2e2754c6-9b7b-4d8d-825e-9a4629b29da8 04/23/23 12:52:31.806
    STEP: Updating secret s-test-opt-upd-ee440296-5155-44e4-96ad-f5854492e709 04/23/23 12:52:31.82
    STEP: Creating secret with name s-test-opt-create-1ab8f0cc-a7b4-46ff-a872-9e3cc1f8b135 04/23/23 12:52:31.83
    STEP: waiting to observe update in volume 04/23/23 12:52:31.843
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:53:44.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-3731" for this suite. 04/23/23 12:53:44.772
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:92
[BeforeEach] [sig-node] Variable Expansion
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:53:44.805
Apr 23 12:53:44.806: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename var-expansion 04/23/23 12:53:44.812
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:53:44.843
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:53:44.851
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:31
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:92
STEP: Creating a pod to test substitution in container's args 04/23/23 12:53:44.857
Apr 23 12:53:44.877: INFO: Waiting up to 5m0s for pod "var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d" in namespace "var-expansion-548" to be "Succeeded or Failed"
Apr 23 12:53:44.888: INFO: Pod "var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.976043ms
Apr 23 12:53:46.897: INFO: Pod "var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019861604s
Apr 23 12:53:48.898: INFO: Pod "var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020186638s
Apr 23 12:53:50.899: INFO: Pod "var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021276037s
STEP: Saw pod success 04/23/23 12:53:50.899
Apr 23 12:53:50.899: INFO: Pod "var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d" satisfied condition "Succeeded or Failed"
Apr 23 12:53:50.913: INFO: Trying to get logs from node eingavuivie7-3 pod var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d container dapi-container: <nil>
STEP: delete the pod 04/23/23 12:53:50.931
Apr 23 12:53:50.982: INFO: Waiting for pod var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d to disappear
Apr 23 12:53:50.996: INFO: Pod var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/node/init/init.go:32
Apr 23 12:53:50.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Variable Expansion
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Variable Expansion
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Variable Expansion
  tear down framework | framework.go:193
STEP: Destroying namespace "var-expansion-548" for this suite. 04/23/23 12:53:51.012
------------------------------
â€¢ [SLOW TEST] [6.246 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:53:44.805
    Apr 23 12:53:44.806: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename var-expansion 04/23/23 12:53:44.812
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:53:44.843
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:53:44.851
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:31
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:92
    STEP: Creating a pod to test substitution in container's args 04/23/23 12:53:44.857
    Apr 23 12:53:44.877: INFO: Waiting up to 5m0s for pod "var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d" in namespace "var-expansion-548" to be "Succeeded or Failed"
    Apr 23 12:53:44.888: INFO: Pod "var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.976043ms
    Apr 23 12:53:46.897: INFO: Pod "var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019861604s
    Apr 23 12:53:48.898: INFO: Pod "var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020186638s
    Apr 23 12:53:50.899: INFO: Pod "var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021276037s
    STEP: Saw pod success 04/23/23 12:53:50.899
    Apr 23 12:53:50.899: INFO: Pod "var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d" satisfied condition "Succeeded or Failed"
    Apr 23 12:53:50.913: INFO: Trying to get logs from node eingavuivie7-3 pod var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d container dapi-container: <nil>
    STEP: delete the pod 04/23/23 12:53:50.931
    Apr 23 12:53:50.982: INFO: Waiting for pod var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d to disappear
    Apr 23 12:53:50.996: INFO: Pod var-expansion-af49439a-3afb-4403-9021-a2dec4618d3d no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:53:50.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Variable Expansion
      tear down framework | framework.go:193
    STEP: Destroying namespace "var-expansion-548" for this suite. 04/23/23 12:53:51.012
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:110
[BeforeEach] [sig-apps] ReplicationController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:53:51.053
Apr 23 12:53:51.053: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename replication-controller 04/23/23 12:53:51.06
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:53:51.134
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:53:51.139
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:57
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:110
STEP: creating a ReplicationController 04/23/23 12:53:51.152
STEP: waiting for RC to be added 04/23/23 12:53:51.17
STEP: waiting for available Replicas 04/23/23 12:53:51.17
STEP: patching ReplicationController 04/23/23 12:53:54.32
STEP: waiting for RC to be modified 04/23/23 12:53:54.34
STEP: patching ReplicationController status 04/23/23 12:53:54.341
STEP: waiting for RC to be modified 04/23/23 12:53:54.366
STEP: waiting for available Replicas 04/23/23 12:53:54.366
STEP: fetching ReplicationController status 04/23/23 12:53:54.367
STEP: patching ReplicationController scale 04/23/23 12:53:54.374
STEP: waiting for RC to be modified 04/23/23 12:53:54.384
STEP: waiting for ReplicationController's scale to be the max amount 04/23/23 12:53:54.385
STEP: fetching ReplicationController; ensuring that it's patched 04/23/23 12:53:56.239
STEP: updating ReplicationController status 04/23/23 12:53:56.247
STEP: waiting for RC to be modified 04/23/23 12:53:56.262
STEP: listing all ReplicationControllers 04/23/23 12:53:56.262
STEP: checking that ReplicationController has expected values 04/23/23 12:53:56.278
STEP: deleting ReplicationControllers by collection 04/23/23 12:53:56.278
STEP: waiting for ReplicationController to have a DELETED watchEvent 04/23/23 12:53:56.316
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/node/init/init.go:32
Apr 23 12:53:56.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] ReplicationController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] ReplicationController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] ReplicationController
  tear down framework | framework.go:193
STEP: Destroying namespace "replication-controller-7084" for this suite. 04/23/23 12:53:56.524
------------------------------
â€¢ [SLOW TEST] [5.554 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:53:51.053
    Apr 23 12:53:51.053: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename replication-controller 04/23/23 12:53:51.06
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:53:51.134
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:53:51.139
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:57
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:110
    STEP: creating a ReplicationController 04/23/23 12:53:51.152
    STEP: waiting for RC to be added 04/23/23 12:53:51.17
    STEP: waiting for available Replicas 04/23/23 12:53:51.17
    STEP: patching ReplicationController 04/23/23 12:53:54.32
    STEP: waiting for RC to be modified 04/23/23 12:53:54.34
    STEP: patching ReplicationController status 04/23/23 12:53:54.341
    STEP: waiting for RC to be modified 04/23/23 12:53:54.366
    STEP: waiting for available Replicas 04/23/23 12:53:54.366
    STEP: fetching ReplicationController status 04/23/23 12:53:54.367
    STEP: patching ReplicationController scale 04/23/23 12:53:54.374
    STEP: waiting for RC to be modified 04/23/23 12:53:54.384
    STEP: waiting for ReplicationController's scale to be the max amount 04/23/23 12:53:54.385
    STEP: fetching ReplicationController; ensuring that it's patched 04/23/23 12:53:56.239
    STEP: updating ReplicationController status 04/23/23 12:53:56.247
    STEP: waiting for RC to be modified 04/23/23 12:53:56.262
    STEP: listing all ReplicationControllers 04/23/23 12:53:56.262
    STEP: checking that ReplicationController has expected values 04/23/23 12:53:56.278
    STEP: deleting ReplicationControllers by collection 04/23/23 12:53:56.278
    STEP: waiting for ReplicationController to have a DELETED watchEvent 04/23/23 12:53:56.316
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:53:56.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] ReplicationController
      tear down framework | framework.go:193
    STEP: Destroying namespace "replication-controller-7084" for this suite. 04/23/23 12:53:56.524
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:57
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:53:56.614
Apr 23 12:53:56.614: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 12:53:56.617
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:53:56.664
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:53:56.669
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:57
STEP: Creating configMap with name configmap-test-volume-d2023188-1e56-433d-9b6e-55665d08f8a3 04/23/23 12:53:56.674
STEP: Creating a pod to test consume configMaps 04/23/23 12:53:56.682
Apr 23 12:53:56.699: INFO: Waiting up to 5m0s for pod "pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68" in namespace "configmap-6080" to be "Succeeded or Failed"
Apr 23 12:53:56.707: INFO: Pod "pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68": Phase="Pending", Reason="", readiness=false. Elapsed: 8.040273ms
Apr 23 12:53:58.718: INFO: Pod "pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68": Phase="Running", Reason="", readiness=true. Elapsed: 2.019310146s
Apr 23 12:54:00.718: INFO: Pod "pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68": Phase="Running", Reason="", readiness=false. Elapsed: 4.018748388s
Apr 23 12:54:02.716: INFO: Pod "pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017138914s
STEP: Saw pod success 04/23/23 12:54:02.716
Apr 23 12:54:02.716: INFO: Pod "pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68" satisfied condition "Succeeded or Failed"
Apr 23 12:54:02.722: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68 container agnhost-container: <nil>
STEP: delete the pod 04/23/23 12:54:02.743
Apr 23 12:54:02.762: INFO: Waiting for pod pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68 to disappear
Apr 23 12:54:02.766: INFO: Pod pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 12:54:02.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-6080" for this suite. 04/23/23 12:54:02.776
------------------------------
â€¢ [SLOW TEST] [6.177 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:53:56.614
    Apr 23 12:53:56.614: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 12:53:56.617
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:53:56.664
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:53:56.669
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:57
    STEP: Creating configMap with name configmap-test-volume-d2023188-1e56-433d-9b6e-55665d08f8a3 04/23/23 12:53:56.674
    STEP: Creating a pod to test consume configMaps 04/23/23 12:53:56.682
    Apr 23 12:53:56.699: INFO: Waiting up to 5m0s for pod "pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68" in namespace "configmap-6080" to be "Succeeded or Failed"
    Apr 23 12:53:56.707: INFO: Pod "pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68": Phase="Pending", Reason="", readiness=false. Elapsed: 8.040273ms
    Apr 23 12:53:58.718: INFO: Pod "pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68": Phase="Running", Reason="", readiness=true. Elapsed: 2.019310146s
    Apr 23 12:54:00.718: INFO: Pod "pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68": Phase="Running", Reason="", readiness=false. Elapsed: 4.018748388s
    Apr 23 12:54:02.716: INFO: Pod "pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017138914s
    STEP: Saw pod success 04/23/23 12:54:02.716
    Apr 23 12:54:02.716: INFO: Pod "pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68" satisfied condition "Succeeded or Failed"
    Apr 23 12:54:02.722: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68 container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 12:54:02.743
    Apr 23 12:54:02.762: INFO: Waiting for pod pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68 to disappear
    Apr 23 12:54:02.766: INFO: Pod pod-configmaps-c4baa27b-d6ea-49d8-b79e-e9c4ac5fde68 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:54:02.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-6080" for this suite. 04/23/23 12:54:02.776
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:102
[BeforeEach] [sig-network] EndpointSlice
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:54:02.792
Apr 23 12:54:02.792: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename endpointslice 04/23/23 12:54:02.8
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:54:02.897
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:54:02.904
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:52
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:102
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/node/init/init.go:32
Apr 23 12:54:03.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] EndpointSlice
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] EndpointSlice
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] EndpointSlice
  tear down framework | framework.go:193
STEP: Destroying namespace "endpointslice-5086" for this suite. 04/23/23 12:54:03.161
------------------------------
â€¢ [0.384 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:102

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:54:02.792
    Apr 23 12:54:02.792: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename endpointslice 04/23/23 12:54:02.8
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:54:02.897
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:54:02.904
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:52
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:102
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:54:03.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] EndpointSlice
      tear down framework | framework.go:193
    STEP: Destroying namespace "endpointslice-5086" for this suite. 04/23/23 12:54:03.161
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:72
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:54:03.178
Apr 23 12:54:03.178: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-probe 04/23/23 12:54:03.181
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:54:03.253
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:54:03.259
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:72
Apr 23 12:54:03.330: INFO: Waiting up to 5m0s for pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825" in namespace "container-probe-5595" to be "running and ready"
Apr 23 12:54:03.357: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Pending", Reason="", readiness=false. Elapsed: 26.794204ms
Apr 23 12:54:03.357: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:54:05.368: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037306851s
Apr 23 12:54:05.368: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:54:07.369: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 4.038641702s
Apr 23 12:54:07.369: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
Apr 23 12:54:09.365: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 6.034990982s
Apr 23 12:54:09.365: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
Apr 23 12:54:11.367: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 8.03690152s
Apr 23 12:54:11.367: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
Apr 23 12:54:13.370: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 10.039231783s
Apr 23 12:54:13.370: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
Apr 23 12:54:15.373: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 12.042959599s
Apr 23 12:54:15.374: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
Apr 23 12:54:17.368: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 14.037386285s
Apr 23 12:54:17.368: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
Apr 23 12:54:19.365: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 16.034328368s
Apr 23 12:54:19.365: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
Apr 23 12:54:21.366: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 18.035402512s
Apr 23 12:54:21.366: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
Apr 23 12:54:23.365: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 20.035019395s
Apr 23 12:54:23.366: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
Apr 23 12:54:25.365: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=true. Elapsed: 22.034554261s
Apr 23 12:54:25.365: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = true)
Apr 23 12:54:25.365: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825" satisfied condition "running and ready"
Apr 23 12:54:25.371: INFO: Container started at 2023-04-23 12:54:05 +0000 UTC, pod became ready at 2023-04-23 12:54:24 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Apr 23 12:54:25.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-5595" for this suite. 04/23/23 12:54:25.382
------------------------------
â€¢ [SLOW TEST] [22.218 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:54:03.178
    Apr 23 12:54:03.178: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-probe 04/23/23 12:54:03.181
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:54:03.253
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:54:03.259
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:72
    Apr 23 12:54:03.330: INFO: Waiting up to 5m0s for pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825" in namespace "container-probe-5595" to be "running and ready"
    Apr 23 12:54:03.357: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Pending", Reason="", readiness=false. Elapsed: 26.794204ms
    Apr 23 12:54:03.357: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:54:05.368: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037306851s
    Apr 23 12:54:05.368: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:54:07.369: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 4.038641702s
    Apr 23 12:54:07.369: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
    Apr 23 12:54:09.365: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 6.034990982s
    Apr 23 12:54:09.365: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
    Apr 23 12:54:11.367: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 8.03690152s
    Apr 23 12:54:11.367: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
    Apr 23 12:54:13.370: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 10.039231783s
    Apr 23 12:54:13.370: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
    Apr 23 12:54:15.373: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 12.042959599s
    Apr 23 12:54:15.374: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
    Apr 23 12:54:17.368: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 14.037386285s
    Apr 23 12:54:17.368: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
    Apr 23 12:54:19.365: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 16.034328368s
    Apr 23 12:54:19.365: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
    Apr 23 12:54:21.366: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 18.035402512s
    Apr 23 12:54:21.366: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
    Apr 23 12:54:23.365: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=false. Elapsed: 20.035019395s
    Apr 23 12:54:23.366: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = false)
    Apr 23 12:54:25.365: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825": Phase="Running", Reason="", readiness=true. Elapsed: 22.034554261s
    Apr 23 12:54:25.365: INFO: The phase of Pod test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825 is Running (Ready = true)
    Apr 23 12:54:25.365: INFO: Pod "test-webserver-124a06a1-6ba3-498f-a481-ba1bd1f42825" satisfied condition "running and ready"
    Apr 23 12:54:25.371: INFO: Container started at 2023-04-23 12:54:05 +0000 UTC, pod became ready at 2023-04-23 12:54:24 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:54:25.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-5595" for this suite. 04/23/23 12:54:25.382
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:167
[BeforeEach] [sig-node] Container Lifecycle Hook
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:54:25.413
Apr 23 12:54:25.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-lifecycle-hook 04/23/23 12:54:25.416
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:54:25.456
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:54:25.468
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:77
STEP: create the container to handle the HTTPGet hook request. 04/23/23 12:54:25.485
Apr 23 12:54:25.502: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2811" to be "running and ready"
Apr 23 12:54:25.513: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 10.49964ms
Apr 23 12:54:25.513: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:54:27.521: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018602393s
Apr 23 12:54:27.521: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:54:29.524: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.021566897s
Apr 23 12:54:29.524: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 23 12:54:29.524: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:167
STEP: create the pod with lifecycle hook 04/23/23 12:54:29.531
Apr 23 12:54:29.542: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-2811" to be "running and ready"
Apr 23 12:54:29.551: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 8.565175ms
Apr 23 12:54:29.551: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:54:31.619: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07668204s
Apr 23 12:54:31.619: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:54:33.560: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.017970597s
Apr 23 12:54:33.561: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Apr 23 12:54:33.561: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 04/23/23 12:54:33.567
STEP: delete the pod with lifecycle hook 04/23/23 12:54:33.808
Apr 23 12:54:33.824: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 23 12:54:33.831: INFO: Pod pod-with-poststart-http-hook still exists
Apr 23 12:54:35.832: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 23 12:54:35.841: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/node/init/init.go:32
Apr 23 12:54:35.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  tear down framework | framework.go:193
STEP: Destroying namespace "container-lifecycle-hook-2811" for this suite. 04/23/23 12:54:35.851
------------------------------
â€¢ [SLOW TEST] [10.447 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:167

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:54:25.413
    Apr 23 12:54:25.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/23/23 12:54:25.416
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:54:25.456
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:54:25.468
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:77
    STEP: create the container to handle the HTTPGet hook request. 04/23/23 12:54:25.485
    Apr 23 12:54:25.502: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2811" to be "running and ready"
    Apr 23 12:54:25.513: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 10.49964ms
    Apr 23 12:54:25.513: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:54:27.521: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018602393s
    Apr 23 12:54:27.521: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:54:29.524: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.021566897s
    Apr 23 12:54:29.524: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 23 12:54:29.524: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:167
    STEP: create the pod with lifecycle hook 04/23/23 12:54:29.531
    Apr 23 12:54:29.542: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-2811" to be "running and ready"
    Apr 23 12:54:29.551: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 8.565175ms
    Apr 23 12:54:29.551: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:54:31.619: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07668204s
    Apr 23 12:54:31.619: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:54:33.560: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.017970597s
    Apr 23 12:54:33.561: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Apr 23 12:54:33.561: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 04/23/23 12:54:33.567
    STEP: delete the pod with lifecycle hook 04/23/23 12:54:33.808
    Apr 23 12:54:33.824: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 23 12:54:33.831: INFO: Pod pod-with-poststart-http-hook still exists
    Apr 23 12:54:35.832: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 23 12:54:35.841: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:54:35.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-lifecycle-hook-2811" for this suite. 04/23/23 12:54:35.851
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:177
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:54:35.862
Apr 23 12:54:35.863: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 12:54:35.867
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:54:35.919
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:54:35.925
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:177
STEP: Creating a pod to test emptydir 0666 on node default medium 04/23/23 12:54:35.933
Apr 23 12:54:35.954: INFO: Waiting up to 5m0s for pod "pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f" in namespace "emptydir-5310" to be "Succeeded or Failed"
Apr 23 12:54:35.963: INFO: Pod "pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.269123ms
Apr 23 12:54:37.979: INFO: Pod "pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024302359s
Apr 23 12:54:39.975: INFO: Pod "pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020311877s
Apr 23 12:54:41.973: INFO: Pod "pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018016726s
STEP: Saw pod success 04/23/23 12:54:41.973
Apr 23 12:54:41.973: INFO: Pod "pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f" satisfied condition "Succeeded or Failed"
Apr 23 12:54:41.982: INFO: Trying to get logs from node eingavuivie7-3 pod pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f container test-container: <nil>
STEP: delete the pod 04/23/23 12:54:42.175
Apr 23 12:54:42.279: INFO: Waiting for pod pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f to disappear
Apr 23 12:54:42.287: INFO: Pod pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 12:54:42.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-5310" for this suite. 04/23/23 12:54:42.303
------------------------------
â€¢ [SLOW TEST] [6.455 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:177

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:54:35.862
    Apr 23 12:54:35.863: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 12:54:35.867
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:54:35.919
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:54:35.925
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:177
    STEP: Creating a pod to test emptydir 0666 on node default medium 04/23/23 12:54:35.933
    Apr 23 12:54:35.954: INFO: Waiting up to 5m0s for pod "pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f" in namespace "emptydir-5310" to be "Succeeded or Failed"
    Apr 23 12:54:35.963: INFO: Pod "pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.269123ms
    Apr 23 12:54:37.979: INFO: Pod "pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024302359s
    Apr 23 12:54:39.975: INFO: Pod "pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020311877s
    Apr 23 12:54:41.973: INFO: Pod "pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018016726s
    STEP: Saw pod success 04/23/23 12:54:41.973
    Apr 23 12:54:41.973: INFO: Pod "pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f" satisfied condition "Succeeded or Failed"
    Apr 23 12:54:41.982: INFO: Trying to get logs from node eingavuivie7-3 pod pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f container test-container: <nil>
    STEP: delete the pod 04/23/23 12:54:42.175
    Apr 23 12:54:42.279: INFO: Waiting for pod pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f to disappear
    Apr 23 12:54:42.287: INFO: Pod pod-d3a55a6f-f9f1-44f0-801c-ff05a15ddf3f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:54:42.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-5310" for this suite. 04/23/23 12:54:42.303
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:54:42.319
Apr 23 12:54:42.319: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename deployment 04/23/23 12:54:42.323
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:54:42.366
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:54:42.372
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Apr 23 12:54:42.413: INFO: Creating deployment "webserver-deployment"
Apr 23 12:54:42.440: INFO: Waiting for observed generation 1
Apr 23 12:54:44.474: INFO: Waiting for all required pods to come up
Apr 23 12:54:44.492: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 04/23/23 12:54:44.492
Apr 23 12:54:44.493: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-zlsrv" in namespace "deployment-8122" to be "running"
Apr 23 12:54:44.494: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-f6g8m" in namespace "deployment-8122" to be "running"
Apr 23 12:54:44.494: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-5skm2" in namespace "deployment-8122" to be "running"
Apr 23 12:54:44.495: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-9bq52" in namespace "deployment-8122" to be "running"
Apr 23 12:54:44.498: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-bss7m" in namespace "deployment-8122" to be "running"
Apr 23 12:54:44.501: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-mgppp" in namespace "deployment-8122" to be "running"
Apr 23 12:54:44.502: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-bstfn" in namespace "deployment-8122" to be "running"
Apr 23 12:54:44.505: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-qpl8t" in namespace "deployment-8122" to be "running"
Apr 23 12:54:44.505: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-qrl74" in namespace "deployment-8122" to be "running"
Apr 23 12:54:44.506: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-mq49z" in namespace "deployment-8122" to be "running"
Apr 23 12:54:44.514: INFO: Pod "webserver-deployment-7f5969cbc7-9bq52": Phase="Pending", Reason="", readiness=false. Elapsed: 19.20914ms
Apr 23 12:54:44.515: INFO: Pod "webserver-deployment-7f5969cbc7-f6g8m": Phase="Pending", Reason="", readiness=false. Elapsed: 21.084716ms
Apr 23 12:54:44.519: INFO: Pod "webserver-deployment-7f5969cbc7-bss7m": Phase="Pending", Reason="", readiness=false. Elapsed: 20.535809ms
Apr 23 12:54:44.523: INFO: Pod "webserver-deployment-7f5969cbc7-mgppp": Phase="Pending", Reason="", readiness=false. Elapsed: 22.10359ms
Apr 23 12:54:44.524: INFO: Pod "webserver-deployment-7f5969cbc7-qrl74": Phase="Pending", Reason="", readiness=false. Elapsed: 18.611319ms
Apr 23 12:54:44.531: INFO: Pod "webserver-deployment-7f5969cbc7-qpl8t": Phase="Pending", Reason="", readiness=false. Elapsed: 26.146557ms
Apr 23 12:54:44.594: INFO: Pod "webserver-deployment-7f5969cbc7-bstfn": Phase="Pending", Reason="", readiness=false. Elapsed: 91.991705ms
Apr 23 12:54:44.597: INFO: Pod "webserver-deployment-7f5969cbc7-5skm2": Phase="Pending", Reason="", readiness=false. Elapsed: 102.63863ms
Apr 23 12:54:44.598: INFO: Pod "webserver-deployment-7f5969cbc7-zlsrv": Phase="Pending", Reason="", readiness=false. Elapsed: 104.616804ms
Apr 23 12:54:44.604: INFO: Pod "webserver-deployment-7f5969cbc7-mq49z": Phase="Pending", Reason="", readiness=false. Elapsed: 97.841507ms
Apr 23 12:54:46.559: INFO: Pod "webserver-deployment-7f5969cbc7-f6g8m": Phase="Running", Reason="", readiness=true. Elapsed: 2.065380861s
Apr 23 12:54:46.559: INFO: Pod "webserver-deployment-7f5969cbc7-f6g8m" satisfied condition "running"
Apr 23 12:54:46.561: INFO: Pod "webserver-deployment-7f5969cbc7-bss7m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062480068s
Apr 23 12:54:46.564: INFO: Pod "webserver-deployment-7f5969cbc7-9bq52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068809706s
Apr 23 12:54:46.565: INFO: Pod "webserver-deployment-7f5969cbc7-qrl74": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059228765s
Apr 23 12:54:46.590: INFO: Pod "webserver-deployment-7f5969cbc7-mgppp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.089204329s
Apr 23 12:54:46.591: INFO: Pod "webserver-deployment-7f5969cbc7-qpl8t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086598957s
Apr 23 12:54:46.604: INFO: Pod "webserver-deployment-7f5969cbc7-5skm2": Phase="Running", Reason="", readiness=true. Elapsed: 2.109480933s
Apr 23 12:54:46.604: INFO: Pod "webserver-deployment-7f5969cbc7-5skm2" satisfied condition "running"
Apr 23 12:54:46.605: INFO: Pod "webserver-deployment-7f5969cbc7-bstfn": Phase="Running", Reason="", readiness=true. Elapsed: 2.103267515s
Apr 23 12:54:46.605: INFO: Pod "webserver-deployment-7f5969cbc7-bstfn" satisfied condition "running"
Apr 23 12:54:46.612: INFO: Pod "webserver-deployment-7f5969cbc7-zlsrv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.118897735s
Apr 23 12:54:46.615: INFO: Pod "webserver-deployment-7f5969cbc7-mq49z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.10924629s
Apr 23 12:54:48.606: INFO: Pod "webserver-deployment-7f5969cbc7-9bq52": Phase="Pending", Reason="", readiness=false. Elapsed: 4.110662139s
Apr 23 12:54:48.607: INFO: Pod "webserver-deployment-7f5969cbc7-bss7m": Phase="Running", Reason="", readiness=true. Elapsed: 4.108585905s
Apr 23 12:54:48.607: INFO: Pod "webserver-deployment-7f5969cbc7-bss7m" satisfied condition "running"
Apr 23 12:54:48.609: INFO: Pod "webserver-deployment-7f5969cbc7-mgppp": Phase="Running", Reason="", readiness=true. Elapsed: 4.107740019s
Apr 23 12:54:48.609: INFO: Pod "webserver-deployment-7f5969cbc7-mgppp" satisfied condition "running"
Apr 23 12:54:48.611: INFO: Pod "webserver-deployment-7f5969cbc7-qpl8t": Phase="Pending", Reason="", readiness=false. Elapsed: 4.105875006s
Apr 23 12:54:48.611: INFO: Pod "webserver-deployment-7f5969cbc7-qrl74": Phase="Pending", Reason="", readiness=false. Elapsed: 4.105390143s
Apr 23 12:54:48.619: INFO: Pod "webserver-deployment-7f5969cbc7-mq49z": Phase="Pending", Reason="", readiness=false. Elapsed: 4.11359916s
Apr 23 12:54:48.626: INFO: Pod "webserver-deployment-7f5969cbc7-zlsrv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.132455146s
Apr 23 12:54:50.569: INFO: Pod "webserver-deployment-7f5969cbc7-qpl8t": Phase="Pending", Reason="", readiness=false. Elapsed: 6.063783385s
Apr 23 12:54:50.569: INFO: Pod "webserver-deployment-7f5969cbc7-9bq52": Phase="Running", Reason="", readiness=true. Elapsed: 6.07462984s
Apr 23 12:54:50.570: INFO: Pod "webserver-deployment-7f5969cbc7-9bq52" satisfied condition "running"
Apr 23 12:54:50.599: INFO: Pod "webserver-deployment-7f5969cbc7-qrl74": Phase="Pending", Reason="", readiness=false. Elapsed: 6.093225233s
Apr 23 12:54:50.616: INFO: Pod "webserver-deployment-7f5969cbc7-mq49z": Phase="Pending", Reason="", readiness=false. Elapsed: 6.109916577s
Apr 23 12:54:50.711: INFO: Pod "webserver-deployment-7f5969cbc7-zlsrv": Phase="Pending", Reason="", readiness=false. Elapsed: 6.217701049s
Apr 23 12:54:52.532: INFO: Pod "webserver-deployment-7f5969cbc7-qrl74": Phase="Running", Reason="", readiness=true. Elapsed: 8.027103133s
Apr 23 12:54:52.532: INFO: Pod "webserver-deployment-7f5969cbc7-qrl74" satisfied condition "running"
Apr 23 12:54:52.564: INFO: Pod "webserver-deployment-7f5969cbc7-qpl8t": Phase="Pending", Reason="", readiness=false. Elapsed: 8.059185745s
Apr 23 12:54:52.612: INFO: Pod "webserver-deployment-7f5969cbc7-zlsrv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.118910221s
Apr 23 12:54:52.617: INFO: Pod "webserver-deployment-7f5969cbc7-mq49z": Phase="Running", Reason="", readiness=true. Elapsed: 8.111092242s
Apr 23 12:54:52.617: INFO: Pod "webserver-deployment-7f5969cbc7-mq49z" satisfied condition "running"
Apr 23 12:54:54.537: INFO: Pod "webserver-deployment-7f5969cbc7-qpl8t": Phase="Running", Reason="", readiness=true. Elapsed: 10.032574145s
Apr 23 12:54:54.538: INFO: Pod "webserver-deployment-7f5969cbc7-qpl8t" satisfied condition "running"
Apr 23 12:54:54.609: INFO: Pod "webserver-deployment-7f5969cbc7-zlsrv": Phase="Running", Reason="", readiness=true. Elapsed: 10.115270142s
Apr 23 12:54:54.609: INFO: Pod "webserver-deployment-7f5969cbc7-zlsrv" satisfied condition "running"
Apr 23 12:54:54.609: INFO: Waiting for deployment "webserver-deployment" to complete
Apr 23 12:54:54.623: INFO: Updating deployment "webserver-deployment" with a non-existent image
Apr 23 12:54:54.643: INFO: Updating deployment webserver-deployment
Apr 23 12:54:54.643: INFO: Waiting for observed generation 2
Apr 23 12:54:56.672: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 23 12:54:56.679: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 23 12:54:56.686: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 23 12:54:56.709: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 23 12:54:56.709: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 23 12:54:56.714: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 23 12:54:56.730: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Apr 23 12:54:56.730: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Apr 23 12:54:56.761: INFO: Updating deployment webserver-deployment
Apr 23 12:54:56.761: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Apr 23 12:54:56.787: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 23 12:54:56.801: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 23 12:54:56.830: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-8122  e99fa27e-0e8b-410f-959c-0951705dd86e 42329 3 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d88358 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-d9f79cb5" is progressing.,LastUpdateTime:2023-04-23 12:54:55 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-23 12:54:56 +0000 UTC,LastTransitionTime:2023-04-23 12:54:56 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Apr 23 12:54:56.839: INFO: New ReplicaSet "webserver-deployment-d9f79cb5" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-d9f79cb5  deployment-8122  04a6d918-078b-457b-9a0c-d1619244661b 42323 3 2023-04-23 12:54:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment e99fa27e-0e8b-410f-959c-0951705dd86e 0xc003d88887 0xc003d88888}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:54:55 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e99fa27e-0e8b-410f-959c-0951705dd86e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: d9f79cb5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d88928 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 23 12:54:56.839: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Apr 23 12:54:56.839: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-7f5969cbc7  deployment-8122  b763bfb7-c142-41f9-973b-2261bfdb8970 42320 3 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment e99fa27e-0e8b-410f-959c-0951705dd86e 0xc003d88787 0xc003d88788}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:54:55 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e99fa27e-0e8b-410f-959c-0951705dd86e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 7f5969cbc7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d88828 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Apr 23 12:54:56.855: INFO: Pod "webserver-deployment-7f5969cbc7-5skm2" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-5skm2 webserver-deployment-7f5969cbc7- deployment-8122  aafb70a4-f800-4bad-836b-56edcebe2d67 42163 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d88e27 0xc003d88e28}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.158\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wqnp5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wqnp5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:10.233.66.158,StartTime:2023-04-23 12:54:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://80b3d3c60a003e476db01f94a13671c5a27dae6edf71132a872e3e1ee54049fb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.158,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.855: INFO: Pod "webserver-deployment-7f5969cbc7-8lg9j" is not available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-8lg9j webserver-deployment-7f5969cbc7- deployment-8122  b1eb7381-6d1c-4eac-b28f-e85006378397 42325 0 2023-04-23 12:54:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d89017 0xc003d89018}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x7dfl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x7dfl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.856: INFO: Pod "webserver-deployment-7f5969cbc7-9bq52" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-9bq52 webserver-deployment-7f5969cbc7- deployment-8122  cc8234e2-6109-49cf-b384-b6902bb8f572 42214 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d89157 0xc003d89158}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.247\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2zms9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2zms9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.130,PodIP:10.233.65.247,StartTime:2023-04-23 12:54:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://769fef0f5e6c2a824cf30046575cda77d47a009f9075c4cfd6a43b2536880856,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.247,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.856: INFO: Pod "webserver-deployment-7f5969cbc7-bss7m" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-bss7m webserver-deployment-7f5969cbc7- deployment-8122  89226b4a-d672-4bcb-9f91-8d43f9e2d14d 42202 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d89347 0xc003d89348}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.103\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x6zt2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x6zt2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.130,PodIP:10.233.65.103,StartTime:2023-04-23 12:54:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://a777f511f0382e6fa8f11d5fd5e5bdd05bebb9807e38e72d8a315ca643a448dc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.103,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.857: INFO: Pod "webserver-deployment-7f5969cbc7-bstfn" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-bstfn webserver-deployment-7f5969cbc7- deployment-8122  fb1055f5-466a-4991-9bdb-a06a6bea90b1 42176 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d89547 0xc003d89548}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:45 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.44\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7qfj2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7qfj2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:10.233.66.44,StartTime:2023-04-23 12:54:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://ca620a0b6e72e7668a3827bd5e5a638f45e35da4e140c503b0f645fc99a1d049,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.44,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.857: INFO: Pod "webserver-deployment-7f5969cbc7-c9trw" is not available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-c9trw webserver-deployment-7f5969cbc7- deployment-8122  f0cb8cfe-0d27-4165-8f00-4066c0fc2cf1 42332 0 2023-04-23 12:54:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d89b17 0xc003d89b18}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nvqpf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nvqpf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.861: INFO: Pod "webserver-deployment-7f5969cbc7-f6g8m" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-f6g8m webserver-deployment-7f5969cbc7- deployment-8122  4dcb472d-e31c-49d4-850e-b921dd28f1c2 42179 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d89c90 0xc003d89c91}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:45 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.52\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vg8q6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vg8q6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:10.233.66.52,StartTime:2023-04-23 12:54:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://75eac2d76572de57bc5156d8135e7871c3365b05878a9a833be874326ab6e805,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.52,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.862: INFO: Pod "webserver-deployment-7f5969cbc7-mgppp" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-mgppp webserver-deployment-7f5969cbc7- deployment-8122  75acdc23-c9fc-4bb0-9603-99a17e423b70 42205 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d89eb7 0xc003d89eb8}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.151\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pzk5z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pzk5z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.130,PodIP:10.233.65.151,StartTime:2023-04-23 12:54:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://ddcb4a7dc1550390202c893a19996d1e52d1e454f0c89bb51bc06acc6badf711,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.151,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.863: INFO: Pod "webserver-deployment-7f5969cbc7-mq49z" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-mq49z webserver-deployment-7f5969cbc7- deployment-8122  acd73763-675f-4242-9db7-fc5eed9c31d6 42240 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc0053260c7 0xc0053260c8}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.172\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d45vq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d45vq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.172,StartTime:2023-04-23 12:54:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://c31f4fdd2ae4261fc68ee185291ec6ea856e958b11a6189209f648bf5488a014,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.172,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.864: INFO: Pod "webserver-deployment-7f5969cbc7-mwgt8" is not available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-mwgt8 webserver-deployment-7f5969cbc7- deployment-8122  9227cc96-f871-46cf-a124-b0af7e9df9cb 42331 0 2023-04-23 12:54:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc0053262b7 0xc0053262b8}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-twjrm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-twjrm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.864: INFO: Pod "webserver-deployment-7f5969cbc7-qrl74" is available:
&Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-qrl74 webserver-deployment-7f5969cbc7- deployment-8122  95e0c236-2828-4654-9b8d-391232578ebc 42237 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc005326420 0xc005326421}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jm7db,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jm7db,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.3,StartTime:2023-04-23 12:54:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://127e928bd01d23853ad189c25be65b1522e170a610f070259f70156df59ef5dd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.3,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.865: INFO: Pod "webserver-deployment-d9f79cb5-6ddhf" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-6ddhf webserver-deployment-d9f79cb5- deployment-8122  80ab0142-6557-42d8-bf10-cb7d618cf076 42326 0 2023-04-23 12:54:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 04a6d918-078b-457b-9a0c-d1619244661b 0xc0053265ef 0xc005326600}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04a6d918-078b-457b-9a0c-d1619244661b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gtb8h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gtb8h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.866: INFO: Pod "webserver-deployment-d9f79cb5-8q4gc" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-8q4gc webserver-deployment-d9f79cb5- deployment-8122  0be7419d-3060-449b-afb0-d507cf0e0808 42271 0 2023-04-23 12:54:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 04a6d918-078b-457b-9a0c-d1619244661b 0xc005326777 0xc005326778}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04a6d918-078b-457b-9a0c-d1619244661b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m4s6x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m4s6x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:,StartTime:2023-04-23 12:54:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.866: INFO: Pod "webserver-deployment-d9f79cb5-bqbg4" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-bqbg4 webserver-deployment-d9f79cb5- deployment-8122  353986bb-615b-432c-895b-d078e7f103a9 42263 0 2023-04-23 12:54:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 04a6d918-078b-457b-9a0c-d1619244661b 0xc005326967 0xc005326968}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04a6d918-078b-457b-9a0c-d1619244661b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vthkz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vthkz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:,StartTime:2023-04-23 12:54:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.867: INFO: Pod "webserver-deployment-d9f79cb5-ch925" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-ch925 webserver-deployment-d9f79cb5- deployment-8122  583547a4-ea13-4cac-8e9e-78b506dab155 42307 0 2023-04-23 12:54:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 04a6d918-078b-457b-9a0c-d1619244661b 0xc005326b57 0xc005326b58}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04a6d918-078b-457b-9a0c-d1619244661b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-57xr7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-57xr7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.130,PodIP:,StartTime:2023-04-23 12:54:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.867: INFO: Pod "webserver-deployment-d9f79cb5-cn2lk" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-cn2lk webserver-deployment-d9f79cb5- deployment-8122  ceb6f5a9-af56-4968-9875-c10fda3ca06f 42295 0 2023-04-23 12:54:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 04a6d918-078b-457b-9a0c-d1619244661b 0xc005326d57 0xc005326d58}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04a6d918-078b-457b-9a0c-d1619244661b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-szs8q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-szs8q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:,StartTime:2023-04-23 12:54:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 23 12:54:56.868: INFO: Pod "webserver-deployment-d9f79cb5-whv7l" is not available:
&Pod{ObjectMeta:{webserver-deployment-d9f79cb5-whv7l webserver-deployment-d9f79cb5- deployment-8122  a4ac4b62-0b17-416e-beeb-0045e3c72dc4 42304 0 2023-04-23 12:54:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 04a6d918-078b-457b-9a0c-d1619244661b 0xc005326f57 0xc005326f58}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04a6d918-078b-457b-9a0c-d1619244661b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tm2r5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tm2r5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:,StartTime:2023-04-23 12:54:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/node/init/init.go:32
Apr 23 12:54:56.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] Deployment
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] Deployment
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] Deployment
  tear down framework | framework.go:193
STEP: Destroying namespace "deployment-8122" for this suite. 04/23/23 12:54:56.892
------------------------------
â€¢ [SLOW TEST] [14.594 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:54:42.319
    Apr 23 12:54:42.319: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename deployment 04/23/23 12:54:42.323
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:54:42.366
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:54:42.372
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Apr 23 12:54:42.413: INFO: Creating deployment "webserver-deployment"
    Apr 23 12:54:42.440: INFO: Waiting for observed generation 1
    Apr 23 12:54:44.474: INFO: Waiting for all required pods to come up
    Apr 23 12:54:44.492: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 04/23/23 12:54:44.492
    Apr 23 12:54:44.493: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-zlsrv" in namespace "deployment-8122" to be "running"
    Apr 23 12:54:44.494: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-f6g8m" in namespace "deployment-8122" to be "running"
    Apr 23 12:54:44.494: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-5skm2" in namespace "deployment-8122" to be "running"
    Apr 23 12:54:44.495: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-9bq52" in namespace "deployment-8122" to be "running"
    Apr 23 12:54:44.498: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-bss7m" in namespace "deployment-8122" to be "running"
    Apr 23 12:54:44.501: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-mgppp" in namespace "deployment-8122" to be "running"
    Apr 23 12:54:44.502: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-bstfn" in namespace "deployment-8122" to be "running"
    Apr 23 12:54:44.505: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-qpl8t" in namespace "deployment-8122" to be "running"
    Apr 23 12:54:44.505: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-qrl74" in namespace "deployment-8122" to be "running"
    Apr 23 12:54:44.506: INFO: Waiting up to 5m0s for pod "webserver-deployment-7f5969cbc7-mq49z" in namespace "deployment-8122" to be "running"
    Apr 23 12:54:44.514: INFO: Pod "webserver-deployment-7f5969cbc7-9bq52": Phase="Pending", Reason="", readiness=false. Elapsed: 19.20914ms
    Apr 23 12:54:44.515: INFO: Pod "webserver-deployment-7f5969cbc7-f6g8m": Phase="Pending", Reason="", readiness=false. Elapsed: 21.084716ms
    Apr 23 12:54:44.519: INFO: Pod "webserver-deployment-7f5969cbc7-bss7m": Phase="Pending", Reason="", readiness=false. Elapsed: 20.535809ms
    Apr 23 12:54:44.523: INFO: Pod "webserver-deployment-7f5969cbc7-mgppp": Phase="Pending", Reason="", readiness=false. Elapsed: 22.10359ms
    Apr 23 12:54:44.524: INFO: Pod "webserver-deployment-7f5969cbc7-qrl74": Phase="Pending", Reason="", readiness=false. Elapsed: 18.611319ms
    Apr 23 12:54:44.531: INFO: Pod "webserver-deployment-7f5969cbc7-qpl8t": Phase="Pending", Reason="", readiness=false. Elapsed: 26.146557ms
    Apr 23 12:54:44.594: INFO: Pod "webserver-deployment-7f5969cbc7-bstfn": Phase="Pending", Reason="", readiness=false. Elapsed: 91.991705ms
    Apr 23 12:54:44.597: INFO: Pod "webserver-deployment-7f5969cbc7-5skm2": Phase="Pending", Reason="", readiness=false. Elapsed: 102.63863ms
    Apr 23 12:54:44.598: INFO: Pod "webserver-deployment-7f5969cbc7-zlsrv": Phase="Pending", Reason="", readiness=false. Elapsed: 104.616804ms
    Apr 23 12:54:44.604: INFO: Pod "webserver-deployment-7f5969cbc7-mq49z": Phase="Pending", Reason="", readiness=false. Elapsed: 97.841507ms
    Apr 23 12:54:46.559: INFO: Pod "webserver-deployment-7f5969cbc7-f6g8m": Phase="Running", Reason="", readiness=true. Elapsed: 2.065380861s
    Apr 23 12:54:46.559: INFO: Pod "webserver-deployment-7f5969cbc7-f6g8m" satisfied condition "running"
    Apr 23 12:54:46.561: INFO: Pod "webserver-deployment-7f5969cbc7-bss7m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062480068s
    Apr 23 12:54:46.564: INFO: Pod "webserver-deployment-7f5969cbc7-9bq52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068809706s
    Apr 23 12:54:46.565: INFO: Pod "webserver-deployment-7f5969cbc7-qrl74": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059228765s
    Apr 23 12:54:46.590: INFO: Pod "webserver-deployment-7f5969cbc7-mgppp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.089204329s
    Apr 23 12:54:46.591: INFO: Pod "webserver-deployment-7f5969cbc7-qpl8t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086598957s
    Apr 23 12:54:46.604: INFO: Pod "webserver-deployment-7f5969cbc7-5skm2": Phase="Running", Reason="", readiness=true. Elapsed: 2.109480933s
    Apr 23 12:54:46.604: INFO: Pod "webserver-deployment-7f5969cbc7-5skm2" satisfied condition "running"
    Apr 23 12:54:46.605: INFO: Pod "webserver-deployment-7f5969cbc7-bstfn": Phase="Running", Reason="", readiness=true. Elapsed: 2.103267515s
    Apr 23 12:54:46.605: INFO: Pod "webserver-deployment-7f5969cbc7-bstfn" satisfied condition "running"
    Apr 23 12:54:46.612: INFO: Pod "webserver-deployment-7f5969cbc7-zlsrv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.118897735s
    Apr 23 12:54:46.615: INFO: Pod "webserver-deployment-7f5969cbc7-mq49z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.10924629s
    Apr 23 12:54:48.606: INFO: Pod "webserver-deployment-7f5969cbc7-9bq52": Phase="Pending", Reason="", readiness=false. Elapsed: 4.110662139s
    Apr 23 12:54:48.607: INFO: Pod "webserver-deployment-7f5969cbc7-bss7m": Phase="Running", Reason="", readiness=true. Elapsed: 4.108585905s
    Apr 23 12:54:48.607: INFO: Pod "webserver-deployment-7f5969cbc7-bss7m" satisfied condition "running"
    Apr 23 12:54:48.609: INFO: Pod "webserver-deployment-7f5969cbc7-mgppp": Phase="Running", Reason="", readiness=true. Elapsed: 4.107740019s
    Apr 23 12:54:48.609: INFO: Pod "webserver-deployment-7f5969cbc7-mgppp" satisfied condition "running"
    Apr 23 12:54:48.611: INFO: Pod "webserver-deployment-7f5969cbc7-qpl8t": Phase="Pending", Reason="", readiness=false. Elapsed: 4.105875006s
    Apr 23 12:54:48.611: INFO: Pod "webserver-deployment-7f5969cbc7-qrl74": Phase="Pending", Reason="", readiness=false. Elapsed: 4.105390143s
    Apr 23 12:54:48.619: INFO: Pod "webserver-deployment-7f5969cbc7-mq49z": Phase="Pending", Reason="", readiness=false. Elapsed: 4.11359916s
    Apr 23 12:54:48.626: INFO: Pod "webserver-deployment-7f5969cbc7-zlsrv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.132455146s
    Apr 23 12:54:50.569: INFO: Pod "webserver-deployment-7f5969cbc7-qpl8t": Phase="Pending", Reason="", readiness=false. Elapsed: 6.063783385s
    Apr 23 12:54:50.569: INFO: Pod "webserver-deployment-7f5969cbc7-9bq52": Phase="Running", Reason="", readiness=true. Elapsed: 6.07462984s
    Apr 23 12:54:50.570: INFO: Pod "webserver-deployment-7f5969cbc7-9bq52" satisfied condition "running"
    Apr 23 12:54:50.599: INFO: Pod "webserver-deployment-7f5969cbc7-qrl74": Phase="Pending", Reason="", readiness=false. Elapsed: 6.093225233s
    Apr 23 12:54:50.616: INFO: Pod "webserver-deployment-7f5969cbc7-mq49z": Phase="Pending", Reason="", readiness=false. Elapsed: 6.109916577s
    Apr 23 12:54:50.711: INFO: Pod "webserver-deployment-7f5969cbc7-zlsrv": Phase="Pending", Reason="", readiness=false. Elapsed: 6.217701049s
    Apr 23 12:54:52.532: INFO: Pod "webserver-deployment-7f5969cbc7-qrl74": Phase="Running", Reason="", readiness=true. Elapsed: 8.027103133s
    Apr 23 12:54:52.532: INFO: Pod "webserver-deployment-7f5969cbc7-qrl74" satisfied condition "running"
    Apr 23 12:54:52.564: INFO: Pod "webserver-deployment-7f5969cbc7-qpl8t": Phase="Pending", Reason="", readiness=false. Elapsed: 8.059185745s
    Apr 23 12:54:52.612: INFO: Pod "webserver-deployment-7f5969cbc7-zlsrv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.118910221s
    Apr 23 12:54:52.617: INFO: Pod "webserver-deployment-7f5969cbc7-mq49z": Phase="Running", Reason="", readiness=true. Elapsed: 8.111092242s
    Apr 23 12:54:52.617: INFO: Pod "webserver-deployment-7f5969cbc7-mq49z" satisfied condition "running"
    Apr 23 12:54:54.537: INFO: Pod "webserver-deployment-7f5969cbc7-qpl8t": Phase="Running", Reason="", readiness=true. Elapsed: 10.032574145s
    Apr 23 12:54:54.538: INFO: Pod "webserver-deployment-7f5969cbc7-qpl8t" satisfied condition "running"
    Apr 23 12:54:54.609: INFO: Pod "webserver-deployment-7f5969cbc7-zlsrv": Phase="Running", Reason="", readiness=true. Elapsed: 10.115270142s
    Apr 23 12:54:54.609: INFO: Pod "webserver-deployment-7f5969cbc7-zlsrv" satisfied condition "running"
    Apr 23 12:54:54.609: INFO: Waiting for deployment "webserver-deployment" to complete
    Apr 23 12:54:54.623: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Apr 23 12:54:54.643: INFO: Updating deployment webserver-deployment
    Apr 23 12:54:54.643: INFO: Waiting for observed generation 2
    Apr 23 12:54:56.672: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Apr 23 12:54:56.679: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Apr 23 12:54:56.686: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Apr 23 12:54:56.709: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Apr 23 12:54:56.709: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Apr 23 12:54:56.714: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Apr 23 12:54:56.730: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Apr 23 12:54:56.730: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Apr 23 12:54:56.761: INFO: Updating deployment webserver-deployment
    Apr 23 12:54:56.761: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Apr 23 12:54:56.787: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Apr 23 12:54:56.801: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 23 12:54:56.830: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-8122  e99fa27e-0e8b-410f-959c-0951705dd86e 42329 3 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d88358 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-d9f79cb5" is progressing.,LastUpdateTime:2023-04-23 12:54:55 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-23 12:54:56 +0000 UTC,LastTransitionTime:2023-04-23 12:54:56 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Apr 23 12:54:56.839: INFO: New ReplicaSet "webserver-deployment-d9f79cb5" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-d9f79cb5  deployment-8122  04a6d918-078b-457b-9a0c-d1619244661b 42323 3 2023-04-23 12:54:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment e99fa27e-0e8b-410f-959c-0951705dd86e 0xc003d88887 0xc003d88888}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:54:55 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e99fa27e-0e8b-410f-959c-0951705dd86e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: d9f79cb5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d88928 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 23 12:54:56.839: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Apr 23 12:54:56.839: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-7f5969cbc7  deployment-8122  b763bfb7-c142-41f9-973b-2261bfdb8970 42320 3 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment e99fa27e-0e8b-410f-959c-0951705dd86e 0xc003d88787 0xc003d88788}] [] [{kube-controller-manager Update apps/v1 2023-04-23 12:54:55 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e99fa27e-0e8b-410f-959c-0951705dd86e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 7f5969cbc7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d88828 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Apr 23 12:54:56.855: INFO: Pod "webserver-deployment-7f5969cbc7-5skm2" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-5skm2 webserver-deployment-7f5969cbc7- deployment-8122  aafb70a4-f800-4bad-836b-56edcebe2d67 42163 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d88e27 0xc003d88e28}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.158\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wqnp5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wqnp5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:10.233.66.158,StartTime:2023-04-23 12:54:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://80b3d3c60a003e476db01f94a13671c5a27dae6edf71132a872e3e1ee54049fb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.158,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.855: INFO: Pod "webserver-deployment-7f5969cbc7-8lg9j" is not available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-8lg9j webserver-deployment-7f5969cbc7- deployment-8122  b1eb7381-6d1c-4eac-b28f-e85006378397 42325 0 2023-04-23 12:54:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d89017 0xc003d89018}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x7dfl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x7dfl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.856: INFO: Pod "webserver-deployment-7f5969cbc7-9bq52" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-9bq52 webserver-deployment-7f5969cbc7- deployment-8122  cc8234e2-6109-49cf-b384-b6902bb8f572 42214 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d89157 0xc003d89158}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.247\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2zms9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2zms9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.130,PodIP:10.233.65.247,StartTime:2023-04-23 12:54:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://769fef0f5e6c2a824cf30046575cda77d47a009f9075c4cfd6a43b2536880856,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.247,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.856: INFO: Pod "webserver-deployment-7f5969cbc7-bss7m" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-bss7m webserver-deployment-7f5969cbc7- deployment-8122  89226b4a-d672-4bcb-9f91-8d43f9e2d14d 42202 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d89347 0xc003d89348}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.103\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x6zt2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x6zt2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.130,PodIP:10.233.65.103,StartTime:2023-04-23 12:54:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://a777f511f0382e6fa8f11d5fd5e5bdd05bebb9807e38e72d8a315ca643a448dc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.103,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.857: INFO: Pod "webserver-deployment-7f5969cbc7-bstfn" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-bstfn webserver-deployment-7f5969cbc7- deployment-8122  fb1055f5-466a-4991-9bdb-a06a6bea90b1 42176 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d89547 0xc003d89548}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:45 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.44\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7qfj2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7qfj2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:10.233.66.44,StartTime:2023-04-23 12:54:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://ca620a0b6e72e7668a3827bd5e5a638f45e35da4e140c503b0f645fc99a1d049,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.44,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.857: INFO: Pod "webserver-deployment-7f5969cbc7-c9trw" is not available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-c9trw webserver-deployment-7f5969cbc7- deployment-8122  f0cb8cfe-0d27-4165-8f00-4066c0fc2cf1 42332 0 2023-04-23 12:54:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d89b17 0xc003d89b18}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nvqpf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nvqpf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.861: INFO: Pod "webserver-deployment-7f5969cbc7-f6g8m" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-f6g8m webserver-deployment-7f5969cbc7- deployment-8122  4dcb472d-e31c-49d4-850e-b921dd28f1c2 42179 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d89c90 0xc003d89c91}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:45 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.52\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vg8q6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vg8q6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:10.233.66.52,StartTime:2023-04-23 12:54:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://75eac2d76572de57bc5156d8135e7871c3365b05878a9a833be874326ab6e805,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.52,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.862: INFO: Pod "webserver-deployment-7f5969cbc7-mgppp" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-mgppp webserver-deployment-7f5969cbc7- deployment-8122  75acdc23-c9fc-4bb0-9603-99a17e423b70 42205 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc003d89eb7 0xc003d89eb8}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.151\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pzk5z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pzk5z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.130,PodIP:10.233.65.151,StartTime:2023-04-23 12:54:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://ddcb4a7dc1550390202c893a19996d1e52d1e454f0c89bb51bc06acc6badf711,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.151,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.863: INFO: Pod "webserver-deployment-7f5969cbc7-mq49z" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-mq49z webserver-deployment-7f5969cbc7- deployment-8122  acd73763-675f-4242-9db7-fc5eed9c31d6 42240 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc0053260c7 0xc0053260c8}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.172\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d45vq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d45vq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.172,StartTime:2023-04-23 12:54:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://c31f4fdd2ae4261fc68ee185291ec6ea856e958b11a6189209f648bf5488a014,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.172,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.864: INFO: Pod "webserver-deployment-7f5969cbc7-mwgt8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-mwgt8 webserver-deployment-7f5969cbc7- deployment-8122  9227cc96-f871-46cf-a124-b0af7e9df9cb 42331 0 2023-04-23 12:54:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc0053262b7 0xc0053262b8}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-twjrm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-twjrm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.864: INFO: Pod "webserver-deployment-7f5969cbc7-qrl74" is available:
    &Pod{ObjectMeta:{webserver-deployment-7f5969cbc7-qrl74 webserver-deployment-7f5969cbc7- deployment-8122  95e0c236-2828-4654-9b8d-391232578ebc 42237 0 2023-04-23 12:54:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7f5969cbc7] map[] [{apps/v1 ReplicaSet webserver-deployment-7f5969cbc7 b763bfb7-c142-41f9-973b-2261bfdb8970 0xc005326420 0xc005326421}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b763bfb7-c142-41f9-973b-2261bfdb8970\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jm7db,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jm7db,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:10.233.64.3,StartTime:2023-04-23 12:54:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-23 12:54:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:cri-o://127e928bd01d23853ad189c25be65b1522e170a610f070259f70156df59ef5dd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.3,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.865: INFO: Pod "webserver-deployment-d9f79cb5-6ddhf" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-6ddhf webserver-deployment-d9f79cb5- deployment-8122  80ab0142-6557-42d8-bf10-cb7d618cf076 42326 0 2023-04-23 12:54:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 04a6d918-078b-457b-9a0c-d1619244661b 0xc0053265ef 0xc005326600}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04a6d918-078b-457b-9a0c-d1619244661b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gtb8h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gtb8h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.866: INFO: Pod "webserver-deployment-d9f79cb5-8q4gc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-8q4gc webserver-deployment-d9f79cb5- deployment-8122  0be7419d-3060-449b-afb0-d507cf0e0808 42271 0 2023-04-23 12:54:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 04a6d918-078b-457b-9a0c-d1619244661b 0xc005326777 0xc005326778}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04a6d918-078b-457b-9a0c-d1619244661b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m4s6x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m4s6x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:,StartTime:2023-04-23 12:54:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.866: INFO: Pod "webserver-deployment-d9f79cb5-bqbg4" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-bqbg4 webserver-deployment-d9f79cb5- deployment-8122  353986bb-615b-432c-895b-d078e7f103a9 42263 0 2023-04-23 12:54:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 04a6d918-078b-457b-9a0c-d1619244661b 0xc005326967 0xc005326968}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04a6d918-078b-457b-9a0c-d1619244661b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vthkz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vthkz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:,StartTime:2023-04-23 12:54:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.867: INFO: Pod "webserver-deployment-d9f79cb5-ch925" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-ch925 webserver-deployment-d9f79cb5- deployment-8122  583547a4-ea13-4cac-8e9e-78b506dab155 42307 0 2023-04-23 12:54:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 04a6d918-078b-457b-9a0c-d1619244661b 0xc005326b57 0xc005326b58}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04a6d918-078b-457b-9a0c-d1619244661b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-57xr7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-57xr7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.130,PodIP:,StartTime:2023-04-23 12:54:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.867: INFO: Pod "webserver-deployment-d9f79cb5-cn2lk" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-cn2lk webserver-deployment-d9f79cb5- deployment-8122  ceb6f5a9-af56-4968-9875-c10fda3ca06f 42295 0 2023-04-23 12:54:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 04a6d918-078b-457b-9a0c-d1619244661b 0xc005326d57 0xc005326d58}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04a6d918-078b-457b-9a0c-d1619244661b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-szs8q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-szs8q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.198,PodIP:,StartTime:2023-04-23 12:54:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 23 12:54:56.868: INFO: Pod "webserver-deployment-d9f79cb5-whv7l" is not available:
    &Pod{ObjectMeta:{webserver-deployment-d9f79cb5-whv7l webserver-deployment-d9f79cb5- deployment-8122  a4ac4b62-0b17-416e-beeb-0045e3c72dc4 42304 0 2023-04-23 12:54:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:d9f79cb5] map[] [{apps/v1 ReplicaSet webserver-deployment-d9f79cb5 04a6d918-078b-457b-9a0c-d1619244661b 0xc005326f57 0xc005326f58}] [] [{kube-controller-manager Update v1 2023-04-23 12:54:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"04a6d918-078b-457b-9a0c-d1619244661b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-23 12:54:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tm2r5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tm2r5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:eingavuivie7-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-23 12:54:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.214,PodIP:,StartTime:2023-04-23 12:54:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:54:56.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] Deployment
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] Deployment
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] Deployment
      tear down framework | framework.go:193
    STEP: Destroying namespace "deployment-8122" for this suite. 04/23/23 12:54:56.892
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:130
[BeforeEach] [sig-storage] Projected downwardAPI
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:54:56.94
Apr 23 12:54:56.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 12:54:56.944
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:54:57.163
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:54:57.167
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:44
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:130
STEP: Creating the pod 04/23/23 12:54:57.176
Apr 23 12:54:57.214: INFO: Waiting up to 5m0s for pod "labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d" in namespace "projected-54" to be "running and ready"
Apr 23 12:54:57.228: INFO: Pod "labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.332348ms
Apr 23 12:54:57.228: INFO: The phase of Pod labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:54:59.235: INFO: Pod "labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020108502s
Apr 23 12:54:59.235: INFO: The phase of Pod labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:55:01.242: INFO: Pod "labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027223219s
Apr 23 12:55:01.242: INFO: The phase of Pod labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:55:03.356: INFO: Pod "labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d": Phase="Running", Reason="", readiness=true. Elapsed: 6.141335621s
Apr 23 12:55:03.356: INFO: The phase of Pod labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d is Running (Ready = true)
Apr 23 12:55:03.356: INFO: Pod "labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d" satisfied condition "running and ready"
Apr 23 12:55:04.309: INFO: Successfully updated pod "labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/node/init/init.go:32
Apr 23 12:55:06.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected downwardAPI
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-54" for this suite. 04/23/23 12:55:06.359
------------------------------
â€¢ [SLOW TEST] [9.435 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:54:56.94
    Apr 23 12:54:56.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 12:54:56.944
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:54:57.163
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:54:57.167
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:44
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:130
    STEP: Creating the pod 04/23/23 12:54:57.176
    Apr 23 12:54:57.214: INFO: Waiting up to 5m0s for pod "labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d" in namespace "projected-54" to be "running and ready"
    Apr 23 12:54:57.228: INFO: Pod "labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.332348ms
    Apr 23 12:54:57.228: INFO: The phase of Pod labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:54:59.235: INFO: Pod "labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020108502s
    Apr 23 12:54:59.235: INFO: The phase of Pod labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:55:01.242: INFO: Pod "labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027223219s
    Apr 23 12:55:01.242: INFO: The phase of Pod labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:55:03.356: INFO: Pod "labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d": Phase="Running", Reason="", readiness=true. Elapsed: 6.141335621s
    Apr 23 12:55:03.356: INFO: The phase of Pod labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d is Running (Ready = true)
    Apr 23 12:55:03.356: INFO: Pod "labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d" satisfied condition "running and ready"
    Apr 23 12:55:04.309: INFO: Successfully updated pod "labelsupdatec3fea0ad-0c57-422f-9ebd-4c3d446ce17d"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:55:06.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected downwardAPI
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-54" for this suite. 04/23/23 12:55:06.359
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:609
[BeforeEach] [sig-node] Security Context
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:55:06.379
Apr 23 12:55:06.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename security-context-test 04/23/23 12:55:06.381
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:55:06.417
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:55:06.421
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:50
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:609
Apr 23 12:55:06.455: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983" in namespace "security-context-test-2197" to be "Succeeded or Failed"
Apr 23 12:55:06.464: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Pending", Reason="", readiness=false. Elapsed: 9.405506ms
Apr 23 12:55:08.484: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029389319s
Apr 23 12:55:10.476: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021383385s
Apr 23 12:55:12.479: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023992369s
Apr 23 12:55:14.471: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016142683s
Apr 23 12:55:16.471: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Pending", Reason="", readiness=false. Elapsed: 10.015735063s
Apr 23 12:55:18.471: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016038148s
Apr 23 12:55:20.520: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.065109898s
Apr 23 12:55:20.520: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/node/init/init.go:32
Apr 23 12:55:20.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Security Context
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Security Context
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Security Context
  tear down framework | framework.go:193
STEP: Destroying namespace "security-context-test-2197" for this suite. 04/23/23 12:55:20.547
------------------------------
â€¢ [SLOW TEST] [14.199 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:555
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:609

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:55:06.379
    Apr 23 12:55:06.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename security-context-test 04/23/23 12:55:06.381
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:55:06.417
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:55:06.421
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:50
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:609
    Apr 23 12:55:06.455: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983" in namespace "security-context-test-2197" to be "Succeeded or Failed"
    Apr 23 12:55:06.464: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Pending", Reason="", readiness=false. Elapsed: 9.405506ms
    Apr 23 12:55:08.484: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029389319s
    Apr 23 12:55:10.476: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021383385s
    Apr 23 12:55:12.479: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023992369s
    Apr 23 12:55:14.471: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016142683s
    Apr 23 12:55:16.471: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Pending", Reason="", readiness=false. Elapsed: 10.015735063s
    Apr 23 12:55:18.471: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016038148s
    Apr 23 12:55:20.520: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.065109898s
    Apr 23 12:55:20.520: INFO: Pod "alpine-nnp-false-1fff3193-dff4-4b4d-a5e3-ff11e0965983" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:55:20.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Security Context
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Security Context
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Security Context
      tear down framework | framework.go:193
    STEP: Destroying namespace "security-context-test-2197" for this suite. 04/23/23 12:55:20.547
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1438
[BeforeEach] [sig-network] Services
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:55:20.586
Apr 23 12:55:20.587: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename services 04/23/23 12:55:20.59
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:55:20.627
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:55:20.632
[BeforeEach] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:766
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1438
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6596 04/23/23 12:55:20.637
STEP: changing the ExternalName service to type=ClusterIP 04/23/23 12:55:20.645
STEP: creating replication controller externalname-service in namespace services-6596 04/23/23 12:55:20.698
I0423 12:55:20.717177      13 runners.go:193] Created replication controller with name: externalname-service, namespace: services-6596, replica count: 2
I0423 12:55:23.770190      13 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 23 12:55:23.771: INFO: Creating new exec pod
Apr 23 12:55:23.790: INFO: Waiting up to 5m0s for pod "execpods8nwb" in namespace "services-6596" to be "running"
Apr 23 12:55:23.799: INFO: Pod "execpods8nwb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.561927ms
Apr 23 12:55:25.811: INFO: Pod "execpods8nwb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020753965s
Apr 23 12:55:27.807: INFO: Pod "execpods8nwb": Phase="Running", Reason="", readiness=true. Elapsed: 4.017012218s
Apr 23 12:55:27.808: INFO: Pod "execpods8nwb" satisfied condition "running"
Apr 23 12:55:28.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6596 exec execpods8nwb -- /bin/sh -x -c nc -v -z -w 2 externalname-service 80'
Apr 23 12:55:29.136: INFO: stderr: "+ nc -v -z -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 23 12:55:29.136: INFO: stdout: ""
Apr 23 12:55:29.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6596 exec execpods8nwb -- /bin/sh -x -c nc -v -z -w 2 10.233.42.254 80'
Apr 23 12:55:29.412: INFO: stderr: "+ nc -v -z -w 2 10.233.42.254 80\nConnection to 10.233.42.254 80 port [tcp/http] succeeded!\n"
Apr 23 12:55:29.412: INFO: stdout: ""
Apr 23 12:55:29.412: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/node/init/init.go:32
Apr 23 12:55:29.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] Services
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] Services
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] Services
  tear down framework | framework.go:193
STEP: Destroying namespace "services-6596" for this suite. 04/23/23 12:55:29.459
------------------------------
â€¢ [SLOW TEST] [8.893 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:55:20.586
    Apr 23 12:55:20.587: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename services 04/23/23 12:55:20.59
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:55:20.627
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:55:20.632
    [BeforeEach] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:766
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1438
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-6596 04/23/23 12:55:20.637
    STEP: changing the ExternalName service to type=ClusterIP 04/23/23 12:55:20.645
    STEP: creating replication controller externalname-service in namespace services-6596 04/23/23 12:55:20.698
    I0423 12:55:20.717177      13 runners.go:193] Created replication controller with name: externalname-service, namespace: services-6596, replica count: 2
    I0423 12:55:23.770190      13 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 23 12:55:23.771: INFO: Creating new exec pod
    Apr 23 12:55:23.790: INFO: Waiting up to 5m0s for pod "execpods8nwb" in namespace "services-6596" to be "running"
    Apr 23 12:55:23.799: INFO: Pod "execpods8nwb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.561927ms
    Apr 23 12:55:25.811: INFO: Pod "execpods8nwb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020753965s
    Apr 23 12:55:27.807: INFO: Pod "execpods8nwb": Phase="Running", Reason="", readiness=true. Elapsed: 4.017012218s
    Apr 23 12:55:27.808: INFO: Pod "execpods8nwb" satisfied condition "running"
    Apr 23 12:55:28.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6596 exec execpods8nwb -- /bin/sh -x -c nc -v -z -w 2 externalname-service 80'
    Apr 23 12:55:29.136: INFO: stderr: "+ nc -v -z -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 23 12:55:29.136: INFO: stdout: ""
    Apr 23 12:55:29.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=services-6596 exec execpods8nwb -- /bin/sh -x -c nc -v -z -w 2 10.233.42.254 80'
    Apr 23 12:55:29.412: INFO: stderr: "+ nc -v -z -w 2 10.233.42.254 80\nConnection to 10.233.42.254 80 port [tcp/http] succeeded!\n"
    Apr 23 12:55:29.412: INFO: stdout: ""
    Apr 23 12:55:29.412: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:55:29.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] Services
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] Services
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] Services
      tear down framework | framework.go:193
    STEP: Destroying namespace "services-6596" for this suite. 04/23/23 12:55:29.459
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:656
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:55:29.483
Apr 23 12:55:29.483: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename webhook 04/23/23 12:55:29.496
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:55:29.542
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:55:29.546
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:90
STEP: Setting up server cert 04/23/23 12:55:29.585
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:55:30.8
STEP: Deploying the webhook pod 04/23/23 12:55:30.817
STEP: Wait for the deployment to be ready 04/23/23 12:55:30.842
Apr 23 12:55:30.857: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 23 12:55:32.890: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 55, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 55, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 55, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 55, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/23/23 12:55:34.898
STEP: Verifying the service has paired with the endpoint 04/23/23 12:55:34.915
Apr 23 12:55:35.915: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:656
STEP: Listing all of the created validation webhooks 04/23/23 12:55:36.148
STEP: Creating a configMap that should be mutated 04/23/23 12:55:36.224
STEP: Deleting the collection of validation webhooks 04/23/23 12:55:36.348
STEP: Creating a configMap that should not be mutated 04/23/23 12:55:36.754
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:55:36.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:105
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "webhook-8890" for this suite. 04/23/23 12:55:37.022
STEP: Destroying namespace "webhook-8890-markers" for this suite. 04/23/23 12:55:37.06
------------------------------
â€¢ [SLOW TEST] [7.636 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:656

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:55:29.483
    Apr 23 12:55:29.483: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename webhook 04/23/23 12:55:29.496
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:55:29.542
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:55:29.546
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:90
    STEP: Setting up server cert 04/23/23 12:55:29.585
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/23/23 12:55:30.8
    STEP: Deploying the webhook pod 04/23/23 12:55:30.817
    STEP: Wait for the deployment to be ready 04/23/23 12:55:30.842
    Apr 23 12:55:30.857: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 23 12:55:32.890: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 55, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 55, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 55, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 55, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-865554f4d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/23/23 12:55:34.898
    STEP: Verifying the service has paired with the endpoint 04/23/23 12:55:34.915
    Apr 23 12:55:35.915: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:656
    STEP: Listing all of the created validation webhooks 04/23/23 12:55:36.148
    STEP: Creating a configMap that should be mutated 04/23/23 12:55:36.224
    STEP: Deleting the collection of validation webhooks 04/23/23 12:55:36.348
    STEP: Creating a configMap that should not be mutated 04/23/23 12:55:36.754
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:55:36.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:105
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "webhook-8890" for this suite. 04/23/23 12:55:37.022
    STEP: Destroying namespace "webhook-8890-markers" for this suite. 04/23/23 12:55:37.06
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:59
[BeforeEach] [sig-node] Containers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:55:37.117
Apr 23 12:55:37.117: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename containers 04/23/23 12:55:37.127
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:55:37.182
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:55:37.193
[BeforeEach] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:31
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:59
STEP: Creating a pod to test override arguments 04/23/23 12:55:37.212
Apr 23 12:55:37.241: INFO: Waiting up to 5m0s for pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616" in namespace "containers-3217" to be "Succeeded or Failed"
Apr 23 12:55:37.250: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Pending", Reason="", readiness=false. Elapsed: 9.21721ms
Apr 23 12:55:39.257: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015899403s
Apr 23 12:55:41.259: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018146581s
Apr 23 12:55:43.260: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018921111s
Apr 23 12:55:45.258: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016648146s
Apr 23 12:55:47.260: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Pending", Reason="", readiness=false. Elapsed: 10.018555436s
Apr 23 12:55:49.267: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Pending", Reason="", readiness=false. Elapsed: 12.02580641s
Apr 23 12:55:51.262: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.020806253s
STEP: Saw pod success 04/23/23 12:55:51.262
Apr 23 12:55:51.262: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616" satisfied condition "Succeeded or Failed"
Apr 23 12:55:51.269: INFO: Trying to get logs from node eingavuivie7-3 pod client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616 container agnhost-container: <nil>
STEP: delete the pod 04/23/23 12:55:51.283
Apr 23 12:55:51.305: INFO: Waiting for pod client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616 to disappear
Apr 23 12:55:51.312: INFO: Pod client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/node/init/init.go:32
Apr 23 12:55:51.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Containers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Containers
  tear down framework | framework.go:193
STEP: Destroying namespace "containers-3217" for this suite. 04/23/23 12:55:51.32
------------------------------
â€¢ [SLOW TEST] [14.215 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:55:37.117
    Apr 23 12:55:37.117: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename containers 04/23/23 12:55:37.127
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:55:37.182
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:55:37.193
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:31
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:59
    STEP: Creating a pod to test override arguments 04/23/23 12:55:37.212
    Apr 23 12:55:37.241: INFO: Waiting up to 5m0s for pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616" in namespace "containers-3217" to be "Succeeded or Failed"
    Apr 23 12:55:37.250: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Pending", Reason="", readiness=false. Elapsed: 9.21721ms
    Apr 23 12:55:39.257: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015899403s
    Apr 23 12:55:41.259: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018146581s
    Apr 23 12:55:43.260: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018921111s
    Apr 23 12:55:45.258: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016648146s
    Apr 23 12:55:47.260: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Pending", Reason="", readiness=false. Elapsed: 10.018555436s
    Apr 23 12:55:49.267: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Pending", Reason="", readiness=false. Elapsed: 12.02580641s
    Apr 23 12:55:51.262: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.020806253s
    STEP: Saw pod success 04/23/23 12:55:51.262
    Apr 23 12:55:51.262: INFO: Pod "client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616" satisfied condition "Succeeded or Failed"
    Apr 23 12:55:51.269: INFO: Trying to get logs from node eingavuivie7-3 pod client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616 container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 12:55:51.283
    Apr 23 12:55:51.305: INFO: Waiting for pod client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616 to disappear
    Apr 23 12:55:51.312: INFO: Pod client-containers-f6ffc4ef-2f2f-4605-bf07-2093ef60d616 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:55:51.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Containers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Containers
      tear down framework | framework.go:193
    STEP: Destroying namespace "containers-3217" for this suite. 04/23/23 12:55:51.32
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:55:51.351
Apr 23 12:55:51.351: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename gc 04/23/23 12:55:51.355
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:55:51.393
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:55:51.4
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:31
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 04/23/23 12:55:51.405
STEP: delete the rc 04/23/23 12:55:56.425
STEP: wait for all pods to be garbage collected 04/23/23 12:55:56.441
STEP: Gathering metrics 04/23/23 12:56:01.459
Apr 23 12:56:01.517: INFO: Waiting up to 5m0s for pod "kube-controller-manager-eingavuivie7-2" in namespace "kube-system" to be "running and ready"
Apr 23 12:56:01.526: INFO: Pod "kube-controller-manager-eingavuivie7-2": Phase="Running", Reason="", readiness=true. Elapsed: 8.870319ms
Apr 23 12:56:01.526: INFO: The phase of Pod kube-controller-manager-eingavuivie7-2 is Running (Ready = true)
Apr 23 12:56:01.526: INFO: Pod "kube-controller-manager-eingavuivie7-2" satisfied condition "running and ready"
Apr 23 12:56:01.618: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/node/init/init.go:32
Apr 23 12:56:01.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] Garbage collector
  tear down framework | framework.go:193
STEP: Destroying namespace "gc-4866" for this suite. 04/23/23 12:56:01.631
------------------------------
â€¢ [SLOW TEST] [10.293 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:55:51.351
    Apr 23 12:55:51.351: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename gc 04/23/23 12:55:51.355
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:55:51.393
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:55:51.4
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:31
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 04/23/23 12:55:51.405
    STEP: delete the rc 04/23/23 12:55:56.425
    STEP: wait for all pods to be garbage collected 04/23/23 12:55:56.441
    STEP: Gathering metrics 04/23/23 12:56:01.459
    Apr 23 12:56:01.517: INFO: Waiting up to 5m0s for pod "kube-controller-manager-eingavuivie7-2" in namespace "kube-system" to be "running and ready"
    Apr 23 12:56:01.526: INFO: Pod "kube-controller-manager-eingavuivie7-2": Phase="Running", Reason="", readiness=true. Elapsed: 8.870319ms
    Apr 23 12:56:01.526: INFO: The phase of Pod kube-controller-manager-eingavuivie7-2 is Running (Ready = true)
    Apr 23 12:56:01.526: INFO: Pod "kube-controller-manager-eingavuivie7-2" satisfied condition "running and ready"
    Apr 23 12:56:01.618: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:56:01.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] Garbage collector
      tear down framework | framework.go:193
    STEP: Destroying namespace "gc-4866" for this suite. 04/23/23 12:56:01.631
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:87
[BeforeEach] [sig-storage] EmptyDir volumes
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:56:01.659
Apr 23 12:56:01.660: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename emptydir 04/23/23 12:56:01.662
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:01.693
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:01.698
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:31
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:87
STEP: Creating a pod to test emptydir volume type on tmpfs 04/23/23 12:56:01.702
Apr 23 12:56:01.720: INFO: Waiting up to 5m0s for pod "pod-66b40f27-4164-464e-a18e-564c7e3fcd56" in namespace "emptydir-8867" to be "Succeeded or Failed"
Apr 23 12:56:01.732: INFO: Pod "pod-66b40f27-4164-464e-a18e-564c7e3fcd56": Phase="Pending", Reason="", readiness=false. Elapsed: 12.076631ms
Apr 23 12:56:03.741: INFO: Pod "pod-66b40f27-4164-464e-a18e-564c7e3fcd56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021488372s
Apr 23 12:56:05.741: INFO: Pod "pod-66b40f27-4164-464e-a18e-564c7e3fcd56": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020948116s
Apr 23 12:56:07.739: INFO: Pod "pod-66b40f27-4164-464e-a18e-564c7e3fcd56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019492621s
STEP: Saw pod success 04/23/23 12:56:07.739
Apr 23 12:56:07.740: INFO: Pod "pod-66b40f27-4164-464e-a18e-564c7e3fcd56" satisfied condition "Succeeded or Failed"
Apr 23 12:56:07.745: INFO: Trying to get logs from node eingavuivie7-3 pod pod-66b40f27-4164-464e-a18e-564c7e3fcd56 container test-container: <nil>
STEP: delete the pod 04/23/23 12:56:07.763
Apr 23 12:56:07.783: INFO: Waiting for pod pod-66b40f27-4164-464e-a18e-564c7e3fcd56 to disappear
Apr 23 12:56:07.789: INFO: Pod pod-66b40f27-4164-464e-a18e-564c7e3fcd56 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/node/init/init.go:32
Apr 23 12:56:07.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] EmptyDir volumes
  tear down framework | framework.go:193
STEP: Destroying namespace "emptydir-8867" for this suite. 04/23/23 12:56:07.798
------------------------------
â€¢ [SLOW TEST] [6.150 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:56:01.659
    Apr 23 12:56:01.660: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename emptydir 04/23/23 12:56:01.662
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:01.693
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:01.698
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:31
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:87
    STEP: Creating a pod to test emptydir volume type on tmpfs 04/23/23 12:56:01.702
    Apr 23 12:56:01.720: INFO: Waiting up to 5m0s for pod "pod-66b40f27-4164-464e-a18e-564c7e3fcd56" in namespace "emptydir-8867" to be "Succeeded or Failed"
    Apr 23 12:56:01.732: INFO: Pod "pod-66b40f27-4164-464e-a18e-564c7e3fcd56": Phase="Pending", Reason="", readiness=false. Elapsed: 12.076631ms
    Apr 23 12:56:03.741: INFO: Pod "pod-66b40f27-4164-464e-a18e-564c7e3fcd56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021488372s
    Apr 23 12:56:05.741: INFO: Pod "pod-66b40f27-4164-464e-a18e-564c7e3fcd56": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020948116s
    Apr 23 12:56:07.739: INFO: Pod "pod-66b40f27-4164-464e-a18e-564c7e3fcd56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019492621s
    STEP: Saw pod success 04/23/23 12:56:07.739
    Apr 23 12:56:07.740: INFO: Pod "pod-66b40f27-4164-464e-a18e-564c7e3fcd56" satisfied condition "Succeeded or Failed"
    Apr 23 12:56:07.745: INFO: Trying to get logs from node eingavuivie7-3 pod pod-66b40f27-4164-464e-a18e-564c7e3fcd56 container test-container: <nil>
    STEP: delete the pod 04/23/23 12:56:07.763
    Apr 23 12:56:07.783: INFO: Waiting for pod pod-66b40f27-4164-464e-a18e-564c7e3fcd56 to disappear
    Apr 23 12:56:07.789: INFO: Pod pod-66b40f27-4164-464e-a18e-564c7e3fcd56 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:56:07.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] EmptyDir volumes
      tear down framework | framework.go:193
    STEP: Destroying namespace "emptydir-8867" for this suite. 04/23/23 12:56:07.798
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:108
[BeforeEach] [sig-apps] DisruptionController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:56:07.811
Apr 23 12:56:07.811: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename disruption 04/23/23 12:56:07.816
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:07.85
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:07.857
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:72
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:108
STEP: creating the pdb 04/23/23 12:56:07.86
STEP: Waiting for the pdb to be processed 04/23/23 12:56:07.87
STEP: updating the pdb 04/23/23 12:56:09.886
STEP: Waiting for the pdb to be processed 04/23/23 12:56:09.904
STEP: patching the pdb 04/23/23 12:56:11.919
STEP: Waiting for the pdb to be processed 04/23/23 12:56:11.942
STEP: Waiting for the pdb to be deleted 04/23/23 12:56:13.973
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/node/init/init.go:32
Apr 23 12:56:13.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] DisruptionController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] DisruptionController
  tear down framework | framework.go:193
STEP: Destroying namespace "disruption-7971" for this suite. 04/23/23 12:56:13.989
------------------------------
â€¢ [SLOW TEST] [6.195 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:56:07.811
    Apr 23 12:56:07.811: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename disruption 04/23/23 12:56:07.816
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:07.85
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:07.857
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:72
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:108
    STEP: creating the pdb 04/23/23 12:56:07.86
    STEP: Waiting for the pdb to be processed 04/23/23 12:56:07.87
    STEP: updating the pdb 04/23/23 12:56:09.886
    STEP: Waiting for the pdb to be processed 04/23/23 12:56:09.904
    STEP: patching the pdb 04/23/23 12:56:11.919
    STEP: Waiting for the pdb to be processed 04/23/23 12:56:11.942
    STEP: Waiting for the pdb to be deleted 04/23/23 12:56:13.973
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:56:13.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      tear down framework | framework.go:193
    STEP: Destroying namespace "disruption-7971" for this suite. 04/23/23 12:56:13.989
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:212
[BeforeEach] [sig-node] Container Lifecycle Hook
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:56:14.007
Apr 23 12:56:14.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-lifecycle-hook 04/23/23 12:56:14.01
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:14.051
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:14.062
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:77
STEP: create the container to handle the HTTPGet hook request. 04/23/23 12:56:14.095
Apr 23 12:56:14.119: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-6869" to be "running and ready"
Apr 23 12:56:14.127: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 8.205245ms
Apr 23 12:56:14.127: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:56:16.136: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017268622s
Apr 23 12:56:16.136: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:56:18.139: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.020117401s
Apr 23 12:56:18.139: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 23 12:56:18.139: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:212
STEP: create the pod with lifecycle hook 04/23/23 12:56:18.155
Apr 23 12:56:18.164: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-6869" to be "running and ready"
Apr 23 12:56:18.172: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 8.704743ms
Apr 23 12:56:18.173: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:56:20.180: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016630947s
Apr 23 12:56:20.180: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 23 12:56:22.184: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.020144636s
Apr 23 12:56:22.184: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Apr 23 12:56:22.184: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 04/23/23 12:56:22.193
Apr 23 12:56:22.213: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 23 12:56:22.224: INFO: Pod pod-with-prestop-http-hook still exists
Apr 23 12:56:24.225: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 23 12:56:24.236: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 04/23/23 12:56:24.236
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/node/init/init.go:32
Apr 23 12:56:24.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
  tear down framework | framework.go:193
STEP: Destroying namespace "container-lifecycle-hook-6869" for this suite. 04/23/23 12:56:24.278
------------------------------
â€¢ [SLOW TEST] [10.285 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:212

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:56:14.007
    Apr 23 12:56:14.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/23/23 12:56:14.01
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:14.051
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:14.062
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:77
    STEP: create the container to handle the HTTPGet hook request. 04/23/23 12:56:14.095
    Apr 23 12:56:14.119: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-6869" to be "running and ready"
    Apr 23 12:56:14.127: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 8.205245ms
    Apr 23 12:56:14.127: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:56:16.136: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017268622s
    Apr 23 12:56:16.136: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:56:18.139: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.020117401s
    Apr 23 12:56:18.139: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 23 12:56:18.139: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:212
    STEP: create the pod with lifecycle hook 04/23/23 12:56:18.155
    Apr 23 12:56:18.164: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-6869" to be "running and ready"
    Apr 23 12:56:18.172: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 8.704743ms
    Apr 23 12:56:18.173: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:56:20.180: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016630947s
    Apr 23 12:56:20.180: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 23 12:56:22.184: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.020144636s
    Apr 23 12:56:22.184: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Apr 23 12:56:22.184: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 04/23/23 12:56:22.193
    Apr 23 12:56:22.213: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 23 12:56:22.224: INFO: Pod pod-with-prestop-http-hook still exists
    Apr 23 12:56:24.225: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 23 12:56:24.236: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 04/23/23 12:56:24.236
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:56:24.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Container Lifecycle Hook
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-lifecycle-hook-6869" for this suite. 04/23/23 12:56:24.278
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:217
[BeforeEach] [sig-node] Downward API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:56:24.299
Apr 23 12:56:24.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 12:56:24.303
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:24.345
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:24.35
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:31
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:217
STEP: Creating a pod to test downward api env vars 04/23/23 12:56:24.355
Apr 23 12:56:24.372: INFO: Waiting up to 5m0s for pod "downward-api-28d59d00-47a5-4567-8ffa-002726348f53" in namespace "downward-api-5167" to be "Succeeded or Failed"
Apr 23 12:56:24.382: INFO: Pod "downward-api-28d59d00-47a5-4567-8ffa-002726348f53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.46714ms
Apr 23 12:56:26.391: INFO: Pod "downward-api-28d59d00-47a5-4567-8ffa-002726348f53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018539664s
Apr 23 12:56:28.389: INFO: Pod "downward-api-28d59d00-47a5-4567-8ffa-002726348f53": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016473138s
Apr 23 12:56:30.394: INFO: Pod "downward-api-28d59d00-47a5-4567-8ffa-002726348f53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022146621s
STEP: Saw pod success 04/23/23 12:56:30.395
Apr 23 12:56:30.395: INFO: Pod "downward-api-28d59d00-47a5-4567-8ffa-002726348f53" satisfied condition "Succeeded or Failed"
Apr 23 12:56:30.418: INFO: Trying to get logs from node eingavuivie7-3 pod downward-api-28d59d00-47a5-4567-8ffa-002726348f53 container dapi-container: <nil>
STEP: delete the pod 04/23/23 12:56:30.435
Apr 23 12:56:30.495: INFO: Waiting for pod downward-api-28d59d00-47a5-4567-8ffa-002726348f53 to disappear
Apr 23 12:56:30.508: INFO: Pod downward-api-28d59d00-47a5-4567-8ffa-002726348f53 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/node/init/init.go:32
Apr 23 12:56:30.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Downward API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Downward API
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-5167" for this suite. 04/23/23 12:56:30.53
------------------------------
â€¢ [SLOW TEST] [6.250 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:217

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:56:24.299
    Apr 23 12:56:24.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 12:56:24.303
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:24.345
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:24.35
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:217
    STEP: Creating a pod to test downward api env vars 04/23/23 12:56:24.355
    Apr 23 12:56:24.372: INFO: Waiting up to 5m0s for pod "downward-api-28d59d00-47a5-4567-8ffa-002726348f53" in namespace "downward-api-5167" to be "Succeeded or Failed"
    Apr 23 12:56:24.382: INFO: Pod "downward-api-28d59d00-47a5-4567-8ffa-002726348f53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.46714ms
    Apr 23 12:56:26.391: INFO: Pod "downward-api-28d59d00-47a5-4567-8ffa-002726348f53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018539664s
    Apr 23 12:56:28.389: INFO: Pod "downward-api-28d59d00-47a5-4567-8ffa-002726348f53": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016473138s
    Apr 23 12:56:30.394: INFO: Pod "downward-api-28d59d00-47a5-4567-8ffa-002726348f53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022146621s
    STEP: Saw pod success 04/23/23 12:56:30.395
    Apr 23 12:56:30.395: INFO: Pod "downward-api-28d59d00-47a5-4567-8ffa-002726348f53" satisfied condition "Succeeded or Failed"
    Apr 23 12:56:30.418: INFO: Trying to get logs from node eingavuivie7-3 pod downward-api-28d59d00-47a5-4567-8ffa-002726348f53 container dapi-container: <nil>
    STEP: delete the pod 04/23/23 12:56:30.435
    Apr 23 12:56:30.495: INFO: Waiting for pod downward-api-28d59d00-47a5-4567-8ffa-002726348f53 to disappear
    Apr 23 12:56:30.508: INFO: Pod downward-api-28d59d00-47a5-4567-8ffa-002726348f53 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:56:30.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Downward API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Downward API
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-5167" for this suite. 04/23/23 12:56:30.53
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:56:30.555
Apr 23 12:56:30.555: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename crd-webhook 04/23/23 12:56:30.561
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:30.615
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:30.624
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 04/23/23 12:56:30.632
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/23/23 12:56:32.555
STEP: Deploying the custom resource conversion webhook pod 04/23/23 12:56:32.618
STEP: Wait for the deployment to be ready 04/23/23 12:56:32.65
Apr 23 12:56:32.679: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Apr 23 12:56:34.714: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-74ff66dd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 23 12:56:36.723: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-74ff66dd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/23/23 12:56:38.725
STEP: Verifying the service has paired with the endpoint 04/23/23 12:56:38.756
Apr 23 12:56:39.757: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Apr 23 12:56:39.767: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Creating a v1 custom resource 04/23/23 12:56:42.966
STEP: Create a v2 custom resource 04/23/23 12:56:43.004
STEP: List CRs in v1 04/23/23 12:56:43.022
STEP: List CRs in v2 04/23/23 12:56:43.265
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/node/init/init.go:32
Apr 23 12:56:43.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  tear down framework | framework.go:193
STEP: Destroying namespace "crd-webhook-5207" for this suite. 04/23/23 12:56:44.161
------------------------------
â€¢ [SLOW TEST] [13.653 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:56:30.555
    Apr 23 12:56:30.555: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename crd-webhook 04/23/23 12:56:30.561
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:30.615
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:30.624
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 04/23/23 12:56:30.632
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/23/23 12:56:32.555
    STEP: Deploying the custom resource conversion webhook pod 04/23/23 12:56:32.618
    STEP: Wait for the deployment to be ready 04/23/23 12:56:32.65
    Apr 23 12:56:32.679: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Apr 23 12:56:34.714: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-74ff66dd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 23 12:56:36.723: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 23, 12, 56, 32, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-74ff66dd47\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/23/23 12:56:38.725
    STEP: Verifying the service has paired with the endpoint 04/23/23 12:56:38.756
    Apr 23 12:56:39.757: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Apr 23 12:56:39.767: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Creating a v1 custom resource 04/23/23 12:56:42.966
    STEP: Create a v2 custom resource 04/23/23 12:56:43.004
    STEP: List CRs in v1 04/23/23 12:56:43.022
    STEP: List CRs in v2 04/23/23 12:56:43.265
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:56:43.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      tear down framework | framework.go:193
    STEP: Destroying namespace "crd-webhook-5207" for this suite. 04/23/23 12:56:44.161
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:88
[BeforeEach] [sig-storage] Projected secret
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:56:44.232
Apr 23 12:56:44.232: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename projected 04/23/23 12:56:44.238
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:44.459
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:44.464
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:88
STEP: Creating projection with secret that has name projected-secret-test-map-07e416ca-d81c-42d3-9d7f-9afc5836aa7c 04/23/23 12:56:44.488
STEP: Creating a pod to test consume secrets 04/23/23 12:56:44.497
Apr 23 12:56:44.521: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5" in namespace "projected-7108" to be "Succeeded or Failed"
Apr 23 12:56:44.528: INFO: Pod "pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.735076ms
Apr 23 12:56:46.604: INFO: Pod "pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083844444s
Apr 23 12:56:48.536: INFO: Pod "pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5": Phase="Running", Reason="", readiness=false. Elapsed: 4.015009937s
Apr 23 12:56:50.534: INFO: Pod "pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5": Phase="Running", Reason="", readiness=false. Elapsed: 6.013674684s
Apr 23 12:56:52.540: INFO: Pod "pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.019056878s
STEP: Saw pod success 04/23/23 12:56:52.54
Apr 23 12:56:52.540: INFO: Pod "pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5" satisfied condition "Succeeded or Failed"
Apr 23 12:56:52.546: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/23/23 12:56:52.559
Apr 23 12:56:52.581: INFO: Waiting for pod pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5 to disappear
Apr 23 12:56:52.588: INFO: Pod pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/node/init/init.go:32
Apr 23 12:56:52.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Projected secret
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Projected secret
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Projected secret
  tear down framework | framework.go:193
STEP: Destroying namespace "projected-7108" for this suite. 04/23/23 12:56:52.596
------------------------------
â€¢ [SLOW TEST] [8.384 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:56:44.232
    Apr 23 12:56:44.232: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename projected 04/23/23 12:56:44.238
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:44.459
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:44.464
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:88
    STEP: Creating projection with secret that has name projected-secret-test-map-07e416ca-d81c-42d3-9d7f-9afc5836aa7c 04/23/23 12:56:44.488
    STEP: Creating a pod to test consume secrets 04/23/23 12:56:44.497
    Apr 23 12:56:44.521: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5" in namespace "projected-7108" to be "Succeeded or Failed"
    Apr 23 12:56:44.528: INFO: Pod "pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.735076ms
    Apr 23 12:56:46.604: INFO: Pod "pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083844444s
    Apr 23 12:56:48.536: INFO: Pod "pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5": Phase="Running", Reason="", readiness=false. Elapsed: 4.015009937s
    Apr 23 12:56:50.534: INFO: Pod "pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5": Phase="Running", Reason="", readiness=false. Elapsed: 6.013674684s
    Apr 23 12:56:52.540: INFO: Pod "pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.019056878s
    STEP: Saw pod success 04/23/23 12:56:52.54
    Apr 23 12:56:52.540: INFO: Pod "pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5" satisfied condition "Succeeded or Failed"
    Apr 23 12:56:52.546: INFO: Trying to get logs from node eingavuivie7-3 pod pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/23/23 12:56:52.559
    Apr 23 12:56:52.581: INFO: Waiting for pod pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5 to disappear
    Apr 23 12:56:52.588: INFO: Pod pod-projected-secrets-7458a66a-3a7f-49ec-86f7-456759e9aaa5 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:56:52.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Projected secret
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Projected secret
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Projected secret
      tear down framework | framework.go:193
    STEP: Destroying namespace "projected-7108" for this suite. 04/23/23 12:56:52.596
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:87
[BeforeEach] [sig-node] Containers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:56:52.63
Apr 23 12:56:52.630: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename containers 04/23/23 12:56:52.632
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:52.671
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:52.675
[BeforeEach] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:31
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:87
STEP: Creating a pod to test override all 04/23/23 12:56:52.678
Apr 23 12:56:52.696: INFO: Waiting up to 5m0s for pod "client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116" in namespace "containers-9536" to be "Succeeded or Failed"
Apr 23 12:56:52.703: INFO: Pod "client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116": Phase="Pending", Reason="", readiness=false. Elapsed: 6.307164ms
Apr 23 12:56:54.712: INFO: Pod "client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015373573s
Apr 23 12:56:56.711: INFO: Pod "client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014289124s
Apr 23 12:56:58.711: INFO: Pod "client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01464899s
STEP: Saw pod success 04/23/23 12:56:58.711
Apr 23 12:56:58.711: INFO: Pod "client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116" satisfied condition "Succeeded or Failed"
Apr 23 12:56:58.717: INFO: Trying to get logs from node eingavuivie7-3 pod client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116 container agnhost-container: <nil>
STEP: delete the pod 04/23/23 12:56:58.735
Apr 23 12:56:58.759: INFO: Waiting for pod client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116 to disappear
Apr 23 12:56:58.764: INFO: Pod client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/node/init/init.go:32
Apr 23 12:56:58.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Containers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Containers
  tear down framework | framework.go:193
STEP: Destroying namespace "containers-9536" for this suite. 04/23/23 12:56:58.776
------------------------------
â€¢ [SLOW TEST] [6.164 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:56:52.63
    Apr 23 12:56:52.630: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename containers 04/23/23 12:56:52.632
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:52.671
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:52.675
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:31
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:87
    STEP: Creating a pod to test override all 04/23/23 12:56:52.678
    Apr 23 12:56:52.696: INFO: Waiting up to 5m0s for pod "client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116" in namespace "containers-9536" to be "Succeeded or Failed"
    Apr 23 12:56:52.703: INFO: Pod "client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116": Phase="Pending", Reason="", readiness=false. Elapsed: 6.307164ms
    Apr 23 12:56:54.712: INFO: Pod "client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015373573s
    Apr 23 12:56:56.711: INFO: Pod "client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014289124s
    Apr 23 12:56:58.711: INFO: Pod "client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01464899s
    STEP: Saw pod success 04/23/23 12:56:58.711
    Apr 23 12:56:58.711: INFO: Pod "client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116" satisfied condition "Succeeded or Failed"
    Apr 23 12:56:58.717: INFO: Trying to get logs from node eingavuivie7-3 pod client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116 container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 12:56:58.735
    Apr 23 12:56:58.759: INFO: Waiting for pod client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116 to disappear
    Apr 23 12:56:58.764: INFO: Pod client-containers-8a8c6ca1-1eb7-4046-a111-2dc644de7116 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:56:58.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Containers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Containers
      tear down framework | framework.go:193
    STEP: Destroying namespace "containers-9536" for this suite. 04/23/23 12:56:58.776
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:649
[BeforeEach] [sig-auth] ServiceAccounts
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:56:58.798
Apr 23 12:56:58.798: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename svcaccounts 04/23/23 12:56:58.801
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:58.834
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:58.838
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:31
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:649
STEP: creating a ServiceAccount 04/23/23 12:56:58.842
STEP: watching for the ServiceAccount to be added 04/23/23 12:56:58.855
STEP: patching the ServiceAccount 04/23/23 12:56:58.857
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 04/23/23 12:56:58.869
STEP: deleting the ServiceAccount 04/23/23 12:56:58.878
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/node/init/init.go:32
Apr 23 12:56:58.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-auth] ServiceAccounts
  tear down framework | framework.go:193
STEP: Destroying namespace "svcaccounts-5766" for this suite. 04/23/23 12:56:58.929
------------------------------
â€¢ [0.155 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:649

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:56:58.798
    Apr 23 12:56:58.798: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename svcaccounts 04/23/23 12:56:58.801
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:58.834
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:58.838
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:31
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:649
    STEP: creating a ServiceAccount 04/23/23 12:56:58.842
    STEP: watching for the ServiceAccount to be added 04/23/23 12:56:58.855
    STEP: patching the ServiceAccount 04/23/23 12:56:58.857
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 04/23/23 12:56:58.869
    STEP: deleting the ServiceAccount 04/23/23 12:56:58.878
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:56:58.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-auth] ServiceAccounts
      tear down framework | framework.go:193
    STEP: Destroying namespace "svcaccounts-5766" for this suite. 04/23/23 12:56:58.929
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:962
[BeforeEach] [sig-cli] Kubectl client
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:56:58.953
Apr 23 12:56:58.953: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubectl 04/23/23 12:56:58.959
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:59.006
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:59.014
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:274
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:962
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 04/23/23 12:56:59.026
Apr 23 12:56:59.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-4673 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr 23 12:56:59.229: INFO: stderr: ""
Apr 23 12:56:59.229: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 04/23/23 12:56:59.229
Apr 23 12:56:59.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-4673 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-4"}]}} --dry-run=server'
Apr 23 12:57:01.682: INFO: stderr: ""
Apr 23 12:57:01.682: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 04/23/23 12:57:01.682
Apr 23 12:57:01.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-4673 delete pods e2e-test-httpd-pod'
Apr 23 12:57:05.228: INFO: stderr: ""
Apr 23 12:57:05.229: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/node/init/init.go:32
Apr 23 12:57:05.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-cli] Kubectl client
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-cli] Kubectl client
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-cli] Kubectl client
  tear down framework | framework.go:193
STEP: Destroying namespace "kubectl-4673" for this suite. 04/23/23 12:57:05.24
------------------------------
â€¢ [SLOW TEST] [6.300 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:956
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:962

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:56:58.953
    Apr 23 12:56:58.953: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubectl 04/23/23 12:56:58.959
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:56:59.006
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:56:59.014
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:274
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:962
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 04/23/23 12:56:59.026
    Apr 23 12:56:59.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-4673 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Apr 23 12:56:59.229: INFO: stderr: ""
    Apr 23 12:56:59.229: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 04/23/23 12:56:59.229
    Apr 23 12:56:59.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-4673 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-4"}]}} --dry-run=server'
    Apr 23 12:57:01.682: INFO: stderr: ""
    Apr 23 12:57:01.682: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 04/23/23 12:57:01.682
    Apr 23 12:57:01.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2504172558 --namespace=kubectl-4673 delete pods e2e-test-httpd-pod'
    Apr 23 12:57:05.228: INFO: stderr: ""
    Apr 23 12:57:05.229: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:57:05.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-cli] Kubectl client
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubectl-4673" for this suite. 04/23/23 12:57:05.24
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:166
[BeforeEach] [sig-node] Downward API
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:57:05.26
Apr 23 12:57:05.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename downward-api 04/23/23 12:57:05.262
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:57:05.312
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:57:05.317
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:31
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:166
STEP: Creating a pod to test downward api env vars 04/23/23 12:57:05.325
Apr 23 12:57:05.345: INFO: Waiting up to 5m0s for pod "downward-api-9f409dd8-0991-4747-81db-546afb06ba91" in namespace "downward-api-7134" to be "Succeeded or Failed"
Apr 23 12:57:05.381: INFO: Pod "downward-api-9f409dd8-0991-4747-81db-546afb06ba91": Phase="Pending", Reason="", readiness=false. Elapsed: 35.973799ms
Apr 23 12:57:07.441: INFO: Pod "downward-api-9f409dd8-0991-4747-81db-546afb06ba91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.095832386s
Apr 23 12:57:09.393: INFO: Pod "downward-api-9f409dd8-0991-4747-81db-546afb06ba91": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048758122s
Apr 23 12:57:11.396: INFO: Pod "downward-api-9f409dd8-0991-4747-81db-546afb06ba91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05108035s
STEP: Saw pod success 04/23/23 12:57:11.397
Apr 23 12:57:11.399: INFO: Pod "downward-api-9f409dd8-0991-4747-81db-546afb06ba91" satisfied condition "Succeeded or Failed"
Apr 23 12:57:11.408: INFO: Trying to get logs from node eingavuivie7-3 pod downward-api-9f409dd8-0991-4747-81db-546afb06ba91 container dapi-container: <nil>
STEP: delete the pod 04/23/23 12:57:11.88
Apr 23 12:57:11.906: INFO: Waiting for pod downward-api-9f409dd8-0991-4747-81db-546afb06ba91 to disappear
Apr 23 12:57:11.916: INFO: Pod downward-api-9f409dd8-0991-4747-81db-546afb06ba91 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/node/init/init.go:32
Apr 23 12:57:11.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Downward API
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Downward API
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Downward API
  tear down framework | framework.go:193
STEP: Destroying namespace "downward-api-7134" for this suite. 04/23/23 12:57:11.937
------------------------------
â€¢ [SLOW TEST] [6.696 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:57:05.26
    Apr 23 12:57:05.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename downward-api 04/23/23 12:57:05.262
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:57:05.312
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:57:05.317
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:166
    STEP: Creating a pod to test downward api env vars 04/23/23 12:57:05.325
    Apr 23 12:57:05.345: INFO: Waiting up to 5m0s for pod "downward-api-9f409dd8-0991-4747-81db-546afb06ba91" in namespace "downward-api-7134" to be "Succeeded or Failed"
    Apr 23 12:57:05.381: INFO: Pod "downward-api-9f409dd8-0991-4747-81db-546afb06ba91": Phase="Pending", Reason="", readiness=false. Elapsed: 35.973799ms
    Apr 23 12:57:07.441: INFO: Pod "downward-api-9f409dd8-0991-4747-81db-546afb06ba91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.095832386s
    Apr 23 12:57:09.393: INFO: Pod "downward-api-9f409dd8-0991-4747-81db-546afb06ba91": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048758122s
    Apr 23 12:57:11.396: INFO: Pod "downward-api-9f409dd8-0991-4747-81db-546afb06ba91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05108035s
    STEP: Saw pod success 04/23/23 12:57:11.397
    Apr 23 12:57:11.399: INFO: Pod "downward-api-9f409dd8-0991-4747-81db-546afb06ba91" satisfied condition "Succeeded or Failed"
    Apr 23 12:57:11.408: INFO: Trying to get logs from node eingavuivie7-3 pod downward-api-9f409dd8-0991-4747-81db-546afb06ba91 container dapi-container: <nil>
    STEP: delete the pod 04/23/23 12:57:11.88
    Apr 23 12:57:11.906: INFO: Waiting for pod downward-api-9f409dd8-0991-4747-81db-546afb06ba91 to disappear
    Apr 23 12:57:11.916: INFO: Pod downward-api-9f409dd8-0991-4747-81db-546afb06ba91 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:57:11.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Downward API
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Downward API
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Downward API
      tear down framework | framework.go:193
    STEP: Destroying namespace "downward-api-7134" for this suite. 04/23/23 12:57:11.937
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:89
[BeforeEach] [sig-storage] ConfigMap
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:57:11.98
Apr 23 12:57:11.981: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename configmap 04/23/23 12:57:11.988
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:57:12.025
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:57:12.037
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:89
STEP: Creating configMap with name configmap-test-volume-map-262dc328-a2af-4da2-b114-d73e2b99b737 04/23/23 12:57:12.053
STEP: Creating a pod to test consume configMaps 04/23/23 12:57:12.07
Apr 23 12:57:12.088: INFO: Waiting up to 5m0s for pod "pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b" in namespace "configmap-9769" to be "Succeeded or Failed"
Apr 23 12:57:12.095: INFO: Pod "pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.035371ms
Apr 23 12:57:14.105: INFO: Pod "pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017083327s
Apr 23 12:57:16.104: INFO: Pod "pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b": Phase="Running", Reason="", readiness=false. Elapsed: 4.015413168s
Apr 23 12:57:18.102: INFO: Pod "pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013843726s
STEP: Saw pod success 04/23/23 12:57:18.102
Apr 23 12:57:18.102: INFO: Pod "pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b" satisfied condition "Succeeded or Failed"
Apr 23 12:57:18.108: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b container agnhost-container: <nil>
STEP: delete the pod 04/23/23 12:57:18.121
Apr 23 12:57:18.142: INFO: Waiting for pod pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b to disappear
Apr 23 12:57:18.146: INFO: Pod pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/node/init/init.go:32
Apr 23 12:57:18.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] ConfigMap
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] ConfigMap
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] ConfigMap
  tear down framework | framework.go:193
STEP: Destroying namespace "configmap-9769" for this suite. 04/23/23 12:57:18.155
------------------------------
â€¢ [SLOW TEST] [6.192 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:57:11.98
    Apr 23 12:57:11.981: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename configmap 04/23/23 12:57:11.988
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:57:12.025
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:57:12.037
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:89
    STEP: Creating configMap with name configmap-test-volume-map-262dc328-a2af-4da2-b114-d73e2b99b737 04/23/23 12:57:12.053
    STEP: Creating a pod to test consume configMaps 04/23/23 12:57:12.07
    Apr 23 12:57:12.088: INFO: Waiting up to 5m0s for pod "pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b" in namespace "configmap-9769" to be "Succeeded or Failed"
    Apr 23 12:57:12.095: INFO: Pod "pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.035371ms
    Apr 23 12:57:14.105: INFO: Pod "pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017083327s
    Apr 23 12:57:16.104: INFO: Pod "pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b": Phase="Running", Reason="", readiness=false. Elapsed: 4.015413168s
    Apr 23 12:57:18.102: INFO: Pod "pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013843726s
    STEP: Saw pod success 04/23/23 12:57:18.102
    Apr 23 12:57:18.102: INFO: Pod "pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b" satisfied condition "Succeeded or Failed"
    Apr 23 12:57:18.108: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b container agnhost-container: <nil>
    STEP: delete the pod 04/23/23 12:57:18.121
    Apr 23 12:57:18.142: INFO: Waiting for pod pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b to disappear
    Apr 23 12:57:18.146: INFO: Pod pod-configmaps-ba7b73f5-465c-41b2-9513-21e679df612b no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:57:18.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] ConfigMap
      tear down framework | framework.go:193
    STEP: Destroying namespace "configmap-9769" for this suite. 04/23/23 12:57:18.155
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:95
[BeforeEach] [sig-node] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:57:18.175
Apr 23 12:57:18.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename secrets 04/23/23 12:57:18.189
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:57:18.226
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:57:18.231
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:95
STEP: creating secret secrets-7201/secret-test-66776dc0-06c3-4d6c-9068-83bd554258c3 04/23/23 12:57:18.237
STEP: Creating a pod to test consume secrets 04/23/23 12:57:18.253
Apr 23 12:57:18.280: INFO: Waiting up to 5m0s for pod "pod-configmaps-ed538036-0044-4e95-9da4-88669564a502" in namespace "secrets-7201" to be "Succeeded or Failed"
Apr 23 12:57:18.308: INFO: Pod "pod-configmaps-ed538036-0044-4e95-9da4-88669564a502": Phase="Pending", Reason="", readiness=false. Elapsed: 27.664911ms
Apr 23 12:57:20.316: INFO: Pod "pod-configmaps-ed538036-0044-4e95-9da4-88669564a502": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035251664s
Apr 23 12:57:22.317: INFO: Pod "pod-configmaps-ed538036-0044-4e95-9da4-88669564a502": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036419163s
Apr 23 12:57:24.318: INFO: Pod "pod-configmaps-ed538036-0044-4e95-9da4-88669564a502": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037566381s
STEP: Saw pod success 04/23/23 12:57:24.318
Apr 23 12:57:24.319: INFO: Pod "pod-configmaps-ed538036-0044-4e95-9da4-88669564a502" satisfied condition "Succeeded or Failed"
Apr 23 12:57:24.327: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-ed538036-0044-4e95-9da4-88669564a502 container env-test: <nil>
STEP: delete the pod 04/23/23 12:57:24.344
Apr 23 12:57:24.373: INFO: Waiting for pod pod-configmaps-ed538036-0044-4e95-9da4-88669564a502 to disappear
Apr 23 12:57:24.381: INFO: Pod pod-configmaps-ed538036-0044-4e95-9da4-88669564a502 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/node/init/init.go:32
Apr 23 12:57:24.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-7201" for this suite. 04/23/23 12:57:24.393
------------------------------
â€¢ [SLOW TEST] [6.241 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:95

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:57:18.175
    Apr 23 12:57:18.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename secrets 04/23/23 12:57:18.189
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:57:18.226
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:57:18.231
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:95
    STEP: creating secret secrets-7201/secret-test-66776dc0-06c3-4d6c-9068-83bd554258c3 04/23/23 12:57:18.237
    STEP: Creating a pod to test consume secrets 04/23/23 12:57:18.253
    Apr 23 12:57:18.280: INFO: Waiting up to 5m0s for pod "pod-configmaps-ed538036-0044-4e95-9da4-88669564a502" in namespace "secrets-7201" to be "Succeeded or Failed"
    Apr 23 12:57:18.308: INFO: Pod "pod-configmaps-ed538036-0044-4e95-9da4-88669564a502": Phase="Pending", Reason="", readiness=false. Elapsed: 27.664911ms
    Apr 23 12:57:20.316: INFO: Pod "pod-configmaps-ed538036-0044-4e95-9da4-88669564a502": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035251664s
    Apr 23 12:57:22.317: INFO: Pod "pod-configmaps-ed538036-0044-4e95-9da4-88669564a502": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036419163s
    Apr 23 12:57:24.318: INFO: Pod "pod-configmaps-ed538036-0044-4e95-9da4-88669564a502": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037566381s
    STEP: Saw pod success 04/23/23 12:57:24.318
    Apr 23 12:57:24.319: INFO: Pod "pod-configmaps-ed538036-0044-4e95-9da4-88669564a502" satisfied condition "Succeeded or Failed"
    Apr 23 12:57:24.327: INFO: Trying to get logs from node eingavuivie7-3 pod pod-configmaps-ed538036-0044-4e95-9da4-88669564a502 container env-test: <nil>
    STEP: delete the pod 04/23/23 12:57:24.344
    Apr 23 12:57:24.373: INFO: Waiting for pod pod-configmaps-ed538036-0044-4e95-9da4-88669564a502 to disappear
    Apr 23 12:57:24.381: INFO: Pod pod-configmaps-ed538036-0044-4e95-9da4-88669564a502 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:57:24.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-7201" for this suite. 04/23/23 12:57:24.393
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:57:24.424
Apr 23 12:57:24.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename kubelet-test 04/23/23 12:57:24.431
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:57:24.481
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:57:24.487
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/node/init/init.go:32
Apr 23 12:57:28.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Kubelet
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Kubelet
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Kubelet
  tear down framework | framework.go:193
STEP: Destroying namespace "kubelet-test-1435" for this suite. 04/23/23 12:57:28.562
------------------------------
â€¢ [4.167 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:57:24.424
    Apr 23 12:57:24.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename kubelet-test 04/23/23 12:57:24.431
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:57:24.481
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:57:24.487
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:57:28.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Kubelet
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Kubelet
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Kubelet
      tear down framework | framework.go:193
    STEP: Destroying namespace "kubelet-test-1435" for this suite. 04/23/23 12:57:28.562
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-scheduling] LimitRange
  should list, patch and delete a LimitRange by collection [Conformance]
  test/e2e/scheduling/limit_range.go:239
[BeforeEach] [sig-scheduling] LimitRange
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:57:28.601
Apr 23 12:57:28.602: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename limitrange 04/23/23 12:57:28.606
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:57:28.649
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:57:28.656
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/metrics/init/init.go:31
[It] should list, patch and delete a LimitRange by collection [Conformance]
  test/e2e/scheduling/limit_range.go:239
STEP: Creating LimitRange "e2e-limitrange-tg2z7" in namespace "limitrange-4830" 04/23/23 12:57:28.662
STEP: Creating another limitRange in another namespace 04/23/23 12:57:28.676
Apr 23 12:57:28.706: INFO: Namespace "e2e-limitrange-tg2z7-7625" created
Apr 23 12:57:28.706: INFO: Creating LimitRange "e2e-limitrange-tg2z7" in namespace "e2e-limitrange-tg2z7-7625"
STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-tg2z7" 04/23/23 12:57:28.718
Apr 23 12:57:28.728: INFO: Found 2 limitRanges
STEP: Patching LimitRange "e2e-limitrange-tg2z7" in "limitrange-4830" namespace 04/23/23 12:57:28.728
Apr 23 12:57:28.763: INFO: LimitRange "e2e-limitrange-tg2z7" has been patched
STEP: Delete LimitRange "e2e-limitrange-tg2z7" by Collection with labelSelector: "e2e-limitrange-tg2z7=patched" 04/23/23 12:57:28.763
STEP: Confirm that the limitRange "e2e-limitrange-tg2z7" has been deleted 04/23/23 12:57:28.783
Apr 23 12:57:28.784: INFO: Requesting list of LimitRange to confirm quantity
Apr 23 12:57:28.791: INFO: Found 0 LimitRange with label "e2e-limitrange-tg2z7=patched"
Apr 23 12:57:28.791: INFO: LimitRange "e2e-limitrange-tg2z7" has been deleted.
STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-tg2z7" 04/23/23 12:57:28.791
Apr 23 12:57:28.801: INFO: Found 1 limitRange
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/node/init/init.go:32
Apr 23 12:57:28.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-scheduling] LimitRange
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-scheduling] LimitRange
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-scheduling] LimitRange
  tear down framework | framework.go:193
STEP: Destroying namespace "limitrange-4830" for this suite. 04/23/23 12:57:28.809
STEP: Destroying namespace "e2e-limitrange-tg2z7-7625" for this suite. 04/23/23 12:57:28.824
------------------------------
â€¢ [0.235 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should list, patch and delete a LimitRange by collection [Conformance]
  test/e2e/scheduling/limit_range.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:57:28.601
    Apr 23 12:57:28.602: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename limitrange 04/23/23 12:57:28.606
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:57:28.649
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:57:28.656
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/metrics/init/init.go:31
    [It] should list, patch and delete a LimitRange by collection [Conformance]
      test/e2e/scheduling/limit_range.go:239
    STEP: Creating LimitRange "e2e-limitrange-tg2z7" in namespace "limitrange-4830" 04/23/23 12:57:28.662
    STEP: Creating another limitRange in another namespace 04/23/23 12:57:28.676
    Apr 23 12:57:28.706: INFO: Namespace "e2e-limitrange-tg2z7-7625" created
    Apr 23 12:57:28.706: INFO: Creating LimitRange "e2e-limitrange-tg2z7" in namespace "e2e-limitrange-tg2z7-7625"
    STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-tg2z7" 04/23/23 12:57:28.718
    Apr 23 12:57:28.728: INFO: Found 2 limitRanges
    STEP: Patching LimitRange "e2e-limitrange-tg2z7" in "limitrange-4830" namespace 04/23/23 12:57:28.728
    Apr 23 12:57:28.763: INFO: LimitRange "e2e-limitrange-tg2z7" has been patched
    STEP: Delete LimitRange "e2e-limitrange-tg2z7" by Collection with labelSelector: "e2e-limitrange-tg2z7=patched" 04/23/23 12:57:28.763
    STEP: Confirm that the limitRange "e2e-limitrange-tg2z7" has been deleted 04/23/23 12:57:28.783
    Apr 23 12:57:28.784: INFO: Requesting list of LimitRange to confirm quantity
    Apr 23 12:57:28.791: INFO: Found 0 LimitRange with label "e2e-limitrange-tg2z7=patched"
    Apr 23 12:57:28.791: INFO: LimitRange "e2e-limitrange-tg2z7" has been deleted.
    STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-tg2z7" 04/23/23 12:57:28.791
    Apr 23 12:57:28.801: INFO: Found 1 limitRange
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:57:28.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-scheduling] LimitRange
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-scheduling] LimitRange
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-scheduling] LimitRange
      tear down framework | framework.go:193
    STEP: Destroying namespace "limitrange-4830" for this suite. 04/23/23 12:57:28.809
    STEP: Destroying namespace "e2e-limitrange-tg2z7-7625" for this suite. 04/23/23 12:57:28.824
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:57:28.837
Apr 23 12:57:28.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename dns 04/23/23 12:57:28.843
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:57:28.875
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:57:28.88
[BeforeEach] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:31
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 04/23/23 12:57:28.887
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-256.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-256.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-256.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-256.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-256.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-256.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 94.58.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.58.94_udp@PTR;check="$$(dig +tcp +noall +answer +search 94.58.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.58.94_tcp@PTR;sleep 1; done
 04/23/23 12:57:28.939
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-256.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-256.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-256.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-256.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-256.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-256.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 94.58.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.58.94_udp@PTR;check="$$(dig +tcp +noall +answer +search 94.58.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.58.94_tcp@PTR;sleep 1; done
 04/23/23 12:57:28.941
STEP: creating a pod to probe DNS 04/23/23 12:57:28.941
STEP: submitting the pod to kubernetes 04/23/23 12:57:28.941
Apr 23 12:57:28.982: INFO: Waiting up to 15m0s for pod "dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d" in namespace "dns-256" to be "running"
Apr 23 12:57:29.016: INFO: Pod "dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d": Phase="Pending", Reason="", readiness=false. Elapsed: 33.723087ms
Apr 23 12:57:31.026: INFO: Pod "dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043824115s
Apr 23 12:57:33.034: INFO: Pod "dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d": Phase="Running", Reason="", readiness=true. Elapsed: 4.051084017s
Apr 23 12:57:33.034: INFO: Pod "dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d" satisfied condition "running"
STEP: retrieving the pod 04/23/23 12:57:33.034
STEP: looking for the results for each expected name from probers 04/23/23 12:57:33.07
Apr 23 12:57:33.088: INFO: Unable to read wheezy_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:33.102: INFO: Unable to read wheezy_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:33.109: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:33.119: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:33.170: INFO: Unable to read jessie_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:33.178: INFO: Unable to read jessie_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:33.190: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:33.210: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:33.261: INFO: Lookups using dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d failed for: [wheezy_udp@dns-test-service.dns-256.svc.cluster.local wheezy_tcp@dns-test-service.dns-256.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_udp@dns-test-service.dns-256.svc.cluster.local jessie_tcp@dns-test-service.dns-256.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local]

Apr 23 12:57:38.273: INFO: Unable to read wheezy_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:38.278: INFO: Unable to read wheezy_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:38.284: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:38.291: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:38.323: INFO: Unable to read jessie_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:38.332: INFO: Unable to read jessie_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:38.338: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:38.345: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:38.377: INFO: Lookups using dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d failed for: [wheezy_udp@dns-test-service.dns-256.svc.cluster.local wheezy_tcp@dns-test-service.dns-256.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_udp@dns-test-service.dns-256.svc.cluster.local jessie_tcp@dns-test-service.dns-256.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local]

Apr 23 12:57:43.281: INFO: Unable to read wheezy_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:43.289: INFO: Unable to read wheezy_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:43.297: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:43.305: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:43.357: INFO: Unable to read jessie_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:43.368: INFO: Unable to read jessie_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:43.384: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:43.393: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:43.461: INFO: Lookups using dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d failed for: [wheezy_udp@dns-test-service.dns-256.svc.cluster.local wheezy_tcp@dns-test-service.dns-256.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_udp@dns-test-service.dns-256.svc.cluster.local jessie_tcp@dns-test-service.dns-256.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local]

Apr 23 12:57:48.273: INFO: Unable to read wheezy_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:48.284: INFO: Unable to read wheezy_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:48.290: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:48.297: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:48.341: INFO: Unable to read jessie_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:48.349: INFO: Unable to read jessie_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:48.356: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:48.361: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:48.395: INFO: Lookups using dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d failed for: [wheezy_udp@dns-test-service.dns-256.svc.cluster.local wheezy_tcp@dns-test-service.dns-256.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_udp@dns-test-service.dns-256.svc.cluster.local jessie_tcp@dns-test-service.dns-256.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local]

Apr 23 12:57:53.272: INFO: Unable to read wheezy_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:53.280: INFO: Unable to read wheezy_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:53.292: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:53.304: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:53.366: INFO: Unable to read jessie_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:53.374: INFO: Unable to read jessie_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:53.381: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:53.389: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:53.414: INFO: Lookups using dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d failed for: [wheezy_udp@dns-test-service.dns-256.svc.cluster.local wheezy_tcp@dns-test-service.dns-256.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_udp@dns-test-service.dns-256.svc.cluster.local jessie_tcp@dns-test-service.dns-256.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local]

Apr 23 12:57:58.273: INFO: Unable to read wheezy_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:58.281: INFO: Unable to read wheezy_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:58.291: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:58.298: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:58.339: INFO: Unable to read jessie_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:58.345: INFO: Unable to read jessie_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:58.358: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:58.370: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
Apr 23 12:57:58.398: INFO: Lookups using dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d failed for: [wheezy_udp@dns-test-service.dns-256.svc.cluster.local wheezy_tcp@dns-test-service.dns-256.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_udp@dns-test-service.dns-256.svc.cluster.local jessie_tcp@dns-test-service.dns-256.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local]

Apr 23 12:58:03.585: INFO: DNS probes using dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d succeeded

STEP: deleting the pod 04/23/23 12:58:03.585
STEP: deleting the test service 04/23/23 12:58:03.681
STEP: deleting the test headless service 04/23/23 12:58:03.784
[AfterEach] [sig-network] DNS
  test/e2e/framework/node/init/init.go:32
Apr 23 12:58:03.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-network] DNS
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-network] DNS
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-network] DNS
  tear down framework | framework.go:193
STEP: Destroying namespace "dns-256" for this suite. 04/23/23 12:58:03.832
------------------------------
â€¢ [SLOW TEST] [35.016 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:57:28.837
    Apr 23 12:57:28.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename dns 04/23/23 12:57:28.843
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:57:28.875
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:57:28.88
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:31
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 04/23/23 12:57:28.887
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-256.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-256.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-256.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-256.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-256.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-256.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 94.58.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.58.94_udp@PTR;check="$$(dig +tcp +noall +answer +search 94.58.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.58.94_tcp@PTR;sleep 1; done
     04/23/23 12:57:28.939
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-256.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-256.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-256.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-256.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-256.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-256.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-256.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 94.58.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.58.94_udp@PTR;check="$$(dig +tcp +noall +answer +search 94.58.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.58.94_tcp@PTR;sleep 1; done
     04/23/23 12:57:28.941
    STEP: creating a pod to probe DNS 04/23/23 12:57:28.941
    STEP: submitting the pod to kubernetes 04/23/23 12:57:28.941
    Apr 23 12:57:28.982: INFO: Waiting up to 15m0s for pod "dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d" in namespace "dns-256" to be "running"
    Apr 23 12:57:29.016: INFO: Pod "dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d": Phase="Pending", Reason="", readiness=false. Elapsed: 33.723087ms
    Apr 23 12:57:31.026: INFO: Pod "dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043824115s
    Apr 23 12:57:33.034: INFO: Pod "dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d": Phase="Running", Reason="", readiness=true. Elapsed: 4.051084017s
    Apr 23 12:57:33.034: INFO: Pod "dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d" satisfied condition "running"
    STEP: retrieving the pod 04/23/23 12:57:33.034
    STEP: looking for the results for each expected name from probers 04/23/23 12:57:33.07
    Apr 23 12:57:33.088: INFO: Unable to read wheezy_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:33.102: INFO: Unable to read wheezy_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:33.109: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:33.119: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:33.170: INFO: Unable to read jessie_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:33.178: INFO: Unable to read jessie_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:33.190: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:33.210: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:33.261: INFO: Lookups using dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d failed for: [wheezy_udp@dns-test-service.dns-256.svc.cluster.local wheezy_tcp@dns-test-service.dns-256.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_udp@dns-test-service.dns-256.svc.cluster.local jessie_tcp@dns-test-service.dns-256.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local]

    Apr 23 12:57:38.273: INFO: Unable to read wheezy_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:38.278: INFO: Unable to read wheezy_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:38.284: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:38.291: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:38.323: INFO: Unable to read jessie_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:38.332: INFO: Unable to read jessie_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:38.338: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:38.345: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:38.377: INFO: Lookups using dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d failed for: [wheezy_udp@dns-test-service.dns-256.svc.cluster.local wheezy_tcp@dns-test-service.dns-256.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_udp@dns-test-service.dns-256.svc.cluster.local jessie_tcp@dns-test-service.dns-256.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local]

    Apr 23 12:57:43.281: INFO: Unable to read wheezy_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:43.289: INFO: Unable to read wheezy_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:43.297: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:43.305: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:43.357: INFO: Unable to read jessie_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:43.368: INFO: Unable to read jessie_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:43.384: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:43.393: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:43.461: INFO: Lookups using dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d failed for: [wheezy_udp@dns-test-service.dns-256.svc.cluster.local wheezy_tcp@dns-test-service.dns-256.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_udp@dns-test-service.dns-256.svc.cluster.local jessie_tcp@dns-test-service.dns-256.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local]

    Apr 23 12:57:48.273: INFO: Unable to read wheezy_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:48.284: INFO: Unable to read wheezy_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:48.290: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:48.297: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:48.341: INFO: Unable to read jessie_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:48.349: INFO: Unable to read jessie_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:48.356: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:48.361: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:48.395: INFO: Lookups using dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d failed for: [wheezy_udp@dns-test-service.dns-256.svc.cluster.local wheezy_tcp@dns-test-service.dns-256.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_udp@dns-test-service.dns-256.svc.cluster.local jessie_tcp@dns-test-service.dns-256.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local]

    Apr 23 12:57:53.272: INFO: Unable to read wheezy_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:53.280: INFO: Unable to read wheezy_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:53.292: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:53.304: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:53.366: INFO: Unable to read jessie_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:53.374: INFO: Unable to read jessie_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:53.381: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:53.389: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:53.414: INFO: Lookups using dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d failed for: [wheezy_udp@dns-test-service.dns-256.svc.cluster.local wheezy_tcp@dns-test-service.dns-256.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_udp@dns-test-service.dns-256.svc.cluster.local jessie_tcp@dns-test-service.dns-256.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local]

    Apr 23 12:57:58.273: INFO: Unable to read wheezy_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:58.281: INFO: Unable to read wheezy_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:58.291: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:58.298: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:58.339: INFO: Unable to read jessie_udp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:58.345: INFO: Unable to read jessie_tcp@dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:58.358: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:58.370: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local from pod dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d: the server could not find the requested resource (get pods dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d)
    Apr 23 12:57:58.398: INFO: Lookups using dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d failed for: [wheezy_udp@dns-test-service.dns-256.svc.cluster.local wheezy_tcp@dns-test-service.dns-256.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_udp@dns-test-service.dns-256.svc.cluster.local jessie_tcp@dns-test-service.dns-256.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-256.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-256.svc.cluster.local]

    Apr 23 12:58:03.585: INFO: DNS probes using dns-256/dns-test-19808811-8b7c-4e0b-9ba5-0310bdd2346d succeeded

    STEP: deleting the pod 04/23/23 12:58:03.585
    STEP: deleting the test service 04/23/23 12:58:03.681
    STEP: deleting the test headless service 04/23/23 12:58:03.784
    [AfterEach] [sig-network] DNS
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:58:03.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-network] DNS
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-network] DNS
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-network] DNS
      tear down framework | framework.go:193
    STEP: Destroying namespace "dns-256" for this suite. 04/23/23 12:58:03.832
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:164
[BeforeEach] [sig-apps] DisruptionController
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:58:03.943
Apr 23 12:58:03.943: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename disruption 04/23/23 12:58:03.946
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:58:03.99
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:58:03.999
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:72
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:164
STEP: Waiting for the pdb to be processed 04/23/23 12:58:04.017
STEP: Updating PodDisruptionBudget status 04/23/23 12:58:06.033
STEP: Waiting for all pods to be running 04/23/23 12:58:06.05
Apr 23 12:58:06.064: INFO: running pods: 0 < 1
Apr 23 12:58:08.075: INFO: running pods: 0 < 1
Apr 23 12:58:10.077: INFO: running pods: 0 < 1
Apr 23 12:58:12.074: INFO: running pods: 0 < 1
STEP: locating a running pod 04/23/23 12:58:14.072
STEP: Waiting for the pdb to be processed 04/23/23 12:58:14.097
STEP: Patching PodDisruptionBudget status 04/23/23 12:58:14.115
STEP: Waiting for the pdb to be processed 04/23/23 12:58:14.142
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/node/init/init.go:32
Apr 23 12:58:14.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-apps] DisruptionController
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-apps] DisruptionController
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-apps] DisruptionController
  tear down framework | framework.go:193
STEP: Destroying namespace "disruption-3799" for this suite. 04/23/23 12:58:14.162
------------------------------
â€¢ [SLOW TEST] [10.230 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:164

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:58:03.943
    Apr 23 12:58:03.943: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename disruption 04/23/23 12:58:03.946
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:58:03.99
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:58:03.999
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:72
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:164
    STEP: Waiting for the pdb to be processed 04/23/23 12:58:04.017
    STEP: Updating PodDisruptionBudget status 04/23/23 12:58:06.033
    STEP: Waiting for all pods to be running 04/23/23 12:58:06.05
    Apr 23 12:58:06.064: INFO: running pods: 0 < 1
    Apr 23 12:58:08.075: INFO: running pods: 0 < 1
    Apr 23 12:58:10.077: INFO: running pods: 0 < 1
    Apr 23 12:58:12.074: INFO: running pods: 0 < 1
    STEP: locating a running pod 04/23/23 12:58:14.072
    STEP: Waiting for the pdb to be processed 04/23/23 12:58:14.097
    STEP: Patching PodDisruptionBudget status 04/23/23 12:58:14.115
    STEP: Waiting for the pdb to be processed 04/23/23 12:58:14.142
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/node/init/init.go:32
    Apr 23 12:58:14.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-apps] DisruptionController
      tear down framework | framework.go:193
    STEP: Destroying namespace "disruption-3799" for this suite. 04/23/23 12:58:14.162
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:199
[BeforeEach] [sig-node] Probing container
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 12:58:14.175
Apr 23 12:58:14.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename container-probe 04/23/23 12:58:14.178
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:58:14.219
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:58:14.224
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:31
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:63
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:199
STEP: Creating pod liveness-d00874fb-365c-400f-9cd3-30c37afe7787 in namespace container-probe-7971 04/23/23 12:58:14.234
Apr 23 12:58:14.249: INFO: Waiting up to 5m0s for pod "liveness-d00874fb-365c-400f-9cd3-30c37afe7787" in namespace "container-probe-7971" to be "not pending"
Apr 23 12:58:14.262: INFO: Pod "liveness-d00874fb-365c-400f-9cd3-30c37afe7787": Phase="Pending", Reason="", readiness=false. Elapsed: 12.438707ms
Apr 23 12:58:16.270: INFO: Pod "liveness-d00874fb-365c-400f-9cd3-30c37afe7787": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020477478s
Apr 23 12:58:18.273: INFO: Pod "liveness-d00874fb-365c-400f-9cd3-30c37afe7787": Phase="Running", Reason="", readiness=true. Elapsed: 4.024101326s
Apr 23 12:58:18.273: INFO: Pod "liveness-d00874fb-365c-400f-9cd3-30c37afe7787" satisfied condition "not pending"
Apr 23 12:58:18.273: INFO: Started pod liveness-d00874fb-365c-400f-9cd3-30c37afe7787 in namespace container-probe-7971
STEP: checking the pod's current state and verifying that restartCount is present 04/23/23 12:58:18.273
Apr 23 12:58:18.282: INFO: Initial restart count of pod liveness-d00874fb-365c-400f-9cd3-30c37afe7787 is 0
Apr 23 12:58:38.395: INFO: Restart count of pod container-probe-7971/liveness-d00874fb-365c-400f-9cd3-30c37afe7787 is now 1 (20.11326227s elapsed)
Apr 23 12:58:58.521: INFO: Restart count of pod container-probe-7971/liveness-d00874fb-365c-400f-9cd3-30c37afe7787 is now 2 (40.239152659s elapsed)
Apr 23 12:59:16.639: INFO: Restart count of pod container-probe-7971/liveness-d00874fb-365c-400f-9cd3-30c37afe7787 is now 3 (58.357389923s elapsed)
Apr 23 12:59:36.728: INFO: Restart count of pod container-probe-7971/liveness-d00874fb-365c-400f-9cd3-30c37afe7787 is now 4 (1m18.44582344s elapsed)
Apr 23 13:00:49.148: INFO: Restart count of pod container-probe-7971/liveness-d00874fb-365c-400f-9cd3-30c37afe7787 is now 5 (2m30.866685175s elapsed)
STEP: deleting the pod 04/23/23 13:00:49.149
[AfterEach] [sig-node] Probing container
  test/e2e/framework/node/init/init.go:32
Apr 23 13:00:49.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Probing container
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Probing container
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Probing container
  tear down framework | framework.go:193
STEP: Destroying namespace "container-probe-7971" for this suite. 04/23/23 13:00:49.188
------------------------------
â€¢ [SLOW TEST] [155.024 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:199

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 12:58:14.175
    Apr 23 12:58:14.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename container-probe 04/23/23 12:58:14.178
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 12:58:14.219
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 12:58:14.224
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:31
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:63
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:199
    STEP: Creating pod liveness-d00874fb-365c-400f-9cd3-30c37afe7787 in namespace container-probe-7971 04/23/23 12:58:14.234
    Apr 23 12:58:14.249: INFO: Waiting up to 5m0s for pod "liveness-d00874fb-365c-400f-9cd3-30c37afe7787" in namespace "container-probe-7971" to be "not pending"
    Apr 23 12:58:14.262: INFO: Pod "liveness-d00874fb-365c-400f-9cd3-30c37afe7787": Phase="Pending", Reason="", readiness=false. Elapsed: 12.438707ms
    Apr 23 12:58:16.270: INFO: Pod "liveness-d00874fb-365c-400f-9cd3-30c37afe7787": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020477478s
    Apr 23 12:58:18.273: INFO: Pod "liveness-d00874fb-365c-400f-9cd3-30c37afe7787": Phase="Running", Reason="", readiness=true. Elapsed: 4.024101326s
    Apr 23 12:58:18.273: INFO: Pod "liveness-d00874fb-365c-400f-9cd3-30c37afe7787" satisfied condition "not pending"
    Apr 23 12:58:18.273: INFO: Started pod liveness-d00874fb-365c-400f-9cd3-30c37afe7787 in namespace container-probe-7971
    STEP: checking the pod's current state and verifying that restartCount is present 04/23/23 12:58:18.273
    Apr 23 12:58:18.282: INFO: Initial restart count of pod liveness-d00874fb-365c-400f-9cd3-30c37afe7787 is 0
    Apr 23 12:58:38.395: INFO: Restart count of pod container-probe-7971/liveness-d00874fb-365c-400f-9cd3-30c37afe7787 is now 1 (20.11326227s elapsed)
    Apr 23 12:58:58.521: INFO: Restart count of pod container-probe-7971/liveness-d00874fb-365c-400f-9cd3-30c37afe7787 is now 2 (40.239152659s elapsed)
    Apr 23 12:59:16.639: INFO: Restart count of pod container-probe-7971/liveness-d00874fb-365c-400f-9cd3-30c37afe7787 is now 3 (58.357389923s elapsed)
    Apr 23 12:59:36.728: INFO: Restart count of pod container-probe-7971/liveness-d00874fb-365c-400f-9cd3-30c37afe7787 is now 4 (1m18.44582344s elapsed)
    Apr 23 13:00:49.148: INFO: Restart count of pod container-probe-7971/liveness-d00874fb-365c-400f-9cd3-30c37afe7787 is now 5 (2m30.866685175s elapsed)
    STEP: deleting the pod 04/23/23 13:00:49.149
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/node/init/init.go:32
    Apr 23 13:00:49.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Probing container
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Probing container
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Probing container
      tear down framework | framework.go:193
    STEP: Destroying namespace "container-probe-7971" for this suite. 04/23/23 13:00:49.188
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:89
[BeforeEach] [sig-storage] Secrets
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 13:00:49.212
Apr 23 13:00:49.213: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename secrets 04/23/23 13:00:49.219
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 13:00:49.259
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 13:00:49.265
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:31
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:89
STEP: Creating secret with name secret-test-map-2e9772d0-f83f-42ca-865e-576766c8bb7c 04/23/23 13:00:49.27
STEP: Creating a pod to test consume secrets 04/23/23 13:00:49.28
Apr 23 13:00:49.300: INFO: Waiting up to 5m0s for pod "pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301" in namespace "secrets-8044" to be "Succeeded or Failed"
Apr 23 13:00:49.317: INFO: Pod "pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301": Phase="Pending", Reason="", readiness=false. Elapsed: 16.773766ms
Apr 23 13:00:51.337: INFO: Pod "pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03654909s
Apr 23 13:00:53.328: INFO: Pod "pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027094272s
Apr 23 13:00:55.327: INFO: Pod "pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026839335s
STEP: Saw pod success 04/23/23 13:00:55.327
Apr 23 13:00:55.328: INFO: Pod "pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301" satisfied condition "Succeeded or Failed"
Apr 23 13:00:55.335: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301 container secret-volume-test: <nil>
STEP: delete the pod 04/23/23 13:00:55.742
Apr 23 13:00:55.769: INFO: Waiting for pod pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301 to disappear
Apr 23 13:00:55.775: INFO: Pod pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/node/init/init.go:32
Apr 23 13:00:55.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-storage] Secrets
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-storage] Secrets
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-storage] Secrets
  tear down framework | framework.go:193
STEP: Destroying namespace "secrets-8044" for this suite. 04/23/23 13:00:55.784
------------------------------
â€¢ [SLOW TEST] [6.586 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 13:00:49.212
    Apr 23 13:00:49.213: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename secrets 04/23/23 13:00:49.219
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 13:00:49.259
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 13:00:49.265
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:31
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:89
    STEP: Creating secret with name secret-test-map-2e9772d0-f83f-42ca-865e-576766c8bb7c 04/23/23 13:00:49.27
    STEP: Creating a pod to test consume secrets 04/23/23 13:00:49.28
    Apr 23 13:00:49.300: INFO: Waiting up to 5m0s for pod "pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301" in namespace "secrets-8044" to be "Succeeded or Failed"
    Apr 23 13:00:49.317: INFO: Pod "pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301": Phase="Pending", Reason="", readiness=false. Elapsed: 16.773766ms
    Apr 23 13:00:51.337: INFO: Pod "pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03654909s
    Apr 23 13:00:53.328: INFO: Pod "pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027094272s
    Apr 23 13:00:55.327: INFO: Pod "pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026839335s
    STEP: Saw pod success 04/23/23 13:00:55.327
    Apr 23 13:00:55.328: INFO: Pod "pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301" satisfied condition "Succeeded or Failed"
    Apr 23 13:00:55.335: INFO: Trying to get logs from node eingavuivie7-3 pod pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301 container secret-volume-test: <nil>
    STEP: delete the pod 04/23/23 13:00:55.742
    Apr 23 13:00:55.769: INFO: Waiting for pod pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301 to disappear
    Apr 23 13:00:55.775: INFO: Pod pod-secrets-d19e27f5-0df2-4d65-a40c-b26cb3d0b301 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/node/init/init.go:32
    Apr 23 13:00:55.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-storage] Secrets
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-storage] Secrets
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-storage] Secrets
      tear down framework | framework.go:193
    STEP: Destroying namespace "secrets-8044" for this suite. 04/23/23 13:00:55.784
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:39
[BeforeEach] [sig-node] Containers
  set up framework | framework.go:178
STEP: Creating a kubernetes client 04/23/23 13:00:55.807
Apr 23 13:00:55.808: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
STEP: Building a namespace api object, basename containers 04/23/23 13:00:55.814
STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 13:00:55.844
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 13:00:55.848
[BeforeEach] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:31
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:39
Apr 23 13:00:55.869: INFO: Waiting up to 5m0s for pod "client-containers-c7faaabe-38d2-4bdf-a10d-5beaa392ab38" in namespace "containers-1549" to be "running"
Apr 23 13:00:55.881: INFO: Pod "client-containers-c7faaabe-38d2-4bdf-a10d-5beaa392ab38": Phase="Pending", Reason="", readiness=false. Elapsed: 11.418524ms
Apr 23 13:00:57.894: INFO: Pod "client-containers-c7faaabe-38d2-4bdf-a10d-5beaa392ab38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024391023s
Apr 23 13:00:59.892: INFO: Pod "client-containers-c7faaabe-38d2-4bdf-a10d-5beaa392ab38": Phase="Running", Reason="", readiness=true. Elapsed: 4.022986637s
Apr 23 13:00:59.893: INFO: Pod "client-containers-c7faaabe-38d2-4bdf-a10d-5beaa392ab38" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/node/init/init.go:32
Apr 23 13:01:00.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
[DeferCleanup (Each)] [sig-node] Containers
  test/e2e/framework/metrics/init/init.go:33
[DeferCleanup (Each)] [sig-node] Containers
  dump namespaces | framework.go:196
[DeferCleanup (Each)] [sig-node] Containers
  tear down framework | framework.go:193
STEP: Destroying namespace "containers-1549" for this suite. 04/23/23 13:01:00.023
------------------------------
â€¢ [4.233 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      set up framework | framework.go:178
    STEP: Creating a kubernetes client 04/23/23 13:00:55.807
    Apr 23 13:00:55.808: INFO: >>> kubeConfig: /tmp/kubeconfig-2504172558
    STEP: Building a namespace api object, basename containers 04/23/23 13:00:55.814
    STEP: Waiting for a default service account to be provisioned in namespace 04/23/23 13:00:55.844
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/23/23 13:00:55.848
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:31
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:39
    Apr 23 13:00:55.869: INFO: Waiting up to 5m0s for pod "client-containers-c7faaabe-38d2-4bdf-a10d-5beaa392ab38" in namespace "containers-1549" to be "running"
    Apr 23 13:00:55.881: INFO: Pod "client-containers-c7faaabe-38d2-4bdf-a10d-5beaa392ab38": Phase="Pending", Reason="", readiness=false. Elapsed: 11.418524ms
    Apr 23 13:00:57.894: INFO: Pod "client-containers-c7faaabe-38d2-4bdf-a10d-5beaa392ab38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024391023s
    Apr 23 13:00:59.892: INFO: Pod "client-containers-c7faaabe-38d2-4bdf-a10d-5beaa392ab38": Phase="Running", Reason="", readiness=true. Elapsed: 4.022986637s
    Apr 23 13:00:59.893: INFO: Pod "client-containers-c7faaabe-38d2-4bdf-a10d-5beaa392ab38" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/node/init/init.go:32
    Apr 23 13:01:00.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    [DeferCleanup (Each)] [sig-node] Containers
      test/e2e/framework/metrics/init/init.go:33
    [DeferCleanup (Each)] [sig-node] Containers
      dump namespaces | framework.go:196
    [DeferCleanup (Each)] [sig-node] Containers
      tear down framework | framework.go:193
    STEP: Destroying namespace "containers-1549" for this suite. 04/23/23 13:01:00.023
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:88
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:88
Apr 23 13:01:00.057: INFO: Running AfterSuite actions on node 1
Apr 23 13:01:00.057: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:88
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:88
    Apr 23 13:01:00.057: INFO: Running AfterSuite actions on node 1
    Apr 23 13:01:00.057: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:153
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:153
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:153

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:153
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:529
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:529
------------------------------
[ReportAfterSuite] PASSED [0.405 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:529

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:529
  << End Captured GinkgoWriter Output
------------------------------

Ran 368 of 7069 Specs in 6494.942 seconds
SUCCESS! -- 368 Passed | 0 Failed | 0 Pending | 6701 Skipped
PASS

Ginkgo ran 1 suite in 1h48m16.073233877s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.4.0[0m

