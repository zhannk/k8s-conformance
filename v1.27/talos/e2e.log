  I0419 12:53:22.753329      20 e2e.go:117] Starting e2e run "fc9b60c8-115f-42cd-a491-b77852ad0f9a" on Ginkgo node 1
  Apr 19 12:53:22.779: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1681908802 - will randomize all specs

Will run 378 of 7207 specs
------------------------------
[ReportBeforeSuite] 
test/e2e/e2e_test.go:148
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
  Apr 19 12:53:22.930: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 12:53:22.931: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Apr 19 12:53:22.959: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Apr 19 12:53:22.962: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-flannel' (0 seconds elapsed)
  Apr 19 12:53:22.962: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  Apr 19 12:53:22.963: INFO: e2e test version: v1.27.1
  Apr 19 12:53:22.963: INFO: kube-apiserver version: v1.27.1
  Apr 19 12:53:22.963: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 12:53:22.966: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.036 seconds]
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:255
  STEP: Creating a kubernetes client @ 04/19/23 12:53:23.195
  Apr 19 12:53:23.195: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename init-container @ 04/19/23 12:53:23.196
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:53:23.209
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:53:23.212
  STEP: creating the pod @ 04/19/23 12:53:23.214
  Apr 19 12:53:23.214: INFO: PodSpec: initContainers in spec.initContainers
  W0419 12:53:23.220967      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "init1", "init2", "run1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "init1", "init2", "run1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "init1", "init2", "run1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "init1", "init2", "run1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 12:53:26.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-283" for this suite. @ 04/19/23 12:53:26.587
• [3.399 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]
test/e2e/apimachinery/resource_quota.go:806
  STEP: Creating a kubernetes client @ 04/19/23 12:53:26.595
  Apr 19 12:53:26.595: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename resourcequota @ 04/19/23 12:53:26.597
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:53:26.612
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:53:26.616
  STEP: Creating a ResourceQuota with best effort scope @ 04/19/23 12:53:26.62
  STEP: Ensuring ResourceQuota status is calculated @ 04/19/23 12:53:26.626
  STEP: Creating a ResourceQuota with not best effort scope @ 04/19/23 12:53:28.631
  STEP: Ensuring ResourceQuota status is calculated @ 04/19/23 12:53:28.636
  STEP: Creating a best-effort pod @ 04/19/23 12:53:30.641
  W0419 12:53:30.656005      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 04/19/23 12:53:30.656
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 04/19/23 12:53:32.661
  STEP: Deleting the pod @ 04/19/23 12:53:34.667
  STEP: Ensuring resource quota status released the pod usage @ 04/19/23 12:53:34.68
  STEP: Creating a not best-effort pod @ 04/19/23 12:53:36.684
  W0419 12:53:36.701021      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 04/19/23 12:53:36.701
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 04/19/23 12:53:38.705
  STEP: Deleting the pod @ 04/19/23 12:53:40.71
  STEP: Ensuring resource quota status released the pod usage @ 04/19/23 12:53:40.723
  Apr 19 12:53:42.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2498" for this suite. @ 04/19/23 12:53:42.736
• [16.148 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]
test/e2e/kubectl/kubectl.go:1640
  STEP: Creating a kubernetes client @ 04/19/23 12:53:42.749
  Apr 19 12:53:42.749: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 12:53:42.75
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:53:42.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:53:42.77
  STEP: creating Agnhost RC @ 04/19/23 12:53:42.773
  Apr 19 12:53:42.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6120 create -f -'
  Apr 19 12:53:43.363: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"agnhost-primary\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"agnhost-primary\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"agnhost-primary\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"agnhost-primary\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 12:53:43.363: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/19/23 12:53:43.363
  Apr 19 12:53:44.369: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 12:53:44.369: INFO: Found 0 / 1
  Apr 19 12:53:45.368: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 12:53:45.368: INFO: Found 1 / 1
  Apr 19 12:53:45.368: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 04/19/23 12:53:45.368
  Apr 19 12:53:45.373: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 12:53:45.373: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 19 12:53:45.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6120 patch pod agnhost-primary-57fpx -p {"metadata":{"annotations":{"x":"y"}}}'
  Apr 19 12:53:45.473: INFO: stderr: ""
  Apr 19 12:53:45.473: INFO: stdout: "pod/agnhost-primary-57fpx patched\n"
  STEP: checking annotations @ 04/19/23 12:53:45.473
  Apr 19 12:53:45.478: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 12:53:45.478: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 19 12:53:45.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6120" for this suite. @ 04/19/23 12:53:45.483
• [2.741 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance]
test/e2e/auth/service_accounts.go:275
  STEP: Creating a kubernetes client @ 04/19/23 12:53:45.492
  Apr 19 12:53:45.492: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/23 12:53:45.494
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:53:45.509
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:53:45.512
  STEP: Creating a pod to test service account token:  @ 04/19/23 12:53:45.515
  W0419 12:53:45.523099      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 12:53:49.536
  Apr 19 12:53:49.540: INFO: Trying to get logs from node talos-default-worker-1 pod test-pod-0a6abbed-20ff-4212-a303-0151c65cf31a container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 12:53:49.557
  Apr 19 12:53:49.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8021" for this suite. @ 04/19/23 12:53:49.581
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod  [Conformance]
test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 04/19/23 12:53:49.59
  Apr 19 12:53:49.590: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename prestop @ 04/19/23 12:53:49.592
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:53:49.607
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:53:49.611
  STEP: Creating server pod server in namespace prestop-3880 @ 04/19/23 12:53:49.615
  W0419 12:53:49.624778      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Waiting for pods to come up. @ 04/19/23 12:53:49.625
  STEP: Creating tester pod tester in namespace prestop-3880 @ 04/19/23 12:53:51.639
  W0419 12:53:51.648222      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "tester" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "tester" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "tester" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "tester" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Deleting pre-stop pod @ 04/19/23 12:53:53.658
  Apr 19 12:53:58.671: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  Apr 19 12:53:58.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Deleting the server pod @ 04/19/23 12:53:58.676
  STEP: Destroying namespace "prestop-3880" for this suite. @ 04/19/23 12:53:58.69
• [9.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 04/19/23 12:53:58.714
  Apr 19 12:53:58.714: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/23 12:53:58.715
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:53:58.734
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:53:58.738
  W0419 12:53:58.748445      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "bin-false9b125bfd-c714-4397-bcdb-65607bd1e020" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "bin-false9b125bfd-c714-4397-bcdb-65607bd1e020" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "bin-false9b125bfd-c714-4397-bcdb-65607bd1e020" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "bin-false9b125bfd-c714-4397-bcdb-65607bd1e020" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 12:53:58.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6085" for this suite. @ 04/19/23 12:53:58.763
• [0.054 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:645
  STEP: Creating a kubernetes client @ 04/19/23 12:53:58.769
  Apr 19 12:53:58.769: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 12:53:58.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:53:58.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:53:58.785
  STEP: Setting up server cert @ 04/19/23 12:53:58.805
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 12:53:58.954
  STEP: Deploying the webhook pod @ 04/19/23 12:53:58.962
  W0419 12:53:58.976314      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 12:53:58.976
  Apr 19 12:53:58.981: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/19/23 12:54:00.993
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 12:54:01.01
  Apr 19 12:54:02.011: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/19/23 12:54:02.07
  STEP: Creating a configMap that should be mutated @ 04/19/23 12:54:02.086
  STEP: Deleting the collection of validation webhooks @ 04/19/23 12:54:02.115
  STEP: Creating a configMap that should not be mutated @ 04/19/23 12:54:02.153
  Apr 19 12:54:02.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4916" for this suite. @ 04/19/23 12:54:02.193
  STEP: Destroying namespace "webhook-markers-2257" for this suite. @ 04/19/23 12:54:02.198
• [3.434 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:123
  STEP: Creating a kubernetes client @ 04/19/23 12:54:02.205
  Apr 19 12:54:02.205: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename sysctl @ 04/19/23 12:54:02.207
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:54:02.217
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:54:02.219
  STEP: Creating a pod with one valid and two invalid sysctls @ 04/19/23 12:54:02.22
  Apr 19 12:54:02.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-556" for this suite. @ 04/19/23 12:54:02.227
• [0.026 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:347
  STEP: Creating a kubernetes client @ 04/19/23 12:54:02.233
  Apr 19 12:54:02.233: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename security-context-test @ 04/19/23 12:54:02.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:54:02.245
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:54:02.247
  W0419 12:54:02.254055      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-user-65534-fb096ca2-06c8-4289-839a-cb02496a0c44" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-user-65534-fb096ca2-06c8-4289-839a-cb02496a0c44" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-user-65534-fb096ca2-06c8-4289-839a-cb02496a0c44" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-user-65534-fb096ca2-06c8-4289-839a-cb02496a0c44" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 12:54:06.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-6457" for this suite. @ 04/19/23 12:54:06.272
• [4.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]
test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 04/19/23 12:54:06.282
  Apr 19 12:54:06.282: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename var-expansion @ 04/19/23 12:54:06.283
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:54:06.303
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:54:06.308
  STEP: creating the pod @ 04/19/23 12:54:06.311
  W0419 12:54:06.321226      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: waiting for pod running @ 04/19/23 12:54:06.322
  STEP: creating a file in subpath @ 04/19/23 12:54:08.334
  Apr 19 12:54:08.338: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-9938 PodName:var-expansion-4c33d41c-7614-4ebd-b87c-84e316aafb60 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 12:54:08.338: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 12:54:08.339: INFO: ExecWithOptions: Clientset creation
  Apr 19 12:54:08.339: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-9938/pods/var-expansion-4c33d41c-7614-4ebd-b87c-84e316aafb60/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 04/19/23 12:54:08.496
  Apr 19 12:54:08.501: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-9938 PodName:var-expansion-4c33d41c-7614-4ebd-b87c-84e316aafb60 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 12:54:08.501: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 12:54:08.501: INFO: ExecWithOptions: Clientset creation
  Apr 19 12:54:08.501: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-9938/pods/var-expansion-4c33d41c-7614-4ebd-b87c-84e316aafb60/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 04/19/23 12:54:08.582
  Apr 19 12:54:09.100: INFO: Successfully updated pod "var-expansion-4c33d41c-7614-4ebd-b87c-84e316aafb60"
  STEP: waiting for annotated pod running @ 04/19/23 12:54:09.1
  STEP: deleting the pod gracefully @ 04/19/23 12:54:09.104
  Apr 19 12:54:09.104: INFO: Deleting pod "var-expansion-4c33d41c-7614-4ebd-b87c-84e316aafb60" in namespace "var-expansion-9938"
  Apr 19 12:54:09.112: INFO: Wait up to 5m0s for pod "var-expansion-4c33d41c-7614-4ebd-b87c-84e316aafb60" to be fully deleted
  Apr 19 12:54:41.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9938" for this suite. @ 04/19/23 12:54:41.197
• [34.923 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
test/e2e/apimachinery/webhook.go:272
  STEP: Creating a kubernetes client @ 04/19/23 12:54:41.212
  Apr 19 12:54:41.212: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 12:54:41.213
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:54:41.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:54:41.239
  STEP: Setting up server cert @ 04/19/23 12:54:41.265
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 12:54:41.608
  STEP: Deploying the webhook pod @ 04/19/23 12:54:41.616
  W0419 12:54:41.626162      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 12:54:41.627
  Apr 19 12:54:41.641: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/19/23 12:54:43.65
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 12:54:43.665
  Apr 19 12:54:44.665: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/19/23 12:54:44.669
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 04/19/23 12:54:44.687
  STEP: Creating a dummy validating-webhook-configuration object @ 04/19/23 12:54:44.702
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 04/19/23 12:54:44.711
  STEP: Creating a dummy mutating-webhook-configuration object @ 04/19/23 12:54:44.718
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 04/19/23 12:54:44.728
  Apr 19 12:54:44.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7447" for this suite. @ 04/19/23 12:54:44.79
  STEP: Destroying namespace "webhook-markers-9493" for this suite. @ 04/19/23 12:54:44.794
• [3.587 seconds]
------------------------------
SS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:268
  STEP: Creating a kubernetes client @ 04/19/23 12:54:44.801
  Apr 19 12:54:44.801: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 12:54:44.803
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:54:44.814
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:54:44.816
  STEP: Creating a pod to test downward api env vars @ 04/19/23 12:54:44.818
  W0419 12:54:44.824656      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 12:54:48.838
  Apr 19 12:54:48.842: INFO: Trying to get logs from node talos-default-worker-1 pod downward-api-68d41bc0-43de-47a9-a2eb-4b2507f35dfa container dapi-container: <nil>
  STEP: delete the pod @ 04/19/23 12:54:48.85
  Apr 19 12:54:48.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6719" for this suite. @ 04/19/23 12:54:48.874
• [4.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:95
  STEP: Creating a kubernetes client @ 04/19/23 12:54:48.89
  Apr 19 12:54:48.890: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename secrets @ 04/19/23 12:54:48.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:54:48.91
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:54:48.914
  STEP: creating secret secrets-1693/secret-test-4f67062a-f3f9-4263-8b9a-449f9b9211b9 @ 04/19/23 12:54:48.917
  STEP: Creating a pod to test consume secrets @ 04/19/23 12:54:48.923
  W0419 12:54:48.931028      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "env-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "env-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "env-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "env-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 12:54:50.941
  Apr 19 12:54:50.945: INFO: Trying to get logs from node talos-default-worker-1 pod pod-configmaps-de8a37be-280d-471a-beaa-5762126988ae container env-test: <nil>
  STEP: delete the pod @ 04/19/23 12:54:50.954
  Apr 19 12:54:50.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1693" for this suite. @ 04/19/23 12:54:50.97
• [2.086 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 04/19/23 12:54:50.978
  Apr 19 12:54:50.978: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 12:54:50.979
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:54:50.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:54:51.001
  STEP: Creating secret with name s-test-opt-del-623c229a-e32a-485e-a636-3e57fc909b37 @ 04/19/23 12:54:51.007
  STEP: Creating secret with name s-test-opt-upd-d13f3ab1-14fb-43fd-adf4-4f005b6f6a9f @ 04/19/23 12:54:51.012
  STEP: Creating the pod @ 04/19/23 12:54:51.016
  W0419 12:54:51.024461      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Deleting secret s-test-opt-del-623c229a-e32a-485e-a636-3e57fc909b37 @ 04/19/23 12:54:53.06
  STEP: Updating secret s-test-opt-upd-d13f3ab1-14fb-43fd-adf4-4f005b6f6a9f @ 04/19/23 12:54:53.066
  STEP: Creating secret with name s-test-opt-create-b7c7aaee-3f2f-4552-8dbd-c330aad2ba15 @ 04/19/23 12:54:53.072
  STEP: waiting to observe update in volume @ 04/19/23 12:54:53.077
  Apr 19 12:54:57.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4672" for this suite. @ 04/19/23 12:54:57.122
• [6.151 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]
test/e2e/network/endpointslice.go:355
  STEP: Creating a kubernetes client @ 04/19/23 12:54:57.133
  Apr 19 12:54:57.133: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename endpointslice @ 04/19/23 12:54:57.136
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:54:57.158
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:54:57.163
  STEP: getting /apis @ 04/19/23 12:54:57.167
  STEP: getting /apis/discovery.k8s.io @ 04/19/23 12:54:57.172
  STEP: getting /apis/discovery.k8s.iov1 @ 04/19/23 12:54:57.174
  STEP: creating @ 04/19/23 12:54:57.176
  STEP: getting @ 04/19/23 12:54:57.199
  STEP: listing @ 04/19/23 12:54:57.203
  STEP: watching @ 04/19/23 12:54:57.206
  Apr 19 12:54:57.206: INFO: starting watch
  STEP: cluster-wide listing @ 04/19/23 12:54:57.207
  STEP: cluster-wide watching @ 04/19/23 12:54:57.211
  Apr 19 12:54:57.211: INFO: starting watch
  STEP: patching @ 04/19/23 12:54:57.212
  STEP: updating @ 04/19/23 12:54:57.217
  Apr 19 12:54:57.224: INFO: waiting for watch events with expected annotations
  Apr 19 12:54:57.224: INFO: saw patched and updated annotations
  STEP: deleting @ 04/19/23 12:54:57.225
  STEP: deleting a collection @ 04/19/23 12:54:57.236
  Apr 19 12:54:57.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-1498" for this suite. @ 04/19/23 12:54:57.252
• [0.124 seconds]
------------------------------
SS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 04/19/23 12:54:57.258
  Apr 19 12:54:57.258: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-probe @ 04/19/23 12:54:57.26
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:54:57.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:54:57.272
  STEP: Creating pod busybox-6a9b504e-dbf5-43f4-947b-8860c4cb8fbc in namespace container-probe-347 @ 04/19/23 12:54:57.275
  W0419 12:54:57.280904      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 12:54:59.288: INFO: Started pod busybox-6a9b504e-dbf5-43f4-947b-8860c4cb8fbc in namespace container-probe-347
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/23 12:54:59.289
  Apr 19 12:54:59.293: INFO: Initial restart count of pod busybox-6a9b504e-dbf5-43f4-947b-8860c4cb8fbc is 0
  Apr 19 12:58:59.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 12:58:59.873
  STEP: Destroying namespace "container-probe-347" for this suite. @ 04/19/23 12:58:59.891
• [242.641 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 04/19/23 12:58:59.901
  Apr 19 12:58:59.901: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename field-validation @ 04/19/23 12:58:59.902
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:58:59.923
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:58:59.925
  STEP: apply creating a deployment @ 04/19/23 12:58:59.927
  Apr 19 12:58:59.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-3669" for this suite. @ 04/19/23 12:58:59.941
• [0.045 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]
test/e2e/kubectl/kubectl.go:1341
  STEP: Creating a kubernetes client @ 04/19/23 12:58:59.947
  Apr 19 12:58:59.947: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 12:58:59.947
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:58:59.959
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:58:59.961
  Apr 19 12:58:59.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4146 create -f -'
  Apr 19 12:59:00.165: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"agnhost-primary\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"agnhost-primary\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"agnhost-primary\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"agnhost-primary\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 12:59:00.165: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Apr 19 12:59:00.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4146 create -f -'
  Apr 19 12:59:00.365: INFO: stderr: ""
  Apr 19 12:59:00.365: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/19/23 12:59:00.365
  Apr 19 12:59:01.369: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 12:59:01.369: INFO: Found 1 / 1
  Apr 19 12:59:01.369: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Apr 19 12:59:01.372: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 12:59:01.372: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 19 12:59:01.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4146 describe pod agnhost-primary-hpwk5'
  Apr 19 12:59:01.439: INFO: stderr: ""
  Apr 19 12:59:01.439: INFO: stdout: "Name:             agnhost-primary-hpwk5\nNamespace:        kubectl-4146\nPriority:         0\nService Account:  default\nNode:             talos-default-worker-1/172.20.0.5\nStart Time:       Wed, 19 Apr 2023 12:59:00 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               10.244.3.15\nIPs:\n  IP:           10.244.3.15\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://70399f1dba4d1f688140593253a9a7f8cfd5025085559e66a493c3fdf95f3da5\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.43\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 19 Apr 2023 12:59:00 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-fwvxq (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-fwvxq:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-4146/agnhost-primary-hpwk5 to talos-default-worker-1\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.43\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  Apr 19 12:59:01.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4146 describe rc agnhost-primary'
  Apr 19 12:59:01.498: INFO: stderr: ""
  Apr 19 12:59:01.498: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-4146\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.43\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-hpwk5\n"
  Apr 19 12:59:01.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4146 describe service agnhost-primary'
  Apr 19 12:59:01.556: INFO: stderr: ""
  Apr 19 12:59:01.556: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-4146\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.108.80.242\nIPs:               10.108.80.242\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.244.3.15:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Apr 19 12:59:01.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4146 describe node talos-default-controlplane-1'
  Apr 19 12:59:01.632: INFO: stderr: ""
  Apr 19 12:59:01.632: INFO: stdout: "Name:               talos-default-controlplane-1\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=talos-default-controlplane-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"c2:40:ec:14:0c:9f\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.20.0.2\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 18 Apr 2023 19:32:12 +0000\nTaints:             node-role.kubernetes.io/control-plane:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  talos-default-controlplane-1\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 19 Apr 2023 12:58:55 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 18 Apr 2023 19:32:30 +0000   Tue, 18 Apr 2023 19:32:30 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Wed, 19 Apr 2023 12:54:28 +0000   Tue, 18 Apr 2023 19:32:12 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 19 Apr 2023 12:54:28 +0000   Tue, 18 Apr 2023 19:32:12 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 19 Apr 2023 12:54:28 +0000   Tue, 18 Apr 2023 19:32:12 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 19 Apr 2023 12:54:28 +0000   Tue, 18 Apr 2023 19:32:25 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.20.0.2\n  Hostname:    talos-default-controlplane-1\nCapacity:\n  cpu:                4\n  ephemeral-storage:  4876Mi\n  hugepages-2Mi:      0\n  memory:             2948724Ki\n  pods:               110\nAllocatable:\n  cpu:                3950m\n  ephemeral-storage:  4333135455\n  hugepages-2Mi:      0\n  memory:             2649716Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 f69a5b01666a05621a294f39fdc59e46\n  System UUID:                2e752df4-7e37-4253-a5c3-7fec9842e6d0\n  Boot ID:                    443a0161-5b14-47be-b153-849568b97a5c\n  Kernel Version:             6.1.24-talos\n  OS Image:                   Talos (v1.4.0)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.20\n  Kubelet Version:            v1.27.1\n  Kube-Proxy Version:         v1.27.1\nPodCIDR:                      10.244.2.0/24\nPodCIDRs:                     10.244.2.0/24\nNon-terminated Pods:          (6 in total)\n  Namespace                   Name                                                    CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                    ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-d779cc7ff-lsdjg                                 100m (2%)     0 (0%)      70Mi (2%)        170Mi (6%)     17h\n  kube-system                 kube-apiserver-talos-default-controlplane-1             200m (5%)     0 (0%)      512Mi (19%)      0 (0%)         17h\n  kube-system                 kube-controller-manager-talos-default-controlplane-1    50m (1%)      0 (0%)      256Mi (9%)       0 (0%)         17h\n  kube-system                 kube-flannel-fxfvq                                      100m (2%)     0 (0%)      50Mi (1%)        0 (0%)         17h\n  kube-system                 kube-proxy-qdllt                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         17h\n  kube-system                 kube-scheduler-talos-default-controlplane-1             10m (0%)      0 (0%)      64Mi (2%)        0 (0%)         17h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                460m (11%)   0 (0%)\n  memory             952Mi (36%)  170Mi (6%)\n  ephemeral-storage  0 (0%)       0 (0%)\n  hugepages-2Mi      0 (0%)       0 (0%)\nEvents:              <none>\n"
  Apr 19 12:59:01.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4146 describe namespace kubectl-4146'
  Apr 19 12:59:01.686: INFO: stderr: ""
  Apr 19 12:59:01.686: INFO: stdout: "Name:         kubectl-4146\nLabels:       e2e-framework=kubectl\n              e2e-run=fc9b60c8-115f-42cd-a491-b77852ad0f9a\n              kubernetes.io/metadata.name=kubectl-4146\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Apr 19 12:59:01.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4146" for this suite. @ 04/19/23 12:59:01.69
• [1.748 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]
test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 04/19/23 12:59:01.699
  Apr 19 12:59:01.699: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename disruption @ 04/19/23 12:59:01.7
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:59:01.718
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:59:01.72
  STEP: Waiting for the pdb to be processed @ 04/19/23 12:59:01.727
  W0419 12:59:03.745007      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  W0419 12:59:03.752243      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  W0419 12:59:03.761493      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Waiting for all pods to be running @ 04/19/23 12:59:03.762
  Apr 19 12:59:03.770: INFO: running pods: 0 < 3
  Apr 19 12:59:05.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8395" for this suite. @ 04/19/23 12:59:05.783
• [4.095 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]
test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 04/19/23 12:59:05.797
  Apr 19 12:59:05.797: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 12:59:05.8
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:59:05.816
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:59:05.819
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-1402 @ 04/19/23 12:59:05.822
  STEP: changing the ExternalName service to type=ClusterIP @ 04/19/23 12:59:05.828
  STEP: creating replication controller externalname-service in namespace services-1402 @ 04/19/23 12:59:05.846
  W0419 12:59:05.855442      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "externalname-service" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "externalname-service" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "externalname-service" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "externalname-service" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  I0419 12:59:05.858061      20 runners.go:194] Created replication controller with name: externalname-service, namespace: services-1402, replica count: 2
  I0419 12:59:08.910009      20 runners.go:194] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 12:59:08.910: INFO: Creating new exec pod
  W0419 12:59:08.923757      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 12:59:11.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1402 exec execpod5n27g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 19 12:59:14.114: INFO: rc: 1
  Apr 19 12:59:14.115: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1402 exec execpod5n27g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 externalname-service 80
  + echo hostName
  nc: connect to externalname-service port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 19 12:59:15.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1402 exec execpod5n27g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 19 12:59:15.324: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 19 12:59:15.324: INFO: stdout: ""
  Apr 19 12:59:16.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1402 exec execpod5n27g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 19 12:59:16.349: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 19 12:59:16.349: INFO: stdout: ""
  Apr 19 12:59:17.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1402 exec execpod5n27g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 19 12:59:19.338: INFO: rc: 1
  Apr 19 12:59:19.338: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1402 exec execpod5n27g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 externalname-service 80
  nc: connect to externalname-service port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 19 12:59:20.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1402 exec execpod5n27g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 19 12:59:20.362: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 19 12:59:20.362: INFO: stdout: "externalname-service-v68bc"
  Apr 19 12:59:20.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1402 exec execpod5n27g -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.102.221.238 80'
  Apr 19 12:59:20.573: INFO: stderr: "+ nc -v -t -w 2 10.102.221.238 80\n+ echo hostName\nConnection to 10.102.221.238 80 port [tcp/http] succeeded!\n"
  Apr 19 12:59:20.573: INFO: stdout: "externalname-service-v68bc"
  Apr 19 12:59:20.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 19 12:59:20.579: INFO: Cleaning up the ExternalName to ClusterIP test service
  STEP: Destroying namespace "services-1402" for this suite. @ 04/19/23 12:59:20.6
• [14.810 seconds]
------------------------------
SS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 04/19/23 12:59:20.607
  Apr 19 12:59:20.607: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-probe @ 04/19/23 12:59:20.61
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 12:59:20.624
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 12:59:20.628
  STEP: Creating pod busybox-2520b5e6-b482-426d-8ebb-15eac5956fa9 in namespace container-probe-785 @ 04/19/23 12:59:20.63
  W0419 12:59:20.642050      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 12:59:22.650: INFO: Started pod busybox-2520b5e6-b482-426d-8ebb-15eac5956fa9 in namespace container-probe-785
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/23 12:59:22.65
  Apr 19 12:59:22.656: INFO: Initial restart count of pod busybox-2520b5e6-b482-426d-8ebb-15eac5956fa9 is 0
  Apr 19 13:00:12.781: INFO: Restart count of pod container-probe-785/busybox-2520b5e6-b482-426d-8ebb-15eac5956fa9 is now 1 (50.125113141s elapsed)
  Apr 19 13:00:12.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 13:00:12.788
  STEP: Destroying namespace "container-probe-785" for this suite. @ 04/19/23 13:00:12.805
• [52.207 seconds]
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:93
  STEP: Creating a kubernetes client @ 04/19/23 13:00:12.815
  Apr 19 13:00:12.815: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 13:00:12.818
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:00:12.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:00:12.838
  STEP: Creating configMap configmap-6173/configmap-test-e54391fc-c2c6-4d88-92d5-947d6635e2d7 @ 04/19/23 13:00:12.841
  STEP: Creating a pod to test consume configMaps @ 04/19/23 13:00:12.846
  W0419 13:00:12.854954      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "env-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "env-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "env-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "env-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:00:16.867
  Apr 19 13:00:16.871: INFO: Trying to get logs from node talos-default-worker-1 pod pod-configmaps-7db5defd-0de2-460d-9a0c-235403dce0a3 container env-test: <nil>
  STEP: delete the pod @ 04/19/23 13:00:16.889
  Apr 19 13:00:16.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6173" for this suite. @ 04/19/23 13:00:16.916
• [4.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
test/e2e/apimachinery/resource_quota.go:76
  STEP: Creating a kubernetes client @ 04/19/23 13:00:16.929
  Apr 19 13:00:16.929: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename resourcequota @ 04/19/23 13:00:16.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:00:16.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:00:16.952
  STEP: Counting existing ResourceQuota @ 04/19/23 13:00:16.956
  STEP: Creating a ResourceQuota @ 04/19/23 13:00:21.961
  STEP: Ensuring resource quota status is calculated @ 04/19/23 13:00:21.971
  Apr 19 13:00:23.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4216" for this suite. @ 04/19/23 13:00:23.982
• [7.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]
test/e2e/kubectl/kubectl.go:1673
  STEP: Creating a kubernetes client @ 04/19/23 13:00:23.996
  Apr 19 13:00:23.996: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 13:00:23.999
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:00:24.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:00:24.018
  Apr 19 13:00:24.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1554 version'
  Apr 19 13:00:24.099: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
  Apr 19 13:00:24.099: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"27\", GitVersion:\"v1.27.1\", GitCommit:\"4c9411232e10168d7b050c49a1b59f6df9d7ea4b\", GitTreeState:\"clean\", BuildDate:\"2023-04-14T13:21:19Z\", GoVersion:\"go1.20.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v5.0.1\nServer Version: version.Info{Major:\"1\", Minor:\"27\", GitVersion:\"v1.27.1\", GitCommit:\"4c9411232e10168d7b050c49a1b59f6df9d7ea4b\", GitTreeState:\"clean\", BuildDate:\"2023-04-14T13:14:42Z\", GoVersion:\"go1.20.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
  Apr 19 13:00:24.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1554" for this suite. @ 04/19/23 13:00:24.104
• [0.115 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance]
test/e2e/instrumentation/core_events.go:175
  STEP: Creating a kubernetes client @ 04/19/23 13:00:24.113
  Apr 19 13:00:24.113: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename events @ 04/19/23 13:00:24.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:00:24.131
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:00:24.134
  STEP: Create set of events @ 04/19/23 13:00:24.137
  Apr 19 13:00:24.143: INFO: created test-event-1
  Apr 19 13:00:24.149: INFO: created test-event-2
  Apr 19 13:00:24.153: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 04/19/23 13:00:24.153
  STEP: delete collection of events @ 04/19/23 13:00:24.156
  Apr 19 13:00:24.156: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/19/23 13:00:24.17
  Apr 19 13:00:24.170: INFO: requesting list of events to confirm quantity
  Apr 19 13:00:24.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-5242" for this suite. @ 04/19/23 13:00:24.178
• [0.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]
test/e2e/apimachinery/webhook.go:300
  STEP: Creating a kubernetes client @ 04/19/23 13:00:24.188
  Apr 19 13:00:24.188: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 13:00:24.189
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:00:24.202
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:00:24.204
  STEP: Setting up server cert @ 04/19/23 13:00:24.221
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 13:00:24.531
  STEP: Deploying the webhook pod @ 04/19/23 13:00:24.539
  W0419 13:00:24.553520      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 13:00:24.554
  Apr 19 13:00:24.563: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/19/23 13:00:26.575
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 13:00:26.593
  Apr 19 13:00:27.597: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 04/19/23 13:00:27.602
  STEP: Creating a custom resource definition that should be denied by the webhook @ 04/19/23 13:00:27.618
  Apr 19 13:00:27.618: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:00:27.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6972" for this suite. @ 04/19/23 13:00:27.686
  STEP: Destroying namespace "webhook-markers-2064" for this suite. @ 04/19/23 13:00:27.691
• [3.508 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:69
  STEP: Creating a kubernetes client @ 04/19/23 13:00:27.7
  Apr 19 13:00:27.700: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 13:00:27.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:00:27.712
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:00:27.714
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 13:00:27.716
  W0419 13:00:27.723941      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:00:29.742
  Apr 19 13:00:29.746: INFO: Trying to get logs from node talos-default-worker-1 pod downwardapi-volume-1133e0db-6976-43f1-a8cb-2e0b88607c66 container client-container: <nil>
  STEP: delete the pod @ 04/19/23 13:00:29.755
  Apr 19 13:00:29.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4009" for this suite. @ 04/19/23 13:00:29.778
• [2.085 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:262
  STEP: Creating a kubernetes client @ 04/19/23 13:00:29.787
  Apr 19 13:00:29.787: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 13:00:29.789
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:00:29.804
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:00:29.807
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 13:00:29.81
  W0419 13:00:29.817455      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:00:31.827
  Apr 19 13:00:31.831: INFO: Trying to get logs from node talos-default-worker-1 pod downwardapi-volume-1bc058e2-a4cc-45c3-822d-824c7789f0fb container client-container: <nil>
  STEP: delete the pod @ 04/19/23 13:00:31.838
  Apr 19 13:00:31.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5869" for this suite. @ 04/19/23 13:00:31.864
• [2.085 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 04/19/23 13:00:31.878
  Apr 19 13:00:31.878: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename field-validation @ 04/19/23 13:00:31.88
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:00:31.895
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:00:31.898
  Apr 19 13:00:31.901: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  W0419 13:00:34.441068      20 warnings.go:70] unknown field "alpha"
  W0419 13:00:34.441108      20 warnings.go:70] unknown field "beta"
  W0419 13:00:34.441122      20 warnings.go:70] unknown field "delta"
  W0419 13:00:34.441178      20 warnings.go:70] unknown field "epsilon"
  W0419 13:00:34.441193      20 warnings.go:70] unknown field "gamma"
  Apr 19 13:00:34.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9727" for this suite. @ 04/19/23 13:00:34.481
• [2.610 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]
test/e2e/storage/subpath.go:106
  STEP: Creating a kubernetes client @ 04/19/23 13:00:34.491
  Apr 19 13:00:34.491: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename subpath @ 04/19/23 13:00:34.494
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:00:34.509
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:00:34.513
  STEP: Setting up data @ 04/19/23 13:00:34.519
  STEP: Creating pod pod-subpath-test-projected-25wk @ 04/19/23 13:00:34.529
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/23 13:00:34.529
  W0419 13:00:34.539142      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-projected-25wk" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-projected-25wk" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-projected-25wk" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-projected-25wk" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:00:58.605
  Apr 19 13:00:58.616: INFO: Trying to get logs from node talos-default-worker-1 pod pod-subpath-test-projected-25wk container test-container-subpath-projected-25wk: <nil>
  STEP: delete the pod @ 04/19/23 13:00:58.625
  STEP: Deleting pod pod-subpath-test-projected-25wk @ 04/19/23 13:00:58.64
  Apr 19 13:00:58.640: INFO: Deleting pod "pod-subpath-test-projected-25wk" in namespace "subpath-6283"
  Apr 19 13:00:58.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6283" for this suite. @ 04/19/23 13:00:58.651
• [24.168 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]
test/e2e/apps/statefulset.go:743
  STEP: Creating a kubernetes client @ 04/19/23 13:00:58.661
  Apr 19 13:00:58.662: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename statefulset @ 04/19/23 13:00:58.666
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:00:58.68
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:00:58.683
  STEP: Creating service test in namespace statefulset-6487 @ 04/19/23 13:00:58.687
  STEP: Looking for a node to schedule stateful set and pod @ 04/19/23 13:00:58.697
  STEP: Creating pod with conflicting port in namespace statefulset-6487 @ 04/19/23 13:00:58.702
  W0419 13:00:58.709874      20 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "webserver" uses hostPort 21017), allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Waiting until pod test-pod will start running in namespace statefulset-6487 @ 04/19/23 13:00:58.71
  STEP: Creating statefulset with conflicting port in namespace statefulset-6487 @ 04/19/23 13:01:00.718
  W0419 13:01:00.724914      20 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "webserver" uses hostPort 21017), allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6487 @ 04/19/23 13:01:00.725
  Apr 19 13:01:00.746: INFO: Observed stateful pod in namespace: statefulset-6487, name: ss-0, uid: c9458758-115a-493e-860b-2f64b1ffba22, status phase: Pending. Waiting for statefulset controller to delete.
  Apr 19 13:01:00.765: INFO: Observed stateful pod in namespace: statefulset-6487, name: ss-0, uid: c9458758-115a-493e-860b-2f64b1ffba22, status phase: Failed. Waiting for statefulset controller to delete.
  Apr 19 13:01:00.774: INFO: Observed stateful pod in namespace: statefulset-6487, name: ss-0, uid: c9458758-115a-493e-860b-2f64b1ffba22, status phase: Failed. Waiting for statefulset controller to delete.
  Apr 19 13:01:00.777: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6487
  STEP: Removing pod with conflicting port in namespace statefulset-6487 @ 04/19/23 13:01:00.777
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6487 and will be in running state @ 04/19/23 13:01:00.79
  Apr 19 13:01:02.799: INFO: Deleting all statefulset in ns statefulset-6487
  Apr 19 13:01:02.803: INFO: Scaling statefulset ss to 0
  W0419 13:01:02.813856      20 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "webserver" uses hostPort 21017), allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:01:12.823: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 13:01:12.827: INFO: Deleting statefulset ss
  Apr 19 13:01:12.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6487" for this suite. @ 04/19/23 13:01:12.849
• [14.195 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods  [Conformance]
test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 04/19/23 13:01:12.858
  Apr 19 13:01:12.858: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 13:01:12.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:01:12.878
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:01:12.882
  STEP: creating service multi-endpoint-test in namespace services-3125 @ 04/19/23 13:01:12.885
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3125 to expose endpoints map[] @ 04/19/23 13:01:12.897
  Apr 19 13:01:12.909: INFO: successfully validated that service multi-endpoint-test in namespace services-3125 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-3125 @ 04/19/23 13:01:12.91
  W0419 13:01:12.921578      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3125 to expose endpoints map[pod1:[100]] @ 04/19/23 13:01:14.934
  Apr 19 13:01:14.944: INFO: successfully validated that service multi-endpoint-test in namespace services-3125 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-3125 @ 04/19/23 13:01:14.944
  W0419 13:01:14.955435      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3125 to expose endpoints map[pod1:[100] pod2:[101]] @ 04/19/23 13:01:16.968
  Apr 19 13:01:16.983: INFO: successfully validated that service multi-endpoint-test in namespace services-3125 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 04/19/23 13:01:16.983
  Apr 19 13:01:16.983: INFO: Creating new exec pod
  W0419 13:01:16.989008      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:01:19.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-3125 exec execpodjp869 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Apr 19 13:01:20.219: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Apr 19 13:01:20.219: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 13:01:20.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-3125 exec execpodjp869 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.103.186.226 80'
  Apr 19 13:01:20.407: INFO: stderr: "+ nc -v -t -w 2 10.103.186.226 80\nConnection to 10.103.186.226 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Apr 19 13:01:20.407: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 13:01:20.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-3125 exec execpodjp869 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Apr 19 13:01:22.626: INFO: rc: 1
  Apr 19 13:01:22.626: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-3125 exec execpodjp869 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81:
  Command stdout:

  stderr:
  + nc -v -t -w 2 multi-endpoint-test 81
  + echo hostName
  nc: connect to multi-endpoint-test port 81 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 19 13:01:23.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-3125 exec execpodjp869 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Apr 19 13:01:25.860: INFO: rc: 1
  Apr 19 13:01:25.860: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-3125 exec execpodjp869 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 multi-endpoint-test 81
  nc: connect to multi-endpoint-test port 81 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 19 13:01:26.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-3125 exec execpodjp869 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Apr 19 13:01:28.861: INFO: rc: 1
  Apr 19 13:01:28.861: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-3125 exec execpodjp869 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 multi-endpoint-test 81
  nc: connect to multi-endpoint-test port 81 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  Apr 19 13:01:29.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-3125 exec execpodjp869 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Apr 19 13:01:29.843: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Apr 19 13:01:29.843: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 13:01:29.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-3125 exec execpodjp869 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.103.186.226 81'
  Apr 19 13:01:30.006: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.103.186.226 81\nConnection to 10.103.186.226 81 port [tcp/*] succeeded!\n"
  Apr 19 13:01:30.006: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-3125 @ 04/19/23 13:01:30.006
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3125 to expose endpoints map[pod2:[101]] @ 04/19/23 13:01:30.022
  Apr 19 13:01:31.041: INFO: successfully validated that service multi-endpoint-test in namespace services-3125 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-3125 @ 04/19/23 13:01:31.041
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3125 to expose endpoints map[] @ 04/19/23 13:01:31.056
  Apr 19 13:01:31.067: INFO: successfully validated that service multi-endpoint-test in namespace services-3125 exposes endpoints map[]
  Apr 19 13:01:31.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3125" for this suite. @ 04/19/23 13:01:31.083
• [18.230 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:145
  STEP: Creating a kubernetes client @ 04/19/23 13:01:31.09
  Apr 19 13:01:31.090: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/23 13:01:31.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:01:31.102
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:01:31.104
  Apr 19 13:01:31.106: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:01:31.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3367" for this suite. @ 04/19/23 13:01:31.66
• [0.577 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]
test/e2e/kubectl/kubectl.go:1701
  STEP: Creating a kubernetes client @ 04/19/23 13:01:31.672
  Apr 19 13:01:31.672: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 13:01:31.675
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:01:31.687
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:01:31.69
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/19/23 13:01:31.692
  Apr 19 13:01:31.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-5050 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  Apr 19 13:01:31.760: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 13:01:31.760: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/19/23 13:01:31.76
  Apr 19 13:01:31.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-5050 delete pods e2e-test-httpd-pod'
  Apr 19 13:01:33.653: INFO: stderr: ""
  Apr 19 13:01:33.653: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 19 13:01:33.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5050" for this suite. @ 04/19/23 13:01:33.659
• [2.001 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]
test/e2e/kubectl/kubectl.go:1574
  STEP: Creating a kubernetes client @ 04/19/23 13:01:33.676
  Apr 19 13:01:33.676: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 13:01:33.68
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:01:33.696
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:01:33.7
  STEP: creating the pod @ 04/19/23 13:01:33.704
  Apr 19 13:01:33.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4829 create -f -'
  Apr 19 13:01:34.391: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"pause\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"pause\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"pause\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"pause\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 13:01:34.391: INFO: stdout: "pod/pause created\n"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 04/19/23 13:01:36.402
  Apr 19 13:01:36.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4829 label pods pause testing-label=testing-label-value'
  Apr 19 13:01:36.501: INFO: stderr: ""
  Apr 19 13:01:36.502: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 04/19/23 13:01:36.502
  Apr 19 13:01:36.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4829 get pod pause -L testing-label'
  Apr 19 13:01:36.572: INFO: stderr: ""
  Apr 19 13:01:36.572: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 04/19/23 13:01:36.573
  Apr 19 13:01:36.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4829 label pods pause testing-label-'
  Apr 19 13:01:36.633: INFO: stderr: ""
  Apr 19 13:01:36.633: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 04/19/23 13:01:36.633
  Apr 19 13:01:36.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4829 get pod pause -L testing-label'
  Apr 19 13:01:36.681: INFO: stderr: ""
  Apr 19 13:01:36.681: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 04/19/23 13:01:36.681
  Apr 19 13:01:36.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4829 delete --grace-period=0 --force -f -'
  Apr 19 13:01:36.748: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 13:01:36.748: INFO: stdout: "pod \"pause\" force deleted\n"
  Apr 19 13:01:36.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4829 get rc,svc -l name=pause --no-headers'
  Apr 19 13:01:36.814: INFO: stderr: "No resources found in kubectl-4829 namespace.\n"
  Apr 19 13:01:36.814: INFO: stdout: ""
  Apr 19 13:01:36.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-4829 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 19 13:01:36.862: INFO: stderr: ""
  Apr 19 13:01:36.863: INFO: stdout: ""
  Apr 19 13:01:36.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4829" for this suite. @ 04/19/23 13:01:36.866
• [3.195 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 04/19/23 13:01:36.872
  Apr 19 13:01:36.872: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-probe @ 04/19/23 13:01:36.873
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:01:36.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:01:36.886
  STEP: Creating pod liveness-3df8eeb6-df8f-41dc-b4ee-d6d47d41da1f in namespace container-probe-4289 @ 04/19/23 13:01:36.888
  W0419 13:01:36.894849      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:01:38.902: INFO: Started pod liveness-3df8eeb6-df8f-41dc-b4ee-d6d47d41da1f in namespace container-probe-4289
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/23 13:01:38.902
  Apr 19 13:01:38.905: INFO: Initial restart count of pod liveness-3df8eeb6-df8f-41dc-b4ee-d6d47d41da1f is 0
  Apr 19 13:01:58.954: INFO: Restart count of pod container-probe-4289/liveness-3df8eeb6-df8f-41dc-b4ee-d6d47d41da1f is now 1 (20.049306108s elapsed)
  Apr 19 13:02:18.998: INFO: Restart count of pod container-probe-4289/liveness-3df8eeb6-df8f-41dc-b4ee-d6d47d41da1f is now 2 (40.092861766s elapsed)
  Apr 19 13:02:39.046: INFO: Restart count of pod container-probe-4289/liveness-3df8eeb6-df8f-41dc-b4ee-d6d47d41da1f is now 3 (1m0.140877953s elapsed)
  Apr 19 13:02:59.100: INFO: Restart count of pod container-probe-4289/liveness-3df8eeb6-df8f-41dc-b4ee-d6d47d41da1f is now 4 (1m20.195376769s elapsed)
  Apr 19 13:04:07.262: INFO: Restart count of pod container-probe-4289/liveness-3df8eeb6-df8f-41dc-b4ee-d6d47d41da1f is now 5 (2m28.357295629s elapsed)
  Apr 19 13:04:07.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 13:04:07.266
  STEP: Destroying namespace "container-probe-4289" for this suite. @ 04/19/23 13:04:07.281
• [150.416 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:423
  STEP: Creating a kubernetes client @ 04/19/23 13:04:07.289
  Apr 19 13:04:07.289: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 13:04:07.291
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:04:07.308
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:04:07.312
  STEP: Creating configMap with name configmap-test-volume-e872af23-fcea-435a-919b-d150a51b4861 @ 04/19/23 13:04:07.316
  STEP: Creating a pod to test consume configMaps @ 04/19/23 13:04:07.321
  W0419 13:04:07.329105      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "configmap-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "configmap-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "configmap-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "configmap-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:04:11.343
  Apr 19 13:04:11.346: INFO: Trying to get logs from node talos-default-worker-1 pod pod-configmaps-e1809e07-3ba5-4ea1-8bef-e49e5d1f649e container configmap-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 13:04:11.36
  Apr 19 13:04:11.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4994" for this suite. @ 04/19/23 13:04:11.379
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:74
  STEP: Creating a kubernetes client @ 04/19/23 13:04:11.391
  Apr 19 13:04:11.391: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:04:11.393
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:04:11.408
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:04:11.412
  STEP: Creating configMap with name projected-configmap-test-volume-8e6b44d1-896e-4e21-a7f0-055af4c1ecd2 @ 04/19/23 13:04:11.415
  STEP: Creating a pod to test consume configMaps @ 04/19/23 13:04:11.42
  W0419 13:04:11.427814      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:04:15.442
  Apr 19 13:04:15.447: INFO: Trying to get logs from node talos-default-worker-1 pod pod-projected-configmaps-ee08081d-3a31-4fd9-980c-5976947d844c container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 13:04:15.454
  Apr 19 13:04:15.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8144" for this suite. @ 04/19/23 13:04:15.48
• [4.097 seconds]
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
test/e2e/network/endpointslice.go:207
  STEP: Creating a kubernetes client @ 04/19/23 13:04:15.487
  Apr 19 13:04:15.487: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename endpointslice @ 04/19/23 13:04:15.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:04:15.505
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:04:15.507
  W0419 13:04:15.517578      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "container1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "container1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "container1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "container1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  W0419 13:04:15.524209      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "container1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "container1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "container1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "container1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: referencing a single matching pod @ 04/19/23 13:04:20.57
  STEP: referencing matching pods with named port @ 04/19/23 13:04:25.579
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 04/19/23 13:04:30.589
  STEP: recreating EndpointSlices after they've been deleted @ 04/19/23 13:04:35.598
  Apr 19 13:04:35.622: INFO: EndpointSlice for Service endpointslice-1112/example-named-port not found
  Apr 19 13:04:45.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-1112" for this suite. @ 04/19/23 13:04:45.641
• [30.161 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 04/19/23 13:04:45.65
  Apr 19 13:04:45.650: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename deployment @ 04/19/23 13:04:45.652
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:04:45.667
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:04:45.671
  Apr 19 13:04:45.674: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  W0419 13:04:45.680410      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:04:45.685: INFO: Pod name sample-pod: Found 0 pods out of 1
  Apr 19 13:04:50.692: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/23 13:04:50.692
  Apr 19 13:04:50.692: INFO: Creating deployment "test-rolling-update-deployment"
  W0419 13:04:50.698936      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:04:50.699: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  Apr 19 13:04:50.712: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  Apr 19 13:04:52.721: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Apr 19 13:04:52.726: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Apr 19 13:04:52.736: INFO: Deployment "test-rolling-update-deployment":
  &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-6313  025d48e0-c059-4207-8804-c0fb544b7b1d 182391 1 2023-04-19 13:04:50 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-04-19 13:04:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:04:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0046976a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-19 13:04:50 +0000 UTC,LastTransitionTime:2023-04-19 13:04:50 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-656d657cd8" has successfully progressed.,LastUpdateTime:2023-04-19 13:04:52 +0000 UTC,LastTransitionTime:2023-04-19 13:04:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 19 13:04:52.742: INFO: New ReplicaSet "test-rolling-update-deployment-656d657cd8" of Deployment "test-rolling-update-deployment":
  &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-656d657cd8  deployment-6313  dc91e065-3a2a-4f70-92ce-ac92a20851b9 182381 1 2023-04-19 13:04:50 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:656d657cd8] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 025d48e0-c059-4207-8804-c0fb544b7b1d 0xc004a7caf7 0xc004a7caf8}] [] [{kube-controller-manager Update apps/v1 2023-04-19 13:04:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"025d48e0-c059-4207-8804-c0fb544b7b1d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:04:52 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 656d657cd8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:656d657cd8] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004a7cba8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 19 13:04:52.743: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Apr 19 13:04:52.743: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-6313  a2b59b62-802a-4e94-a5c3-1929594292b2 182390 2 2023-04-19 13:04:45 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 025d48e0-c059-4207-8804-c0fb544b7b1d 0xc004a7c9c7 0xc004a7c9c8}] [] [{e2e.test Update apps/v1 2023-04-19 13:04:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:04:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"025d48e0-c059-4207-8804-c0fb544b7b1d\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:04:52 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004a7ca88 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 19 13:04:52.748: INFO: Pod "test-rolling-update-deployment-656d657cd8-gkxfm" is available:
  &Pod{ObjectMeta:{test-rolling-update-deployment-656d657cd8-gkxfm test-rolling-update-deployment-656d657cd8- deployment-6313  aa0b2707-2158-4e95-bf60-e9947b0f011b 182380 0 2023-04-19 13:04:50 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:656d657cd8] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-656d657cd8 dc91e065-3a2a-4f70-92ce-ac92a20851b9 0xc004697de7 0xc004697de8}] [] [{kube-controller-manager Update v1 2023-04-19 13:04:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"dc91e065-3a2a-4f70-92ce-ac92a20851b9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:04:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.3.35\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nncl5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nncl5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:04:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:04:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:04:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:04:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:10.244.3.35,StartTime:2023-04-19 13:04:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:04:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:containerd://2d8a5dcb3643de2e91523ae48b31eb23b9e70c8461348a5889d356114a467fdd,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.35,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:04:52.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6313" for this suite. @ 04/19/23 13:04:52.754
• [7.111 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:85
  STEP: Creating a kubernetes client @ 04/19/23 13:04:52.767
  Apr 19 13:04:52.767: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/23 13:04:52.77
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:04:52.785
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:04:52.788
  Apr 19 13:04:52.793: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:04:59.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6211" for this suite. @ 04/19/23 13:04:59.03
• [6.270 seconds]
------------------------------
S
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:486
  STEP: Creating a kubernetes client @ 04/19/23 13:04:59.039
  Apr 19 13:04:59.040: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename security-context-test @ 04/19/23 13:04:59.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:04:59.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:04:59.067
  W0419 13:04:59.078745      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-readonly-false-59d19cab-26f9-4df4-9577-903ba49fb837" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-readonly-false-59d19cab-26f9-4df4-9577-903ba49fb837" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-readonly-false-59d19cab-26f9-4df4-9577-903ba49fb837" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-readonly-false-59d19cab-26f9-4df4-9577-903ba49fb837" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:05:03.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-1036" for this suite. @ 04/19/23 13:05:03.1
• [4.069 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:176
  STEP: Creating a kubernetes client @ 04/19/23 13:05:03.107
  Apr 19 13:05:03.107: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename crd-webhook @ 04/19/23 13:05:03.109
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:05:03.128
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:05:03.132
  STEP: Setting up server cert @ 04/19/23 13:05:03.135
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/19/23 13:05:03.455
  STEP: Deploying the custom resource conversion webhook pod @ 04/19/23 13:05:03.469
  W0419 13:05:03.480846      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-crd-conversion-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-crd-conversion-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-crd-conversion-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-crd-conversion-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 13:05:03.481
  Apr 19 13:05:03.489: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/19/23 13:05:05.501
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 13:05:05.52
  Apr 19 13:05:06.520: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Apr 19 13:05:06.525: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Creating a v1 custom resource @ 04/19/23 13:05:09.085
  STEP: Create a v2 custom resource @ 04/19/23 13:05:09.107
  STEP: List CRs in v1 @ 04/19/23 13:05:09.137
  STEP: List CRs in v2 @ 04/19/23 13:05:09.145
  Apr 19 13:05:09.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-3882" for this suite. @ 04/19/23 13:05:09.713
• [6.612 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]
test/e2e/apimachinery/resource_quota.go:161
  STEP: Creating a kubernetes client @ 04/19/23 13:05:09.728
  Apr 19 13:05:09.729: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename resourcequota @ 04/19/23 13:05:09.731
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:05:09.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:05:09.748
  STEP: Discovering how many secrets are in namespace by default @ 04/19/23 13:05:09.751
  STEP: Counting existing ResourceQuota @ 04/19/23 13:05:14.755
  STEP: Creating a ResourceQuota @ 04/19/23 13:05:19.759
  STEP: Ensuring resource quota status is calculated @ 04/19/23 13:05:19.769
  STEP: Creating a Secret @ 04/19/23 13:05:21.773
  STEP: Ensuring resource quota status captures secret creation @ 04/19/23 13:05:21.79
  STEP: Deleting a secret @ 04/19/23 13:05:23.795
  STEP: Ensuring resource quota status released usage @ 04/19/23 13:05:23.801
  Apr 19 13:05:25.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5175" for this suite. @ 04/19/23 13:05:25.81
• [16.089 seconds]
------------------------------
S
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]
test/e2e/apps/job.go:513
  STEP: Creating a kubernetes client @ 04/19/23 13:05:25.818
  Apr 19 13:05:25.819: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename job @ 04/19/23 13:05:25.82
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:05:25.837
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:05:25.841
  STEP: Creating a job @ 04/19/23 13:05:25.846
  W0419 13:05:25.852802      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring active pods == parallelism @ 04/19/23 13:05:25.852
  STEP: Orphaning one of the Job's Pods @ 04/19/23 13:05:27.858
  Apr 19 13:05:28.377: INFO: Successfully updated pod "adopt-release-4rdkn"
  STEP: Checking that the Job readopts the Pod @ 04/19/23 13:05:28.377
  STEP: Removing the labels from the Job's Pod @ 04/19/23 13:05:30.388
  Apr 19 13:05:30.900: INFO: Successfully updated pod "adopt-release-4rdkn"
  STEP: Checking that the Job releases the Pod @ 04/19/23 13:05:30.9
  Apr 19 13:05:32.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-4301" for this suite. @ 04/19/23 13:05:32.912
• [7.098 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]
test/e2e/scheduling/predicates.go:467
  STEP: Creating a kubernetes client @ 04/19/23 13:05:32.917
  Apr 19 13:05:32.917: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename sched-pred @ 04/19/23 13:05:32.918
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:05:32.934
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:05:32.938
  Apr 19 13:05:32.942: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 19 13:05:32.949: INFO: Waiting for terminating namespaces to be deleted...
  Apr 19 13:05:32.952: INFO: 
  Logging pods the apiserver thinks is on node talos-default-worker-1 before test
  Apr 19 13:05:32.958: INFO: adopt-release-4rdkn from job-4301 started at 2023-04-19 13:05:25 +0000 UTC (1 container statuses recorded)
  Apr 19 13:05:32.958: INFO: 	Container c ready: true, restart count 0
  Apr 19 13:05:32.958: INFO: adopt-release-n9gzt from job-4301 started at 2023-04-19 13:05:25 +0000 UTC (1 container statuses recorded)
  Apr 19 13:05:32.958: INFO: 	Container c ready: true, restart count 0
  Apr 19 13:05:32.958: INFO: kube-flannel-xtc62 from kube-system started at 2023-04-18 19:32:12 +0000 UTC (1 container statuses recorded)
  Apr 19 13:05:32.958: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 19 13:05:32.958: INFO: kube-proxy-j7zxh from kube-system started at 2023-04-18 19:32:12 +0000 UTC (1 container statuses recorded)
  Apr 19 13:05:32.959: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 19 13:05:32.960: INFO: sonobuoy from sonobuoy started at 2023-04-19 12:53:21 +0000 UTC (1 container statuses recorded)
  Apr 19 13:05:32.960: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 19 13:05:32.960: INFO: 
  Logging pods the apiserver thinks is on node talos-default-worker-2 before test
  Apr 19 13:05:32.966: INFO: adopt-release-7lb4l from job-4301 started at 2023-04-19 13:05:31 +0000 UTC (1 container statuses recorded)
  Apr 19 13:05:32.966: INFO: 	Container c ready: false, restart count 0
  Apr 19 13:05:32.966: INFO: coredns-d779cc7ff-z6svh from kube-system started at 2023-04-18 19:38:29 +0000 UTC (1 container statuses recorded)
  Apr 19 13:05:32.966: INFO: 	Container coredns ready: true, restart count 0
  Apr 19 13:05:32.966: INFO: kube-flannel-xntjw from kube-system started at 2023-04-18 19:32:33 +0000 UTC (1 container statuses recorded)
  Apr 19 13:05:32.966: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 19 13:05:32.966: INFO: kube-proxy-qxzd4 from kube-system started at 2023-04-18 19:32:33 +0000 UTC (1 container statuses recorded)
  Apr 19 13:05:32.966: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 19 13:05:32.966: INFO: sonobuoy-e2e-job-9b851c216c1a4329 from sonobuoy started at 2023-04-19 12:53:22 +0000 UTC (2 container statuses recorded)
  Apr 19 13:05:32.966: INFO: 	Container e2e ready: true, restart count 0
  Apr 19 13:05:32.966: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/19/23 13:05:32.966
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/19/23 13:05:34.982
  STEP: Trying to apply a random label on the found node. @ 04/19/23 13:05:34.99
  STEP: verifying the node has the label kubernetes.io/e2e-d48e598a-9c57-4441-9c9c-53680b28b688 42 @ 04/19/23 13:05:35.003
  STEP: Trying to relaunch the pod, now with labels. @ 04/19/23 13:05:35.007
  STEP: removing the label kubernetes.io/e2e-d48e598a-9c57-4441-9c9c-53680b28b688 off the node talos-default-worker-1 @ 04/19/23 13:05:37.024
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-d48e598a-9c57-4441-9c9c-53680b28b688 @ 04/19/23 13:05:37.04
  Apr 19 13:05:37.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-690" for this suite. @ 04/19/23 13:05:37.05
• [4.140 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]
test/e2e/apps/daemon_set.go:194
  STEP: Creating a kubernetes client @ 04/19/23 13:05:37.058
  Apr 19 13:05:37.058: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename daemonsets @ 04/19/23 13:05:37.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:05:37.077
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:05:37.081
  Apr 19 13:05:37.099: INFO: Creating daemon "daemon-set" with a node selector
  W0419 13:05:37.104670      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Initially, daemon pods should not be running on any nodes. @ 04/19/23 13:05:37.104
  Apr 19 13:05:37.107: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:05:37.107: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 04/19/23 13:05:37.107
  Apr 19 13:05:37.124: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:05:37.124: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:05:38.129: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:05:38.129: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:05:39.128: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 13:05:39.128: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 04/19/23 13:05:39.131
  Apr 19 13:05:39.147: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 13:05:39.147: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  Apr 19 13:05:40.153: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:05:40.153: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 04/19/23 13:05:40.153
  W0419 13:05:40.159696      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:05:40.165: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:05:40.165: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:05:41.170: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:05:41.170: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:05:42.170: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 13:05:42.170: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/23 13:05:42.179
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3581, will wait for the garbage collector to delete the pods @ 04/19/23 13:05:42.179
  Apr 19 13:05:42.238: INFO: Deleting DaemonSet.extensions daemon-set took: 4.450029ms
  Apr 19 13:05:42.339: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.965359ms
  Apr 19 13:05:43.242: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:05:43.243: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 19 13:05:43.246: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"182844"},"items":null}

  Apr 19 13:05:43.249: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"182844"},"items":null}

  Apr 19 13:05:43.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3581" for this suite. @ 04/19/23 13:05:43.267
• [6.214 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 04/19/23 13:05:43.274
  Apr 19 13:05:43.274: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-runtime @ 04/19/23 13:05:43.276
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:05:43.286
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:05:43.289
  STEP: create the container @ 04/19/23 13:05:43.292
  W0419 13:05:43.298930      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  W0419 13:05:43.298956      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "termination-message-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "termination-message-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "termination-message-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "termination-message-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: wait for the container to reach Failed @ 04/19/23 13:05:43.299
  STEP: get the container status @ 04/19/23 13:05:46.316
  STEP: the container should be terminated @ 04/19/23 13:05:46.32
  STEP: the termination message should be set @ 04/19/23 13:05:46.32
  Apr 19 13:05:46.320: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/19/23 13:05:46.32
  Apr 19 13:05:46.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7541" for this suite. @ 04/19/23 13:05:46.347
• [3.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]
test/e2e/kubectl/kubectl.go:1027
  STEP: Creating a kubernetes client @ 04/19/23 13:05:46.366
  Apr 19 13:05:46.366: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 13:05:46.367
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:05:46.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:05:46.389
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/19/23 13:05:46.392
  Apr 19 13:05:46.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-9765 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Apr 19 13:05:46.475: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 13:05:46.475: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 04/19/23 13:05:46.475
  Apr 19 13:05:46.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-9765 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-4"}]}} --dry-run=server'
  Apr 19 13:05:46.546: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 13:05:46.546: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/19/23 13:05:46.546
  Apr 19 13:05:46.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-9765 delete pods e2e-test-httpd-pod'
  Apr 19 13:05:48.247: INFO: stderr: ""
  Apr 19 13:05:48.247: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 19 13:05:48.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9765" for this suite. @ 04/19/23 13:05:48.254
• [1.899 seconds]
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 04/19/23 13:05:48.265
  Apr 19 13:05:48.265: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename proxy @ 04/19/23 13:05:48.265
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:05:48.278
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:05:48.281
  Apr 19 13:05:48.284: INFO: Creating pod...
  W0419 13:05:48.291643      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:05:50.300: INFO: Creating service...
  Apr 19 13:05:50.315: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-664/pods/agnhost/proxy/some/path/with/DELETE
  Apr 19 13:05:50.326: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 19 13:05:50.326: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-664/pods/agnhost/proxy/some/path/with/GET
  Apr 19 13:05:50.333: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Apr 19 13:05:50.334: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-664/pods/agnhost/proxy/some/path/with/HEAD
  Apr 19 13:05:50.341: INFO: http.Client request:HEAD | StatusCode:200
  Apr 19 13:05:50.342: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-664/pods/agnhost/proxy/some/path/with/OPTIONS
  Apr 19 13:05:50.347: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 19 13:05:50.347: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-664/pods/agnhost/proxy/some/path/with/PATCH
  Apr 19 13:05:50.352: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 19 13:05:50.352: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-664/pods/agnhost/proxy/some/path/with/POST
  Apr 19 13:05:50.357: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 19 13:05:50.357: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-664/pods/agnhost/proxy/some/path/with/PUT
  Apr 19 13:05:50.361: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 19 13:05:50.362: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-664/services/test-service/proxy/some/path/with/DELETE
  Apr 19 13:05:50.369: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 19 13:05:50.370: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-664/services/test-service/proxy/some/path/with/GET
  Apr 19 13:05:50.376: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Apr 19 13:05:50.376: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-664/services/test-service/proxy/some/path/with/HEAD
  Apr 19 13:05:50.381: INFO: http.Client request:HEAD | StatusCode:200
  Apr 19 13:05:50.381: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-664/services/test-service/proxy/some/path/with/OPTIONS
  Apr 19 13:05:50.386: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 19 13:05:50.386: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-664/services/test-service/proxy/some/path/with/PATCH
  Apr 19 13:05:50.391: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 19 13:05:50.391: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-664/services/test-service/proxy/some/path/with/POST
  Apr 19 13:05:50.395: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 19 13:05:50.395: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-664/services/test-service/proxy/some/path/with/PUT
  Apr 19 13:05:50.399: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 19 13:05:50.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-664" for this suite. @ 04/19/23 13:05:50.402
• [2.142 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:87
  STEP: Creating a kubernetes client @ 04/19/23 13:05:50.407
  Apr 19 13:05:50.407: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 13:05:50.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:05:50.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:05:50.42
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 04/19/23 13:05:50.423
  W0419 13:05:50.428688      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:05:54.446
  Apr 19 13:05:54.450: INFO: Trying to get logs from node talos-default-worker-2 pod pod-330b6ff3-3119-4973-b323-e23ed83df252 container test-container: <nil>
  STEP: delete the pod @ 04/19/23 13:05:54.461
  Apr 19 13:05:54.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4043" for this suite. @ 04/19/23 13:05:54.488
• [4.089 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:398
  STEP: Creating a kubernetes client @ 04/19/23 13:05:54.495
  Apr 19 13:05:54.496: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename namespaces @ 04/19/23 13:05:54.497
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:05:54.511
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:05:54.514
  STEP: Creating namespace "e2e-ns-nc7ns" @ 04/19/23 13:05:54.516
  Apr 19 13:05:54.529: INFO: Namespace "e2e-ns-nc7ns-6532" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-nc7ns-6532" @ 04/19/23 13:05:54.53
  Apr 19 13:05:54.537: INFO: Namespace "e2e-ns-nc7ns-6532" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-nc7ns-6532" @ 04/19/23 13:05:54.537
  Apr 19 13:05:54.545: INFO: Namespace "e2e-ns-nc7ns-6532" has []v1.FinalizerName{"kubernetes"}
  Apr 19 13:05:54.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3024" for this suite. @ 04/19/23 13:05:54.549
  STEP: Destroying namespace "e2e-ns-nc7ns-6532" for this suite. @ 04/19/23 13:05:54.554
• [0.063 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance]
test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 04/19/23 13:05:54.562
  Apr 19 13:05:54.563: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename dns @ 04/19/23 13:05:54.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:05:54.574
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:05:54.577
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 04/19/23 13:05:54.579
  W0419 13:05:54.585268      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:05:54.585: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-3096  75c75de9-0679-427c-be8c-288390622923 182987 0 2023-04-19 13:05:54 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-04-19 13:05:54 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-264bq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-264bq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  STEP: Verifying customized DNS suffix list is configured on pod... @ 04/19/23 13:05:56.594
  Apr 19 13:05:56.594: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-3096 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:05:56.594: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:05:56.595: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:05:56.596: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-3096/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 04/19/23 13:05:56.769
  Apr 19 13:05:56.769: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-3096 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:05:56.769: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:05:56.769: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:05:56.769: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-3096/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 19 13:05:56.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 19 13:05:56.882: INFO: Deleting pod test-dns-nameservers...
  STEP: Destroying namespace "dns-3096" for this suite. @ 04/19/23 13:05:56.891
• [2.336 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]
test/e2e/apps/rc.go:94
  STEP: Creating a kubernetes client @ 04/19/23 13:05:56.9
  Apr 19 13:05:56.900: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename replication-controller @ 04/19/23 13:05:56.901
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:05:56.915
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:05:56.917
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 04/19/23 13:05:56.919
  W0419 13:05:56.926059      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-adoption" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-adoption" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-adoption" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-adoption" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: When a replication controller with a matching selector is created @ 04/19/23 13:05:58.937
  W0419 13:05:58.944349      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-adoption" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-adoption" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-adoption" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-adoption" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Then the orphan pod is adopted @ 04/19/23 13:05:58.944
  Apr 19 13:05:59.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9367" for this suite. @ 04/19/23 13:05:59.959
• [3.069 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance]
test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 04/19/23 13:05:59.971
  Apr 19 13:05:59.971: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename deployment @ 04/19/23 13:05:59.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:05:59.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:05:59.989
  Apr 19 13:05:59.991: INFO: Creating deployment "webserver-deployment"
  W0419 13:06:00.001136      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:06:00.001: INFO: Waiting for observed generation 1
  Apr 19 13:06:02.008: INFO: Waiting for all required pods to come up
  Apr 19 13:06:02.012: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 04/19/23 13:06:02.012
  Apr 19 13:06:04.024: INFO: Waiting for deployment "webserver-deployment" to complete
  Apr 19 13:06:04.032: INFO: Updating deployment "webserver-deployment" with a non-existent image
  W0419 13:06:04.050240      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:06:04.050: INFO: Updating deployment webserver-deployment
  Apr 19 13:06:04.051: INFO: Waiting for observed generation 2
  Apr 19 13:06:06.061: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Apr 19 13:06:06.063: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Apr 19 13:06:06.067: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Apr 19 13:06:06.077: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Apr 19 13:06:06.077: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Apr 19 13:06:06.081: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Apr 19 13:06:06.087: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Apr 19 13:06:06.087: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  W0419 13:06:06.096176      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:06:06.096: INFO: Updating deployment webserver-deployment
  Apr 19 13:06:06.096: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Apr 19 13:06:06.103: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  Apr 19 13:06:06.108: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Apr 19 13:06:06.118: INFO: Deployment "webserver-deployment":
  &Deployment{ObjectMeta:{webserver-deployment  deployment-1246  a2332b18-6145-4f85-b96e-221e0e9e1e05 183280 3 2023-04-19 13:05:59 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00476ec98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-7b75d79cf5" is progressing.,LastUpdateTime:2023-04-19 13:06:04 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-19 13:06:06 +0000 UTC,LastTransitionTime:2023-04-19 13:06:06 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

  Apr 19 13:06:06.128: INFO: New ReplicaSet "webserver-deployment-7b75d79cf5" of Deployment "webserver-deployment":
  &ReplicaSet{ObjectMeta:{webserver-deployment-7b75d79cf5  deployment-1246  68827e83-5918-4a1b-941c-8252c43ffa20 183273 3 2023-04-19 13:06:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment a2332b18-6145-4f85-b96e-221e0e9e1e05 0xc00476f197 0xc00476f198}] [] [{kube-controller-manager Update apps/v1 2023-04-19 13:06:04 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a2332b18-6145-4f85-b96e-221e0e9e1e05\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 7b75d79cf5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00476f238 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 19 13:06:06.129: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Apr 19 13:06:06.130: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-67bd4bf6dc  deployment-1246  99299959-0fca-4cff-a1e2-4909e7e3b9ef 183270 3 2023-04-19 13:06:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment a2332b18-6145-4f85-b96e-221e0e9e1e05 0xc00476f0a7 0xc00476f0a8}] [] [{kube-controller-manager Update apps/v1 2023-04-19 13:06:04 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a2332b18-6145-4f85-b96e-221e0e9e1e05\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 67bd4bf6dc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00476f138 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
  Apr 19 13:06:06.144: INFO: Pod "webserver-deployment-67bd4bf6dc-4f62b" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-4f62b webserver-deployment-67bd4bf6dc- deployment-1246  55fa8c36-7d3b-4192-973d-0cfd998e1764 183152 0 2023-04-19 13:06:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc004854cf7 0xc004854cf8}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:06:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.3.50\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9t6sf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9t6sf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:10.244.3.50,StartTime:2023-04-19 13:06:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:06:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://ac3a9fbdc4e7978c1e038c5fb1dbcc5f9b7fa01a565f85dbcbd18c8712559f4d,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.50,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.144: INFO: Pod "webserver-deployment-67bd4bf6dc-4gwsh" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-4gwsh webserver-deployment-67bd4bf6dc- deployment-1246  96066099-d674-411a-a717-ec18bf9790fe 183158 0 2023-04-19 13:06:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc004854ed0 0xc004854ed1}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:06:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.3.48\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nvc9f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nvc9f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:10.244.3.48,StartTime:2023-04-19 13:06:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:06:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://67e236286079e1e910f8d515d71d2f3eea27b07ec8a4bb0fd01a912a1ba64d2c,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.48,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.145: INFO: Pod "webserver-deployment-67bd4bf6dc-52574" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-52574 webserver-deployment-67bd4bf6dc- deployment-1246  62d15b7b-f79f-4df0-9cf0-3078fa3f7258 183144 0 2023-04-19 13:06:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc0048550a0 0xc0048550a1}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:06:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.32\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rpzdx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rpzdx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.6,PodIP:10.244.1.32,StartTime:2023-04-19 13:06:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:06:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://4996ce8f41d6cab9e3a876a6e251c4cdbfc55283bf4c5a73306009a5420a197c,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.32,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.145: INFO: Pod "webserver-deployment-67bd4bf6dc-56fqv" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-56fqv webserver-deployment-67bd4bf6dc- deployment-1246  82cd8fa1-7cf5-4523-a474-9612e1f047ec 183155 0 2023-04-19 13:06:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc004855270 0xc004855271}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:06:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.3.51\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-svfzt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-svfzt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:10.244.3.51,StartTime:2023-04-19 13:06:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:06:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://87c99df88048ba1ef4ef25cc1d22a8df905cf2703d6c9759830c248f657a920a,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.51,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.145: INFO: Pod "webserver-deployment-67bd4bf6dc-74s9f" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-74s9f webserver-deployment-67bd4bf6dc- deployment-1246  77adb3ed-83f3-4b85-be3c-28b2c8301852 183286 0 2023-04-19 13:06:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc004855440 0xc004855441}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nbhw8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nbhw8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.146: INFO: Pod "webserver-deployment-67bd4bf6dc-c7rst" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-c7rst webserver-deployment-67bd4bf6dc- deployment-1246  31aff0b6-7f1e-4a0f-ab9e-4318d96a140a 183187 0 2023-04-19 13:06:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc004855580 0xc004855581}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:06:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.3.52\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zxc9z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zxc9z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:10.244.3.52,StartTime:2023-04-19 13:06:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:06:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://063fb9bda31eb069fda35354a46949d9e37a181e5ef5bbb4f9b5cf0ab4298814,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.52,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.146: INFO: Pod "webserver-deployment-67bd4bf6dc-dg8d2" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-dg8d2 webserver-deployment-67bd4bf6dc- deployment-1246  706d0d87-e4d4-4d16-97fb-0c2a49966d98 183184 0 2023-04-19 13:06:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc004855750 0xc004855751}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:06:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.31\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jsjrj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jsjrj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.6,PodIP:10.244.1.31,StartTime:2023-04-19 13:06:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:06:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://529c3fe715a85d3255ed84497c8ba73b7700ecb4ab3a970597795f6c0478a7cb,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.31,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.146: INFO: Pod "webserver-deployment-67bd4bf6dc-fcz8c" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-fcz8c webserver-deployment-67bd4bf6dc- deployment-1246  b5c96a7f-3f2a-487c-bbcc-9d1c3a81e280 183288 0 2023-04-19 13:06:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc004855920 0xc004855921}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zg44l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zg44l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.147: INFO: Pod "webserver-deployment-67bd4bf6dc-fzd95" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-fzd95 webserver-deployment-67bd4bf6dc- deployment-1246  17c0542e-4a80-4a21-9e7b-16ea2cc0e7d2 183162 0 2023-04-19 13:06:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc004855a60 0xc004855a61}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:06:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.3.49\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fp7fr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fp7fr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:10.244.3.49,StartTime:2023-04-19 13:06:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:06:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://58ac40af64b2fd7b3362691cf955823ed7233abb0d7ebdb1e6fd2e660fbf96de,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.49,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.147: INFO: Pod "webserver-deployment-67bd4bf6dc-lgv7q" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-lgv7q webserver-deployment-67bd4bf6dc- deployment-1246  f37eddc5-802e-4913-89a5-45ff04905582 183287 0 2023-04-19 13:06:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc004855c30 0xc004855c31}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9twgd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9twgd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.147: INFO: Pod "webserver-deployment-67bd4bf6dc-mqr7q" is available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-mqr7q webserver-deployment-67bd4bf6dc- deployment-1246  0dce2a54-4132-4916-bf50-6d8814a72302 183175 0 2023-04-19 13:06:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc004855d70 0xc004855d71}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:06:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.33\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pgqr7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pgqr7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.6,PodIP:10.244.1.33,StartTime:2023-04-19 13:06:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:06:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://e1de82d2c1ef64c165df397e8f0e73bf5186f1ca977ab2f7aa5c2c6b223421b6,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.33,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.147: INFO: Pod "webserver-deployment-67bd4bf6dc-pfmz9" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-pfmz9 webserver-deployment-67bd4bf6dc- deployment-1246  ba1394d9-1309-45ca-97a5-c71a3bffd816 183291 0 2023-04-19 13:06:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc004855f40 0xc004855f41}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hzd5w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hzd5w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.6,PodIP:,StartTime:2023-04-19 13:06:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.147: INFO: Pod "webserver-deployment-67bd4bf6dc-smfn2" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-smfn2 webserver-deployment-67bd4bf6dc- deployment-1246  72f2da1a-f7bf-4c26-81ec-209aef0ed2eb 183281 0 2023-04-19 13:06:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc0049b40f0 0xc0049b40f1}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8g8n2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8g8n2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.148: INFO: Pod "webserver-deployment-67bd4bf6dc-vbvqw" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-vbvqw webserver-deployment-67bd4bf6dc- deployment-1246  92a52420-392e-4de4-b483-3b2f9de4f658 183284 0 2023-04-19 13:06:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc0049b4240 0xc0049b4241}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-969dv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-969dv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.148: INFO: Pod "webserver-deployment-67bd4bf6dc-wn7hm" is not available:
  &Pod{ObjectMeta:{webserver-deployment-67bd4bf6dc-wn7hm webserver-deployment-67bd4bf6dc- deployment-1246  2d61f3fe-c538-488f-935e-122a3705e5f2 183293 0 2023-04-19 13:06:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet webserver-deployment-67bd4bf6dc 99299959-0fca-4cff-a1e2-4909e7e3b9ef 0xc0049b4380 0xc0049b4381}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99299959-0fca-4cff-a1e2-4909e7e3b9ef\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x2tkv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x2tkv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.148: INFO: Pod "webserver-deployment-7b75d79cf5-28jl4" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-28jl4 webserver-deployment-7b75d79cf5- deployment-1246  77ec0517-1af2-40d5-b9be-dbb41025e117 183283 0 2023-04-19 13:06:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 68827e83-5918-4a1b-941c-8252c43ffa20 0xc0049b44d0 0xc0049b44d1}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"68827e83-5918-4a1b-941c-8252c43ffa20\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4ssk7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4ssk7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.154: INFO: Pod "webserver-deployment-7b75d79cf5-2rctr" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-2rctr webserver-deployment-7b75d79cf5- deployment-1246  cf7d940f-e180-4f77-8f58-41e86dc2e602 183282 0 2023-04-19 13:06:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 68827e83-5918-4a1b-941c-8252c43ffa20 0xc0049b4620 0xc0049b4621}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"68827e83-5918-4a1b-941c-8252c43ffa20\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pv6xp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pv6xp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.154: INFO: Pod "webserver-deployment-7b75d79cf5-7dwn9" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-7dwn9 webserver-deployment-7b75d79cf5- deployment-1246  4caf3001-3ca4-4973-8f7b-f0183647fdc7 183220 0 2023-04-19 13:06:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 68827e83-5918-4a1b-941c-8252c43ffa20 0xc0049b4770 0xc0049b4771}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"68827e83-5918-4a1b-941c-8252c43ffa20\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:06:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j9tvr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j9tvr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:,StartTime:2023-04-19 13:06:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.155: INFO: Pod "webserver-deployment-7b75d79cf5-97n55" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-97n55 webserver-deployment-7b75d79cf5- deployment-1246  9804b30c-3d73-4217-88f7-770b7e7eead4 183244 0 2023-04-19 13:06:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 68827e83-5918-4a1b-941c-8252c43ffa20 0xc0049b4940 0xc0049b4941}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"68827e83-5918-4a1b-941c-8252c43ffa20\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:06:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fwzw9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fwzw9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.6,PodIP:,StartTime:2023-04-19 13:06:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.155: INFO: Pod "webserver-deployment-7b75d79cf5-cpptn" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-cpptn webserver-deployment-7b75d79cf5- deployment-1246  08cac347-33e4-468a-ab92-bea0eb8125d7 183240 0 2023-04-19 13:06:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 68827e83-5918-4a1b-941c-8252c43ffa20 0xc0049b4b10 0xc0049b4b11}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"68827e83-5918-4a1b-941c-8252c43ffa20\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:06:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7vw26,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7vw26,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:,StartTime:2023-04-19 13:06:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.156: INFO: Pod "webserver-deployment-7b75d79cf5-jbkmv" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-jbkmv webserver-deployment-7b75d79cf5- deployment-1246  f5f6d98e-8958-4b8b-920e-1e1a9b3b088c 183221 0 2023-04-19 13:06:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 68827e83-5918-4a1b-941c-8252c43ffa20 0xc0049b4ce0 0xc0049b4ce1}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"68827e83-5918-4a1b-941c-8252c43ffa20\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:06:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nlhdn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nlhdn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.6,PodIP:,StartTime:2023-04-19 13:06:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.156: INFO: Pod "webserver-deployment-7b75d79cf5-shlsc" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-shlsc webserver-deployment-7b75d79cf5- deployment-1246  b2242ebb-6949-4f14-b2a0-eeedd89d5a8e 183289 0 2023-04-19 13:06:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 68827e83-5918-4a1b-941c-8252c43ffa20 0xc0049b4eb0 0xc0049b4eb1}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"68827e83-5918-4a1b-941c-8252c43ffa20\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rms4d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rms4d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.157: INFO: Pod "webserver-deployment-7b75d79cf5-zsz6h" is not available:
  &Pod{ObjectMeta:{webserver-deployment-7b75d79cf5-zsz6h webserver-deployment-7b75d79cf5- deployment-1246  617f800b-33fe-41fb-8ae7-3b869f3e5b08 183214 0 2023-04-19 13:06:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:7b75d79cf5] map[] [{apps/v1 ReplicaSet webserver-deployment-7b75d79cf5 68827e83-5918-4a1b-941c-8252c43ffa20 0xc0049b5010 0xc0049b5011}] [] [{kube-controller-manager Update v1 2023-04-19 13:06:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"68827e83-5918-4a1b-941c-8252c43ffa20\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:06:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vtllh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vtllh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:06:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.6,PodIP:,StartTime:2023-04-19 13:06:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:06:06.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1246" for this suite. @ 04/19/23 13:06:06.163
• [6.204 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 04/19/23 13:06:06.175
  Apr 19 13:06:06.175: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename secrets @ 04/19/23 13:06:06.177
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:06:06.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:06:06.192
  STEP: Creating secret with name secret-test-map-0b385684-4f53-46bc-ac28-c938173b538b @ 04/19/23 13:06:06.194
  STEP: Creating a pod to test consume secrets @ 04/19/23 13:06:06.199
  W0419 13:06:06.207483      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:06:10.217
  Apr 19 13:06:10.220: INFO: Trying to get logs from node talos-default-worker-1 pod pod-secrets-23c8f1da-0892-4c27-947c-37625740b7d4 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 13:06:10.232
  Apr 19 13:06:10.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1994" for this suite. @ 04/19/23 13:06:10.245
• [4.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]
test/e2e/apps/statefulset.go:852
  STEP: Creating a kubernetes client @ 04/19/23 13:06:10.254
  Apr 19 13:06:10.254: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename statefulset @ 04/19/23 13:06:10.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:06:10.266
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:06:10.268
  STEP: Creating service test in namespace statefulset-9728 @ 04/19/23 13:06:10.271
  STEP: Creating statefulset ss in namespace statefulset-9728 @ 04/19/23 13:06:10.275
  W0419 13:06:10.280021      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:06:10.283: INFO: Found 0 stateful pods, waiting for 1
  Apr 19 13:06:20.288: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 04/19/23 13:06:20.295
  STEP: updating a scale subresource @ 04/19/23 13:06:20.298
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/19/23 13:06:20.304
  STEP: Patch a scale subresource @ 04/19/23 13:06:20.309
  STEP: verifying the statefulset Spec.Replicas was modified @ 04/19/23 13:06:20.322
  Apr 19 13:06:20.327: INFO: Deleting all statefulset in ns statefulset-9728
  Apr 19 13:06:20.332: INFO: Scaling statefulset ss to 0
  W0419 13:06:20.353449      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:06:30.361: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 13:06:30.365: INFO: Deleting statefulset ss
  Apr 19 13:06:30.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-9728" for this suite. @ 04/19/23 13:06:30.393
• [20.146 seconds]
------------------------------
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 04/19/23 13:06:30.401
  Apr 19 13:06:30.401: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-runtime @ 04/19/23 13:06:30.403
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:06:30.419
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:06:30.423
  STEP: create the container @ 04/19/23 13:06:30.426
  W0419 13:06:30.435547      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  W0419 13:06:30.435581      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "termination-message-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "termination-message-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "termination-message-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "termination-message-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: wait for the container to reach Succeeded @ 04/19/23 13:06:30.435
  STEP: get the container status @ 04/19/23 13:06:33.452
  STEP: the container should be terminated @ 04/19/23 13:06:33.456
  STEP: the termination message should be set @ 04/19/23 13:06:33.456
  Apr 19 13:06:33.456: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 04/19/23 13:06:33.456
  Apr 19 13:06:33.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-959" for this suite. @ 04/19/23 13:06:33.478
• [3.082 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]
test/e2e/auth/service_accounts.go:740
  STEP: Creating a kubernetes client @ 04/19/23 13:06:33.485
  Apr 19 13:06:33.485: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/23 13:06:33.486
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:06:33.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:06:33.501
  Apr 19 13:06:33.506: INFO: Got root ca configmap in namespace "svcaccounts-7068"
  Apr 19 13:06:33.511: INFO: Deleted root ca configmap in namespace "svcaccounts-7068"
  STEP: waiting for a new root ca configmap created @ 04/19/23 13:06:34.012
  Apr 19 13:06:34.016: INFO: Recreated root ca configmap in namespace "svcaccounts-7068"
  Apr 19 13:06:34.020: INFO: Updated root ca configmap in namespace "svcaccounts-7068"
  STEP: waiting for the root ca configmap reconciled @ 04/19/23 13:06:34.521
  Apr 19 13:06:34.525: INFO: Reconciled root ca configmap in namespace "svcaccounts-7068"
  Apr 19 13:06:34.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7068" for this suite. @ 04/19/23 13:06:34.531
• [1.054 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]
test/e2e/apps/daemon_set.go:294
  STEP: Creating a kubernetes client @ 04/19/23 13:06:34.55
  Apr 19 13:06:34.550: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename daemonsets @ 04/19/23 13:06:34.552
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:06:34.565
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:06:34.568
  STEP: Creating a simple DaemonSet "daemon-set" @ 04/19/23 13:06:34.587
  W0419 13:06:34.591585      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/23 13:06:34.592
  Apr 19 13:06:34.596: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:06:34.596: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:06:34.596: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:06:34.602: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:06:34.602: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:06:35.608: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:06:35.608: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:06:35.608: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:06:35.612: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 13:06:35.612: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 04/19/23 13:06:35.615
  Apr 19 13:06:35.630: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:06:35.631: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:06:35.631: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:06:35.636: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 13:06:35.636: INFO: Node talos-default-worker-2 is running 0 daemon pod, expected 1
  Apr 19 13:06:36.643: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:06:36.643: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:06:36.643: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:06:36.649: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 13:06:36.649: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 04/19/23 13:06:36.649
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/23 13:06:36.659
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3370, will wait for the garbage collector to delete the pods @ 04/19/23 13:06:36.66
  Apr 19 13:06:36.720: INFO: Deleting DaemonSet.extensions daemon-set took: 5.153501ms
  Apr 19 13:06:36.820: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.324696ms
  Apr 19 13:06:38.324: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:06:38.324: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 19 13:06:38.326: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"183826"},"items":null}

  Apr 19 13:06:38.329: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"183826"},"items":null}

  Apr 19 13:06:38.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3370" for this suite. @ 04/19/23 13:06:38.347
• [3.806 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance]
test/e2e/apps/replica_set.go:154
  STEP: Creating a kubernetes client @ 04/19/23 13:06:38.356
  Apr 19 13:06:38.357: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename replicaset @ 04/19/23 13:06:38.357
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:06:38.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:06:38.37
  W0419 13:06:38.378329      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:06:38.381: INFO: Pod name sample-pod: Found 0 pods out of 1
  Apr 19 13:06:43.389: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/23 13:06:43.389
  STEP: Scaling up "test-rs" replicaset  @ 04/19/23 13:06:43.389
  W0419 13:06:43.403179      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:06:43.403: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 04/19/23 13:06:43.403
  W0419 13:06:43.410484      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  W0419 13:06:43.410541      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "test-rs", "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "test-rs", "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "test-rs", "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "test-rs", "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:06:43.413: INFO: observed ReplicaSet test-rs in namespace replicaset-7819 with ReadyReplicas 1, AvailableReplicas 1
  Apr 19 13:06:43.419: INFO: observed ReplicaSet test-rs in namespace replicaset-7819 with ReadyReplicas 1, AvailableReplicas 1
  Apr 19 13:06:43.426: INFO: observed ReplicaSet test-rs in namespace replicaset-7819 with ReadyReplicas 1, AvailableReplicas 1
  Apr 19 13:06:43.436: INFO: observed ReplicaSet test-rs in namespace replicaset-7819 with ReadyReplicas 1, AvailableReplicas 1
  Apr 19 13:06:44.303: INFO: observed ReplicaSet test-rs in namespace replicaset-7819 with ReadyReplicas 2, AvailableReplicas 2
  Apr 19 13:06:44.460: INFO: observed Replicaset test-rs in namespace replicaset-7819 with ReadyReplicas 3 found true
  Apr 19 13:06:44.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-7819" for this suite. @ 04/19/23 13:06:44.466
• [6.117 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 04/19/23 13:06:44.484
  Apr 19 13:06:44.485: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename containers @ 04/19/23 13:06:44.488
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:06:44.503
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:06:44.505
  STEP: Creating a pod to test override arguments @ 04/19/23 13:06:44.508
  W0419 13:06:44.514617      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:06:46.522
  Apr 19 13:06:46.524: INFO: Trying to get logs from node talos-default-worker-2 pod client-containers-3d70ca5e-454d-4a5e-b7b3-6231fd1f970d container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 13:06:46.532
  Apr 19 13:06:46.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4644" for this suite. @ 04/19/23 13:06:46.561
• [2.084 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:163
  STEP: Creating a kubernetes client @ 04/19/23 13:06:46.568
  Apr 19 13:06:46.568: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:06:46.57
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:06:46.582
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:06:46.585
  STEP: Creating the pod @ 04/19/23 13:06:46.587
  W0419 13:06:46.594506      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:06:49.129: INFO: Successfully updated pod "annotationupdate65b6bb5f-ed71-46ab-8802-6e3a93870dc1"
  Apr 19 13:06:51.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1303" for this suite. @ 04/19/23 13:06:51.15
• [4.590 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
test/e2e/auth/service_accounts.go:529
  STEP: Creating a kubernetes client @ 04/19/23 13:06:51.163
  Apr 19 13:06:51.163: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/23 13:06:51.165
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:06:51.18
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:06:51.185
  W0419 13:06:51.203886      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "oidc-discovery-validator" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "oidc-discovery-validator" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "oidc-discovery-validator" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "oidc-discovery-validator" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:06:51.205: INFO: created pod
  STEP: Saw pod success @ 04/19/23 13:06:55.219
  Apr 19 13:07:25.219: INFO: polling logs
  Apr 19 13:07:25.227: INFO: Pod logs: 
  I0419 13:06:51.835034       1 log.go:198] OK: Got token
  I0419 13:06:51.835210       1 log.go:198] validating with in-cluster discovery
  I0419 13:06:51.835510       1 log.go:198] OK: got issuer https://172.20.0.1:6443
  I0419 13:06:51.835581       1 log.go:198] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://172.20.0.1:6443", Subject:"system:serviceaccount:svcaccounts-4370:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1681910211, NotBefore:1681909611, IssuedAt:1681909611, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4370", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"54e8af26-0b22-4867-bdda-a06d21ceb04b"}}}
  I0419 13:06:51.839425       1 log.go:198] OK: Constructed OIDC provider for issuer https://172.20.0.1:6443
  I0419 13:06:51.842066       1 log.go:198] OK: Validated signature on JWT
  I0419 13:06:51.842164       1 log.go:198] OK: Got valid claims from token!
  I0419 13:06:51.842239       1 log.go:198] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://172.20.0.1:6443", Subject:"system:serviceaccount:svcaccounts-4370:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1681910211, NotBefore:1681909611, IssuedAt:1681909611, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4370", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"54e8af26-0b22-4867-bdda-a06d21ceb04b"}}}

  Apr 19 13:07:25.227: INFO: completed pod
  Apr 19 13:07:25.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-4370" for this suite. @ 04/19/23 13:07:25.239
• [34.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:167
  STEP: Creating a kubernetes client @ 04/19/23 13:07:25.253
  Apr 19 13:07:25.253: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 13:07:25.256
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:07:25.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:07:25.277
  STEP: Creating a pod to test downward api env vars @ 04/19/23 13:07:25.281
  W0419 13:07:25.303924      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:07:29.32
  Apr 19 13:07:29.324: INFO: Trying to get logs from node talos-default-worker-1 pod downward-api-8b88aac2-d446-423c-9ab8-28489841c03e container dapi-container: <nil>
  STEP: delete the pod @ 04/19/23 13:07:29.333
  Apr 19 13:07:29.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9168" for this suite. @ 04/19/23 13:07:29.359
• [4.113 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:218
  STEP: Creating a kubernetes client @ 04/19/23 13:07:29.372
  Apr 19 13:07:29.373: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 13:07:29.374
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:07:29.389
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:07:29.393
  STEP: Creating a pod to test downward api env vars @ 04/19/23 13:07:29.397
  W0419 13:07:29.405990      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:07:33.42
  Apr 19 13:07:33.424: INFO: Trying to get logs from node talos-default-worker-1 pod downward-api-7c85f5d9-a34f-4508-8826-a3355cefc459 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/23 13:07:33.432
  Apr 19 13:07:33.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6793" for this suite. @ 04/19/23 13:07:33.452
• [4.087 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]
test/e2e/apimachinery/garbage_collector.go:817
  STEP: Creating a kubernetes client @ 04/19/23 13:07:33.463
  Apr 19 13:07:33.463: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename gc @ 04/19/23 13:07:33.465
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:07:33.484
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:07:33.488
  W0419 13:07:33.498583      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  W0419 13:07:33.512458      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  W0419 13:07:33.518803      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:07:33.528: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"5fed4985-828c-45bc-9ba6-c69e6a368dcd", Controller:(*bool)(0xc0040bf02a), BlockOwnerDeletion:(*bool)(0xc0040bf02b)}}
  Apr 19 13:07:33.539: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"cd373f62-3763-4709-9beb-3ea5c15a8e8b", Controller:(*bool)(0xc004280642), BlockOwnerDeletion:(*bool)(0xc004280643)}}
  Apr 19 13:07:33.545: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f7b97aa0-19f1-4c9e-a5ac-aef437488886", Controller:(*bool)(0xc0040bf292), BlockOwnerDeletion:(*bool)(0xc0040bf293)}}
  Apr 19 13:07:38.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-7075" for this suite. @ 04/19/23 13:07:38.557
• [5.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:85
  STEP: Creating a kubernetes client @ 04/19/23 13:07:38.568
  Apr 19 13:07:38.568: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:07:38.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:07:38.584
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:07:38.587
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 13:07:38.589
  W0419 13:07:38.594935      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:07:42.609
  Apr 19 13:07:42.613: INFO: Trying to get logs from node talos-default-worker-1 pod downwardapi-volume-78fb281c-39dc-491f-a34b-1b534d16e292 container client-container: <nil>
  STEP: delete the pod @ 04/19/23 13:07:42.619
  Apr 19 13:07:42.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4215" for this suite. @ 04/19/23 13:07:42.641
• [4.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:236
  STEP: Creating a kubernetes client @ 04/19/23 13:07:42.65
  Apr 19 13:07:42.651: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:07:42.653
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:07:42.668
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:07:42.671
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 13:07:42.676
  W0419 13:07:42.684045      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:07:44.7
  Apr 19 13:07:44.704: INFO: Trying to get logs from node talos-default-worker-1 pod downwardapi-volume-8f434f88-65cc-4dc7-9659-4a9ac657f05e container client-container: <nil>
  STEP: delete the pod @ 04/19/23 13:07:44.711
  Apr 19 13:07:44.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6263" for this suite. @ 04/19/23 13:07:44.73
• [2.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:156
  STEP: Creating a kubernetes client @ 04/19/23 13:07:44.745
  Apr 19 13:07:44.745: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/23 13:07:44.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:07:44.763
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:07:44.767
  STEP: Deleting RuntimeClass runtimeclass-9986-delete-me @ 04/19/23 13:07:44.775
  STEP: Waiting for the RuntimeClass to disappear @ 04/19/23 13:07:44.781
  Apr 19 13:07:44.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9986" for this suite. @ 04/19/23 13:07:44.795
• [0.055 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]
test/e2e/apimachinery/resource_quota.go:395
  STEP: Creating a kubernetes client @ 04/19/23 13:07:44.802
  Apr 19 13:07:44.803: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename resourcequota @ 04/19/23 13:07:44.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:07:44.815
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:07:44.818
  STEP: Counting existing ResourceQuota @ 04/19/23 13:07:44.821
  STEP: Creating a ResourceQuota @ 04/19/23 13:07:49.825
  STEP: Ensuring resource quota status is calculated @ 04/19/23 13:07:49.832
  STEP: Creating a ReplicationController @ 04/19/23 13:07:51.837
  W0419 13:07:51.854760      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-rc" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-rc" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-rc" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-rc" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring resource quota status captures replication controller creation @ 04/19/23 13:07:51.854
  STEP: Deleting a ReplicationController @ 04/19/23 13:07:53.861
  STEP: Ensuring resource quota status released usage @ 04/19/23 13:07:53.868
  Apr 19 13:07:55.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-717" for this suite. @ 04/19/23 13:07:55.878
• [11.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]
test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 04/19/23 13:07:55.891
  Apr 19 13:07:55.891: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename sched-preemption @ 04/19/23 13:07:55.893
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:07:55.914
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:07:55.917
  Apr 19 13:07:55.935: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 19 13:08:55.958: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/19/23 13:08:55.962
  Apr 19 13:08:55.990: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Apr 19 13:08:55.998: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Apr 19 13:08:56.017: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Apr 19 13:08:56.023: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/19/23 13:08:56.024
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 04/19/23 13:08:58.039
  Apr 19 13:09:02.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-337" for this suite. @ 04/19/23 13:09:02.145
• [66.263 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]
test/e2e/apimachinery/resource_quota.go:232
  STEP: Creating a kubernetes client @ 04/19/23 13:09:02.157
  Apr 19 13:09:02.157: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename resourcequota @ 04/19/23 13:09:02.158
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:09:02.171
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:09:02.174
  STEP: Counting existing ResourceQuota @ 04/19/23 13:09:02.176
  STEP: Creating a ResourceQuota @ 04/19/23 13:09:07.181
  STEP: Ensuring resource quota status is calculated @ 04/19/23 13:09:07.187
  STEP: Creating a Pod that fits quota @ 04/19/23 13:09:09.192
  W0419 13:09:09.207891      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring ResourceQuota status captures the pod usage @ 04/19/23 13:09:09.208
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 04/19/23 13:09:11.213
  W0419 13:09:11.215615      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 04/19/23 13:09:11.215
  W0419 13:09:11.218085      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring a pod cannot update its resource requirements @ 04/19/23 13:09:11.218
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 04/19/23 13:09:11.223
  STEP: Deleting the pod @ 04/19/23 13:09:13.228
  STEP: Ensuring resource quota status released the pod usage @ 04/19/23 13:09:13.243
  Apr 19 13:09:15.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1546" for this suite. @ 04/19/23 13:09:15.253
• [13.102 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance]
test/e2e/apps/job.go:642
  STEP: Creating a kubernetes client @ 04/19/23 13:09:15.26
  Apr 19 13:09:15.261: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename job @ 04/19/23 13:09:15.262
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:09:15.279
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:09:15.282
  STEP: Creating a job @ 04/19/23 13:09:15.286
  W0419 13:09:15.292996      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensure pods equal to parallelism count is attached to the job @ 04/19/23 13:09:15.293
  STEP: patching /status @ 04/19/23 13:09:17.298
  STEP: updating /status @ 04/19/23 13:09:17.305
  STEP: get /status @ 04/19/23 13:09:17.338
  Apr 19 13:09:17.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8661" for this suite. @ 04/19/23 13:09:17.346
• [2.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
test/e2e/network/endpointslice.go:104
  STEP: Creating a kubernetes client @ 04/19/23 13:09:17.359
  Apr 19 13:09:17.359: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename endpointslice @ 04/19/23 13:09:17.361
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:09:17.382
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:09:17.385
  Apr 19 13:09:19.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-9477" for this suite. @ 04/19/23 13:09:19.453
• [2.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 04/19/23 13:09:19.466
  Apr 19 13:09:19.467: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename dns @ 04/19/23 13:09:19.469
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:09:19.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:09:19.483
  STEP: Creating a test headless service @ 04/19/23 13:09:19.484
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8855 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8855;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8855 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8855;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8855.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8855.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8855.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8855.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8855.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8855.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8855.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8855.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8855.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8855.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8855.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8855.svc;check="$$(dig +notcp +noall +answer +search 90.30.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.30.90_udp@PTR;check="$$(dig +tcp +noall +answer +search 90.30.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.30.90_tcp@PTR;sleep 1; done
   @ 04/19/23 13:09:19.497
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8855 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8855;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8855 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8855;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8855.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8855.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8855.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8855.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8855.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8855.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8855.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8855.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8855.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8855.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8855.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8855.svc;check="$$(dig +notcp +noall +answer +search 90.30.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.30.90_udp@PTR;check="$$(dig +tcp +noall +answer +search 90.30.110.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.110.30.90_tcp@PTR;sleep 1; done
   @ 04/19/23 13:09:19.497
  STEP: creating a pod to probe DNS @ 04/19/23 13:09:19.497
  STEP: submitting the pod to kubernetes @ 04/19/23 13:09:19.497
  W0419 13:09:19.504624      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: retrieving the pod @ 04/19/23 13:09:21.512
  STEP: looking for the results for each expected name from probers @ 04/19/23 13:09:21.516
  Apr 19 13:09:21.520: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.524: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.529: INFO: Unable to read wheezy_udp@dns-test-service.dns-8855 from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.532: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8855 from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.536: INFO: Unable to read wheezy_udp@dns-test-service.dns-8855.svc from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.539: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8855.svc from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.542: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8855.svc from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.549: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8855.svc from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.567: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.571: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.575: INFO: Unable to read jessie_udp@dns-test-service.dns-8855 from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.579: INFO: Unable to read jessie_tcp@dns-test-service.dns-8855 from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.583: INFO: Unable to read jessie_udp@dns-test-service.dns-8855.svc from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.589: INFO: Unable to read jessie_tcp@dns-test-service.dns-8855.svc from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.594: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8855.svc from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.599: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8855.svc from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:21.614: INFO: Lookups using dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8855 wheezy_tcp@dns-test-service.dns-8855 wheezy_udp@dns-test-service.dns-8855.svc wheezy_tcp@dns-test-service.dns-8855.svc wheezy_udp@_http._tcp.dns-test-service.dns-8855.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8855.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8855 jessie_tcp@dns-test-service.dns-8855 jessie_udp@dns-test-service.dns-8855.svc jessie_tcp@dns-test-service.dns-8855.svc jessie_udp@_http._tcp.dns-test-service.dns-8855.svc jessie_tcp@_http._tcp.dns-test-service.dns-8855.svc]

  Apr 19 13:09:26.646: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8855.svc from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:26.650: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8855.svc from pod dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9: the server could not find the requested resource (get pods dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9)
  Apr 19 13:09:26.710: INFO: Lookups using dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-8855.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8855.svc]

  Apr 19 13:09:31.722: INFO: DNS probes using dns-8855/dns-test-e855ff1e-8a68-4dac-8041-eea4a1c4e2d9 succeeded

  Apr 19 13:09:31.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 13:09:31.728
  STEP: deleting the test service @ 04/19/23 13:09:31.752
  STEP: deleting the test headless service @ 04/19/23 13:09:31.775
  STEP: Destroying namespace "dns-8855" for this suite. @ 04/19/23 13:09:31.783
• [12.325 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:370
  STEP: Creating a kubernetes client @ 04/19/23 13:09:31.794
  Apr 19 13:09:31.795: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename namespaces @ 04/19/23 13:09:31.796
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:09:31.809
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:09:31.811
  STEP: Updating Namespace "namespaces-5703" @ 04/19/23 13:09:31.814
  Apr 19 13:09:31.820: INFO: Namespace "namespaces-5703" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"fc9b60c8-115f-42cd-a491-b77852ad0f9a", "kubernetes.io/metadata.name":"namespaces-5703", "namespaces-5703":"updated", "pod-security.kubernetes.io/enforce":"baseline"}
  Apr 19 13:09:31.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-5703" for this suite. @ 04/19/23 13:09:31.826
• [0.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2187
  STEP: Creating a kubernetes client @ 04/19/23 13:09:31.837
  Apr 19 13:09:31.837: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 13:09:31.838
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:09:31.847
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:09:31.857
  STEP: creating service in namespace services-8694 @ 04/19/23 13:09:31.859
  STEP: creating service affinity-clusterip-transition in namespace services-8694 @ 04/19/23 13:09:31.86
  STEP: creating replication controller affinity-clusterip-transition in namespace services-8694 @ 04/19/23 13:09:31.869
  W0419 13:09:31.876039      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-clusterip-transition" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-clusterip-transition" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-clusterip-transition" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-clusterip-transition" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  I0419 13:09:31.877044      20 runners.go:194] Created replication controller with name: affinity-clusterip-transition, namespace: services-8694, replica count: 3
  I0419 13:09:34.928897      20 runners.go:194] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 13:09:34.935: INFO: Creating new exec pod
  W0419 13:09:34.944175      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:09:37.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-8694 exec execpod-affinitymckfb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  Apr 19 13:09:38.169: INFO: stderr: "+ + nc -v -t -w 2 affinity-clusterip-transition 80\necho hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Apr 19 13:09:38.169: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 13:09:38.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-8694 exec execpod-affinitymckfb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.108.87.230 80'
  Apr 19 13:09:38.387: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.108.87.230 80\nConnection to 10.108.87.230 80 port [tcp/http] succeeded!\n"
  Apr 19 13:09:38.387: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 13:09:38.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-8694 exec execpod-affinitymckfb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.108.87.230:80/ ; done'
  Apr 19 13:09:38.702: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n"
  Apr 19 13:09:38.702: INFO: stdout: "\naffinity-clusterip-transition-l2wrb\naffinity-clusterip-transition-p6b8k\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-l2wrb\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-l2wrb\naffinity-clusterip-transition-p6b8k\naffinity-clusterip-transition-l2wrb\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-p6b8k\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-l2wrb\naffinity-clusterip-transition-p6b8k\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-p6b8k\naffinity-clusterip-transition-rtnp5"
  Apr 19 13:09:38.702: INFO: Received response from host: affinity-clusterip-transition-l2wrb
  Apr 19 13:09:38.702: INFO: Received response from host: affinity-clusterip-transition-p6b8k
  Apr 19 13:09:38.702: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:38.702: INFO: Received response from host: affinity-clusterip-transition-l2wrb
  Apr 19 13:09:38.702: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:38.702: INFO: Received response from host: affinity-clusterip-transition-l2wrb
  Apr 19 13:09:38.702: INFO: Received response from host: affinity-clusterip-transition-p6b8k
  Apr 19 13:09:38.703: INFO: Received response from host: affinity-clusterip-transition-l2wrb
  Apr 19 13:09:38.703: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:38.703: INFO: Received response from host: affinity-clusterip-transition-p6b8k
  Apr 19 13:09:38.704: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:38.704: INFO: Received response from host: affinity-clusterip-transition-l2wrb
  Apr 19 13:09:38.704: INFO: Received response from host: affinity-clusterip-transition-p6b8k
  Apr 19 13:09:38.704: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:38.704: INFO: Received response from host: affinity-clusterip-transition-p6b8k
  Apr 19 13:09:38.704: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:38.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-8694 exec execpod-affinitymckfb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.108.87.230:80/ ; done'
  Apr 19 13:09:39.016: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.108.87.230:80/\n"
  Apr 19 13:09:39.016: INFO: stdout: "\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5\naffinity-clusterip-transition-rtnp5"
  Apr 19 13:09:39.016: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.016: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.016: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.016: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.016: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.016: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.016: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.016: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.016: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.016: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.016: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.016: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.016: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.016: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.017: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.017: INFO: Received response from host: affinity-clusterip-transition-rtnp5
  Apr 19 13:09:39.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 19 13:09:39.022: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-8694, will wait for the garbage collector to delete the pods @ 04/19/23 13:09:39.031
  Apr 19 13:09:39.090: INFO: Deleting ReplicationController affinity-clusterip-transition took: 4.824983ms
  Apr 19 13:09:39.190: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.800079ms
  STEP: Destroying namespace "services-8694" for this suite. @ 04/19/23 13:09:40.91
• [9.082 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:240
  STEP: Creating a kubernetes client @ 04/19/23 13:09:40.922
  Apr 19 13:09:40.922: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 13:09:40.925
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:09:40.941
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:09:40.944
  STEP: Creating configMap with name cm-test-opt-del-679c19f0-178d-422c-a684-e19f67ae1532 @ 04/19/23 13:09:40.953
  STEP: Creating configMap with name cm-test-opt-upd-b21b04a8-abff-419c-ba84-b93567dba1e4 @ 04/19/23 13:09:40.958
  STEP: Creating the pod @ 04/19/23 13:09:40.962
  W0419 13:09:40.973224      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Deleting configmap cm-test-opt-del-679c19f0-178d-422c-a684-e19f67ae1532 @ 04/19/23 13:09:43.008
  STEP: Updating configmap cm-test-opt-upd-b21b04a8-abff-419c-ba84-b93567dba1e4 @ 04/19/23 13:09:43.014
  STEP: Creating configMap with name cm-test-opt-create-859f5db2-6ee8-4715-a2d3-c6e63bd30ff6 @ 04/19/23 13:09:43.02
  STEP: waiting to observe update in volume @ 04/19/23 13:09:43.025
  Apr 19 13:09:47.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4654" for this suite. @ 04/19/23 13:09:47.066
• [6.152 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 04/19/23 13:09:47.076
  Apr 19 13:09:47.076: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/23 13:09:47.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:09:47.096
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:09:47.1
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 04/19/23 13:09:47.104
  Apr 19 13:09:47.105: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 04/19/23 13:09:52.679
  Apr 19 13:09:52.679: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:09:54.130: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:10:00.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4986" for this suite. @ 04/19/23 13:10:00.112
• [13.043 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high  [Conformance]
test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 04/19/23 13:10:00.12
  Apr 19 13:10:00.120: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename svc-latency @ 04/19/23 13:10:00.122
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:10:00.136
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:10:00.14
  Apr 19 13:10:00.143: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-5766 @ 04/19/23 13:10:00.145
  W0419 13:10:00.152250      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "svc-latency-rc" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "svc-latency-rc" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "svc-latency-rc" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "svc-latency-rc" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  I0419 13:10:00.152637      20 runners.go:194] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5766, replica count: 1
  I0419 13:10:01.203387      20 runners.go:194] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 13:10:01.322: INFO: Created: latency-svc-r8kzl
  Apr 19 13:10:01.329: INFO: Got endpoints: latency-svc-r8kzl [24.317928ms]
  Apr 19 13:10:01.347: INFO: Created: latency-svc-5c6zh
  Apr 19 13:10:01.351: INFO: Got endpoints: latency-svc-5c6zh [19.140813ms]
  Apr 19 13:10:01.357: INFO: Created: latency-svc-crhmh
  Apr 19 13:10:01.361: INFO: Got endpoints: latency-svc-crhmh [28.502488ms]
  Apr 19 13:10:01.368: INFO: Created: latency-svc-mx2mv
  Apr 19 13:10:01.371: INFO: Got endpoints: latency-svc-mx2mv [39.677209ms]
  Apr 19 13:10:01.379: INFO: Created: latency-svc-qjp2p
  Apr 19 13:10:01.383: INFO: Got endpoints: latency-svc-qjp2p [50.027551ms]
  Apr 19 13:10:01.390: INFO: Created: latency-svc-55r4z
  Apr 19 13:10:01.392: INFO: Got endpoints: latency-svc-55r4z [58.211852ms]
  Apr 19 13:10:01.400: INFO: Created: latency-svc-hmr7k
  Apr 19 13:10:01.403: INFO: Got endpoints: latency-svc-hmr7k [69.302085ms]
  Apr 19 13:10:01.411: INFO: Created: latency-svc-dxsck
  Apr 19 13:10:01.415: INFO: Got endpoints: latency-svc-dxsck [81.784472ms]
  Apr 19 13:10:01.425: INFO: Created: latency-svc-g8bxd
  Apr 19 13:10:01.428: INFO: Got endpoints: latency-svc-g8bxd [94.909073ms]
  Apr 19 13:10:01.439: INFO: Created: latency-svc-4xggl
  Apr 19 13:10:01.442: INFO: Got endpoints: latency-svc-4xggl [108.135818ms]
  Apr 19 13:10:01.454: INFO: Created: latency-svc-fgz5b
  Apr 19 13:10:01.456: INFO: Got endpoints: latency-svc-fgz5b [123.880883ms]
  Apr 19 13:10:01.466: INFO: Created: latency-svc-bt6bm
  Apr 19 13:10:01.469: INFO: Got endpoints: latency-svc-bt6bm [135.892284ms]
  Apr 19 13:10:01.479: INFO: Created: latency-svc-26bcq
  Apr 19 13:10:01.483: INFO: Got endpoints: latency-svc-26bcq [148.935064ms]
  Apr 19 13:10:01.489: INFO: Created: latency-svc-vm2pg
  Apr 19 13:10:01.493: INFO: Got endpoints: latency-svc-vm2pg [160.3418ms]
  Apr 19 13:10:01.500: INFO: Created: latency-svc-brxbj
  Apr 19 13:10:01.505: INFO: Got endpoints: latency-svc-brxbj [171.879262ms]
  Apr 19 13:10:01.515: INFO: Created: latency-svc-gckjn
  Apr 19 13:10:01.519: INFO: Got endpoints: latency-svc-gckjn [185.09225ms]
  Apr 19 13:10:01.527: INFO: Created: latency-svc-7kbbs
  Apr 19 13:10:01.530: INFO: Got endpoints: latency-svc-7kbbs [178.204572ms]
  Apr 19 13:10:01.543: INFO: Created: latency-svc-gjcp5
  Apr 19 13:10:01.548: INFO: Got endpoints: latency-svc-gjcp5 [186.698638ms]
  Apr 19 13:10:01.553: INFO: Created: latency-svc-bgjsr
  Apr 19 13:10:01.557: INFO: Got endpoints: latency-svc-bgjsr [185.494365ms]
  Apr 19 13:10:01.563: INFO: Created: latency-svc-v7vsf
  Apr 19 13:10:01.566: INFO: Got endpoints: latency-svc-v7vsf [183.321233ms]
  Apr 19 13:10:01.572: INFO: Created: latency-svc-msmt8
  Apr 19 13:10:01.576: INFO: Got endpoints: latency-svc-msmt8 [182.934286ms]
  Apr 19 13:10:01.580: INFO: Created: latency-svc-ql6hk
  Apr 19 13:10:01.582: INFO: Got endpoints: latency-svc-ql6hk [179.30564ms]
  Apr 19 13:10:01.587: INFO: Created: latency-svc-5bgr5
  Apr 19 13:10:01.591: INFO: Got endpoints: latency-svc-5bgr5 [176.055045ms]
  Apr 19 13:10:01.594: INFO: Created: latency-svc-jtqqf
  Apr 19 13:10:01.597: INFO: Got endpoints: latency-svc-jtqqf [168.85965ms]
  Apr 19 13:10:01.603: INFO: Created: latency-svc-289sd
  Apr 19 13:10:01.611: INFO: Got endpoints: latency-svc-289sd [168.868136ms]
  Apr 19 13:10:01.624: INFO: Created: latency-svc-q6cbg
  Apr 19 13:10:01.628: INFO: Got endpoints: latency-svc-q6cbg [171.3565ms]
  Apr 19 13:10:01.634: INFO: Created: latency-svc-djq77
  Apr 19 13:10:01.639: INFO: Got endpoints: latency-svc-djq77 [170.389303ms]
  Apr 19 13:10:01.656: INFO: Created: latency-svc-q62cg
  Apr 19 13:10:01.657: INFO: Got endpoints: latency-svc-q62cg [174.265816ms]
  Apr 19 13:10:01.667: INFO: Created: latency-svc-qfrtm
  Apr 19 13:10:01.671: INFO: Got endpoints: latency-svc-qfrtm [178.322836ms]
  Apr 19 13:10:01.674: INFO: Created: latency-svc-ztrh6
  Apr 19 13:10:01.679: INFO: Got endpoints: latency-svc-ztrh6 [173.303708ms]
  Apr 19 13:10:01.682: INFO: Created: latency-svc-96xzk
  Apr 19 13:10:01.685: INFO: Got endpoints: latency-svc-96xzk [166.551345ms]
  Apr 19 13:10:01.690: INFO: Created: latency-svc-29bzj
  Apr 19 13:10:01.694: INFO: Got endpoints: latency-svc-29bzj [163.790158ms]
  Apr 19 13:10:01.697: INFO: Created: latency-svc-n7jh4
  Apr 19 13:10:01.700: INFO: Got endpoints: latency-svc-n7jh4 [152.618843ms]
  Apr 19 13:10:01.705: INFO: Created: latency-svc-v2ffn
  Apr 19 13:10:01.711: INFO: Got endpoints: latency-svc-v2ffn [154.067436ms]
  Apr 19 13:10:01.713: INFO: Created: latency-svc-bzxwh
  Apr 19 13:10:01.719: INFO: Got endpoints: latency-svc-bzxwh [153.221236ms]
  Apr 19 13:10:01.723: INFO: Created: latency-svc-7dntn
  Apr 19 13:10:01.727: INFO: Got endpoints: latency-svc-7dntn [150.147392ms]
  Apr 19 13:10:01.731: INFO: Created: latency-svc-rxwl2
  Apr 19 13:10:01.734: INFO: Got endpoints: latency-svc-rxwl2 [151.95627ms]
  Apr 19 13:10:01.845: INFO: Created: latency-svc-g2drt
  Apr 19 13:10:01.848: INFO: Created: latency-svc-zmxhs
  Apr 19 13:10:01.848: INFO: Created: latency-svc-msm62
  Apr 19 13:10:01.848: INFO: Created: latency-svc-krndh
  Apr 19 13:10:01.848: INFO: Created: latency-svc-vzbct
  Apr 19 13:10:01.848: INFO: Created: latency-svc-9pf75
  Apr 19 13:10:01.848: INFO: Created: latency-svc-5kr56
  Apr 19 13:10:01.848: INFO: Created: latency-svc-9qcg7
  Apr 19 13:10:01.848: INFO: Created: latency-svc-6l47c
  Apr 19 13:10:01.849: INFO: Created: latency-svc-hldv5
  Apr 19 13:10:01.849: INFO: Created: latency-svc-9jzwq
  Apr 19 13:10:01.849: INFO: Created: latency-svc-2cj8h
  Apr 19 13:10:01.849: INFO: Created: latency-svc-cnmps
  Apr 19 13:10:01.849: INFO: Created: latency-svc-dr2jh
  Apr 19 13:10:01.849: INFO: Created: latency-svc-pn9t5
  Apr 19 13:10:01.850: INFO: Got endpoints: latency-svc-zmxhs [171.764156ms]
  Apr 19 13:10:01.851: INFO: Got endpoints: latency-svc-msm62 [239.436639ms]
  Apr 19 13:10:01.851: INFO: Got endpoints: latency-svc-g2drt [115.847344ms]
  Apr 19 13:10:01.864: INFO: Created: latency-svc-xbkj2
  Apr 19 13:10:01.872: INFO: Created: latency-svc-vsfnq
  Apr 19 13:10:01.875: INFO: Got endpoints: latency-svc-krndh [148.547006ms]
  Apr 19 13:10:01.882: INFO: Created: latency-svc-mqf24
  Apr 19 13:10:01.890: INFO: Created: latency-svc-h2qkh
  Apr 19 13:10:01.926: INFO: Got endpoints: latency-svc-vzbct [298.404572ms]
  Apr 19 13:10:01.940: INFO: Created: latency-svc-7gc4h
  Apr 19 13:10:01.974: INFO: Got endpoints: latency-svc-6l47c [280.140736ms]
  Apr 19 13:10:01.988: INFO: Created: latency-svc-gnlgb
  Apr 19 13:10:02.026: INFO: Got endpoints: latency-svc-9pf75 [434.362802ms]
  Apr 19 13:10:02.040: INFO: Created: latency-svc-8k6cx
  Apr 19 13:10:02.075: INFO: Got endpoints: latency-svc-5kr56 [435.75074ms]
  Apr 19 13:10:02.091: INFO: Created: latency-svc-56d84
  Apr 19 13:10:02.126: INFO: Got endpoints: latency-svc-9qcg7 [468.306801ms]
  Apr 19 13:10:02.141: INFO: Created: latency-svc-hhrs5
  Apr 19 13:10:02.176: INFO: Got endpoints: latency-svc-dr2jh [456.404706ms]
  Apr 19 13:10:02.191: INFO: Created: latency-svc-flls9
  Apr 19 13:10:02.227: INFO: Got endpoints: latency-svc-2cj8h [629.191942ms]
  Apr 19 13:10:02.247: INFO: Created: latency-svc-gv7wv
  Apr 19 13:10:02.276: INFO: Got endpoints: latency-svc-pn9t5 [604.634394ms]
  Apr 19 13:10:02.290: INFO: Created: latency-svc-ztt2w
  Apr 19 13:10:02.326: INFO: Got endpoints: latency-svc-cnmps [625.246402ms]
  Apr 19 13:10:02.346: INFO: Created: latency-svc-5tk2k
  Apr 19 13:10:02.375: INFO: Got endpoints: latency-svc-9jzwq [663.949911ms]
  Apr 19 13:10:02.389: INFO: Created: latency-svc-f2lgb
  Apr 19 13:10:02.425: INFO: Got endpoints: latency-svc-hldv5 [739.327008ms]
  Apr 19 13:10:02.439: INFO: Created: latency-svc-5j94x
  Apr 19 13:10:02.476: INFO: Got endpoints: latency-svc-xbkj2 [625.338042ms]
  Apr 19 13:10:02.494: INFO: Created: latency-svc-qpnq8
  Apr 19 13:10:02.526: INFO: Got endpoints: latency-svc-vsfnq [675.304949ms]
  Apr 19 13:10:02.543: INFO: Created: latency-svc-fwwmj
  Apr 19 13:10:02.575: INFO: Got endpoints: latency-svc-mqf24 [724.607517ms]
  Apr 19 13:10:02.588: INFO: Created: latency-svc-cv4gb
  Apr 19 13:10:02.625: INFO: Got endpoints: latency-svc-h2qkh [749.242131ms]
  Apr 19 13:10:02.635: INFO: Created: latency-svc-vvmkt
  Apr 19 13:10:02.675: INFO: Got endpoints: latency-svc-7gc4h [748.5491ms]
  Apr 19 13:10:02.689: INFO: Created: latency-svc-2tdl9
  Apr 19 13:10:02.725: INFO: Got endpoints: latency-svc-gnlgb [750.401358ms]
  Apr 19 13:10:02.740: INFO: Created: latency-svc-7b6xp
  Apr 19 13:10:02.776: INFO: Got endpoints: latency-svc-8k6cx [749.653963ms]
  Apr 19 13:10:02.792: INFO: Created: latency-svc-44csc
  Apr 19 13:10:02.825: INFO: Got endpoints: latency-svc-56d84 [749.682798ms]
  Apr 19 13:10:02.841: INFO: Created: latency-svc-26g98
  Apr 19 13:10:02.875: INFO: Got endpoints: latency-svc-hhrs5 [749.392022ms]
  Apr 19 13:10:02.891: INFO: Created: latency-svc-4wmc2
  Apr 19 13:10:02.926: INFO: Got endpoints: latency-svc-flls9 [749.4714ms]
  Apr 19 13:10:02.942: INFO: Created: latency-svc-kb6x9
  Apr 19 13:10:02.976: INFO: Got endpoints: latency-svc-gv7wv [749.028199ms]
  Apr 19 13:10:02.997: INFO: Created: latency-svc-rgxlk
  Apr 19 13:10:03.026: INFO: Got endpoints: latency-svc-ztt2w [749.643744ms]
  Apr 19 13:10:03.046: INFO: Created: latency-svc-smbc2
  Apr 19 13:10:03.076: INFO: Got endpoints: latency-svc-5tk2k [750.197975ms]
  Apr 19 13:10:03.091: INFO: Created: latency-svc-fk2s4
  Apr 19 13:10:03.126: INFO: Got endpoints: latency-svc-f2lgb [750.060967ms]
  Apr 19 13:10:03.140: INFO: Created: latency-svc-hs946
  Apr 19 13:10:03.176: INFO: Got endpoints: latency-svc-5j94x [751.26061ms]
  Apr 19 13:10:03.190: INFO: Created: latency-svc-tqtfj
  Apr 19 13:10:03.227: INFO: Got endpoints: latency-svc-qpnq8 [749.456252ms]
  Apr 19 13:10:03.243: INFO: Created: latency-svc-ht56p
  Apr 19 13:10:03.276: INFO: Got endpoints: latency-svc-fwwmj [749.571618ms]
  Apr 19 13:10:03.293: INFO: Created: latency-svc-zcpx2
  Apr 19 13:10:03.326: INFO: Got endpoints: latency-svc-cv4gb [750.773555ms]
  Apr 19 13:10:03.345: INFO: Created: latency-svc-sr7z8
  Apr 19 13:10:03.376: INFO: Got endpoints: latency-svc-vvmkt [750.802861ms]
  Apr 19 13:10:03.388: INFO: Created: latency-svc-xw2sh
  Apr 19 13:10:03.424: INFO: Got endpoints: latency-svc-2tdl9 [748.616863ms]
  Apr 19 13:10:03.438: INFO: Created: latency-svc-cpcsj
  Apr 19 13:10:03.476: INFO: Got endpoints: latency-svc-7b6xp [750.851482ms]
  Apr 19 13:10:03.488: INFO: Created: latency-svc-nhk5t
  Apr 19 13:10:03.525: INFO: Got endpoints: latency-svc-44csc [749.121793ms]
  Apr 19 13:10:03.541: INFO: Created: latency-svc-6mstr
  Apr 19 13:10:03.576: INFO: Got endpoints: latency-svc-26g98 [750.389634ms]
  Apr 19 13:10:03.592: INFO: Created: latency-svc-fl895
  Apr 19 13:10:03.625: INFO: Got endpoints: latency-svc-4wmc2 [749.973293ms]
  Apr 19 13:10:03.643: INFO: Created: latency-svc-8gr5j
  Apr 19 13:10:03.677: INFO: Got endpoints: latency-svc-kb6x9 [751.327077ms]
  Apr 19 13:10:03.693: INFO: Created: latency-svc-hth76
  Apr 19 13:10:03.727: INFO: Got endpoints: latency-svc-rgxlk [751.025369ms]
  Apr 19 13:10:03.747: INFO: Created: latency-svc-c278z
  Apr 19 13:10:03.776: INFO: Got endpoints: latency-svc-smbc2 [750.437385ms]
  Apr 19 13:10:03.789: INFO: Created: latency-svc-9672m
  Apr 19 13:10:03.825: INFO: Got endpoints: latency-svc-fk2s4 [748.573185ms]
  Apr 19 13:10:03.839: INFO: Created: latency-svc-lzw86
  Apr 19 13:10:03.875: INFO: Got endpoints: latency-svc-hs946 [748.373992ms]
  Apr 19 13:10:03.887: INFO: Created: latency-svc-dszpn
  Apr 19 13:10:03.925: INFO: Got endpoints: latency-svc-tqtfj [749.095476ms]
  Apr 19 13:10:03.939: INFO: Created: latency-svc-6sqmg
  Apr 19 13:10:03.975: INFO: Got endpoints: latency-svc-ht56p [748.676418ms]
  Apr 19 13:10:03.991: INFO: Created: latency-svc-nkl56
  Apr 19 13:10:04.027: INFO: Got endpoints: latency-svc-zcpx2 [751.260795ms]
  Apr 19 13:10:04.045: INFO: Created: latency-svc-smn6g
  Apr 19 13:10:04.076: INFO: Got endpoints: latency-svc-sr7z8 [749.939793ms]
  Apr 19 13:10:04.096: INFO: Created: latency-svc-pmtrv
  Apr 19 13:10:04.127: INFO: Got endpoints: latency-svc-xw2sh [751.008809ms]
  Apr 19 13:10:04.143: INFO: Created: latency-svc-9vtqs
  Apr 19 13:10:04.175: INFO: Got endpoints: latency-svc-cpcsj [751.399535ms]
  Apr 19 13:10:04.196: INFO: Created: latency-svc-qdprq
  Apr 19 13:10:04.227: INFO: Got endpoints: latency-svc-nhk5t [750.278688ms]
  Apr 19 13:10:04.249: INFO: Created: latency-svc-ff9rx
  Apr 19 13:10:04.277: INFO: Got endpoints: latency-svc-6mstr [751.550218ms]
  Apr 19 13:10:04.291: INFO: Created: latency-svc-8v7p4
  Apr 19 13:10:04.326: INFO: Got endpoints: latency-svc-fl895 [750.086898ms]
  Apr 19 13:10:04.341: INFO: Created: latency-svc-4fdnn
  Apr 19 13:10:04.375: INFO: Got endpoints: latency-svc-8gr5j [749.166689ms]
  Apr 19 13:10:04.385: INFO: Created: latency-svc-cbf95
  Apr 19 13:10:04.425: INFO: Got endpoints: latency-svc-hth76 [748.397284ms]
  Apr 19 13:10:04.436: INFO: Created: latency-svc-xmgqv
  Apr 19 13:10:04.476: INFO: Got endpoints: latency-svc-c278z [747.923763ms]
  Apr 19 13:10:04.488: INFO: Created: latency-svc-qlw84
  Apr 19 13:10:04.525: INFO: Got endpoints: latency-svc-9672m [748.640891ms]
  Apr 19 13:10:04.538: INFO: Created: latency-svc-m7slk
  Apr 19 13:10:04.575: INFO: Got endpoints: latency-svc-lzw86 [750.110121ms]
  Apr 19 13:10:04.586: INFO: Created: latency-svc-rr98n
  Apr 19 13:10:04.626: INFO: Got endpoints: latency-svc-dszpn [750.46713ms]
  Apr 19 13:10:04.638: INFO: Created: latency-svc-p2swh
  Apr 19 13:10:04.676: INFO: Got endpoints: latency-svc-6sqmg [750.24774ms]
  Apr 19 13:10:04.689: INFO: Created: latency-svc-pc7js
  Apr 19 13:10:04.725: INFO: Got endpoints: latency-svc-nkl56 [749.880489ms]
  Apr 19 13:10:04.740: INFO: Created: latency-svc-rh7xc
  Apr 19 13:10:04.776: INFO: Got endpoints: latency-svc-smn6g [748.433601ms]
  Apr 19 13:10:04.791: INFO: Created: latency-svc-5c5zn
  Apr 19 13:10:04.827: INFO: Got endpoints: latency-svc-pmtrv [749.100845ms]
  Apr 19 13:10:04.840: INFO: Created: latency-svc-c76tm
  Apr 19 13:10:04.876: INFO: Got endpoints: latency-svc-9vtqs [749.224106ms]
  Apr 19 13:10:04.890: INFO: Created: latency-svc-qjr8z
  Apr 19 13:10:04.926: INFO: Got endpoints: latency-svc-qdprq [749.677468ms]
  Apr 19 13:10:04.938: INFO: Created: latency-svc-p5gjx
  Apr 19 13:10:04.975: INFO: Got endpoints: latency-svc-ff9rx [746.391095ms]
  Apr 19 13:10:04.985: INFO: Created: latency-svc-6tncr
  Apr 19 13:10:05.026: INFO: Got endpoints: latency-svc-8v7p4 [748.303537ms]
  Apr 19 13:10:05.036: INFO: Created: latency-svc-pffjc
  Apr 19 13:10:05.076: INFO: Got endpoints: latency-svc-4fdnn [749.564487ms]
  Apr 19 13:10:05.088: INFO: Created: latency-svc-v9rj5
  Apr 19 13:10:05.125: INFO: Got endpoints: latency-svc-cbf95 [749.459058ms]
  Apr 19 13:10:05.138: INFO: Created: latency-svc-kl2fm
  Apr 19 13:10:05.175: INFO: Got endpoints: latency-svc-xmgqv [749.259905ms]
  Apr 19 13:10:05.188: INFO: Created: latency-svc-h9nw8
  Apr 19 13:10:05.225: INFO: Got endpoints: latency-svc-qlw84 [748.977705ms]
  Apr 19 13:10:05.238: INFO: Created: latency-svc-vk5tc
  Apr 19 13:10:05.275: INFO: Got endpoints: latency-svc-m7slk [748.856076ms]
  Apr 19 13:10:05.286: INFO: Created: latency-svc-pqbgw
  Apr 19 13:10:05.326: INFO: Got endpoints: latency-svc-rr98n [750.363889ms]
  Apr 19 13:10:05.340: INFO: Created: latency-svc-q2znl
  Apr 19 13:10:05.375: INFO: Got endpoints: latency-svc-p2swh [748.673965ms]
  Apr 19 13:10:05.385: INFO: Created: latency-svc-z6lss
  Apr 19 13:10:05.425: INFO: Got endpoints: latency-svc-pc7js [749.680755ms]
  Apr 19 13:10:05.435: INFO: Created: latency-svc-bjbfl
  Apr 19 13:10:05.475: INFO: Got endpoints: latency-svc-rh7xc [750.000638ms]
  Apr 19 13:10:05.487: INFO: Created: latency-svc-wqg7z
  Apr 19 13:10:05.526: INFO: Got endpoints: latency-svc-5c5zn [749.980368ms]
  Apr 19 13:10:05.538: INFO: Created: latency-svc-cxlh8
  Apr 19 13:10:05.577: INFO: Got endpoints: latency-svc-c76tm [749.538959ms]
  Apr 19 13:10:05.590: INFO: Created: latency-svc-5zctg
  Apr 19 13:10:05.626: INFO: Got endpoints: latency-svc-qjr8z [749.061442ms]
  Apr 19 13:10:05.639: INFO: Created: latency-svc-rrnwn
  Apr 19 13:10:05.676: INFO: Got endpoints: latency-svc-p5gjx [750.219537ms]
  Apr 19 13:10:05.693: INFO: Created: latency-svc-729xr
  Apr 19 13:10:05.727: INFO: Got endpoints: latency-svc-6tncr [751.789407ms]
  Apr 19 13:10:05.741: INFO: Created: latency-svc-klzcw
  Apr 19 13:10:05.776: INFO: Got endpoints: latency-svc-pffjc [750.13526ms]
  Apr 19 13:10:05.790: INFO: Created: latency-svc-zg7q5
  Apr 19 13:10:05.827: INFO: Got endpoints: latency-svc-v9rj5 [750.915564ms]
  Apr 19 13:10:05.842: INFO: Created: latency-svc-wfwvv
  Apr 19 13:10:05.877: INFO: Got endpoints: latency-svc-kl2fm [751.817118ms]
  Apr 19 13:10:05.891: INFO: Created: latency-svc-h5knc
  Apr 19 13:10:05.928: INFO: Got endpoints: latency-svc-h9nw8 [752.395625ms]
  Apr 19 13:10:05.943: INFO: Created: latency-svc-l6xwp
  Apr 19 13:10:05.977: INFO: Got endpoints: latency-svc-vk5tc [751.92962ms]
  Apr 19 13:10:05.992: INFO: Created: latency-svc-g65df
  Apr 19 13:10:06.027: INFO: Got endpoints: latency-svc-pqbgw [752.359598ms]
  Apr 19 13:10:06.044: INFO: Created: latency-svc-wvh44
  Apr 19 13:10:06.077: INFO: Got endpoints: latency-svc-q2znl [751.513076ms]
  Apr 19 13:10:06.092: INFO: Created: latency-svc-dhg5w
  Apr 19 13:10:06.127: INFO: Got endpoints: latency-svc-z6lss [752.322947ms]
  Apr 19 13:10:06.143: INFO: Created: latency-svc-vq9sw
  Apr 19 13:10:06.177: INFO: Got endpoints: latency-svc-bjbfl [751.819292ms]
  Apr 19 13:10:06.192: INFO: Created: latency-svc-dr9c4
  Apr 19 13:10:06.226: INFO: Got endpoints: latency-svc-wqg7z [750.86008ms]
  Apr 19 13:10:06.240: INFO: Created: latency-svc-d789b
  Apr 19 13:10:06.277: INFO: Got endpoints: latency-svc-cxlh8 [750.363157ms]
  Apr 19 13:10:06.291: INFO: Created: latency-svc-wgx4p
  Apr 19 13:10:06.326: INFO: Got endpoints: latency-svc-5zctg [749.1937ms]
  Apr 19 13:10:06.347: INFO: Created: latency-svc-xlbbw
  Apr 19 13:10:06.377: INFO: Got endpoints: latency-svc-rrnwn [750.801199ms]
  Apr 19 13:10:06.389: INFO: Created: latency-svc-ffdkc
  Apr 19 13:10:06.425: INFO: Got endpoints: latency-svc-729xr [747.316464ms]
  Apr 19 13:10:06.437: INFO: Created: latency-svc-49zsg
  Apr 19 13:10:06.476: INFO: Got endpoints: latency-svc-klzcw [748.960882ms]
  Apr 19 13:10:06.488: INFO: Created: latency-svc-swvmk
  Apr 19 13:10:06.526: INFO: Got endpoints: latency-svc-zg7q5 [749.890758ms]
  Apr 19 13:10:06.538: INFO: Created: latency-svc-tlr5c
  Apr 19 13:10:06.577: INFO: Got endpoints: latency-svc-wfwvv [749.735477ms]
  Apr 19 13:10:06.590: INFO: Created: latency-svc-l4ttf
  Apr 19 13:10:06.625: INFO: Got endpoints: latency-svc-h5knc [747.781495ms]
  Apr 19 13:10:06.638: INFO: Created: latency-svc-5v2wl
  Apr 19 13:10:06.676: INFO: Got endpoints: latency-svc-l6xwp [746.996561ms]
  Apr 19 13:10:06.690: INFO: Created: latency-svc-9qzkk
  Apr 19 13:10:06.727: INFO: Got endpoints: latency-svc-g65df [750.016463ms]
  Apr 19 13:10:06.741: INFO: Created: latency-svc-h7pdr
  Apr 19 13:10:06.777: INFO: Got endpoints: latency-svc-wvh44 [749.083031ms]
  Apr 19 13:10:06.793: INFO: Created: latency-svc-qfgqr
  Apr 19 13:10:06.826: INFO: Got endpoints: latency-svc-dhg5w [747.494177ms]
  Apr 19 13:10:06.841: INFO: Created: latency-svc-4pxvp
  Apr 19 13:10:06.876: INFO: Got endpoints: latency-svc-vq9sw [748.822901ms]
  Apr 19 13:10:06.888: INFO: Created: latency-svc-lhwf9
  Apr 19 13:10:06.926: INFO: Got endpoints: latency-svc-dr9c4 [748.427369ms]
  Apr 19 13:10:06.938: INFO: Created: latency-svc-k7c4s
  Apr 19 13:10:06.975: INFO: Got endpoints: latency-svc-d789b [748.466923ms]
  Apr 19 13:10:06.988: INFO: Created: latency-svc-x69cw
  Apr 19 13:10:07.025: INFO: Got endpoints: latency-svc-wgx4p [748.410868ms]
  Apr 19 13:10:07.043: INFO: Created: latency-svc-tjvjf
  Apr 19 13:10:07.076: INFO: Got endpoints: latency-svc-xlbbw [747.695505ms]
  Apr 19 13:10:07.091: INFO: Created: latency-svc-fq96f
  Apr 19 13:10:07.126: INFO: Got endpoints: latency-svc-ffdkc [748.579485ms]
  Apr 19 13:10:07.147: INFO: Created: latency-svc-wtrgc
  Apr 19 13:10:07.177: INFO: Got endpoints: latency-svc-49zsg [751.195819ms]
  Apr 19 13:10:07.198: INFO: Created: latency-svc-cmbxz
  Apr 19 13:10:07.227: INFO: Got endpoints: latency-svc-swvmk [751.145645ms]
  Apr 19 13:10:07.247: INFO: Created: latency-svc-6zvk8
  Apr 19 13:10:07.275: INFO: Got endpoints: latency-svc-tlr5c [749.722301ms]
  Apr 19 13:10:07.291: INFO: Created: latency-svc-g2pxv
  Apr 19 13:10:07.326: INFO: Got endpoints: latency-svc-l4ttf [748.237804ms]
  Apr 19 13:10:07.344: INFO: Created: latency-svc-67bdz
  Apr 19 13:10:07.376: INFO: Got endpoints: latency-svc-5v2wl [750.288155ms]
  Apr 19 13:10:07.390: INFO: Created: latency-svc-x6gm4
  Apr 19 13:10:07.425: INFO: Got endpoints: latency-svc-9qzkk [749.298617ms]
  Apr 19 13:10:07.439: INFO: Created: latency-svc-c5xst
  Apr 19 13:10:07.476: INFO: Got endpoints: latency-svc-h7pdr [747.558228ms]
  Apr 19 13:10:07.488: INFO: Created: latency-svc-pxjbq
  Apr 19 13:10:07.526: INFO: Got endpoints: latency-svc-qfgqr [748.880694ms]
  Apr 19 13:10:07.542: INFO: Created: latency-svc-j59wk
  Apr 19 13:10:07.577: INFO: Got endpoints: latency-svc-4pxvp [749.120023ms]
  Apr 19 13:10:07.595: INFO: Created: latency-svc-mvwk8
  Apr 19 13:10:07.627: INFO: Got endpoints: latency-svc-lhwf9 [751.32762ms]
  Apr 19 13:10:07.646: INFO: Created: latency-svc-s5ccx
  Apr 19 13:10:07.676: INFO: Got endpoints: latency-svc-k7c4s [749.501609ms]
  Apr 19 13:10:07.705: INFO: Created: latency-svc-6xpk5
  Apr 19 13:10:07.726: INFO: Got endpoints: latency-svc-x69cw [750.687887ms]
  Apr 19 13:10:07.742: INFO: Created: latency-svc-2j55c
  Apr 19 13:10:07.776: INFO: Got endpoints: latency-svc-tjvjf [749.910157ms]
  Apr 19 13:10:07.790: INFO: Created: latency-svc-jn2nf
  Apr 19 13:10:07.825: INFO: Got endpoints: latency-svc-fq96f [748.793708ms]
  Apr 19 13:10:07.838: INFO: Created: latency-svc-btbdm
  Apr 19 13:10:07.875: INFO: Got endpoints: latency-svc-wtrgc [747.059621ms]
  Apr 19 13:10:07.887: INFO: Created: latency-svc-r7dpb
  Apr 19 13:10:07.926: INFO: Got endpoints: latency-svc-cmbxz [746.742987ms]
  Apr 19 13:10:07.939: INFO: Created: latency-svc-7cwzw
  Apr 19 13:10:07.977: INFO: Got endpoints: latency-svc-6zvk8 [748.945604ms]
  Apr 19 13:10:07.992: INFO: Created: latency-svc-vd258
  Apr 19 13:10:08.026: INFO: Got endpoints: latency-svc-g2pxv [749.759141ms]
  Apr 19 13:10:08.042: INFO: Created: latency-svc-gdckc
  Apr 19 13:10:08.076: INFO: Got endpoints: latency-svc-67bdz [750.005663ms]
  Apr 19 13:10:08.092: INFO: Created: latency-svc-rngw7
  Apr 19 13:10:08.126: INFO: Got endpoints: latency-svc-x6gm4 [750.199278ms]
  Apr 19 13:10:08.141: INFO: Created: latency-svc-krqj4
  Apr 19 13:10:08.176: INFO: Got endpoints: latency-svc-c5xst [750.266823ms]
  Apr 19 13:10:08.193: INFO: Created: latency-svc-4flhk
  Apr 19 13:10:08.226: INFO: Got endpoints: latency-svc-pxjbq [750.762774ms]
  Apr 19 13:10:08.241: INFO: Created: latency-svc-tp4jz
  Apr 19 13:10:08.276: INFO: Got endpoints: latency-svc-j59wk [749.365811ms]
  Apr 19 13:10:08.291: INFO: Created: latency-svc-pxgmk
  Apr 19 13:10:08.326: INFO: Got endpoints: latency-svc-mvwk8 [749.430101ms]
  Apr 19 13:10:08.350: INFO: Created: latency-svc-ddm8z
  Apr 19 13:10:08.377: INFO: Got endpoints: latency-svc-s5ccx [749.25382ms]
  Apr 19 13:10:08.388: INFO: Created: latency-svc-g6gpn
  Apr 19 13:10:08.425: INFO: Got endpoints: latency-svc-6xpk5 [748.924151ms]
  Apr 19 13:10:08.439: INFO: Created: latency-svc-m4tkf
  Apr 19 13:10:08.475: INFO: Got endpoints: latency-svc-2j55c [748.135039ms]
  Apr 19 13:10:08.492: INFO: Created: latency-svc-2ml7g
  Apr 19 13:10:08.525: INFO: Got endpoints: latency-svc-jn2nf [748.969357ms]
  Apr 19 13:10:08.536: INFO: Created: latency-svc-hnkwt
  Apr 19 13:10:08.576: INFO: Got endpoints: latency-svc-btbdm [750.527153ms]
  Apr 19 13:10:08.589: INFO: Created: latency-svc-ff4zn
  Apr 19 13:10:08.625: INFO: Got endpoints: latency-svc-r7dpb [750.065154ms]
  Apr 19 13:10:08.637: INFO: Created: latency-svc-z6p9j
  Apr 19 13:10:08.676: INFO: Got endpoints: latency-svc-7cwzw [749.905686ms]
  Apr 19 13:10:08.691: INFO: Created: latency-svc-vgw7w
  Apr 19 13:10:08.727: INFO: Got endpoints: latency-svc-vd258 [749.759712ms]
  Apr 19 13:10:08.743: INFO: Created: latency-svc-jv5wc
  Apr 19 13:10:08.776: INFO: Got endpoints: latency-svc-gdckc [749.139057ms]
  Apr 19 13:10:08.795: INFO: Created: latency-svc-9jdzs
  Apr 19 13:10:08.828: INFO: Got endpoints: latency-svc-rngw7 [751.051159ms]
  Apr 19 13:10:08.841: INFO: Created: latency-svc-69fm8
  Apr 19 13:10:08.877: INFO: Got endpoints: latency-svc-krqj4 [750.597056ms]
  Apr 19 13:10:08.887: INFO: Created: latency-svc-n59tq
  Apr 19 13:10:08.926: INFO: Got endpoints: latency-svc-4flhk [749.574655ms]
  Apr 19 13:10:08.938: INFO: Created: latency-svc-xbzcr
  Apr 19 13:10:08.977: INFO: Got endpoints: latency-svc-tp4jz [750.793666ms]
  Apr 19 13:10:08.993: INFO: Created: latency-svc-hfz4m
  Apr 19 13:10:09.026: INFO: Got endpoints: latency-svc-pxgmk [749.065329ms]
  Apr 19 13:10:09.040: INFO: Created: latency-svc-28l52
  Apr 19 13:10:09.076: INFO: Got endpoints: latency-svc-ddm8z [747.735671ms]
  Apr 19 13:10:09.086: INFO: Created: latency-svc-9jhwl
  Apr 19 13:10:09.125: INFO: Got endpoints: latency-svc-g6gpn [747.867539ms]
  Apr 19 13:10:09.135: INFO: Created: latency-svc-wrp4j
  Apr 19 13:10:09.176: INFO: Got endpoints: latency-svc-m4tkf [750.214147ms]
  Apr 19 13:10:09.225: INFO: Got endpoints: latency-svc-2ml7g [750.680193ms]
  Apr 19 13:10:09.276: INFO: Got endpoints: latency-svc-hnkwt [750.963112ms]
  Apr 19 13:10:09.325: INFO: Got endpoints: latency-svc-ff4zn [749.515504ms]
  Apr 19 13:10:09.376: INFO: Got endpoints: latency-svc-z6p9j [750.671956ms]
  Apr 19 13:10:09.425: INFO: Got endpoints: latency-svc-vgw7w [748.080127ms]
  Apr 19 13:10:09.476: INFO: Got endpoints: latency-svc-jv5wc [748.083915ms]
  Apr 19 13:10:09.525: INFO: Got endpoints: latency-svc-9jdzs [748.62407ms]
  Apr 19 13:10:09.576: INFO: Got endpoints: latency-svc-69fm8 [748.344033ms]
  Apr 19 13:10:09.627: INFO: Got endpoints: latency-svc-n59tq [749.736368ms]
  Apr 19 13:10:09.677: INFO: Got endpoints: latency-svc-xbzcr [750.702442ms]
  Apr 19 13:10:09.726: INFO: Got endpoints: latency-svc-hfz4m [747.676367ms]
  Apr 19 13:10:09.776: INFO: Got endpoints: latency-svc-28l52 [750.693744ms]
  Apr 19 13:10:09.826: INFO: Got endpoints: latency-svc-9jhwl [750.255282ms]
  Apr 19 13:10:09.878: INFO: Got endpoints: latency-svc-wrp4j [752.337923ms]
  Apr 19 13:10:09.878: INFO: Latencies: [19.140813ms 28.502488ms 39.677209ms 50.027551ms 58.211852ms 69.302085ms 81.784472ms 94.909073ms 108.135818ms 115.847344ms 123.880883ms 135.892284ms 148.547006ms 148.935064ms 150.147392ms 151.95627ms 152.618843ms 153.221236ms 154.067436ms 160.3418ms 163.790158ms 166.551345ms 168.85965ms 168.868136ms 170.389303ms 171.3565ms 171.764156ms 171.879262ms 173.303708ms 174.265816ms 176.055045ms 178.204572ms 178.322836ms 179.30564ms 182.934286ms 183.321233ms 185.09225ms 185.494365ms 186.698638ms 239.436639ms 280.140736ms 298.404572ms 434.362802ms 435.75074ms 456.404706ms 468.306801ms 604.634394ms 625.246402ms 625.338042ms 629.191942ms 663.949911ms 675.304949ms 724.607517ms 739.327008ms 746.391095ms 746.742987ms 746.996561ms 747.059621ms 747.316464ms 747.494177ms 747.558228ms 747.676367ms 747.695505ms 747.735671ms 747.781495ms 747.867539ms 747.923763ms 748.080127ms 748.083915ms 748.135039ms 748.237804ms 748.303537ms 748.344033ms 748.373992ms 748.397284ms 748.410868ms 748.427369ms 748.433601ms 748.466923ms 748.5491ms 748.573185ms 748.579485ms 748.616863ms 748.62407ms 748.640891ms 748.673965ms 748.676418ms 748.793708ms 748.822901ms 748.856076ms 748.880694ms 748.924151ms 748.945604ms 748.960882ms 748.969357ms 748.977705ms 749.028199ms 749.061442ms 749.065329ms 749.083031ms 749.095476ms 749.100845ms 749.120023ms 749.121793ms 749.139057ms 749.166689ms 749.1937ms 749.224106ms 749.242131ms 749.25382ms 749.259905ms 749.298617ms 749.365811ms 749.392022ms 749.430101ms 749.456252ms 749.459058ms 749.4714ms 749.501609ms 749.515504ms 749.538959ms 749.564487ms 749.571618ms 749.574655ms 749.643744ms 749.653963ms 749.677468ms 749.680755ms 749.682798ms 749.722301ms 749.735477ms 749.736368ms 749.759141ms 749.759712ms 749.880489ms 749.890758ms 749.905686ms 749.910157ms 749.939793ms 749.973293ms 749.980368ms 750.000638ms 750.005663ms 750.016463ms 750.060967ms 750.065154ms 750.086898ms 750.110121ms 750.13526ms 750.197975ms 750.199278ms 750.214147ms 750.219537ms 750.24774ms 750.255282ms 750.266823ms 750.278688ms 750.288155ms 750.363157ms 750.363889ms 750.389634ms 750.401358ms 750.437385ms 750.46713ms 750.527153ms 750.597056ms 750.671956ms 750.680193ms 750.687887ms 750.693744ms 750.702442ms 750.762774ms 750.773555ms 750.793666ms 750.801199ms 750.802861ms 750.851482ms 750.86008ms 750.915564ms 750.963112ms 751.008809ms 751.025369ms 751.051159ms 751.145645ms 751.195819ms 751.26061ms 751.260795ms 751.327077ms 751.32762ms 751.399535ms 751.513076ms 751.550218ms 751.789407ms 751.817118ms 751.819292ms 751.92962ms 752.322947ms 752.337923ms 752.359598ms 752.395625ms]
  Apr 19 13:10:09.878: INFO: 50 %ile: 749.095476ms
  Apr 19 13:10:09.878: INFO: 90 %ile: 751.008809ms
  Apr 19 13:10:09.878: INFO: 99 %ile: 752.359598ms
  Apr 19 13:10:09.878: INFO: Total sample count: 200
  Apr 19 13:10:09.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-5766" for this suite. @ 04/19/23 13:10:09.885
• [9.772 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:117
  STEP: Creating a kubernetes client @ 04/19/23 13:10:09.893
  Apr 19 13:10:09.893: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 13:10:09.894
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:10:09.907
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:10:09.911
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/19/23 13:10:09.912
  W0419 13:10:09.919693      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:10:13.934
  Apr 19 13:10:13.938: INFO: Trying to get logs from node talos-default-worker-1 pod pod-cd73efcd-0880-4069-b948-47f6e80c9e5c container test-container: <nil>
  STEP: delete the pod @ 04/19/23 13:10:13.954
  Apr 19 13:10:13.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-210" for this suite. @ 04/19/23 13:10:13.979
• [4.093 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:497
  STEP: Creating a kubernetes client @ 04/19/23 13:10:13.987
  Apr 19 13:10:13.987: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 13:10:13.99
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:10:14.005
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:10:14.009
  STEP: Setting up server cert @ 04/19/23 13:10:14.033
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 13:10:14.322
  STEP: Deploying the webhook pod @ 04/19/23 13:10:14.329
  W0419 13:10:14.339681      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 13:10:14.339
  Apr 19 13:10:14.346: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 04/19/23 13:10:16.356
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 13:10:16.366
  Apr 19 13:10:17.367: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 13:10:18.368: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 13:10:19.367: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 13:10:20.367: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 13:10:21.367: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 13:10:22.367: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 13:10:23.367: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 13:10:24.367: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 13:10:25.368: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 13:10:26.367: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 13:10:27.367: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 04/19/23 13:10:27.372
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 04/19/23 13:10:27.392
  STEP: Creating a configMap that should not be mutated @ 04/19/23 13:10:27.4
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 04/19/23 13:10:27.411
  STEP: Creating a configMap that should be mutated @ 04/19/23 13:10:27.419
  Apr 19 13:10:27.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5420" for this suite. @ 04/19/23 13:10:27.487
  STEP: Destroying namespace "webhook-markers-8510" for this suite. @ 04/19/23 13:10:27.491
• [13.510 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:243
  STEP: Creating a kubernetes client @ 04/19/23 13:10:27.498
  Apr 19 13:10:27.498: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename namespaces @ 04/19/23 13:10:27.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:10:27.511
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:10:27.513
  STEP: Creating a test namespace @ 04/19/23 13:10:27.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:10:27.527
  STEP: Creating a pod in the namespace @ 04/19/23 13:10:27.53
  W0419 13:10:27.535905      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Waiting for the pod to have running status @ 04/19/23 13:10:27.536
  STEP: Deleting the namespace @ 04/19/23 13:10:29.549
  STEP: Waiting for the namespace to be removed. @ 04/19/23 13:10:29.558
  STEP: Recreating the namespace @ 04/19/23 13:10:40.561
  STEP: Verifying there are no pods in the namespace @ 04/19/23 13:10:40.582
  Apr 19 13:10:40.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4975" for this suite. @ 04/19/23 13:10:40.593
  STEP: Destroying namespace "nsdeletetest-7760" for this suite. @ 04/19/23 13:10:40.6
  Apr 19 13:10:40.606: INFO: Namespace nsdeletetest-7760 was already deleted
  STEP: Destroying namespace "nsdeletetest-5141" for this suite. @ 04/19/23 13:10:40.606
• [13.115 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] server version should find the server version [Conformance]
test/e2e/apimachinery/server_version.go:40
  STEP: Creating a kubernetes client @ 04/19/23 13:10:40.615
  Apr 19 13:10:40.615: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename server-version @ 04/19/23 13:10:40.617
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:10:40.632
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:10:40.636
  STEP: Request ServerVersion @ 04/19/23 13:10:40.64
  STEP: Confirm major version @ 04/19/23 13:10:40.642
  Apr 19 13:10:40.642: INFO: Major version: 1
  STEP: Confirm minor version @ 04/19/23 13:10:40.642
  Apr 19 13:10:40.642: INFO: cleanMinorVersion: 27
  Apr 19 13:10:40.642: INFO: Minor version: 27
  Apr 19 13:10:40.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-5743" for this suite. @ 04/19/23 13:10:40.647
• [0.039 seconds]
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 04/19/23 13:10:40.653
  Apr 19 13:10:40.653: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:10:40.655
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:10:40.669
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:10:40.672
  STEP: Creating projection with secret that has name projected-secret-test-afd2044d-3a51-4e35-85bc-1843997a3fe0 @ 04/19/23 13:10:40.675
  STEP: Creating a pod to test consume secrets @ 04/19/23 13:10:40.679
  W0419 13:10:40.687072      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:10:44.702
  Apr 19 13:10:44.706: INFO: Trying to get logs from node talos-default-worker-1 pod pod-projected-secrets-fa7da716-49b0-4d76-a5ef-20ffaa345ebe container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 13:10:44.726
  Apr 19 13:10:44.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3181" for this suite. @ 04/19/23 13:10:44.749
• [4.104 seconds]
------------------------------
S
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:45
  STEP: Creating a kubernetes client @ 04/19/23 13:10:44.758
  Apr 19 13:10:44.758: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 13:10:44.759
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:10:44.773
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:10:44.776
  STEP: Creating configMap configmap-3524/configmap-test-2068bfbe-1827-4719-b7a8-7ef3ffcbf1b4 @ 04/19/23 13:10:44.779
  STEP: Creating a pod to test consume configMaps @ 04/19/23 13:10:44.784
  W0419 13:10:44.791999      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "env-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "env-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "env-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "env-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:10:48.807
  Apr 19 13:10:48.811: INFO: Trying to get logs from node talos-default-worker-1 pod pod-configmaps-e54a45ef-4d86-4d22-97f5-79d11304ec26 container env-test: <nil>
  STEP: delete the pod @ 04/19/23 13:10:48.82
  Apr 19 13:10:48.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3524" for this suite. @ 04/19/23 13:10:48.84
• [4.096 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]
test/e2e/auth/service_accounts.go:161
  STEP: Creating a kubernetes client @ 04/19/23 13:10:48.857
  Apr 19 13:10:48.857: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/23 13:10:48.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:10:48.876
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:10:48.879
  W0419 13:10:48.899319      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:10:48.902: INFO: created pod pod-service-account-defaultsa
  Apr 19 13:10:48.904: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  W0419 13:10:48.910364      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:10:48.912: INFO: created pod pod-service-account-mountsa
  Apr 19 13:10:48.912: INFO: pod pod-service-account-mountsa service account token volume mount: true
  W0419 13:10:48.917425      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:10:48.917: INFO: created pod pod-service-account-nomountsa
  Apr 19 13:10:48.917: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  W0419 13:10:48.922634      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:10:48.922: INFO: created pod pod-service-account-defaultsa-mountspec
  Apr 19 13:10:48.922: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  W0419 13:10:48.928079      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:10:48.928: INFO: created pod pod-service-account-mountsa-mountspec
  Apr 19 13:10:48.928: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  W0419 13:10:48.933292      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:10:48.933: INFO: created pod pod-service-account-nomountsa-mountspec
  Apr 19 13:10:48.933: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  W0419 13:10:48.939464      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:10:48.939: INFO: created pod pod-service-account-defaultsa-nomountspec
  Apr 19 13:10:48.939: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  W0419 13:10:48.944135      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:10:48.944: INFO: created pod pod-service-account-mountsa-nomountspec
  Apr 19 13:10:48.944: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  W0419 13:10:48.948822      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:10:48.949: INFO: created pod pod-service-account-nomountsa-nomountspec
  Apr 19 13:10:48.949: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Apr 19 13:10:48.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2277" for this suite. @ 04/19/23 13:10:48.954
• [0.105 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]
test/e2e/apimachinery/webhook.go:331
  STEP: Creating a kubernetes client @ 04/19/23 13:10:48.962
  Apr 19 13:10:48.962: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 13:10:48.963
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:10:48.977
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:10:48.979
  STEP: Setting up server cert @ 04/19/23 13:10:49.001
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 13:10:49.261
  STEP: Deploying the webhook pod @ 04/19/23 13:10:49.273
  W0419 13:10:49.289212      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 13:10:49.289
  Apr 19 13:10:49.298: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/19/23 13:10:51.31
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 13:10:51.324
  Apr 19 13:10:52.328: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 13:10:52.333: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-227-crds.webhook.example.com via the AdmissionRegistration API @ 04/19/23 13:10:52.85
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/19/23 13:10:52.861
  Apr 19 13:10:54.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3442" for this suite. @ 04/19/23 13:10:55.442
  STEP: Destroying namespace "webhook-markers-9286" for this suite. @ 04/19/23 13:10:55.451
• [6.496 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:571
  STEP: Creating a kubernetes client @ 04/19/23 13:10:55.462
  Apr 19 13:10:55.462: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 13:10:55.464
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:10:55.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:10:55.485
  STEP: Setting up server cert @ 04/19/23 13:10:55.513
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 13:10:55.892
  STEP: Deploying the webhook pod @ 04/19/23 13:10:55.897
  W0419 13:10:55.906989      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 13:10:55.907
  Apr 19 13:10:55.916: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/19/23 13:10:57.926
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 13:10:57.942
  Apr 19 13:10:58.946: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 04/19/23 13:10:59.005
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/23 13:10:59.046
  STEP: Deleting the collection of validation webhooks @ 04/19/23 13:10:59.082
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/23 13:10:59.121
  Apr 19 13:10:59.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4155" for this suite. @ 04/19/23 13:10:59.165
  STEP: Destroying namespace "webhook-markers-5032" for this suite. @ 04/19/23 13:10:59.171
• [3.714 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance]
test/e2e/network/ingress.go:556
  STEP: Creating a kubernetes client @ 04/19/23 13:10:59.178
  Apr 19 13:10:59.178: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename ingress @ 04/19/23 13:10:59.179
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:10:59.189
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:10:59.191
  STEP: getting /apis @ 04/19/23 13:10:59.193
  STEP: getting /apis/networking.k8s.io @ 04/19/23 13:10:59.197
  STEP: getting /apis/networking.k8s.iov1 @ 04/19/23 13:10:59.199
  STEP: creating @ 04/19/23 13:10:59.2
  STEP: getting @ 04/19/23 13:10:59.209
  STEP: listing @ 04/19/23 13:10:59.211
  STEP: watching @ 04/19/23 13:10:59.213
  Apr 19 13:10:59.213: INFO: starting watch
  STEP: cluster-wide listing @ 04/19/23 13:10:59.214
  STEP: cluster-wide watching @ 04/19/23 13:10:59.217
  Apr 19 13:10:59.217: INFO: starting watch
  STEP: patching @ 04/19/23 13:10:59.217
  STEP: updating @ 04/19/23 13:10:59.22
  Apr 19 13:10:59.226: INFO: waiting for watch events with expected annotations
  Apr 19 13:10:59.226: INFO: saw patched and updated annotations
  STEP: patching /status @ 04/19/23 13:10:59.226
  STEP: updating /status @ 04/19/23 13:10:59.23
  STEP: get /status @ 04/19/23 13:10:59.235
  STEP: deleting @ 04/19/23 13:10:59.238
  STEP: deleting a collection @ 04/19/23 13:10:59.247
  Apr 19 13:10:59.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-7619" for this suite. @ 04/19/23 13:10:59.263
• [0.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 04/19/23 13:10:59.271
  Apr 19 13:10:59.271: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename containers @ 04/19/23 13:10:59.272
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:10:59.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:10:59.284
  STEP: Creating a pod to test override command @ 04/19/23 13:10:59.287
  W0419 13:10:59.293136      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:11:03.305
  Apr 19 13:11:03.309: INFO: Trying to get logs from node talos-default-worker-2 pod client-containers-26715e7f-6fd3-4859-be3f-6b30552fc37f container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 13:11:03.32
  Apr 19 13:11:03.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-2192" for this suite. @ 04/19/23 13:11:03.339
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:85
  STEP: Creating a kubernetes client @ 04/19/23 13:11:03.351
  Apr 19 13:11:03.351: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 13:11:03.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:11:03.37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:11:03.379
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 13:11:03.384
  W0419 13:11:03.393534      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:11:07.408
  Apr 19 13:11:07.413: INFO: Trying to get logs from node talos-default-worker-2 pod downwardapi-volume-a8edb60a-7663-4a7f-8255-2387433b3e1f container client-container: <nil>
  STEP: delete the pod @ 04/19/23 13:11:07.42
  Apr 19 13:11:07.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6857" for this suite. @ 04/19/23 13:11:07.445
• [4.103 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:208
  STEP: Creating a kubernetes client @ 04/19/23 13:11:07.459
  Apr 19 13:11:07.459: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:11:07.46
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:11:07.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:11:07.478
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 13:11:07.481
  W0419 13:11:07.487998      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:11:11.501
  Apr 19 13:11:11.504: INFO: Trying to get logs from node talos-default-worker-2 pod downwardapi-volume-cc4e2852-65b2-4023-a4f6-d01a7b07ca71 container client-container: <nil>
  STEP: delete the pod @ 04/19/23 13:11:11.511
  Apr 19 13:11:11.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6560" for this suite. @ 04/19/23 13:11:11.535
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:74
  STEP: Creating a kubernetes client @ 04/19/23 13:11:11.548
  Apr 19 13:11:11.549: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 13:11:11.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:11:11.567
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:11:11.571
  STEP: Creating configMap with name configmap-test-volume-8c510a22-700c-4787-be2f-2c5068d0243d @ 04/19/23 13:11:11.574
  STEP: Creating a pod to test consume configMaps @ 04/19/23 13:11:11.581
  W0419 13:11:11.590857      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:11:15.606
  Apr 19 13:11:15.610: INFO: Trying to get logs from node talos-default-worker-2 pod pod-configmaps-cf50f148-3139-40f5-b6ce-036619ebbde5 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 13:11:15.617
  Apr 19 13:11:15.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6795" for this suite. @ 04/19/23 13:11:15.636
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:131
  STEP: Creating a kubernetes client @ 04/19/23 13:11:15.646
  Apr 19 13:11:15.647: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:11:15.648
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:11:15.664
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:11:15.667
  STEP: Creating the pod @ 04/19/23 13:11:15.672
  W0419 13:11:15.681713      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:11:18.221: INFO: Successfully updated pod "labelsupdate3afe60b1-127b-484c-ad60-f0de94227663"
  Apr 19 13:11:22.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1810" for this suite. @ 04/19/23 13:11:22.252
• [6.612 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:54
  STEP: Creating a kubernetes client @ 04/19/23 13:11:22.26
  Apr 19 13:11:22.260: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:11:22.261
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:11:22.281
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:11:22.285
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 13:11:22.289
  W0419 13:11:22.299944      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:11:26.314
  Apr 19 13:11:26.317: INFO: Trying to get logs from node talos-default-worker-2 pod downwardapi-volume-b3801039-9830-42af-abaf-c40ce4dafe49 container client-container: <nil>
  STEP: delete the pod @ 04/19/23 13:11:26.324
  Apr 19 13:11:26.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3011" for this suite. @ 04/19/23 13:11:26.347
• [4.093 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance]
test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 04/19/23 13:11:26.36
  Apr 19 13:11:26.360: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pods @ 04/19/23 13:11:26.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:11:26.378
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:11:26.381
  STEP: Create a pod @ 04/19/23 13:11:26.384
  STEP: patching /status @ 04/19/23 13:11:28.397
  Apr 19 13:11:28.403: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Apr 19 13:11:28.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-23" for this suite. @ 04/19/23 13:11:28.409
• [2.062 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support ephemeral VolumeLifecycleMode in CSIDriver API [Conformance]
test/e2e/storage/csi_inline.go:46
  STEP: Creating a kubernetes client @ 04/19/23 13:11:28.422
  Apr 19 13:11:28.422: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/19/23 13:11:28.425
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:11:28.439
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:11:28.442
  STEP: creating @ 04/19/23 13:11:28.444
  STEP: getting @ 04/19/23 13:11:28.457
  STEP: listing @ 04/19/23 13:11:28.463
  STEP: deleting @ 04/19/23 13:11:28.466
  Apr 19 13:11:28.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-6031" for this suite. @ 04/19/23 13:11:28.484
• [0.066 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
test/e2e/apps/statefulset.go:591
  STEP: Creating a kubernetes client @ 04/19/23 13:11:28.488
  Apr 19 13:11:28.488: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename statefulset @ 04/19/23 13:11:28.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:11:28.501
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:11:28.503
  STEP: Creating service test in namespace statefulset-6065 @ 04/19/23 13:11:28.506
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 04/19/23 13:11:28.51
  STEP: Creating stateful set ss in namespace statefulset-6065 @ 04/19/23 13:11:28.513
  W0419 13:11:28.517449      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6065 @ 04/19/23 13:11:28.517
  Apr 19 13:11:28.521: INFO: Found 0 stateful pods, waiting for 1
  Apr 19 13:11:38.526: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 04/19/23 13:11:38.527
  Apr 19 13:11:38.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-6065 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 13:11:38.712: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 13:11:38.712: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 13:11:38.712: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 13:11:38.716: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  Apr 19 13:11:48.721: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 19 13:11:48.722: INFO: Waiting for statefulset status.replicas updated to 0
  W0419 13:11:48.737277      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:11:48.743: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999599s
  Apr 19 13:11:49.748: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.9934491s
  Apr 19 13:11:50.753: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988331613s
  Apr 19 13:11:51.759: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.982506306s
  Apr 19 13:11:52.764: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.977513415s
  Apr 19 13:11:53.770: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.972539619s
  Apr 19 13:11:54.775: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.966770738s
  Apr 19 13:11:55.780: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.961317939s
  Apr 19 13:11:56.785: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.956349132s
  Apr 19 13:11:57.790: INFO: Verifying statefulset ss doesn't scale past 1 for another 950.790086ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6065 @ 04/19/23 13:11:58.791
  Apr 19 13:11:58.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-6065 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 19 13:11:58.968: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 19 13:11:58.968: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 13:11:58.968: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 19 13:11:58.972: INFO: Found 1 stateful pods, waiting for 3
  Apr 19 13:12:08.978: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 13:12:08.978: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 13:12:08.978: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 04/19/23 13:12:08.978
  STEP: Scale down will halt with unhealthy stateful pod @ 04/19/23 13:12:08.978
  Apr 19 13:12:08.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-6065 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 13:12:09.214: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 13:12:09.214: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 13:12:09.214: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 13:12:09.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-6065 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 13:12:09.397: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 13:12:09.397: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 13:12:09.397: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 13:12:09.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-6065 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 13:12:09.603: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 13:12:09.603: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 13:12:09.603: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 13:12:09.603: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 13:12:09.607: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
  Apr 19 13:12:19.616: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 19 13:12:19.617: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Apr 19 13:12:19.617: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  W0419 13:12:19.627987      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:12:19.633: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999539s
  Apr 19 13:12:20.638: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994373176s
  Apr 19 13:12:21.643: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989507209s
  Apr 19 13:12:22.648: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984658328s
  Apr 19 13:12:23.653: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979836085s
  Apr 19 13:12:24.659: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974111008s
  Apr 19 13:12:25.664: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.96862995s
  Apr 19 13:12:26.669: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.963347343s
  Apr 19 13:12:27.674: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.958585505s
  Apr 19 13:12:28.680: INFO: Verifying statefulset ss doesn't scale past 3 for another 952.584258ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6065 @ 04/19/23 13:12:29.68
  Apr 19 13:12:29.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-6065 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 19 13:12:29.830: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 19 13:12:29.830: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 13:12:29.830: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 19 13:12:29.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-6065 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 19 13:12:30.011: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 19 13:12:30.011: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 13:12:30.011: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 19 13:12:30.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-6065 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 19 13:12:30.179: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 19 13:12:30.179: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 13:12:30.179: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 19 13:12:30.179: INFO: Scaling statefulset ss to 0
  W0419 13:12:30.188407      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 04/19/23 13:12:40.196
  Apr 19 13:12:40.196: INFO: Deleting all statefulset in ns statefulset-6065
  Apr 19 13:12:40.200: INFO: Scaling statefulset ss to 0
  W0419 13:12:40.208577      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:12:40.212: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 13:12:40.215: INFO: Deleting statefulset ss
  Apr 19 13:12:40.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6065" for this suite. @ 04/19/23 13:12:40.235
• [71.755 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]
test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 04/19/23 13:12:40.25
  Apr 19 13:12:40.250: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename conformance-tests @ 04/19/23 13:12:40.252
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:12:40.268
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:12:40.272
  STEP: Getting node addresses @ 04/19/23 13:12:40.275
  Apr 19 13:12:40.275: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Apr 19 13:12:40.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-8748" for this suite. @ 04/19/23 13:12:40.286
• [0.042 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]
test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 04/19/23 13:12:40.294
  Apr 19 13:12:40.294: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename crd-watch @ 04/19/23 13:12:40.295
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:12:40.315
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:12:40.317
  Apr 19 13:12:40.319: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Creating first CR  @ 04/19/23 13:12:42.856
  Apr 19 13:12:42.863: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-19T13:12:42Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-19T13:12:42Z]] name:name1 resourceVersion:187971 uid:d84d2e65-8bb6-4332-a0f8-00f58fbb997c] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Creating second CR @ 04/19/23 13:12:52.864
  Apr 19 13:12:52.870: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-19T13:12:52Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-19T13:12:52Z]] name:name2 resourceVersion:188026 uid:08fe8b3c-296a-4ab4-9b3e-5015451053fb] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Modifying first CR @ 04/19/23 13:13:02.87
  Apr 19 13:13:02.877: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-19T13:12:42Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-19T13:13:02Z]] name:name1 resourceVersion:188063 uid:d84d2e65-8bb6-4332-a0f8-00f58fbb997c] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Modifying second CR @ 04/19/23 13:13:12.877
  Apr 19 13:13:12.884: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-19T13:12:52Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-19T13:13:12Z]] name:name2 resourceVersion:188085 uid:08fe8b3c-296a-4ab4-9b3e-5015451053fb] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Deleting first CR @ 04/19/23 13:13:22.885
  Apr 19 13:13:22.892: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-19T13:12:42Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-19T13:13:02Z]] name:name1 resourceVersion:188109 uid:d84d2e65-8bb6-4332-a0f8-00f58fbb997c] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Deleting second CR @ 04/19/23 13:13:32.893
  Apr 19 13:13:32.901: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-19T13:12:52Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-19T13:13:12Z]] name:name2 resourceVersion:188130 uid:08fe8b3c-296a-4ab4-9b3e-5015451053fb] num:map[num1:9223372036854775807 num2:1000000]]}
  Apr 19 13:13:43.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-2841" for this suite. @ 04/19/23 13:13:43.426
• [63.139 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:609
  STEP: Creating a kubernetes client @ 04/19/23 13:13:43.437
  Apr 19 13:13:43.437: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename security-context-test @ 04/19/23 13:13:43.439
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:13:43.455
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:13:43.459
  W0419 13:13:43.470923      20 warnings.go:70] would violate PodSecurity "restricted:latest": unrestricted capabilities (container "alpine-nnp-false-9d9584d7-cea3-4595-91c4-1731c61e43b1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "alpine-nnp-false-9d9584d7-cea3-4595-91c4-1731c61e43b1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "alpine-nnp-false-9d9584d7-cea3-4595-91c4-1731c61e43b1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:13:45.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-9228" for this suite. @ 04/19/23 13:13:45.498
• [2.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:262
  STEP: Creating a kubernetes client @ 04/19/23 13:13:45.505
  Apr 19 13:13:45.506: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:13:45.507
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:13:45.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:13:45.521
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 13:13:45.524
  W0419 13:13:45.531149      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:13:47.539
  Apr 19 13:13:47.543: INFO: Trying to get logs from node talos-default-worker-1 pod downwardapi-volume-a9159919-fa50-48db-9da7-89fd1e1e64fe container client-container: <nil>
  STEP: delete the pod @ 04/19/23 13:13:47.559
  Apr 19 13:13:47.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6462" for this suite. @ 04/19/23 13:13:47.581
• [2.087 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/replica_set.go:111
  STEP: Creating a kubernetes client @ 04/19/23 13:13:47.593
  Apr 19 13:13:47.593: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename replicaset @ 04/19/23 13:13:47.595
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:13:47.607
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:13:47.61
  Apr 19 13:13:47.613: INFO: Creating ReplicaSet my-hostname-basic-b4ee6d54-08fc-4061-bbc9-a498cd48e21c
  W0419 13:13:47.618866      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "my-hostname-basic-b4ee6d54-08fc-4061-bbc9-a498cd48e21c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "my-hostname-basic-b4ee6d54-08fc-4061-bbc9-a498cd48e21c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "my-hostname-basic-b4ee6d54-08fc-4061-bbc9-a498cd48e21c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "my-hostname-basic-b4ee6d54-08fc-4061-bbc9-a498cd48e21c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:13:47.622: INFO: Pod name my-hostname-basic-b4ee6d54-08fc-4061-bbc9-a498cd48e21c: Found 0 pods out of 1
  Apr 19 13:13:52.630: INFO: Pod name my-hostname-basic-b4ee6d54-08fc-4061-bbc9-a498cd48e21c: Found 1 pods out of 1
  Apr 19 13:13:52.630: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-b4ee6d54-08fc-4061-bbc9-a498cd48e21c" is running
  Apr 19 13:13:52.635: INFO: Pod "my-hostname-basic-b4ee6d54-08fc-4061-bbc9-a498cd48e21c-pb5b9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-19 13:13:47 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-19 13:13:48 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-19 13:13:48 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-19 13:13:47 +0000 UTC Reason: Message:}])
  Apr 19 13:13:52.635: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/19/23 13:13:52.635
  Apr 19 13:13:52.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-5552" for this suite. @ 04/19/23 13:13:52.655
• [5.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 04/19/23 13:13:52.668
  Apr 19 13:13:52.668: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/23 13:13:52.669
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:13:52.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:13:52.684
  Apr 19 13:13:52.686: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/19/23 13:13:53.982
  Apr 19 13:13:53.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8819 --namespace=crd-publish-openapi-8819 create -f -'
  Apr 19 13:13:54.558: INFO: stderr: ""
  Apr 19 13:13:54.558: INFO: stdout: "e2e-test-crd-publish-openapi-3968-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Apr 19 13:13:54.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8819 --namespace=crd-publish-openapi-8819 delete e2e-test-crd-publish-openapi-3968-crds test-cr'
  Apr 19 13:13:54.629: INFO: stderr: ""
  Apr 19 13:13:54.629: INFO: stdout: "e2e-test-crd-publish-openapi-3968-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Apr 19 13:13:54.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8819 --namespace=crd-publish-openapi-8819 apply -f -'
  Apr 19 13:13:55.131: INFO: stderr: ""
  Apr 19 13:13:55.131: INFO: stdout: "e2e-test-crd-publish-openapi-3968-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Apr 19 13:13:55.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8819 --namespace=crd-publish-openapi-8819 delete e2e-test-crd-publish-openapi-3968-crds test-cr'
  Apr 19 13:13:55.209: INFO: stderr: ""
  Apr 19 13:13:55.209: INFO: stdout: "e2e-test-crd-publish-openapi-3968-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/19/23 13:13:55.209
  Apr 19 13:13:55.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8819 explain e2e-test-crd-publish-openapi-3968-crds'
  Apr 19 13:13:55.807: INFO: stderr: ""
  Apr 19 13:13:55.807: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-3968-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  Apr 19 13:13:57.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8819" for this suite. @ 04/19/23 13:13:57.777
• [5.114 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
test/e2e/apps/job.go:430
  STEP: Creating a kubernetes client @ 04/19/23 13:13:57.785
  Apr 19 13:13:57.785: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename job @ 04/19/23 13:13:57.788
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:13:57.802
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:13:57.806
  STEP: Creating a job @ 04/19/23 13:13:57.809
  W0419 13:13:57.814117      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring job reaches completions @ 04/19/23 13:13:57.814
  Apr 19 13:14:07.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1908" for this suite. @ 04/19/23 13:14:07.822
• [10.044 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]
test/e2e/scheduling/predicates.go:444
  STEP: Creating a kubernetes client @ 04/19/23 13:14:07.832
  Apr 19 13:14:07.832: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename sched-pred @ 04/19/23 13:14:07.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:14:07.856
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:14:07.86
  Apr 19 13:14:07.864: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 19 13:14:07.873: INFO: Waiting for terminating namespaces to be deleted...
  Apr 19 13:14:07.878: INFO: 
  Logging pods the apiserver thinks is on node talos-default-worker-1 before test
  Apr 19 13:14:07.885: INFO: fail-once-local-59cpz from job-1908 started at 2023-04-19 13:14:02 +0000 UTC (1 container statuses recorded)
  Apr 19 13:14:07.885: INFO: 	Container c ready: false, restart count 1
  Apr 19 13:14:07.886: INFO: fail-once-local-g6t97 from job-1908 started at 2023-04-19 13:14:02 +0000 UTC (1 container statuses recorded)
  Apr 19 13:14:07.886: INFO: 	Container c ready: false, restart count 1
  Apr 19 13:14:07.886: INFO: fail-once-local-lnhx5 from job-1908 started at 2023-04-19 13:13:57 +0000 UTC (1 container statuses recorded)
  Apr 19 13:14:07.886: INFO: 	Container c ready: false, restart count 1
  Apr 19 13:14:07.886: INFO: fail-once-local-xlqkl from job-1908 started at 2023-04-19 13:13:57 +0000 UTC (1 container statuses recorded)
  Apr 19 13:14:07.886: INFO: 	Container c ready: false, restart count 1
  Apr 19 13:14:07.886: INFO: kube-flannel-xtc62 from kube-system started at 2023-04-18 19:32:12 +0000 UTC (1 container statuses recorded)
  Apr 19 13:14:07.886: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 19 13:14:07.886: INFO: kube-proxy-j7zxh from kube-system started at 2023-04-18 19:32:12 +0000 UTC (1 container statuses recorded)
  Apr 19 13:14:07.886: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 19 13:14:07.886: INFO: sonobuoy from sonobuoy started at 2023-04-19 12:53:21 +0000 UTC (1 container statuses recorded)
  Apr 19 13:14:07.886: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 19 13:14:07.886: INFO: 
  Logging pods the apiserver thinks is on node talos-default-worker-2 before test
  Apr 19 13:14:07.892: INFO: coredns-d779cc7ff-z6svh from kube-system started at 2023-04-18 19:38:29 +0000 UTC (1 container statuses recorded)
  Apr 19 13:14:07.892: INFO: 	Container coredns ready: true, restart count 0
  Apr 19 13:14:07.892: INFO: kube-flannel-xntjw from kube-system started at 2023-04-18 19:32:33 +0000 UTC (1 container statuses recorded)
  Apr 19 13:14:07.892: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 19 13:14:07.892: INFO: kube-proxy-qxzd4 from kube-system started at 2023-04-18 19:32:33 +0000 UTC (1 container statuses recorded)
  Apr 19 13:14:07.892: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 19 13:14:07.892: INFO: sonobuoy-e2e-job-9b851c216c1a4329 from sonobuoy started at 2023-04-19 12:53:22 +0000 UTC (2 container statuses recorded)
  Apr 19 13:14:07.893: INFO: 	Container e2e ready: true, restart count 0
  Apr 19 13:14:07.893: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 04/19/23 13:14:07.893
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.17575847062ec31f], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) didn't match Pod's node affinity/selector, 3 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling..] @ 04/19/23 13:14:07.916
  Apr 19 13:14:08.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-882" for this suite. @ 04/19/23 13:14:08.922
• [1.097 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:194
  STEP: Creating a kubernetes client @ 04/19/23 13:14:08.931
  Apr 19 13:14:08.932: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 13:14:08.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:14:08.95
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:14:08.954
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 13:14:08.957
  W0419 13:14:08.967606      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:14:12.983
  Apr 19 13:14:12.986: INFO: Trying to get logs from node talos-default-worker-1 pod downwardapi-volume-e1a3f04d-b99b-4e4f-b0ce-d1620e6b138e container client-container: <nil>
  STEP: delete the pod @ 04/19/23 13:14:12.995
  Apr 19 13:14:13.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-610" for this suite. @ 04/19/23 13:14:13.009
• [4.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:57
  STEP: Creating a kubernetes client @ 04/19/23 13:14:13.015
  Apr 19 13:14:13.015: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:14:13.016
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:14:13.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:14:13.028
  STEP: Creating configMap with name projected-configmap-test-volume-6e527d91-4ea7-4fa8-83ba-5c2265adeeec @ 04/19/23 13:14:13.03
  STEP: Creating a pod to test consume configMaps @ 04/19/23 13:14:13.034
  W0419 13:14:13.039869      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:14:17.053
  Apr 19 13:14:17.057: INFO: Trying to get logs from node talos-default-worker-1 pod pod-projected-configmaps-1d99eedb-f2ff-4026-99cc-bfeb224f30b8 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 13:14:17.064
  Apr 19 13:14:17.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9866" for this suite. @ 04/19/23 13:14:17.087
• [4.078 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]
test/e2e/kubectl/kubectl.go:1480
  STEP: Creating a kubernetes client @ 04/19/23 13:14:17.097
  Apr 19 13:14:17.097: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 13:14:17.099
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:14:17.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:14:17.124
  STEP: creating Agnhost RC @ 04/19/23 13:14:17.128
  Apr 19 13:14:17.128: INFO: namespace kubectl-9249
  Apr 19 13:14:17.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-9249 create -f -'
  Apr 19 13:14:17.758: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"agnhost-primary\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"agnhost-primary\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"agnhost-primary\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"agnhost-primary\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 13:14:17.758: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 04/19/23 13:14:17.758
  Apr 19 13:14:18.764: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 13:14:18.764: INFO: Found 1 / 1
  Apr 19 13:14:18.764: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Apr 19 13:14:18.768: INFO: Selector matched 1 pods for map[app:agnhost]
  Apr 19 13:14:18.768: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Apr 19 13:14:18.768: INFO: wait on agnhost-primary startup in kubectl-9249 
  Apr 19 13:14:18.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-9249 logs agnhost-primary-2f8qp agnhost-primary'
  Apr 19 13:14:18.879: INFO: stderr: ""
  Apr 19 13:14:18.879: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 04/19/23 13:14:18.879
  Apr 19 13:14:18.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-9249 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  Apr 19 13:14:18.983: INFO: stderr: ""
  Apr 19 13:14:18.983: INFO: stdout: "service/rm2 exposed\n"
  Apr 19 13:14:18.990: INFO: Service rm2 in namespace kubectl-9249 found.
  STEP: exposing service @ 04/19/23 13:14:20.997
  Apr 19 13:14:20.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-9249 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Apr 19 13:14:21.109: INFO: stderr: ""
  Apr 19 13:14:21.109: INFO: stdout: "service/rm3 exposed\n"
  Apr 19 13:14:21.115: INFO: Service rm3 in namespace kubectl-9249 found.
  Apr 19 13:14:23.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9249" for this suite. @ 04/19/23 13:14:23.128
• [6.038 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]
test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 04/19/23 13:14:23.135
  Apr 19 13:14:23.135: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/19/23 13:14:23.136
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:14:23.158
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:14:23.163
  W0419 13:14:23.183834      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:14:25.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Cleaning up the secret @ 04/19/23 13:14:25.204
  STEP: Cleaning up the configmap @ 04/19/23 13:14:25.21
  STEP: Cleaning up the pod @ 04/19/23 13:14:25.217
  STEP: Destroying namespace "emptydir-wrapper-8856" for this suite. @ 04/19/23 13:14:25.23
• [2.102 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]
test/e2e/apimachinery/garbage_collector.go:379
  STEP: Creating a kubernetes client @ 04/19/23 13:14:25.239
  Apr 19 13:14:25.239: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename gc @ 04/19/23 13:14:25.241
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:14:25.256
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:14:25.261
  STEP: create the rc @ 04/19/23 13:14:25.27
  W0419 13:14:25.277177      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  W0419 13:14:25.277510      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: delete the rc @ 04/19/23 13:14:31.282
  STEP: wait for the rc to be deleted @ 04/19/23 13:14:31.288
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 04/19/23 13:14:36.292
  STEP: Gathering metrics @ 04/19/23 13:15:06.307
  Apr 19 13:15:06.379: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 19 13:15:06.381: INFO: Deleting pod "simpletest.rc-2k59f" in namespace "gc-8261"
  Apr 19 13:15:06.392: INFO: Deleting pod "simpletest.rc-2r7p6" in namespace "gc-8261"
  Apr 19 13:15:06.408: INFO: Deleting pod "simpletest.rc-455kl" in namespace "gc-8261"
  Apr 19 13:15:06.418: INFO: Deleting pod "simpletest.rc-4l74h" in namespace "gc-8261"
  Apr 19 13:15:06.426: INFO: Deleting pod "simpletest.rc-4tcdt" in namespace "gc-8261"
  Apr 19 13:15:06.435: INFO: Deleting pod "simpletest.rc-5ndqk" in namespace "gc-8261"
  Apr 19 13:15:06.444: INFO: Deleting pod "simpletest.rc-5px2v" in namespace "gc-8261"
  Apr 19 13:15:06.454: INFO: Deleting pod "simpletest.rc-5vzkn" in namespace "gc-8261"
  Apr 19 13:15:06.463: INFO: Deleting pod "simpletest.rc-67tzw" in namespace "gc-8261"
  Apr 19 13:15:06.474: INFO: Deleting pod "simpletest.rc-6bcwg" in namespace "gc-8261"
  Apr 19 13:15:06.484: INFO: Deleting pod "simpletest.rc-6chwd" in namespace "gc-8261"
  Apr 19 13:15:06.493: INFO: Deleting pod "simpletest.rc-6fqtz" in namespace "gc-8261"
  Apr 19 13:15:06.501: INFO: Deleting pod "simpletest.rc-6vkjm" in namespace "gc-8261"
  Apr 19 13:15:06.512: INFO: Deleting pod "simpletest.rc-769s5" in namespace "gc-8261"
  Apr 19 13:15:06.522: INFO: Deleting pod "simpletest.rc-78x97" in namespace "gc-8261"
  Apr 19 13:15:06.533: INFO: Deleting pod "simpletest.rc-7cz67" in namespace "gc-8261"
  Apr 19 13:15:06.543: INFO: Deleting pod "simpletest.rc-7hb9b" in namespace "gc-8261"
  Apr 19 13:15:06.553: INFO: Deleting pod "simpletest.rc-7rfch" in namespace "gc-8261"
  Apr 19 13:15:06.564: INFO: Deleting pod "simpletest.rc-86nb9" in namespace "gc-8261"
  Apr 19 13:15:06.573: INFO: Deleting pod "simpletest.rc-87qhj" in namespace "gc-8261"
  Apr 19 13:15:06.582: INFO: Deleting pod "simpletest.rc-89ts2" in namespace "gc-8261"
  Apr 19 13:15:06.591: INFO: Deleting pod "simpletest.rc-8w86w" in namespace "gc-8261"
  Apr 19 13:15:06.604: INFO: Deleting pod "simpletest.rc-8xkpq" in namespace "gc-8261"
  Apr 19 13:15:06.615: INFO: Deleting pod "simpletest.rc-9c658" in namespace "gc-8261"
  Apr 19 13:15:06.625: INFO: Deleting pod "simpletest.rc-9fp5l" in namespace "gc-8261"
  Apr 19 13:15:06.641: INFO: Deleting pod "simpletest.rc-9lsvt" in namespace "gc-8261"
  Apr 19 13:15:06.651: INFO: Deleting pod "simpletest.rc-9q9lr" in namespace "gc-8261"
  Apr 19 13:15:06.663: INFO: Deleting pod "simpletest.rc-9vk9v" in namespace "gc-8261"
  Apr 19 13:15:06.671: INFO: Deleting pod "simpletest.rc-bbzc9" in namespace "gc-8261"
  Apr 19 13:15:06.682: INFO: Deleting pod "simpletest.rc-br96p" in namespace "gc-8261"
  Apr 19 13:15:06.693: INFO: Deleting pod "simpletest.rc-bs5kb" in namespace "gc-8261"
  Apr 19 13:15:06.704: INFO: Deleting pod "simpletest.rc-bszht" in namespace "gc-8261"
  Apr 19 13:15:06.713: INFO: Deleting pod "simpletest.rc-c97j4" in namespace "gc-8261"
  Apr 19 13:15:06.725: INFO: Deleting pod "simpletest.rc-c9tqk" in namespace "gc-8261"
  Apr 19 13:15:06.736: INFO: Deleting pod "simpletest.rc-djrms" in namespace "gc-8261"
  Apr 19 13:15:06.748: INFO: Deleting pod "simpletest.rc-dnk2b" in namespace "gc-8261"
  Apr 19 13:15:06.757: INFO: Deleting pod "simpletest.rc-drx79" in namespace "gc-8261"
  Apr 19 13:15:06.767: INFO: Deleting pod "simpletest.rc-dxgbn" in namespace "gc-8261"
  Apr 19 13:15:06.778: INFO: Deleting pod "simpletest.rc-dxnhk" in namespace "gc-8261"
  Apr 19 13:15:06.787: INFO: Deleting pod "simpletest.rc-f775b" in namespace "gc-8261"
  Apr 19 13:15:06.797: INFO: Deleting pod "simpletest.rc-ffgdg" in namespace "gc-8261"
  Apr 19 13:15:06.806: INFO: Deleting pod "simpletest.rc-fgqzl" in namespace "gc-8261"
  Apr 19 13:15:06.818: INFO: Deleting pod "simpletest.rc-fh7zz" in namespace "gc-8261"
  Apr 19 13:15:06.826: INFO: Deleting pod "simpletest.rc-fj8m2" in namespace "gc-8261"
  Apr 19 13:15:06.837: INFO: Deleting pod "simpletest.rc-fqqx4" in namespace "gc-8261"
  Apr 19 13:15:06.848: INFO: Deleting pod "simpletest.rc-gqz4x" in namespace "gc-8261"
  Apr 19 13:15:06.858: INFO: Deleting pod "simpletest.rc-gw6ml" in namespace "gc-8261"
  Apr 19 13:15:06.867: INFO: Deleting pod "simpletest.rc-hb9tl" in namespace "gc-8261"
  Apr 19 13:15:06.875: INFO: Deleting pod "simpletest.rc-hqg2m" in namespace "gc-8261"
  Apr 19 13:15:06.888: INFO: Deleting pod "simpletest.rc-j4flm" in namespace "gc-8261"
  Apr 19 13:15:06.896: INFO: Deleting pod "simpletest.rc-j6h8p" in namespace "gc-8261"
  Apr 19 13:15:06.905: INFO: Deleting pod "simpletest.rc-j6p66" in namespace "gc-8261"
  Apr 19 13:15:06.917: INFO: Deleting pod "simpletest.rc-j6xdn" in namespace "gc-8261"
  Apr 19 13:15:06.928: INFO: Deleting pod "simpletest.rc-jgh4x" in namespace "gc-8261"
  Apr 19 13:15:06.939: INFO: Deleting pod "simpletest.rc-jjkg2" in namespace "gc-8261"
  Apr 19 13:15:06.950: INFO: Deleting pod "simpletest.rc-jwdk9" in namespace "gc-8261"
  Apr 19 13:15:06.958: INFO: Deleting pod "simpletest.rc-k2wnf" in namespace "gc-8261"
  Apr 19 13:15:06.967: INFO: Deleting pod "simpletest.rc-k7qtp" in namespace "gc-8261"
  Apr 19 13:15:06.977: INFO: Deleting pod "simpletest.rc-l7pn4" in namespace "gc-8261"
  Apr 19 13:15:06.988: INFO: Deleting pod "simpletest.rc-l94hw" in namespace "gc-8261"
  Apr 19 13:15:07.005: INFO: Deleting pod "simpletest.rc-lghwx" in namespace "gc-8261"
  Apr 19 13:15:07.055: INFO: Deleting pod "simpletest.rc-lm9df" in namespace "gc-8261"
  Apr 19 13:15:07.106: INFO: Deleting pod "simpletest.rc-lnk4k" in namespace "gc-8261"
  Apr 19 13:15:07.155: INFO: Deleting pod "simpletest.rc-lpbj6" in namespace "gc-8261"
  Apr 19 13:15:07.206: INFO: Deleting pod "simpletest.rc-lqwrm" in namespace "gc-8261"
  Apr 19 13:15:07.254: INFO: Deleting pod "simpletest.rc-mcnb4" in namespace "gc-8261"
  Apr 19 13:15:07.305: INFO: Deleting pod "simpletest.rc-mffqt" in namespace "gc-8261"
  Apr 19 13:15:07.354: INFO: Deleting pod "simpletest.rc-mldz8" in namespace "gc-8261"
  Apr 19 13:15:07.403: INFO: Deleting pod "simpletest.rc-mpzvf" in namespace "gc-8261"
  Apr 19 13:15:07.457: INFO: Deleting pod "simpletest.rc-n2f7l" in namespace "gc-8261"
  Apr 19 13:15:07.504: INFO: Deleting pod "simpletest.rc-njsxg" in namespace "gc-8261"
  Apr 19 13:15:07.555: INFO: Deleting pod "simpletest.rc-nm8ng" in namespace "gc-8261"
  Apr 19 13:15:07.603: INFO: Deleting pod "simpletest.rc-npt2h" in namespace "gc-8261"
  Apr 19 13:15:07.656: INFO: Deleting pod "simpletest.rc-nzzqq" in namespace "gc-8261"
  Apr 19 13:15:07.705: INFO: Deleting pod "simpletest.rc-p79jx" in namespace "gc-8261"
  Apr 19 13:15:07.755: INFO: Deleting pod "simpletest.rc-pmrqt" in namespace "gc-8261"
  Apr 19 13:15:07.804: INFO: Deleting pod "simpletest.rc-pnsgr" in namespace "gc-8261"
  Apr 19 13:15:07.855: INFO: Deleting pod "simpletest.rc-prmwf" in namespace "gc-8261"
  Apr 19 13:15:07.905: INFO: Deleting pod "simpletest.rc-pxs6b" in namespace "gc-8261"
  Apr 19 13:15:07.955: INFO: Deleting pod "simpletest.rc-pz9bj" in namespace "gc-8261"
  Apr 19 13:15:08.005: INFO: Deleting pod "simpletest.rc-q5r4j" in namespace "gc-8261"
  Apr 19 13:15:08.054: INFO: Deleting pod "simpletest.rc-q68qf" in namespace "gc-8261"
  Apr 19 13:15:08.104: INFO: Deleting pod "simpletest.rc-qdch9" in namespace "gc-8261"
  Apr 19 13:15:08.154: INFO: Deleting pod "simpletest.rc-qm4gr" in namespace "gc-8261"
  Apr 19 13:15:08.204: INFO: Deleting pod "simpletest.rc-qxxrm" in namespace "gc-8261"
  Apr 19 13:15:08.254: INFO: Deleting pod "simpletest.rc-rp8wp" in namespace "gc-8261"
  Apr 19 13:15:08.306: INFO: Deleting pod "simpletest.rc-rwcmc" in namespace "gc-8261"
  Apr 19 13:15:08.357: INFO: Deleting pod "simpletest.rc-s2vwx" in namespace "gc-8261"
  Apr 19 13:15:08.404: INFO: Deleting pod "simpletest.rc-sgd8n" in namespace "gc-8261"
  Apr 19 13:15:08.454: INFO: Deleting pod "simpletest.rc-vmrc2" in namespace "gc-8261"
  Apr 19 13:15:08.506: INFO: Deleting pod "simpletest.rc-vqfvv" in namespace "gc-8261"
  Apr 19 13:15:08.557: INFO: Deleting pod "simpletest.rc-w8chv" in namespace "gc-8261"
  Apr 19 13:15:08.606: INFO: Deleting pod "simpletest.rc-wfhjv" in namespace "gc-8261"
  Apr 19 13:15:08.656: INFO: Deleting pod "simpletest.rc-wh25g" in namespace "gc-8261"
  Apr 19 13:15:08.705: INFO: Deleting pod "simpletest.rc-wmpn7" in namespace "gc-8261"
  Apr 19 13:15:08.755: INFO: Deleting pod "simpletest.rc-wsg8g" in namespace "gc-8261"
  Apr 19 13:15:08.806: INFO: Deleting pod "simpletest.rc-x2pf8" in namespace "gc-8261"
  Apr 19 13:15:08.855: INFO: Deleting pod "simpletest.rc-xdz8r" in namespace "gc-8261"
  Apr 19 13:15:08.904: INFO: Deleting pod "simpletest.rc-xh9kc" in namespace "gc-8261"
  Apr 19 13:15:08.957: INFO: Deleting pod "simpletest.rc-xl65j" in namespace "gc-8261"
  Apr 19 13:15:09.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8261" for this suite. @ 04/19/23 13:15:09.049
• [43.863 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]
test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 04/19/23 13:15:09.102
  Apr 19 13:15:09.102: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pods @ 04/19/23 13:15:09.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:15:09.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:15:09.119
  STEP: creating a Pod with a static label @ 04/19/23 13:15:09.126
  STEP: watching for Pod to be ready @ 04/19/23 13:15:09.134
  Apr 19 13:15:09.135: INFO: observed Pod pod-test in namespace pods-2943 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Apr 19 13:15:09.138: INFO: observed Pod pod-test in namespace pods-2943 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 13:15:09 +0000 UTC  }]
  Apr 19 13:15:09.768: INFO: observed Pod pod-test in namespace pods-2943 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 13:15:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 13:15:09 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 13:15:09 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 13:15:09 +0000 UTC  }]
  Apr 19 13:15:12.458: INFO: Found Pod pod-test in namespace pods-2943 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 13:15:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 13:15:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 13:15:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 13:15:09 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 04/19/23 13:15:12.462
  STEP: getting the Pod and ensuring that it's patched @ 04/19/23 13:15:12.471
  STEP: replacing the Pod's status Ready condition to False @ 04/19/23 13:15:12.476
  STEP: check the Pod again to ensure its Ready conditions are False @ 04/19/23 13:15:12.487
  STEP: deleting the Pod via a Collection with a LabelSelector @ 04/19/23 13:15:12.487
  STEP: watching for the Pod to be deleted @ 04/19/23 13:15:12.494
  Apr 19 13:15:12.496: INFO: observed event type MODIFIED
  Apr 19 13:15:13.497: INFO: observed event type MODIFIED
  Apr 19 13:15:14.602: INFO: observed event type MODIFIED
  Apr 19 13:15:15.467: INFO: observed event type MODIFIED
  Apr 19 13:15:15.472: INFO: observed event type MODIFIED
  Apr 19 13:15:15.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2943" for this suite. @ 04/19/23 13:15:15.484
• [6.386 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should provide DNS for services  [Conformance]
test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 04/19/23 13:15:15.489
  Apr 19 13:15:15.489: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename dns @ 04/19/23 13:15:15.489
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:15:15.5
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:15:15.504
  STEP: Creating a test headless service @ 04/19/23 13:15:15.507
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3616.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3616.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3616.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3616.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3616.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3616.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3616.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3616.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3616.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3616.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3616.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3616.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 255.203.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.203.255_udp@PTR;check="$$(dig +tcp +noall +answer +search 255.203.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.203.255_tcp@PTR;sleep 1; done
   @ 04/19/23 13:15:15.525
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3616.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3616.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3616.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3616.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3616.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3616.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3616.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3616.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3616.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3616.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3616.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3616.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 255.203.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.203.255_udp@PTR;check="$$(dig +tcp +noall +answer +search 255.203.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.203.255_tcp@PTR;sleep 1; done
   @ 04/19/23 13:15:15.528
  STEP: creating a pod to probe DNS @ 04/19/23 13:15:15.528
  STEP: submitting the pod to kubernetes @ 04/19/23 13:15:15.528
  W0419 13:15:15.542137      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: retrieving the pod @ 04/19/23 13:15:17.552
  STEP: looking for the results for each expected name from probers @ 04/19/23 13:15:17.558
  Apr 19 13:15:17.564: INFO: Unable to read wheezy_udp@dns-test-service.dns-3616.svc.cluster.local from pod dns-3616/dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6: the server could not find the requested resource (get pods dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6)
  Apr 19 13:15:17.569: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3616.svc.cluster.local from pod dns-3616/dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6: the server could not find the requested resource (get pods dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6)
  Apr 19 13:15:17.574: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3616.svc.cluster.local from pod dns-3616/dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6: the server could not find the requested resource (get pods dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6)
  Apr 19 13:15:17.579: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3616.svc.cluster.local from pod dns-3616/dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6: the server could not find the requested resource (get pods dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6)
  Apr 19 13:15:17.598: INFO: Unable to read jessie_udp@dns-test-service.dns-3616.svc.cluster.local from pod dns-3616/dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6: the server could not find the requested resource (get pods dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6)
  Apr 19 13:15:17.603: INFO: Unable to read jessie_tcp@dns-test-service.dns-3616.svc.cluster.local from pod dns-3616/dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6: the server could not find the requested resource (get pods dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6)
  Apr 19 13:15:17.608: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3616.svc.cluster.local from pod dns-3616/dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6: the server could not find the requested resource (get pods dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6)
  Apr 19 13:15:17.613: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3616.svc.cluster.local from pod dns-3616/dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6: the server could not find the requested resource (get pods dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6)
  Apr 19 13:15:17.629: INFO: Lookups using dns-3616/dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6 failed for: [wheezy_udp@dns-test-service.dns-3616.svc.cluster.local wheezy_tcp@dns-test-service.dns-3616.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3616.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3616.svc.cluster.local jessie_udp@dns-test-service.dns-3616.svc.cluster.local jessie_tcp@dns-test-service.dns-3616.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3616.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3616.svc.cluster.local]

  Apr 19 13:15:22.687: INFO: DNS probes using dns-3616/dns-test-912402a5-75fa-4fa7-8e07-05e62ea2b4d6 succeeded

  Apr 19 13:15:22.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 13:15:22.692
  STEP: deleting the test service @ 04/19/23 13:15:22.708
  STEP: deleting the test headless service @ 04/19/23 13:15:22.73
  STEP: Destroying namespace "dns-3616" for this suite. @ 04/19/23 13:15:22.741
• [7.258 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]
test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 04/19/23 13:15:22.749
  Apr 19 13:15:22.749: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename deployment @ 04/19/23 13:15:22.75
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:15:22.761
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:15:22.764
  Apr 19 13:15:22.766: INFO: Creating simple deployment test-new-deployment
  W0419 13:15:22.770348      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:15:22.777: INFO: deployment "test-new-deployment" doesn't have the required revision set
  STEP: getting scale subresource @ 04/19/23 13:15:24.793
  STEP: updating a scale subresource @ 04/19/23 13:15:24.797
  STEP: verifying the deployment Spec.Replicas was modified @ 04/19/23 13:15:24.803
  STEP: Patch a scale subresource @ 04/19/23 13:15:24.808
  Apr 19 13:15:24.825: INFO: Deployment "test-new-deployment":
  &Deployment{ObjectMeta:{test-new-deployment  deployment-1499  9e601d48-3ebd-4d5b-b591-13b333c0277d 190631 3 2023-04-19 13:15:22 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-04-19 13:15:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:15:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006f23a38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-19 13:15:23 +0000 UTC,LastTransitionTime:2023-04-19 13:15:23 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-67bd4bf6dc" has successfully progressed.,LastUpdateTime:2023-04-19 13:15:23 +0000 UTC,LastTransitionTime:2023-04-19 13:15:22 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 19 13:15:24.832: INFO: New ReplicaSet "test-new-deployment-67bd4bf6dc" of Deployment "test-new-deployment":
  &ReplicaSet{ObjectMeta:{test-new-deployment-67bd4bf6dc  deployment-1499  5469ea64-340f-406f-922f-aa0846de16a4 190635 2 2023-04-19 13:15:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 9e601d48-3ebd-4d5b-b591-13b333c0277d 0xc006e4b317 0xc006e4b318}] [] [{kube-controller-manager Update apps/v1 2023-04-19 13:15:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9e601d48-3ebd-4d5b-b591-13b333c0277d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:15:24 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 67bd4bf6dc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006e4b3a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 19 13:15:24.836: INFO: Pod "test-new-deployment-67bd4bf6dc-r24x5" is available:
  &Pod{ObjectMeta:{test-new-deployment-67bd4bf6dc-r24x5 test-new-deployment-67bd4bf6dc- deployment-1499  810a7f7c-a647-495e-ac3d-4113b470ed27 190623 0 2023-04-19 13:15:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet test-new-deployment-67bd4bf6dc 5469ea64-340f-406f-922f-aa0846de16a4 0xc006f23e27 0xc006f23e28}] [] [{kube-controller-manager Update v1 2023-04-19 13:15:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5469ea64-340f-406f-922f-aa0846de16a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:15:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.3.145\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7n92r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7n92r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:10.244.3.145,StartTime:2023-04-19 13:15:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:15:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://7e90da7010cdd5bf269b887b816ab0fe563919acf46945889d49a9c7266c5d1f,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.145,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:15:24.838: INFO: Pod "test-new-deployment-67bd4bf6dc-r6hsn" is not available:
  &Pod{ObjectMeta:{test-new-deployment-67bd4bf6dc-r6hsn test-new-deployment-67bd4bf6dc- deployment-1499  bf10a3d1-4ca0-457f-804b-786ca9cf274a 190638 0 2023-04-19 13:15:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:67bd4bf6dc] map[] [{apps/v1 ReplicaSet test-new-deployment-67bd4bf6dc 5469ea64-340f-406f-922f-aa0846de16a4 0xc006f72000 0xc006f72001}] [] [{kube-controller-manager Update v1 2023-04-19 13:15:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5469ea64-340f-406f-922f-aa0846de16a4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:15:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jpjfv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jpjfv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.6,PodIP:,StartTime:2023-04-19 13:15:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:15:24.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1499" for this suite. @ 04/19/23 13:15:24.844
• [2.104 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance]
test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 04/19/23 13:15:24.855
  Apr 19 13:15:24.856: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename deployment @ 04/19/23 13:15:24.858
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:15:24.872
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:15:24.874
  W0419 13:15:24.879753      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:15:24.882: INFO: Pod name rollover-pod: Found 0 pods out of 1
  Apr 19 13:15:29.891: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/23 13:15:29.891
  Apr 19 13:15:29.891: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  Apr 19 13:15:31.895: INFO: Creating deployment "test-rollover-deployment"
  W0419 13:15:31.906826      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "redis-slave" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "redis-slave" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "redis-slave" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "redis-slave" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:15:31.910: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  Apr 19 13:15:33.919: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Apr 19 13:15:33.927: INFO: Ensure that both replica sets have 1 created replica
  Apr 19 13:15:33.934: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  W0419 13:15:33.943373      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:15:33.943: INFO: Updating deployment test-rollover-deployment
  Apr 19 13:15:33.943: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  Apr 19 13:15:35.953: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Apr 19 13:15:35.961: INFO: Make sure deployment "test-rollover-deployment" is complete
  Apr 19 13:15:35.969: INFO: all replica sets need to contain the pod-template-hash label
  Apr 19 13:15:35.969: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 13, 15, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 13:15:37.978: INFO: all replica sets need to contain the pod-template-hash label
  Apr 19 13:15:37.978: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 13, 15, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 13:15:39.978: INFO: all replica sets need to contain the pod-template-hash label
  Apr 19 13:15:39.979: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 13, 15, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 13:15:41.978: INFO: all replica sets need to contain the pod-template-hash label
  Apr 19 13:15:41.978: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 13, 15, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 13:15:43.977: INFO: all replica sets need to contain the pod-template-hash label
  Apr 19 13:15:43.977: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 13, 15, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 13, 15, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-57777854c9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 13:15:45.977: INFO: 
  Apr 19 13:15:45.977: INFO: Ensure that both old replica sets have no replicas
  Apr 19 13:15:45.987: INFO: Deployment "test-rollover-deployment":
  &Deployment{ObjectMeta:{test-rollover-deployment  deployment-2876  99bf7817-5dd7-4239-acf2-3699fdea675b 190823 2 2023-04-19 13:15:31 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-19 13:15:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:15:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0070f19c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-19 13:15:31 +0000 UTC,LastTransitionTime:2023-04-19 13:15:31 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-57777854c9" has successfully progressed.,LastUpdateTime:2023-04-19 13:15:45 +0000 UTC,LastTransitionTime:2023-04-19 13:15:31 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 19 13:15:45.991: INFO: New ReplicaSet "test-rollover-deployment-57777854c9" of Deployment "test-rollover-deployment":
  &ReplicaSet{ObjectMeta:{test-rollover-deployment-57777854c9  deployment-2876  f754cf18-1938-4762-a1d5-c7289f8b84b5 190813 2 2023-04-19 13:15:33 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:57777854c9] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 99bf7817-5dd7-4239-acf2-3699fdea675b 0xc007146417 0xc007146418}] [] [{kube-controller-manager Update apps/v1 2023-04-19 13:15:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99bf7817-5dd7-4239-acf2-3699fdea675b\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:15:45 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 57777854c9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:57777854c9] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0071464c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 19 13:15:45.995: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Apr 19 13:15:45.996: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-2876  8ea57906-71e9-4bbd-b862-ef5ffbf7207b 190822 2 2023-04-19 13:15:24 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 99bf7817-5dd7-4239-acf2-3699fdea675b 0xc0071462e7 0xc0071462e8}] [] [{e2e.test Update apps/v1 2023-04-19 13:15:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:15:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99bf7817-5dd7-4239-acf2-3699fdea675b\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:15:45 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0071463a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 19 13:15:45.997: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-58779b56b4  deployment-2876  796ce989-61c3-4129-8084-64ac4703a99e 190771 2 2023-04-19 13:15:31 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:58779b56b4] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 99bf7817-5dd7-4239-acf2-3699fdea675b 0xc007146537 0xc007146538}] [] [{kube-controller-manager Update apps/v1 2023-04-19 13:15:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99bf7817-5dd7-4239-acf2-3699fdea675b\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:15:33 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 58779b56b4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:58779b56b4] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0071465e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 19 13:15:46.006: INFO: Pod "test-rollover-deployment-57777854c9-dz27m" is available:
  &Pod{ObjectMeta:{test-rollover-deployment-57777854c9-dz27m test-rollover-deployment-57777854c9- deployment-2876  ae37f079-22c0-42e5-b0da-13bb9eed3048 190789 0 2023-04-19 13:15:33 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:57777854c9] map[] [{apps/v1 ReplicaSet test-rollover-deployment-57777854c9 f754cf18-1938-4762-a1d5-c7289f8b84b5 0xc007146827 0xc007146828}] [] [{kube-controller-manager Update v1 2023-04-19 13:15:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f754cf18-1938-4762-a1d5-c7289f8b84b5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:15:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.3.148\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kxht8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kxht8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:10.244.3.148,StartTime:2023-04-19 13:15:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:15:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:containerd://f8bce4af86199ecd1a7c0391981d5890bc8de97e8ce1a2b51ff5c50f04d2a4b6,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.148,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:15:46.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2876" for this suite. @ 04/19/23 13:15:46.013
• [21.165 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:252
  STEP: Creating a kubernetes client @ 04/19/23 13:15:46.023
  Apr 19 13:15:46.023: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename namespaces @ 04/19/23 13:15:46.025
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:15:46.04
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:15:46.043
  STEP: Creating a test namespace @ 04/19/23 13:15:46.046
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:15:46.059
  STEP: Creating a service in the namespace @ 04/19/23 13:15:46.062
  STEP: Deleting the namespace @ 04/19/23 13:15:46.073
  STEP: Waiting for the namespace to be removed. @ 04/19/23 13:15:46.083
  STEP: Recreating the namespace @ 04/19/23 13:15:52.088
  STEP: Verifying there is no service in the namespace @ 04/19/23 13:15:52.107
  Apr 19 13:15:52.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9230" for this suite. @ 04/19/23 13:15:52.116
  STEP: Destroying namespace "nsdeletetest-2385" for this suite. @ 04/19/23 13:15:52.123
  Apr 19 13:15:52.128: INFO: Namespace nsdeletetest-2385 was already deleted
  STEP: Destroying namespace "nsdeletetest-7162" for this suite. @ 04/19/23 13:15:52.128
• [6.113 seconds]
------------------------------
SSS
------------------------------
[sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]
test/e2e/storage/csistoragecapacity.go:49
  STEP: Creating a kubernetes client @ 04/19/23 13:15:52.138
  Apr 19 13:15:52.138: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename csistoragecapacity @ 04/19/23 13:15:52.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:15:52.155
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:15:52.158
  STEP: getting /apis @ 04/19/23 13:15:52.163
  STEP: getting /apis/storage.k8s.io @ 04/19/23 13:15:52.168
  STEP: getting /apis/storage.k8s.io/v1 @ 04/19/23 13:15:52.17
  STEP: creating @ 04/19/23 13:15:52.171
  STEP: watching @ 04/19/23 13:15:52.187
  Apr 19 13:15:52.187: INFO: starting watch
  STEP: getting @ 04/19/23 13:15:52.193
  STEP: listing in namespace @ 04/19/23 13:15:52.197
  STEP: listing across namespaces @ 04/19/23 13:15:52.2
  STEP: patching @ 04/19/23 13:15:52.203
  STEP: updating @ 04/19/23 13:15:52.208
  Apr 19 13:15:52.213: INFO: waiting for watch events with expected annotations in namespace
  Apr 19 13:15:52.214: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 04/19/23 13:15:52.214
  STEP: deleting a collection @ 04/19/23 13:15:52.225
  Apr 19 13:15:52.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-1220" for this suite. @ 04/19/23 13:15:52.24
• [0.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:55
  STEP: Creating a kubernetes client @ 04/19/23 13:15:52.246
  Apr 19 13:15:52.246: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/23 13:15:52.247
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:15:52.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:15:52.26
  Apr 19 13:15:52.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-1638" for this suite. @ 04/19/23 13:15:52.27
• [0.027 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 04/19/23 13:15:52.276
  Apr 19 13:15:52.276: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename deployment @ 04/19/23 13:15:52.277
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:15:52.286
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:15:52.288
  Apr 19 13:15:52.290: INFO: Creating deployment "test-recreate-deployment"
  W0419 13:15:52.294857      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:15:52.295: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Apr 19 13:15:52.300: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
  Apr 19 13:15:54.309: INFO: Waiting deployment "test-recreate-deployment" to complete
  Apr 19 13:15:54.313: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  W0419 13:15:54.323888      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:15:54.323: INFO: Updating deployment test-recreate-deployment
  Apr 19 13:15:54.324: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  Apr 19 13:15:54.389: INFO: Deployment "test-recreate-deployment":
  &Deployment{ObjectMeta:{test-recreate-deployment  deployment-8604  cc7df201-4d6d-483f-9ba6-69185cf1bf85 190956 2 2023-04-19 13:15:52 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-19 13:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004454f18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-19 13:15:54 +0000 UTC,LastTransitionTime:2023-04-19 13:15:54 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-54757ffd6c" is progressing.,LastUpdateTime:2023-04-19 13:15:54 +0000 UTC,LastTransitionTime:2023-04-19 13:15:52 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

  Apr 19 13:15:54.392: INFO: New ReplicaSet "test-recreate-deployment-54757ffd6c" of Deployment "test-recreate-deployment":
  &ReplicaSet{ObjectMeta:{test-recreate-deployment-54757ffd6c  deployment-8604  f18679c1-45ce-4dc8-9507-de6ce3a94cc1 190954 1 2023-04-19 13:15:54 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:54757ffd6c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment cc7df201-4d6d-483f-9ba6-69185cf1bf85 0xc0044552a7 0xc0044552a8}] [] [{kube-controller-manager Update apps/v1 2023-04-19 13:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc7df201-4d6d-483f-9ba6-69185cf1bf85\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:15:54 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 54757ffd6c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:54757ffd6c] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004455348 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 19 13:15:54.392: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Apr 19 13:15:54.393: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-6c99bf8bf6  deployment-8604  11e492d0-4974-4652-8f75-49bdbaec0bf6 190945 2 2023-04-19 13:15:52 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:6c99bf8bf6] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment cc7df201-4d6d-483f-9ba6-69185cf1bf85 0xc0044553b7 0xc0044553b8}] [] [{kube-controller-manager Update apps/v1 2023-04-19 13:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc7df201-4d6d-483f-9ba6-69185cf1bf85\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:15:54 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6c99bf8bf6,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:6c99bf8bf6] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004455468 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
  Apr 19 13:15:54.397: INFO: Pod "test-recreate-deployment-54757ffd6c-css5f" is not available:
  &Pod{ObjectMeta:{test-recreate-deployment-54757ffd6c-css5f test-recreate-deployment-54757ffd6c- deployment-8604  7a832b24-35f0-4a0d-a1da-80572948732d 190957 0 2023-04-19 13:15:54 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:54757ffd6c] map[] [{apps/v1 ReplicaSet test-recreate-deployment-54757ffd6c f18679c1-45ce-4dc8-9507-de6ce3a94cc1 0xc0044558f7 0xc0044558f8}] [] [{kube-controller-manager Update v1 2023-04-19 13:15:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f18679c1-45ce-4dc8-9507-de6ce3a94cc1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:15:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gth46,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gth46,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:15:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:,StartTime:2023-04-19 13:15:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:,ContainerID:,Started:*false,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:15:54.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8604" for this suite. @ 04/19/23 13:15:54.4
• [2.129 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 04/19/23 13:15:54.406
  Apr 19 13:15:54.406: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename taint-multiple-pods @ 04/19/23 13:15:54.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:15:54.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:15:54.42
  Apr 19 13:15:54.422: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 19 13:16:54.438: INFO: Waiting for terminating namespaces to be deleted...
  Apr 19 13:16:54.443: INFO: Starting informer...
  STEP: Starting pods... @ 04/19/23 13:16:54.443
  W0419 13:16:54.462091      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:16:54.470: INFO: Pod1 is running on talos-default-worker-1. Tainting Node
  W0419 13:16:54.476926      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:16:56.694: INFO: Pod2 is running on talos-default-worker-1. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/19/23 13:16:56.694
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/19/23 13:16:56.709
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 04/19/23 13:16:56.715
  Apr 19 13:17:02.750: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  Apr 19 13:17:22.789: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  Apr 19 13:17:22.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/19/23 13:17:22.805
  STEP: Destroying namespace "taint-multiple-pods-5341" for this suite. @ 04/19/23 13:17:22.809
• [88.410 seconds]
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]
test/e2e/apps/statefulset.go:981
  STEP: Creating a kubernetes client @ 04/19/23 13:17:22.817
  Apr 19 13:17:22.817: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename statefulset @ 04/19/23 13:17:22.82
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:17:22.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:17:22.837
  STEP: Creating service test in namespace statefulset-3162 @ 04/19/23 13:17:22.839
  STEP: Creating statefulset ss in namespace statefulset-3162 @ 04/19/23 13:17:22.846
  W0419 13:17:22.850723      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:17:22.854: INFO: Found 0 stateful pods, waiting for 1
  Apr 19 13:17:32.858: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 04/19/23 13:17:32.866
  W0419 13:17:32.877827      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Getting /status @ 04/19/23 13:17:32.877
  Apr 19 13:17:32.883: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 04/19/23 13:17:32.883
  Apr 19 13:17:32.893: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 04/19/23 13:17:32.893
  Apr 19 13:17:32.895: INFO: Observed &StatefulSet event: ADDED
  Apr 19 13:17:32.896: INFO: Found Statefulset ss in namespace statefulset-3162 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 19 13:17:32.896: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 04/19/23 13:17:32.896
  Apr 19 13:17:32.896: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 19 13:17:32.905: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 04/19/23 13:17:32.905
  Apr 19 13:17:32.909: INFO: Observed &StatefulSet event: ADDED
  Apr 19 13:17:32.909: INFO: Deleting all statefulset in ns statefulset-3162
  Apr 19 13:17:32.913: INFO: Scaling statefulset ss to 0
  W0419 13:17:32.924367      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:17:42.934: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 13:17:42.937: INFO: Deleting statefulset ss
  Apr 19 13:17:42.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3162" for this suite. @ 04/19/23 13:17:42.958
• [20.147 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 04/19/23 13:17:42.968
  Apr 19 13:17:42.969: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/23 13:17:42.972
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:17:42.989
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:17:42.993
  W0419 13:17:43.003929      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-readonly-fsd2687f03-1def-4a75-b461-e7af474383bd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-readonly-fsd2687f03-1def-4a75-b461-e7af474383bd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-readonly-fsd2687f03-1def-4a75-b461-e7af474383bd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-readonly-fsd2687f03-1def-4a75-b461-e7af474383bd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:17:45.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6845" for this suite. @ 04/19/23 13:17:45.036
• [2.076 seconds]
------------------------------
S
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]
test/e2e/common/node/ephemeral_containers.go:46
  STEP: Creating a kubernetes client @ 04/19/23 13:17:45.044
  Apr 19 13:17:45.044: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 04/19/23 13:17:45.047
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:17:45.068
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:17:45.073
  STEP: creating a target pod @ 04/19/23 13:17:45.084
  W0419 13:17:45.095432      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: adding an ephemeral container @ 04/19/23 13:17:47.114
  W0419 13:17:47.126348      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "test-container-1", "debugger" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "test-container-1", "debugger" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "test-container-1", "debugger" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "test-container-1", "debugger" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: checking pod container endpoints @ 04/19/23 13:17:49.135
  Apr 19 13:17:49.135: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-3934 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:17:49.135: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:17:49.135: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:17:49.136: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-3934/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Apr 19 13:17:49.235: INFO: Exec stderr: ""
  Apr 19 13:17:49.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-3934" for this suite. @ 04/19/23 13:17:49.247
• [4.213 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:208
  STEP: Creating a kubernetes client @ 04/19/23 13:17:49.262
  Apr 19 13:17:49.262: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 13:17:49.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:17:49.28
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:17:49.284
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 13:17:49.286
  W0419 13:17:49.293877      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:17:53.309
  Apr 19 13:17:53.313: INFO: Trying to get logs from node talos-default-worker-2 pod downwardapi-volume-eef3aaa9-e25c-49bb-a0f7-e61df9d40750 container client-container: <nil>
  STEP: delete the pod @ 04/19/23 13:17:53.323
  Apr 19 13:17:53.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7995" for this suite. @ 04/19/23 13:17:53.347
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]
test/e2e/instrumentation/core_events.go:57
  STEP: Creating a kubernetes client @ 04/19/23 13:17:53.36
  Apr 19 13:17:53.360: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename events @ 04/19/23 13:17:53.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:17:53.378
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:17:53.382
  STEP: creating a test event @ 04/19/23 13:17:53.385
  STEP: listing all events in all namespaces @ 04/19/23 13:17:53.391
  STEP: patching the test event @ 04/19/23 13:17:53.396
  STEP: fetching the test event @ 04/19/23 13:17:53.405
  STEP: updating the test event @ 04/19/23 13:17:53.409
  STEP: getting the test event @ 04/19/23 13:17:53.419
  STEP: deleting the test event @ 04/19/23 13:17:53.422
  STEP: listing all events in all namespaces @ 04/19/23 13:17:53.429
  Apr 19 13:17:53.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6071" for this suite. @ 04/19/23 13:17:53.438
• [0.083 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service  [Conformance]
test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 04/19/23 13:17:53.444
  Apr 19 13:17:53.445: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 13:17:53.446
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:17:53.457
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:17:53.46
  Apr 19 13:17:53.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8246" for this suite. @ 04/19/23 13:17:53.467
• [0.027 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]
test/e2e/apimachinery/namespace.go:303
  STEP: Creating a kubernetes client @ 04/19/23 13:17:53.472
  Apr 19 13:17:53.472: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename namespaces @ 04/19/23 13:17:53.474
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:17:53.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:17:53.486
  STEP: Read namespace status @ 04/19/23 13:17:53.488
  Apr 19 13:17:53.491: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 04/19/23 13:17:53.491
  Apr 19 13:17:53.495: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 04/19/23 13:17:53.495
  Apr 19 13:17:53.504: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Apr 19 13:17:53.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4528" for this suite. @ 04/19/23 13:17:53.508
• [0.040 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:47
  STEP: Creating a kubernetes client @ 04/19/23 13:17:53.512
  Apr 19 13:17:53.512: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 13:17:53.514
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:17:53.524
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:17:53.525
  STEP: Creating configMap with name configmap-test-volume-b23b20c4-6363-4fff-a562-13c0366e589c @ 04/19/23 13:17:53.527
  STEP: Creating a pod to test consume configMaps @ 04/19/23 13:17:53.53
  W0419 13:17:53.536685      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:17:57.548
  Apr 19 13:17:57.552: INFO: Trying to get logs from node talos-default-worker-2 pod pod-configmaps-ea3a0af8-37ee-4af1-bdd4-aa879418f3cb container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 13:17:57.559
  Apr 19 13:17:57.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1312" for this suite. @ 04/19/23 13:17:57.584
• [4.079 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]
test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 04/19/23 13:17:57.592
  Apr 19 13:17:57.592: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename disruption @ 04/19/23 13:17:57.593
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:17:57.608
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:17:57.611
  STEP: creating the pdb @ 04/19/23 13:17:57.615
  STEP: Waiting for the pdb to be processed @ 04/19/23 13:17:57.62
  STEP: updating the pdb @ 04/19/23 13:17:57.625
  STEP: Waiting for the pdb to be processed @ 04/19/23 13:17:57.634
  STEP: patching the pdb @ 04/19/23 13:17:59.642
  STEP: Waiting for the pdb to be processed @ 04/19/23 13:17:59.65
  STEP: Waiting for the pdb to be deleted @ 04/19/23 13:17:59.659
  Apr 19 13:17:59.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3659" for this suite. @ 04/19/23 13:17:59.667
• [2.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 04/19/23 13:17:59.678
  Apr 19 13:17:59.678: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename var-expansion @ 04/19/23 13:17:59.68
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:17:59.698
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:17:59.701
  STEP: Creating a pod to test substitution in container's command @ 04/19/23 13:17:59.705
  W0419 13:17:59.713410      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:18:03.727
  Apr 19 13:18:03.730: INFO: Trying to get logs from node talos-default-worker-2 pod var-expansion-ebc54613-6306-4386-99ba-f17f0a765670 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/23 13:18:03.736
  Apr 19 13:18:03.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6074" for this suite. @ 04/19/23 13:18:03.756
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 04/19/23 13:18:03.768
  Apr 19 13:18:03.769: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename var-expansion @ 04/19/23 13:18:03.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:18:03.789
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:18:03.793
  W0419 13:18:03.805772      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:18:05.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 19 13:18:05.821: INFO: Deleting pod "var-expansion-c950f247-55e7-4bd7-8237-a8f19037e0d4" in namespace "var-expansion-9073"
  Apr 19 13:18:05.832: INFO: Wait up to 5m0s for pod "var-expansion-c950f247-55e7-4bd7-8237-a8f19037e0d4" to be fully deleted
  STEP: Destroying namespace "var-expansion-9073" for this suite. @ 04/19/23 13:18:07.845
• [4.084 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]
test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 04/19/23 13:18:07.855
  Apr 19 13:18:07.855: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir-wrapper @ 04/19/23 13:18:07.858
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:18:07.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:18:07.878
  STEP: Creating 50 configmaps @ 04/19/23 13:18:07.882
  STEP: Creating RC which spawns configmap-volume pods @ 04/19/23 13:18:08.112
  W0419 13:18:08.173050      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:18:08.223: INFO: Pod name wrapped-volume-race-2a98a53c-b614-439a-a860-45ef6e215b66: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/19/23 13:18:08.223
  STEP: Creating RC which spawns configmap-volume pods @ 04/19/23 13:18:10.284
  W0419 13:18:10.308163      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:18:10.314: INFO: Pod name wrapped-volume-race-d2226076-a195-4c65-82dc-3b6f26e34ae9: Found 0 pods out of 5
  Apr 19 13:18:15.324: INFO: Pod name wrapped-volume-race-d2226076-a195-4c65-82dc-3b6f26e34ae9: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/19/23 13:18:15.324
  STEP: Creating RC which spawns configmap-volume pods @ 04/19/23 13:18:15.352
  W0419 13:18:15.361638      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:18:15.369: INFO: Pod name wrapped-volume-race-4b9949f6-78a9-4609-ac84-3b268336cb32: Found 0 pods out of 5
  Apr 19 13:18:20.377: INFO: Pod name wrapped-volume-race-4b9949f6-78a9-4609-ac84-3b268336cb32: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 04/19/23 13:18:20.378
  Apr 19 13:18:20.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController wrapped-volume-race-4b9949f6-78a9-4609-ac84-3b268336cb32 in namespace emptydir-wrapper-6224, will wait for the garbage collector to delete the pods @ 04/19/23 13:18:20.405
  Apr 19 13:18:20.469: INFO: Deleting ReplicationController wrapped-volume-race-4b9949f6-78a9-4609-ac84-3b268336cb32 took: 8.887144ms
  Apr 19 13:18:20.570: INFO: Terminating ReplicationController wrapped-volume-race-4b9949f6-78a9-4609-ac84-3b268336cb32 pods took: 100.885139ms
  STEP: deleting ReplicationController wrapped-volume-race-d2226076-a195-4c65-82dc-3b6f26e34ae9 in namespace emptydir-wrapper-6224, will wait for the garbage collector to delete the pods @ 04/19/23 13:18:21.271
  Apr 19 13:18:21.333: INFO: Deleting ReplicationController wrapped-volume-race-d2226076-a195-4c65-82dc-3b6f26e34ae9 took: 7.432962ms
  Apr 19 13:18:21.433: INFO: Terminating ReplicationController wrapped-volume-race-d2226076-a195-4c65-82dc-3b6f26e34ae9 pods took: 100.501078ms
  STEP: deleting ReplicationController wrapped-volume-race-2a98a53c-b614-439a-a860-45ef6e215b66 in namespace emptydir-wrapper-6224, will wait for the garbage collector to delete the pods @ 04/19/23 13:18:22.334
  Apr 19 13:18:22.395: INFO: Deleting ReplicationController wrapped-volume-race-2a98a53c-b614-439a-a860-45ef6e215b66 took: 6.816124ms
  Apr 19 13:18:22.499: INFO: Terminating ReplicationController wrapped-volume-race-2a98a53c-b614-439a-a860-45ef6e215b66 pods took: 104.0211ms
  STEP: Cleaning up the configMaps @ 04/19/23 13:18:23.4
  STEP: Destroying namespace "emptydir-wrapper-6224" for this suite. @ 04/19/23 13:18:23.57
• [15.719 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]
test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 04/19/23 13:18:23.574
  Apr 19 13:18:23.574: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename taint-single-pod @ 04/19/23 13:18:23.575
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:18:23.586
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:18:23.589
  Apr 19 13:18:23.592: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 19 13:19:23.608: INFO: Waiting for terminating namespaces to be deleted...
  Apr 19 13:19:23.612: INFO: Starting informer...
  STEP: Starting pod... @ 04/19/23 13:19:23.612
  W0419 13:19:23.623694      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:19:23.828: INFO: Pod is running on talos-default-worker-1. Tainting Node
  STEP: Trying to apply a taint on the Node @ 04/19/23 13:19:23.828
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/19/23 13:19:23.841
  STEP: Waiting short time to make sure Pod is queued for deletion @ 04/19/23 13:19:23.845
  Apr 19 13:19:23.845: INFO: Pod wasn't evicted. Proceeding
  Apr 19 13:19:23.845: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 04/19/23 13:19:23.863
  STEP: Waiting some time to make sure that toleration time passed. @ 04/19/23 13:19:23.869
  Apr 19 13:20:38.869: INFO: Pod wasn't evicted. Test successful
  Apr 19 13:20:38.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-8789" for this suite. @ 04/19/23 13:20:38.875
• [135.307 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]
test/e2e/apps/daemon_set.go:166
  STEP: Creating a kubernetes client @ 04/19/23 13:20:38.884
  Apr 19 13:20:38.884: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename daemonsets @ 04/19/23 13:20:38.887
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:20:38.908
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:20:38.912
  STEP: Creating simple DaemonSet "daemon-set" @ 04/19/23 13:20:38.934
  W0419 13:20:38.940723      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/23 13:20:38.94
  Apr 19 13:20:38.947: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:38.948: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:38.948: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:38.953: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:20:38.953: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:20:39.959: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:39.959: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:39.959: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:39.963: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:20:39.963: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:20:40.958: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:40.958: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:40.958: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:40.962: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 13:20:40.962: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 04/19/23 13:20:40.966
  Apr 19 13:20:40.980: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:40.981: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:40.982: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:40.988: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 13:20:40.988: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:20:41.993: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:41.993: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:41.993: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:41.997: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 13:20:41.997: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:20:42.993: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:42.993: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:42.993: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:42.997: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 13:20:42.997: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:20:43.992: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:43.992: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:43.992: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:20:43.996: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 13:20:43.996: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/23 13:20:43.999
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-682, will wait for the garbage collector to delete the pods @ 04/19/23 13:20:43.999
  Apr 19 13:20:44.057: INFO: Deleting DaemonSet.extensions daemon-set took: 4.987748ms
  Apr 19 13:20:44.158: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.122114ms
  Apr 19 13:20:45.263: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:20:45.263: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 19 13:20:45.268: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"192469"},"items":null}

  Apr 19 13:20:45.272: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"192469"},"items":null}

  Apr 19 13:20:45.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-682" for this suite. @ 04/19/23 13:20:45.289
• [6.417 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 04/19/23 13:20:45.308
  Apr 19 13:20:45.308: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:20:45.311
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:20:45.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:20:45.332
  STEP: Creating projection with secret that has name projected-secret-test-map-a7dccaa6-a6c2-4672-8bd3-e35799222df4 @ 04/19/23 13:20:45.335
  STEP: Creating a pod to test consume secrets @ 04/19/23 13:20:45.339
  W0419 13:20:45.347377      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:20:47.357
  Apr 19 13:20:47.362: INFO: Trying to get logs from node talos-default-worker-1 pod pod-projected-secrets-16bd4c99-e427-4368-98e6-9a05f3515296 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 13:20:47.378
  Apr 19 13:20:47.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3464" for this suite. @ 04/19/23 13:20:47.395
• [2.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 04/19/23 13:20:47.408
  Apr 19 13:20:47.408: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename containers @ 04/19/23 13:20:47.409
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:20:47.422
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:20:47.424
  W0419 13:20:47.433417      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:20:49.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-3423" for this suite. @ 04/19/23 13:20:49.45
• [2.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:334
  STEP: Creating a kubernetes client @ 04/19/23 13:20:49.46
  Apr 19 13:20:49.460: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename init-container @ 04/19/23 13:20:49.462
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:20:49.477
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:20:49.48
  STEP: creating the pod @ 04/19/23 13:20:49.483
  Apr 19 13:20:49.483: INFO: PodSpec: initContainers in spec.initContainers
  W0419 13:20:49.494470      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "init1", "init2", "run1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "init1", "init2", "run1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "init1", "init2", "run1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "init1", "init2", "run1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:21:36.305: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-76302c14-87da-4a6b-a506-021a763c93bf", GenerateName:"", Namespace:"init-container-1742", SelfLink:"", UID:"5524b051-be9c-4a67-b3db-466f33a7718b", ResourceVersion:"192680", Generation:0, CreationTimestamp:time.Date(2023, time.April, 19, 13, 20, 49, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"483751231"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 19, 13, 20, 49, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051e49c0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 19, 13, 21, 36, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0051e4a08), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-982fh", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc003a9c040), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-982fh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-982fh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-982fh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004636fd8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"talos-default-worker-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00072f420), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004637050)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004637070)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004637078), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00463707c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000e63000), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 19, 13, 20, 49, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 19, 13, 20, 49, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 19, 13, 20, 49, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 19, 13, 20, 49, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.20.0.5", PodIP:"10.244.3.160", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.3.160"}}, StartTime:time.Date(2023, time.April, 19, 13, 20, 49, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00072f500)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00072f5e0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:2e0f836850e09b8b7cc937681d6194537a09fbd5f6b9e08f4d646a85128e8937", ContainerID:"containerd://b02016157ce5e102751836633abef5ec8469710b53c16b29fc45a096914655b6", Started:(*bool)(nil), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003a9c320), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"", ContainerID:"", Started:(*bool)(nil), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003a9c2e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc0046370ff), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:""}}
  Apr 19 13:21:36.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-1742" for this suite. @ 04/19/23 13:21:36.311
• [46.859 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 04/19/23 13:21:36.322
  Apr 19 13:21:36.322: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename var-expansion @ 04/19/23 13:21:36.327
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:21:36.342
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:21:36.346
  W0419 13:21:36.357546      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:21:38.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 19 13:21:38.371: INFO: Deleting pod "var-expansion-1de9901a-34bb-487a-94ad-6982caa3b018" in namespace "var-expansion-1911"
  Apr 19 13:21:38.378: INFO: Wait up to 5m0s for pod "var-expansion-1de9901a-34bb-487a-94ad-6982caa3b018" to be fully deleted
  STEP: Destroying namespace "var-expansion-1911" for this suite. @ 04/19/23 13:21:40.391
• [4.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]
test/e2e/auth/service_accounts.go:78
  STEP: Creating a kubernetes client @ 04/19/23 13:21:40.404
  Apr 19 13:21:40.404: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/23 13:21:40.405
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:21:40.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:21:40.429
  W0419 13:21:40.445807      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: reading a file in the container @ 04/19/23 13:21:42.455
  Apr 19 13:21:42.455: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2812 pod-service-account-9a8f734c-f3bd-4202-927c-af1b8737cdec -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 04/19/23 13:21:42.647
  Apr 19 13:21:42.647: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2812 pod-service-account-9a8f734c-f3bd-4202-927c-af1b8737cdec -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 04/19/23 13:21:42.82
  Apr 19 13:21:42.820: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2812 pod-service-account-9a8f734c-f3bd-4202-927c-af1b8737cdec -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  Apr 19 13:21:42.976: INFO: Got root ca configmap in namespace "svcaccounts-2812"
  Apr 19 13:21:42.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2812" for this suite. @ 04/19/23 13:21:42.984
• [2.587 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]
test/e2e/storage/csi_inline.go:131
  STEP: Creating a kubernetes client @ 04/19/23 13:21:42.993
  Apr 19 13:21:42.993: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename csiinlinevolumes @ 04/19/23 13:21:42.995
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:21:43.012
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:21:43.015
  STEP: creating @ 04/19/23 13:21:43.018
  W0419 13:21:43.026968      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-csi-inline-volumes" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-csi-inline-volumes" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-csi-inline-volumes" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-csi-inline-volumes" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  W0419 13:21:43.035115      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-csi-inline-volumes" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-csi-inline-volumes" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-csi-inline-volumes" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-csi-inline-volumes" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: getting @ 04/19/23 13:21:43.035
  STEP: listing in namespace @ 04/19/23 13:21:43.039
  STEP: patching @ 04/19/23 13:21:43.042
  STEP: deleting @ 04/19/23 13:21:43.047
  Apr 19 13:21:43.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-4875" for this suite. @ 04/19/23 13:21:43.058
• [0.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:286
  STEP: Creating a kubernetes client @ 04/19/23 13:21:43.062
  Apr 19 13:21:43.062: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename field-validation @ 04/19/23 13:21:43.063
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:21:43.073
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:21:43.075
  Apr 19 13:21:43.077: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:21:45.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1372" for this suite. @ 04/19/23 13:21:45.637
• [2.580 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance]
test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 04/19/23 13:21:45.644
  Apr 19 13:21:45.644: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename events @ 04/19/23 13:21:45.645
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:21:45.658
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:21:45.661
  STEP: Create set of events @ 04/19/23 13:21:45.664
  STEP: get a list of Events with a label in the current namespace @ 04/19/23 13:21:45.677
  STEP: delete a list of events @ 04/19/23 13:21:45.68
  Apr 19 13:21:45.680: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 04/19/23 13:21:45.694
  Apr 19 13:21:45.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6022" for this suite. @ 04/19/23 13:21:45.7
• [0.061 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 04/19/23 13:21:45.706
  Apr 19 13:21:45.706: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename var-expansion @ 04/19/23 13:21:45.708
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:21:45.717
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:21:45.72
  STEP: Creating a pod to test env composition @ 04/19/23 13:21:45.722
  W0419 13:21:45.728308      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:21:47.737
  Apr 19 13:21:47.740: INFO: Trying to get logs from node talos-default-worker-2 pod var-expansion-a3dface7-97fa-43c5-99ab-372004184198 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/23 13:21:47.747
  Apr 19 13:21:47.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-7920" for this suite. @ 04/19/23 13:21:47.766
• [2.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]
test/e2e/apimachinery/resource_quota.go:101
  STEP: Creating a kubernetes client @ 04/19/23 13:21:47.782
  Apr 19 13:21:47.782: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename resourcequota @ 04/19/23 13:21:47.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:21:47.8
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:21:47.805
  STEP: Counting existing ResourceQuota @ 04/19/23 13:21:47.809
  STEP: Creating a ResourceQuota @ 04/19/23 13:21:52.816
  STEP: Ensuring resource quota status is calculated @ 04/19/23 13:21:52.821
  STEP: Creating a Service @ 04/19/23 13:21:54.827
  STEP: Creating a NodePort Service @ 04/19/23 13:21:54.851
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 04/19/23 13:21:54.881
  STEP: Ensuring resource quota status captures service creation @ 04/19/23 13:21:54.906
  STEP: Deleting Services @ 04/19/23 13:21:56.911
  STEP: Ensuring resource quota status released usage @ 04/19/23 13:21:56.957
  Apr 19 13:21:58.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4619" for this suite. @ 04/19/23 13:21:58.967
• [11.193 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]
test/e2e/apimachinery/webhook.go:284
  STEP: Creating a kubernetes client @ 04/19/23 13:21:58.982
  Apr 19 13:21:58.982: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 13:21:58.984
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:21:59
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:21:59.005
  STEP: Setting up server cert @ 04/19/23 13:21:59.028
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 13:21:59.454
  STEP: Deploying the webhook pod @ 04/19/23 13:21:59.466
  W0419 13:21:59.475994      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 13:21:59.476
  Apr 19 13:21:59.483: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/19/23 13:22:01.495
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 13:22:01.51
  Apr 19 13:22:02.513: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 13:22:02.517: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-992-crds.webhook.example.com via the AdmissionRegistration API @ 04/19/23 13:22:03.029
  STEP: Creating a custom resource that should be mutated by the webhook @ 04/19/23 13:22:03.046
  Apr 19 13:22:05.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6061" for this suite. @ 04/19/23 13:22:05.637
  STEP: Destroying namespace "webhook-markers-7255" for this suite. @ 04/19/23 13:22:05.644
• [6.671 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:109
  STEP: Creating a kubernetes client @ 04/19/23 13:22:05.655
  Apr 19 13:22:05.656: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 13:22:05.659
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:22:05.684
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:22:05.689
  STEP: Creating configMap with name configmap-test-volume-map-d91e90b0-1635-4011-84de-7870741356b0 @ 04/19/23 13:22:05.693
  STEP: Creating a pod to test consume configMaps @ 04/19/23 13:22:05.7
  W0419 13:22:05.711734      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:22:09.729
  Apr 19 13:22:09.733: INFO: Trying to get logs from node talos-default-worker-1 pod pod-configmaps-3a42d8c6-2344-4dc5-ad91-791e8c1a6ec4 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 13:22:09.74
  Apr 19 13:22:09.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8164" for this suite. @ 04/19/23 13:22:09.766
• [4.120 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]
test/e2e/apimachinery/resource_quota.go:693
  STEP: Creating a kubernetes client @ 04/19/23 13:22:09.78
  Apr 19 13:22:09.781: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename resourcequota @ 04/19/23 13:22:09.786
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:22:09.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:22:09.804
  STEP: Creating a ResourceQuota with terminating scope @ 04/19/23 13:22:09.808
  STEP: Ensuring ResourceQuota status is calculated @ 04/19/23 13:22:09.813
  STEP: Creating a ResourceQuota with not terminating scope @ 04/19/23 13:22:11.817
  STEP: Ensuring ResourceQuota status is calculated @ 04/19/23 13:22:11.823
  STEP: Creating a long running pod @ 04/19/23 13:22:13.828
  W0419 13:22:13.849467      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 04/19/23 13:22:13.85
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 04/19/23 13:22:15.856
  STEP: Deleting the pod @ 04/19/23 13:22:17.86
  STEP: Ensuring resource quota status released the pod usage @ 04/19/23 13:22:17.874
  STEP: Creating a terminating pod @ 04/19/23 13:22:19.878
  W0419 13:22:19.892085      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 04/19/23 13:22:19.892
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 04/19/23 13:22:21.897
  STEP: Deleting the pod @ 04/19/23 13:22:23.902
  STEP: Ensuring resource quota status released the pod usage @ 04/19/23 13:22:23.915
  Apr 19 13:22:25.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2020" for this suite. @ 04/19/23 13:22:25.925
• [16.152 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]
test/e2e/apps/replica_set.go:165
  STEP: Creating a kubernetes client @ 04/19/23 13:22:25.933
  Apr 19 13:22:25.933: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename replicaset @ 04/19/23 13:22:25.935
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:22:25.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:22:25.949
  STEP: Create a ReplicaSet @ 04/19/23 13:22:25.952
  W0419 13:22:25.961833      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Verify that the required pods have come up @ 04/19/23 13:22:25.961
  Apr 19 13:22:25.965: INFO: Pod name sample-pod: Found 0 pods out of 3
  Apr 19 13:22:30.972: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 04/19/23 13:22:30.975
  Apr 19 13:22:30.985: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 04/19/23 13:22:30.986
  STEP: DeleteCollection of the ReplicaSets @ 04/19/23 13:22:30.994
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 04/19/23 13:22:31.003
  Apr 19 13:22:31.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-7406" for this suite. @ 04/19/23 13:22:31.012
• [5.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 04/19/23 13:22:31.025
  Apr 19 13:22:31.025: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:22:31.026
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:22:31.037
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:22:31.039
  STEP: Creating configMap with name configmap-projected-all-test-volume-be52d6aa-bbbe-4ca8-9cd4-5361b707779d @ 04/19/23 13:22:31.041
  STEP: Creating secret with name secret-projected-all-test-volume-3b314146-fefe-4490-9753-bc7c55e2b023 @ 04/19/23 13:22:31.044
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 04/19/23 13:22:31.048
  W0419 13:22:31.054721      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-all-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-all-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-all-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-all-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:22:35.069
  Apr 19 13:22:35.073: INFO: Trying to get logs from node talos-default-worker-1 pod projected-volume-d749d3be-f546-4d1e-97ea-4349a873fd85 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 13:22:35.083
  Apr 19 13:22:35.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7623" for this suite. @ 04/19/23 13:22:35.104
• [4.089 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 04/19/23 13:22:35.114
  Apr 19 13:22:35.114: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pods @ 04/19/23 13:22:35.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:22:35.13
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:22:35.133
  STEP: Saw pod success @ 04/19/23 13:22:41.193
  Apr 19 13:22:41.197: INFO: Trying to get logs from node talos-default-worker-2 pod client-envvars-d5143f6a-5e10-4726-b259-1cd69e78ea61 container env3cont: <nil>
  STEP: delete the pod @ 04/19/23 13:22:41.204
  Apr 19 13:22:41.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2062" for this suite. @ 04/19/23 13:22:41.222
• [6.114 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 04/19/23 13:22:41.23
  Apr 19 13:22:41.230: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename events @ 04/19/23 13:22:41.23
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:22:41.249
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:22:41.252
  STEP: creating a test event @ 04/19/23 13:22:41.256
  STEP: listing events in all namespaces @ 04/19/23 13:22:41.26
  STEP: listing events in test namespace @ 04/19/23 13:22:41.264
  STEP: listing events with field selection filtering on source @ 04/19/23 13:22:41.266
  STEP: listing events with field selection filtering on reportingController @ 04/19/23 13:22:41.269
  STEP: getting the test event @ 04/19/23 13:22:41.27
  STEP: patching the test event @ 04/19/23 13:22:41.273
  STEP: getting the test event @ 04/19/23 13:22:41.28
  STEP: updating the test event @ 04/19/23 13:22:41.282
  STEP: getting the test event @ 04/19/23 13:22:41.287
  STEP: deleting the test event @ 04/19/23 13:22:41.29
  STEP: listing events in all namespaces @ 04/19/23 13:22:41.294
  STEP: listing events in test namespace @ 04/19/23 13:22:41.297
  Apr 19 13:22:41.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4684" for this suite. @ 04/19/23 13:22:41.302
• [0.077 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 04/19/23 13:22:41.31
  Apr 19 13:22:41.310: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/23 13:22:41.313
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:22:41.324
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:22:41.326
  W0419 13:22:41.332940      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "bin-false29de2c84-61b6-425b-a544-cac157455d64" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "bin-false29de2c84-61b6-425b-a544-cac157455d64" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "bin-false29de2c84-61b6-425b-a544-cac157455d64" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "bin-false29de2c84-61b6-425b-a544-cac157455d64" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:22:45.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6034" for this suite. @ 04/19/23 13:22:45.345
• [4.048 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]
test/e2e/apps/rc.go:424
  STEP: Creating a kubernetes client @ 04/19/23 13:22:45.36
  Apr 19 13:22:45.360: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename replication-controller @ 04/19/23 13:22:45.361
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:22:45.376
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:22:45.38
  STEP: Creating ReplicationController "e2e-rc-dhwv2" @ 04/19/23 13:22:45.384
  W0419 13:22:45.390099      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:22:45.390: INFO: Get Replication Controller "e2e-rc-dhwv2" to confirm replicas
  Apr 19 13:22:46.395: INFO: Get Replication Controller "e2e-rc-dhwv2" to confirm replicas
  Apr 19 13:22:46.399: INFO: Found 1 replicas for "e2e-rc-dhwv2" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-dhwv2" @ 04/19/23 13:22:46.399
  STEP: Updating a scale subresource @ 04/19/23 13:22:46.402
  STEP: Verifying replicas where modified for replication controller "e2e-rc-dhwv2" @ 04/19/23 13:22:46.407
  Apr 19 13:22:46.407: INFO: Get Replication Controller "e2e-rc-dhwv2" to confirm replicas
  Apr 19 13:22:47.411: INFO: Get Replication Controller "e2e-rc-dhwv2" to confirm replicas
  Apr 19 13:22:47.415: INFO: Found 2 replicas for "e2e-rc-dhwv2" replication controller
  Apr 19 13:22:47.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-6877" for this suite. @ 04/19/23 13:22:47.419
• [2.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 04/19/23 13:22:47.429
  Apr 19 13:22:47.430: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-probe @ 04/19/23 13:22:47.432
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:22:47.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:22:47.453
  W0419 13:22:47.462418      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:23:09.520: INFO: Container started at 2023-04-19 13:22:48 +0000 UTC, pod became ready at 2023-04-19 13:23:07 +0000 UTC
  Apr 19 13:23:09.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2900" for this suite. @ 04/19/23 13:23:09.524
• [22.101 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 04/19/23 13:23:09.536
  Apr 19 13:23:09.536: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 04/19/23 13:23:09.539
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:23:09.561
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:23:09.565
  STEP: Setting up the test @ 04/19/23 13:23:09.569
  STEP: Creating hostNetwork=false pod @ 04/19/23 13:23:09.569
  W0419 13:23:09.577956      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "busybox-1", "busybox-2", "busybox-3" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "busybox-1", "busybox-2", "busybox-3" must set securityContext.capabilities.drop=["ALL"]), restricted volume types (volume "host-etc-hosts" uses restricted volume type "hostPath"), runAsNonRoot != true (pod or containers "busybox-1", "busybox-2", "busybox-3" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "busybox-1", "busybox-2", "busybox-3" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Creating hostNetwork=true pod @ 04/19/23 13:23:11.591
  W0419 13:23:11.601834      20 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (containers "busybox-1", "busybox-2" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "busybox-1", "busybox-2" must set securityContext.capabilities.drop=["ALL"]), restricted volume types (volume "host-etc-hosts" uses restricted volume type "hostPath"), runAsNonRoot != true (pod or containers "busybox-1", "busybox-2" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "busybox-1", "busybox-2" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Running the test @ 04/19/23 13:23:13.614
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 04/19/23 13:23:13.614
  Apr 19 13:23:13.614: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9438 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:23:13.614: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:23:13.616: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:23:13.616: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9438/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 19 13:23:13.734: INFO: Exec stderr: ""
  Apr 19 13:23:13.734: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9438 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:23:13.734: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:23:13.735: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:23:13.736: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9438/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 19 13:23:13.848: INFO: Exec stderr: ""
  Apr 19 13:23:13.848: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9438 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:23:13.848: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:23:13.849: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:23:13.849: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9438/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 19 13:23:13.950: INFO: Exec stderr: ""
  Apr 19 13:23:13.950: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9438 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:23:13.950: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:23:13.950: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:23:13.951: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9438/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 19 13:23:14.045: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 04/19/23 13:23:14.045
  Apr 19 13:23:14.045: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9438 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:23:14.045: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:23:14.046: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:23:14.047: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9438/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Apr 19 13:23:14.131: INFO: Exec stderr: ""
  Apr 19 13:23:14.131: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9438 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:23:14.131: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:23:14.131: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:23:14.132: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9438/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Apr 19 13:23:14.222: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 04/19/23 13:23:14.222
  Apr 19 13:23:14.222: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9438 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:23:14.222: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:23:14.222: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:23:14.222: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9438/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 19 13:23:14.375: INFO: Exec stderr: ""
  Apr 19 13:23:14.375: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9438 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:23:14.375: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:23:14.375: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:23:14.375: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9438/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Apr 19 13:23:14.502: INFO: Exec stderr: ""
  Apr 19 13:23:14.503: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9438 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:23:14.503: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:23:14.507: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:23:14.507: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9438/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 19 13:23:14.634: INFO: Exec stderr: ""
  Apr 19 13:23:14.634: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9438 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:23:14.634: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:23:14.637: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:23:14.637: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-9438/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Apr 19 13:23:14.719: INFO: Exec stderr: ""
  Apr 19 13:23:14.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-9438" for this suite. @ 04/19/23 13:23:14.724
• [5.194 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance]
test/e2e/common/node/podtemplates.go:176
  STEP: Creating a kubernetes client @ 04/19/23 13:23:14.731
  Apr 19 13:23:14.731: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename podtemplate @ 04/19/23 13:23:14.733
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:23:14.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:23:14.747
  STEP: Create a pod template @ 04/19/23 13:23:14.749
  W0419 13:23:14.753591      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "e2e-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "e2e-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "e2e-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "e2e-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Replace a pod template @ 04/19/23 13:23:14.754
  W0419 13:23:14.761440      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "e2e-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "e2e-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "e2e-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "e2e-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:23:14.761: INFO: Found updated podtemplate annotation: "true"

  Apr 19 13:23:14.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-7185" for this suite. @ 04/19/23 13:23:14.766
• [0.041 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]
test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 04/19/23 13:23:14.772
  Apr 19 13:23:14.772: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 13:23:14.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:23:14.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:23:14.786
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-570 @ 04/19/23 13:23:14.788
  STEP: changing the ExternalName service to type=NodePort @ 04/19/23 13:23:14.792
  STEP: creating replication controller externalname-service in namespace services-570 @ 04/19/23 13:23:14.804
  W0419 13:23:14.810269      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "externalname-service" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "externalname-service" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "externalname-service" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "externalname-service" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  I0419 13:23:14.810645      20 runners.go:194] Created replication controller with name: externalname-service, namespace: services-570, replica count: 2
  I0419 13:23:17.861144      20 runners.go:194] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 13:23:17.861: INFO: Creating new exec pod
  W0419 13:23:17.870585      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:23:20.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-570 exec execpodpm2vm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Apr 19 13:23:21.105: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Apr 19 13:23:21.105: INFO: stdout: "externalname-service-mnj7b"
  Apr 19 13:23:21.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-570 exec execpodpm2vm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.107.93.34 80'
  Apr 19 13:23:21.326: INFO: stderr: "+ echo+ nc hostName\n -v -t -w 2 10.107.93.34 80\nConnection to 10.107.93.34 80 port [tcp/http] succeeded!\n"
  Apr 19 13:23:21.326: INFO: stdout: "externalname-service-mnj7b"
  Apr 19 13:23:21.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-570 exec execpodpm2vm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.0.5 31381'
  Apr 19 13:23:21.546: INFO: stderr: "+ nc -v -t -w 2 172.20.0.5 31381\nConnection to 172.20.0.5 31381 port [tcp/*] succeeded!\n+ echo hostName\n"
  Apr 19 13:23:21.546: INFO: stdout: ""
  Apr 19 13:23:22.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-570 exec execpodpm2vm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.0.5 31381'
  Apr 19 13:23:22.769: INFO: stderr: "+ nc -v -t -w 2 172.20.0.5 31381\n+ echo hostName\nConnection to 172.20.0.5 31381 port [tcp/*] succeeded!\n"
  Apr 19 13:23:22.769: INFO: stdout: "externalname-service-khbp6"
  Apr 19 13:23:22.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-570 exec execpodpm2vm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.0.6 31381'
  Apr 19 13:23:22.991: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.0.6 31381\nConnection to 172.20.0.6 31381 port [tcp/*] succeeded!\n"
  Apr 19 13:23:22.991: INFO: stdout: "externalname-service-mnj7b"
  Apr 19 13:23:22.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 19 13:23:22.997: INFO: Cleaning up the ExternalName to NodePort test service
  STEP: Destroying namespace "services-570" for this suite. @ 04/19/23 13:23:23.02
• [8.256 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]
test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 04/19/23 13:23:23.028
  Apr 19 13:23:23.028: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename proxy @ 04/19/23 13:23:23.029
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:23:23.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:23:23.046
  STEP: starting an echo server on multiple ports @ 04/19/23 13:23:23.056
  STEP: creating replication controller proxy-service-vxnrb in namespace proxy-2605 @ 04/19/23 13:23:23.056
  W0419 13:23:23.060832      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "proxy-service-vxnrb" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "proxy-service-vxnrb" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "proxy-service-vxnrb" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "proxy-service-vxnrb" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  I0419 13:23:23.060948      20 runners.go:194] Created replication controller with name: proxy-service-vxnrb, namespace: proxy-2605, replica count: 1
  I0419 13:23:24.111607      20 runners.go:194] proxy-service-vxnrb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  I0419 13:23:25.112629      20 runners.go:194] proxy-service-vxnrb Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 13:23:25.116: INFO: setup took 2.068358561s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 04/19/23 13:23:25.117
  Apr 19 13:23:25.124: INFO: (0) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 7.719289ms)
  Apr 19 13:23:25.125: INFO: (0) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 7.93227ms)
  Apr 19 13:23:25.126: INFO: (0) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 8.499685ms)
  Apr 19 13:23:25.126: INFO: (0) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 8.913923ms)
  Apr 19 13:23:25.127: INFO: (0) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 9.149186ms)
  Apr 19 13:23:25.127: INFO: (0) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 9.703536ms)
  Apr 19 13:23:25.133: INFO: (0) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 15.75851ms)
  Apr 19 13:23:25.133: INFO: (0) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 16.11014ms)
  Apr 19 13:23:25.134: INFO: (0) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 16.853056ms)
  Apr 19 13:23:25.134: INFO: (0) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 16.749351ms)
  Apr 19 13:23:25.134: INFO: (0) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 17.656786ms)
  Apr 19 13:23:25.135: INFO: (0) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 17.560575ms)
  Apr 19 13:23:25.136: INFO: (0) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 18.89395ms)
  Apr 19 13:23:25.137: INFO: (0) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 20.159948ms)
  Apr 19 13:23:25.138: INFO: (0) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 20.978415ms)
  Apr 19 13:23:25.139: INFO: (0) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 21.452575ms)
  Apr 19 13:23:25.144: INFO: (1) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 4.885296ms)
  Apr 19 13:23:25.144: INFO: (1) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 4.816597ms)
  Apr 19 13:23:25.145: INFO: (1) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 4.950107ms)
  Apr 19 13:23:25.145: INFO: (1) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 5.424468ms)
  Apr 19 13:23:25.145: INFO: (1) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 5.157298ms)
  Apr 19 13:23:25.146: INFO: (1) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 7.166311ms)
  Apr 19 13:23:25.147: INFO: (1) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 7.196347ms)
  Apr 19 13:23:25.147: INFO: (1) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 6.670861ms)
  Apr 19 13:23:25.147: INFO: (1) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 6.607662ms)
  Apr 19 13:23:25.149: INFO: (1) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 9.181006ms)
  Apr 19 13:23:25.149: INFO: (1) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 9.235679ms)
  Apr 19 13:23:25.149: INFO: (1) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 9.161119ms)
  Apr 19 13:23:25.149: INFO: (1) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 9.626603ms)
  Apr 19 13:23:25.149: INFO: (1) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 10.286141ms)
  Apr 19 13:23:25.149: INFO: (1) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 9.608127ms)
  Apr 19 13:23:25.150: INFO: (1) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 9.367877ms)
  Apr 19 13:23:25.154: INFO: (2) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 3.864189ms)
  Apr 19 13:23:25.155: INFO: (2) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 5.208564ms)
  Apr 19 13:23:25.157: INFO: (2) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 7.111358ms)
  Apr 19 13:23:25.157: INFO: (2) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 7.241712ms)
  Apr 19 13:23:25.158: INFO: (2) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 7.597851ms)
  Apr 19 13:23:25.158: INFO: (2) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 8.03374ms)
  Apr 19 13:23:25.158: INFO: (2) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 7.716033ms)
  Apr 19 13:23:25.158: INFO: (2) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 8.334245ms)
  Apr 19 13:23:25.158: INFO: (2) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 7.869611ms)
  Apr 19 13:23:25.158: INFO: (2) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 7.765636ms)
  Apr 19 13:23:25.158: INFO: (2) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 8.316001ms)
  Apr 19 13:23:25.158: INFO: (2) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 7.92718ms)
  Apr 19 13:23:25.158: INFO: (2) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 8.139448ms)
  Apr 19 13:23:25.158: INFO: (2) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 8.274152ms)
  Apr 19 13:23:25.158: INFO: (2) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 8.148586ms)
  Apr 19 13:23:25.158: INFO: (2) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 8.183531ms)
  Apr 19 13:23:25.164: INFO: (3) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 5.137632ms)
  Apr 19 13:23:25.164: INFO: (3) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 5.485795ms)
  Apr 19 13:23:25.164: INFO: (3) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 5.549133ms)
  Apr 19 13:23:25.164: INFO: (3) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 4.496635ms)
  Apr 19 13:23:25.164: INFO: (3) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 4.34986ms)
  Apr 19 13:23:25.164: INFO: (3) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 4.149614ms)
  Apr 19 13:23:25.164: INFO: (3) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 4.113136ms)
  Apr 19 13:23:25.164: INFO: (3) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 5.321255ms)
  Apr 19 13:23:25.164: INFO: (3) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 5.487909ms)
  Apr 19 13:23:25.167: INFO: (3) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 7.297528ms)
  Apr 19 13:23:25.167: INFO: (3) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 7.77233ms)
  Apr 19 13:23:25.167: INFO: (3) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 6.542209ms)
  Apr 19 13:23:25.168: INFO: (3) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 8.69908ms)
  Apr 19 13:23:25.168: INFO: (3) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 7.990399ms)
  Apr 19 13:23:25.168: INFO: (3) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 8.545231ms)
  Apr 19 13:23:25.168: INFO: (3) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 7.630724ms)
  Apr 19 13:23:25.174: INFO: (4) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 3.800608ms)
  Apr 19 13:23:25.175: INFO: (4) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 3.938728ms)
  Apr 19 13:23:25.175: INFO: (4) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 4.851514ms)
  Apr 19 13:23:25.175: INFO: (4) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 4.509201ms)
  Apr 19 13:23:25.176: INFO: (4) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 5.034096ms)
  Apr 19 13:23:25.179: INFO: (4) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 8.261218ms)
  Apr 19 13:23:25.179: INFO: (4) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 8.286266ms)
  Apr 19 13:23:25.179: INFO: (4) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 7.758073ms)
  Apr 19 13:23:25.179: INFO: (4) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 8.228877ms)
  Apr 19 13:23:25.179: INFO: (4) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 8.228656ms)
  Apr 19 13:23:25.180: INFO: (4) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 8.982683ms)
  Apr 19 13:23:25.180: INFO: (4) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 9.460921ms)
  Apr 19 13:23:25.180: INFO: (4) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 9.082951ms)
  Apr 19 13:23:25.180: INFO: (4) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 8.337571ms)
  Apr 19 13:23:25.180: INFO: (4) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 8.632045ms)
  Apr 19 13:23:25.180: INFO: (4) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 8.831439ms)
  Apr 19 13:23:25.184: INFO: (5) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 3.626341ms)
  Apr 19 13:23:25.185: INFO: (5) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 3.995014ms)
  Apr 19 13:23:25.185: INFO: (5) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 4.206722ms)
  Apr 19 13:23:25.186: INFO: (5) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 4.328741ms)
  Apr 19 13:23:25.186: INFO: (5) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 4.177468ms)
  Apr 19 13:23:25.188: INFO: (5) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 5.83012ms)
  Apr 19 13:23:25.188: INFO: (5) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 5.926573ms)
  Apr 19 13:23:25.188: INFO: (5) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 5.797009ms)
  Apr 19 13:23:25.188: INFO: (5) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 7.417432ms)
  Apr 19 13:23:25.188: INFO: (5) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 7.220793ms)
  Apr 19 13:23:25.188: INFO: (5) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 6.368612ms)
  Apr 19 13:23:25.193: INFO: (5) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 11.684839ms)
  Apr 19 13:23:25.194: INFO: (5) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 11.79726ms)
  Apr 19 13:23:25.194: INFO: (5) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 11.391638ms)
  Apr 19 13:23:25.194: INFO: (5) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 11.883672ms)
  Apr 19 13:23:25.194: INFO: (5) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 12.045015ms)
  Apr 19 13:23:25.198: INFO: (6) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 4.102575ms)
  Apr 19 13:23:25.198: INFO: (6) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 3.570938ms)
  Apr 19 13:23:25.198: INFO: (6) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 4.328811ms)
  Apr 19 13:23:25.199: INFO: (6) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 3.99809ms)
  Apr 19 13:23:25.199: INFO: (6) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 4.198927ms)
  Apr 19 13:23:25.200: INFO: (6) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 5.915531ms)
  Apr 19 13:23:25.200: INFO: (6) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 5.799845ms)
  Apr 19 13:23:25.200: INFO: (6) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 6.075131ms)
  Apr 19 13:23:25.201: INFO: (6) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 6.145723ms)
  Apr 19 13:23:25.201: INFO: (6) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 6.362632ms)
  Apr 19 13:23:25.201: INFO: (6) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 6.288873ms)
  Apr 19 13:23:25.202: INFO: (6) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 7.749927ms)
  Apr 19 13:23:25.202: INFO: (6) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 7.722236ms)
  Apr 19 13:23:25.202: INFO: (6) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 7.763263ms)
  Apr 19 13:23:25.202: INFO: (6) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 7.877136ms)
  Apr 19 13:23:25.202: INFO: (6) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 7.841971ms)
  Apr 19 13:23:25.206: INFO: (7) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 3.381923ms)
  Apr 19 13:23:25.208: INFO: (7) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 5.263296ms)
  Apr 19 13:23:25.209: INFO: (7) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 6.139723ms)
  Apr 19 13:23:25.209: INFO: (7) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 6.412915ms)
  Apr 19 13:23:25.209: INFO: (7) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 6.750951ms)
  Apr 19 13:23:25.209: INFO: (7) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 6.497816ms)
  Apr 19 13:23:25.209: INFO: (7) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 6.661142ms)
  Apr 19 13:23:25.210: INFO: (7) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 7.060442ms)
  Apr 19 13:23:25.210: INFO: (7) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 6.890242ms)
  Apr 19 13:23:25.210: INFO: (7) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 6.995089ms)
  Apr 19 13:23:25.210: INFO: (7) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 6.986453ms)
  Apr 19 13:23:25.210: INFO: (7) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 6.879973ms)
  Apr 19 13:23:25.210: INFO: (7) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 6.9047ms)
  Apr 19 13:23:25.211: INFO: (7) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 8.387023ms)
  Apr 19 13:23:25.211: INFO: (7) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 8.32646ms)
  Apr 19 13:23:25.210: INFO: (7) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 6.965895ms)
  Apr 19 13:23:25.217: INFO: (8) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 4.737358ms)
  Apr 19 13:23:25.217: INFO: (8) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 4.985444ms)
  Apr 19 13:23:25.218: INFO: (8) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 5.538974ms)
  Apr 19 13:23:25.218: INFO: (8) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 5.94146ms)
  Apr 19 13:23:25.218: INFO: (8) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 5.535478ms)
  Apr 19 13:23:25.218: INFO: (8) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 5.753257ms)
  Apr 19 13:23:25.218: INFO: (8) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 5.920501ms)
  Apr 19 13:23:25.218: INFO: (8) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 6.699064ms)
  Apr 19 13:23:25.218: INFO: (8) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 6.258635ms)
  Apr 19 13:23:25.220: INFO: (8) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 8.197238ms)
  Apr 19 13:23:25.220: INFO: (8) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 8.63467ms)
  Apr 19 13:23:25.220: INFO: (8) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 8.265165ms)
  Apr 19 13:23:25.220: INFO: (8) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 8.691205ms)
  Apr 19 13:23:25.220: INFO: (8) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 8.678391ms)
  Apr 19 13:23:25.221: INFO: (8) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 8.579485ms)
  Apr 19 13:23:25.221: INFO: (8) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 8.994035ms)
  Apr 19 13:23:25.227: INFO: (9) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 4.842566ms)
  Apr 19 13:23:25.227: INFO: (9) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 5.262645ms)
  Apr 19 13:23:25.229: INFO: (9) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 6.535896ms)
  Apr 19 13:23:25.229: INFO: (9) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 6.694825ms)
  Apr 19 13:23:25.229: INFO: (9) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 6.67621ms)
  Apr 19 13:23:25.229: INFO: (9) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 6.750049ms)
  Apr 19 13:23:25.229: INFO: (9) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 6.786928ms)
  Apr 19 13:23:25.229: INFO: (9) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 6.852762ms)
  Apr 19 13:23:25.229: INFO: (9) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 6.987414ms)
  Apr 19 13:23:25.229: INFO: (9) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 6.744839ms)
  Apr 19 13:23:25.229: INFO: (9) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 6.738927ms)
  Apr 19 13:23:25.229: INFO: (9) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 6.939093ms)
  Apr 19 13:23:25.229: INFO: (9) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 7.330148ms)
  Apr 19 13:23:25.229: INFO: (9) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 7.190225ms)
  Apr 19 13:23:25.229: INFO: (9) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 6.887027ms)
  Apr 19 13:23:25.229: INFO: (9) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 7.067205ms)
  Apr 19 13:23:25.232: INFO: (10) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 3.061189ms)
  Apr 19 13:23:25.234: INFO: (10) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 4.60485ms)
  Apr 19 13:23:25.234: INFO: (10) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 4.437425ms)
  Apr 19 13:23:25.234: INFO: (10) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 4.959666ms)
  Apr 19 13:23:25.234: INFO: (10) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 4.580986ms)
  Apr 19 13:23:25.235: INFO: (10) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 5.249591ms)
  Apr 19 13:23:25.235: INFO: (10) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 5.401526ms)
  Apr 19 13:23:25.235: INFO: (10) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 5.921272ms)
  Apr 19 13:23:25.236: INFO: (10) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 6.690828ms)
  Apr 19 13:23:25.237: INFO: (10) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 6.724732ms)
  Apr 19 13:23:25.237: INFO: (10) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 6.954293ms)
  Apr 19 13:23:25.237: INFO: (10) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 7.031118ms)
  Apr 19 13:23:25.237: INFO: (10) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 6.725693ms)
  Apr 19 13:23:25.237: INFO: (10) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 7.189144ms)
  Apr 19 13:23:25.237: INFO: (10) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 8.172291ms)
  Apr 19 13:23:25.237: INFO: (10) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 6.873871ms)
  Apr 19 13:23:25.243: INFO: (11) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 4.41343ms)
  Apr 19 13:23:25.244: INFO: (11) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 4.324553ms)
  Apr 19 13:23:25.244: INFO: (11) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 4.441232ms)
  Apr 19 13:23:25.244: INFO: (11) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 4.467942ms)
  Apr 19 13:23:25.244: INFO: (11) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 4.587598ms)
  Apr 19 13:23:25.244: INFO: (11) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 4.977029ms)
  Apr 19 13:23:25.244: INFO: (11) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 4.4932ms)
  Apr 19 13:23:25.244: INFO: (11) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 5.145284ms)
  Apr 19 13:23:25.247: INFO: (11) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 7.351008ms)
  Apr 19 13:23:25.247: INFO: (11) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 7.54371ms)
  Apr 19 13:23:25.247: INFO: (11) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 7.811843ms)
  Apr 19 13:23:25.247: INFO: (11) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 7.8473ms)
  Apr 19 13:23:25.247: INFO: (11) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 7.970842ms)
  Apr 19 13:23:25.247: INFO: (11) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 7.633668ms)
  Apr 19 13:23:25.247: INFO: (11) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 7.706856ms)
  Apr 19 13:23:25.247: INFO: (11) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 7.974809ms)
  Apr 19 13:23:25.252: INFO: (12) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 3.651129ms)
  Apr 19 13:23:25.254: INFO: (12) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 5.607603ms)
  Apr 19 13:23:25.254: INFO: (12) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 5.668928ms)
  Apr 19 13:23:25.255: INFO: (12) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 5.948143ms)
  Apr 19 13:23:25.255: INFO: (12) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 5.720595ms)
  Apr 19 13:23:25.255: INFO: (12) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 5.801568ms)
  Apr 19 13:23:25.255: INFO: (12) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 6.123493ms)
  Apr 19 13:23:25.255: INFO: (12) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 6.593526ms)
  Apr 19 13:23:25.255: INFO: (12) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 6.267252ms)
  Apr 19 13:23:25.256: INFO: (12) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 7.490419ms)
  Apr 19 13:23:25.257: INFO: (12) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 7.627388ms)
  Apr 19 13:23:25.258: INFO: (12) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 9.122214ms)
  Apr 19 13:23:25.258: INFO: (12) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 9.073774ms)
  Apr 19 13:23:25.258: INFO: (12) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 9.223726ms)
  Apr 19 13:23:25.258: INFO: (12) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 9.092449ms)
  Apr 19 13:23:25.258: INFO: (12) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 9.183952ms)
  Apr 19 13:23:25.263: INFO: (13) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 4.351073ms)
  Apr 19 13:23:25.263: INFO: (13) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 4.013821ms)
  Apr 19 13:23:25.263: INFO: (13) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 4.740635ms)
  Apr 19 13:23:25.264: INFO: (13) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 5.030739ms)
  Apr 19 13:23:25.266: INFO: (13) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 6.686942ms)
  Apr 19 13:23:25.266: INFO: (13) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 7.570089ms)
  Apr 19 13:23:25.266: INFO: (13) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 6.822917ms)
  Apr 19 13:23:25.266: INFO: (13) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 7.375294ms)
  Apr 19 13:23:25.266: INFO: (13) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 6.948021ms)
  Apr 19 13:23:25.267: INFO: (13) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 7.159699ms)
  Apr 19 13:23:25.267: INFO: (13) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 7.539592ms)
  Apr 19 13:23:25.268: INFO: (13) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 8.997501ms)
  Apr 19 13:23:25.268: INFO: (13) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 8.894638ms)
  Apr 19 13:23:25.268: INFO: (13) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 9.228284ms)
  Apr 19 13:23:25.269: INFO: (13) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 9.690874ms)
  Apr 19 13:23:25.269: INFO: (13) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 9.747259ms)
  Apr 19 13:23:25.275: INFO: (14) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 5.447692ms)
  Apr 19 13:23:25.275: INFO: (14) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 5.448394ms)
  Apr 19 13:23:25.275: INFO: (14) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 5.665812ms)
  Apr 19 13:23:25.275: INFO: (14) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 5.883071ms)
  Apr 19 13:23:25.275: INFO: (14) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 5.694215ms)
  Apr 19 13:23:25.275: INFO: (14) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 5.615597ms)
  Apr 19 13:23:25.275: INFO: (14) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 5.688785ms)
  Apr 19 13:23:25.275: INFO: (14) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 5.785937ms)
  Apr 19 13:23:25.276: INFO: (14) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 6.283843ms)
  Apr 19 13:23:25.276: INFO: (14) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 6.206658ms)
  Apr 19 13:23:25.276: INFO: (14) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 6.631926ms)
  Apr 19 13:23:25.276: INFO: (14) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 6.455445ms)
  Apr 19 13:23:25.278: INFO: (14) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 8.136494ms)
  Apr 19 13:23:25.278: INFO: (14) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 8.183781ms)
  Apr 19 13:23:25.278: INFO: (14) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 8.255317ms)
  Apr 19 13:23:25.278: INFO: (14) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 8.200594ms)
  Apr 19 13:23:25.283: INFO: (15) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 4.158771ms)
  Apr 19 13:23:25.285: INFO: (15) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 5.846021ms)
  Apr 19 13:23:25.285: INFO: (15) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 5.529857ms)
  Apr 19 13:23:25.285: INFO: (15) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 5.823499ms)
  Apr 19 13:23:25.285: INFO: (15) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 5.66437ms)
  Apr 19 13:23:25.286: INFO: (15) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 6.484842ms)
  Apr 19 13:23:25.286: INFO: (15) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 5.766903ms)
  Apr 19 13:23:25.286: INFO: (15) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 6.257724ms)
  Apr 19 13:23:25.286: INFO: (15) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 6.126899ms)
  Apr 19 13:23:25.287: INFO: (15) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 6.812185ms)
  Apr 19 13:23:25.287: INFO: (15) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 7.398277ms)
  Apr 19 13:23:25.287: INFO: (15) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 7.648668ms)
  Apr 19 13:23:25.288: INFO: (15) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 8.573152ms)
  Apr 19 13:23:25.288: INFO: (15) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 8.994345ms)
  Apr 19 13:23:25.288: INFO: (15) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 8.698129ms)
  Apr 19 13:23:25.288: INFO: (15) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 9.067573ms)
  Apr 19 13:23:25.293: INFO: (16) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 3.247519ms)
  Apr 19 13:23:25.293: INFO: (16) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 3.393003ms)
  Apr 19 13:23:25.294: INFO: (16) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 3.829073ms)
  Apr 19 13:23:25.295: INFO: (16) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 5.221709ms)
  Apr 19 13:23:25.298: INFO: (16) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 7.822734ms)
  Apr 19 13:23:25.298: INFO: (16) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 7.88443ms)
  Apr 19 13:23:25.298: INFO: (16) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 7.974729ms)
  Apr 19 13:23:25.298: INFO: (16) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 8.083584ms)
  Apr 19 13:23:25.298: INFO: (16) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 8.024803ms)
  Apr 19 13:23:25.298: INFO: (16) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 8.056883ms)
  Apr 19 13:23:25.298: INFO: (16) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 7.954782ms)
  Apr 19 13:23:25.298: INFO: (16) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 8.038929ms)
  Apr 19 13:23:25.299: INFO: (16) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 9.235487ms)
  Apr 19 13:23:25.300: INFO: (16) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 9.389958ms)
  Apr 19 13:23:25.301: INFO: (16) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 10.497518ms)
  Apr 19 13:23:25.301: INFO: (16) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 10.846444ms)
  Apr 19 13:23:25.308: INFO: (17) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 4.493751ms)
  Apr 19 13:23:25.310: INFO: (17) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 6.439215ms)
  Apr 19 13:23:25.310: INFO: (17) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 7.798148ms)
  Apr 19 13:23:25.310: INFO: (17) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 6.915761ms)
  Apr 19 13:23:25.310: INFO: (17) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 7.173896ms)
  Apr 19 13:23:25.310: INFO: (17) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 7.044893ms)
  Apr 19 13:23:25.311: INFO: (17) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 7.378089ms)
  Apr 19 13:23:25.311: INFO: (17) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 7.842351ms)
  Apr 19 13:23:25.311: INFO: (17) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 8.862077ms)
  Apr 19 13:23:25.311: INFO: (17) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 7.658166ms)
  Apr 19 13:23:25.311: INFO: (17) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 7.817253ms)
  Apr 19 13:23:25.311: INFO: (17) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 8.249415ms)
  Apr 19 13:23:25.312: INFO: (17) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 8.114513ms)
  Apr 19 13:23:25.312: INFO: (17) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 8.493624ms)
  Apr 19 13:23:25.312: INFO: (17) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 8.843582ms)
  Apr 19 13:23:25.312: INFO: (17) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 8.865933ms)
  Apr 19 13:23:25.316: INFO: (18) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 3.138715ms)
  Apr 19 13:23:25.317: INFO: (18) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 4.365159ms)
  Apr 19 13:23:25.317: INFO: (18) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 4.196884ms)
  Apr 19 13:23:25.318: INFO: (18) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 4.210969ms)
  Apr 19 13:23:25.318: INFO: (18) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 5.130467ms)
  Apr 19 13:23:25.318: INFO: (18) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 4.811558ms)
  Apr 19 13:23:25.319: INFO: (18) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 5.772742ms)
  Apr 19 13:23:25.319: INFO: (18) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 7.051415ms)
  Apr 19 13:23:25.319: INFO: (18) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 5.926182ms)
  Apr 19 13:23:25.319: INFO: (18) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 6.753285ms)
  Apr 19 13:23:25.319: INFO: (18) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 6.403027ms)
  Apr 19 13:23:25.319: INFO: (18) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 5.902096ms)
  Apr 19 13:23:25.320: INFO: (18) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 6.520988ms)
  Apr 19 13:23:25.320: INFO: (18) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 6.384282ms)
  Apr 19 13:23:25.320: INFO: (18) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 6.991984ms)
  Apr 19 13:23:25.320: INFO: (18) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 7.092882ms)
  Apr 19 13:23:25.325: INFO: (19) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">... (200; 4.251737ms)
  Apr 19 13:23:25.327: INFO: (19) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 5.487758ms)
  Apr 19 13:23:25.328: INFO: (19) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:462/proxy/: tls qux (200; 6.242236ms)
  Apr 19 13:23:25.328: INFO: (19) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:460/proxy/: tls baz (200; 6.490271ms)
  Apr 19 13:23:25.329: INFO: (19) /api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/https:proxy-service-vxnrb-c2fds:443/proxy/tlsrewritem... (200; 7.3681ms)
  Apr 19 13:23:25.330: INFO: (19) /api/v1/namespaces/proxy-2605/pods/http:proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 8.876243ms)
  Apr 19 13:23:25.330: INFO: (19) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds/proxy/rewriteme">test</a> (200; 8.198621ms)
  Apr 19 13:23:25.330: INFO: (19) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname2/proxy/: bar (200; 8.360173ms)
  Apr 19 13:23:25.330: INFO: (19) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname1/proxy/: foo (200; 8.40666ms)
  Apr 19 13:23:25.330: INFO: (19) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname1/proxy/: tls baz (200; 8.382886ms)
  Apr 19 13:23:25.330: INFO: (19) /api/v1/namespaces/proxy-2605/services/https:proxy-service-vxnrb:tlsportname2/proxy/: tls qux (200; 8.497351ms)
  Apr 19 13:23:25.330: INFO: (19) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/: <a href="/api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:1080/proxy/rewriteme">test<... (200; 8.502931ms)
  Apr 19 13:23:25.330: INFO: (19) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:160/proxy/: foo (200; 8.425275ms)
  Apr 19 13:23:25.330: INFO: (19) /api/v1/namespaces/proxy-2605/pods/proxy-service-vxnrb-c2fds:162/proxy/: bar (200; 8.382665ms)
  Apr 19 13:23:25.330: INFO: (19) /api/v1/namespaces/proxy-2605/services/proxy-service-vxnrb:portname1/proxy/: foo (200; 8.831369ms)
  Apr 19 13:23:25.331: INFO: (19) /api/v1/namespaces/proxy-2605/services/http:proxy-service-vxnrb:portname2/proxy/: bar (200; 9.544067ms)
  Apr 19 13:23:25.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController proxy-service-vxnrb in namespace proxy-2605, will wait for the garbage collector to delete the pods @ 04/19/23 13:23:25.335
  Apr 19 13:23:25.393: INFO: Deleting ReplicationController proxy-service-vxnrb took: 4.052933ms
  Apr 19 13:23:25.493: INFO: Terminating ReplicationController proxy-service-vxnrb pods took: 100.220882ms
  STEP: Destroying namespace "proxy-2605" for this suite. @ 04/19/23 13:23:27.894
• [4.874 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]
test/e2e/apimachinery/webhook.go:314
  STEP: Creating a kubernetes client @ 04/19/23 13:23:27.903
  Apr 19 13:23:27.903: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 13:23:27.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:23:27.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:23:27.924
  STEP: Setting up server cert @ 04/19/23 13:23:27.946
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 13:23:28.144
  STEP: Deploying the webhook pod @ 04/19/23 13:23:28.151
  W0419 13:23:28.158004      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 13:23:28.159
  Apr 19 13:23:28.164: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/19/23 13:23:30.174
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 13:23:30.191
  Apr 19 13:23:31.191: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 13:23:31.195: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5739-crds.webhook.example.com via the AdmissionRegistration API @ 04/19/23 13:23:31.711
  STEP: Creating a custom resource while v1 is storage version @ 04/19/23 13:23:31.726
  STEP: Patching Custom Resource Definition to set v2 as storage @ 04/19/23 13:23:33.756
  STEP: Patching the custom resource while v2 is storage version @ 04/19/23 13:23:33.762
  Apr 19 13:23:33.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-609" for this suite. @ 04/19/23 13:23:34.339
  STEP: Destroying namespace "webhook-markers-3349" for this suite. @ 04/19/23 13:23:34.344
• [6.449 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:168
  STEP: Creating a kubernetes client @ 04/19/23 13:23:34.352
  Apr 19 13:23:34.352: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/19/23 13:23:34.354
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:23:34.371
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:23:34.374
  STEP: create the container to handle the HTTPGet hook request. @ 04/19/23 13:23:34.381
  W0419 13:23:34.389562      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "container-handle-http-request", "container-handle-https-request" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "container-handle-http-request", "container-handle-https-request" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "container-handle-http-request", "container-handle-https-request" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "container-handle-http-request", "container-handle-https-request" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: create the pod with lifecycle hook @ 04/19/23 13:23:36.401
  W0419 13:23:36.407267      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-with-poststart-http-hook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-with-poststart-http-hook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-with-poststart-http-hook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-with-poststart-http-hook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: check poststart hook @ 04/19/23 13:23:38.422
  STEP: delete the pod with lifecycle hook @ 04/19/23 13:23:38.429
  Apr 19 13:23:40.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5096" for this suite. @ 04/19/23 13:23:40.449
• [6.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:131
  STEP: Creating a kubernetes client @ 04/19/23 13:23:40.462
  Apr 19 13:23:40.462: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 13:23:40.463
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:23:40.478
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:23:40.481
  STEP: Creating the pod @ 04/19/23 13:23:40.484
  W0419 13:23:40.498432      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:23:43.036: INFO: Successfully updated pod "labelsupdatef6b457f1-f6de-4fc8-9217-27e5f9c7197d"
  Apr 19 13:23:47.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5708" for this suite. @ 04/19/23 13:23:47.065
• [6.609 seconds]
------------------------------
S
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:129
  STEP: Creating a kubernetes client @ 04/19/23 13:23:47.071
  Apr 19 13:23:47.071: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename security-context @ 04/19/23 13:23:47.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:23:47.093
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:23:47.097
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/19/23 13:23:47.101
  W0419 13:23:47.110916      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:23:51.126
  Apr 19 13:23:51.129: INFO: Trying to get logs from node talos-default-worker-1 pod security-context-506a4176-03a7-45b5-bb2f-5cbcc9cf1d72 container test-container: <nil>
  STEP: delete the pod @ 04/19/23 13:23:51.136
  Apr 19 13:23:51.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-6243" for this suite. @ 04/19/23 13:23:51.158
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 04/19/23 13:23:51.171
  Apr 19 13:23:51.171: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename secrets @ 04/19/23 13:23:51.174
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:23:51.186
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:23:51.189
  STEP: Creating secret with name secret-test-cfe6e276-1c2b-4a6a-b6f6-049836d766d1 @ 04/19/23 13:23:51.192
  STEP: Creating a pod to test consume secrets @ 04/19/23 13:23:51.196
  W0419 13:23:51.203291      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:23:55.215
  Apr 19 13:23:55.219: INFO: Trying to get logs from node talos-default-worker-1 pod pod-secrets-31470845-2039-4f19-b610-8becd6d5c00b container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 13:23:55.227
  Apr 19 13:23:55.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6322" for this suite. @ 04/19/23 13:23:55.246
• [4.086 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 04/19/23 13:23:55.258
  Apr 19 13:23:55.258: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-probe @ 04/19/23 13:23:55.261
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:23:55.278
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:23:55.281
  STEP: Creating pod test-webserver-0335862f-7a65-4b6f-a84f-df4222317e86 in namespace container-probe-1318 @ 04/19/23 13:23:55.284
  W0419 13:23:55.293323      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:23:57.303: INFO: Started pod test-webserver-0335862f-7a65-4b6f-a84f-df4222317e86 in namespace container-probe-1318
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/23 13:23:57.303
  Apr 19 13:23:57.307: INFO: Initial restart count of pod test-webserver-0335862f-7a65-4b6f-a84f-df4222317e86 is 0
  Apr 19 13:27:57.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 13:27:57.869
  STEP: Destroying namespace "container-probe-1318" for this suite. @ 04/19/23 13:27:57.882
• [242.636 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:152
  STEP: Creating a kubernetes client @ 04/19/23 13:27:57.895
  Apr 19 13:27:57.895: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/19/23 13:27:57.896
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:27:57.909
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:27:57.911
  STEP: create the container to handle the HTTPGet hook request. @ 04/19/23 13:27:57.917
  W0419 13:27:57.925516      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "container-handle-http-request", "container-handle-https-request" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "container-handle-http-request", "container-handle-https-request" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "container-handle-http-request", "container-handle-https-request" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "container-handle-http-request", "container-handle-https-request" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: create the pod with lifecycle hook @ 04/19/23 13:27:59.938
  W0419 13:27:59.946920      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-with-prestop-exec-hook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-with-prestop-exec-hook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-with-prestop-exec-hook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-with-prestop-exec-hook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: delete the pod with lifecycle hook @ 04/19/23 13:28:01.96
  STEP: check prestop hook @ 04/19/23 13:28:03.978
  Apr 19 13:28:03.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-1802" for this suite. @ 04/19/23 13:28:04.003
• [6.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/configmap_volume.go:504
  STEP: Creating a kubernetes client @ 04/19/23 13:28:04.025
  Apr 19 13:28:04.025: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 13:28:04.026
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:28:04.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:28:04.045
  Apr 19 13:28:04.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-863" for this suite. @ 04/19/23 13:28:04.083
• [0.064 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance]
test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 04/19/23 13:28:04.089
  Apr 19 13:28:04.089: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 13:28:04.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:28:04.101
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:28:04.104
  STEP: creating service nodeport-test with type=NodePort in namespace services-1529 @ 04/19/23 13:28:04.106
  STEP: creating replication controller nodeport-test in namespace services-1529 @ 04/19/23 13:28:04.118
  W0419 13:28:04.125319      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nodeport-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nodeport-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nodeport-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nodeport-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  I0419 13:28:04.127395      20 runners.go:194] Created replication controller with name: nodeport-test, namespace: services-1529, replica count: 2
  I0419 13:28:07.178250      20 runners.go:194] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 13:28:07.178: INFO: Creating new exec pod
  W0419 13:28:07.187636      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:28:10.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1529 exec execpod98p67 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Apr 19 13:28:10.380: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Apr 19 13:28:10.380: INFO: stdout: "nodeport-test-pn9b8"
  Apr 19 13:28:10.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1529 exec execpod98p67 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.97.199.82 80'
  Apr 19 13:28:10.563: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.97.199.82 80\nConnection to 10.97.199.82 80 port [tcp/http] succeeded!\n"
  Apr 19 13:28:10.563: INFO: stdout: "nodeport-test-pn9b8"
  Apr 19 13:28:10.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1529 exec execpod98p67 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.0.5 32105'
  Apr 19 13:28:10.724: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.0.5 32105\nConnection to 172.20.0.5 32105 port [tcp/*] succeeded!\n"
  Apr 19 13:28:10.724: INFO: stdout: ""
  Apr 19 13:28:11.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1529 exec execpod98p67 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.0.5 32105'
  Apr 19 13:28:11.916: INFO: stderr: "+ nc -v -t -w 2 172.20.0.5 32105\n+ echo hostName\nConnection to 172.20.0.5 32105 port [tcp/*] succeeded!\n"
  Apr 19 13:28:11.916: INFO: stdout: ""
  Apr 19 13:28:12.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1529 exec execpod98p67 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.0.5 32105'
  Apr 19 13:28:12.935: INFO: stderr: "+ nc -v -t -w 2 172.20.0.5 32105\n+ echo hostName\nConnection to 172.20.0.5 32105 port [tcp/*] succeeded!\n"
  Apr 19 13:28:12.935: INFO: stdout: "nodeport-test-pn9b8"
  Apr 19 13:28:12.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1529 exec execpod98p67 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.0.6 32105'
  Apr 19 13:28:13.108: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.0.6 32105\nConnection to 172.20.0.6 32105 port [tcp/*] succeeded!\n"
  Apr 19 13:28:13.108: INFO: stdout: "nodeport-test-v2r8w"
  Apr 19 13:28:13.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1529" for this suite. @ 04/19/23 13:28:13.113
• [9.030 seconds]
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance]
test/e2e/network/service.go:3113
  STEP: Creating a kubernetes client @ 04/19/23 13:28:13.119
  Apr 19 13:28:13.119: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 13:28:13.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:28:13.138
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:28:13.141
  STEP: fetching services @ 04/19/23 13:28:13.143
  Apr 19 13:28:13.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6987" for this suite. @ 04/19/23 13:28:13.151
• [0.037 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]
test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 04/19/23 13:28:13.16
  Apr 19 13:28:13.160: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename deployment @ 04/19/23 13:28:13.162
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:28:13.175
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:28:13.177
  STEP: creating a Deployment @ 04/19/23 13:28:13.183
  W0419 13:28:13.188427      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-deployment" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-deployment" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-deployment" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-deployment" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: waiting for Deployment to be created @ 04/19/23 13:28:13.188
  STEP: waiting for all Replicas to be Ready @ 04/19/23 13:28:13.191
  Apr 19 13:28:13.193: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 13:28:13.193: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 13:28:13.197: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 13:28:13.197: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 13:28:13.204: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 13:28:13.204: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 13:28:13.219: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 13:28:13.219: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Apr 19 13:28:14.176: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Apr 19 13:28:14.176: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Apr 19 13:28:14.399: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 04/19/23 13:28:14.399
  W0419 13:28:14.407318      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  W0419 13:28:14.407349      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-deployment" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-deployment" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-deployment" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-deployment" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:28:14.408: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 04/19/23 13:28:14.409
  Apr 19 13:28:14.410: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0
  Apr 19 13:28:14.410: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0
  Apr 19 13:28:14.411: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0
  Apr 19 13:28:14.411: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0
  Apr 19 13:28:14.411: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0
  Apr 19 13:28:14.411: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0
  Apr 19 13:28:14.411: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0
  Apr 19 13:28:14.412: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 0
  Apr 19 13:28:14.412: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1
  Apr 19 13:28:14.412: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1
  Apr 19 13:28:14.412: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2
  Apr 19 13:28:14.412: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2
  Apr 19 13:28:14.412: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2
  Apr 19 13:28:14.413: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2
  Apr 19 13:28:14.419: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2
  Apr 19 13:28:14.419: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2
  Apr 19 13:28:14.429: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2
  Apr 19 13:28:14.429: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2
  Apr 19 13:28:14.435: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1
  Apr 19 13:28:14.435: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1
  Apr 19 13:28:14.448: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1
  Apr 19 13:28:14.448: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1
  Apr 19 13:28:15.194: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2
  Apr 19 13:28:15.194: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2
  Apr 19 13:28:15.211: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1
  STEP: listing Deployments @ 04/19/23 13:28:15.211
  Apr 19 13:28:15.214: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 04/19/23 13:28:15.214
  W0419 13:28:15.222760      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-deployment" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-deployment" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-deployment" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-deployment" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:28:15.224: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 04/19/23 13:28:15.224
  Apr 19 13:28:15.230: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 13:28:15.232: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 13:28:15.241: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 13:28:15.251: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 13:28:15.260: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 13:28:16.196: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 13:28:16.206: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 13:28:16.217: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 13:28:16.222: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Apr 19 13:28:17.432: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 04/19/23 13:28:17.447
  STEP: fetching the DeploymentStatus @ 04/19/23 13:28:17.453
  Apr 19 13:28:17.457: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1
  Apr 19 13:28:17.457: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1
  Apr 19 13:28:17.457: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1
  Apr 19 13:28:17.457: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1
  Apr 19 13:28:17.457: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 1
  Apr 19 13:28:17.457: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2
  Apr 19 13:28:17.458: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2
  Apr 19 13:28:17.458: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2
  Apr 19 13:28:17.458: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 2
  Apr 19 13:28:17.458: INFO: observed Deployment test-deployment in namespace deployment-6590 with ReadyReplicas 3
  STEP: deleting the Deployment @ 04/19/23 13:28:17.458
  Apr 19 13:28:17.465: INFO: observed event type MODIFIED
  Apr 19 13:28:17.465: INFO: observed event type MODIFIED
  Apr 19 13:28:17.465: INFO: observed event type MODIFIED
  Apr 19 13:28:17.466: INFO: observed event type MODIFIED
  Apr 19 13:28:17.466: INFO: observed event type MODIFIED
  Apr 19 13:28:17.466: INFO: observed event type MODIFIED
  Apr 19 13:28:17.466: INFO: observed event type MODIFIED
  Apr 19 13:28:17.466: INFO: observed event type MODIFIED
  Apr 19 13:28:17.467: INFO: observed event type MODIFIED
  Apr 19 13:28:17.467: INFO: observed event type MODIFIED
  Apr 19 13:28:17.467: INFO: observed event type MODIFIED
  Apr 19 13:28:17.470: INFO: Log out all the ReplicaSets if there is no deployment created
  Apr 19 13:28:17.474: INFO: ReplicaSet "test-deployment-58db457f5f":
  &ReplicaSet{ObjectMeta:{test-deployment-58db457f5f  deployment-6590  1f39aa4a-eadb-4a7f-a2b9-f32a49e9a1bb 194677 3 2023-04-19 13:28:13 +0000 UTC <nil> <nil> map[pod-template-hash:58db457f5f test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 6beee919-555a-43af-ad65-fce113d93fa3 0xc004b27947 0xc004b27948}] [] [{kube-controller-manager Update apps/v1 2023-04-19 13:28:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6beee919-555a-43af-ad65-fce113d93fa3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:28:15 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 58db457f5f,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:58db457f5f test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004b279d0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

  Apr 19 13:28:17.478: INFO: ReplicaSet "test-deployment-5b5dcbcd95":
  &ReplicaSet{ObjectMeta:{test-deployment-5b5dcbcd95  deployment-6590  e15c7614-9b24-467a-bf0e-4ccb8277ae2c 194759 4 2023-04-19 13:28:14 +0000 UTC <nil> <nil> map[pod-template-hash:5b5dcbcd95 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 6beee919-555a-43af-ad65-fce113d93fa3 0xc004b27a37 0xc004b27a38}] [] [{kube-controller-manager Update apps/v1 2023-04-19 13:28:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6beee919-555a-43af-ad65-fce113d93fa3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:28:17 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 5b5dcbcd95,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:5b5dcbcd95 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.9 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004b27ac0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

  Apr 19 13:28:17.482: INFO: pod: "test-deployment-5b5dcbcd95-pgpbt":
  &Pod{ObjectMeta:{test-deployment-5b5dcbcd95-pgpbt test-deployment-5b5dcbcd95- deployment-6590  e40e813a-8c7a-426c-863d-2775c693c38a 194755 0 2023-04-19 13:28:14 +0000 UTC 2023-04-19 13:28:18 +0000 UTC 0xc003f020c8 map[pod-template-hash:5b5dcbcd95 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-5b5dcbcd95 e15c7614-9b24-467a-bf0e-4ccb8277ae2c 0xc003f020f7 0xc003f020f8}] [] [{kube-controller-manager Update v1 2023-04-19 13:28:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e15c7614-9b24-467a-bf0e-4ccb8277ae2c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:28:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.3.181\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5wwmj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.9,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5wwmj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:28:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:28:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:28:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:28:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:10.244.3.181,StartTime:2023-04-19 13:28:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:28:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.9,ImageID:registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097,ContainerID:containerd://8c5491fb6b8053e8c4c37ee50cefb7541f0cc2b7de16a64f26f50c3275913a5f,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.181,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}

  Apr 19 13:28:17.483: INFO: ReplicaSet "test-deployment-6fc78d85c6":
  &ReplicaSet{ObjectMeta:{test-deployment-6fc78d85c6  deployment-6590  fbbad10c-e1c0-4a05-a027-be95031c73b8 194751 2 2023-04-19 13:28:15 +0000 UTC <nil> <nil> map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 6beee919-555a-43af-ad65-fce113d93fa3 0xc004b27b27 0xc004b27b28}] [] [{kube-controller-manager Update apps/v1 2023-04-19 13:28:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6beee919-555a-43af-ad65-fce113d93fa3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:28:17 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 6fc78d85c6,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004b27bb0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

  Apr 19 13:28:17.487: INFO: pod: "test-deployment-6fc78d85c6-6fkfs":
  &Pod{ObjectMeta:{test-deployment-6fc78d85c6-6fkfs test-deployment-6fc78d85c6- deployment-6590  e44a0f17-23a9-4cf9-bc64-e77c522b6871 194766 0 2023-04-19 13:28:16 +0000 UTC 2023-04-19 13:28:18 +0000 UTC 0xc003f02cf8 map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-6fc78d85c6 fbbad10c-e1c0-4a05-a027-be95031c73b8 0xc003f02d27 0xc003f02d28}] [] [{kube-controller-manager Update v1 2023-04-19 13:28:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fbbad10c-e1c0-4a05-a027-be95031c73b8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:28:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.147\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nkskx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nkskx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:28:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:28:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:28:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:28:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.6,PodIP:10.244.1.147,StartTime:2023-04-19 13:28:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:28:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://e110fa199e45bdb2f45e812be471898b926842747b2be2b8773fb67deab830c5,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.147,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}

  Apr 19 13:28:17.487: INFO: pod: "test-deployment-6fc78d85c6-j9n2g":
  &Pod{ObjectMeta:{test-deployment-6fc78d85c6-j9n2g test-deployment-6fc78d85c6- deployment-6590  adf634c7-153f-45b3-8694-2a1055030e89 194765 0 2023-04-19 13:28:15 +0000 UTC 2023-04-19 13:28:18 +0000 UTC 0xc003f02ee0 map[pod-template-hash:6fc78d85c6 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-6fc78d85c6 fbbad10c-e1c0-4a05-a027-be95031c73b8 0xc003f02f17 0xc003f02f18}] [] [{kube-controller-manager Update v1 2023-04-19 13:28:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fbbad10c-e1c0-4a05-a027-be95031c73b8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:28:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.3.182\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m557g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m557g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:28:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:28:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:28:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:28:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:10.244.3.182,StartTime:2023-04-19 13:28:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:28:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://05b574d6be2b6248a99c2affd3d781c04c8e49e60e2f892b69e25aaf834f11c1,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.182,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}

  Apr 19 13:28:17.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-6590" for this suite. @ 04/19/23 13:28:17.492
• [4.336 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2202
  STEP: Creating a kubernetes client @ 04/19/23 13:28:17.499
  Apr 19 13:28:17.499: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 13:28:17.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:28:17.51
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:28:17.512
  STEP: creating service in namespace services-1108 @ 04/19/23 13:28:17.514
  STEP: creating service affinity-nodeport in namespace services-1108 @ 04/19/23 13:28:17.514
  STEP: creating replication controller affinity-nodeport in namespace services-1108 @ 04/19/23 13:28:17.526
  W0419 13:28:17.531451      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-nodeport" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-nodeport" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-nodeport" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-nodeport" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  I0419 13:28:17.532964      20 runners.go:194] Created replication controller with name: affinity-nodeport, namespace: services-1108, replica count: 3
  I0419 13:28:20.583692      20 runners.go:194] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 13:28:20.592: INFO: Creating new exec pod
  W0419 13:28:20.597840      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:28:23.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1108 exec execpod-affinityx5gv4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  Apr 19 13:28:23.850: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Apr 19 13:28:23.850: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 13:28:23.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1108 exec execpod-affinityx5gv4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.104.128.245 80'
  Apr 19 13:28:24.067: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.104.128.245 80\nConnection to 10.104.128.245 80 port [tcp/http] succeeded!\n"
  Apr 19 13:28:24.067: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 13:28:24.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1108 exec execpod-affinityx5gv4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.0.5 32250'
  Apr 19 13:28:24.286: INFO: stderr: "+ nc -v -t -w 2 172.20.0.5 32250\nConnection to 172.20.0.5 32250 port [tcp/*] succeeded!\n+ echo hostName\n"
  Apr 19 13:28:24.286: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 13:28:24.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1108 exec execpod-affinityx5gv4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.0.6 32250'
  Apr 19 13:28:24.449: INFO: stderr: "+ nc -v -t -w 2 172.20.0.6 32250\n+ echo hostName\nConnection to 172.20.0.6 32250 port [tcp/*] succeeded!\n"
  Apr 19 13:28:24.449: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 13:28:24.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1108 exec execpod-affinityx5gv4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.20.0.5:32250/ ; done'
  Apr 19 13:28:24.677: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32250/\n"
  Apr 19 13:28:24.677: INFO: stdout: "\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5\naffinity-nodeport-cvwg5"
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Received response from host: affinity-nodeport-cvwg5
  Apr 19 13:28:24.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 19 13:28:24.682: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-1108, will wait for the garbage collector to delete the pods @ 04/19/23 13:28:24.694
  Apr 19 13:28:24.754: INFO: Deleting ReplicationController affinity-nodeport took: 6.500571ms
  Apr 19 13:28:24.855: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.437388ms
  STEP: Destroying namespace "services-1108" for this suite. @ 04/19/23 13:28:26.577
• [9.083 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]
test/e2e/storage/subpath.go:70
  STEP: Creating a kubernetes client @ 04/19/23 13:28:26.583
  Apr 19 13:28:26.584: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename subpath @ 04/19/23 13:28:26.585
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:28:26.598
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:28:26.6
  STEP: Setting up data @ 04/19/23 13:28:26.602
  STEP: Creating pod pod-subpath-test-configmap-dc6f @ 04/19/23 13:28:26.608
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/23 13:28:26.608
  W0419 13:28:26.615452      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-configmap-dc6f" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-configmap-dc6f" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-configmap-dc6f" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-configmap-dc6f" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:28:48.669
  Apr 19 13:28:48.673: INFO: Trying to get logs from node talos-default-worker-1 pod pod-subpath-test-configmap-dc6f container test-container-subpath-configmap-dc6f: <nil>
  STEP: delete the pod @ 04/19/23 13:28:48.68
  STEP: Deleting pod pod-subpath-test-configmap-dc6f @ 04/19/23 13:28:48.693
  Apr 19 13:28:48.693: INFO: Deleting pod "pod-subpath-test-configmap-dc6f" in namespace "subpath-8221"
  Apr 19 13:28:48.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-8221" for this suite. @ 04/19/23 13:28:48.701
• [22.124 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:523
  STEP: Creating a kubernetes client @ 04/19/23 13:28:48.71
  Apr 19 13:28:48.710: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-probe @ 04/19/23 13:28:48.714
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:28:48.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:28:48.733
  STEP: Creating pod test-grpc-e2b2fbcd-b43b-404e-93e5-e2c8e046245e in namespace container-probe-9082 @ 04/19/23 13:28:48.736
  W0419 13:28:48.743446      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:28:50.758: INFO: Started pod test-grpc-e2b2fbcd-b43b-404e-93e5-e2c8e046245e in namespace container-probe-9082
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/23 13:28:50.758
  Apr 19 13:28:50.761: INFO: Initial restart count of pod test-grpc-e2b2fbcd-b43b-404e-93e5-e2c8e046245e is 0
  Apr 19 13:32:51.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 13:32:51.322
  STEP: Destroying namespace "container-probe-9082" for this suite. @ 04/19/23 13:32:51.335
• [242.636 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]
test/e2e/apps/daemon_set.go:864
  STEP: Creating a kubernetes client @ 04/19/23 13:32:51.35
  Apr 19 13:32:51.350: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename daemonsets @ 04/19/23 13:32:51.352
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:32:51.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:32:51.37
  STEP: Creating simple DaemonSet "daemon-set" @ 04/19/23 13:32:51.391
  W0419 13:32:51.397252      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/23 13:32:51.397
  Apr 19 13:32:51.402: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:32:51.402: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:32:51.402: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:32:51.404: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:32:51.404: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:32:52.409: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:32:52.409: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:32:52.409: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:32:52.412: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:32:52.412: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:32:53.411: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:32:53.411: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:32:53.411: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:32:53.415: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 13:32:53.415: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Getting /status @ 04/19/23 13:32:53.42
  Apr 19 13:32:53.424: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 04/19/23 13:32:53.424
  Apr 19 13:32:53.434: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 04/19/23 13:32:53.434
  Apr 19 13:32:53.436: INFO: Observed &DaemonSet event: ADDED
  Apr 19 13:32:53.437: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 13:32:53.437: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 13:32:53.438: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 13:32:53.438: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 13:32:53.439: INFO: Found daemon set daemon-set in namespace daemonsets-9358 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 19 13:32:53.439: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 04/19/23 13:32:53.439
  STEP: watching for the daemon set status to be patched @ 04/19/23 13:32:53.446
  Apr 19 13:32:53.449: INFO: Observed &DaemonSet event: ADDED
  Apr 19 13:32:53.450: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 13:32:53.451: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 13:32:53.452: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 13:32:53.453: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 13:32:53.453: INFO: Observed daemon set daemon-set in namespace daemonsets-9358 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 19 13:32:53.454: INFO: Observed &DaemonSet event: MODIFIED
  Apr 19 13:32:53.454: INFO: Found daemon set daemon-set in namespace daemonsets-9358 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Apr 19 13:32:53.455: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/23 13:32:53.46
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9358, will wait for the garbage collector to delete the pods @ 04/19/23 13:32:53.46
  Apr 19 13:32:53.519: INFO: Deleting DaemonSet.extensions daemon-set took: 5.955426ms
  Apr 19 13:32:53.620: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.845967ms
  Apr 19 13:32:56.024: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:32:56.024: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 19 13:32:56.028: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"195671"},"items":null}

  Apr 19 13:32:56.031: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"195671"},"items":null}

  Apr 19 13:32:56.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9358" for this suite. @ 04/19/23 13:32:56.047
• [4.703 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]
test/e2e/apimachinery/discovery.go:122
  STEP: Creating a kubernetes client @ 04/19/23 13:32:56.059
  Apr 19 13:32:56.059: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename discovery @ 04/19/23 13:32:56.059
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:32:56.078
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:32:56.082
  STEP: Setting up server cert @ 04/19/23 13:32:56.086
  Apr 19 13:32:56.294: INFO: Checking APIGroup: apiregistration.k8s.io
  Apr 19 13:32:56.296: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Apr 19 13:32:56.296: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Apr 19 13:32:56.296: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Apr 19 13:32:56.296: INFO: Checking APIGroup: apps
  Apr 19 13:32:56.298: INFO: PreferredVersion.GroupVersion: apps/v1
  Apr 19 13:32:56.299: INFO: Versions found [{apps/v1 v1}]
  Apr 19 13:32:56.299: INFO: apps/v1 matches apps/v1
  Apr 19 13:32:56.299: INFO: Checking APIGroup: events.k8s.io
  Apr 19 13:32:56.301: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Apr 19 13:32:56.301: INFO: Versions found [{events.k8s.io/v1 v1}]
  Apr 19 13:32:56.301: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Apr 19 13:32:56.301: INFO: Checking APIGroup: authentication.k8s.io
  Apr 19 13:32:56.302: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Apr 19 13:32:56.302: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  Apr 19 13:32:56.302: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Apr 19 13:32:56.302: INFO: Checking APIGroup: authorization.k8s.io
  Apr 19 13:32:56.304: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Apr 19 13:32:56.304: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Apr 19 13:32:56.304: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Apr 19 13:32:56.304: INFO: Checking APIGroup: autoscaling
  Apr 19 13:32:56.305: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Apr 19 13:32:56.305: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Apr 19 13:32:56.305: INFO: autoscaling/v2 matches autoscaling/v2
  Apr 19 13:32:56.305: INFO: Checking APIGroup: batch
  Apr 19 13:32:56.307: INFO: PreferredVersion.GroupVersion: batch/v1
  Apr 19 13:32:56.307: INFO: Versions found [{batch/v1 v1}]
  Apr 19 13:32:56.308: INFO: batch/v1 matches batch/v1
  Apr 19 13:32:56.308: INFO: Checking APIGroup: certificates.k8s.io
  Apr 19 13:32:56.309: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Apr 19 13:32:56.310: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Apr 19 13:32:56.310: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Apr 19 13:32:56.310: INFO: Checking APIGroup: networking.k8s.io
  Apr 19 13:32:56.312: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Apr 19 13:32:56.312: INFO: Versions found [{networking.k8s.io/v1 v1}]
  Apr 19 13:32:56.312: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Apr 19 13:32:56.312: INFO: Checking APIGroup: policy
  Apr 19 13:32:56.314: INFO: PreferredVersion.GroupVersion: policy/v1
  Apr 19 13:32:56.314: INFO: Versions found [{policy/v1 v1}]
  Apr 19 13:32:56.314: INFO: policy/v1 matches policy/v1
  Apr 19 13:32:56.314: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Apr 19 13:32:56.316: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Apr 19 13:32:56.316: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Apr 19 13:32:56.317: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Apr 19 13:32:56.317: INFO: Checking APIGroup: storage.k8s.io
  Apr 19 13:32:56.323: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Apr 19 13:32:56.323: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Apr 19 13:32:56.323: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Apr 19 13:32:56.323: INFO: Checking APIGroup: admissionregistration.k8s.io
  Apr 19 13:32:56.325: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Apr 19 13:32:56.325: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  Apr 19 13:32:56.325: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Apr 19 13:32:56.325: INFO: Checking APIGroup: apiextensions.k8s.io
  Apr 19 13:32:56.327: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Apr 19 13:32:56.327: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Apr 19 13:32:56.327: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Apr 19 13:32:56.327: INFO: Checking APIGroup: scheduling.k8s.io
  Apr 19 13:32:56.329: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Apr 19 13:32:56.329: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Apr 19 13:32:56.330: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Apr 19 13:32:56.331: INFO: Checking APIGroup: coordination.k8s.io
  Apr 19 13:32:56.332: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Apr 19 13:32:56.332: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Apr 19 13:32:56.332: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Apr 19 13:32:56.332: INFO: Checking APIGroup: node.k8s.io
  Apr 19 13:32:56.334: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Apr 19 13:32:56.334: INFO: Versions found [{node.k8s.io/v1 v1}]
  Apr 19 13:32:56.334: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Apr 19 13:32:56.334: INFO: Checking APIGroup: discovery.k8s.io
  Apr 19 13:32:56.335: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Apr 19 13:32:56.336: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Apr 19 13:32:56.336: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Apr 19 13:32:56.336: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Apr 19 13:32:56.337: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta3
  Apr 19 13:32:56.337: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta3 v1beta3} {flowcontrol.apiserver.k8s.io/v1beta2 v1beta2}]
  Apr 19 13:32:56.337: INFO: flowcontrol.apiserver.k8s.io/v1beta3 matches flowcontrol.apiserver.k8s.io/v1beta3
  Apr 19 13:32:56.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-3286" for this suite. @ 04/19/23 13:32:56.341
• [0.288 seconds]
------------------------------
SSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]
test/e2e/scheduling/limit_range.go:239
  STEP: Creating a kubernetes client @ 04/19/23 13:32:56.347
  Apr 19 13:32:56.347: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename limitrange @ 04/19/23 13:32:56.348
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:32:56.36
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:32:56.363
  STEP: Creating LimitRange "e2e-limitrange-47476" in namespace "limitrange-2731" @ 04/19/23 13:32:56.365
  STEP: Creating another limitRange in another namespace @ 04/19/23 13:32:56.369
  Apr 19 13:32:56.379: INFO: Namespace "e2e-limitrange-47476-2949" created
  Apr 19 13:32:56.379: INFO: Creating LimitRange "e2e-limitrange-47476" in namespace "e2e-limitrange-47476-2949"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-47476" @ 04/19/23 13:32:56.383
  Apr 19 13:32:56.386: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-47476" in "limitrange-2731" namespace @ 04/19/23 13:32:56.387
  Apr 19 13:32:56.393: INFO: LimitRange "e2e-limitrange-47476" has been patched
  STEP: Delete LimitRange "e2e-limitrange-47476" by Collection with labelSelector: "e2e-limitrange-47476=patched" @ 04/19/23 13:32:56.393
  STEP: Confirm that the limitRange "e2e-limitrange-47476" has been deleted @ 04/19/23 13:32:56.399
  Apr 19 13:32:56.399: INFO: Requesting list of LimitRange to confirm quantity
  Apr 19 13:32:56.402: INFO: Found 0 LimitRange with label "e2e-limitrange-47476=patched"
  Apr 19 13:32:56.402: INFO: LimitRange "e2e-limitrange-47476" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-47476" @ 04/19/23 13:32:56.402
  Apr 19 13:32:56.404: INFO: Found 1 limitRange
  Apr 19 13:32:56.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-2731" for this suite. @ 04/19/23 13:32:56.408
  STEP: Destroying namespace "e2e-limitrange-47476-2949" for this suite. @ 04/19/23 13:32:56.413
• [0.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]
test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 04/19/23 13:32:56.419
  Apr 19 13:32:56.419: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename watch @ 04/19/23 13:32:56.421
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:32:56.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:32:56.433
  STEP: getting a starting resourceVersion @ 04/19/23 13:32:56.435
  STEP: starting a background goroutine to produce watch events @ 04/19/23 13:32:56.438
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 04/19/23 13:32:56.438
  Apr 19 13:32:59.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-338" for this suite. @ 04/19/23 13:32:59.275
• [2.914 seconds]
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]
test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 04/19/23 13:32:59.334
  Apr 19 13:32:59.334: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename sched-preemption @ 04/19/23 13:32:59.335
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:32:59.348
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:32:59.352
  Apr 19 13:32:59.368: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 19 13:33:59.392: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 04/19/23 13:33:59.395
  Apr 19 13:33:59.419: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Apr 19 13:33:59.427: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Apr 19 13:33:59.441: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Apr 19 13:33:59.446: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 04/19/23 13:33:59.446
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 04/19/23 13:34:01.464
  Apr 19 13:34:05.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-7359" for this suite. @ 04/19/23 13:34:05.543
• [66.216 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:808
  STEP: Creating a kubernetes client @ 04/19/23 13:34:05.551
  Apr 19 13:34:05.551: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/23 13:34:05.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:34:05.568
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:34:05.571
  STEP: Creating ServiceAccount "e2e-sa-hdtzc"  @ 04/19/23 13:34:05.573
  Apr 19 13:34:05.578: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-hdtzc"  @ 04/19/23 13:34:05.578
  Apr 19 13:34:05.584: INFO: AutomountServiceAccountToken: true
  Apr 19 13:34:05.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7233" for this suite. @ 04/19/23 13:34:05.59
• [0.043 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:99
  STEP: Creating a kubernetes client @ 04/19/23 13:34:05.595
  Apr 19 13:34:05.595: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:34:05.596
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:34:05.607
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:34:05.609
  STEP: Creating configMap with name projected-configmap-test-volume-map-a6833f39-b80b-4cee-9097-83fc73ec295b @ 04/19/23 13:34:05.612
  STEP: Creating a pod to test consume configMaps @ 04/19/23 13:34:05.617
  W0419 13:34:05.625692      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:34:09.64
  Apr 19 13:34:09.644: INFO: Trying to get logs from node talos-default-worker-1 pod pod-projected-configmaps-7b2ec4a8-767a-4176-ac45-dae878e5d61a container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 13:34:09.659
  Apr 19 13:34:09.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-766" for this suite. @ 04/19/23 13:34:09.678
• [4.089 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:97
  STEP: Creating a kubernetes client @ 04/19/23 13:34:09.686
  Apr 19 13:34:09.686: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 13:34:09.69
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:34:09.703
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:34:09.707
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/19/23 13:34:09.71
  W0419 13:34:09.717087      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:34:13.73
  Apr 19 13:34:13.734: INFO: Trying to get logs from node talos-default-worker-1 pod pod-1f5ead52-4c87-483d-83d0-da8b18a0cdd1 container test-container: <nil>
  STEP: delete the pod @ 04/19/23 13:34:13.742
  Apr 19 13:34:13.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5269" for this suite. @ 04/19/23 13:34:13.762
• [4.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]
test/e2e/common/node/runtimeclass.go:189
  STEP: Creating a kubernetes client @ 04/19/23 13:34:13.77
  Apr 19 13:34:13.771: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/23 13:34:13.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:34:13.791
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:34:13.795
  STEP: getting /apis @ 04/19/23 13:34:13.798
  STEP: getting /apis/node.k8s.io @ 04/19/23 13:34:13.804
  STEP: getting /apis/node.k8s.io/v1 @ 04/19/23 13:34:13.806
  STEP: creating @ 04/19/23 13:34:13.808
  STEP: watching @ 04/19/23 13:34:13.82
  Apr 19 13:34:13.820: INFO: starting watch
  STEP: getting @ 04/19/23 13:34:13.826
  STEP: listing @ 04/19/23 13:34:13.829
  STEP: patching @ 04/19/23 13:34:13.831
  STEP: updating @ 04/19/23 13:34:13.836
  Apr 19 13:34:13.840: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 04/19/23 13:34:13.84
  STEP: deleting a collection @ 04/19/23 13:34:13.85
  Apr 19 13:34:13.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8818" for this suite. @ 04/19/23 13:34:13.863
• [0.096 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:321
  STEP: Creating a kubernetes client @ 04/19/23 13:34:13.869
  Apr 19 13:34:13.870: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename gc @ 04/19/23 13:34:13.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:34:13.88
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:34:13.882
  STEP: create the rc @ 04/19/23 13:34:13.884
  W0419 13:34:13.888172      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  W0419 13:34:13.888196      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: delete the rc @ 04/19/23 13:34:18.893
  STEP: wait for all pods to be garbage collected @ 04/19/23 13:34:18.901
  STEP: Gathering metrics @ 04/19/23 13:34:23.909
  Apr 19 13:34:23.975: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 19 13:34:23.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6561" for this suite. @ 04/19/23 13:34:23.981
• [10.119 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]
test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 04/19/23 13:34:23.991
  Apr 19 13:34:23.991: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename subjectreview @ 04/19/23 13:34:23.995
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:34:24.013
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:34:24.016
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-4645" @ 04/19/23 13:34:24.019
  Apr 19 13:34:24.024: INFO: saUsername: "system:serviceaccount:subjectreview-4645:e2e"
  Apr 19 13:34:24.024: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-4645"}
  Apr 19 13:34:24.024: INFO: saUID: "4334ea5e-aa35-484a-90b3-c043b61528bd"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-4645:e2e" @ 04/19/23 13:34:24.024
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-4645:e2e" @ 04/19/23 13:34:24.024
  Apr 19 13:34:24.026: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-4645:e2e" api 'list' configmaps in "subjectreview-4645" namespace @ 04/19/23 13:34:24.026
  Apr 19 13:34:24.028: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-4645:e2e" @ 04/19/23 13:34:24.028
  Apr 19 13:34:24.030: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Apr 19 13:34:24.030: INFO: LocalSubjectAccessReview has been verified
  Apr 19 13:34:24.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-4645" for this suite. @ 04/19/23 13:34:24.035
• [0.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]
test/e2e/apimachinery/field_validation.go:465
  STEP: Creating a kubernetes client @ 04/19/23 13:34:24.041
  Apr 19 13:34:24.041: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename field-validation @ 04/19/23 13:34:24.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:34:24.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:34:24.056
  Apr 19 13:34:24.057: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  W0419 13:34:26.585838      20 warnings.go:70] unknown field "alpha"
  W0419 13:34:26.586356      20 warnings.go:70] unknown field "beta"
  W0419 13:34:26.586379      20 warnings.go:70] unknown field "delta"
  W0419 13:34:26.586400      20 warnings.go:70] unknown field "epsilon"
  W0419 13:34:26.586423      20 warnings.go:70] unknown field "gamma"
  Apr 19 13:34:26.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7086" for this suite. @ 04/19/23 13:34:26.614
• [2.579 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:58
  STEP: Creating a kubernetes client @ 04/19/23 13:34:26.624
  Apr 19 13:34:26.624: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/23 13:34:26.627
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:34:26.642
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:34:26.647
  Apr 19 13:34:26.651: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:34:27.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9964" for this suite. @ 04/19/23 13:34:27.685
• [1.069 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]
test/e2e/storage/subpath.go:92
  STEP: Creating a kubernetes client @ 04/19/23 13:34:27.693
  Apr 19 13:34:27.693: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename subpath @ 04/19/23 13:34:27.697
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:34:27.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:34:27.713
  STEP: Setting up data @ 04/19/23 13:34:27.715
  STEP: Creating pod pod-subpath-test-downwardapi-s8vp @ 04/19/23 13:34:27.723
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/23 13:34:27.723
  W0419 13:34:27.731386      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-downwardapi-s8vp" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-downwardapi-s8vp" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-downwardapi-s8vp" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-downwardapi-s8vp" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:34:51.797
  Apr 19 13:34:51.800: INFO: Trying to get logs from node talos-default-worker-1 pod pod-subpath-test-downwardapi-s8vp container test-container-subpath-downwardapi-s8vp: <nil>
  STEP: delete the pod @ 04/19/23 13:34:51.808
  STEP: Deleting pod pod-subpath-test-downwardapi-s8vp @ 04/19/23 13:34:51.827
  Apr 19 13:34:51.827: INFO: Deleting pod "pod-subpath-test-downwardapi-s8vp" in namespace "subpath-6654"
  Apr 19 13:34:51.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6654" for this suite. @ 04/19/23 13:34:51.837
• [24.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 04/19/23 13:34:51.847
  Apr 19 13:34:51.847: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/23 13:34:51.849
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:34:51.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:34:51.866
  Apr 19 13:34:51.870: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 04/19/23 13:34:53.394
  Apr 19 13:34:53.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8238 --namespace=crd-publish-openapi-8238 create -f -'
  Apr 19 13:34:53.932: INFO: stderr: ""
  Apr 19 13:34:53.932: INFO: stdout: "e2e-test-crd-publish-openapi-400-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Apr 19 13:34:53.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8238 --namespace=crd-publish-openapi-8238 delete e2e-test-crd-publish-openapi-400-crds test-foo'
  Apr 19 13:34:53.997: INFO: stderr: ""
  Apr 19 13:34:53.997: INFO: stdout: "e2e-test-crd-publish-openapi-400-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Apr 19 13:34:53.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8238 --namespace=crd-publish-openapi-8238 apply -f -'
  Apr 19 13:34:54.429: INFO: stderr: ""
  Apr 19 13:34:54.429: INFO: stdout: "e2e-test-crd-publish-openapi-400-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Apr 19 13:34:54.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8238 --namespace=crd-publish-openapi-8238 delete e2e-test-crd-publish-openapi-400-crds test-foo'
  Apr 19 13:34:54.482: INFO: stderr: ""
  Apr 19 13:34:54.482: INFO: stdout: "e2e-test-crd-publish-openapi-400-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 04/19/23 13:34:54.482
  Apr 19 13:34:54.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8238 --namespace=crd-publish-openapi-8238 create -f -'
  Apr 19 13:34:54.995: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 04/19/23 13:34:54.995
  Apr 19 13:34:54.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8238 --namespace=crd-publish-openapi-8238 create -f -'
  Apr 19 13:34:55.178: INFO: rc: 1
  Apr 19 13:34:55.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8238 --namespace=crd-publish-openapi-8238 apply -f -'
  Apr 19 13:34:55.373: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 04/19/23 13:34:55.373
  Apr 19 13:34:55.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8238 --namespace=crd-publish-openapi-8238 create -f -'
  Apr 19 13:34:55.550: INFO: rc: 1
  Apr 19 13:34:55.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8238 --namespace=crd-publish-openapi-8238 apply -f -'
  Apr 19 13:34:55.705: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 04/19/23 13:34:55.705
  Apr 19 13:34:55.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8238 explain e2e-test-crd-publish-openapi-400-crds'
  Apr 19 13:34:55.870: INFO: stderr: ""
  Apr 19 13:34:55.871: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-400-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 04/19/23 13:34:55.872
  Apr 19 13:34:55.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8238 explain e2e-test-crd-publish-openapi-400-crds.metadata'
  Apr 19 13:34:56.043: INFO: stderr: ""
  Apr 19 13:34:56.043: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-400-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Apr 19 13:34:56.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8238 explain e2e-test-crd-publish-openapi-400-crds.spec'
  Apr 19 13:34:56.205: INFO: stderr: ""
  Apr 19 13:34:56.205: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-400-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Apr 19 13:34:56.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8238 explain e2e-test-crd-publish-openapi-400-crds.spec.bars'
  Apr 19 13:34:56.363: INFO: stderr: ""
  Apr 19 13:34:56.363: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-400-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 04/19/23 13:34:56.364
  Apr 19 13:34:56.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-8238 explain e2e-test-crd-publish-openapi-400-crds.spec.bars2'
  Apr 19 13:34:56.522: INFO: rc: 1
  Apr 19 13:34:57.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8238" for this suite. @ 04/19/23 13:34:57.929
• [6.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]
test/e2e/apimachinery/resource_quota.go:328
  STEP: Creating a kubernetes client @ 04/19/23 13:34:57.942
  Apr 19 13:34:57.942: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename resourcequota @ 04/19/23 13:34:57.944
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:34:57.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:34:57.957
  STEP: Counting existing ResourceQuota @ 04/19/23 13:35:14.963
  STEP: Creating a ResourceQuota @ 04/19/23 13:35:19.967
  STEP: Ensuring resource quota status is calculated @ 04/19/23 13:35:19.973
  STEP: Creating a ConfigMap @ 04/19/23 13:35:21.976
  STEP: Ensuring resource quota status captures configMap creation @ 04/19/23 13:35:21.986
  STEP: Deleting a ConfigMap @ 04/19/23 13:35:23.99
  STEP: Ensuring resource quota status released usage @ 04/19/23 13:35:23.996
  Apr 19 13:35:26.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4921" for this suite. @ 04/19/23 13:35:26.005
• [28.070 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]
test/e2e/apimachinery/webhook.go:260
  STEP: Creating a kubernetes client @ 04/19/23 13:35:26.012
  Apr 19 13:35:26.012: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 13:35:26.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:35:26.031
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:35:26.035
  STEP: Setting up server cert @ 04/19/23 13:35:26.054
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 13:35:26.292
  STEP: Deploying the webhook pod @ 04/19/23 13:35:26.299
  W0419 13:35:26.308349      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 13:35:26.308
  Apr 19 13:35:26.315: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/19/23 13:35:28.325
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 13:35:28.339
  Apr 19 13:35:29.343: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 04/19/23 13:35:29.347
  STEP: create a pod that should be updated by the webhook @ 04/19/23 13:35:29.367
  W0419 13:35:29.382060      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webhook-added-init-container", "example" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webhook-added-init-container", "example" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webhook-added-init-container", "example" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webhook-added-init-container", "example" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:35:29.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2410" for this suite. @ 04/19/23 13:35:29.422
  STEP: Destroying namespace "webhook-markers-578" for this suite. @ 04/19/23 13:35:29.426
• [3.418 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:127
  STEP: Creating a kubernetes client @ 04/19/23 13:35:29.431
  Apr 19 13:35:29.431: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 13:35:29.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:35:29.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:35:29.445
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 04/19/23 13:35:29.447
  W0419 13:35:29.453450      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:35:33.464
  Apr 19 13:35:33.467: INFO: Trying to get logs from node talos-default-worker-1 pod pod-fa90963f-4401-420b-ab5d-e077c23644ff container test-container: <nil>
  STEP: delete the pod @ 04/19/23 13:35:33.481
  Apr 19 13:35:33.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8178" for this suite. @ 04/19/23 13:35:33.496
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:99
  STEP: Creating a kubernetes client @ 04/19/23 13:35:33.507
  Apr 19 13:35:33.508: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 13:35:33.511
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:35:33.522
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:35:33.525
  STEP: Creating configMap with name configmap-test-volume-map-6ad98a64-8f85-4424-bde6-f7f2d7bfc34a @ 04/19/23 13:35:33.528
  STEP: Creating a pod to test consume configMaps @ 04/19/23 13:35:33.531
  W0419 13:35:33.537896      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:35:37.55
  Apr 19 13:35:37.553: INFO: Trying to get logs from node talos-default-worker-1 pod pod-configmaps-6635abee-016c-49d8-a71a-a713c37c1f8f container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 13:35:37.56
  Apr 19 13:35:37.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4001" for this suite. @ 04/19/23 13:35:37.577
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
test/e2e/scheduling/predicates.go:705
  STEP: Creating a kubernetes client @ 04/19/23 13:35:37.588
  Apr 19 13:35:37.589: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename sched-pred @ 04/19/23 13:35:37.592
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:35:37.603
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:35:37.607
  Apr 19 13:35:37.611: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 19 13:35:37.618: INFO: Waiting for terminating namespaces to be deleted...
  Apr 19 13:35:37.621: INFO: 
  Logging pods the apiserver thinks is on node talos-default-worker-1 before test
  Apr 19 13:35:37.628: INFO: kube-flannel-xtc62 from kube-system started at 2023-04-18 19:32:12 +0000 UTC (1 container statuses recorded)
  Apr 19 13:35:37.628: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 19 13:35:37.628: INFO: kube-proxy-j7zxh from kube-system started at 2023-04-18 19:32:12 +0000 UTC (1 container statuses recorded)
  Apr 19 13:35:37.628: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 19 13:35:37.628: INFO: sonobuoy from sonobuoy started at 2023-04-19 12:53:21 +0000 UTC (1 container statuses recorded)
  Apr 19 13:35:37.628: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 19 13:35:37.628: INFO: webhook-to-be-mutated from webhook-2410 started at 2023-04-19 13:35:29 +0000 UTC (1 container statuses recorded)
  Apr 19 13:35:37.628: INFO: 	Container example ready: false, restart count 0
  Apr 19 13:35:37.628: INFO: 
  Logging pods the apiserver thinks is on node talos-default-worker-2 before test
  Apr 19 13:35:37.634: INFO: coredns-d779cc7ff-z6svh from kube-system started at 2023-04-18 19:38:29 +0000 UTC (1 container statuses recorded)
  Apr 19 13:35:37.634: INFO: 	Container coredns ready: true, restart count 0
  Apr 19 13:35:37.634: INFO: kube-flannel-xntjw from kube-system started at 2023-04-18 19:32:33 +0000 UTC (1 container statuses recorded)
  Apr 19 13:35:37.634: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 19 13:35:37.634: INFO: kube-proxy-qxzd4 from kube-system started at 2023-04-18 19:32:33 +0000 UTC (1 container statuses recorded)
  Apr 19 13:35:37.634: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 19 13:35:37.634: INFO: sonobuoy-e2e-job-9b851c216c1a4329 from sonobuoy started at 2023-04-19 12:53:22 +0000 UTC (2 container statuses recorded)
  Apr 19 13:35:37.634: INFO: 	Container e2e ready: true, restart count 0
  Apr 19 13:35:37.634: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/19/23 13:35:37.634
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/19/23 13:35:39.651
  STEP: Trying to apply a random label on the found node. @ 04/19/23 13:35:39.666
  STEP: verifying the node has the label kubernetes.io/e2e-71ca552f-e8eb-48fd-a319-90c13321022c 95 @ 04/19/23 13:35:39.68
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 04/19/23 13:35:39.683
  W0419 13:35:39.688358      20 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54322), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.20.0.5 on the node which pod4 resides and expect not scheduled @ 04/19/23 13:35:41.695
  W0419 13:35:41.703842      20 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54322), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: removing the label kubernetes.io/e2e-71ca552f-e8eb-48fd-a319-90c13321022c off the node talos-default-worker-1 @ 04/19/23 13:40:41.705
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-71ca552f-e8eb-48fd-a319-90c13321022c @ 04/19/23 13:40:41.723
  Apr 19 13:40:41.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-5848" for this suite. @ 04/19/23 13:40:41.731
• [304.149 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
test/e2e/apps/job.go:370
  STEP: Creating a kubernetes client @ 04/19/23 13:40:41.743
  Apr 19 13:40:41.743: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename job @ 04/19/23 13:40:41.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:40:41.756
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:40:41.76
  STEP: Creating Indexed job @ 04/19/23 13:40:41.762
  W0419 13:40:41.766539      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring job reaches completions @ 04/19/23 13:40:41.766
  STEP: Ensuring pods with index for job exist @ 04/19/23 13:40:49.77
  Apr 19 13:40:49.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2977" for this suite. @ 04/19/23 13:40:49.779
• [8.047 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]
test/e2e/apimachinery/field_validation.go:610
  STEP: Creating a kubernetes client @ 04/19/23 13:40:49.79
  Apr 19 13:40:49.790: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename field-validation @ 04/19/23 13:40:49.792
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:40:49.804
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:40:49.809
  Apr 19 13:40:49.813: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  W0419 13:40:52.342975      20 warnings.go:70] unknown field "alpha"
  W0419 13:40:52.343019      20 warnings.go:70] unknown field "beta"
  W0419 13:40:52.343040      20 warnings.go:70] unknown field "delta"
  W0419 13:40:52.343059      20 warnings.go:70] unknown field "epsilon"
  W0419 13:40:52.343083      20 warnings.go:70] unknown field "gamma"
  Apr 19 13:40:52.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6408" for this suite. @ 04/19/23 13:40:52.372
• [2.588 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:177
  STEP: Creating a kubernetes client @ 04/19/23 13:40:52.384
  Apr 19 13:40:52.384: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename init-container @ 04/19/23 13:40:52.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:40:52.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:40:52.407
  STEP: creating the pod @ 04/19/23 13:40:52.41
  Apr 19 13:40:52.410: INFO: PodSpec: initContainers in spec.initContainers
  W0419 13:40:52.418065      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "init1", "init2", "run1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "init1", "init2", "run1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "init1", "init2", "run1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "init1", "init2", "run1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:40:56.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-357" for this suite. @ 04/19/23 13:40:56.844
• [4.467 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:124
  STEP: Creating a kubernetes client @ 04/19/23 13:40:56.852
  Apr 19 13:40:56.852: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 13:40:56.853
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:40:56.864
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:40:56.868
  STEP: Creating configMap with name configmap-test-upd-94f9e906-4801-4974-ac0b-ecefc0e749cc @ 04/19/23 13:40:56.875
  STEP: Creating the pod @ 04/19/23 13:40:56.879
  W0419 13:40:56.885719      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Updating configmap configmap-test-upd-94f9e906-4801-4974-ac0b-ecefc0e749cc @ 04/19/23 13:40:58.909
  STEP: waiting to observe update in volume @ 04/19/23 13:40:58.914
  Apr 19 13:42:23.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-23" for this suite. @ 04/19/23 13:42:23.271
• [86.430 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance]
test/e2e/apps/rc.go:103
  STEP: Creating a kubernetes client @ 04/19/23 13:42:23.285
  Apr 19 13:42:23.285: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename replication-controller @ 04/19/23 13:42:23.288
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:42:23.3
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:42:23.308
  STEP: Given a ReplicationController is created @ 04/19/23 13:42:23.312
  W0419 13:42:23.316751      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-release" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-release" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-release" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-release" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: When the matched label of one of its pods change @ 04/19/23 13:42:23.316
  Apr 19 13:42:23.320: INFO: Pod name pod-release: Found 0 pods out of 1
  Apr 19 13:42:28.323: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/19/23 13:42:28.33
  Apr 19 13:42:29.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-7919" for this suite. @ 04/19/23 13:42:29.342
• [6.065 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance]
test/e2e/network/service.go:3548
  STEP: Creating a kubernetes client @ 04/19/23 13:42:29.35
  Apr 19 13:42:29.350: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 13:42:29.351
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:42:29.364
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:42:29.368
  STEP: creating a collection of services @ 04/19/23 13:42:29.373
  Apr 19 13:42:29.374: INFO: Creating e2e-svc-a-fmqnq
  Apr 19 13:42:29.386: INFO: Creating e2e-svc-b-hgqxv
  Apr 19 13:42:29.399: INFO: Creating e2e-svc-c-b75k2
  STEP: deleting service collection @ 04/19/23 13:42:29.415
  Apr 19 13:42:29.433: INFO: Collection of services has been deleted
  Apr 19 13:42:29.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-903" for this suite. @ 04/19/23 13:42:29.436
• [0.090 seconds]
------------------------------
SSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]
test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 04/19/23 13:42:29.441
  Apr 19 13:42:29.441: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename cronjob @ 04/19/23 13:42:29.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:42:29.452
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:42:29.454
  STEP: Creating a suspended cronjob @ 04/19/23 13:42:29.456
  W0419 13:42:29.460268      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring no jobs are scheduled @ 04/19/23 13:42:29.46
  STEP: Ensuring no job exists by listing jobs explicitly @ 04/19/23 13:47:29.466
  STEP: Removing cronjob @ 04/19/23 13:47:29.469
  Apr 19 13:47:29.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-990" for this suite. @ 04/19/23 13:47:29.479
• [300.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:54
  STEP: Creating a kubernetes client @ 04/19/23 13:47:29.497
  Apr 19 13:47:29.497: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 13:47:29.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:47:29.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:47:29.522
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 13:47:29.528
  W0419 13:47:29.536529      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:47:31.548
  Apr 19 13:47:31.552: INFO: Trying to get logs from node talos-default-worker-1 pod downwardapi-volume-d33538c4-e5d0-458a-bfb1-252a6fc462dd container client-container: <nil>
  STEP: delete the pod @ 04/19/23 13:47:31.572
  Apr 19 13:47:31.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7909" for this suite. @ 04/19/23 13:47:31.59
• [2.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 04/19/23 13:47:31.599
  Apr 19 13:47:31.599: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename cronjob @ 04/19/23 13:47:31.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:47:31.611
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:47:31.614
  STEP: Creating a ForbidConcurrent cronjob @ 04/19/23 13:47:31.617
  W0419 13:47:31.621547      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring a job is scheduled @ 04/19/23 13:47:31.622
  STEP: Ensuring exactly one is scheduled @ 04/19/23 13:48:01.626
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/19/23 13:48:01.629
  STEP: Ensuring no more jobs are scheduled @ 04/19/23 13:48:01.632
  STEP: Removing cronjob @ 04/19/23 13:53:01.639
  Apr 19 13:53:01.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-9892" for this suite. @ 04/19/23 13:53:01.648
• [330.057 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 04/19/23 13:53:01.657
  Apr 19 13:53:01.657: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename secrets @ 04/19/23 13:53:01.661
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:53:01.675
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:53:01.678
  Apr 19 13:53:01.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3891" for this suite. @ 04/19/23 13:53:01.708
• [0.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]
test/e2e/storage/subpath.go:80
  STEP: Creating a kubernetes client @ 04/19/23 13:53:01.715
  Apr 19 13:53:01.715: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename subpath @ 04/19/23 13:53:01.715
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:53:01.723
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:53:01.726
  STEP: Setting up data @ 04/19/23 13:53:01.728
  STEP: Creating pod pod-subpath-test-configmap-zfkh @ 04/19/23 13:53:01.733
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/23 13:53:01.733
  W0419 13:53:01.738512      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-configmap-zfkh" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-configmap-zfkh" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-configmap-zfkh" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-configmap-zfkh" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:53:25.789
  Apr 19 13:53:25.792: INFO: Trying to get logs from node talos-default-worker-1 pod pod-subpath-test-configmap-zfkh container test-container-subpath-configmap-zfkh: <nil>
  STEP: delete the pod @ 04/19/23 13:53:25.807
  STEP: Deleting pod pod-subpath-test-configmap-zfkh @ 04/19/23 13:53:25.819
  Apr 19 13:53:25.819: INFO: Deleting pod "pod-subpath-test-configmap-zfkh" in namespace "subpath-4489"
  Apr 19 13:53:25.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-4489" for this suite. @ 04/19/23 13:53:25.826
• [24.117 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 04/19/23 13:53:25.838
  Apr 19 13:53:25.838: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename secrets @ 04/19/23 13:53:25.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:53:25.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:53:25.856
  STEP: Creating secret with name secret-test-map-86be3045-9619-4e6d-b863-5a1fe08b9637 @ 04/19/23 13:53:25.859
  STEP: Creating a pod to test consume secrets @ 04/19/23 13:53:25.864
  W0419 13:53:25.871266      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:53:29.883
  Apr 19 13:53:29.886: INFO: Trying to get logs from node talos-default-worker-1 pod pod-secrets-d249c921-d1bf-48e9-8d85-252c5b31cefa container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 13:53:29.892
  Apr 19 13:53:29.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6363" for this suite. @ 04/19/23 13:53:29.914
• [4.082 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]
test/e2e/kubectl/kubectl.go:396
  STEP: Creating a kubernetes client @ 04/19/23 13:53:29.921
  Apr 19 13:53:29.922: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 13:53:29.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:53:29.936
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:53:29.94
  STEP: creating all guestbook components @ 04/19/23 13:53:29.944
  Apr 19 13:53:29.944: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Apr 19 13:53:29.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-7871 create -f -'
  Apr 19 13:53:30.617: INFO: stderr: ""
  Apr 19 13:53:30.617: INFO: stdout: "service/agnhost-replica created\n"
  Apr 19 13:53:30.617: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Apr 19 13:53:30.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-7871 create -f -'
  Apr 19 13:53:31.272: INFO: stderr: ""
  Apr 19 13:53:31.272: INFO: stdout: "service/agnhost-primary created\n"
  Apr 19 13:53:31.273: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Apr 19 13:53:31.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-7871 create -f -'
  Apr 19 13:53:31.525: INFO: stderr: ""
  Apr 19 13:53:31.525: INFO: stdout: "service/frontend created\n"
  Apr 19 13:53:31.525: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.43
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Apr 19 13:53:31.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-7871 create -f -'
  Apr 19 13:53:31.713: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"guestbook-frontend\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"guestbook-frontend\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"guestbook-frontend\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"guestbook-frontend\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 13:53:31.713: INFO: stdout: "deployment.apps/frontend created\n"
  Apr 19 13:53:31.713: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.43
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Apr 19 13:53:31.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-7871 create -f -'
  Apr 19 13:53:31.919: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"primary\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"primary\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"primary\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"primary\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 13:53:31.919: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Apr 19 13:53:31.919: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.43
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Apr 19 13:53:31.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-7871 create -f -'
  Apr 19 13:53:32.525: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"replica\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"replica\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"replica\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"replica\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 13:53:32.525: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 04/19/23 13:53:32.525
  Apr 19 13:53:32.525: INFO: Waiting for all frontend pods to be Running.
  Apr 19 13:53:37.578: INFO: Waiting for frontend to serve content.
  Apr 19 13:53:37.587: INFO: Trying to add a new entry to the guestbook.
  Apr 19 13:53:37.597: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 04/19/23 13:53:37.604
  Apr 19 13:53:37.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-7871 delete --grace-period=0 --force -f -'
  Apr 19 13:53:37.711: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 13:53:37.711: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/23 13:53:37.712
  Apr 19 13:53:37.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-7871 delete --grace-period=0 --force -f -'
  Apr 19 13:53:37.772: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 13:53:37.772: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/23 13:53:37.772
  Apr 19 13:53:37.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-7871 delete --grace-period=0 --force -f -'
  Apr 19 13:53:37.836: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 13:53:37.836: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/23 13:53:37.836
  Apr 19 13:53:37.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-7871 delete --grace-period=0 --force -f -'
  Apr 19 13:53:37.885: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 13:53:37.885: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/23 13:53:37.886
  Apr 19 13:53:37.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-7871 delete --grace-period=0 --force -f -'
  Apr 19 13:53:37.964: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 13:53:37.964: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 04/19/23 13:53:37.964
  Apr 19 13:53:37.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-7871 delete --grace-period=0 --force -f -'
  Apr 19 13:53:38.063: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 13:53:38.063: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Apr 19 13:53:38.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7871" for this suite. @ 04/19/23 13:53:38.067
• [8.151 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]
test/e2e/apimachinery/webhook.go:118
  STEP: Creating a kubernetes client @ 04/19/23 13:53:38.076
  Apr 19 13:53:38.076: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 13:53:38.08
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:53:38.092
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:53:38.101
  STEP: Setting up server cert @ 04/19/23 13:53:38.117
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 13:53:38.33
  STEP: Deploying the webhook pod @ 04/19/23 13:53:38.338
  W0419 13:53:38.346919      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 13:53:38.346
  Apr 19 13:53:38.353: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/19/23 13:53:40.366
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 13:53:40.381
  Apr 19 13:53:41.381: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 04/19/23 13:53:41.385
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 04/19/23 13:53:41.387
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 04/19/23 13:53:41.387
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 04/19/23 13:53:41.387
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 04/19/23 13:53:41.389
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/19/23 13:53:41.389
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 04/19/23 13:53:41.391
  Apr 19 13:53:41.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7283" for this suite. @ 04/19/23 13:53:41.437
  STEP: Destroying namespace "webhook-markers-7890" for this suite. @ 04/19/23 13:53:41.444
• [3.374 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance]
test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 04/19/23 13:53:41.45
  Apr 19 13:53:41.450: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename cronjob @ 04/19/23 13:53:41.451
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:53:41.459
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:53:41.462
  STEP: Creating a cronjob @ 04/19/23 13:53:41.464
  STEP: creating @ 04/19/23 13:53:41.464
  W0419 13:53:41.468033      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: getting @ 04/19/23 13:53:41.468
  STEP: listing @ 04/19/23 13:53:41.47
  STEP: watching @ 04/19/23 13:53:41.472
  Apr 19 13:53:41.472: INFO: starting watch
  STEP: cluster-wide listing @ 04/19/23 13:53:41.473
  STEP: cluster-wide watching @ 04/19/23 13:53:41.475
  Apr 19 13:53:41.475: INFO: starting watch
  STEP: patching @ 04/19/23 13:53:41.476
  W0419 13:53:41.481011      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: updating @ 04/19/23 13:53:41.481
  W0419 13:53:41.486545      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:53:41.486: INFO: waiting for watch events with expected annotations
  Apr 19 13:53:41.487: INFO: saw patched and updated annotations
  STEP: patching /status @ 04/19/23 13:53:41.487
  STEP: updating /status @ 04/19/23 13:53:41.491
  STEP: get /status @ 04/19/23 13:53:41.495
  STEP: deleting @ 04/19/23 13:53:41.498
  W0419 13:53:41.501051      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: deleting a collection @ 04/19/23 13:53:41.505
  Apr 19 13:53:41.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-5183" for this suite. @ 04/19/23 13:53:41.514
• [0.068 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:107
  STEP: Creating a kubernetes client @ 04/19/23 13:53:41.518
  Apr 19 13:53:41.518: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pod-network-test @ 04/19/23 13:53:41.519
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:53:41.527
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:53:41.529
  STEP: Performing setup for networking test in namespace pod-network-test-6241 @ 04/19/23 13:53:41.53
  STEP: creating a selector @ 04/19/23 13:53:41.53
  STEP: Creating the service pods in kubernetes @ 04/19/23 13:53:41.53
  Apr 19 13:53:41.530: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  W0419 13:53:41.539808      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  W0419 13:53:41.543324      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Creating test pods @ 04/19/23 13:54:03.604
  W0419 13:54:03.610051      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  W0419 13:54:03.616891      20 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:54:05.635: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Apr 19 13:54:05.635: INFO: Going to poll 10.244.3.215 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  Apr 19 13:54:05.638: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.3.215:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6241 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:54:05.638: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:54:05.639: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:54:05.639: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-6241/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.3.215%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 19 13:54:05.739: INFO: Found all 1 expected endpoints: [netserver-0]
  Apr 19 13:54:05.739: INFO: Going to poll 10.244.1.158 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  Apr 19 13:54:05.745: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.158:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6241 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:54:05.745: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:54:05.747: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:54:05.747: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-6241/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.1.158%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Apr 19 13:54:05.861: INFO: Found all 1 expected endpoints: [netserver-1]
  Apr 19 13:54:05.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-6241" for this suite. @ 04/19/23 13:54:05.867
• [24.354 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
test/e2e/apps/daemon_set.go:374
  STEP: Creating a kubernetes client @ 04/19/23 13:54:05.874
  Apr 19 13:54:05.874: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename daemonsets @ 04/19/23 13:54:05.876
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:54:05.887
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:54:05.891
  Apr 19 13:54:05.908: INFO: Creating simple daemon set daemon-set
  W0419 13:54:05.913450      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/23 13:54:05.914
  Apr 19 13:54:05.918: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:05.918: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:05.918: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:05.921: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:54:05.921: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:54:06.925: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:06.925: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:06.926: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:06.929: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:54:06.929: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:54:07.926: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:07.926: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:07.926: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:07.930: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 13:54:07.930: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Update daemon pods image. @ 04/19/23 13:54:07.944
  W0419 13:54:07.954577      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Check that daemon pods images are updated. @ 04/19/23 13:54:07.973
  Apr 19 13:54:07.978: INFO: Wrong image for pod: daemon-set-kclgs. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 19 13:54:07.986: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:07.988: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:07.990: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:08.993: INFO: Wrong image for pod: daemon-set-kclgs. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 19 13:54:08.997: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:08.997: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:08.997: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:09.994: INFO: Wrong image for pod: daemon-set-kclgs. Expected: registry.k8s.io/e2e-test-images/agnhost:2.43, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Apr 19 13:54:09.994: INFO: Pod daemon-set-pk774 is not available
  Apr 19 13:54:09.998: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:09.998: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:09.998: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:10.996: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:10.997: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:10.997: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:11.994: INFO: Pod daemon-set-h8wrz is not available
  Apr 19 13:54:11.998: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:11.998: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:11.998: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 04/19/23 13:54:11.999
  Apr 19 13:54:12.003: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:12.003: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:12.003: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:12.007: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 13:54:12.007: INFO: Node talos-default-worker-2 is running 0 daemon pod, expected 1
  Apr 19 13:54:13.011: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:13.011: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:13.011: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:54:13.015: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 13:54:13.015: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/23 13:54:13.028
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2011, will wait for the garbage collector to delete the pods @ 04/19/23 13:54:13.028
  Apr 19 13:54:13.087: INFO: Deleting DaemonSet.extensions daemon-set took: 5.952143ms
  Apr 19 13:54:13.191: INFO: Terminating DaemonSet.extensions daemon-set pods took: 103.444964ms
  Apr 19 13:54:14.395: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 13:54:14.395: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 19 13:54:14.398: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"199875"},"items":null}

  Apr 19 13:54:14.402: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"199875"},"items":null}

  Apr 19 13:54:14.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2011" for this suite. @ 04/19/23 13:54:14.42
• [8.559 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:109
  STEP: Creating a kubernetes client @ 04/19/23 13:54:14.435
  Apr 19 13:54:14.435: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:54:14.438
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:54:14.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:54:14.452
  STEP: Creating configMap with name projected-configmap-test-volume-map-5d925bc1-d3d0-4021-8c0b-3c737c825380 @ 04/19/23 13:54:14.455
  STEP: Creating a pod to test consume configMaps @ 04/19/23 13:54:14.459
  W0419 13:54:14.467426      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:54:16.476
  Apr 19 13:54:16.478: INFO: Trying to get logs from node talos-default-worker-1 pod pod-projected-configmaps-74c2707e-e6dd-4394-b8e5-cefbdce18bf8 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 13:54:16.484
  Apr 19 13:54:16.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8722" for this suite. @ 04/19/23 13:54:16.503
• [2.072 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:95
  STEP: Creating a kubernetes client @ 04/19/23 13:54:16.507
  Apr 19 13:54:16.507: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pod-network-test @ 04/19/23 13:54:16.508
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:54:16.516
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:54:16.519
  STEP: Performing setup for networking test in namespace pod-network-test-2806 @ 04/19/23 13:54:16.522
  STEP: creating a selector @ 04/19/23 13:54:16.522
  STEP: Creating the service pods in kubernetes @ 04/19/23 13:54:16.523
  Apr 19 13:54:16.523: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  W0419 13:54:16.534962      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  W0419 13:54:16.540124      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Creating test pods @ 04/19/23 13:54:38.596
  W0419 13:54:38.601702      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:54:40.613: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Apr 19 13:54:40.613: INFO: Breadth first check of 10.244.3.220 on host 172.20.0.5...
  Apr 19 13:54:40.616: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.221:9080/dial?request=hostname&protocol=udp&host=10.244.3.220&port=8081&tries=1'] Namespace:pod-network-test-2806 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:54:40.616: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:54:40.617: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:54:40.617: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-2806/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.3.221%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.3.220%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 19 13:54:40.749: INFO: Waiting for responses: map[]
  Apr 19 13:54:40.750: INFO: reached 10.244.3.220 after 0/1 tries
  Apr 19 13:54:40.750: INFO: Breadth first check of 10.244.1.161 on host 172.20.0.6...
  Apr 19 13:54:40.754: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.221:9080/dial?request=hostname&protocol=udp&host=10.244.1.161&port=8081&tries=1'] Namespace:pod-network-test-2806 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 13:54:40.755: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:54:40.756: INFO: ExecWithOptions: Clientset creation
  Apr 19 13:54:40.756: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-2806/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.3.221%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.1.161%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 19 13:54:40.885: INFO: Waiting for responses: map[]
  Apr 19 13:54:40.886: INFO: reached 10.244.1.161 after 0/1 tries
  Apr 19 13:54:40.887: INFO: Going to retry 0 out of 2 pods....
  Apr 19 13:54:40.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-2806" for this suite. @ 04/19/23 13:54:40.893
• [24.391 seconds]
------------------------------
S
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:46
  STEP: Creating a kubernetes client @ 04/19/23 13:54:40.901
  Apr 19 13:54:40.902: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename secrets @ 04/19/23 13:54:40.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:54:40.919
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:54:40.922
  STEP: Creating secret with name secret-test-94ca319f-bb80-4183-bb42-561bd5a6a24b @ 04/19/23 13:54:40.925
  STEP: Creating a pod to test consume secrets @ 04/19/23 13:54:40.929
  W0419 13:54:40.936502      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-env-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-env-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-env-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-env-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:54:44.949
  Apr 19 13:54:44.952: INFO: Trying to get logs from node talos-default-worker-1 pod pod-secrets-45272fb9-f1fa-40a2-9a8e-c8622aae71ea container secret-env-test: <nil>
  STEP: delete the pod @ 04/19/23 13:54:44.96
  Apr 19 13:54:44.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2543" for this suite. @ 04/19/23 13:54:44.984
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2165
  STEP: Creating a kubernetes client @ 04/19/23 13:54:44.994
  Apr 19 13:54:44.994: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 13:54:44.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:54:45.006
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:54:45.012
  STEP: creating service in namespace services-6149 @ 04/19/23 13:54:45.016
  STEP: creating service affinity-clusterip in namespace services-6149 @ 04/19/23 13:54:45.016
  STEP: creating replication controller affinity-clusterip in namespace services-6149 @ 04/19/23 13:54:45.028
  W0419 13:54:45.035063      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-clusterip" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-clusterip" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-clusterip" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-clusterip" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  I0419 13:54:45.036934      20 runners.go:194] Created replication controller with name: affinity-clusterip, namespace: services-6149, replica count: 3
  I0419 13:54:48.088472      20 runners.go:194] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 13:54:48.095: INFO: Creating new exec pod
  W0419 13:54:48.100940      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:54:51.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-6149 exec execpod-affinityhqgxj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  Apr 19 13:54:51.288: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Apr 19 13:54:51.288: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 13:54:51.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-6149 exec execpod-affinityhqgxj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.106.96.11 80'
  Apr 19 13:54:51.439: INFO: stderr: "+ nc -v -t -w 2 10.106.96.11 80\nConnection to 10.106.96.11 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Apr 19 13:54:51.439: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 13:54:51.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-6149 exec execpod-affinityhqgxj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.106.96.11:80/ ; done'
  Apr 19 13:54:51.723: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.106.96.11:80/\n"
  Apr 19 13:54:51.723: INFO: stdout: "\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4\naffinity-clusterip-4gcs4"
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Received response from host: affinity-clusterip-4gcs4
  Apr 19 13:54:51.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 19 13:54:51.729: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-6149, will wait for the garbage collector to delete the pods @ 04/19/23 13:54:51.738
  Apr 19 13:54:51.805: INFO: Deleting ReplicationController affinity-clusterip took: 6.103567ms
  Apr 19 13:54:51.905: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.224373ms
  STEP: Destroying namespace "services-6149" for this suite. @ 04/19/23 13:54:53.523
• [8.533 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 04/19/23 13:54:53.527
  Apr 19 13:54:53.527: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/23 13:54:53.53
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:54:53.538
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:54:53.541
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 04/19/23 13:54:53.543
  Apr 19 13:54:53.544: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:54:55.552: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:55:01.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7419" for this suite. @ 04/19/23 13:55:01.128
• [7.608 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:402
  STEP: Creating a kubernetes client @ 04/19/23 13:55:01.136
  Apr 19 13:55:01.136: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 13:55:01.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:55:01.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:55:01.16
  STEP: Setting up server cert @ 04/19/23 13:55:01.183
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 13:55:01.618
  STEP: Deploying the webhook pod @ 04/19/23 13:55:01.631
  W0419 13:55:01.641862      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 13:55:01.641
  Apr 19 13:55:01.651: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/19/23 13:55:03.661
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 13:55:03.681
  Apr 19 13:55:04.681: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 04/19/23 13:55:04.686
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/23 13:55:04.701
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 04/19/23 13:55:04.709
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/23 13:55:04.72
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 04/19/23 13:55:04.732
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 04/19/23 13:55:04.74
  Apr 19 13:55:04.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7896" for this suite. @ 04/19/23 13:55:04.792
  STEP: Destroying namespace "webhook-markers-3853" for this suite. @ 04/19/23 13:55:04.797
• [3.667 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 04/19/23 13:55:04.804
  Apr 19 13:55:04.805: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-runtime @ 04/19/23 13:55:04.806
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:55:04.817
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:55:04.819
  STEP: create the container @ 04/19/23 13:55:04.821
  W0419 13:55:04.827736      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  W0419 13:55:04.827761      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "termination-message-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "termination-message-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "termination-message-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "termination-message-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: wait for the container to reach Succeeded @ 04/19/23 13:55:04.827
  STEP: get the container status @ 04/19/23 13:55:07.845
  STEP: the container should be terminated @ 04/19/23 13:55:07.848
  STEP: the termination message should be set @ 04/19/23 13:55:07.848
  Apr 19 13:55:07.848: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 04/19/23 13:55:07.848
  Apr 19 13:55:07.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-5157" for this suite. @ 04/19/23 13:55:07.874
• [3.076 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]
test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 04/19/23 13:55:07.883
  Apr 19 13:55:07.883: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename tables @ 04/19/23 13:55:07.884
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:55:07.899
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:55:07.902
  Apr 19 13:55:07.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-5872" for this suite. @ 04/19/23 13:55:07.913
• [0.038 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 04/19/23 13:55:07.927
  Apr 19 13:55:07.927: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:55:07.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:55:07.945
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:55:07.948
  STEP: Creating secret with name projected-secret-test-b5fb520e-c7ba-4f37-94dd-db525395f4ad @ 04/19/23 13:55:07.952
  STEP: Creating a pod to test consume secrets @ 04/19/23 13:55:07.958
  W0419 13:55:07.964538      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:55:11.977
  Apr 19 13:55:11.981: INFO: Trying to get logs from node talos-default-worker-1 pod pod-projected-secrets-f1de55d9-2088-4927-921b-4f17ad5c38a9 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 13:55:11.994
  Apr 19 13:55:12.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2673" for this suite. @ 04/19/23 13:55:12.013
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:124
  STEP: Creating a kubernetes client @ 04/19/23 13:55:12.027
  Apr 19 13:55:12.027: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:55:12.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:55:12.049
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:55:12.052
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-5545d2b9-f2f3-4f8a-9e4e-263776c96eaa @ 04/19/23 13:55:12.06
  STEP: Creating the pod @ 04/19/23 13:55:12.065
  W0419 13:55:12.072905      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Updating configmap projected-configmap-test-upd-5545d2b9-f2f3-4f8a-9e4e-263776c96eaa @ 04/19/23 13:55:14.092
  STEP: waiting to observe update in volume @ 04/19/23 13:55:14.097
  Apr 19 13:56:46.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-374" for this suite. @ 04/19/23 13:56:46.545
• [94.525 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]
test/e2e/apps/statefulset.go:912
  STEP: Creating a kubernetes client @ 04/19/23 13:56:46.555
  Apr 19 13:56:46.555: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename statefulset @ 04/19/23 13:56:46.558
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:56:46.574
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:56:46.579
  STEP: Creating service test in namespace statefulset-1788 @ 04/19/23 13:56:46.584
  W0419 13:56:46.600409      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:56:46.604: INFO: Found 0 stateful pods, waiting for 1
  Apr 19 13:56:56.613: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 04/19/23 13:56:56.62
  W0419 13:56:56.632788      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  W0419 13:56:56.632840      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "test-ss", "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "test-ss", "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "test-ss", "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "test-ss", "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:56:56.641: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 13:56:56.642: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
  Apr 19 13:57:06.647: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 13:57:06.647: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 04/19/23 13:57:06.655
  STEP: Delete all of the StatefulSets @ 04/19/23 13:57:06.658
  STEP: Verify that StatefulSets have been deleted @ 04/19/23 13:57:06.667
  Apr 19 13:57:06.671: INFO: Deleting all statefulset in ns statefulset-1788
  Apr 19 13:57:06.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1788" for this suite. @ 04/19/23 13:57:06.692
• [20.145 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]
test/e2e/apps/controller_revision.go:124
  STEP: Creating a kubernetes client @ 04/19/23 13:57:06.701
  Apr 19 13:57:06.701: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename controllerrevisions @ 04/19/23 13:57:06.702
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:57:06.714
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:57:06.716
  STEP: Creating DaemonSet "e2e-rxxsx-daemon-set" @ 04/19/23 13:57:06.728
  W0419 13:57:06.732565      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/23 13:57:06.734
  Apr 19 13:57:06.739: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:57:06.739: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:57:06.739: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:57:06.744: INFO: Number of nodes with available pods controlled by daemonset e2e-rxxsx-daemon-set: 0
  Apr 19 13:57:06.744: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  Apr 19 13:57:07.749: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:57:07.749: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:57:07.749: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 13:57:07.752: INFO: Number of nodes with available pods controlled by daemonset e2e-rxxsx-daemon-set: 2
  Apr 19 13:57:07.752: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-rxxsx-daemon-set
  STEP: Confirm DaemonSet "e2e-rxxsx-daemon-set" successfully created with "daemonset-name=e2e-rxxsx-daemon-set" label @ 04/19/23 13:57:07.754
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-rxxsx-daemon-set" @ 04/19/23 13:57:07.759
  Apr 19 13:57:07.762: INFO: Located ControllerRevision: "e2e-rxxsx-daemon-set-578964d864"
  STEP: Patching ControllerRevision "e2e-rxxsx-daemon-set-578964d864" @ 04/19/23 13:57:07.764
  Apr 19 13:57:07.770: INFO: e2e-rxxsx-daemon-set-578964d864 has been patched
  STEP: Create a new ControllerRevision @ 04/19/23 13:57:07.77
  Apr 19 13:57:07.777: INFO: Created ControllerRevision: e2e-rxxsx-daemon-set-79cddd4bf4
  STEP: Confirm that there are two ControllerRevisions @ 04/19/23 13:57:07.778
  Apr 19 13:57:07.778: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 19 13:57:07.781: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-rxxsx-daemon-set-578964d864" @ 04/19/23 13:57:07.782
  STEP: Confirm that there is only one ControllerRevision @ 04/19/23 13:57:07.787
  Apr 19 13:57:07.787: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 19 13:57:07.791: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-rxxsx-daemon-set-79cddd4bf4" @ 04/19/23 13:57:07.794
  Apr 19 13:57:07.801: INFO: e2e-rxxsx-daemon-set-79cddd4bf4 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 04/19/23 13:57:07.801
  W0419 13:57:07.805636      20 warnings.go:70] unknown field "updateStrategy"
  W0419 13:57:07.805656      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Confirm that there are two ControllerRevisions @ 04/19/23 13:57:07.805
  Apr 19 13:57:07.806: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 19 13:57:08.810: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 19 13:57:08.814: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-rxxsx-daemon-set-79cddd4bf4=updated" @ 04/19/23 13:57:08.814
  STEP: Confirm that there is only one ControllerRevision @ 04/19/23 13:57:08.821
  Apr 19 13:57:08.821: INFO: Requesting list of ControllerRevisions to confirm quantity
  Apr 19 13:57:08.824: INFO: Found 1 ControllerRevisions
  Apr 19 13:57:08.827: INFO: ControllerRevision "e2e-rxxsx-daemon-set-979dfcb5f" has revision 3
  STEP: Deleting DaemonSet "e2e-rxxsx-daemon-set" @ 04/19/23 13:57:08.83
  STEP: deleting DaemonSet.extensions e2e-rxxsx-daemon-set in namespace controllerrevisions-2360, will wait for the garbage collector to delete the pods @ 04/19/23 13:57:08.83
  Apr 19 13:57:08.888: INFO: Deleting DaemonSet.extensions e2e-rxxsx-daemon-set took: 5.527313ms
  Apr 19 13:57:08.989: INFO: Terminating DaemonSet.extensions e2e-rxxsx-daemon-set pods took: 100.281641ms
  Apr 19 13:57:09.794: INFO: Number of nodes with available pods controlled by daemonset e2e-rxxsx-daemon-set: 0
  Apr 19 13:57:09.794: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-rxxsx-daemon-set
  Apr 19 13:57:09.797: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"200811"},"items":null}

  Apr 19 13:57:09.801: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"200811"},"items":null}

  Apr 19 13:57:09.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-2360" for this suite. @ 04/19/23 13:57:09.817
• [3.122 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 04/19/23 13:57:09.826
  Apr 19 13:57:09.826: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:57:09.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:57:09.844
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:57:09.847
  STEP: Creating projection with secret that has name projected-secret-test-ffa626ec-31c4-453c-bb02-a0acb85548b8 @ 04/19/23 13:57:09.85
  STEP: Creating a pod to test consume secrets @ 04/19/23 13:57:09.855
  W0419 13:57:09.862969      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:57:11.875
  Apr 19 13:57:11.878: INFO: Trying to get logs from node talos-default-worker-1 pod pod-projected-secrets-5356ae59-eac6-45e8-957c-3a2784f95718 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 13:57:11.883
  Apr 19 13:57:11.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4666" for this suite. @ 04/19/23 13:57:11.895
• [2.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 04/19/23 13:57:11.903
  Apr 19 13:57:11.904: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/23 13:57:11.905
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:57:11.922
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:57:11.925
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 04/19/23 13:57:11.929
  Apr 19 13:57:11.930: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:57:13.413: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 13:57:19.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-8745" for this suite. @ 04/19/23 13:57:19.079
• [7.182 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:147
  STEP: Creating a kubernetes client @ 04/19/23 13:57:19.089
  Apr 19 13:57:19.089: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 13:57:19.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:57:19.106
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:57:19.109
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 04/19/23 13:57:19.113
  W0419 13:57:19.121584      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:57:23.134
  Apr 19 13:57:23.138: INFO: Trying to get logs from node talos-default-worker-1 pod pod-fc83d3c5-b904-4f5e-97d8-3b52a98c0d16 container test-container: <nil>
  STEP: delete the pod @ 04/19/23 13:57:23.151
  Apr 19 13:57:23.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6361" for this suite. @ 04/19/23 13:57:23.175
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]
test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 04/19/23 13:57:23.188
  Apr 19 13:57:23.188: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename watch @ 04/19/23 13:57:23.19
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:57:23.206
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:57:23.209
  STEP: creating a watch on configmaps with label A @ 04/19/23 13:57:23.215
  STEP: creating a watch on configmaps with label B @ 04/19/23 13:57:23.218
  STEP: creating a watch on configmaps with label A or B @ 04/19/23 13:57:23.22
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 04/19/23 13:57:23.222
  Apr 19 13:57:23.227: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1028  a19457d6-3691-46b6-8101-e87212ed14da 200952 0 2023-04-19 13:57:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-19 13:57:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 13:57:23.227: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1028  a19457d6-3691-46b6-8101-e87212ed14da 200952 0 2023-04-19 13:57:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-19 13:57:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 04/19/23 13:57:23.227
  Apr 19 13:57:23.233: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1028  a19457d6-3691-46b6-8101-e87212ed14da 200953 0 2023-04-19 13:57:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-19 13:57:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 13:57:23.233: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1028  a19457d6-3691-46b6-8101-e87212ed14da 200953 0 2023-04-19 13:57:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-19 13:57:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 04/19/23 13:57:23.234
  Apr 19 13:57:23.241: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1028  a19457d6-3691-46b6-8101-e87212ed14da 200954 0 2023-04-19 13:57:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-19 13:57:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 13:57:23.241: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1028  a19457d6-3691-46b6-8101-e87212ed14da 200954 0 2023-04-19 13:57:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-19 13:57:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 04/19/23 13:57:23.241
  Apr 19 13:57:23.245: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1028  a19457d6-3691-46b6-8101-e87212ed14da 200955 0 2023-04-19 13:57:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-19 13:57:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 13:57:23.245: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1028  a19457d6-3691-46b6-8101-e87212ed14da 200955 0 2023-04-19 13:57:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-19 13:57:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 04/19/23 13:57:23.246
  Apr 19 13:57:23.249: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1028  e3067e4c-9c00-4086-9c2d-a83166286b56 200956 0 2023-04-19 13:57:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-19 13:57:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 13:57:23.249: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1028  e3067e4c-9c00-4086-9c2d-a83166286b56 200956 0 2023-04-19 13:57:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-19 13:57:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 04/19/23 13:57:33.25
  Apr 19 13:57:33.257: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1028  e3067e4c-9c00-4086-9c2d-a83166286b56 200990 0 2023-04-19 13:57:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-19 13:57:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 13:57:33.258: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1028  e3067e4c-9c00-4086-9c2d-a83166286b56 200990 0 2023-04-19 13:57:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-19 13:57:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 13:57:43.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1028" for this suite. @ 04/19/23 13:57:43.264
• [20.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 04/19/23 13:57:43.277
  Apr 19 13:57:43.277: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 13:57:43.278
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:57:43.296
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:57:43.299
  STEP: Creating projection with secret that has name projected-secret-test-map-f1c5e421-88ce-43cb-8ef7-0f9f9171aae8 @ 04/19/23 13:57:43.302
  STEP: Creating a pod to test consume secrets @ 04/19/23 13:57:43.306
  W0419 13:57:43.315133      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:57:47.329
  Apr 19 13:57:47.332: INFO: Trying to get logs from node talos-default-worker-1 pod pod-projected-secrets-400d33f3-23f9-4ac1-832d-af7cd2e0972f container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 13:57:47.34
  Apr 19 13:57:47.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3610" for this suite. @ 04/19/23 13:57:47.363
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]
test/e2e/apps/deployment.go:485
  STEP: Creating a kubernetes client @ 04/19/23 13:57:47.374
  Apr 19 13:57:47.374: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename deployment @ 04/19/23 13:57:47.375
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:57:47.388
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:57:47.391
  STEP: creating a Deployment @ 04/19/23 13:57:47.397
  Apr 19 13:57:47.397: INFO: Creating simple deployment test-deployment-45fw8
  W0419 13:57:47.407249      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 13:57:47.417: INFO: deployment "test-deployment-45fw8" doesn't have the required revision set
  STEP: Getting /status @ 04/19/23 13:57:49.431
  Apr 19 13:57:49.435: INFO: Deployment test-deployment-45fw8 has Conditions: [{Available True 2023-04-19 13:57:48 +0000 UTC 2023-04-19 13:57:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-04-19 13:57:48 +0000 UTC 2023-04-19 13:57:47 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-45fw8-5994cf9475" has successfully progressed.}]
  STEP: updating Deployment Status @ 04/19/23 13:57:49.435
  Apr 19 13:57:49.450: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 13, 57, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 13, 57, 48, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 13, 57, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 13, 57, 47, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-45fw8-5994cf9475\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 04/19/23 13:57:49.45
  Apr 19 13:57:49.452: INFO: Observed &Deployment event: ADDED
  Apr 19 13:57:49.453: INFO: Observed Deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-19 13:57:47 +0000 UTC 2023-04-19 13:57:47 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-45fw8-5994cf9475"}
  Apr 19 13:57:49.454: INFO: Observed &Deployment event: MODIFIED
  Apr 19 13:57:49.455: INFO: Observed Deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-19 13:57:47 +0000 UTC 2023-04-19 13:57:47 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-45fw8-5994cf9475"}
  Apr 19 13:57:49.456: INFO: Observed Deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-19 13:57:47 +0000 UTC 2023-04-19 13:57:47 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 19 13:57:49.457: INFO: Observed &Deployment event: MODIFIED
  Apr 19 13:57:49.457: INFO: Observed Deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-19 13:57:47 +0000 UTC 2023-04-19 13:57:47 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 19 13:57:49.457: INFO: Observed Deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-19 13:57:47 +0000 UTC 2023-04-19 13:57:47 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-45fw8-5994cf9475" is progressing.}
  Apr 19 13:57:49.458: INFO: Observed &Deployment event: MODIFIED
  Apr 19 13:57:49.458: INFO: Observed Deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-19 13:57:48 +0000 UTC 2023-04-19 13:57:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 19 13:57:49.458: INFO: Observed Deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-19 13:57:48 +0000 UTC 2023-04-19 13:57:47 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-45fw8-5994cf9475" has successfully progressed.}
  Apr 19 13:57:49.458: INFO: Observed &Deployment event: MODIFIED
  Apr 19 13:57:49.458: INFO: Observed Deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-19 13:57:48 +0000 UTC 2023-04-19 13:57:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 19 13:57:49.458: INFO: Observed Deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-19 13:57:48 +0000 UTC 2023-04-19 13:57:47 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-45fw8-5994cf9475" has successfully progressed.}
  Apr 19 13:57:49.458: INFO: Found Deployment test-deployment-45fw8 in namespace deployment-1801 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 19 13:57:49.459: INFO: Deployment test-deployment-45fw8 has an updated status
  STEP: patching the Statefulset Status @ 04/19/23 13:57:49.459
  Apr 19 13:57:49.459: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 19 13:57:49.466: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 04/19/23 13:57:49.466
  Apr 19 13:57:49.468: INFO: Observed &Deployment event: ADDED
  Apr 19 13:57:49.468: INFO: Observed deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-19 13:57:47 +0000 UTC 2023-04-19 13:57:47 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-45fw8-5994cf9475"}
  Apr 19 13:57:49.468: INFO: Observed &Deployment event: MODIFIED
  Apr 19 13:57:49.468: INFO: Observed deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-19 13:57:47 +0000 UTC 2023-04-19 13:57:47 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-45fw8-5994cf9475"}
  Apr 19 13:57:49.468: INFO: Observed deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-19 13:57:47 +0000 UTC 2023-04-19 13:57:47 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 19 13:57:49.468: INFO: Observed &Deployment event: MODIFIED
  Apr 19 13:57:49.468: INFO: Observed deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-19 13:57:47 +0000 UTC 2023-04-19 13:57:47 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Apr 19 13:57:49.468: INFO: Observed deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-19 13:57:47 +0000 UTC 2023-04-19 13:57:47 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-45fw8-5994cf9475" is progressing.}
  Apr 19 13:57:49.468: INFO: Observed &Deployment event: MODIFIED
  Apr 19 13:57:49.468: INFO: Observed deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-19 13:57:48 +0000 UTC 2023-04-19 13:57:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 19 13:57:49.468: INFO: Observed deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-19 13:57:48 +0000 UTC 2023-04-19 13:57:47 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-45fw8-5994cf9475" has successfully progressed.}
  Apr 19 13:57:49.468: INFO: Observed &Deployment event: MODIFIED
  Apr 19 13:57:49.468: INFO: Observed deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-19 13:57:48 +0000 UTC 2023-04-19 13:57:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Apr 19 13:57:49.468: INFO: Observed deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-19 13:57:48 +0000 UTC 2023-04-19 13:57:47 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-45fw8-5994cf9475" has successfully progressed.}
  Apr 19 13:57:49.468: INFO: Observed deployment test-deployment-45fw8 in namespace deployment-1801 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 19 13:57:49.468: INFO: Observed &Deployment event: MODIFIED
  Apr 19 13:57:49.469: INFO: Found deployment test-deployment-45fw8 in namespace deployment-1801 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Apr 19 13:57:49.469: INFO: Deployment test-deployment-45fw8 has a patched status
  Apr 19 13:57:49.472: INFO: Deployment "test-deployment-45fw8":
  &Deployment{ObjectMeta:{test-deployment-45fw8  deployment-1801  b7210ca1-b9f6-4226-a8bb-947cbf451ab1 201073 1 2023-04-19 13:57:47 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-19 13:57:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-04-19 13:57:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-04-19 13:57:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003f03de8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-45fw8-5994cf9475",LastUpdateTime:2023-04-19 13:57:49 +0000 UTC,LastTransitionTime:2023-04-19 13:57:49 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 19 13:57:49.476: INFO: New ReplicaSet "test-deployment-45fw8-5994cf9475" of Deployment "test-deployment-45fw8":
  &ReplicaSet{ObjectMeta:{test-deployment-45fw8-5994cf9475  deployment-1801  54918812-e464-421f-ac44-ff386b4b367a 201067 1 2023-04-19 13:57:47 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:5994cf9475] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-45fw8 b7210ca1-b9f6-4226-a8bb-947cbf451ab1 0xc00438af60 0xc00438af61}] [] [{kube-controller-manager Update apps/v1 2023-04-19 13:57:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b7210ca1-b9f6-4226-a8bb-947cbf451ab1\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 13:57:48 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 5994cf9475,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:5994cf9475] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-4 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00438b008 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 19 13:57:49.479: INFO: Pod "test-deployment-45fw8-5994cf9475-2dn6k" is available:
  &Pod{ObjectMeta:{test-deployment-45fw8-5994cf9475-2dn6k test-deployment-45fw8-5994cf9475- deployment-1801  4a22f0b3-eb6c-4702-99e8-9b1267090f13 201066 0 2023-04-19 13:57:47 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:5994cf9475] map[] [{apps/v1 ReplicaSet test-deployment-45fw8-5994cf9475 54918812-e464-421f-ac44-ff386b4b367a 0xc00438b3b0 0xc00438b3b1}] [] [{kube-controller-manager Update v1 2023-04-19 13:57:47 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54918812-e464-421f-ac44-ff386b4b367a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 13:57:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.3.236\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-25hfg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-25hfg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:57:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:57:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:57:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 13:57:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:10.244.3.236,StartTime:2023-04-19 13:57:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 13:57:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-4,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22,ContainerID:containerd://d9c69e5c2f6bdcb665f246df3ac06603de9c35cb51c66276bcba01aaf2dbd147,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.236,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 13:57:49.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1801" for this suite. @ 04/19/23 13:57:49.483
• [2.114 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 04/19/23 13:57:49.488
  Apr 19 13:57:49.488: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pods @ 04/19/23 13:57:49.489
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:57:49.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:57:49.501
  Apr 19 13:57:49.503: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: creating the pod @ 04/19/23 13:57:49.504
  STEP: submitting the pod to kubernetes @ 04/19/23 13:57:49.504
  Apr 19 13:57:51.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1206" for this suite. @ 04/19/23 13:57:51.542
• [2.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]
test/e2e/common/node/configmap.go:138
  STEP: Creating a kubernetes client @ 04/19/23 13:57:51.558
  Apr 19 13:57:51.559: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 13:57:51.562
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:57:51.581
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:57:51.584
  STEP: Creating configMap that has name configmap-test-emptyKey-39bb81ae-7b62-41bb-9f51-38faf48dd729 @ 04/19/23 13:57:51.588
  Apr 19 13:57:51.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3130" for this suite. @ 04/19/23 13:57:51.595
• [0.043 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]
test/e2e/kubectl/kubectl.go:1775
  STEP: Creating a kubernetes client @ 04/19/23 13:57:51.604
  Apr 19 13:57:51.604: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 13:57:51.606
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:57:51.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:57:51.623
  STEP: starting the proxy server @ 04/19/23 13:57:51.626
  Apr 19 13:57:51.627: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1735 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 04/19/23 13:57:51.688
  Apr 19 13:57:51.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1735" for this suite. @ 04/19/23 13:57:51.698
• [0.105 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:272
  STEP: Creating a kubernetes client @ 04/19/23 13:57:51.711
  Apr 19 13:57:51.711: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename namespaces @ 04/19/23 13:57:51.714
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:57:51.727
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:57:51.729
  STEP: creating a Namespace @ 04/19/23 13:57:51.731
  STEP: patching the Namespace @ 04/19/23 13:57:51.743
  STEP: get the Namespace and ensuring it has the label @ 04/19/23 13:57:51.748
  Apr 19 13:57:51.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-8838" for this suite. @ 04/19/23 13:57:51.755
  STEP: Destroying namespace "nspatchtest-f2264987-f418-4645-9c27-6036f1af9f9e-3656" for this suite. @ 04/19/23 13:57:51.759
• [0.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:344
  STEP: Creating a kubernetes client @ 04/19/23 13:57:51.769
  Apr 19 13:57:51.769: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename field-validation @ 04/19/23 13:57:51.771
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:57:51.782
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:57:51.784
  Apr 19 13:57:51.786: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  W0419 13:57:51.787501      20 field_validation.go:417] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc00594aca0 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  W0419 13:57:54.316206      20 warnings.go:70] unknown field "alpha"
  W0419 13:57:54.316232      20 warnings.go:70] unknown field "beta"
  W0419 13:57:54.316241      20 warnings.go:70] unknown field "delta"
  W0419 13:57:54.316275      20 warnings.go:70] unknown field "epsilon"
  W0419 13:57:54.316284      20 warnings.go:70] unknown field "gamma"
  Apr 19 13:57:54.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-8614" for this suite. @ 04/19/23 13:57:54.348
• [2.585 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:89
  STEP: Creating a kubernetes client @ 04/19/23 13:57:54.36
  Apr 19 13:57:54.361: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 13:57:54.364
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:57:54.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:57:54.383
  STEP: Creating configMap with name configmap-test-volume-map-4a63f57f-d5de-4cfc-890d-f329575d3565 @ 04/19/23 13:57:54.386
  STEP: Creating a pod to test consume configMaps @ 04/19/23 13:57:54.391
  W0419 13:57:54.403519      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:57:58.418
  Apr 19 13:57:58.421: INFO: Trying to get logs from node talos-default-worker-2 pod pod-configmaps-c7e8e9ab-70fc-484f-bfc0-53f23adbbf29 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 13:57:58.429
  Apr 19 13:57:58.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9033" for this suite. @ 04/19/23 13:57:58.446
• [4.091 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 04/19/23 13:57:58.452
  Apr 19 13:57:58.452: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/23 13:57:58.453
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:57:58.467
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:57:58.471
  STEP: set up a multi version CRD @ 04/19/23 13:57:58.475
  Apr 19 13:57:58.477: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: rename a version @ 04/19/23 13:58:01.851
  STEP: check the new version name is served @ 04/19/23 13:58:01.865
  STEP: check the old version name is removed @ 04/19/23 13:58:02.643
  STEP: check the other version is not changed @ 04/19/23 13:58:03.411
  Apr 19 13:58:06.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7112" for this suite. @ 04/19/23 13:58:06.145
• [7.698 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]
test/e2e/kubectl/kubectl.go:1735
  STEP: Creating a kubernetes client @ 04/19/23 13:58:06.155
  Apr 19 13:58:06.155: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 13:58:06.157
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:58:06.169
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:58:06.172
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 04/19/23 13:58:06.176
  Apr 19 13:58:06.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-859 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Apr 19 13:58:06.234: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 13:58:06.234: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 04/19/23 13:58:06.234
  STEP: verifying the pod e2e-test-httpd-pod was created @ 04/19/23 13:58:11.287
  Apr 19 13:58:11.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-859 get pod e2e-test-httpd-pod -o json'
  Apr 19 13:58:11.382: INFO: stderr: ""
  Apr 19 13:58:11.382: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-04-19T13:58:06Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-859\",\n        \"resourceVersion\": \"201257\",\n        \"uid\": \"da135928-e598-4be5-bc50-dc05cdce4912\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-6bsw4\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"talos-default-worker-1\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-6bsw4\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-19T13:58:06Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-19T13:58:07Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-19T13:58:07Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-19T13:58:06Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://8436f1cc6cf1b663e9e93b03af8b46a5a58bc4121b20a06f030a8969584eaf71\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-04-19T13:58:06Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.20.0.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.3.238\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.3.238\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-04-19T13:58:06Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 04/19/23 13:58:11.382
  Apr 19 13:58:11.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-859 replace -f -'
  Apr 19 13:58:11.921: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"e2e-test-httpd-pod\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"e2e-test-httpd-pod\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"e2e-test-httpd-pod\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"e2e-test-httpd-pod\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 13:58:11.921: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-4 @ 04/19/23 13:58:11.921
  Apr 19 13:58:11.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-859 delete pods e2e-test-httpd-pod'
  Apr 19 13:58:13.844: INFO: stderr: ""
  Apr 19 13:58:13.844: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Apr 19 13:58:13.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-859" for this suite. @ 04/19/23 13:58:13.849
• [7.700 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 04/19/23 13:58:13.859
  Apr 19 13:58:13.859: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pods @ 04/19/23 13:58:13.862
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:58:13.875
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:58:13.878
  STEP: creating the pod @ 04/19/23 13:58:13.882
  STEP: setting up watch @ 04/19/23 13:58:13.882
  STEP: submitting the pod to kubernetes @ 04/19/23 13:58:13.987
  STEP: verifying the pod is in kubernetes @ 04/19/23 13:58:13.995
  STEP: verifying pod creation was observed @ 04/19/23 13:58:13.999
  STEP: deleting the pod gracefully @ 04/19/23 13:58:16.015
  STEP: verifying pod deletion was observed @ 04/19/23 13:58:16.027
  Apr 19 13:58:16.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1020" for this suite. @ 04/19/23 13:58:16.855
• [3.001 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance]
test/e2e/common/node/lease.go:72
  STEP: Creating a kubernetes client @ 04/19/23 13:58:16.865
  Apr 19 13:58:16.865: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename lease-test @ 04/19/23 13:58:16.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:58:16.877
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:58:16.882
  Apr 19 13:58:16.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-8760" for this suite. @ 04/19/23 13:58:16.928
• [0.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:479
  STEP: Creating a kubernetes client @ 04/19/23 13:58:16.936
  Apr 19 13:58:16.936: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename gc @ 04/19/23 13:58:16.937
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:58:16.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:58:16.949
  STEP: create the deployment @ 04/19/23 13:58:16.952
  W0419 13:58:16.956503      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  W0419 13:58:16.956645      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/19/23 13:58:16.956
  STEP: delete the deployment @ 04/19/23 13:58:17.47
  STEP: wait for all rs to be garbage collected @ 04/19/23 13:58:17.476
  STEP: expected 0 rs, got 1 rs @ 04/19/23 13:58:17.479
  STEP: expected 0 pods, got 2 pods @ 04/19/23 13:58:17.482
  STEP: Gathering metrics @ 04/19/23 13:58:17.994
  Apr 19 13:58:18.037: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 19 13:58:18.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-692" for this suite. @ 04/19/23 13:58:18.045
• [1.118 seconds]
------------------------------
SS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]
test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 04/19/23 13:58:18.054
  Apr 19 13:58:18.054: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename disruption @ 04/19/23 13:58:18.055
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:58:18.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:58:18.071
  STEP: Waiting for the pdb to be processed @ 04/19/23 13:58:18.077
  STEP: Updating PodDisruptionBudget status @ 04/19/23 13:58:20.083
  W0419 13:58:20.090140      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Waiting for all pods to be running @ 04/19/23 13:58:20.09
  Apr 19 13:58:20.094: INFO: running pods: 0 < 1
  STEP: locating a running pod @ 04/19/23 13:58:22.098
  STEP: Waiting for the pdb to be processed @ 04/19/23 13:58:22.105
  STEP: Patching PodDisruptionBudget status @ 04/19/23 13:58:22.111
  STEP: Waiting for the pdb to be processed @ 04/19/23 13:58:22.119
  Apr 19 13:58:22.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-5515" for this suite. @ 04/19/23 13:58:22.127
• [4.078 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]
test/e2e/apimachinery/resource_quota.go:451
  STEP: Creating a kubernetes client @ 04/19/23 13:58:22.132
  Apr 19 13:58:22.132: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename resourcequota @ 04/19/23 13:58:22.136
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:58:22.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:58:22.148
  STEP: Counting existing ResourceQuota @ 04/19/23 13:58:22.15
  STEP: Creating a ResourceQuota @ 04/19/23 13:58:27.154
  STEP: Ensuring resource quota status is calculated @ 04/19/23 13:58:27.159
  STEP: Creating a ReplicaSet @ 04/19/23 13:58:29.163
  W0419 13:58:29.172276      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-rs" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-rs" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-rs" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-rs" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring resource quota status captures replicaset creation @ 04/19/23 13:58:29.173
  STEP: Deleting a ReplicaSet @ 04/19/23 13:58:31.178
  STEP: Ensuring resource quota status released usage @ 04/19/23 13:58:31.183
  Apr 19 13:58:33.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4981" for this suite. @ 04/19/23 13:58:33.192
• [11.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]
test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 04/19/23 13:58:33.207
  Apr 19 13:58:33.208: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename var-expansion @ 04/19/23 13:58:33.209
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:58:33.222
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:58:33.225
  STEP: Creating a pod to test substitution in volume subpath @ 04/19/23 13:58:33.228
  W0419 13:58:33.236294      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:58:37.249
  Apr 19 13:58:37.252: INFO: Trying to get logs from node talos-default-worker-1 pod var-expansion-898d97a0-6f2f-4949-a0af-167bcc82c9e2 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/23 13:58:37.261
  Apr 19 13:58:37.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5904" for this suite. @ 04/19/23 13:58:37.279
• [4.078 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:236
  STEP: Creating a kubernetes client @ 04/19/23 13:58:37.293
  Apr 19 13:58:37.293: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 13:58:37.296
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:58:37.307
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:58:37.313
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 13:58:37.317
  W0419 13:58:37.324811      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 13:58:41.339
  Apr 19 13:58:41.342: INFO: Trying to get logs from node talos-default-worker-1 pod downwardapi-volume-c9fc22a8-3b4e-4656-8446-45f867cf0af4 container client-container: <nil>
  STEP: delete the pod @ 04/19/23 13:58:41.349
  Apr 19 13:58:41.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8952" for this suite. @ 04/19/23 13:58:41.374
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]
test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 04/19/23 13:58:41.387
  Apr 19 13:58:41.387: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename cronjob @ 04/19/23 13:58:41.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 13:58:41.398
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 13:58:41.4
  STEP: Creating a cronjob @ 04/19/23 13:58:41.403
  W0419 13:58:41.407549      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring more than one job is running at a time @ 04/19/23 13:58:41.407
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 04/19/23 14:00:01.411
  STEP: Removing cronjob @ 04/19/23 14:00:01.414
  Apr 19 14:00:01.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-9807" for this suite. @ 04/19/23 14:00:01.424
• [80.042 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:222
  STEP: Creating a kubernetes client @ 04/19/23 14:00:01.439
  Apr 19 14:00:01.439: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 14:00:01.443
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:00:01.456
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:00:01.459
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 14:00:01.462
  W0419 14:00:01.468795      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 14:00:05.482
  Apr 19 14:00:05.485: INFO: Trying to get logs from node talos-default-worker-2 pod downwardapi-volume-82a4ce48-1e2f-42d1-b8cf-6942e0c8ced5 container client-container: <nil>
  STEP: delete the pod @ 04/19/23 14:00:05.497
  Apr 19 14:00:05.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4734" for this suite. @ 04/19/23 14:00:05.515
• [4.084 seconds]
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:375
  STEP: Creating a kubernetes client @ 04/19/23 14:00:05.522
  Apr 19 14:00:05.523: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 14:00:05.525
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:00:05.538
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:00:05.541
  STEP: Creating configMap with name projected-configmap-test-volume-0b04fb88-5e2a-4465-9600-8d6f91c52bf1 @ 04/19/23 14:00:05.545
  STEP: Creating a pod to test consume configMaps @ 04/19/23 14:00:05.549
  W0419 14:00:05.555604      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-configmap-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-configmap-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-configmap-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-configmap-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 14:00:09.569
  Apr 19 14:00:09.572: INFO: Trying to get logs from node talos-default-worker-2 pod pod-projected-configmaps-b9238dc2-7297-4375-883c-35b345865adc container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 14:00:09.576
  Apr 19 14:00:09.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5197" for this suite. @ 04/19/23 14:00:09.591
• [4.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:647
  STEP: Creating a kubernetes client @ 04/19/23 14:00:09.595
  Apr 19 14:00:09.595: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename svcaccounts @ 04/19/23 14:00:09.596
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:00:09.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:00:09.607
  STEP: creating a ServiceAccount @ 04/19/23 14:00:09.609
  STEP: watching for the ServiceAccount to be added @ 04/19/23 14:00:09.615
  STEP: patching the ServiceAccount @ 04/19/23 14:00:09.618
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 04/19/23 14:00:09.622
  STEP: deleting the ServiceAccount @ 04/19/23 14:00:09.625
  Apr 19 14:00:09.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-605" for this suite. @ 04/19/23 14:00:09.636
• [0.045 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:91
  STEP: Creating a kubernetes client @ 04/19/23 14:00:09.641
  Apr 19 14:00:09.641: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 14:00:09.642
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:00:09.649
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:00:09.652
  STEP: Creating a pod to test downward api env vars @ 04/19/23 14:00:09.654
  W0419 14:00:09.659901      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 14:00:13.671
  Apr 19 14:00:13.674: INFO: Trying to get logs from node talos-default-worker-2 pod downward-api-b1f0f866-31e4-4e44-ae83-34c9ea7dff60 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/23 14:00:13.681
  Apr 19 14:00:13.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4645" for this suite. @ 04/19/23 14:00:13.696
• [4.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 04/19/23 14:00:13.709
  Apr 19 14:00:13.709: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-runtime @ 04/19/23 14:00:13.711
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:00:13.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:00:13.725
  W0419 14:00:13.734316      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "terminate-cmd-rpa" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "terminate-cmd-rpa" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "terminate-cmd-rpa" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "terminate-cmd-rpa" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 04/19/23 14:00:13.735
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 04/19/23 14:00:32.812
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 04/19/23 14:00:32.816
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 04/19/23 14:00:32.821
  STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] @ 04/19/23 14:00:32.821
  W0419 14:00:32.837838      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "terminate-cmd-rpof" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "terminate-cmd-rpof" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "terminate-cmd-rpof" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "terminate-cmd-rpof" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 04/19/23 14:00:32.838
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 04/19/23 14:00:35.86
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 04/19/23 14:00:36.867
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 04/19/23 14:00:36.873
  STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] @ 04/19/23 14:00:36.873
  W0419 14:00:36.888103      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "terminate-cmd-rpn" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "terminate-cmd-rpn" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "terminate-cmd-rpn" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "terminate-cmd-rpn" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 04/19/23 14:00:36.888
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 04/19/23 14:00:37.903
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 04/19/23 14:00:39.916
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 04/19/23 14:00:39.923
  STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] @ 04/19/23 14:00:39.923
  Apr 19 14:00:39.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-340" for this suite. @ 04/19/23 14:00:39.95
• [26.249 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]
test/e2e/apimachinery/webhook.go:249
  STEP: Creating a kubernetes client @ 04/19/23 14:00:39.961
  Apr 19 14:00:39.961: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 14:00:39.962
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:00:39.975
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:00:39.979
  STEP: Setting up server cert @ 04/19/23 14:00:39.994
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 14:00:40.226
  STEP: Deploying the webhook pod @ 04/19/23 14:00:40.231
  W0419 14:00:40.239778      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 14:00:40.239
  Apr 19 14:00:40.248: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 04/19/23 14:00:42.258
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 14:00:42.268
  Apr 19 14:00:43.269: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 04/19/23 14:00:43.273
  STEP: create a configmap that should be updated by the webhook @ 04/19/23 14:00:43.293
  Apr 19 14:00:43.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1038" for this suite. @ 04/19/23 14:00:43.349
  STEP: Destroying namespace "webhook-markers-7289" for this suite. @ 04/19/23 14:00:43.354
• [3.397 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:197
  STEP: Creating a kubernetes client @ 04/19/23 14:00:43.362
  Apr 19 14:00:43.362: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 14:00:43.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:00:43.371
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:00:43.375
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/19/23 14:00:43.377
  W0419 14:00:43.383540      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 14:00:45.389
  Apr 19 14:00:45.392: INFO: Trying to get logs from node talos-default-worker-1 pod pod-44a95a9e-e0ed-4cac-b115-2bd0a0a49b9f container test-container: <nil>
  STEP: delete the pod @ 04/19/23 14:00:45.401
  Apr 19 14:00:45.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1826" for this suite. @ 04/19/23 14:00:45.42
• [2.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
test/e2e/apps/statefulset.go:701
  STEP: Creating a kubernetes client @ 04/19/23 14:00:45.429
  Apr 19 14:00:45.429: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename statefulset @ 04/19/23 14:00:45.431
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:00:45.441
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:00:45.444
  STEP: Creating service test in namespace statefulset-7455 @ 04/19/23 14:00:45.446
  STEP: Creating stateful set ss in namespace statefulset-7455 @ 04/19/23 14:00:45.451
  W0419 14:00:45.457480      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7455 @ 04/19/23 14:00:45.458
  Apr 19 14:00:45.461: INFO: Found 0 stateful pods, waiting for 1
  Apr 19 14:00:55.465: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 04/19/23 14:00:55.465
  Apr 19 14:00:55.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-7455 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 14:00:55.673: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 14:00:55.673: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 14:00:55.673: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 14:00:55.677: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  Apr 19 14:01:05.681: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 19 14:01:05.682: INFO: Waiting for statefulset status.replicas updated to 0
  W0419 14:01:05.691478      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:01:05.694: INFO: POD   NODE                    PHASE    GRACE  CONDITIONS
  Apr 19 14:01:05.694: INFO: ss-0  talos-default-worker-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:00:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:00:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:00:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:00:45 +0000 UTC  }]
  Apr 19 14:01:05.694: INFO: 
  Apr 19 14:01:05.694: INFO: StatefulSet ss has not reached scale 3, at 1
  Apr 19 14:01:06.699: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996688125s
  Apr 19 14:01:07.704: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991210009s
  Apr 19 14:01:08.708: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986875323s
  Apr 19 14:01:09.712: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981716439s
  Apr 19 14:01:10.717: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978608684s
  Apr 19 14:01:11.721: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.974382204s
  Apr 19 14:01:12.725: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.970090685s
  Apr 19 14:01:13.730: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.965874989s
  Apr 19 14:01:14.734: INFO: Verifying statefulset ss doesn't scale past 3 for another 961.299678ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7455 @ 04/19/23 14:01:15.734
  Apr 19 14:01:15.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-7455 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 19 14:01:15.946: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 19 14:01:15.946: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 14:01:15.946: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 19 14:01:15.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-7455 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 19 14:01:16.155: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Apr 19 14:01:16.155: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 14:01:16.155: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 19 14:01:16.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-7455 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 19 14:01:16.335: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Apr 19 14:01:16.335: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 14:01:16.335: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Apr 19 14:01:16.348: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
  Apr 19 14:01:26.355: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 14:01:26.355: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 14:01:26.355: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 04/19/23 14:01:26.355
  Apr 19 14:01:26.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-7455 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 14:01:26.577: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 14:01:26.577: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 14:01:26.577: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 14:01:26.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-7455 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 14:01:26.829: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 14:01:26.830: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 14:01:26.830: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 14:01:26.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-7455 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 14:01:27.004: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 14:01:27.004: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 14:01:27.004: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Apr 19 14:01:27.004: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 14:01:27.008: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
  Apr 19 14:01:37.018: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Apr 19 14:01:37.018: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Apr 19 14:01:37.018: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  W0419 14:01:37.026886      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:01:37.032: INFO: POD   NODE                    PHASE    GRACE  CONDITIONS
  Apr 19 14:01:37.032: INFO: ss-0  talos-default-worker-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:00:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:26 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:00:45 +0000 UTC  }]
  Apr 19 14:01:37.033: INFO: ss-1  talos-default-worker-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:05 +0000 UTC  }]
  Apr 19 14:01:37.035: INFO: ss-2  talos-default-worker-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:05 +0000 UTC  }]
  Apr 19 14:01:37.035: INFO: 
  Apr 19 14:01:37.035: INFO: StatefulSet ss has not reached scale 0, at 3
  Apr 19 14:01:38.040: INFO: POD   NODE                    PHASE      GRACE  CONDITIONS
  Apr 19 14:01:38.040: INFO: ss-0  talos-default-worker-1  Succeeded  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:00:45 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:26 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:26 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:00:45 +0000 UTC  }]
  Apr 19 14:01:38.040: INFO: ss-1  talos-default-worker-2  Succeeded  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:05 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:27 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:27 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:05 +0000 UTC  }]
  Apr 19 14:01:38.040: INFO: ss-2  talos-default-worker-1  Succeeded  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:05 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:27 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:27 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-19 14:01:05 +0000 UTC  }]
  Apr 19 14:01:38.040: INFO: 
  Apr 19 14:01:38.040: INFO: StatefulSet ss has not reached scale 0, at 3
  Apr 19 14:01:39.044: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.986307906s
  Apr 19 14:01:40.048: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.982295958s
  Apr 19 14:01:41.052: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.97829998s
  Apr 19 14:01:42.057: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.972741402s
  Apr 19 14:01:43.061: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.969009105s
  Apr 19 14:01:44.065: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.965320582s
  Apr 19 14:01:45.069: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.961226965s
  Apr 19 14:01:46.072: INFO: Verifying statefulset ss doesn't scale past 0 for another 957.416052ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7455 @ 04/19/23 14:01:47.073
  Apr 19 14:01:47.077: INFO: Scaling statefulset ss to 0
  W0419 14:01:47.084874      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:01:47.087: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 14:01:47.092: INFO: Deleting all statefulset in ns statefulset-7455
  Apr 19 14:01:47.095: INFO: Scaling statefulset ss to 0
  W0419 14:01:47.101819      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:01:47.104: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 14:01:47.107: INFO: Deleting statefulset ss
  Apr 19 14:01:47.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7455" for this suite. @ 04/19/23 14:01:47.122
• [61.700 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 04/19/23 14:01:47.136
  Apr 19 14:01:47.136: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/23 14:01:47.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:01:47.151
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:01:47.155
  Apr 19 14:01:47.158: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/19/23 14:01:48.587
  Apr 19 14:01:48.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-4070 --namespace=crd-publish-openapi-4070 create -f -'
  Apr 19 14:01:49.129: INFO: stderr: ""
  Apr 19 14:01:49.130: INFO: stdout: "e2e-test-crd-publish-openapi-5136-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Apr 19 14:01:49.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-4070 --namespace=crd-publish-openapi-4070 delete e2e-test-crd-publish-openapi-5136-crds test-cr'
  Apr 19 14:01:49.208: INFO: stderr: ""
  Apr 19 14:01:49.208: INFO: stdout: "e2e-test-crd-publish-openapi-5136-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Apr 19 14:01:49.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-4070 --namespace=crd-publish-openapi-4070 apply -f -'
  Apr 19 14:01:49.705: INFO: stderr: ""
  Apr 19 14:01:49.705: INFO: stdout: "e2e-test-crd-publish-openapi-5136-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Apr 19 14:01:49.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-4070 --namespace=crd-publish-openapi-4070 delete e2e-test-crd-publish-openapi-5136-crds test-cr'
  Apr 19 14:01:49.776: INFO: stderr: ""
  Apr 19 14:01:49.776: INFO: stdout: "e2e-test-crd-publish-openapi-5136-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 04/19/23 14:01:49.776
  Apr 19 14:01:49.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-4070 explain e2e-test-crd-publish-openapi-5136-crds'
  Apr 19 14:01:50.362: INFO: stderr: ""
  Apr 19 14:01:50.362: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-5136-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  Apr 19 14:01:51.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4070" for this suite. @ 04/19/23 14:01:51.826
• [4.701 seconds]
------------------------------
S
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]
test/e2e/network/endpointslice.go:68
  STEP: Creating a kubernetes client @ 04/19/23 14:01:51.836
  Apr 19 14:01:51.836: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename endpointslice @ 04/19/23 14:01:51.837
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:01:51.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:01:51.852
  Apr 19 14:01:51.861: INFO: Endpoints addresses: [172.20.0.2 172.20.0.3 172.20.0.4] , ports: [6443]
  Apr 19 14:01:51.861: INFO: EndpointSlices addresses: [172.20.0.2 172.20.0.3 172.20.0.4] , ports: [6443]
  Apr 19 14:01:51.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-285" for this suite. @ 04/19/23 14:01:51.866
• [0.034 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance]
test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 04/19/23 14:01:51.872
  Apr 19 14:01:51.872: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename dns @ 04/19/23 14:01:51.875
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:01:51.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:01:51.888
  STEP: Creating a test externalName service @ 04/19/23 14:01:51.89
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6002.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6002.svc.cluster.local; sleep 1; done
   @ 04/19/23 14:01:51.894
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6002.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6002.svc.cluster.local; sleep 1; done
   @ 04/19/23 14:01:51.894
  STEP: creating a pod to probe DNS @ 04/19/23 14:01:51.894
  STEP: submitting the pod to kubernetes @ 04/19/23 14:01:51.894
  W0419 14:01:51.900688      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: retrieving the pod @ 04/19/23 14:01:53.91
  STEP: looking for the results for each expected name from probers @ 04/19/23 14:01:53.914
  Apr 19 14:01:53.923: INFO: DNS probes using dns-test-57c7fbd3-4ebb-404b-8f46-7337a9ce3aee succeeded

  STEP: changing the externalName to bar.example.com @ 04/19/23 14:01:53.923
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6002.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6002.svc.cluster.local; sleep 1; done
   @ 04/19/23 14:01:53.932
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6002.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6002.svc.cluster.local; sleep 1; done
   @ 04/19/23 14:01:53.932
  STEP: creating a second pod to probe DNS @ 04/19/23 14:01:53.932
  STEP: submitting the pod to kubernetes @ 04/19/23 14:01:53.934
  W0419 14:01:53.946596      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: retrieving the pod @ 04/19/23 14:01:55.958
  STEP: looking for the results for each expected name from probers @ 04/19/23 14:01:55.963
  Apr 19 14:01:55.968: INFO: File wheezy_udp@dns-test-service-3.dns-6002.svc.cluster.local from pod  dns-6002/dns-test-d44b41dc-ab6b-4c6e-9fb9-65a1cc4b794f contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 19 14:01:55.976: INFO: File jessie_udp@dns-test-service-3.dns-6002.svc.cluster.local from pod  dns-6002/dns-test-d44b41dc-ab6b-4c6e-9fb9-65a1cc4b794f contains 'foo.example.com.
  ' instead of 'bar.example.com.'
  Apr 19 14:01:55.981: INFO: Lookups using dns-6002/dns-test-d44b41dc-ab6b-4c6e-9fb9-65a1cc4b794f failed for: [wheezy_udp@dns-test-service-3.dns-6002.svc.cluster.local jessie_udp@dns-test-service-3.dns-6002.svc.cluster.local]

  Apr 19 14:02:00.995: INFO: DNS probes using dns-test-d44b41dc-ab6b-4c6e-9fb9-65a1cc4b794f succeeded

  STEP: changing the service to type=ClusterIP @ 04/19/23 14:02:00.995
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6002.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-6002.svc.cluster.local; sleep 1; done
   @ 04/19/23 14:02:01.015
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6002.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6002.svc.cluster.local; sleep 1; done
   @ 04/19/23 14:02:01.02
  STEP: creating a third pod to probe DNS @ 04/19/23 14:02:01.022
  STEP: submitting the pod to kubernetes @ 04/19/23 14:02:01.028
  W0419 14:02:01.035583      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: retrieving the pod @ 04/19/23 14:02:03.047
  STEP: looking for the results for each expected name from probers @ 04/19/23 14:02:03.051
  Apr 19 14:02:03.061: INFO: DNS probes using dns-test-9fd3620f-5938-47c0-b78f-a72dfa6976c5 succeeded

  Apr 19 14:02:03.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 14:02:03.067
  STEP: deleting the pod @ 04/19/23 14:02:03.086
  STEP: deleting the pod @ 04/19/23 14:02:03.102
  STEP: deleting the test externalName service @ 04/19/23 14:02:03.116
  STEP: Destroying namespace "dns-6002" for this suite. @ 04/19/23 14:02:03.134
• [11.268 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 04/19/23 14:02:03.143
  Apr 19 14:02:03.143: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename secrets @ 04/19/23 14:02:03.144
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:02:03.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:02:03.159
  STEP: Creating secret with name secret-test-81351589-7e95-44ca-93dc-aa8dd09868e7 @ 04/19/23 14:02:03.16
  STEP: Creating a pod to test consume secrets @ 04/19/23 14:02:03.165
  W0419 14:02:03.171506      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 14:02:07.183
  Apr 19 14:02:07.186: INFO: Trying to get logs from node talos-default-worker-1 pod pod-secrets-d701d924-ff43-4b1a-8d4c-72785cd4c7ce container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 14:02:07.198
  Apr 19 14:02:07.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7384" for this suite. @ 04/19/23 14:02:07.218
• [4.081 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:89
  STEP: Creating a kubernetes client @ 04/19/23 14:02:07.225
  Apr 19 14:02:07.225: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 14:02:07.226
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:02:07.24
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:02:07.243
  STEP: Creating configMap with name projected-configmap-test-volume-map-ae403461-5736-439a-ab1c-e5dd52d13170 @ 04/19/23 14:02:07.246
  STEP: Creating a pod to test consume configMaps @ 04/19/23 14:02:07.251
  W0419 14:02:07.259365      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 14:02:11.276
  Apr 19 14:02:11.280: INFO: Trying to get logs from node talos-default-worker-1 pod pod-projected-configmaps-7c9f5245-a40e-49e9-b800-3f38a894ab2e container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 14:02:11.288
  Apr 19 14:02:11.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7882" for this suite. @ 04/19/23 14:02:11.308
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]
test/e2e/apps/statefulset.go:327
  STEP: Creating a kubernetes client @ 04/19/23 14:02:11.32
  Apr 19 14:02:11.320: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename statefulset @ 04/19/23 14:02:11.322
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:02:11.342
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:02:11.346
  STEP: Creating service test in namespace statefulset-1688 @ 04/19/23 14:02:11.349
  STEP: Creating a new StatefulSet @ 04/19/23 14:02:11.354
  W0419 14:02:11.359781      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:02:11.363: INFO: Found 0 stateful pods, waiting for 3
  Apr 19 14:02:21.370: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 14:02:21.370: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 14:02:21.371: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=false
  Apr 19 14:02:31.371: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 14:02:31.371: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 14:02:31.371: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/19/23 14:02:31.384
  W0419 14:02:31.405140      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:02:31.405: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 04/19/23 14:02:31.405
  STEP: Not applying an update when the partition is greater than the number of replicas @ 04/19/23 14:02:41.424
  STEP: Performing a canary update @ 04/19/23 14:02:41.424
  W0419 14:02:41.444657      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:02:41.444: INFO: Updating stateful set ss2
  Apr 19 14:02:41.456: INFO: Waiting for Pod statefulset-1688/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  STEP: Restoring Pods to the correct revision when they are deleted @ 04/19/23 14:02:51.466
  Apr 19 14:02:51.504: INFO: Found 2 stateful pods, waiting for 3
  Apr 19 14:03:01.513: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 14:03:01.513: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 14:03:01.513: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=false
  Apr 19 14:03:11.509: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 14:03:11.510: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 14:03:11.510: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 04/19/23 14:03:11.517
  W0419 14:03:11.537405      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:03:11.537: INFO: Updating stateful set ss2
  Apr 19 14:03:11.552: INFO: Waiting for Pod statefulset-1688/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  W0419 14:03:21.584754      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:03:21.584: INFO: Updating stateful set ss2
  Apr 19 14:03:21.593: INFO: Waiting for StatefulSet statefulset-1688/ss2 to complete update
  Apr 19 14:03:21.593: INFO: Waiting for Pod statefulset-1688/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  Apr 19 14:03:31.602: INFO: Deleting all statefulset in ns statefulset-1688
  Apr 19 14:03:31.606: INFO: Scaling statefulset ss2 to 0
  W0419 14:03:31.620960      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:03:41.635: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 14:03:41.638: INFO: Deleting statefulset ss2
  Apr 19 14:03:41.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1688" for this suite. @ 04/19/23 14:03:41.657
• [90.347 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 04/19/23 14:03:41.668
  Apr 19 14:03:41.669: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 14:03:41.671
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:03:41.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:03:41.698
  STEP: Creating projection with secret that has name projected-secret-test-8ce51de4-fdd5-4d62-89e2-c0ec68355349 @ 04/19/23 14:03:41.701
  STEP: Creating a pod to test consume secrets @ 04/19/23 14:03:41.706
  W0419 14:03:41.714950      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "projected-secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "projected-secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "projected-secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "projected-secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 14:03:43.723
  Apr 19 14:03:43.727: INFO: Trying to get logs from node talos-default-worker-1 pod pod-projected-secrets-a2bdb011-449e-4c6f-ab28-716f2bbcf960 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 14:03:43.744
  Apr 19 14:03:43.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5598" for this suite. @ 04/19/23 14:03:43.764
• [2.103 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:354
  STEP: Creating a kubernetes client @ 04/19/23 14:03:43.775
  Apr 19 14:03:43.775: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 14:03:43.776
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:03:43.79
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:03:43.793
  STEP: creating a replication controller @ 04/19/23 14:03:43.796
  Apr 19 14:03:43.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 create -f -'
  Apr 19 14:03:44.325: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"update-demo\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"update-demo\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"update-demo\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"update-demo\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 14:03:44.325: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/19/23 14:03:44.325
  Apr 19 14:03:44.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 19 14:03:44.382: INFO: stderr: ""
  Apr 19 14:03:44.382: INFO: stdout: "update-demo-nautilus-d6pxb update-demo-nautilus-jgzdw "
  Apr 19 14:03:44.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods update-demo-nautilus-d6pxb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 14:03:44.432: INFO: stderr: ""
  Apr 19 14:03:44.432: INFO: stdout: ""
  Apr 19 14:03:44.432: INFO: update-demo-nautilus-d6pxb is created but not running
  Apr 19 14:03:49.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 19 14:03:49.514: INFO: stderr: ""
  Apr 19 14:03:49.514: INFO: stdout: "update-demo-nautilus-d6pxb update-demo-nautilus-jgzdw "
  Apr 19 14:03:49.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods update-demo-nautilus-d6pxb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 14:03:49.585: INFO: stderr: ""
  Apr 19 14:03:49.585: INFO: stdout: "true"
  Apr 19 14:03:49.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods update-demo-nautilus-d6pxb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 19 14:03:49.636: INFO: stderr: ""
  Apr 19 14:03:49.637: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 19 14:03:49.637: INFO: validating pod update-demo-nautilus-d6pxb
  Apr 19 14:04:04.883: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 19 14:04:04.883: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 19 14:04:04.883: INFO: update-demo-nautilus-d6pxb is verified up and running
  Apr 19 14:04:04.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods update-demo-nautilus-jgzdw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 14:04:04.974: INFO: stderr: ""
  Apr 19 14:04:04.974: INFO: stdout: "true"
  Apr 19 14:04:04.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods update-demo-nautilus-jgzdw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 19 14:04:05.048: INFO: stderr: ""
  Apr 19 14:04:05.048: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 19 14:04:05.048: INFO: validating pod update-demo-nautilus-jgzdw
  Apr 19 14:04:20.499: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 19 14:04:20.499: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 19 14:04:20.499: INFO: update-demo-nautilus-jgzdw is verified up and running
  STEP: scaling down the replication controller @ 04/19/23 14:04:20.499
  Apr 19 14:04:20.503: INFO: scanned /root for discovery docs: <nil>
  Apr 19 14:04:20.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  Apr 19 14:04:21.609: INFO: stderr: ""
  Apr 19 14:04:21.609: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/19/23 14:04:21.609
  Apr 19 14:04:21.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 19 14:04:21.711: INFO: stderr: ""
  Apr 19 14:04:21.711: INFO: stdout: "update-demo-nautilus-d6pxb "
  Apr 19 14:04:21.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods update-demo-nautilus-d6pxb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 14:04:21.800: INFO: stderr: ""
  Apr 19 14:04:21.800: INFO: stdout: "true"
  Apr 19 14:04:21.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods update-demo-nautilus-d6pxb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 19 14:04:21.878: INFO: stderr: ""
  Apr 19 14:04:21.878: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 19 14:04:21.878: INFO: validating pod update-demo-nautilus-d6pxb
  Apr 19 14:04:21.882: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 19 14:04:21.883: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 19 14:04:21.883: INFO: update-demo-nautilus-d6pxb is verified up and running
  STEP: scaling up the replication controller @ 04/19/23 14:04:21.883
  Apr 19 14:04:21.886: INFO: scanned /root for discovery docs: <nil>
  Apr 19 14:04:21.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  Apr 19 14:04:22.965: INFO: stderr: ""
  Apr 19 14:04:22.965: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/19/23 14:04:22.966
  Apr 19 14:04:22.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 19 14:04:23.070: INFO: stderr: ""
  Apr 19 14:04:23.070: INFO: stdout: "update-demo-nautilus-4xsj6 update-demo-nautilus-d6pxb "
  Apr 19 14:04:23.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods update-demo-nautilus-4xsj6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 14:04:23.133: INFO: stderr: ""
  Apr 19 14:04:23.133: INFO: stdout: "true"
  Apr 19 14:04:23.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods update-demo-nautilus-4xsj6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 19 14:04:23.186: INFO: stderr: ""
  Apr 19 14:04:23.186: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 19 14:04:23.186: INFO: validating pod update-demo-nautilus-4xsj6
  Apr 19 14:04:23.193: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 19 14:04:23.193: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 19 14:04:23.193: INFO: update-demo-nautilus-4xsj6 is verified up and running
  Apr 19 14:04:23.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods update-demo-nautilus-d6pxb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 14:04:23.247: INFO: stderr: ""
  Apr 19 14:04:23.247: INFO: stdout: "true"
  Apr 19 14:04:23.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods update-demo-nautilus-d6pxb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 19 14:04:23.301: INFO: stderr: ""
  Apr 19 14:04:23.301: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 19 14:04:23.301: INFO: validating pod update-demo-nautilus-d6pxb
  Apr 19 14:04:23.306: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 19 14:04:23.306: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 19 14:04:23.306: INFO: update-demo-nautilus-d6pxb is verified up and running
  STEP: using delete to clean up resources @ 04/19/23 14:04:23.307
  Apr 19 14:04:23.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 delete --grace-period=0 --force -f -'
  Apr 19 14:04:23.365: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 14:04:23.365: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Apr 19 14:04:23.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get rc,svc -l name=update-demo --no-headers'
  Apr 19 14:04:23.460: INFO: stderr: "No resources found in kubectl-1899 namespace.\n"
  Apr 19 14:04:23.460: INFO: stdout: ""
  Apr 19 14:04:23.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-1899 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 19 14:04:23.545: INFO: stderr: ""
  Apr 19 14:04:23.545: INFO: stdout: ""
  Apr 19 14:04:23.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1899" for this suite. @ 04/19/23 14:04:23.549
• [39.783 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
test/e2e/apimachinery/aggregator.go:92
  STEP: Creating a kubernetes client @ 04/19/23 14:04:23.558
  Apr 19 14:04:23.558: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename aggregator @ 04/19/23 14:04:23.558
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:04:23.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:04:23.574
  Apr 19 14:04:23.576: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Registering the sample API server. @ 04/19/23 14:04:23.577
  Apr 19 14:04:23.762: INFO: Found ClusterRoles; assuming RBAC is enabled.
  W0419 14:04:23.778730      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "sample-apiserver", "etcd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "sample-apiserver", "etcd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "sample-apiserver", "etcd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "sample-apiserver", "etcd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:04:23.785: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
  Apr 19 14:04:25.834: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 14:04:27.841: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 14:04:29.841: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 14:04:31.841: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 14:04:33.840: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 14:04:35.840: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 14:04:37.839: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 14:04:39.840: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 14:04:41.842: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 14:04:43.840: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6dfd6dfd5b\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 14:04:45.956: INFO: Waited 111.413459ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 04/19/23 14:04:45.988
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 04/19/23 14:04:45.992
  STEP: List APIServices @ 04/19/23 14:04:46.002
  Apr 19 14:04:46.007: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 04/19/23 14:04:46.007
  Apr 19 14:04:46.017: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 04/19/23 14:04:46.017
  Apr 19 14:04:46.025: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2023, time.April, 19, 14, 4, 45, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 04/19/23 14:04:46.025
  Apr 19 14:04:46.028: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2023-04-19 14:04:45 +0000 UTC Passed all checks passed}
  Apr 19 14:04:46.028: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 19 14:04:46.028: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 04/19/23 14:04:46.029
  Apr 19 14:04:46.037: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete APIService "dynamic-flunder-534491780" @ 04/19/23 14:04:46.037
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 04/19/23 14:04:46.05
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 04/19/23 14:04:46.054
  STEP: Patch APIService Status @ 04/19/23 14:04:46.057
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 04/19/23 14:04:46.062
  Apr 19 14:04:46.066: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2023-04-19 14:04:45 +0000 UTC Passed all checks passed}
  Apr 19 14:04:46.066: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 19 14:04:46.066: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Apr 19 14:04:46.066: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "e2e-apiservice=patched" @ 04/19/23 14:04:46.066
  STEP: Confirm that the generated APIService has been deleted @ 04/19/23 14:04:46.071
  Apr 19 14:04:46.071: INFO: Requesting list of APIServices to confirm quantity
  Apr 19 14:04:46.075: INFO: Found 0 APIService with label "e2e-apiservice=patched"
  Apr 19 14:04:46.075: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  Apr 19 14:04:46.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-5863" for this suite. @ 04/19/23 14:04:46.153
• [22.600 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
test/e2e/scheduling/limit_range.go:61
  STEP: Creating a kubernetes client @ 04/19/23 14:04:46.16
  Apr 19 14:04:46.160: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename limitrange @ 04/19/23 14:04:46.161
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:04:46.172
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:04:46.175
  STEP: Creating a LimitRange @ 04/19/23 14:04:46.177
  STEP: Setting up watch @ 04/19/23 14:04:46.177
  STEP: Submitting a LimitRange @ 04/19/23 14:04:46.28
  STEP: Verifying LimitRange creation was observed @ 04/19/23 14:04:46.29
  STEP: Fetching the LimitRange to ensure it has proper values @ 04/19/23 14:04:46.29
  Apr 19 14:04:46.294: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Apr 19 14:04:46.294: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 04/19/23 14:04:46.294
  W0419 14:04:46.300205      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 04/19/23 14:04:46.3
  Apr 19 14:04:46.304: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Apr 19 14:04:46.304: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 04/19/23 14:04:46.305
  W0419 14:04:46.309690      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 04/19/23 14:04:46.311
  Apr 19 14:04:46.318: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Apr 19 14:04:46.318: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 04/19/23 14:04:46.318
  STEP: Failing to create a Pod with more than max resources @ 04/19/23 14:04:46.32
  STEP: Updating a LimitRange @ 04/19/23 14:04:46.321
  STEP: Verifying LimitRange updating is effective @ 04/19/23 14:04:46.325
  STEP: Creating a Pod with less than former min resources @ 04/19/23 14:04:48.329
  W0419 14:04:48.335453      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Failing to create a Pod with more than max resources @ 04/19/23 14:04:48.335
  STEP: Deleting a LimitRange @ 04/19/23 14:04:48.34
  STEP: Verifying the LimitRange was deleted @ 04/19/23 14:04:48.346
  Apr 19 14:04:53.351: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 04/19/23 14:04:53.351
  W0419 14:04:53.357208      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pause" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pause" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pause" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pause" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:04:53.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-4363" for this suite. @ 04/19/23 14:04:53.362
• [7.209 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:198
  STEP: Creating a kubernetes client @ 04/19/23 14:04:53.372
  Apr 19 14:04:53.372: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/23 14:04:53.374
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:04:53.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:04:53.393
  STEP: fetching the /apis discovery document @ 04/19/23 14:04:53.397
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 04/19/23 14:04:53.398
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 04/19/23 14:04:53.398
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 04/19/23 14:04:53.399
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 04/19/23 14:04:53.4
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 04/19/23 14:04:53.4
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 04/19/23 14:04:53.401
  Apr 19 14:04:53.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-5648" for this suite. @ 04/19/23 14:04:53.404
• [0.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:207
  STEP: Creating a kubernetes client @ 04/19/23 14:04:53.411
  Apr 19 14:04:53.411: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 14:04:53.412
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:04:53.421
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:04:53.423
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/19/23 14:04:53.424
  W0419 14:04:53.430135      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 14:04:57.441
  Apr 19 14:04:57.444: INFO: Trying to get logs from node talos-default-worker-1 pod pod-dbee05eb-5bd1-4f59-a22f-d91b5d750da0 container test-container: <nil>
  STEP: delete the pod @ 04/19/23 14:04:57.451
  Apr 19 14:04:57.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2816" for this suite. @ 04/19/23 14:04:57.469
• [4.063 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]
test/e2e/kubectl/kubectl.go:1800
  STEP: Creating a kubernetes client @ 04/19/23 14:04:57.475
  Apr 19 14:04:57.475: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 14:04:57.477
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:04:57.488
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:04:57.491
  STEP: Starting the proxy @ 04/19/23 14:04:57.494
  Apr 19 14:04:57.495: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-9201 proxy --unix-socket=/tmp/kubectl-proxy-unix360231057/test'
  STEP: retrieving proxy /api/ output @ 04/19/23 14:04:57.535
  Apr 19 14:04:57.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9201" for this suite. @ 04/19/23 14:04:57.542
• [0.072 seconds]
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 04/19/23 14:04:57.547
  Apr 19 14:04:57.547: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename sched-preemption @ 04/19/23 14:04:57.549
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:04:57.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:04:57.562
  Apr 19 14:04:57.574: INFO: Waiting up to 1m0s for all nodes to be ready
  Apr 19 14:05:57.595: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/19/23 14:05:57.599
  Apr 19 14:05:57.599: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/19/23 14:05:57.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:05:57.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:05:57.618
  Apr 19 14:05:57.631: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Apr 19 14:05:57.635: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  Apr 19 14:05:57.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 19 14:05:57.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-6833" for this suite. @ 04/19/23 14:05:57.689
  STEP: Destroying namespace "sched-preemption-7387" for this suite. @ 04/19/23 14:05:57.693
• [60.151 seconds]
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 04/19/23 14:05:57.699
  Apr 19 14:05:57.699: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename var-expansion @ 04/19/23 14:05:57.701
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:05:57.711
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:05:57.714
  STEP: Creating a pod to test substitution in container's args @ 04/19/23 14:05:57.716
  W0419 14:05:57.721926      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 14:06:01.733
  Apr 19 14:06:01.736: INFO: Trying to get logs from node talos-default-worker-1 pod var-expansion-c9341fd9-351b-4219-b76a-fe27f6a60479 container dapi-container: <nil>
  STEP: delete the pod @ 04/19/23 14:06:01.744
  Apr 19 14:06:01.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4043" for this suite. @ 04/19/23 14:06:01.763
• [4.071 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]
test/e2e/common/node/secrets.go:140
  STEP: Creating a kubernetes client @ 04/19/23 14:06:01.774
  Apr 19 14:06:01.775: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename secrets @ 04/19/23 14:06:01.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:06:01.796
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:06:01.799
  STEP: Creating projection with secret that has name secret-emptykey-test-6438d5b9-64e4-437b-80b9-d8c0589223fe @ 04/19/23 14:06:01.802
  Apr 19 14:06:01.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2639" for this suite. @ 04/19/23 14:06:01.809
• [0.042 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:77
  STEP: Creating a kubernetes client @ 04/19/23 14:06:01.816
  Apr 19 14:06:01.817: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename sysctl @ 04/19/23 14:06:01.819
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:06:01.832
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:06:01.835
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 04/19/23 14:06:01.846
  W0419 14:06:01.853475      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Watching for error events or started pod @ 04/19/23 14:06:01.853
  STEP: Waiting for pod completion @ 04/19/23 14:06:03.86
  STEP: Checking that the pod succeeded @ 04/19/23 14:06:05.871
  STEP: Getting logs from the pod @ 04/19/23 14:06:05.871
  STEP: Checking that the sysctl is actually updated @ 04/19/23 14:06:05.877
  Apr 19 14:06:05.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-7498" for this suite. @ 04/19/23 14:06:05.882
• [4.072 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:167
  STEP: Creating a kubernetes client @ 04/19/23 14:06:05.889
  Apr 19 14:06:05.890: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 14:06:05.891
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:06:05.911
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:06:05.914
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 04/19/23 14:06:05.918
  W0419 14:06:05.925372      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 14:06:09.938
  Apr 19 14:06:09.942: INFO: Trying to get logs from node talos-default-worker-1 pod pod-a3a080da-a987-4b0b-ae2d-194ae90bfb62 container test-container: <nil>
  STEP: delete the pod @ 04/19/23 14:06:09.949
  Apr 19 14:06:09.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1125" for this suite. @ 04/19/23 14:06:09.97
• [4.087 seconds]
------------------------------
SS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:129
  STEP: Creating a kubernetes client @ 04/19/23 14:06:09.977
  Apr 19 14:06:09.978: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/23 14:06:09.981
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:06:09.995
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:06:09.998
  W0419 14:06:10.010397      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:06:10.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-1803" for this suite. @ 04/19/23 14:06:10.022
• [0.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance]
test/e2e/apps/job.go:713
  STEP: Creating a kubernetes client @ 04/19/23 14:06:10.03
  Apr 19 14:06:10.030: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename job @ 04/19/23 14:06:10.032
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:06:10.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:06:10.048
  STEP: Creating a suspended job @ 04/19/23 14:06:10.052
  W0419 14:06:10.055103      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Patching the Job @ 04/19/23 14:06:10.055
  W0419 14:06:10.065823      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Watching for Job to be patched @ 04/19/23 14:06:10.065
  Apr 19 14:06:10.068: INFO: Event ADDED observed for Job e2e-vz6nc in namespace job-5923 with labels: map[e2e-job-label:e2e-vz6nc] and annotations: map[batch.kubernetes.io/job-tracking:]
  Apr 19 14:06:10.068: INFO: Event MODIFIED observed for Job e2e-vz6nc in namespace job-5923 with labels: map[e2e-job-label:e2e-vz6nc] and annotations: map[batch.kubernetes.io/job-tracking:]
  Apr 19 14:06:10.068: INFO: Event MODIFIED found for Job e2e-vz6nc in namespace job-5923 with labels: map[e2e-job-label:e2e-vz6nc e2e-vz6nc:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
  STEP: Updating the job @ 04/19/23 14:06:10.068
  W0419 14:06:10.074414      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Watching for Job to be updated @ 04/19/23 14:06:10.074
  Apr 19 14:06:10.076: INFO: Event MODIFIED found for Job e2e-vz6nc in namespace job-5923 with labels: map[e2e-job-label:e2e-vz6nc e2e-vz6nc:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 19 14:06:10.076: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 04/19/23 14:06:10.076
  Apr 19 14:06:10.079: INFO: Job: e2e-vz6nc as labels: map[e2e-job-label:e2e-vz6nc e2e-vz6nc:patched]
  STEP: Waiting for job to complete @ 04/19/23 14:06:10.079
  STEP: Delete a job collection with a labelselector @ 04/19/23 14:06:16.085
  STEP: Watching for Job to be deleted @ 04/19/23 14:06:16.094
  Apr 19 14:06:16.096: INFO: Event MODIFIED observed for Job e2e-vz6nc in namespace job-5923 with labels: map[e2e-job-label:e2e-vz6nc e2e-vz6nc:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 19 14:06:16.096: INFO: Event MODIFIED observed for Job e2e-vz6nc in namespace job-5923 with labels: map[e2e-job-label:e2e-vz6nc e2e-vz6nc:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 19 14:06:16.097: INFO: Event MODIFIED observed for Job e2e-vz6nc in namespace job-5923 with labels: map[e2e-job-label:e2e-vz6nc e2e-vz6nc:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 19 14:06:16.097: INFO: Event MODIFIED observed for Job e2e-vz6nc in namespace job-5923 with labels: map[e2e-job-label:e2e-vz6nc e2e-vz6nc:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 19 14:06:16.097: INFO: Event MODIFIED observed for Job e2e-vz6nc in namespace job-5923 with labels: map[e2e-job-label:e2e-vz6nc e2e-vz6nc:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 19 14:06:16.098: INFO: Event MODIFIED observed for Job e2e-vz6nc in namespace job-5923 with labels: map[e2e-job-label:e2e-vz6nc e2e-vz6nc:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 19 14:06:16.098: INFO: Event MODIFIED observed for Job e2e-vz6nc in namespace job-5923 with labels: map[e2e-job-label:e2e-vz6nc e2e-vz6nc:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 19 14:06:16.099: INFO: Event MODIFIED observed for Job e2e-vz6nc in namespace job-5923 with labels: map[e2e-job-label:e2e-vz6nc e2e-vz6nc:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  Apr 19 14:06:16.099: INFO: Event DELETED found for Job e2e-vz6nc in namespace job-5923 with labels: map[e2e-job-label:e2e-vz6nc e2e-vz6nc:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
  STEP: Relist jobs to confirm deletion @ 04/19/23 14:06:16.099
  Apr 19 14:06:16.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5923" for this suite. @ 04/19/23 14:06:16.107
• [6.085 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 04/19/23 14:06:16.117
  Apr 19 14:06:16.117: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pods @ 04/19/23 14:06:16.117
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:06:16.129
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:06:16.132
  STEP: creating the pod @ 04/19/23 14:06:16.134
  STEP: submitting the pod to kubernetes @ 04/19/23 14:06:16.134
  W0419 14:06:16.139234      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: verifying the pod is in kubernetes @ 04/19/23 14:06:18.15
  STEP: updating the pod @ 04/19/23 14:06:18.152
  Apr 19 14:06:18.664: INFO: Successfully updated pod "pod-update-activedeadlineseconds-21767bba-8c7d-4183-82d8-4951c953943c"
  Apr 19 14:06:22.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3698" for this suite. @ 04/19/23 14:06:22.682
• [6.576 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:107
  STEP: Creating a kubernetes client @ 04/19/23 14:06:22.695
  Apr 19 14:06:22.695: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 14:06:22.698
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:06:22.71
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:06:22.713
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/19/23 14:06:22.716
  W0419 14:06:22.724350      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 14:06:26.738
  Apr 19 14:06:26.741: INFO: Trying to get logs from node talos-default-worker-1 pod pod-fc76e186-a164-46dd-bd87-c309fdbea37f container test-container: <nil>
  STEP: delete the pod @ 04/19/23 14:06:26.749
  Apr 19 14:06:26.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9348" for this suite. @ 04/19/23 14:06:26.773
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]
test/e2e/apimachinery/webhook.go:198
  STEP: Creating a kubernetes client @ 04/19/23 14:06:26.792
  Apr 19 14:06:26.793: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 14:06:26.797
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:06:26.815
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:06:26.819
  STEP: Setting up server cert @ 04/19/23 14:06:26.835
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 14:06:27.177
  STEP: Deploying the webhook pod @ 04/19/23 14:06:27.184
  W0419 14:06:27.194214      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 14:06:27.194
  Apr 19 14:06:27.201: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  Apr 19 14:06:29.215: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7497495989\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 14:06:31.220: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7497495989\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 14:06:33.220: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7497495989\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Apr 19 14:06:35.219: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 19, 14, 6, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7497495989\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 04/19/23 14:06:37.219
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 14:06:37.237
  Apr 19 14:06:38.238: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/19/23 14:06:38.243
  STEP: create a pod that should be denied by the webhook @ 04/19/23 14:06:38.261
  W0419 14:06:38.281907      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webhook-disallow" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webhook-disallow" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webhook-disallow" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webhook-disallow" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: create a pod that causes the webhook to hang @ 04/19/23 14:06:38.282
  W0419 14:06:48.287880      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "wait-forever" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "wait-forever" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "wait-forever" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "wait-forever" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: create a configmap that should be denied by the webhook @ 04/19/23 14:06:48.291
  STEP: create a configmap that should be admitted by the webhook @ 04/19/23 14:06:48.301
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/19/23 14:06:48.311
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 04/19/23 14:06:48.322
  STEP: create a namespace that bypass the webhook @ 04/19/23 14:06:48.328
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 04/19/23 14:06:48.342
  Apr 19 14:06:48.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4274" for this suite. @ 04/19/23 14:06:48.409
  STEP: Destroying namespace "webhook-markers-619" for this suite. @ 04/19/23 14:06:48.415
  STEP: Destroying namespace "exempted-namespace-1608" for this suite. @ 04/19/23 14:06:48.421
• [21.634 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 04/19/23 14:06:48.429
  Apr 19 14:06:48.429: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-probe @ 04/19/23 14:06:48.431
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:06:48.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:06:48.444
  STEP: Creating pod liveness-9420d4a1-da72-43c8-855d-17f85509f58d in namespace container-probe-448 @ 04/19/23 14:06:48.446
  W0419 14:06:48.452461      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:06:50.460: INFO: Started pod liveness-9420d4a1-da72-43c8-855d-17f85509f58d in namespace container-probe-448
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/23 14:06:50.46
  Apr 19 14:06:50.464: INFO: Initial restart count of pod liveness-9420d4a1-da72-43c8-855d-17f85509f58d is 0
  Apr 19 14:07:10.511: INFO: Restart count of pod container-probe-448/liveness-9420d4a1-da72-43c8-855d-17f85509f58d is now 1 (20.046828872s elapsed)
  Apr 19 14:07:10.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 14:07:10.515
  STEP: Destroying namespace "container-probe-448" for this suite. @ 04/19/23 14:07:10.528
• [22.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 04/19/23 14:07:10.539
  Apr 19 14:07:10.541: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename watch @ 04/19/23 14:07:10.544
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:07:10.561
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:07:10.565
  STEP: creating a watch on configmaps with a certain label @ 04/19/23 14:07:10.569
  STEP: creating a new configmap @ 04/19/23 14:07:10.57
  STEP: modifying the configmap once @ 04/19/23 14:07:10.575
  STEP: changing the label value of the configmap @ 04/19/23 14:07:10.583
  STEP: Expecting to observe a delete notification for the watched object @ 04/19/23 14:07:10.59
  Apr 19 14:07:10.590: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3042  1be73493-e4f6-43ec-935c-4e0e3f44e9e8 204296 0 2023-04-19 14:07:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-19 14:07:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 14:07:10.591: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3042  1be73493-e4f6-43ec-935c-4e0e3f44e9e8 204297 0 2023-04-19 14:07:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-19 14:07:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 14:07:10.591: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3042  1be73493-e4f6-43ec-935c-4e0e3f44e9e8 204298 0 2023-04-19 14:07:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-19 14:07:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 04/19/23 14:07:10.591
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 04/19/23 14:07:10.599
  STEP: changing the label value of the configmap back @ 04/19/23 14:07:20.599
  STEP: modifying the configmap a third time @ 04/19/23 14:07:20.608
  STEP: deleting the configmap @ 04/19/23 14:07:20.621
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 04/19/23 14:07:20.627
  Apr 19 14:07:20.627: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3042  1be73493-e4f6-43ec-935c-4e0e3f44e9e8 204332 0 2023-04-19 14:07:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-19 14:07:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 14:07:20.627: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3042  1be73493-e4f6-43ec-935c-4e0e3f44e9e8 204333 0 2023-04-19 14:07:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-19 14:07:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 14:07:20.627: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-3042  1be73493-e4f6-43ec-935c-4e0e3f44e9e8 204334 0 2023-04-19 14:07:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-19 14:07:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 14:07:20.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3042" for this suite. @ 04/19/23 14:07:20.633
• [10.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:164
  STEP: Creating a kubernetes client @ 04/19/23 14:07:20.645
  Apr 19 14:07:20.645: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename security-context @ 04/19/23 14:07:20.648
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:07:20.664
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:07:20.667
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 04/19/23 14:07:20.671
  W0419 14:07:20.680441      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Saw pod success @ 04/19/23 14:07:24.694
  Apr 19 14:07:24.697: INFO: Trying to get logs from node talos-default-worker-1 pod security-context-7e66fee0-4385-4b39-b313-ffede721200d container test-container: <nil>
  STEP: delete the pod @ 04/19/23 14:07:24.705
  Apr 19 14:07:24.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-9952" for this suite. @ 04/19/23 14:07:24.731
• [4.093 seconds]
------------------------------
SSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance]
test/e2e/common/node/podtemplates.go:122
  STEP: Creating a kubernetes client @ 04/19/23 14:07:24.739
  Apr 19 14:07:24.739: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename podtemplate @ 04/19/23 14:07:24.74
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:07:24.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:07:24.759
  STEP: Create set of pod templates @ 04/19/23 14:07:24.762
  W0419 14:07:24.767683      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:07:24.767: INFO: created test-podtemplate-1
  W0419 14:07:24.773658      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:07:24.774: INFO: created test-podtemplate-2
  W0419 14:07:24.779392      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "token-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "token-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "token-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "token-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:07:24.779: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 04/19/23 14:07:24.78
  STEP: delete collection of pod templates @ 04/19/23 14:07:24.783
  Apr 19 14:07:24.784: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 04/19/23 14:07:24.795
  Apr 19 14:07:24.795: INFO: requesting list of pod templates to confirm quantity
  Apr 19 14:07:24.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-5479" for this suite. @ 04/19/23 14:07:24.806
• [0.072 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]
test/e2e/apps/rc.go:112
  STEP: Creating a kubernetes client @ 04/19/23 14:07:24.813
  Apr 19 14:07:24.813: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename replication-controller @ 04/19/23 14:07:24.814
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:07:24.824
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:07:24.827
  STEP: creating a ReplicationController @ 04/19/23 14:07:24.831
  W0419 14:07:24.835484      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "rc-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "rc-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "rc-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "rc-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: waiting for RC to be added @ 04/19/23 14:07:24.835
  STEP: waiting for available Replicas @ 04/19/23 14:07:24.835
  STEP: patching ReplicationController @ 04/19/23 14:07:26.076
  W0419 14:07:26.085942      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "rc-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "rc-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "rc-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "rc-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: waiting for RC to be modified @ 04/19/23 14:07:26.086
  STEP: patching ReplicationController status @ 04/19/23 14:07:26.086
  STEP: waiting for RC to be modified @ 04/19/23 14:07:26.093
  STEP: waiting for available Replicas @ 04/19/23 14:07:26.093
  STEP: fetching ReplicationController status @ 04/19/23 14:07:26.097
  STEP: patching ReplicationController scale @ 04/19/23 14:07:26.102
  STEP: waiting for RC to be modified @ 04/19/23 14:07:26.108
  STEP: waiting for ReplicationController's scale to be the max amount @ 04/19/23 14:07:26.11
  STEP: fetching ReplicationController; ensuring that it's patched @ 04/19/23 14:07:26.869
  STEP: updating ReplicationController status @ 04/19/23 14:07:26.872
  STEP: waiting for RC to be modified @ 04/19/23 14:07:26.878
  STEP: listing all ReplicationControllers @ 04/19/23 14:07:26.878
  STEP: checking that ReplicationController has expected values @ 04/19/23 14:07:26.882
  STEP: deleting ReplicationControllers by collection @ 04/19/23 14:07:26.882
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 04/19/23 14:07:26.888
  Apr 19 14:07:26.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  E0419 14:07:26.926813      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-9702" for this suite. @ 04/19/23 14:07:26.929
• [2.121 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]
test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 04/19/23 14:07:26.935
  Apr 19 14:07:26.935: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename watch @ 04/19/23 14:07:26.936
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:07:26.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:07:26.949
  STEP: creating a new configmap @ 04/19/23 14:07:26.951
  STEP: modifying the configmap once @ 04/19/23 14:07:26.955
  STEP: modifying the configmap a second time @ 04/19/23 14:07:26.961
  STEP: deleting the configmap @ 04/19/23 14:07:26.966
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 04/19/23 14:07:26.97
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 04/19/23 14:07:26.971
  Apr 19 14:07:26.972: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6665  b00315c7-8fac-42dd-92bd-ff06a7eea071 204424 0 2023-04-19 14:07:26 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-19 14:07:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 14:07:26.972: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6665  b00315c7-8fac-42dd-92bd-ff06a7eea071 204425 0 2023-04-19 14:07:26 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-19 14:07:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 14:07:26.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6665" for this suite. @ 04/19/23 14:07:26.978
• [0.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 04/19/23 14:07:26.988
  Apr 19 14:07:26.988: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename hostport @ 04/19/23 14:07:26.989
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:07:27.001
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:07:27.003
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 04/19/23 14:07:27.008
  W0419 14:07:27.013885      20 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54323), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:07:27.927279      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:28.927423      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.20.0.5 on the node which pod1 resides and expect scheduled @ 04/19/23 14:07:29.022
  W0419 14:07:29.033670      20 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54323), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:07:29.928382      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:30.929410      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:31.929633      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:32.930228      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:33.930678      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:34.930796      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:35.931534      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:36.931868      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:37.932806      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:38.932856      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:39.933005      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:40.933100      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:41.933224      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:42.934230      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:43.935300      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:44.935476      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:45.935854      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:46.935845      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:47.935796      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:48.935925      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:49.936049      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:50.936165      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.20.0.5 but use UDP protocol on the node which pod2 resides @ 04/19/23 14:07:51.091
  W0419 14:07:51.097448      20 warnings.go:70] would violate PodSecurity "restricted:latest": hostPort (container "agnhost" uses hostPort 54323), allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:07:51.936324      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:52.937204      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  W0419 14:07:53.115482      20 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (container "e2e-host-exec" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "e2e-host-exec" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "e2e-host-exec" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "e2e-host-exec" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:07:53.938158      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:54.938226      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 04/19/23 14:07:55.128
  Apr 19 14:07:55.128: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.20.0.5 http://127.0.0.1:54323/hostname] Namespace:hostport-7701 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 14:07:55.128: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 14:07:55.131: INFO: ExecWithOptions: Clientset creation
  Apr 19 14:07:55.131: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-7701/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.20.0.5+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.20.0.5, port: 54323 @ 04/19/23 14:07:55.26
  Apr 19 14:07:55.260: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.20.0.5:54323/hostname] Namespace:hostport-7701 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 14:07:55.262: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 14:07:55.265: INFO: ExecWithOptions: Clientset creation
  Apr 19 14:07:55.265: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-7701/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.20.0.5%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.20.0.5, port: 54323 UDP @ 04/19/23 14:07:55.395
  Apr 19 14:07:55.395: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.20.0.5 54323] Namespace:hostport-7701 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 14:07:55.396: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 14:07:55.397: INFO: ExecWithOptions: Clientset creation
  Apr 19 14:07:55.397: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-7701/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.20.0.5+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E0419 14:07:55.938884      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:56.938917      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:57.940071      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:58.940377      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:07:59.940407      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:08:00.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-7701" for this suite. @ 04/19/23 14:08:00.514
• [33.533 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]
test/e2e/apimachinery/webhook.go:220
  STEP: Creating a kubernetes client @ 04/19/23 14:08:00.532
  Apr 19 14:08:00.532: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 14:08:00.534
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:08:00.554
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:08:00.558
  STEP: Setting up server cert @ 04/19/23 14:08:00.581
  E0419 14:08:00.940732      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 14:08:00.956
  STEP: Deploying the webhook pod @ 04/19/23 14:08:00.964
  W0419 14:08:00.979337      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 14:08:00.979
  Apr 19 14:08:00.987: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 14:08:01.941029      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:02.941094      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/23 14:08:02.998
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 14:08:03.015
  E0419 14:08:03.941616      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:08:04.016: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Apr 19 14:08:04.021: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 04/19/23 14:08:04.537
  STEP: Creating a custom resource that should be denied by the webhook @ 04/19/23 14:08:04.557
  E0419 14:08:04.942331      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:05.942614      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 04/19/23 14:08:06.575
  STEP: Updating the custom resource with disallowed data should be denied @ 04/19/23 14:08:06.582
  STEP: Deleting the custom resource should be denied @ 04/19/23 14:08:06.593
  STEP: Remove the offending key and value from the custom resource data @ 04/19/23 14:08:06.601
  STEP: Deleting the updated custom resource should be successful @ 04/19/23 14:08:06.611
  Apr 19 14:08:06.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  E0419 14:08:06.942937      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-6278" for this suite. @ 04/19/23 14:08:07.179
  STEP: Destroying namespace "webhook-markers-9605" for this suite. @ 04/19/23 14:08:07.19
• [6.665 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:69
  STEP: Creating a kubernetes client @ 04/19/23 14:08:07.202
  Apr 19 14:08:07.202: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 14:08:07.204
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:08:07.22
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:08:07.224
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 14:08:07.233
  W0419 14:08:07.241106      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:08:07.943788      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:08.943938      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:09.944846      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:10.944956      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:08:11.254
  Apr 19 14:08:11.257: INFO: Trying to get logs from node talos-default-worker-1 pod downwardapi-volume-0e12cc17-3adf-426a-a841-8f7c5d4187a5 container client-container: <nil>
  STEP: delete the pod @ 04/19/23 14:08:11.264
  Apr 19 14:08:11.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4771" for this suite. @ 04/19/23 14:08:11.283
• [4.088 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:124
  STEP: Creating a kubernetes client @ 04/19/23 14:08:11.292
  Apr 19 14:08:11.292: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pod-network-test @ 04/19/23 14:08:11.294
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:08:11.309
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:08:11.312
  STEP: Performing setup for networking test in namespace pod-network-test-7383 @ 04/19/23 14:08:11.315
  STEP: creating a selector @ 04/19/23 14:08:11.315
  STEP: Creating the service pods in kubernetes @ 04/19/23 14:08:11.315
  Apr 19 14:08:11.315: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  W0419 14:08:11.328110      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  W0419 14:08:11.334549      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:08:11.945995      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:12.947053      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:13.947127      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:14.947226      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:15.948317      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:16.948375      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:17.949349      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:18.949522      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:19.949639      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:20.949792      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:21.949939      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:22.950518      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:23.950649      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:24.950763      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:25.950883      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:26.951050      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:27.951593      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:28.951850      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:29.951983      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:30.952073      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:31.952211      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:32.952642      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:33.952765      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:34.953308      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:35.953516      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:36.953842      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/19/23 14:08:37.408
  W0419 14:08:37.414839      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  W0419 14:08:37.424922      20 warnings.go:70] would violate PodSecurity "restricted:latest": host namespaces (hostNetwork=true), allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:08:37.954810      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:38.954917      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:08:39.444: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Apr 19 14:08:39.444: INFO: Going to poll 10.244.3.30 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  Apr 19 14:08:39.448: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.3.30 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7383 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 14:08:39.448: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 14:08:39.448: INFO: ExecWithOptions: Clientset creation
  Apr 19 14:08:39.449: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-7383/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.3.30+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0419 14:08:39.956029      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:08:40.581: INFO: Found all 1 expected endpoints: [netserver-0]
  Apr 19 14:08:40.582: INFO: Going to poll 10.244.1.180 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  Apr 19 14:08:40.586: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.180 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7383 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 14:08:40.586: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 14:08:40.587: INFO: ExecWithOptions: Clientset creation
  Apr 19 14:08:40.587: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-7383/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.1.180+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E0419 14:08:40.956991      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:08:41.705: INFO: Found all 1 expected endpoints: [netserver-1]
  Apr 19 14:08:41.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-7383" for this suite. @ 04/19/23 14:08:41.712
• [30.427 seconds]
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]
test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 04/19/23 14:08:41.721
  Apr 19 14:08:41.721: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename sched-preemption @ 04/19/23 14:08:41.723
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:08:41.739
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:08:41.742
  Apr 19 14:08:41.763: INFO: Waiting up to 1m0s for all nodes to be ready
  E0419 14:08:41.957085      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:42.958021      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:43.958146      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:44.958523      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:45.959385      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:46.959465      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:47.960562      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:48.960699      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:49.961395      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:50.961556      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:51.962324      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:52.963013      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:53.963575      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:54.963699      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:55.963846      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:56.964506      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:57.965457      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:58.965612      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:08:59.966264      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:00.966376      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:01.967213      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:02.968110      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:03.968639      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:04.968716      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:05.969809      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:06.969914      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:07.970284      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:08.970394      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:09.971087      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:10.971801      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:11.972808      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:12.973463      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:13.974120      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:14.974180      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:15.974374      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:16.975271      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:17.976125      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:18.976440      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:19.976515      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:20.976651      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:21.977371      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:22.978118      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:23.978234      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:24.978342      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:25.978991      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:26.979471      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:27.980490      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:28.980914      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:29.981820      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:30.981953      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:31.982778      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:32.983821      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:33.984868      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:34.985402      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:35.986216      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:36.986358      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:37.986429      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:38.986550      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:39.986921      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:40.987285      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:09:41.786: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 04/19/23 14:09:41.791
  Apr 19 14:09:41.791: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename sched-preemption-path @ 04/19/23 14:09:41.793
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:09:41.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:09:41.815
  STEP: Finding an available node @ 04/19/23 14:09:41.818
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 04/19/23 14:09:41.818
  E0419 14:09:41.987944      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:42.988463      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 04/19/23 14:09:43.84
  Apr 19 14:09:43.849: INFO: found a healthy node: talos-default-worker-1
  E0419 14:09:43.988543      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:44.988664      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:45.988943      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:46.989199      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:47.989401      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:48.989638      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:09:49.923: INFO: pods created so far: [1 1 1]
  Apr 19 14:09:49.923: INFO: length of pods created so far: 3
  E0419 14:09:49.989786      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:50.989920      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:09:51.933: INFO: pods created so far: [2 2 1]
  E0419 14:09:51.990475      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:52.990851      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:53.991344      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:54.991624      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:55.991907      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:56.992064      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:09:57.992938      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:09:58.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 19 14:09:58.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  E0419 14:09:58.993707      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "sched-preemption-path-9717" for this suite. @ 04/19/23 14:09:59.001
  STEP: Destroying namespace "sched-preemption-6332" for this suite. @ 04/19/23 14:09:59.006
• [77.297 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:47
  STEP: Creating a kubernetes client @ 04/19/23 14:09:59.031
  Apr 19 14:09:59.031: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 14:09:59.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:09:59.047
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:09:59.05
  STEP: Creating configMap with name projected-configmap-test-volume-052acaa7-78ae-45f6-8c42-98aaec507754 @ 04/19/23 14:09:59.053
  STEP: Creating a pod to test consume configMaps @ 04/19/23 14:09:59.057
  W0419 14:09:59.063688      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:09:59.994395      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:00.994718      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:01.995420      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:02.995948      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:10:03.075
  Apr 19 14:10:03.080: INFO: Trying to get logs from node talos-default-worker-2 pod pod-projected-configmaps-94d0c42b-cd39-444c-872d-f1d8c0143ddf container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 14:10:03.09
  Apr 19 14:10:03.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4811" for this suite. @ 04/19/23 14:10:03.114
• [4.090 seconds]
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
test/e2e/apimachinery/garbage_collector.go:538
  STEP: Creating a kubernetes client @ 04/19/23 14:10:03.121
  Apr 19 14:10:03.121: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename gc @ 04/19/23 14:10:03.123
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:10:03.137
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:10:03.141
  STEP: create the deployment @ 04/19/23 14:10:03.144
  W0419 14:10:03.149485      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  W0419 14:10:03.149530      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the Deployment to create new ReplicaSet @ 04/19/23 14:10:03.149
  STEP: delete the deployment @ 04/19/23 14:10:03.261
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 04/19/23 14:10:03.266
  STEP: Gathering metrics @ 04/19/23 14:10:03.789
  Apr 19 14:10:03.834: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 19 14:10:03.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8311" for this suite. @ 04/19/23 14:10:03.845
• [0.729 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:45
  STEP: Creating a kubernetes client @ 04/19/23 14:10:03.851
  Apr 19 14:10:03.851: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 14:10:03.852
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:10:03.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:10:03.865
  STEP: Creating a pod to test downward api env vars @ 04/19/23 14:10:03.868
  W0419 14:10:03.874162      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:10:03.996063      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:04.996517      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:05.997025      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:06.997249      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:10:07.887
  Apr 19 14:10:07.891: INFO: Trying to get logs from node talos-default-worker-2 pod downward-api-93e42af8-735c-4976-8e52-00b8dbe6da9f container dapi-container: <nil>
  STEP: delete the pod @ 04/19/23 14:10:07.9
  Apr 19 14:10:07.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7337" for this suite. @ 04/19/23 14:10:07.923
• [4.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 04/19/23 14:10:07.935
  Apr 19 14:10:07.936: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/23 14:10:07.939
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:10:07.952
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:10:07.955
  Apr 19 14:10:07.959: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  E0419 14:10:07.998047      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:08.998329      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 04/19/23 14:10:09.359
  Apr 19 14:10:09.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-944 --namespace=crd-publish-openapi-944 create -f -'
  Apr 19 14:10:09.933: INFO: stderr: ""
  Apr 19 14:10:09.933: INFO: stdout: "e2e-test-crd-publish-openapi-3986-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Apr 19 14:10:09.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-944 --namespace=crd-publish-openapi-944 delete e2e-test-crd-publish-openapi-3986-crds test-cr'
  E0419 14:10:09.999099      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:10:10.002: INFO: stderr: ""
  Apr 19 14:10:10.002: INFO: stdout: "e2e-test-crd-publish-openapi-3986-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Apr 19 14:10:10.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-944 --namespace=crd-publish-openapi-944 apply -f -'
  Apr 19 14:10:10.192: INFO: stderr: ""
  Apr 19 14:10:10.192: INFO: stdout: "e2e-test-crd-publish-openapi-3986-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Apr 19 14:10:10.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-944 --namespace=crd-publish-openapi-944 delete e2e-test-crd-publish-openapi-3986-crds test-cr'
  Apr 19 14:10:10.259: INFO: stderr: ""
  Apr 19 14:10:10.259: INFO: stdout: "e2e-test-crd-publish-openapi-3986-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 04/19/23 14:10:10.26
  Apr 19 14:10:10.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=crd-publish-openapi-944 explain e2e-test-crd-publish-openapi-3986-crds'
  Apr 19 14:10:10.743: INFO: stderr: ""
  Apr 19 14:10:10.743: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-3986-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0419 14:10:10.999887      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:11.999977      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:10:12.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-944" for this suite. @ 04/19/23 14:10:12.194
• [4.266 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 04/19/23 14:10:12.201
  Apr 19 14:10:12.201: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-runtime @ 04/19/23 14:10:12.204
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:10:12.218
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:10:12.221
  STEP: create the container @ 04/19/23 14:10:12.224
  W0419 14:10:12.232750      20 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  W0419 14:10:12.232790      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "termination-message-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "termination-message-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "termination-message-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "termination-message-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: wait for the container to reach Succeeded @ 04/19/23 14:10:12.233
  E0419 14:10:13.000963      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:14.001635      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:15.002694      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: get the container status @ 04/19/23 14:10:15.252
  STEP: the container should be terminated @ 04/19/23 14:10:15.255
  STEP: the termination message should be set @ 04/19/23 14:10:15.255
  Apr 19 14:10:15.255: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 04/19/23 14:10:15.255
  Apr 19 14:10:15.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-4739" for this suite. @ 04/19/23 14:10:15.279
• [3.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:222
  STEP: Creating a kubernetes client @ 04/19/23 14:10:15.29
  Apr 19 14:10:15.291: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 14:10:15.293
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:10:15.308
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:10:15.312
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 14:10:15.316
  W0419 14:10:15.326511      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:10:16.003498      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:17.004427      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:18.004592      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:19.004768      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:10:19.34
  Apr 19 14:10:19.344: INFO: Trying to get logs from node talos-default-worker-1 pod downwardapi-volume-72416b5f-c84e-42f1-9a1d-1e7f0e78a84b container client-container: <nil>
  STEP: delete the pod @ 04/19/23 14:10:19.36
  Apr 19 14:10:19.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5322" for this suite. @ 04/19/23 14:10:19.384
• [4.105 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]
test/e2e/apimachinery/resource_quota.go:946
  STEP: Creating a kubernetes client @ 04/19/23 14:10:19.405
  Apr 19 14:10:19.406: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename resourcequota @ 04/19/23 14:10:19.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:10:19.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:10:19.431
  STEP: Creating a ResourceQuota @ 04/19/23 14:10:19.434
  STEP: Getting a ResourceQuota @ 04/19/23 14:10:19.438
  STEP: Listing all ResourceQuotas with LabelSelector @ 04/19/23 14:10:19.441
  STEP: Patching the ResourceQuota @ 04/19/23 14:10:19.445
  STEP: Deleting a Collection of ResourceQuotas @ 04/19/23 14:10:19.45
  STEP: Verifying the deleted ResourceQuota @ 04/19/23 14:10:19.456
  Apr 19 14:10:19.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3755" for this suite. @ 04/19/23 14:10:19.462
• [0.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance]
test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 04/19/23 14:10:19.467
  Apr 19 14:10:19.468: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename deployment @ 04/19/23 14:10:19.469
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:10:19.48
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:10:19.482
  W0419 14:10:19.488404      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:10:19.491: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  E0419 14:10:20.005472      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:21.005898      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:22.006034      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:23.006129      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:24.006734      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:10:24.496: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/23 14:10:24.496
  Apr 19 14:10:24.496: INFO: Creating deployment test-cleanup-deployment
  W0419 14:10:24.506157      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 04/19/23 14:10:24.506
  E0419 14:10:25.007213      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:26.007328      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:10:26.528: INFO: Deployment "test-cleanup-deployment":
  &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-4302  fbcbdd54-7001-47c7-9191-de0edc6b8feb 205505 1 2023-04-19 14:10:24 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-19 14:10:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 14:10:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0042c7f78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-19 14:10:24 +0000 UTC,LastTransitionTime:2023-04-19 14:10:24 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-68b75d69f8" has successfully progressed.,LastUpdateTime:2023-04-19 14:10:25 +0000 UTC,LastTransitionTime:2023-04-19 14:10:24 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

  Apr 19 14:10:26.532: INFO: New ReplicaSet "test-cleanup-deployment-68b75d69f8" of Deployment "test-cleanup-deployment":
  &ReplicaSet{ObjectMeta:{test-cleanup-deployment-68b75d69f8  deployment-4302  c87d0acb-4625-4df5-8904-33b7afdc2e19 205495 1 2023-04-19 14:10:24 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:68b75d69f8] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment fbcbdd54-7001-47c7-9191-de0edc6b8feb 0xc003664ba7 0xc003664ba8}] [] [{kube-controller-manager Update apps/v1 2023-04-19 14:10:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fbcbdd54-7001-47c7-9191-de0edc6b8feb\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-19 14:10:25 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 68b75d69f8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:68b75d69f8] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.43 [] []  [] [] [] {map[] map[] []} [] [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003664c58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil> [] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
  Apr 19 14:10:26.537: INFO: Pod "test-cleanup-deployment-68b75d69f8-q2klz" is available:
  &Pod{ObjectMeta:{test-cleanup-deployment-68b75d69f8-q2klz test-cleanup-deployment-68b75d69f8- deployment-4302  0b4bfe9e-5f55-4864-82fb-175681c28d0a 205494 0 2023-04-19 14:10:24 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:68b75d69f8] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-68b75d69f8 c87d0acb-4625-4df5-8904-33b7afdc2e19 0xc003664ff7 0xc003664ff8}] [] [{kube-controller-manager Update v1 2023-04-19 14:10:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c87d0acb-4625-4df5-8904-33b7afdc2e19\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-19 14:10:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.3.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-42wjs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-42wjs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-default-worker-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 14:10:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 14:10:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 14:10:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-19 14:10:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.0.5,PodIP:10.244.3.41,StartTime:2023-04-19 14:10:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-19 14:10:25 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.43,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:16bbf38c463a4223d8cfe4da12bc61010b082a79b4bb003e2d3ba3ece5dd5f9e,ContainerID:containerd://1f721bf970c32457e32bb9e19b5dbec236be733c11c571ef1383a84000871a1c,Started:*true,AllocatedResources:ResourceList{},Resources:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.41,},},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,},}
  Apr 19 14:10:26.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4302" for this suite. @ 04/19/23 14:10:26.547
• [7.087 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]
test/e2e/apps/replica_set.go:143
  STEP: Creating a kubernetes client @ 04/19/23 14:10:26.559
  Apr 19 14:10:26.560: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename replicaset @ 04/19/23 14:10:26.562
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:10:26.576
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:10:26.578
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 04/19/23 14:10:26.581
  W0419 14:10:26.585938      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:10:26.589: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0419 14:10:27.007963      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:28.008548      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:29.009121      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:30.009234      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:31.009373      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:10:31.594: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/23 14:10:31.595
  STEP: getting scale subresource @ 04/19/23 14:10:31.595
  STEP: updating a scale subresource @ 04/19/23 14:10:31.599
  STEP: verifying the replicaset Spec.Replicas was modified @ 04/19/23 14:10:31.61
  STEP: Patch a scale subresource @ 04/19/23 14:10:31.615
  Apr 19 14:10:31.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-5636" for this suite. @ 04/19/23 14:10:31.637
• [5.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance]
test/e2e/network/service.go:3138
  STEP: Creating a kubernetes client @ 04/19/23 14:10:31.65
  Apr 19 14:10:31.650: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 14:10:31.651
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:10:31.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:10:31.665
  STEP: creating an Endpoint @ 04/19/23 14:10:31.67
  STEP: waiting for available Endpoint @ 04/19/23 14:10:31.674
  STEP: listing all Endpoints @ 04/19/23 14:10:31.676
  STEP: updating the Endpoint @ 04/19/23 14:10:31.678
  STEP: fetching the Endpoint @ 04/19/23 14:10:31.683
  STEP: patching the Endpoint @ 04/19/23 14:10:31.687
  STEP: fetching the Endpoint @ 04/19/23 14:10:31.694
  STEP: deleting the Endpoint by Collection @ 04/19/23 14:10:31.696
  STEP: waiting for Endpoint deletion @ 04/19/23 14:10:31.702
  STEP: fetching the Endpoint @ 04/19/23 14:10:31.704
  Apr 19 14:10:31.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-9244" for this suite. @ 04/19/23 14:10:31.711
• [0.066 seconds]
------------------------------
S
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance]
test/e2e/network/service.go:3322
  STEP: Creating a kubernetes client @ 04/19/23 14:10:31.718
  Apr 19 14:10:31.718: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 14:10:31.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:10:31.728
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:10:31.731
  STEP: creating a Service @ 04/19/23 14:10:31.735
  STEP: watching for the Service to be added @ 04/19/23 14:10:31.744
  Apr 19 14:10:31.746: INFO: Found Service test-service-qmmn5 in namespace services-6250 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
  Apr 19 14:10:31.746: INFO: Service test-service-qmmn5 created
  STEP: Getting /status @ 04/19/23 14:10:31.746
  Apr 19 14:10:31.751: INFO: Service test-service-qmmn5 has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 04/19/23 14:10:31.751
  STEP: watching for the Service to be patched @ 04/19/23 14:10:31.757
  Apr 19 14:10:31.760: INFO: observed Service test-service-qmmn5 in namespace services-6250 with annotations: map[] & LoadBalancer: {[]}
  Apr 19 14:10:31.762: INFO: Found Service test-service-qmmn5 in namespace services-6250 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
  Apr 19 14:10:31.763: INFO: Service test-service-qmmn5 has service status patched
  STEP: updating the ServiceStatus @ 04/19/23 14:10:31.763
  Apr 19 14:10:31.771: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 04/19/23 14:10:31.772
  Apr 19 14:10:31.774: INFO: Observed Service test-service-qmmn5 in namespace services-6250 with annotations: map[] & Conditions: {[]}
  Apr 19 14:10:31.774: INFO: Observed event: &Service{ObjectMeta:{test-service-qmmn5  services-6250  10ff3fe5-5bea-434a-babe-1adac207befb 205592 0 2023-04-19 14:10:31 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-04-19 14:10:31 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-04-19 14:10:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.103.146.47,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.103.146.47],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Apr 19 14:10:31.775: INFO: Found Service test-service-qmmn5 in namespace services-6250 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 19 14:10:31.775: INFO: Service test-service-qmmn5 has service status updated
  STEP: patching the service @ 04/19/23 14:10:31.775
  STEP: watching for the Service to be patched @ 04/19/23 14:10:31.786
  Apr 19 14:10:31.788: INFO: observed Service test-service-qmmn5 in namespace services-6250 with labels: map[test-service-static:true]
  Apr 19 14:10:31.788: INFO: observed Service test-service-qmmn5 in namespace services-6250 with labels: map[test-service-static:true]
  Apr 19 14:10:31.788: INFO: observed Service test-service-qmmn5 in namespace services-6250 with labels: map[test-service-static:true]
  Apr 19 14:10:31.788: INFO: Found Service test-service-qmmn5 in namespace services-6250 with labels: map[test-service:patched test-service-static:true]
  Apr 19 14:10:31.788: INFO: Service test-service-qmmn5 patched
  STEP: deleting the service @ 04/19/23 14:10:31.788
  STEP: watching for the Service to be deleted @ 04/19/23 14:10:31.799
  Apr 19 14:10:31.805: INFO: Observed event: ADDED
  Apr 19 14:10:31.805: INFO: Observed event: MODIFIED
  Apr 19 14:10:31.805: INFO: Observed event: MODIFIED
  Apr 19 14:10:31.805: INFO: Observed event: MODIFIED
  Apr 19 14:10:31.805: INFO: Found Service test-service-qmmn5 in namespace services-6250 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Apr 19 14:10:31.805: INFO: Service test-service-qmmn5 deleted
  Apr 19 14:10:31.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6250" for this suite. @ 04/19/23 14:10:31.808
• [0.096 seconds]
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]
test/e2e/common/node/configmap.go:169
  STEP: Creating a kubernetes client @ 04/19/23 14:10:31.813
  Apr 19 14:10:31.813: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 14:10:31.813
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:10:31.823
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:10:31.826
  STEP: creating a ConfigMap @ 04/19/23 14:10:31.829
  STEP: fetching the ConfigMap @ 04/19/23 14:10:31.832
  STEP: patching the ConfigMap @ 04/19/23 14:10:31.834
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 04/19/23 14:10:31.838
  STEP: deleting the ConfigMap by collection with a label selector @ 04/19/23 14:10:31.841
  STEP: listing all ConfigMaps in test namespace @ 04/19/23 14:10:31.847
  Apr 19 14:10:31.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4324" for this suite. @ 04/19/23 14:10:31.853
• [0.044 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 04/19/23 14:10:31.857
  Apr 19 14:10:31.857: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pods @ 04/19/23 14:10:31.858
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:10:31.867
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:10:31.87
  STEP: creating pod @ 04/19/23 14:10:31.872
  E0419 14:10:32.010203      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:33.010324      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:10:33.891: INFO: Pod pod-hostip-45ca1eb3-1e57-430f-b2b0-80f6801a9487 has hostIP: 172.20.0.5
  Apr 19 14:10:33.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7118" for this suite. @ 04/19/23 14:10:33.896
• [2.046 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:141
  STEP: Creating a kubernetes client @ 04/19/23 14:10:33.907
  Apr 19 14:10:33.907: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename crd-webhook @ 04/19/23 14:10:33.91
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:10:33.93
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:10:33.934
  STEP: Setting up server cert @ 04/19/23 14:10:33.938
  E0419 14:10:34.011329      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 04/19/23 14:10:34.123
  STEP: Deploying the custom resource conversion webhook pod @ 04/19/23 14:10:34.131
  W0419 14:10:34.147713      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-crd-conversion-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-crd-conversion-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-crd-conversion-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-crd-conversion-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 14:10:34.148
  Apr 19 14:10:34.158: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0419 14:10:35.011459      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:36.011625      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/23 14:10:36.169
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 14:10:36.185
  E0419 14:10:37.011784      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:10:37.186: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Apr 19 14:10:37.189: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  E0419 14:10:38.012357      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:39.012472      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 04/19/23 14:10:39.759
  STEP: v2 custom resource should be converted @ 04/19/23 14:10:39.769
  Apr 19 14:10:39.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  E0419 14:10:40.013358      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "crd-webhook-2308" for this suite. @ 04/19/23 14:10:40.336
• [6.435 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:84
  STEP: Creating a kubernetes client @ 04/19/23 14:10:40.346
  Apr 19 14:10:40.346: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pod-network-test @ 04/19/23 14:10:40.347
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:10:40.358
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:10:40.36
  STEP: Performing setup for networking test in namespace pod-network-test-4468 @ 04/19/23 14:10:40.362
  STEP: creating a selector @ 04/19/23 14:10:40.362
  STEP: Creating the service pods in kubernetes @ 04/19/23 14:10:40.362
  Apr 19 14:10:40.362: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  W0419 14:10:40.374427      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  W0419 14:10:40.378865      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:10:41.013912      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:42.014050      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:43.014099      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:44.014490      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:45.014622      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:46.014734      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:47.014877      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:48.015890      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:49.016559      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:50.016952      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:51.017070      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:52.017208      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:53.017814      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:54.018551      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:55.020351      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:56.019673      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:57.020041      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:58.020570      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:10:59.020741      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:00.020831      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:01.021720      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:02.021855      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 04/19/23 14:11:02.442
  W0419 14:11:02.453040      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:11:03.022925      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:04.023239      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:11:04.465: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  Apr 19 14:11:04.465: INFO: Breadth first check of 10.244.3.45 on host 172.20.0.5...
  Apr 19 14:11:04.468: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.46:9080/dial?request=hostname&protocol=http&host=10.244.3.45&port=8083&tries=1'] Namespace:pod-network-test-4468 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 14:11:04.468: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 14:11:04.469: INFO: ExecWithOptions: Clientset creation
  Apr 19 14:11:04.469: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-4468/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.3.46%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.3.45%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 19 14:11:04.588: INFO: Waiting for responses: map[]
  Apr 19 14:11:04.589: INFO: reached 10.244.3.45 after 0/1 tries
  Apr 19 14:11:04.589: INFO: Breadth first check of 10.244.1.184 on host 172.20.0.6...
  Apr 19 14:11:04.593: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.46:9080/dial?request=hostname&protocol=http&host=10.244.1.184&port=8083&tries=1'] Namespace:pod-network-test-4468 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 14:11:04.593: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 14:11:04.595: INFO: ExecWithOptions: Clientset creation
  Apr 19 14:11:04.595: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-4468/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.3.46%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.1.184%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Apr 19 14:11:04.721: INFO: Waiting for responses: map[]
  Apr 19 14:11:04.722: INFO: reached 10.244.1.184 after 0/1 tries
  Apr 19 14:11:04.722: INFO: Going to retry 0 out of 2 pods....
  Apr 19 14:11:04.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4468" for this suite. @ 04/19/23 14:11:04.727
• [24.389 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 04/19/23 14:11:04.736
  Apr 19 14:11:04.736: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename containers @ 04/19/23 14:11:04.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:11:04.757
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:11:04.76
  STEP: Creating a pod to test override all @ 04/19/23 14:11:04.763
  W0419 14:11:04.772135      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:11:05.023460      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:06.024229      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:11:06.781
  Apr 19 14:11:06.785: INFO: Trying to get logs from node talos-default-worker-1 pod client-containers-4cdc82e7-5f71-41a1-a858-89224a59af12 container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 14:11:06.792
  Apr 19 14:11:06.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-6721" for this suite. @ 04/19/23 14:11:06.809
• [2.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 04/19/23 14:11:06.82
  Apr 19 14:11:06.820: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-probe @ 04/19/23 14:11:06.822
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:11:06.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:11:06.836
  W0419 14:11:06.843792      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:11:07.025009      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:08.026133      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:09.026711      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:10.027388      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:11.027878      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:12.028171      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:13.028313      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:14.028939      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:15.029882      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:16.029998      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:17.030295      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:18.030766      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:19.031832      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:20.032707      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:21.033825      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:22.033867      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:23.034015      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:24.034242      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:25.034728      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:26.035014      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:27.035939      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:28.036167      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:29.037110      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:30.037365      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:31.037620      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:32.038725      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:33.038998      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:34.039827      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:35.040707      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:36.040786      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:37.041113      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:38.042122      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:39.042990      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:40.043218      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:41.044177      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:42.044817      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:43.045090      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:44.046140      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:45.046489      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:46.047040      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:47.047665      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:48.047872      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:49.048266      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:50.049127      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:51.050069      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:52.050187      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:53.050622      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:54.051010      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:55.051307      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:56.051377      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:57.051534      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:58.052367      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:11:59.052482      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:00.052606      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:01.052921      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:02.053107      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:03.053623      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:04.053762      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:05.053916      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:06.054054      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:12:06.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-2410" for this suite. @ 04/19/23 14:12:06.853
• [60.040 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 04/19/23 14:12:06.863
  Apr 19 14:12:06.863: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pods @ 04/19/23 14:12:06.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:12:06.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:12:06.886
  Apr 19 14:12:06.889: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: creating the pod @ 04/19/23 14:12:06.891
  STEP: submitting the pod to kubernetes @ 04/19/23 14:12:06.892
  E0419 14:12:07.054538      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:08.055241      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:12:09.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1608" for this suite. @ 04/19/23 14:12:09.017
• [2.160 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]
test/e2e/apps/replica_set.go:176
  STEP: Creating a kubernetes client @ 04/19/23 14:12:09.027
  Apr 19 14:12:09.027: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename replicaset @ 04/19/23 14:12:09.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:12:09.04
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:12:09.043
  STEP: Create a Replicaset @ 04/19/23 14:12:09.051
  E0419 14:12:09.055273      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  W0419 14:12:09.056499      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Verify that the required pods have come up. @ 04/19/23 14:12:09.056
  Apr 19 14:12:09.060: INFO: Pod name sample-pod: Found 0 pods out of 1
  E0419 14:12:10.055504      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:11.055591      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:12.055864      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:13.056636      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:14.056701      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:12:14.065: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 04/19/23 14:12:14.065
  STEP: Getting /status @ 04/19/23 14:12:14.066
  Apr 19 14:12:14.071: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 04/19/23 14:12:14.071
  Apr 19 14:12:14.082: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 04/19/23 14:12:14.082
  Apr 19 14:12:14.085: INFO: Observed &ReplicaSet event: ADDED
  Apr 19 14:12:14.086: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 19 14:12:14.087: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 19 14:12:14.088: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 19 14:12:14.089: INFO: Found replicaset test-rs in namespace replicaset-9378 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Apr 19 14:12:14.091: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 04/19/23 14:12:14.091
  Apr 19 14:12:14.092: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Apr 19 14:12:14.098: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 04/19/23 14:12:14.098
  Apr 19 14:12:14.099: INFO: Observed &ReplicaSet event: ADDED
  Apr 19 14:12:14.100: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 19 14:12:14.100: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 19 14:12:14.100: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 19 14:12:14.101: INFO: Observed replicaset test-rs in namespace replicaset-9378 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Apr 19 14:12:14.101: INFO: Observed &ReplicaSet event: MODIFIED
  Apr 19 14:12:14.101: INFO: Found replicaset test-rs in namespace replicaset-9378 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Apr 19 14:12:14.101: INFO: Replicaset test-rs has a patched status
  Apr 19 14:12:14.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9378" for this suite. @ 04/19/23 14:12:14.105
• [5.084 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance]
test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 04/19/23 14:12:14.113
  Apr 19 14:12:14.113: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pods @ 04/19/23 14:12:14.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:12:14.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:12:14.135
  STEP: Create set of pods @ 04/19/23 14:12:14.138
  Apr 19 14:12:14.144: INFO: created test-pod-1
  Apr 19 14:12:14.150: INFO: created test-pod-2
  Apr 19 14:12:14.156: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 04/19/23 14:12:14.156
  E0419 14:12:15.056885      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:16.056956      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 04/19/23 14:12:16.2
  Apr 19 14:12:16.206: INFO: Pod quantity 3 is different from expected quantity 0
  E0419 14:12:17.057116      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:12:17.210: INFO: Pod quantity 3 is different from expected quantity 0
  E0419 14:12:18.057252      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:12:18.211: INFO: Pod quantity 2 is different from expected quantity 0
  E0419 14:12:19.058264      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:12:19.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4874" for this suite. @ 04/19/23 14:12:19.213
• [5.106 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]
test/e2e/common/node/podtemplates.go:53
  STEP: Creating a kubernetes client @ 04/19/23 14:12:19.219
  Apr 19 14:12:19.219: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename podtemplate @ 04/19/23 14:12:19.22
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:12:19.231
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:12:19.236
  W0419 14:12:19.247758      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  W0419 14:12:19.254939      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:12:19.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-8218" for this suite. @ 04/19/23 14:12:19.268
• [0.054 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]
test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 04/19/23 14:12:19.275
  Apr 19 14:12:19.275: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename endpointslicemirroring @ 04/19/23 14:12:19.276
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:12:19.288
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:12:19.29
  STEP: mirroring a new custom Endpoint @ 04/19/23 14:12:19.301
  Apr 19 14:12:19.312: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E0419 14:12:20.058748      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:21.058856      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 04/19/23 14:12:21.316
  Apr 19 14:12:21.326: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E0419 14:12:22.058933      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:23.059555      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 04/19/23 14:12:23.331
  Apr 19 14:12:23.342: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E0419 14:12:24.059676      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:25.060174      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:12:25.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-9137" for this suite. @ 04/19/23 14:12:25.353
• [6.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]
test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 04/19/23 14:12:25.364
  Apr 19 14:12:25.364: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename disruption @ 04/19/23 14:12:25.367
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:12:25.384
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:12:25.388
  STEP: Creating a pdb that targets all three pods in a test replica set @ 04/19/23 14:12:25.392
  STEP: Waiting for the pdb to be processed @ 04/19/23 14:12:25.403
  W0419 14:12:25.413415      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "donothing" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "donothing" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "donothing" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "donothing" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: First trying to evict a pod which shouldn't be evictable @ 04/19/23 14:12:25.413
  STEP: Waiting for all pods to be running @ 04/19/23 14:12:25.413
  Apr 19 14:12:25.417: INFO: pods: 0 < 3
  E0419 14:12:26.061204      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:27.061448      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 04/19/23 14:12:27.422
  STEP: Updating the pdb to allow a pod to be evicted @ 04/19/23 14:12:27.435
  STEP: Waiting for the pdb to be processed @ 04/19/23 14:12:27.444
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/19/23 14:12:27.449
  STEP: Waiting for all pods to be running @ 04/19/23 14:12:27.449
  STEP: Waiting for the pdb to observed all healthy pods @ 04/19/23 14:12:27.453
  STEP: Patching the pdb to disallow a pod to be evicted @ 04/19/23 14:12:27.481
  STEP: Waiting for the pdb to be processed @ 04/19/23 14:12:27.5
  STEP: Waiting for all pods to be running @ 04/19/23 14:12:27.503
  Apr 19 14:12:27.507: INFO: running pods: 2 < 3
  E0419 14:12:28.065568      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:29.066129      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 04/19/23 14:12:29.513
  STEP: Deleting the pdb to allow a pod to be evicted @ 04/19/23 14:12:29.522
  STEP: Waiting for the pdb to be deleted @ 04/19/23 14:12:29.528
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 04/19/23 14:12:29.532
  STEP: Waiting for all pods to be running @ 04/19/23 14:12:29.532
  Apr 19 14:12:29.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-4910" for this suite. @ 04/19/23 14:12:29.563
• [4.210 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 04/19/23 14:12:29.574
  Apr 19 14:12:29.574: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename secrets @ 04/19/23 14:12:29.575
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:12:29.587
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:12:29.589
  STEP: Creating secret with name secret-test-bcc989f1-364d-463a-80eb-1ddab17e7524 @ 04/19/23 14:12:29.591
  STEP: Creating a pod to test consume secrets @ 04/19/23 14:12:29.594
  W0419 14:12:29.600073      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:12:30.066680      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:31.067162      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:32.067804      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:33.068872      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:12:33.611
  Apr 19 14:12:33.614: INFO: Trying to get logs from node talos-default-worker-1 pod pod-secrets-ac4af6ed-0c2c-4800-9c47-c4629b901f1d container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 14:12:33.621
  Apr 19 14:12:33.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7908" for this suite. @ 04/19/23 14:12:33.639
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 04/19/23 14:12:33.651
  Apr 19 14:12:33.652: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-probe @ 04/19/23 14:12:33.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:12:33.669
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:12:33.672
  STEP: Creating pod liveness-8d4e739a-5d4f-44b6-b57b-a864050c132a in namespace container-probe-1223 @ 04/19/23 14:12:33.676
  W0419 14:12:33.684393      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:12:34.069676      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:35.069898      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:12:35.698: INFO: Started pod liveness-8d4e739a-5d4f-44b6-b57b-a864050c132a in namespace container-probe-1223
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/23 14:12:35.698
  Apr 19 14:12:35.702: INFO: Initial restart count of pod liveness-8d4e739a-5d4f-44b6-b57b-a864050c132a is 0
  E0419 14:12:36.069926      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:37.070991      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:38.072027      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:39.072111      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:40.072723      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:41.072838      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:42.072944      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:43.073585      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:44.074389      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:45.074979      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:46.075140      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:47.075295      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:48.076357      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:49.076476      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:50.077031      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:51.077414      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:52.077539      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:53.078261      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:54.078488      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:55.078664      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:56.079378      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:57.079548      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:58.079676      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:12:59.079831      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:00.080499      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:01.080629      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:02.081325      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:03.082021      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:04.082266      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:05.082409      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:06.082967      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:07.083352      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:08.084197      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:09.084453      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:10.084960      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:11.085126      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:12.085270      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:13.085347      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:14.085484      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:15.085644      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:16.086328      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:17.087026      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:18.087912      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:19.088083      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:20.088079      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:21.088223      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:22.088312      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:23.089084      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:24.089878      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:25.090348      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:26.091211      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:27.091537      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:28.091679      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:29.091984      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:30.092665      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:31.092774      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:32.092929      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:33.093955      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:34.094805      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:35.094938      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:36.095810      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:37.095947      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:38.096071      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:39.096342      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:40.097057      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:41.097350      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:42.097467      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:43.098169      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:44.098317      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:45.099072      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:46.099231      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:47.099547      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:48.099646      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:49.099781      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:50.100251      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:51.100390      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:52.101469      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:53.102097      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:54.102808      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:55.102928      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:56.103735      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:57.103862      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:58.104291      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:13:59.104426      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:00.105553      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:01.105689      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:02.105719      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:03.106065      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:04.107157      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:05.107314      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:06.107900      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:07.108791      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:08.108855      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:09.109128      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:10.109255      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:11.109848      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:12.110337      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:13.110894      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:14.111772      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:15.112804      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:16.113838      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:17.113948      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:18.114476      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:19.115015      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:20.115348      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:21.115284      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:22.116018      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:23.116896      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:24.117000      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:25.117712      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:26.118330      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:27.118449      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:28.118571      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:29.118845      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:30.119458      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:31.120151      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:32.120192      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:33.120603      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:34.121348      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:35.121488      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:36.122529      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:37.122633      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:38.123566      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:39.124458      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:40.125003      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:41.125268      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:42.125593      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:43.126270      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:44.126971      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:45.127069      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:46.127174      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:47.127453      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:48.128195      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:49.128311      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:50.129323      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:51.129455      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:52.129973      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:53.130679      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:54.131023      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:55.131420      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:56.132306      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:57.132437      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:58.133000      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:14:59.133392      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:00.133631      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:01.133726      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:02.134048      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:03.134891      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:04.135931      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:05.136112      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:06.136577      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:07.136694      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:08.137359      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:09.137624      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:10.138767      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:11.138866      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:12.139149      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:13.139910      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:14.140378      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:15.140686      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:16.141099      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:17.141213      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:18.142212      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:19.142355      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:20.142897      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:21.143095      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:22.143576      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:23.144216      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:24.145271      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:25.145586      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:26.146562      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:27.147116      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:28.148169      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:29.148451      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:30.149227      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:31.149668      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:32.149894      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:33.150511      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:34.150739      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:35.150871      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:36.151165      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:37.151287      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:38.151968      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:39.152109      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:40.153121      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:41.153272      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:42.153290      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:43.154383      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:44.155187      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:45.155485      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:46.156437      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:47.156591      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:48.157296      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:49.157597      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:50.157959      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:51.158106      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:52.158653      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:53.159355      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:54.160388      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:55.161258      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:56.162312      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:57.162468      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:58.163319      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:15:59.163479      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:00.164372      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:01.164524      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:02.164731      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:03.164879      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:04.165115      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:05.166087      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:06.166230      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:07.166391      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:08.166853      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:09.167425      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:10.167738      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:11.167894      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:12.168005      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:13.168380      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:14.168514      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:15.168744      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:16.169074      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:17.169170      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:18.169617      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:19.169726      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:20.170158      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:21.169977      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:22.170944      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:23.171553      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:24.171697      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:25.172652      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:26.172778      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:27.172902      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:28.173301      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:29.173795      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:30.173916      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:31.174440      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:32.174726      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:33.174864      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:34.174967      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:35.175446      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:36.175592      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:16:36.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 14:16:36.242
  STEP: Destroying namespace "container-probe-1223" for this suite. @ 04/19/23 14:16:36.262
• [242.621 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 04/19/23 14:16:36.271
  Apr 19 14:16:36.271: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename secrets @ 04/19/23 14:16:36.272
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:16:36.288
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:16:36.291
  STEP: Creating secret with name secret-test-6ae95c26-72ee-419f-b346-66aad6433c48 @ 04/19/23 14:16:36.313
  STEP: Creating a pod to test consume secrets @ 04/19/23 14:16:36.318
  W0419 14:16:36.324783      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:16:37.175790      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:38.175975      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:16:38.333
  Apr 19 14:16:38.336: INFO: Trying to get logs from node talos-default-worker-1 pod pod-secrets-24bd58a8-ed86-45f0-bb78-493958a16680 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 14:16:38.346
  Apr 19 14:16:38.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-606" for this suite. @ 04/19/23 14:16:38.36
  STEP: Destroying namespace "secret-namespace-2951" for this suite. @ 04/19/23 14:16:38.364
• [2.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]
test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 04/19/23 14:16:38.369
  Apr 19 14:16:38.369: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename disruption @ 04/19/23 14:16:38.369
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:16:38.38
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:16:38.383
  STEP: Creating a kubernetes client @ 04/19/23 14:16:38.386
  Apr 19 14:16:38.386: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename disruption-2 @ 04/19/23 14:16:38.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:16:38.398
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:16:38.4
  STEP: Waiting for the pdb to be processed @ 04/19/23 14:16:38.406
  E0419 14:16:39.176092      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:40.176247      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 04/19/23 14:16:40.418
  E0419 14:16:41.176358      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:42.176477      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 04/19/23 14:16:42.43
  STEP: listing a collection of PDBs across all namespaces @ 04/19/23 14:16:42.435
  STEP: listing a collection of PDBs in namespace disruption-1102 @ 04/19/23 14:16:42.439
  STEP: deleting a collection of PDBs @ 04/19/23 14:16:42.442
  STEP: Waiting for the PDB collection to be deleted @ 04/19/23 14:16:42.453
  Apr 19 14:16:42.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 19 14:16:42.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-9767" for this suite. @ 04/19/23 14:16:42.465
  STEP: Destroying namespace "disruption-1102" for this suite. @ 04/19/23 14:16:42.47
• [4.107 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]
test/e2e/apps/daemon_set.go:432
  STEP: Creating a kubernetes client @ 04/19/23 14:16:42.478
  Apr 19 14:16:42.478: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename daemonsets @ 04/19/23 14:16:42.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:16:42.491
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:16:42.494
  Apr 19 14:16:42.510: INFO: Create a RollingUpdate DaemonSet
  W0419 14:16:42.515040      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:16:42.515: INFO: Check that daemon pods launch on every node of the cluster
  Apr 19 14:16:42.518: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:42.518: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:42.518: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:42.521: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 14:16:42.521: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  E0419 14:16:43.176620      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:16:43.524: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:43.524: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:43.524: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:43.528: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 14:16:43.528: INFO: Node talos-default-worker-2 is running 0 daemon pod, expected 1
  E0419 14:16:44.177065      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:16:44.526: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:44.526: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:44.526: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:44.531: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 14:16:44.531: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  Apr 19 14:16:44.531: INFO: Update the DaemonSet to trigger a rollout
  W0419 14:16:44.541294      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:16:44.541: INFO: Updating DaemonSet daemon-set
  E0419 14:16:45.177882      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:46.178567      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:16:46.564: INFO: Roll back the DaemonSet before rollout is complete
  W0419 14:16:46.572432      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:16:46.572: INFO: Updating DaemonSet daemon-set
  Apr 19 14:16:46.572: INFO: Make sure DaemonSet rollback is complete
  Apr 19 14:16:46.576: INFO: Wrong image for pod: daemon-set-m5x9m. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  Apr 19 14:16:46.577: INFO: Pod daemon-set-m5x9m is not available
  Apr 19 14:16:46.581: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:46.581: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:46.581: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0419 14:16:47.179353      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:16:47.589: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:47.589: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:47.589: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0419 14:16:48.179944      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:16:48.589: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:48.589: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:48.589: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0419 14:16:49.180033      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:16:49.591: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:49.592: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:49.592: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E0419 14:16:50.180097      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:16:50.586: INFO: Pod daemon-set-5s7df is not available
  Apr 19 14:16:50.590: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:50.590: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:16:50.590: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 04/19/23 14:16:50.596
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2272, will wait for the garbage collector to delete the pods @ 04/19/23 14:16:50.597
  Apr 19 14:16:50.665: INFO: Deleting DaemonSet.extensions daemon-set took: 8.676854ms
  Apr 19 14:16:50.766: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.613483ms
  E0419 14:16:51.180490      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:16:51.971: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 14:16:51.971: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Apr 19 14:16:51.974: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"207151"},"items":null}

  Apr 19 14:16:51.978: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"207151"},"items":null}

  Apr 19 14:16:51.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-2272" for this suite. @ 04/19/23 14:16:51.993
• [9.521 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]
test/e2e/apps/rc.go:85
  STEP: Creating a kubernetes client @ 04/19/23 14:16:52.003
  Apr 19 14:16:52.003: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename replication-controller @ 04/19/23 14:16:52.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:16:52.024
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:16:52.027
  Apr 19 14:16:52.029: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0419 14:16:52.180636      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 04/19/23 14:16:53.041
  W0419 14:16:53.047447      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Checking rc "condition-test" has the desired failure condition set @ 04/19/23 14:16:53.047
  E0419 14:16:53.180777      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 04/19/23 14:16:54.055
  W0419 14:16:54.064487      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "httpd" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "httpd" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "httpd" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "httpd" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:16:54.064: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 04/19/23 14:16:54.064
  E0419 14:16:54.181206      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:16:55.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-7904" for this suite. @ 04/19/23 14:16:55.077
• [3.081 seconds]
------------------------------
S
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]
test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 04/19/23 14:16:55.083
  Apr 19 14:16:55.083: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename cronjob @ 04/19/23 14:16:55.087
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:16:55.106
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:16:55.109
  STEP: Creating a ReplaceConcurrent cronjob @ 04/19/23 14:16:55.111
  W0419 14:16:55.115941      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring a job is scheduled @ 04/19/23 14:16:55.116
  E0419 14:16:55.182251      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:56.182319      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:57.182570      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:58.183032      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:16:59.183789      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:00.183964      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 04/19/23 14:17:01.12
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 04/19/23 14:17:01.123
  STEP: Ensuring the job is replaced with a new one @ 04/19/23 14:17:01.126
  E0419 14:17:01.185040      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:02.185140      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:03.185644      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:04.185862      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:05.185847      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:06.186170      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:07.187210      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:08.187894      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:09.188382      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:10.188639      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:11.189027      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:12.189380      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:13.189681      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:14.190314      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:15.190873      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:16.191037      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:17.191277      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:18.192417      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:19.192945      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:20.193377      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:21.194080      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:22.194525      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:23.195377      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:24.196257      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:25.196363      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:26.196671      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:27.197518      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:28.198202      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:29.198468      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:30.199012      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:31.199451      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:32.199586      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:33.200620      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:34.201041      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:35.201276      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:36.202002      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:37.202408      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:38.202836      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:39.203437      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:40.203712      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:41.204432      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:42.204891      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:43.205452      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:44.205627      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:45.206310      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:46.206432      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:47.207422      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:48.208460      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:49.208781      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:50.208902      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:51.209096      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:52.209222      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:53.209415      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:54.209563      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:55.210563      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:56.210644      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:57.211305      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:58.211481      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:17:59.212042      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:00.212376      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 04/19/23 14:18:01.131
  Apr 19 14:18:01.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-9886" for this suite. @ 04/19/23 14:18:01.144
• [66.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]
test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 04/19/23 14:18:01.161
  Apr 19 14:18:01.162: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename watch @ 04/19/23 14:18:01.165
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:18:01.181
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:18:01.185
  STEP: creating a watch on configmaps @ 04/19/23 14:18:01.188
  STEP: creating a new configmap @ 04/19/23 14:18:01.19
  STEP: modifying the configmap once @ 04/19/23 14:18:01.195
  STEP: closing the watch once it receives two notifications @ 04/19/23 14:18:01.203
  Apr 19 14:18:01.203: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7522  3e506156-8c15-4f65-b5f1-1fd4bad8aae0 207445 0 2023-04-19 14:18:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-19 14:18:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 14:18:01.204: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7522  3e506156-8c15-4f65-b5f1-1fd4bad8aae0 207446 0 2023-04-19 14:18:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-19 14:18:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 04/19/23 14:18:01.204
  E0419 14:18:01.212588      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 04/19/23 14:18:01.212
  STEP: deleting the configmap @ 04/19/23 14:18:01.214
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 04/19/23 14:18:01.22
  Apr 19 14:18:01.220: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7522  3e506156-8c15-4f65-b5f1-1fd4bad8aae0 207447 0 2023-04-19 14:18:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-19 14:18:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 14:18:01.220: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7522  3e506156-8c15-4f65-b5f1-1fd4bad8aae0 207448 0 2023-04-19 14:18:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-19 14:18:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Apr 19 14:18:01.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-7522" for this suite. @ 04/19/23 14:18:01.225
• [0.069 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]
test/e2e/storage/subpath.go:60
  STEP: Creating a kubernetes client @ 04/19/23 14:18:01.23
  Apr 19 14:18:01.230: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename subpath @ 04/19/23 14:18:01.231
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:18:01.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:18:01.244
  STEP: Setting up data @ 04/19/23 14:18:01.246
  STEP: Creating pod pod-subpath-test-secret-sdsw @ 04/19/23 14:18:01.253
  STEP: Creating a pod to test atomic-volume-subpath @ 04/19/23 14:18:01.253
  W0419 14:18:01.258576      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container-subpath-secret-sdsw" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container-subpath-secret-sdsw" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container-subpath-secret-sdsw" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container-subpath-secret-sdsw" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:18:02.212784      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:03.213345      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:04.213512      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:05.213636      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:06.213964      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:07.214080      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:08.214464      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:09.214635      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:10.214750      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:11.215053      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:12.215178      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:13.215645      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:14.215784      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:15.216071      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:16.216147      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:17.216812      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:18.217927      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:19.218464      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:20.219373      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:21.218704      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:22.218865      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:23.219400      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:18:23.313
  Apr 19 14:18:23.316: INFO: Trying to get logs from node talos-default-worker-2 pod pod-subpath-test-secret-sdsw container test-container-subpath-secret-sdsw: <nil>
  STEP: delete the pod @ 04/19/23 14:18:23.324
  STEP: Deleting pod pod-subpath-test-secret-sdsw @ 04/19/23 14:18:23.338
  Apr 19 14:18:23.338: INFO: Deleting pod "pod-subpath-test-secret-sdsw" in namespace "subpath-3664"
  Apr 19 14:18:23.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3664" for this suite. @ 04/19/23 14:18:23.345
• [22.121 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 04/19/23 14:18:23.352
  Apr 19 14:18:23.352: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pods @ 04/19/23 14:18:23.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:18:23.366
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:18:23.368
  STEP: creating the pod @ 04/19/23 14:18:23.371
  STEP: submitting the pod to kubernetes @ 04/19/23 14:18:23.371
  W0419 14:18:23.377977      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: verifying QOS class is set on the pod @ 04/19/23 14:18:23.378
  Apr 19 14:18:23.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7758" for this suite. @ 04/19/23 14:18:23.386
• [0.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]
test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 04/19/23 14:18:23.393
  Apr 19 14:18:23.393: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename certificates @ 04/19/23 14:18:23.394
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:18:23.405
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:18:23.408
  STEP: getting /apis @ 04/19/23 14:18:23.667
  STEP: getting /apis/certificates.k8s.io @ 04/19/23 14:18:23.671
  STEP: getting /apis/certificates.k8s.io/v1 @ 04/19/23 14:18:23.672
  STEP: creating @ 04/19/23 14:18:23.673
  STEP: getting @ 04/19/23 14:18:23.684
  STEP: listing @ 04/19/23 14:18:23.687
  STEP: watching @ 04/19/23 14:18:23.689
  Apr 19 14:18:23.689: INFO: starting watch
  STEP: patching @ 04/19/23 14:18:23.69
  STEP: updating @ 04/19/23 14:18:23.695
  Apr 19 14:18:23.700: INFO: waiting for watch events with expected annotations
  Apr 19 14:18:23.700: INFO: saw patched and updated annotations
  STEP: getting /approval @ 04/19/23 14:18:23.7
  STEP: patching /approval @ 04/19/23 14:18:23.704
  STEP: updating /approval @ 04/19/23 14:18:23.709
  STEP: getting /status @ 04/19/23 14:18:23.714
  STEP: patching /status @ 04/19/23 14:18:23.718
  STEP: updating /status @ 04/19/23 14:18:23.723
  STEP: deleting @ 04/19/23 14:18:23.728
  STEP: deleting a collection @ 04/19/23 14:18:23.738
  Apr 19 14:18:23.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-4049" for this suite. @ 04/19/23 14:18:23.749
• [0.360 seconds]
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]
test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 04/19/23 14:18:23.754
  Apr 19 14:18:23.754: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename proxy @ 04/19/23 14:18:23.754
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:18:23.764
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:18:23.766
  Apr 19 14:18:23.769: INFO: Creating pod...
  W0419 14:18:23.774830      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:18:24.220326      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:25.220449      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:18:25.782: INFO: Creating service...
  Apr 19 14:18:25.794: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5242/pods/agnhost/proxy?method=DELETE
  Apr 19 14:18:25.808: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 19 14:18:25.808: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5242/pods/agnhost/proxy?method=OPTIONS
  Apr 19 14:18:25.814: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 19 14:18:25.814: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5242/pods/agnhost/proxy?method=PATCH
  Apr 19 14:18:25.819: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 19 14:18:25.820: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5242/pods/agnhost/proxy?method=POST
  Apr 19 14:18:25.826: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 19 14:18:25.827: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5242/pods/agnhost/proxy?method=PUT
  Apr 19 14:18:25.831: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 19 14:18:25.831: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5242/services/e2e-proxy-test-service/proxy?method=DELETE
  Apr 19 14:18:25.836: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Apr 19 14:18:25.836: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5242/services/e2e-proxy-test-service/proxy?method=OPTIONS
  Apr 19 14:18:25.840: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Apr 19 14:18:25.840: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5242/services/e2e-proxy-test-service/proxy?method=PATCH
  Apr 19 14:18:25.843: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Apr 19 14:18:25.843: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5242/services/e2e-proxy-test-service/proxy?method=POST
  Apr 19 14:18:25.847: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Apr 19 14:18:25.847: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5242/services/e2e-proxy-test-service/proxy?method=PUT
  Apr 19 14:18:25.850: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Apr 19 14:18:25.850: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5242/pods/agnhost/proxy?method=GET
  Apr 19 14:18:25.852: INFO: http.Client request:GET StatusCode:301
  Apr 19 14:18:25.852: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5242/services/e2e-proxy-test-service/proxy?method=GET
  Apr 19 14:18:25.855: INFO: http.Client request:GET StatusCode:301
  Apr 19 14:18:25.855: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5242/pods/agnhost/proxy?method=HEAD
  Apr 19 14:18:25.857: INFO: http.Client request:HEAD StatusCode:301
  Apr 19 14:18:25.857: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-5242/services/e2e-proxy-test-service/proxy?method=HEAD
  Apr 19 14:18:25.859: INFO: http.Client request:HEAD StatusCode:301
  Apr 19 14:18:25.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-5242" for this suite. @ 04/19/23 14:18:25.862
• [2.112 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]
test/e2e/apimachinery/webhook.go:209
  STEP: Creating a kubernetes client @ 04/19/23 14:18:25.866
  Apr 19 14:18:25.866: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 14:18:25.867
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:18:25.876
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:18:25.878
  STEP: Setting up server cert @ 04/19/23 14:18:25.892
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 14:18:26.056
  STEP: Deploying the webhook pod @ 04/19/23 14:18:26.062
  W0419 14:18:26.074117      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 14:18:26.074
  Apr 19 14:18:26.080: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 14:18:26.220733      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:27.220864      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/23 14:18:28.092
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 14:18:28.111
  E0419 14:18:28.221442      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:18:29.112: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 04/19/23 14:18:29.116
  STEP: create a pod @ 04/19/23 14:18:29.132
  W0419 14:18:29.141545      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "container1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "container1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "container1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "container1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:18:29.222210      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:30.222696      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 04/19/23 14:18:31.151
  Apr 19 14:18:31.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=webhook-8580 attach --namespace=webhook-8580 to-be-attached-pod -i -c=container1'
  E0419 14:18:31.222708      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:18:31.243: INFO: rc: 1
  Apr 19 14:18:31.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8580" for this suite. @ 04/19/23 14:18:31.29
  STEP: Destroying namespace "webhook-markers-6153" for this suite. @ 04/19/23 14:18:31.295
• [5.433 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:177
  STEP: Creating a kubernetes client @ 04/19/23 14:18:31.301
  Apr 19 14:18:31.301: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 14:18:31.302
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:18:31.313
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:18:31.315
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 04/19/23 14:18:31.317
  W0419 14:18:31.324110      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:18:32.223216      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:33.223947      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:34.224063      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:35.224216      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:18:35.345
  Apr 19 14:18:35.349: INFO: Trying to get logs from node talos-default-worker-1 pod pod-9d3618e4-6b59-4dff-ad5a-06a9723d91d5 container test-container: <nil>
  STEP: delete the pod @ 04/19/23 14:18:35.362
  Apr 19 14:18:35.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2097" for this suite. @ 04/19/23 14:18:35.38
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:187
  STEP: Creating a kubernetes client @ 04/19/23 14:18:35.401
  Apr 19 14:18:35.401: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 14:18:35.405
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:18:35.421
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:18:35.425
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/19/23 14:18:35.428
  W0419 14:18:35.437721      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:18:36.224275      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:37.224430      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:38.225195      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:39.225290      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:18:39.452
  Apr 19 14:18:39.456: INFO: Trying to get logs from node talos-default-worker-1 pod pod-3ea5eba0-dcde-4c11-b104-9ea08d1009db container test-container: <nil>
  STEP: delete the pod @ 04/19/23 14:18:39.463
  Apr 19 14:18:39.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4273" for this suite. @ 04/19/23 14:18:39.486
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 04/19/23 14:18:39.495
  Apr 19 14:18:39.496: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename var-expansion @ 04/19/23 14:18:39.498
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:18:39.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:18:39.515
  STEP: creating the pod with failed condition @ 04/19/23 14:18:39.518
  W0419 14:18:39.527237      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "dapi-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "dapi-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "dapi-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "dapi-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:18:40.226327      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:41.226921      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:42.227881      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:43.227960      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:44.228080      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:45.228214      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:46.228298      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:47.228477      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:48.229125      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:49.229250      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:50.229369      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:51.229817      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:52.229875      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:53.230215      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:54.230690      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:55.230973      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:56.231124      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:57.231485      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:58.232043      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:18:59.232467      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:00.233251      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:01.233598      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:02.233680      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:03.234406      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:04.234583      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:05.234869      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:06.235315      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:07.236397      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:08.237084      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:09.237392      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:10.238240      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:11.238531      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:12.239078      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:13.239301      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:14.239835      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:15.239971      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:16.240840      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:17.241000      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:18.241031      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:19.241647      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:20.242456      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:21.243010      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:22.243175      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:23.243256      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:24.243393      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:25.243678      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:26.244545      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:27.244690      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:28.245327      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:29.245444      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:30.246171      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:31.246491      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:32.246665      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:33.247082      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:34.247358      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:35.247724      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:36.247824      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:37.248107      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:38.248347      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:39.249134      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:40.249256      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:41.249417      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:42.249521      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:43.250517      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:44.251282      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:45.251596      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:46.251714      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:47.252155      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:48.253041      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:49.253693      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:50.254713      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:51.254929      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:52.255025      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:53.255150      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:54.255286      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:55.255617      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:56.255682      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:57.256062      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:58.256583      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:19:59.256718      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:00.257231      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:01.257368      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:02.257440      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:03.257586      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:04.258318      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:05.258541      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:06.259497      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:07.260380      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:08.261098      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:09.261494      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:10.262581      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:11.262948      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:12.263077      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:13.264094      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:14.265169      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:15.265511      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:16.265595      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:17.265813      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:18.265950      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:19.266121      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:20.266586      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:21.266410      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:22.267351      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:23.268442      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:24.269456      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:25.269591      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:26.270556      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:27.270801      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:28.270979      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:29.271083      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:30.271462      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:31.272431      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:32.273450      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:33.274017      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:34.274981      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:35.275233      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:36.275331      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:37.275588      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:38.275703      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:39.275846      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: updating the pod @ 04/19/23 14:20:39.528
  Apr 19 14:20:40.040: INFO: Successfully updated pod "var-expansion-60532614-1ec0-41c3-aaaf-236b702ddf64"
  STEP: waiting for pod running @ 04/19/23 14:20:40.04
  E0419 14:20:40.275981      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:41.276448      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 04/19/23 14:20:42.049
  Apr 19 14:20:42.049: INFO: Deleting pod "var-expansion-60532614-1ec0-41c3-aaaf-236b702ddf64" in namespace "var-expansion-6197"
  Apr 19 14:20:42.060: INFO: Wait up to 5m0s for pod "var-expansion-60532614-1ec0-41c3-aaaf-236b702ddf64" to be fully deleted
  E0419 14:20:42.276645      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:43.277245      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:44.277879      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:45.278029      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:46.278429      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:47.279261      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:48.279935      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:49.280582      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:50.281519      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:51.281871      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:52.282254      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:53.282626      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:54.282772      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:55.282901      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:56.283287      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:57.283421      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:58.284125      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:20:59.284560      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:00.285328      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:01.285645      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:02.286432      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:03.287106      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:04.287907      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:05.288524      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:06.289400      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:07.289644      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:08.290181      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:09.290466      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:10.290851      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:11.291277      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:12.292099      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:13.292845      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:21:14.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6197" for this suite. @ 04/19/23 14:21:14.142
• [154.654 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster  [Conformance]
test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 04/19/23 14:21:14.154
  Apr 19 14:21:14.154: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename dns @ 04/19/23 14:21:14.157
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:21:14.173
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:21:14.177
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/19/23 14:21:14.18
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 04/19/23 14:21:14.181
  STEP: creating a pod to probe DNS @ 04/19/23 14:21:14.181
  STEP: submitting the pod to kubernetes @ 04/19/23 14:21:14.181
  W0419 14:21:14.191361      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:21:14.293001      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:15.293122      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/23 14:21:16.201
  STEP: looking for the results for each expected name from probers @ 04/19/23 14:21:16.205
  Apr 19 14:21:16.222: INFO: DNS probes using dns-7412/dns-test-6df3afce-79d9-44fd-82c5-a52f8317fa03 succeeded

  Apr 19 14:21:16.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 14:21:16.228
  STEP: Destroying namespace "dns-7412" for this suite. @ 04/19/23 14:21:16.245
• [2.098 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:163
  STEP: Creating a kubernetes client @ 04/19/23 14:21:16.254
  Apr 19 14:21:16.254: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 14:21:16.257
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:21:16.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:21:16.275
  STEP: Creating the pod @ 04/19/23 14:21:16.279
  W0419 14:21:16.287594      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:21:16.293275      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:17.294347      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:18.294911      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:21:18.822: INFO: Successfully updated pod "annotationupdatea232d54b-6457-4324-8e75-74a410392dac"
  E0419 14:21:19.295026      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:20.295224      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:21.296160      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:22.296487      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:21:22.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4676" for this suite. @ 04/19/23 14:21:22.849
• [6.602 seconds]
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]
test/e2e/apps/statefulset.go:316
  STEP: Creating a kubernetes client @ 04/19/23 14:21:22.857
  Apr 19 14:21:22.857: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename statefulset @ 04/19/23 14:21:22.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:21:22.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:21:22.874
  STEP: Creating service test in namespace statefulset-8651 @ 04/19/23 14:21:22.877
  STEP: Creating a new StatefulSet @ 04/19/23 14:21:22.882
  W0419 14:21:22.887615      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:21:22.890: INFO: Found 0 stateful pods, waiting for 3
  E0419 14:21:23.297513      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:24.297880      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:25.298009      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:26.298271      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:27.298528      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:28.298960      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:29.299042      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:30.299338      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:31.299469      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:32.299583      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:21:32.896: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 14:21:32.896: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 14:21:32.896: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Apr 19 14:21:32.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-8651 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 14:21:33.099: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 14:21:33.099: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 14:21:33.099: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0419 14:21:33.300674      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:34.300826      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:35.300981      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:36.301254      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:37.301644      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:38.302136      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:39.302486      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:40.302930      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:41.303162      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:42.303544      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 04/19/23 14:21:43.12
  W0419 14:21:43.145341      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:21:43.145: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 04/19/23 14:21:43.145
  E0419 14:21:43.304069      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:44.304464      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:45.304608      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:46.304724      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:47.304877      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:48.305006      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:49.305364      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:50.305647      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:51.306161      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:52.306409      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 04/19/23 14:21:53.163
  Apr 19 14:21:53.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-8651 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E0419 14:21:53.307436      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:21:53.403: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 19 14:21:53.403: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 14:21:53.403: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0419 14:21:54.307924      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:55.308252      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:56.308340      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:57.308455      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:58.308626      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:21:59.309490      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:00.309850      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:01.309899      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:02.310040      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:03.310577      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 04/19/23 14:22:03.425
  Apr 19 14:22:03.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-8651 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Apr 19 14:22:03.626: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Apr 19 14:22:03.626: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Apr 19 14:22:03.626: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0419 14:22:04.311461      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:05.311564      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:06.311699      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:07.311931      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:08.312361      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:09.312942      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:10.313222      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:11.313358      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:12.314018      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:13.314600      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  W0419 14:22:13.663236      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:22:13.663: INFO: Updating stateful set ss2
  E0419 14:22:14.314966      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:15.315220      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:16.315515      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:17.315646      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:18.316116      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:19.316663      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:20.317123      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:21.317261      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:22.317892      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:23.318416      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 04/19/23 14:22:23.68
  Apr 19 14:22:23.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=statefulset-8651 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Apr 19 14:22:23.866: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Apr 19 14:22:23.866: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Apr 19 14:22:23.866: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0419 14:22:24.319105      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:25.319922      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:26.320222      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:27.320343      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:28.320496      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:29.321160      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:30.321320      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:31.321444      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:32.321592      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:33.322415      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:22:33.887: INFO: Waiting for StatefulSet statefulset-8651/ss2 to complete update
  Apr 19 14:22:33.888: INFO: Waiting for Pod statefulset-8651/ss2-0 to have revision ss2-7b6c9599d5 update revision ss2-5459d8585b
  Apr 19 14:22:33.888: INFO: Waiting for Pod statefulset-8651/ss2-1 to have revision ss2-7b6c9599d5 update revision ss2-5459d8585b
  E0419 14:22:34.323349      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:35.324285      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:36.324535      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:37.324899      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:38.325655      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:39.326039      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:40.326629      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:41.326952      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:42.327095      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:43.327929      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:22:43.897: INFO: Deleting all statefulset in ns statefulset-8651
  Apr 19 14:22:43.900: INFO: Scaling statefulset ss2 to 0
  W0419 14:22:43.910848      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "webserver" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "webserver" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "webserver" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "webserver" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:22:44.328524      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:45.329114      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:46.329258      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:47.329471      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:48.330000      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:49.330547      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:50.330823      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:51.331097      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:52.331246      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:53.331670      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:22:53.920: INFO: Waiting for statefulset status.replicas updated to 0
  Apr 19 14:22:53.924: INFO: Deleting statefulset ss2
  Apr 19 14:22:53.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8651" for this suite. @ 04/19/23 14:22:53.943
• [91.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]
test/e2e/apimachinery/webhook.go:237
  STEP: Creating a kubernetes client @ 04/19/23 14:22:53.958
  Apr 19 14:22:53.959: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 14:22:53.963
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:22:53.98
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:22:53.983
  STEP: Setting up server cert @ 04/19/23 14:22:54.011
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 14:22:54.197
  STEP: Deploying the webhook pod @ 04/19/23 14:22:54.206
  W0419 14:22:54.222473      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 14:22:54.222
  Apr 19 14:22:54.230: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 14:22:54.332628      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:55.332811      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/23 14:22:56.241
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 14:22:56.259
  E0419 14:22:56.333156      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:22:57.259: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 04/19/23 14:22:57.265
  STEP: create a namespace for the webhook @ 04/19/23 14:22:57.282
  STEP: create a configmap should be unconditionally rejected by the webhook @ 04/19/23 14:22:57.297
  Apr 19 14:22:57.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  E0419 14:22:57.333575      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-4542" for this suite. @ 04/19/23 14:22:57.343
  STEP: Destroying namespace "webhook-markers-1440" for this suite. @ 04/19/23 14:22:57.348
  STEP: Destroying namespace "fail-closed-namespace-8758" for this suite. @ 04/19/23 14:22:57.354
• [3.400 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
test/e2e/apimachinery/garbage_collector.go:713
  STEP: Creating a kubernetes client @ 04/19/23 14:22:57.361
  Apr 19 14:22:57.361: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename gc @ 04/19/23 14:22:57.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:22:57.373
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:22:57.375
  STEP: create the rc1 @ 04/19/23 14:22:57.381
  W0419 14:22:57.385569      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: create the rc2 @ 04/19/23 14:22:57.385
  W0419 14:22:57.390590      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:22:58.333911      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:22:59.336845      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:00.337413      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:01.343284      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:02.343737      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:03.346198      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 04/19/23 14:23:03.398
  STEP: delete the rc simpletest-rc-to-be-deleted @ 04/19/23 14:23:03.861
  STEP: wait for the rc to be deleted @ 04/19/23 14:23:03.866
  E0419 14:23:04.354705      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:05.383409      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:06.404775      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:07.426438      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:08.429290      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:08.900: INFO: 68 pods remaining
  Apr 19 14:23:08.900: INFO: 68 pods has nil DeletionTimestamp
  Apr 19 14:23:08.900: INFO: 
  E0419 14:23:09.430811      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:10.430949      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:11.431187      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:12.433892      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:13.434015      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/19/23 14:23:13.879
  Apr 19 14:23:13.939: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 19 14:23:13.949: INFO: Deleting pod "simpletest-rc-to-be-deleted-2b672" in namespace "gc-6983"
  Apr 19 14:23:13.964: INFO: Deleting pod "simpletest-rc-to-be-deleted-2fkpn" in namespace "gc-6983"
  Apr 19 14:23:13.976: INFO: Deleting pod "simpletest-rc-to-be-deleted-2xfq9" in namespace "gc-6983"
  Apr 19 14:23:13.986: INFO: Deleting pod "simpletest-rc-to-be-deleted-522rb" in namespace "gc-6983"
  Apr 19 14:23:13.995: INFO: Deleting pod "simpletest-rc-to-be-deleted-5b8vw" in namespace "gc-6983"
  Apr 19 14:23:14.005: INFO: Deleting pod "simpletest-rc-to-be-deleted-5kkhz" in namespace "gc-6983"
  Apr 19 14:23:14.015: INFO: Deleting pod "simpletest-rc-to-be-deleted-5kv8h" in namespace "gc-6983"
  Apr 19 14:23:14.027: INFO: Deleting pod "simpletest-rc-to-be-deleted-667hv" in namespace "gc-6983"
  Apr 19 14:23:14.035: INFO: Deleting pod "simpletest-rc-to-be-deleted-69xxl" in namespace "gc-6983"
  Apr 19 14:23:14.046: INFO: Deleting pod "simpletest-rc-to-be-deleted-6cwdw" in namespace "gc-6983"
  Apr 19 14:23:14.056: INFO: Deleting pod "simpletest-rc-to-be-deleted-6h727" in namespace "gc-6983"
  Apr 19 14:23:14.068: INFO: Deleting pod "simpletest-rc-to-be-deleted-6js86" in namespace "gc-6983"
  Apr 19 14:23:14.082: INFO: Deleting pod "simpletest-rc-to-be-deleted-6vxz6" in namespace "gc-6983"
  Apr 19 14:23:14.105: INFO: Deleting pod "simpletest-rc-to-be-deleted-7759j" in namespace "gc-6983"
  Apr 19 14:23:14.114: INFO: Deleting pod "simpletest-rc-to-be-deleted-77gd5" in namespace "gc-6983"
  Apr 19 14:23:14.127: INFO: Deleting pod "simpletest-rc-to-be-deleted-7g54k" in namespace "gc-6983"
  Apr 19 14:23:14.139: INFO: Deleting pod "simpletest-rc-to-be-deleted-7wgzn" in namespace "gc-6983"
  Apr 19 14:23:14.150: INFO: Deleting pod "simpletest-rc-to-be-deleted-8466p" in namespace "gc-6983"
  Apr 19 14:23:14.162: INFO: Deleting pod "simpletest-rc-to-be-deleted-84nr9" in namespace "gc-6983"
  Apr 19 14:23:14.172: INFO: Deleting pod "simpletest-rc-to-be-deleted-857tq" in namespace "gc-6983"
  Apr 19 14:23:14.184: INFO: Deleting pod "simpletest-rc-to-be-deleted-8698d" in namespace "gc-6983"
  Apr 19 14:23:14.195: INFO: Deleting pod "simpletest-rc-to-be-deleted-88pwp" in namespace "gc-6983"
  Apr 19 14:23:14.205: INFO: Deleting pod "simpletest-rc-to-be-deleted-8lj47" in namespace "gc-6983"
  Apr 19 14:23:14.223: INFO: Deleting pod "simpletest-rc-to-be-deleted-8pcdr" in namespace "gc-6983"
  Apr 19 14:23:14.235: INFO: Deleting pod "simpletest-rc-to-be-deleted-8q255" in namespace "gc-6983"
  Apr 19 14:23:14.246: INFO: Deleting pod "simpletest-rc-to-be-deleted-8w9mh" in namespace "gc-6983"
  Apr 19 14:23:14.258: INFO: Deleting pod "simpletest-rc-to-be-deleted-9j4sg" in namespace "gc-6983"
  Apr 19 14:23:14.271: INFO: Deleting pod "simpletest-rc-to-be-deleted-9tmmb" in namespace "gc-6983"
  Apr 19 14:23:14.282: INFO: Deleting pod "simpletest-rc-to-be-deleted-b5xtt" in namespace "gc-6983"
  Apr 19 14:23:14.294: INFO: Deleting pod "simpletest-rc-to-be-deleted-b899s" in namespace "gc-6983"
  Apr 19 14:23:14.305: INFO: Deleting pod "simpletest-rc-to-be-deleted-blfcd" in namespace "gc-6983"
  Apr 19 14:23:14.314: INFO: Deleting pod "simpletest-rc-to-be-deleted-bpx46" in namespace "gc-6983"
  Apr 19 14:23:14.323: INFO: Deleting pod "simpletest-rc-to-be-deleted-bsc4l" in namespace "gc-6983"
  Apr 19 14:23:14.334: INFO: Deleting pod "simpletest-rc-to-be-deleted-c79t5" in namespace "gc-6983"
  Apr 19 14:23:14.346: INFO: Deleting pod "simpletest-rc-to-be-deleted-czzxt" in namespace "gc-6983"
  Apr 19 14:23:14.356: INFO: Deleting pod "simpletest-rc-to-be-deleted-d24q9" in namespace "gc-6983"
  Apr 19 14:23:14.366: INFO: Deleting pod "simpletest-rc-to-be-deleted-fdqwz" in namespace "gc-6983"
  Apr 19 14:23:14.377: INFO: Deleting pod "simpletest-rc-to-be-deleted-fh8kf" in namespace "gc-6983"
  Apr 19 14:23:14.387: INFO: Deleting pod "simpletest-rc-to-be-deleted-flsxf" in namespace "gc-6983"
  Apr 19 14:23:14.398: INFO: Deleting pod "simpletest-rc-to-be-deleted-fr4zn" in namespace "gc-6983"
  Apr 19 14:23:14.409: INFO: Deleting pod "simpletest-rc-to-be-deleted-fttlc" in namespace "gc-6983"
  Apr 19 14:23:14.419: INFO: Deleting pod "simpletest-rc-to-be-deleted-ftzs8" in namespace "gc-6983"
  Apr 19 14:23:14.429: INFO: Deleting pod "simpletest-rc-to-be-deleted-ggp2v" in namespace "gc-6983"
  E0419 14:23:14.434342      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:14.438: INFO: Deleting pod "simpletest-rc-to-be-deleted-gmcqw" in namespace "gc-6983"
  Apr 19 14:23:14.450: INFO: Deleting pod "simpletest-rc-to-be-deleted-gr479" in namespace "gc-6983"
  Apr 19 14:23:14.459: INFO: Deleting pod "simpletest-rc-to-be-deleted-grllf" in namespace "gc-6983"
  Apr 19 14:23:14.468: INFO: Deleting pod "simpletest-rc-to-be-deleted-gw9lg" in namespace "gc-6983"
  Apr 19 14:23:14.479: INFO: Deleting pod "simpletest-rc-to-be-deleted-hb9nd" in namespace "gc-6983"
  Apr 19 14:23:14.488: INFO: Deleting pod "simpletest-rc-to-be-deleted-hst62" in namespace "gc-6983"
  Apr 19 14:23:14.498: INFO: Deleting pod "simpletest-rc-to-be-deleted-hzxr9" in namespace "gc-6983"
  Apr 19 14:23:14.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-6983" for this suite. @ 04/19/23 14:23:14.513
• [17.157 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:137
  STEP: Creating a kubernetes client @ 04/19/23 14:23:14.519
  Apr 19 14:23:14.519: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 14:23:14.519
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:23:14.535
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:23:14.538
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 04/19/23 14:23:14.54
  W0419 14:23:14.548138      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:23:15.434383      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:16.434941      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:17.435075      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:18.435885      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:23:18.561
  Apr 19 14:23:18.565: INFO: Trying to get logs from node talos-default-worker-1 pod pod-d7d11349-7971-4b05-b9c6-c24ebb15a334 container test-container: <nil>
  STEP: delete the pod @ 04/19/23 14:23:18.581
  Apr 19 14:23:18.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7582" for this suite. @ 04/19/23 14:23:18.601
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods  [Conformance]
test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 04/19/23 14:23:18.611
  Apr 19 14:23:18.611: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 14:23:18.612
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:23:18.625
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:23:18.628
  STEP: creating service endpoint-test2 in namespace services-1750 @ 04/19/23 14:23:18.631
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1750 to expose endpoints map[] @ 04/19/23 14:23:18.645
  Apr 19 14:23:18.656: INFO: successfully validated that service endpoint-test2 in namespace services-1750 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-1750 @ 04/19/23 14:23:18.658
  W0419 14:23:18.666718      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:23:19.436472      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:20.436532      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1750 to expose endpoints map[pod1:[80]] @ 04/19/23 14:23:20.676
  Apr 19 14:23:20.686: INFO: successfully validated that service endpoint-test2 in namespace services-1750 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 04/19/23 14:23:20.686
  Apr 19 14:23:20.686: INFO: Creating new exec pod
  W0419 14:23:20.691886      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:23:21.437520      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:22.437621      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:23.437811      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:23.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1750 exec execpod6pm7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 19 14:23:23.855: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 19 14:23:23.855: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 14:23:23.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1750 exec execpod6pm7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.248.138 80'
  Apr 19 14:23:24.040: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.248.138 80\nConnection to 10.96.248.138 80 port [tcp/http] succeeded!\n"
  Apr 19 14:23:24.040: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-1750 @ 04/19/23 14:23:24.041
  W0419 14:23:24.048644      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:23:24.437869      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:25.438324      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1750 to expose endpoints map[pod1:[80] pod2:[80]] @ 04/19/23 14:23:26.062
  Apr 19 14:23:26.076: INFO: successfully validated that service endpoint-test2 in namespace services-1750 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 04/19/23 14:23:26.076
  E0419 14:23:26.439010      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:27.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1750 exec execpod6pm7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 19 14:23:27.288: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 19 14:23:27.288: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 14:23:27.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1750 exec execpod6pm7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.248.138 80'
  E0419 14:23:27.439104      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:27.513: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.248.138 80\nConnection to 10.96.248.138 80 port [tcp/http] succeeded!\n"
  Apr 19 14:23:27.513: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-1750 @ 04/19/23 14:23:27.513
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1750 to expose endpoints map[pod2:[80]] @ 04/19/23 14:23:27.523
  Apr 19 14:23:27.539: INFO: successfully validated that service endpoint-test2 in namespace services-1750 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 04/19/23 14:23:27.539
  E0419 14:23:28.439498      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:28.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1750 exec execpod6pm7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  E0419 14:23:29.440273      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:30.440530      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:30.778: INFO: rc: 1
  Apr 19 14:23:30.778: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1750 exec execpod6pm7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 endpoint-test2 80
  nc: connect to endpoint-test2 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  E0419 14:23:31.440817      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:31.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1750 exec execpod6pm7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  E0419 14:23:32.441637      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:33.442347      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:34.009: INFO: rc: 1
  Apr 19 14:23:34.009: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1750 exec execpod6pm7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 endpoint-test2 80
  + echo hostName
  nc: connect to endpoint-test2 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  E0419 14:23:34.442671      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:34.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1750 exec execpod6pm7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  E0419 14:23:35.443156      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:36.444133      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:36.983: INFO: rc: 1
  Apr 19 14:23:36.983: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1750 exec execpod6pm7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 endpoint-test2 80
  nc: connect to endpoint-test2 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  E0419 14:23:37.444261      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:37.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1750 exec execpod6pm7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Apr 19 14:23:37.991: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Apr 19 14:23:37.991: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 14:23:37.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-1750 exec execpod6pm7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.248.138 80'
  Apr 19 14:23:38.208: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.248.138 80\nConnection to 10.96.248.138 80 port [tcp/http] succeeded!\n"
  Apr 19 14:23:38.208: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-1750 @ 04/19/23 14:23:38.208
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1750 to expose endpoints map[] @ 04/19/23 14:23:38.23
  Apr 19 14:23:38.244: INFO: successfully validated that service endpoint-test2 in namespace services-1750 exposes endpoints map[]
  Apr 19 14:23:38.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1750" for this suite. @ 04/19/23 14:23:38.266
• [19.661 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]
test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 04/19/23 14:23:38.272
  Apr 19 14:23:38.272: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 14:23:38.273
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:23:38.285
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:23:38.288
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-738 @ 04/19/23 14:23:38.29
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/19/23 14:23:38.302
  STEP: creating service externalsvc in namespace services-738 @ 04/19/23 14:23:38.302
  STEP: creating replication controller externalsvc in namespace services-738 @ 04/19/23 14:23:38.312
  W0419 14:23:38.317432      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "externalsvc" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "externalsvc" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "externalsvc" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "externalsvc" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  I0419 14:23:38.317633      20 runners.go:194] Created replication controller with name: externalsvc, namespace: services-738, replica count: 2
  E0419 14:23:38.445041      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:39.445517      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:40.445658      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0419 14:23:41.370309      20 runners.go:194] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 04/19/23 14:23:41.374
  Apr 19 14:23:41.400: INFO: Creating new exec pod
  W0419 14:23:41.411747      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:23:41.446436      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:42.446987      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:43.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-738 exec execpodgpw4v -- /bin/sh -x -c nslookup nodeport-service.services-738.svc.cluster.local'
  E0419 14:23:43.447841      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:43.602: INFO: stderr: "+ nslookup nodeport-service.services-738.svc.cluster.local\n"
  Apr 19 14:23:43.602: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-738.svc.cluster.local\tcanonical name = externalsvc.services-738.svc.cluster.local.\nName:\texternalsvc.services-738.svc.cluster.local\nAddress: 10.105.91.0\n\n"
  Apr 19 14:23:43.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-738, will wait for the garbage collector to delete the pods @ 04/19/23 14:23:43.607
  Apr 19 14:23:43.668: INFO: Deleting ReplicationController externalsvc took: 6.529284ms
  Apr 19 14:23:43.769: INFO: Terminating ReplicationController externalsvc pods took: 101.183819ms
  E0419 14:23:44.448541      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:45.449139      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:45.489: INFO: Cleaning up the NodePort to ExternalName test service
  STEP: Destroying namespace "services-738" for this suite. @ 04/19/23 14:23:45.498
• [7.231 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:546
  STEP: Creating a kubernetes client @ 04/19/23 14:23:45.507
  Apr 19 14:23:45.507: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-probe @ 04/19/23 14:23:45.508
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:23:45.519
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:23:45.523
  STEP: Creating pod test-grpc-ce913f72-e469-4f89-aed1-ab3c418e90ec in namespace container-probe-5554 @ 04/19/23 14:23:45.526
  W0419 14:23:45.532680      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:23:46.449227      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:47.449674      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:23:47.541: INFO: Started pod test-grpc-ce913f72-e469-4f89-aed1-ab3c418e90ec in namespace container-probe-5554
  STEP: checking the pod's current state and verifying that restartCount is present @ 04/19/23 14:23:47.541
  Apr 19 14:23:47.545: INFO: Initial restart count of pod test-grpc-ce913f72-e469-4f89-aed1-ab3c418e90ec is 0
  E0419 14:23:48.450660      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:49.450770      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:50.451247      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:51.451584      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:52.451714      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:53.452468      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:54.452535      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:55.452793      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:56.453564      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:57.453682      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:58.453775      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:23:59.453949      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:00.454934      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:01.455279      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:02.455922      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:03.456805      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:04.457721      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:05.458257      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:06.458423      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:07.459445      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:08.459837      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:09.460810      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:10.461342      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:11.461561      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:12.461949      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:13.462473      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:14.462637      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:15.462770      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:16.463590      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:17.464358      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:18.464996      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:19.465812      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:20.466142      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:21.466052      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:22.466144      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:23.466680      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:24.466722      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:25.467002      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:26.467353      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:27.467513      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:28.468254      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:29.468363      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:30.468869      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:31.469015      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:32.469179      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:33.469257      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:34.470292      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:35.470501      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:36.471561      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:37.471967      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:38.472100      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:39.472694      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:40.472763      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:41.472889      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:42.472996      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:43.473581      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:44.473655      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:45.473853      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:46.473872      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:47.473982      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:48.474978      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:49.475099      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:50.475216      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:51.475517      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:52.476456      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:53.476982      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:54.477143      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:55.477270      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:56.478082      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:57.478355      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:58.479012      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:24:59.479847      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:00.480112      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:01.480272      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:25:01.723: INFO: Restart count of pod container-probe-5554/test-grpc-ce913f72-e469-4f89-aed1-ab3c418e90ec is now 1 (1m14.178011948s elapsed)
  Apr 19 14:25:01.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 14:25:01.729
  STEP: Destroying namespace "container-probe-5554" for this suite. @ 04/19/23 14:25:01.739
• [76.239 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
test/e2e/apimachinery/garbage_collector.go:638
  STEP: Creating a kubernetes client @ 04/19/23 14:25:01.747
  Apr 19 14:25:01.747: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename gc @ 04/19/23 14:25:01.748
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:25:01.763
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:25:01.766
  STEP: create the rc @ 04/19/23 14:25:01.775
  W0419 14:25:01.782127      20 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  W0419 14:25:01.782180      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "nginx" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "nginx" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "nginx" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "nginx" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:25:02.480947      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:03.488117      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:04.488327      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:05.490060      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:06.493907      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:07.497444      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: delete the rc @ 04/19/23 14:25:07.823
  STEP: wait for the rc to be deleted @ 04/19/23 14:25:07.832
  E0419 14:25:08.527926      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:25:08.846: INFO: 80 pods remaining
  Apr 19 14:25:08.846: INFO: 80 pods has nil DeletionTimestamp
  Apr 19 14:25:08.846: INFO: 
  E0419 14:25:09.530971      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:25:09.875: INFO: 69 pods remaining
  Apr 19 14:25:09.875: INFO: 69 pods has nil DeletionTimestamp
  Apr 19 14:25:09.875: INFO: 
  E0419 14:25:10.542364      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:25:10.847: INFO: 60 pods remaining
  Apr 19 14:25:10.848: INFO: 60 pods has nil DeletionTimestamp
  Apr 19 14:25:10.848: INFO: 
  E0419 14:25:11.548908      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:25:11.843: INFO: 40 pods remaining
  Apr 19 14:25:11.843: INFO: 40 pods has nil DeletionTimestamp
  Apr 19 14:25:11.843: INFO: 
  E0419 14:25:12.550644      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:25:12.844: INFO: 31 pods remaining
  Apr 19 14:25:12.844: INFO: 30 pods has nil DeletionTimestamp
  Apr 19 14:25:12.844: INFO: 
  E0419 14:25:13.568328      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:25:13.847: INFO: 20 pods remaining
  Apr 19 14:25:13.847: INFO: 20 pods has nil DeletionTimestamp
  Apr 19 14:25:13.847: INFO: 
  E0419 14:25:14.568641      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 04/19/23 14:25:14.838
  Apr 19 14:25:14.887: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Apr 19 14:25:14.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8904" for this suite. @ 04/19/23 14:25:14.893
• [13.151 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:157
  STEP: Creating a kubernetes client @ 04/19/23 14:25:14.898
  Apr 19 14:25:14.898: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 14:25:14.899
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:25:14.911
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:25:14.914
  STEP: Creating a pod to test emptydir volume type on node default medium @ 04/19/23 14:25:14.916
  W0419 14:25:14.923861      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:25:15.568695      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:16.568804      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:17.569809      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:18.570122      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:19.570157      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:20.570312      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:25:20.942
  Apr 19 14:25:20.945: INFO: Trying to get logs from node talos-default-worker-1 pod pod-1e4ff4e0-aab6-48ee-8115-b3df2a1a8592 container test-container: <nil>
  STEP: delete the pod @ 04/19/23 14:25:20.962
  Apr 19 14:25:20.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7096" for this suite. @ 04/19/23 14:25:20.978
• [6.085 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance]
test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 04/19/23 14:25:20.984
  Apr 19 14:25:20.984: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename dns @ 04/19/23 14:25:20.986
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:25:20.996
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:25:21
  STEP: Creating a test headless service @ 04/19/23 14:25:21.003
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2145.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2145.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 04/19/23 14:25:21.008
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2145.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2145.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 04/19/23 14:25:21.008
  STEP: creating a pod to probe DNS @ 04/19/23 14:25:21.008
  STEP: submitting the pod to kubernetes @ 04/19/23 14:25:21.008
  W0419 14:25:21.018123      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:25:21.571143      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:22.572176      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/23 14:25:23.028
  STEP: looking for the results for each expected name from probers @ 04/19/23 14:25:23.032
  Apr 19 14:25:23.047: INFO: DNS probes using dns-2145/dns-test-06e34447-8674-49e6-9fc5-13e5cd2820b6 succeeded

  Apr 19 14:25:23.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 14:25:23.051
  STEP: deleting the test headless service @ 04/19/23 14:25:23.061
  STEP: Destroying namespace "dns-2145" for this suite. @ 04/19/23 14:25:23.071
• [2.092 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 04/19/23 14:25:23.078
  Apr 19 14:25:23.078: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename field-validation @ 04/19/23 14:25:23.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:25:23.091
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:25:23.094
  STEP: apply creating a deployment @ 04/19/23 14:25:23.096
  Apr 19 14:25:23.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5634" for this suite. @ 04/19/23 14:25:23.109
• [0.036 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:528
  STEP: Creating a kubernetes client @ 04/19/23 14:25:23.115
  Apr 19 14:25:23.115: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename security-context-test @ 04/19/23 14:25:23.116
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:25:23.126
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:25:23.129
  W0419 14:25:23.137707      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-privileged-false-1d8ca4c3-24b8-4c2d-809b-602289794e31" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-privileged-false-1d8ca4c3-24b8-4c2d-809b-602289794e31" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-privileged-false-1d8ca4c3-24b8-4c2d-809b-602289794e31" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-privileged-false-1d8ca4c3-24b8-4c2d-809b-602289794e31" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:25:23.573040      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:24.573196      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:25.574094      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:26.574348      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:25:27.157: INFO: Got logs for pod "busybox-privileged-false-1d8ca4c3-24b8-4c2d-809b-602289794e31": "ip: RTNETLINK answers: Operation not permitted\n"
  Apr 19 14:25:27.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-8023" for this suite. @ 04/19/23 14:25:27.162
• [4.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:250
  STEP: Creating a kubernetes client @ 04/19/23 14:25:27.169
  Apr 19 14:25:27.169: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 14:25:27.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:25:27.189
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:25:27.193
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 14:25:27.197
  W0419 14:25:27.206828      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:25:27.575437      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:28.576398      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:29.577198      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:30.577323      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:25:31.22
  Apr 19 14:25:31.224: INFO: Trying to get logs from node talos-default-worker-1 pod downwardapi-volume-e83ae982-3ba6-4873-b4c4-ae12f91bf7d3 container client-container: <nil>
  STEP: delete the pod @ 04/19/23 14:25:31.231
  Apr 19 14:25:31.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5605" for this suite. @ 04/19/23 14:25:31.258
• [4.096 seconds]
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:217
  STEP: Creating a kubernetes client @ 04/19/23 14:25:31.265
  Apr 19 14:25:31.265: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 14:25:31.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:25:31.281
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:25:31.285
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 04/19/23 14:25:31.289
  W0419 14:25:31.297033      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:25:31.578155      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:32.578658      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:33.578693      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:34.578806      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:25:35.31
  Apr 19 14:25:35.314: INFO: Trying to get logs from node talos-default-worker-1 pod pod-a65b34a7-315b-4e91-a7a8-a18404b31928 container test-container: <nil>
  STEP: delete the pod @ 04/19/23 14:25:35.321
  Apr 19 14:25:35.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1180" for this suite. @ 04/19/23 14:25:35.345
• [4.087 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:269
  STEP: Creating a kubernetes client @ 04/19/23 14:25:35.355
  Apr 19 14:25:35.355: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename custom-resource-definition @ 04/19/23 14:25:35.358
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:25:35.37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:25:35.374
  Apr 19 14:25:35.376: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  E0419 14:25:35.579730      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:36.580433      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:37.580596      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:25:38.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9390" for this suite. @ 04/19/23 14:25:38.48
• [3.135 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 04/19/23 14:25:38.491
  Apr 19 14:25:38.491: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename secrets @ 04/19/23 14:25:38.494
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:25:38.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:25:38.518
  STEP: Creating secret with name s-test-opt-del-dc9b4465-5df4-431c-9df8-f1fbfadb1328 @ 04/19/23 14:25:38.527
  STEP: Creating secret with name s-test-opt-upd-c843f0d8-9173-4583-81de-5e9b7b6c92b5 @ 04/19/23 14:25:38.533
  STEP: Creating the pod @ 04/19/23 14:25:38.538
  W0419 14:25:38.546939      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "dels-volume-test", "upds-volume-test", "creates-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:25:38.580946      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:39.581089      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-dc9b4465-5df4-431c-9df8-f1fbfadb1328 @ 04/19/23 14:25:40.569
  STEP: Updating secret s-test-opt-upd-c843f0d8-9173-4583-81de-5e9b7b6c92b5 @ 04/19/23 14:25:40.573
  STEP: Creating secret with name s-test-opt-create-71651d54-5b41-48ab-aa93-f8ccb7e38a95 @ 04/19/23 14:25:40.577
  E0419 14:25:40.581715      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: waiting to observe update in volume @ 04/19/23 14:25:40.581
  E0419 14:25:41.581930      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:42.582091      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:43.583110      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:44.583316      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:45.583478      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:46.583599      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:47.583725      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:48.583782      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:49.583913      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:50.584547      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:51.584952      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:52.585080      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:53.585323      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:54.585622      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:55.585770      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:56.586092      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:57.586746      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:58.587677      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:25:59.588631      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:00.588920      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:01.589390      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:02.589716      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:03.590787      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:04.591063      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:05.591418      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:06.591538      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:07.592119      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:08.592276      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:09.593326      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:10.593547      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:11.593670      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:12.593850      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:13.594035      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:14.594148      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:15.594206      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:16.594479      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:17.594609      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:18.595510      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:19.595752      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:20.596165      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:21.596189      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:22.596486      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:23.597404      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:24.597630      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:25.597837      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:26.597916      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:27.598072      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:28.598189      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:29.598341      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:30.598450      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:31.598563      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:32.598797      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:33.598931      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:34.599032      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:35.599179      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:36.599252      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:37.599397      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:38.599550      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:39.599657      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:40.600168      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:41.601197      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:42.601497      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:43.602064      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:44.602307      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:45.603108      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:46.603454      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:47.603564      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:48.604136      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:49.604776      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:50.604898      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:51.605057      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:52.605626      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:53.605862      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:54.605908      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:55.606855      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:56.606983      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:57.607124      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:58.607561      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:26:59.607748      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:00.608034      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:01.608119      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:02.608540      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:03.608616      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:04.609060      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:05.609829      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:06.610117      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:07.610222      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:08.610517      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:09.610671      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:10.611318      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:11.611419      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:12.611519      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:27:13.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3351" for this suite. @ 04/19/23 14:27:13.048
• [94.566 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs  [Conformance]
test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 04/19/23 14:27:13.06
  Apr 19 14:27:13.060: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl-logs @ 04/19/23 14:27:13.063
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:27:13.078
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:27:13.08
  STEP: creating an pod @ 04/19/23 14:27:13.083
  Apr 19 14:27:13.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-logs-3059 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.43 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  Apr 19 14:27:13.161: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"logs-generator\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"logs-generator\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"logs-generator\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"logs-generator\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 14:27:13.161: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 04/19/23 14:27:13.162
  Apr 19 14:27:13.162: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0419 14:27:13.611525      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:14.611756      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:27:15.171: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 04/19/23 14:27:15.171
  Apr 19 14:27:15.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-logs-3059 logs logs-generator logs-generator'
  Apr 19 14:27:15.265: INFO: stderr: ""
  Apr 19 14:27:15.265: INFO: stdout: "I0419 14:27:13.793860       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/m962 569\nI0419 14:27:13.994548       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/zmwb 324\nI0419 14:27:14.194850       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/qv8d 505\nI0419 14:27:14.393969       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/4x8k 486\nI0419 14:27:14.594343       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/x7hc 549\nI0419 14:27:14.794668       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/m75 390\nI0419 14:27:14.994949       1 logs_generator.go:76] 6 POST /api/v1/namespaces/default/pods/xrl 507\nI0419 14:27:15.200524       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/lnzf 402\n"
  STEP: limiting log lines @ 04/19/23 14:27:15.265
  Apr 19 14:27:15.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-logs-3059 logs logs-generator logs-generator --tail=1'
  Apr 19 14:27:15.335: INFO: stderr: ""
  Apr 19 14:27:15.335: INFO: stdout: "I0419 14:27:15.200524       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/lnzf 402\n"
  Apr 19 14:27:15.335: INFO: got output "I0419 14:27:15.200524       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/lnzf 402\n"
  STEP: limiting log bytes @ 04/19/23 14:27:15.335
  Apr 19 14:27:15.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-logs-3059 logs logs-generator logs-generator --limit-bytes=1'
  Apr 19 14:27:15.394: INFO: stderr: ""
  Apr 19 14:27:15.394: INFO: stdout: "I"
  Apr 19 14:27:15.394: INFO: got output "I"
  STEP: exposing timestamps @ 04/19/23 14:27:15.394
  Apr 19 14:27:15.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-logs-3059 logs logs-generator logs-generator --tail=1 --timestamps'
  Apr 19 14:27:15.456: INFO: stderr: ""
  Apr 19 14:27:15.456: INFO: stdout: "2023-04-19T14:27:15.394083382Z I0419 14:27:15.393978       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/5nt 263\n"
  Apr 19 14:27:15.456: INFO: got output "2023-04-19T14:27:15.394083382Z I0419 14:27:15.393978       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/5nt 263\n"
  STEP: restricting to a time range @ 04/19/23 14:27:15.456
  E0419 14:27:15.612202      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:16.612333      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:17.612443      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:27:17.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-logs-3059 logs logs-generator logs-generator --since=1s'
  Apr 19 14:27:18.057: INFO: stderr: ""
  Apr 19 14:27:18.057: INFO: stdout: "I0419 14:27:17.194230       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/qgd 322\nI0419 14:27:17.394622       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/h4wz 406\nI0419 14:27:17.593894       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/dwtt 377\nI0419 14:27:17.794239       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/cg5b 430\nI0419 14:27:17.994538       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/nk9m 401\n"
  Apr 19 14:27:18.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-logs-3059 logs logs-generator logs-generator --since=24h'
  Apr 19 14:27:18.139: INFO: stderr: ""
  Apr 19 14:27:18.139: INFO: stdout: "I0419 14:27:13.793860       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/m962 569\nI0419 14:27:13.994548       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/zmwb 324\nI0419 14:27:14.194850       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/qv8d 505\nI0419 14:27:14.393969       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/4x8k 486\nI0419 14:27:14.594343       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/x7hc 549\nI0419 14:27:14.794668       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/m75 390\nI0419 14:27:14.994949       1 logs_generator.go:76] 6 POST /api/v1/namespaces/default/pods/xrl 507\nI0419 14:27:15.200524       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/lnzf 402\nI0419 14:27:15.393978       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/5nt 263\nI0419 14:27:15.594522       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/zbt 531\nI0419 14:27:15.794927       1 logs_generator.go:76] 10 POST /api/v1/namespaces/kube-system/pods/jdp 383\nI0419 14:27:15.994245       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/j6cg 200\nI0419 14:27:16.194579       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/f5vg 308\nI0419 14:27:16.394928       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/ptf6 350\nI0419 14:27:16.594236       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/8xzz 458\nI0419 14:27:16.794572       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/s22 245\nI0419 14:27:16.994880       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/6t9 486\nI0419 14:27:17.194230       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/qgd 322\nI0419 14:27:17.394622       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/h4wz 406\nI0419 14:27:17.593894       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/dwtt 377\nI0419 14:27:17.794239       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/cg5b 430\nI0419 14:27:17.994538       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/nk9m 401\n"
  Apr 19 14:27:18.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-logs-3059 delete pod logs-generator'
  E0419 14:27:18.613104      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:27:19.319: INFO: stderr: ""
  Apr 19 14:27:19.319: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Apr 19 14:27:19.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-3059" for this suite. @ 04/19/23 14:27:19.324
• [6.271 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 04/19/23 14:27:19.338
  Apr 19 14:27:19.338: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename secrets @ 04/19/23 14:27:19.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:27:19.355
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:27:19.359
  STEP: Creating secret with name secret-test-f9b10f41-c15a-4c58-b247-87e3de6eb3f8 @ 04/19/23 14:27:19.362
  STEP: Creating a pod to test consume secrets @ 04/19/23 14:27:19.367
  W0419 14:27:19.379202      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "secret-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "secret-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "secret-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "secret-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:27:19.613233      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:20.613537      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:21.614602      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:22.614831      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:27:23.391
  Apr 19 14:27:23.393: INFO: Trying to get logs from node talos-default-worker-1 pod pod-secrets-b986d5f6-02fc-4291-be96-ee3a0ec19091 container secret-volume-test: <nil>
  STEP: delete the pod @ 04/19/23 14:27:23.397
  Apr 19 14:27:23.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2169" for this suite. @ 04/19/23 14:27:23.417
• [4.085 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]
test/e2e/kubectl/kubectl.go:830
  STEP: Creating a kubernetes client @ 04/19/23 14:27:23.423
  Apr 19 14:27:23.423: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 14:27:23.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:27:23.435
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:27:23.438
  STEP: validating api versions @ 04/19/23 14:27:23.44
  Apr 19 14:27:23.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6584 api-versions'
  Apr 19 14:27:23.491: INFO: stderr: ""
  Apr 19 14:27:23.491: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta2\nflowcontrol.apiserver.k8s.io/v1beta3\nmygroup.example.com/v1\nmygroup.example.com/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Apr 19 14:27:23.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6584" for this suite. @ 04/19/23 14:27:23.495
• [0.076 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:174
  STEP: Creating a kubernetes client @ 04/19/23 14:27:23.5
  Apr 19 14:27:23.500: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 14:27:23.5
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:27:23.511
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:27:23.513
  STEP: Creating configMap with name cm-test-opt-del-25776419-358c-4db3-9a55-defa6e5c62cb @ 04/19/23 14:27:23.519
  STEP: Creating configMap with name cm-test-opt-upd-a21a7f7e-7fce-416e-9466-d9c0453f4ed9 @ 04/19/23 14:27:23.522
  STEP: Creating the pod @ 04/19/23 14:27:23.526
  W0419 14:27:23.537266      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "delcm-volume-test", "updcm-volume-test", "createcm-volume-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:27:23.615156      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:24.615281      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-25776419-358c-4db3-9a55-defa6e5c62cb @ 04/19/23 14:27:25.567
  STEP: Updating configmap cm-test-opt-upd-a21a7f7e-7fce-416e-9466-d9c0453f4ed9 @ 04/19/23 14:27:25.573
  STEP: Creating configMap with name cm-test-opt-create-5790eb56-038b-4617-9c09-92ad71ce4aab @ 04/19/23 14:27:25.578
  STEP: waiting to observe update in volume @ 04/19/23 14:27:25.583
  E0419 14:27:25.615712      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:26.616256      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:27.616632      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:28.617073      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:29.617851      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:30.618120      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:31.618410      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:32.619564      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:33.620375      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:34.621142      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:35.621311      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:36.621398      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:37.622100      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:38.622208      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:39.622512      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:40.622618      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:41.622781      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:42.622817      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:43.623393      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:44.623535      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:45.623742      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:46.623866      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:47.624273      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:48.625359      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:49.625519      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:50.625652      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:51.626059      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:52.626161      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:53.626229      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:54.626317      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:55.626441      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:56.626901      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:57.627266      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:58.627378      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:27:59.627812      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:00.628150      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:01.628299      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:02.628362      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:03.628538      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:04.629440      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:05.629575      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:06.629710      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:07.629846      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:08.629970      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:09.630085      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:10.631056      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:11.631219      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:12.631770      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:13.631874      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:14.632016      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:15.632694      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:16.633062      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:17.633178      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:18.633270      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:19.633769      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:20.634036      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:21.634695      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:22.635633      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:23.635756      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:24.636339      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:25.636566      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:26.637026      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:27.637312      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:28.637419      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:29.637710      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:30.637873      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:31.637935      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:32.638035      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:33.638643      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:34.639608      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:35.639850      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:36.639947      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:37.640259      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:38.641232      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:39.641697      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:28:39.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9804" for this suite. @ 04/19/23 14:28:39.957
• [76.465 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:194
  STEP: Creating a kubernetes client @ 04/19/23 14:28:39.968
  Apr 19 14:28:39.968: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename projected @ 04/19/23 14:28:39.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:28:39.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:28:39.99
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 14:28:39.993
  W0419 14:28:40.001364      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:28:40.641943      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:41.642452      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:42.642500      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:43.642667      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:28:44.016
  Apr 19 14:28:44.019: INFO: Trying to get logs from node talos-default-worker-2 pod downwardapi-volume-e539b812-7c8b-4dea-bb05-bbcd7037aa7a container client-container: <nil>
  STEP: delete the pod @ 04/19/23 14:28:44.026
  Apr 19 14:28:44.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2189" for this suite. @ 04/19/23 14:28:44.049
• [4.089 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]
test/e2e/scheduling/predicates.go:332
  STEP: Creating a kubernetes client @ 04/19/23 14:28:44.059
  Apr 19 14:28:44.059: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename sched-pred @ 04/19/23 14:28:44.063
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:28:44.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:28:44.079
  Apr 19 14:28:44.081: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Apr 19 14:28:44.088: INFO: Waiting for terminating namespaces to be deleted...
  Apr 19 14:28:44.091: INFO: 
  Logging pods the apiserver thinks is on node talos-default-worker-1 before test
  Apr 19 14:28:44.095: INFO: kube-flannel-xtc62 from kube-system started at 2023-04-18 19:32:12 +0000 UTC (1 container statuses recorded)
  Apr 19 14:28:44.095: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 19 14:28:44.095: INFO: kube-proxy-j7zxh from kube-system started at 2023-04-18 19:32:12 +0000 UTC (1 container statuses recorded)
  Apr 19 14:28:44.095: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 19 14:28:44.095: INFO: pod-projected-configmaps-4fa1d336-4f93-435a-861b-89a48737a9be from projected-9804 started at 2023-04-19 14:27:23 +0000 UTC (3 container statuses recorded)
  Apr 19 14:28:44.095: INFO: 	Container createcm-volume-test ready: true, restart count 0
  Apr 19 14:28:44.095: INFO: 	Container delcm-volume-test ready: true, restart count 0
  Apr 19 14:28:44.095: INFO: 	Container updcm-volume-test ready: true, restart count 0
  Apr 19 14:28:44.095: INFO: sonobuoy from sonobuoy started at 2023-04-19 12:53:21 +0000 UTC (1 container statuses recorded)
  Apr 19 14:28:44.095: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Apr 19 14:28:44.095: INFO: 
  Logging pods the apiserver thinks is on node talos-default-worker-2 before test
  Apr 19 14:28:44.100: INFO: coredns-d779cc7ff-z6svh from kube-system started at 2023-04-18 19:38:29 +0000 UTC (1 container statuses recorded)
  Apr 19 14:28:44.101: INFO: 	Container coredns ready: true, restart count 0
  Apr 19 14:28:44.101: INFO: kube-flannel-xntjw from kube-system started at 2023-04-18 19:32:33 +0000 UTC (1 container statuses recorded)
  Apr 19 14:28:44.101: INFO: 	Container kube-flannel ready: true, restart count 0
  Apr 19 14:28:44.101: INFO: kube-proxy-qxzd4 from kube-system started at 2023-04-18 19:32:33 +0000 UTC (1 container statuses recorded)
  Apr 19 14:28:44.101: INFO: 	Container kube-proxy ready: true, restart count 0
  Apr 19 14:28:44.101: INFO: sonobuoy-e2e-job-9b851c216c1a4329 from sonobuoy started at 2023-04-19 12:53:22 +0000 UTC (2 container statuses recorded)
  Apr 19 14:28:44.101: INFO: 	Container e2e ready: true, restart count 0
  Apr 19 14:28:44.101: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  STEP: verifying the node has the label node talos-default-worker-1 @ 04/19/23 14:28:44.116
  STEP: verifying the node has the label node talos-default-worker-2 @ 04/19/23 14:28:44.124
  Apr 19 14:28:44.135: INFO: Pod coredns-d779cc7ff-z6svh requesting resource cpu=100m on Node talos-default-worker-2
  Apr 19 14:28:44.137: INFO: Pod kube-flannel-xntjw requesting resource cpu=100m on Node talos-default-worker-2
  Apr 19 14:28:44.138: INFO: Pod kube-flannel-xtc62 requesting resource cpu=100m on Node talos-default-worker-1
  Apr 19 14:28:44.139: INFO: Pod kube-proxy-j7zxh requesting resource cpu=0m on Node talos-default-worker-1
  Apr 19 14:28:44.140: INFO: Pod kube-proxy-qxzd4 requesting resource cpu=0m on Node talos-default-worker-2
  Apr 19 14:28:44.142: INFO: Pod pod-projected-configmaps-4fa1d336-4f93-435a-861b-89a48737a9be requesting resource cpu=0m on Node talos-default-worker-1
  Apr 19 14:28:44.143: INFO: Pod sonobuoy requesting resource cpu=0m on Node talos-default-worker-1
  Apr 19 14:28:44.143: INFO: Pod sonobuoy-e2e-job-9b851c216c1a4329 requesting resource cpu=0m on Node talos-default-worker-2
  STEP: Starting Pods to consume most of the cluster CPU. @ 04/19/23 14:28:44.144
  Apr 19 14:28:44.145: INFO: Creating a pod which consumes cpu=1295m on Node talos-default-worker-1
  Apr 19 14:28:44.153: INFO: Creating a pod which consumes cpu=1225m on Node talos-default-worker-2
  E0419 14:28:44.643850      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:45.644113      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 04/19/23 14:28:46.172
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-4f284b87-7394-48c9-8d5e-738916199763.17575c593ad16ca8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5609/filler-pod-4f284b87-7394-48c9-8d5e-738916199763 to talos-default-worker-1] @ 04/19/23 14:28:46.177
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-4f284b87-7394-48c9-8d5e-738916199763.17575c5958b9e3de], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/19/23 14:28:46.177
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-4f284b87-7394-48c9-8d5e-738916199763.17575c59596b8ee3], Reason = [Created], Message = [Created container filler-pod-4f284b87-7394-48c9-8d5e-738916199763] @ 04/19/23 14:28:46.177
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-4f284b87-7394-48c9-8d5e-738916199763.17575c595ffab467], Reason = [Started], Message = [Started container filler-pod-4f284b87-7394-48c9-8d5e-738916199763] @ 04/19/23 14:28:46.177
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-dd0c7102-522e-4a1c-ba8d-e5da7a1fe8fc.17575c593b4a4495], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5609/filler-pod-dd0c7102-522e-4a1c-ba8d-e5da7a1fe8fc to talos-default-worker-2] @ 04/19/23 14:28:46.177
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-dd0c7102-522e-4a1c-ba8d-e5da7a1fe8fc.17575c59595deb84], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 04/19/23 14:28:46.177
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-dd0c7102-522e-4a1c-ba8d-e5da7a1fe8fc.17575c5959c9a392], Reason = [Created], Message = [Created container filler-pod-dd0c7102-522e-4a1c-ba8d-e5da7a1fe8fc] @ 04/19/23 14:28:46.177
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-dd0c7102-522e-4a1c-ba8d-e5da7a1fe8fc.17575c595fe41c81], Reason = [Started], Message = [Started container filler-pod-dd0c7102-522e-4a1c-ba8d-e5da7a1fe8fc] @ 04/19/23 14:28:46.177
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.17575c59b3ac6dbf], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 Insufficient cpu, 3 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }. preemption: 0/5 nodes are available: 2 No preemption victims found for incoming pod, 3 Preemption is not helpful for scheduling..] @ 04/19/23 14:28:46.189
  E0419 14:28:46.644863      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: removing the label node off the node talos-default-worker-1 @ 04/19/23 14:28:47.188
  STEP: verifying the node doesn't have the label node @ 04/19/23 14:28:47.205
  STEP: removing the label node off the node talos-default-worker-2 @ 04/19/23 14:28:47.209
  STEP: verifying the node doesn't have the label node @ 04/19/23 14:28:47.232
  Apr 19 14:28:47.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-5609" for this suite. @ 04/19/23 14:28:47.247
• [3.197 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]
test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 04/19/23 14:28:47.273
  Apr 19 14:28:47.274: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 14:28:47.278
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:28:47.296
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:28:47.299
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-3094 @ 04/19/23 14:28:47.302
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 04/19/23 14:28:47.312
  STEP: creating service externalsvc in namespace services-3094 @ 04/19/23 14:28:47.314
  STEP: creating replication controller externalsvc in namespace services-3094 @ 04/19/23 14:28:47.325
  W0419 14:28:47.331503      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "externalsvc" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "externalsvc" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "externalsvc" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "externalsvc" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  I0419 14:28:47.331600      20 runners.go:194] Created replication controller with name: externalsvc, namespace: services-3094, replica count: 2
  E0419 14:28:47.645415      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:48.646330      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:49.646640      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0419 14:28:50.382111      20 runners.go:194] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 04/19/23 14:28:50.386
  Apr 19 14:28:50.404: INFO: Creating new exec pod
  W0419 14:28:50.416397      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:28:50.646989      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:51.647248      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:28:52.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-3094 exec execpodl8j4q -- /bin/sh -x -c nslookup clusterip-service.services-3094.svc.cluster.local'
  E0419 14:28:52.652038      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:28:52.655: INFO: stderr: "+ nslookup clusterip-service.services-3094.svc.cluster.local\n"
  Apr 19 14:28:52.655: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-3094.svc.cluster.local\tcanonical name = externalsvc.services-3094.svc.cluster.local.\nName:\texternalsvc.services-3094.svc.cluster.local\nAddress: 10.96.142.114\n\n"
  Apr 19 14:28:52.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-3094, will wait for the garbage collector to delete the pods @ 04/19/23 14:28:52.659
  Apr 19 14:28:52.717: INFO: Deleting ReplicationController externalsvc took: 5.056274ms
  Apr 19 14:28:52.818: INFO: Terminating ReplicationController externalsvc pods took: 100.814374ms
  E0419 14:28:53.652932      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:54.654036      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:28:54.945: INFO: Cleaning up the ClusterIP to ExternalName test service
  STEP: Destroying namespace "services-3094" for this suite. @ 04/19/23 14:28:54.959
• [7.694 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:104
  STEP: Creating a kubernetes client @ 04/19/23 14:28:54.972
  Apr 19 14:28:54.972: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename runtimeclass @ 04/19/23 14:28:54.974
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:28:54.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:28:54.99
  W0419 14:28:55.003526      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:28:55.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4864" for this suite. @ 04/19/23 14:28:55.018
• [0.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]
test/e2e/kubectl/kubectl.go:1315
  STEP: Creating a kubernetes client @ 04/19/23 14:28:55.026
  Apr 19 14:28:55.026: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 14:28:55.027
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:28:55.039
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:28:55.042
  STEP: validating cluster-info @ 04/19/23 14:28:55.044
  Apr 19 14:28:55.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6249 cluster-info'
  Apr 19 14:28:55.096: INFO: stderr: ""
  Apr 19 14:28:55.097: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Apr 19 14:28:55.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6249" for this suite. @ 04/19/23 14:28:55.1
• [0.079 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 04/19/23 14:28:55.107
  Apr 19 14:28:55.107: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename crd-publish-openapi @ 04/19/23 14:28:55.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:28:55.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:28:55.124
  STEP: set up a multi version CRD @ 04/19/23 14:28:55.126
  Apr 19 14:28:55.127: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  E0419 14:28:55.654524      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:56.654509      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:57.654941      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:28:58.655280      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 04/19/23 14:28:59.219
  STEP: check the unserved version gets removed @ 04/19/23 14:28:59.238
  E0419 14:28:59.655373      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:00.655983      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 04/19/23 14:29:01.086
  E0419 14:29:01.656162      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:02.656904      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:03.657409      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:29:03.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3767" for this suite. @ 04/19/23 14:29:03.924
• [8.822 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:135
  STEP: Creating a kubernetes client @ 04/19/23 14:29:03.931
  Apr 19 14:29:03.931: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/19/23 14:29:03.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:29:03.943
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:29:03.946
  STEP: create the container to handle the HTTPGet hook request. @ 04/19/23 14:29:03.952
  W0419 14:29:03.964728      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "container-handle-http-request", "container-handle-https-request" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "container-handle-http-request", "container-handle-https-request" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "container-handle-http-request", "container-handle-https-request" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "container-handle-http-request", "container-handle-https-request" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:29:04.657516      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:05.657609      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/19/23 14:29:05.975
  W0419 14:29:05.986056      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-with-poststart-exec-hook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-with-poststart-exec-hook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-with-poststart-exec-hook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-with-poststart-exec-hook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:29:06.657716      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:07.657965      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 04/19/23 14:29:07.998
  STEP: delete the pod with lifecycle hook @ 04/19/23 14:29:08.011
  E0419 14:29:08.658777      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:09.659273      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:29:10.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-1198" for this suite. @ 04/19/23 14:29:10.026
• [6.100 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]
test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 04/19/23 14:29:10.031
  Apr 19 14:29:10.031: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename dns @ 04/19/23 14:29:10.033
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:29:10.041
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:29:10.045
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3916.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3916.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 04/19/23 14:29:10.047
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3916.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3916.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 04/19/23 14:29:10.047
  STEP: creating a pod to probe /etc/hosts @ 04/19/23 14:29:10.047
  STEP: submitting the pod to kubernetes @ 04/19/23 14:29:10.047
  W0419 14:29:10.059154      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:29:10.659398      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:11.659492      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/23 14:29:12.067
  STEP: looking for the results for each expected name from probers @ 04/19/23 14:29:12.071
  Apr 19 14:29:12.086: INFO: DNS probes using dns-3916/dns-test-cadbf209-edbc-4ea5-b396-610e69ccc34f succeeded

  Apr 19 14:29:12.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 14:29:12.092
  STEP: Destroying namespace "dns-3916" for this suite. @ 04/19/23 14:29:12.101
• [2.077 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:250
  STEP: Creating a kubernetes client @ 04/19/23 14:29:12.112
  Apr 19 14:29:12.112: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename downward-api @ 04/19/23 14:29:12.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:29:12.128
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:29:12.132
  STEP: Creating a pod to test downward API volume plugin @ 04/19/23 14:29:12.136
  W0419 14:29:12.143745      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "client-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "client-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "client-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "client-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:29:12.659654      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:13.659785      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:29:14.152
  Apr 19 14:29:14.155: INFO: Trying to get logs from node talos-default-worker-1 pod downwardapi-volume-99b3ab02-89e7-491f-84ed-078f169b70b2 container client-container: <nil>
  STEP: delete the pod @ 04/19/23 14:29:14.169
  Apr 19 14:29:14.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9262" for this suite. @ 04/19/23 14:29:14.188
• [2.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]
test/e2e/common/storage/empty_dir.go:227
  STEP: Creating a kubernetes client @ 04/19/23 14:29:14.197
  Apr 19 14:29:14.197: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename emptydir @ 04/19/23 14:29:14.199
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:29:14.214
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:29:14.218
  STEP: Creating Pod @ 04/19/23 14:29:14.221
  W0419 14:29:14.229470      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "busybox-main-container", "busybox-sub-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "busybox-main-container", "busybox-sub-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "busybox-main-container", "busybox-sub-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "busybox-main-container", "busybox-sub-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:29:14.660439      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:15.660597      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 04/19/23 14:29:16.237
  Apr 19 14:29:16.237: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7586 PodName:pod-sharedvolume-8cac4917-ed14-47db-bfd0-8c0ebdda57d2 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Apr 19 14:29:16.237: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  Apr 19 14:29:16.238: INFO: ExecWithOptions: Clientset creation
  Apr 19 14:29:16.238: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-7586/pods/pod-sharedvolume-8cac4917-ed14-47db-bfd0-8c0ebdda57d2/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  Apr 19 14:29:16.373: INFO: Exec stderr: ""
  Apr 19 14:29:16.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7586" for this suite. @ 04/19/23 14:29:16.38
• [2.187 seconds]
------------------------------
[sig-apps] Job should delete a job [Conformance]
test/e2e/apps/job.go:485
  STEP: Creating a kubernetes client @ 04/19/23 14:29:16.386
  Apr 19 14:29:16.386: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename job @ 04/19/23 14:29:16.389
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:29:16.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:29:16.402
  STEP: Creating a job @ 04/19/23 14:29:16.406
  W0419 14:29:16.417701      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "c" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "c" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "c" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "c" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Ensuring active pods == parallelism @ 04/19/23 14:29:16.417
  E0419 14:29:16.661164      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:17.661267      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: delete a job @ 04/19/23 14:29:18.422
  STEP: deleting Job.batch foo in namespace job-8649, will wait for the garbage collector to delete the pods @ 04/19/23 14:29:18.422
  Apr 19 14:29:18.482: INFO: Deleting Job.batch foo took: 5.92138ms
  Apr 19 14:29:18.583: INFO: Terminating Job.batch foo pods took: 100.938015ms
  E0419 14:29:18.661298      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:19.661897      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:20.662965      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:21.663122      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:22.663781      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:23.664346      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:24.664451      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:25.665300      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:26.666416      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:27.667380      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:28.668391      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:29.669086      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:30.669893      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:31.670416      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:32.671219      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:33.671561      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:34.672460      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:35.673398      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:36.673495      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:37.674318      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:38.675414      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:39.676297      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:40.676684      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:41.676770      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:42.677701      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:43.677784      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:44.678766      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:45.678830      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:46.679872      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:47.680156      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:48.680767      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:49.680801      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 04/19/23 14:29:49.983
  Apr 19 14:29:49.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8649" for this suite. @ 04/19/23 14:29:49.992
• [33.613 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]
test/e2e/apps/daemon_set.go:825
  STEP: Creating a kubernetes client @ 04/19/23 14:29:50.001
  Apr 19 14:29:50.002: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename daemonsets @ 04/19/23 14:29:50.003
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:29:50.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:29:50.019
  STEP: Creating simple DaemonSet "daemon-set" @ 04/19/23 14:29:50.035
  W0419 14:29:50.040398      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "app" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "app" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "app" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "app" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Check that daemon pods launch on every node of the cluster. @ 04/19/23 14:29:50.04
  Apr 19 14:29:50.045: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:29:50.045: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:29:50.046: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:29:50.050: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Apr 19 14:29:50.050: INFO: Node talos-default-worker-1 is running 0 daemon pod, expected 1
  E0419 14:29:50.682304      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:29:51.055: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:29:51.055: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:29:51.055: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:29:51.059: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Apr 19 14:29:51.059: INFO: Node talos-default-worker-2 is running 0 daemon pod, expected 1
  E0419 14:29:51.683211      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:29:52.054: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-1 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:29:52.057: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-2 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:29:52.060: INFO: DaemonSet pods can't tolerate node talos-default-controlplane-3 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Apr 19 14:29:52.065: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Apr 19 14:29:52.066: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: listing all DaemonSets @ 04/19/23 14:29:52.071
  STEP: DeleteCollection of the DaemonSets @ 04/19/23 14:29:52.074
  STEP: Verify that ReplicaSets have been deleted @ 04/19/23 14:29:52.081
  Apr 19 14:29:52.091: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"214323"},"items":null}

  Apr 19 14:29:52.096: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"214323"},"items":[{"metadata":{"name":"daemon-set-dl5sn","generateName":"daemon-set-","namespace":"daemonsets-3293","uid":"fdafd09c-2d6c-4fe6-9ef2-cbf04a4f8325","resourceVersion":"214319","creationTimestamp":"2023-04-19T14:29:50Z","labels":{"controller-revision-hash":"6974d7cff5","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"1646dafc-3134-4f2a-92d0-963d13950b9a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-19T14:29:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1646dafc-3134-4f2a-92d0-963d13950b9a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-19T14:29:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.1.56\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-xmq8h","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-xmq8h","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"talos-default-worker-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["talos-default-worker-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-19T14:29:50Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-19T14:29:51Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-19T14:29:51Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-19T14:29:50Z"}],"hostIP":"172.20.0.6","podIP":"10.244.1.56","podIPs":[{"ip":"10.244.1.56"}],"startTime":"2023-04-19T14:29:50Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-19T14:29:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://1ed9d11f61a05d8b71e9f7d77bb5edade025a3295a67bf971351d60783fab851","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-fxcgd","generateName":"daemon-set-","namespace":"daemonsets-3293","uid":"d9b4c7d2-e74a-43e0-ba6c-ad340a9d7f83","resourceVersion":"214316","creationTimestamp":"2023-04-19T14:29:50Z","labels":{"controller-revision-hash":"6974d7cff5","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"1646dafc-3134-4f2a-92d0-963d13950b9a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-19T14:29:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1646dafc-3134-4f2a-92d0-963d13950b9a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-19T14:29:50Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.3.196\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-64gmh","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-64gmh","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"talos-default-worker-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["talos-default-worker-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-19T14:29:50Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-19T14:29:50Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-19T14:29:50Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-19T14:29:50Z"}],"hostIP":"172.20.0.5","podIP":"10.244.3.196","podIPs":[{"ip":"10.244.3.196"}],"startTime":"2023-04-19T14:29:50Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-19T14:29:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://e3ab971d244f164816d953462aa097d26b4729345c776475ce8d7d1a59d5abc8","started":true}],"qosClass":"BestEffort"}}]}

  Apr 19 14:29:52.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-3293" for this suite. @ 04/19/23 14:29:52.107
• [2.111 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 04/19/23 14:29:52.113
  Apr 19 14:29:52.113: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/23 14:29:52.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:29:52.124
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:29:52.126
  W0419 14:29:52.135029      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "busybox-scheduling-1d755c4f-9661-4fe5-8a59-37213fcfb7c9" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "busybox-scheduling-1d755c4f-9661-4fe5-8a59-37213fcfb7c9" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "busybox-scheduling-1d755c4f-9661-4fe5-8a59-37213fcfb7c9" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "busybox-scheduling-1d755c4f-9661-4fe5-8a59-37213fcfb7c9" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:29:52.684303      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:53.685059      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:29:54.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6839" for this suite. @ 04/19/23 14:29:54.153
• [2.045 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]
test/e2e/kubectl/kubectl.go:996
  STEP: Creating a kubernetes client @ 04/19/23 14:29:54.159
  Apr 19 14:29:54.159: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 14:29:54.159
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:29:54.169
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:29:54.173
  STEP: create deployment with httpd image @ 04/19/23 14:29:54.177
  Apr 19 14:29:54.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-9075 create -f -'
  Apr 19 14:29:54.434: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"httpd\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"httpd\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"httpd\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"httpd\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 14:29:54.434: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 04/19/23 14:29:54.434
  Apr 19 14:29:54.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-9075 diff -f -'
  Apr 19 14:29:54.611: INFO: rc: 1
  Apr 19 14:29:54.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-9075 delete -f -'
  Apr 19 14:29:54.672: INFO: stderr: ""
  Apr 19 14:29:54.672: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Apr 19 14:29:54.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9075" for this suite. @ 04/19/23 14:29:54.677
• [0.524 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]
test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 04/19/23 14:29:54.684
  Apr 19 14:29:54.684: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename dns @ 04/19/23 14:29:54.685
  E0419 14:29:54.685945      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:29:54.693
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:29:54.696
  STEP: Creating a test headless service @ 04/19/23 14:29:54.698
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6216.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-6216.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6216.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-6216.svc.cluster.local;sleep 1; done
   @ 04/19/23 14:29:54.702
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6216.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-6216.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6216.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-6216.svc.cluster.local;sleep 1; done
   @ 04/19/23 14:29:54.702
  STEP: creating a pod to probe DNS @ 04/19/23 14:29:54.703
  STEP: submitting the pod to kubernetes @ 04/19/23 14:29:54.703
  W0419 14:29:54.709790      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "webserver", "querier", "jessie-querier" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "webserver", "querier", "jessie-querier" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "webserver", "querier", "jessie-querier" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:29:55.686151      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:56.686263      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 04/19/23 14:29:56.717
  STEP: looking for the results for each expected name from probers @ 04/19/23 14:29:56.721
  Apr 19 14:29:56.726: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local from pod dns-6216/dns-test-73668abd-c23e-4d96-906b-3d0a63a64950: the server could not find the requested resource (get pods dns-test-73668abd-c23e-4d96-906b-3d0a63a64950)
  Apr 19 14:29:56.730: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local from pod dns-6216/dns-test-73668abd-c23e-4d96-906b-3d0a63a64950: the server could not find the requested resource (get pods dns-test-73668abd-c23e-4d96-906b-3d0a63a64950)
  Apr 19 14:29:56.734: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6216.svc.cluster.local from pod dns-6216/dns-test-73668abd-c23e-4d96-906b-3d0a63a64950: the server could not find the requested resource (get pods dns-test-73668abd-c23e-4d96-906b-3d0a63a64950)
  Apr 19 14:29:56.739: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6216.svc.cluster.local from pod dns-6216/dns-test-73668abd-c23e-4d96-906b-3d0a63a64950: the server could not find the requested resource (get pods dns-test-73668abd-c23e-4d96-906b-3d0a63a64950)
  Apr 19 14:29:56.743: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local from pod dns-6216/dns-test-73668abd-c23e-4d96-906b-3d0a63a64950: the server could not find the requested resource (get pods dns-test-73668abd-c23e-4d96-906b-3d0a63a64950)
  Apr 19 14:29:56.747: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local from pod dns-6216/dns-test-73668abd-c23e-4d96-906b-3d0a63a64950: the server could not find the requested resource (get pods dns-test-73668abd-c23e-4d96-906b-3d0a63a64950)
  Apr 19 14:29:56.751: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6216.svc.cluster.local from pod dns-6216/dns-test-73668abd-c23e-4d96-906b-3d0a63a64950: the server could not find the requested resource (get pods dns-test-73668abd-c23e-4d96-906b-3d0a63a64950)
  Apr 19 14:29:56.755: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6216.svc.cluster.local from pod dns-6216/dns-test-73668abd-c23e-4d96-906b-3d0a63a64950: the server could not find the requested resource (get pods dns-test-73668abd-c23e-4d96-906b-3d0a63a64950)
  Apr 19 14:29:56.755: INFO: Lookups using dns-6216/dns-test-73668abd-c23e-4d96-906b-3d0a63a64950 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6216.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6216.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6216.svc.cluster.local jessie_udp@dns-test-service-2.dns-6216.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6216.svc.cluster.local]

  E0419 14:29:57.686393      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:58.687087      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:29:59.687229      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:00.687465      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:01.687777      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:30:01.779: INFO: DNS probes using dns-6216/dns-test-73668abd-c23e-4d96-906b-3d0a63a64950 succeeded

  Apr 19 14:30:01.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 04/19/23 14:30:01.783
  STEP: deleting the test headless service @ 04/19/23 14:30:01.8
  STEP: Destroying namespace "dns-6216" for this suite. @ 04/19/23 14:30:01.813
• [7.138 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:458
  STEP: Creating a kubernetes client @ 04/19/23 14:30:01.835
  Apr 19 14:30:01.835: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename init-container @ 04/19/23 14:30:01.842
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:30:01.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:30:01.86
  STEP: creating the pod @ 04/19/23 14:30:01.863
  Apr 19 14:30:01.863: INFO: PodSpec: initContainers in spec.initContainers
  W0419 14:30:01.870952      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "init1", "init2", "run1" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "init1", "init2", "run1" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "init1", "init2", "run1" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "init1", "init2", "run1" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:30:02.688013      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:03.688147      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:04.688231      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:30:05.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5991" for this suite. @ 04/19/23 14:30:05.128
• [3.298 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2224
  STEP: Creating a kubernetes client @ 04/19/23 14:30:05.137
  Apr 19 14:30:05.137: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename services @ 04/19/23 14:30:05.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:30:05.148
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:30:05.151
  STEP: creating service in namespace services-6091 @ 04/19/23 14:30:05.154
  STEP: creating service affinity-nodeport-transition in namespace services-6091 @ 04/19/23 14:30:05.154
  STEP: creating replication controller affinity-nodeport-transition in namespace services-6091 @ 04/19/23 14:30:05.166
  W0419 14:30:05.174721      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "affinity-nodeport-transition" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "affinity-nodeport-transition" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "affinity-nodeport-transition" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "affinity-nodeport-transition" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  I0419 14:30:05.174840      20 runners.go:194] Created replication controller with name: affinity-nodeport-transition, namespace: services-6091, replica count: 3
  E0419 14:30:05.688419      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:06.688765      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:07.688874      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  I0419 14:30:08.226632      20 runners.go:194] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Apr 19 14:30:08.234: INFO: Creating new exec pod
  W0419 14:30:08.238530      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:30:08.688957      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:09.689097      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:10.689917      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:30:11.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-6091 exec execpod-affinityzsvmf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  Apr 19 14:30:11.467: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Apr 19 14:30:11.467: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 14:30:11.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-6091 exec execpod-affinityzsvmf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.110.2.47 80'
  Apr 19 14:30:11.648: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.110.2.47 80\nConnection to 10.110.2.47 80 port [tcp/http] succeeded!\n"
  Apr 19 14:30:11.648: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 14:30:11.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-6091 exec execpod-affinityzsvmf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.0.5 32215'
  E0419 14:30:11.690169      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:30:11.797: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.0.5 32215\nConnection to 172.20.0.5 32215 port [tcp/*] succeeded!\n"
  Apr 19 14:30:11.797: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 14:30:11.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-6091 exec execpod-affinityzsvmf -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.20.0.6 32215'
  Apr 19 14:30:11.947: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.20.0.6 32215\nConnection to 172.20.0.6 32215 port [tcp/*] succeeded!\n"
  Apr 19 14:30:11.947: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Apr 19 14:30:11.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-6091 exec execpod-affinityzsvmf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.20.0.5:32215/ ; done'
  Apr 19 14:30:12.165: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n"
  Apr 19 14:30:12.165: INFO: stdout: "\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-lzc9x\naffinity-nodeport-transition-g7vrf\naffinity-nodeport-transition-lzc9x\naffinity-nodeport-transition-lzc9x\naffinity-nodeport-transition-lzc9x\naffinity-nodeport-transition-g7vrf\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-g7vrf\naffinity-nodeport-transition-g7vrf\naffinity-nodeport-transition-g7vrf\naffinity-nodeport-transition-g7vrf\naffinity-nodeport-transition-g7vrf\naffinity-nodeport-transition-g7vrf\naffinity-nodeport-transition-mksnd"
  Apr 19 14:30:12.165: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-lzc9x
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-g7vrf
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-lzc9x
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-lzc9x
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-lzc9x
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-g7vrf
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-g7vrf
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-g7vrf
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-g7vrf
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-g7vrf
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-g7vrf
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-g7vrf
  Apr 19 14:30:12.166: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=services-6091 exec execpod-affinityzsvmf -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.20.0.5:32215/ ; done'
  Apr 19 14:30:12.361: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.20.0.5:32215/\n"
  Apr 19 14:30:12.361: INFO: stdout: "\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd\naffinity-nodeport-transition-mksnd"
  Apr 19 14:30:12.361: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.361: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.361: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.361: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.362: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.362: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.362: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.362: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.362: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.362: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.362: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.362: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.362: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.362: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.362: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.362: INFO: Received response from host: affinity-nodeport-transition-mksnd
  Apr 19 14:30:12.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  Apr 19 14:30:12.366: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-6091, will wait for the garbage collector to delete the pods @ 04/19/23 14:30:12.376
  Apr 19 14:30:12.433: INFO: Deleting ReplicationController affinity-nodeport-transition took: 4.47407ms
  Apr 19 14:30:12.534: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.964282ms
  E0419 14:30:12.690326      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:13.690930      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-6091" for this suite. @ 04/19/23 14:30:14.158
• [9.026 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:341
  STEP: Creating a kubernetes client @ 04/19/23 14:30:14.166
  Apr 19 14:30:14.166: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubectl @ 04/19/23 14:30:14.167
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:30:14.178
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:30:14.186
  STEP: creating a replication controller @ 04/19/23 14:30:14.188
  Apr 19 14:30:14.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6088 create -f -'
  Apr 19 14:30:14.434: INFO: stderr: "Warning: would violate PodSecurity \"restricted:latest\": allowPrivilegeEscalation != false (container \"update-demo\" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \"update-demo\" must set securityContext.capabilities.drop=[\"ALL\"]), runAsNonRoot != true (pod or container \"update-demo\" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \"update-demo\" must set securityContext.seccompProfile.type to \"RuntimeDefault\" or \"Localhost\")\n"
  Apr 19 14:30:14.434: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 04/19/23 14:30:14.434
  Apr 19 14:30:14.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6088 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 19 14:30:14.496: INFO: stderr: ""
  Apr 19 14:30:14.496: INFO: stdout: "update-demo-nautilus-lwgbs update-demo-nautilus-r9m9g "
  Apr 19 14:30:14.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6088 get pods update-demo-nautilus-lwgbs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 14:30:14.546: INFO: stderr: ""
  Apr 19 14:30:14.546: INFO: stdout: ""
  Apr 19 14:30:14.546: INFO: update-demo-nautilus-lwgbs is created but not running
  E0419 14:30:14.691832      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:15.692796      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:16.692967      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:17.693055      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:18.693453      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:30:19.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6088 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Apr 19 14:30:19.642: INFO: stderr: ""
  Apr 19 14:30:19.642: INFO: stdout: "update-demo-nautilus-lwgbs update-demo-nautilus-r9m9g "
  Apr 19 14:30:19.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6088 get pods update-demo-nautilus-lwgbs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0419 14:30:19.694076      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:30:19.736: INFO: stderr: ""
  Apr 19 14:30:19.736: INFO: stdout: "true"
  Apr 19 14:30:19.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6088 get pods update-demo-nautilus-lwgbs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 19 14:30:19.811: INFO: stderr: ""
  Apr 19 14:30:19.811: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 19 14:30:19.812: INFO: validating pod update-demo-nautilus-lwgbs
  Apr 19 14:30:19.816: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 19 14:30:19.816: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 19 14:30:19.816: INFO: update-demo-nautilus-lwgbs is verified up and running
  Apr 19 14:30:19.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6088 get pods update-demo-nautilus-r9m9g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Apr 19 14:30:19.872: INFO: stderr: ""
  Apr 19 14:30:19.872: INFO: stdout: "true"
  Apr 19 14:30:19.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6088 get pods update-demo-nautilus-r9m9g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Apr 19 14:30:19.926: INFO: stderr: ""
  Apr 19 14:30:19.926: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Apr 19 14:30:19.926: INFO: validating pod update-demo-nautilus-r9m9g
  E0419 14:30:20.694153      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:21.694405      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:22.694552      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:23.695289      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:24.695384      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:25.695559      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:26.695701      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:27.695735      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:28.696472      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:29.696761      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:30.696957      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:31.697275      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:32.697500      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:33.698285      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:34.698583      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:30:35.315: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Apr 19 14:30:35.315: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Apr 19 14:30:35.315: INFO: update-demo-nautilus-r9m9g is verified up and running
  STEP: using delete to clean up resources @ 04/19/23 14:30:35.315
  Apr 19 14:30:35.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6088 delete --grace-period=0 --force -f -'
  Apr 19 14:30:35.385: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Apr 19 14:30:35.386: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Apr 19 14:30:35.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6088 get rc,svc -l name=update-demo --no-headers'
  Apr 19 14:30:35.472: INFO: stderr: "No resources found in kubectl-6088 namespace.\n"
  Apr 19 14:30:35.472: INFO: stdout: ""
  Apr 19 14:30:35.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-4081233856 --namespace=kubectl-6088 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Apr 19 14:30:35.566: INFO: stderr: ""
  Apr 19 14:30:35.566: INFO: stdout: ""
  Apr 19 14:30:35.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6088" for this suite. @ 04/19/23 14:30:35.57
• [21.407 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]
test/e2e/apimachinery/webhook.go:370
  STEP: Creating a kubernetes client @ 04/19/23 14:30:35.574
  Apr 19 14:30:35.574: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename webhook @ 04/19/23 14:30:35.575
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:30:35.583
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:30:35.586
  STEP: Setting up server cert @ 04/19/23 14:30:35.602
  E0419 14:30:35.698913      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 04/19/23 14:30:35.833
  STEP: Deploying the webhook pod @ 04/19/23 14:30:35.839
  W0419 14:30:35.854038      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "sample-webhook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "sample-webhook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "sample-webhook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "sample-webhook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Wait for the deployment to be ready @ 04/19/23 14:30:35.854
  Apr 19 14:30:35.860: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E0419 14:30:36.699044      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:37.699187      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 04/19/23 14:30:37.868
  STEP: Verifying the service has paired with the endpoint @ 04/19/23 14:30:37.878
  E0419 14:30:38.699746      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:30:38.880: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 04/19/23 14:30:38.883
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/19/23 14:30:38.884
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 04/19/23 14:30:38.903
  E0419 14:30:39.699842      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 04/19/23 14:30:39.914
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/19/23 14:30:39.914
  E0419 14:30:40.700020      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 04/19/23 14:30:40.936
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/19/23 14:30:40.936
  E0419 14:30:41.700983      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:42.701296      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:43.701413      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:44.701817      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:45.702296      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 04/19/23 14:30:45.97
  STEP: Registering slow webhook via the AdmissionRegistration API @ 04/19/23 14:30:45.97
  E0419 14:30:46.702449      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:47.702582      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:48.702709      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:49.702829      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:50.703343      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:30:50.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2573" for this suite. @ 04/19/23 14:30:51.049
  STEP: Destroying namespace "webhook-markers-9334" for this suite. @ 04/19/23 14:30:51.052
• [15.482 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]
test/e2e/network/ingressclass.go:266
  STEP: Creating a kubernetes client @ 04/19/23 14:30:51.058
  Apr 19 14:30:51.058: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename ingressclass @ 04/19/23 14:30:51.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:30:51.067
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:30:51.069
  STEP: getting /apis @ 04/19/23 14:30:51.071
  STEP: getting /apis/networking.k8s.io @ 04/19/23 14:30:51.074
  STEP: getting /apis/networking.k8s.iov1 @ 04/19/23 14:30:51.075
  STEP: creating @ 04/19/23 14:30:51.077
  STEP: getting @ 04/19/23 14:30:51.085
  STEP: listing @ 04/19/23 14:30:51.087
  STEP: watching @ 04/19/23 14:30:51.089
  Apr 19 14:30:51.089: INFO: starting watch
  STEP: patching @ 04/19/23 14:30:51.09
  STEP: updating @ 04/19/23 14:30:51.093
  Apr 19 14:30:51.096: INFO: waiting for watch events with expected annotations
  Apr 19 14:30:51.097: INFO: saw patched and updated annotations
  STEP: deleting @ 04/19/23 14:30:51.097
  STEP: deleting a collection @ 04/19/23 14:30:51.104
  Apr 19 14:30:51.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-4272" for this suite. @ 04/19/23 14:30:51.115
• [0.061 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/rc.go:69
  STEP: Creating a kubernetes client @ 04/19/23 14:30:51.124
  Apr 19 14:30:51.124: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename replication-controller @ 04/19/23 14:30:51.125
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:30:51.134
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:30:51.137
  STEP: Creating replication controller my-hostname-basic-e2f5c644-0395-4bcf-bc4e-5479f227e091 @ 04/19/23 14:30:51.139
  W0419 14:30:51.143750      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "my-hostname-basic-e2f5c644-0395-4bcf-bc4e-5479f227e091" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "my-hostname-basic-e2f5c644-0395-4bcf-bc4e-5479f227e091" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "my-hostname-basic-e2f5c644-0395-4bcf-bc4e-5479f227e091" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "my-hostname-basic-e2f5c644-0395-4bcf-bc4e-5479f227e091" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  Apr 19 14:30:51.146: INFO: Pod name my-hostname-basic-e2f5c644-0395-4bcf-bc4e-5479f227e091: Found 0 pods out of 1
  E0419 14:30:51.703468      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:52.703867      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:53.704862      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:54.705053      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:55.705976      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:30:56.155: INFO: Pod name my-hostname-basic-e2f5c644-0395-4bcf-bc4e-5479f227e091: Found 1 pods out of 1
  Apr 19 14:30:56.155: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-e2f5c644-0395-4bcf-bc4e-5479f227e091" are running
  Apr 19 14:30:56.160: INFO: Pod "my-hostname-basic-e2f5c644-0395-4bcf-bc4e-5479f227e091-6kw67" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-19 14:30:51 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-19 14:30:52 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-19 14:30:52 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-19 14:30:51 +0000 UTC Reason: Message:}])
  Apr 19 14:30:56.160: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 04/19/23 14:30:56.16
  Apr 19 14:30:56.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-507" for this suite. @ 04/19/23 14:30:56.174
• [5.054 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]
test/e2e/apps/replica_set.go:131
  STEP: Creating a kubernetes client @ 04/19/23 14:30:56.18
  Apr 19 14:30:56.180: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename replicaset @ 04/19/23 14:30:56.181
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:30:56.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:30:56.194
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 04/19/23 14:30:56.197
  W0419 14:30:56.203127      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-adoption-release" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-adoption-release" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-adoption-release" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-adoption-release" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:30:56.706816      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:30:57.707064      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 04/19/23 14:30:58.215
  W0419 14:30:58.220879      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-adoption-release" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-adoption-release" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-adoption-release" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-adoption-release" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Then the orphan pod is adopted @ 04/19/23 14:30:58.222
  E0419 14:30:58.707850      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 04/19/23 14:30:59.229
  Apr 19 14:30:59.233: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 04/19/23 14:30:59.244
  E0419 14:30:59.709895      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:31:00.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1481" for this suite. @ 04/19/23 14:31:00.256
• [4.082 seconds]
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 04/19/23 14:31:00.263
  Apr 19 14:31:00.263: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename pods @ 04/19/23 14:31:00.265
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:31:00.276
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:31:00.28
  STEP: creating the pod @ 04/19/23 14:31:00.284
  STEP: submitting the pod to kubernetes @ 04/19/23 14:31:00.285
  E0419 14:31:00.710981      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:01.711255      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 04/19/23 14:31:02.302
  STEP: updating the pod @ 04/19/23 14:31:02.306
  E0419 14:31:02.711308      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:31:02.817: INFO: Successfully updated pod "pod-update-aa0d2c16-9a5b-465b-8b5f-8f9acef393ad"
  STEP: verifying the updated pod is in kubernetes @ 04/19/23 14:31:02.82
  Apr 19 14:31:02.824: INFO: Pod update OK
  Apr 19 14:31:02.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6323" for this suite. @ 04/19/23 14:31:02.829
• [2.575 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:175
  STEP: Creating a kubernetes client @ 04/19/23 14:31:02.842
  Apr 19 14:31:02.842: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 14:31:02.843
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:31:02.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:31:02.856
  STEP: Creating configMap with name configmap-test-upd-f616734e-59a2-41ae-9f84-ecb71d324f38 @ 04/19/23 14:31:02.861
  STEP: Creating the pod @ 04/19/23 14:31:02.866
  W0419 14:31:02.873255      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "agnhost-container", "configmap-volume-binary-test" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "agnhost-container", "configmap-volume-binary-test" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "agnhost-container", "configmap-volume-binary-test" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "agnhost-container", "configmap-volume-binary-test" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:31:03.711600      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:04.712001      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 04/19/23 14:31:04.88
  STEP: Waiting for pod with binary data @ 04/19/23 14:31:04.888
  Apr 19 14:31:04.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8986" for this suite. @ 04/19/23 14:31:04.899
• [2.065 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]
test/e2e/apimachinery/resource_quota.go:1013
  STEP: Creating a kubernetes client @ 04/19/23 14:31:04.909
  Apr 19 14:31:04.910: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename resourcequota @ 04/19/23 14:31:04.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:31:04.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:31:04.932
  STEP: Creating resourceQuota "e2e-rq-status-nl9dx" @ 04/19/23 14:31:04.937
  Apr 19 14:31:04.944: INFO: Resource quota "e2e-rq-status-nl9dx" reports spec: hard cpu limit of 500m
  Apr 19 14:31:04.944: INFO: Resource quota "e2e-rq-status-nl9dx" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-nl9dx" /status @ 04/19/23 14:31:04.944
  STEP: Confirm /status for "e2e-rq-status-nl9dx" resourceQuota via watch @ 04/19/23 14:31:04.952
  Apr 19 14:31:04.955: INFO: observed resourceQuota "e2e-rq-status-nl9dx" in namespace "resourcequota-635" with hard status: v1.ResourceList(nil)
  Apr 19 14:31:04.955: INFO: Found resourceQuota "e2e-rq-status-nl9dx" in namespace "resourcequota-635" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Apr 19 14:31:04.956: INFO: ResourceQuota "e2e-rq-status-nl9dx" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 04/19/23 14:31:04.959
  Apr 19 14:31:04.963: INFO: Resource quota "e2e-rq-status-nl9dx" reports spec: hard cpu limit of 1
  Apr 19 14:31:04.963: INFO: Resource quota "e2e-rq-status-nl9dx" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-nl9dx" /status @ 04/19/23 14:31:04.963
  STEP: Confirm /status for "e2e-rq-status-nl9dx" resourceQuota via watch @ 04/19/23 14:31:04.967
  Apr 19 14:31:04.969: INFO: observed resourceQuota "e2e-rq-status-nl9dx" in namespace "resourcequota-635" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Apr 19 14:31:04.969: INFO: Found resourceQuota "e2e-rq-status-nl9dx" in namespace "resourcequota-635" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Apr 19 14:31:04.969: INFO: ResourceQuota "e2e-rq-status-nl9dx" /status was patched
  STEP: Get "e2e-rq-status-nl9dx" /status @ 04/19/23 14:31:04.969
  Apr 19 14:31:04.972: INFO: Resourcequota "e2e-rq-status-nl9dx" reports status: hard cpu of 1
  Apr 19 14:31:04.972: INFO: Resourcequota "e2e-rq-status-nl9dx" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-nl9dx" /status before checking Spec is unchanged @ 04/19/23 14:31:04.975
  Apr 19 14:31:04.978: INFO: Resourcequota "e2e-rq-status-nl9dx" reports status: hard cpu of 2
  Apr 19 14:31:04.978: INFO: Resourcequota "e2e-rq-status-nl9dx" reports status: hard memory of 2Gi
  Apr 19 14:31:04.981: INFO: Found resourceQuota "e2e-rq-status-nl9dx" in namespace "resourcequota-635" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  E0419 14:31:05.712572      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:06.712883      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:07.713004      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:08.713215      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:09.713972      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:10.714991      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:11.715106      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:12.715347      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:13.716342      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:14.716603      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:15.716747      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:16.716849      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:17.717076      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:18.717230      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:19.717340      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:20.717437      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:21.717676      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:22.717777      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:23.718524      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:24.718873      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:25.719737      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:26.720066      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:27.720161      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:28.720784      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:29.720886      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:30.721231      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:31.721527      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:32.722167      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:33.722691      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:34.722819      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:35.722862      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:36.723021      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:37.723633      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:38.723767      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:39.724070      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:40.724188      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:41.724281      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:42.724445      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:43.725010      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:44.725866      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:45.726771      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:46.727464      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:47.727593      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:48.728029      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:49.728269      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:50.728877      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:51.729061      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:52.729344      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:53.729971      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:54.730068      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:55.731034      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:56.731197      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:57.731643      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:58.732231      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:31:59.732422      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:00.733329      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:01.733389      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:02.733567      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:03.733992      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:04.734458      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:05.735421      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:06.735554      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:07.735634      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:08.736204      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:09.736535      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:32:09.987: INFO: ResourceQuota "e2e-rq-status-nl9dx" Spec was unchanged and /status reset
  Apr 19 14:32:09.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-635" for this suite. @ 04/19/23 14:32:09.991
• [65.086 seconds]
------------------------------
S
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:57
  STEP: Creating a kubernetes client @ 04/19/23 14:32:09.997
  Apr 19 14:32:09.998: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename configmap @ 04/19/23 14:32:10.001
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:32:10.011
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:32:10.014
  STEP: Creating configMap with name configmap-test-volume-1cd9615f-f117-472d-a2c9-e0d1213b0106 @ 04/19/23 14:32:10.016
  STEP: Creating a pod to test consume configMaps @ 04/19/23 14:32:10.021
  W0419 14:32:10.027521      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:32:10.737014      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:11.737354      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:12.738318      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:13.738919      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 04/19/23 14:32:14.042
  Apr 19 14:32:14.045: INFO: Trying to get logs from node talos-default-worker-1 pod pod-configmaps-d122956d-0900-4c2c-aa79-fd4f470bc2eb container agnhost-container: <nil>
  STEP: delete the pod @ 04/19/23 14:32:14.052
  Apr 19 14:32:14.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1078" for this suite. @ 04/19/23 14:32:14.071
• [4.080 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:213
  STEP: Creating a kubernetes client @ 04/19/23 14:32:14.081
  Apr 19 14:32:14.082: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 04/19/23 14:32:14.086
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:32:14.097
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:32:14.1
  STEP: create the container to handle the HTTPGet hook request. @ 04/19/23 14:32:14.107
  W0419 14:32:14.113727      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (containers "container-handle-http-request", "container-handle-https-request" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (containers "container-handle-http-request", "container-handle-https-request" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or containers "container-handle-http-request", "container-handle-https-request" must set securityContext.runAsNonRoot=true), seccompProfile (pod or containers "container-handle-http-request", "container-handle-https-request" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:32:14.739096      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:15.739419      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 04/19/23 14:32:16.123
  W0419 14:32:16.127442      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "pod-with-prestop-http-hook" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "pod-with-prestop-http-hook" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "pod-with-prestop-http-hook" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "pod-with-prestop-http-hook" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  E0419 14:32:16.739522      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:17.739806      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 04/19/23 14:32:18.142
  E0419 14:32:18.740767      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:19.741077      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 04/19/23 14:32:20.162
  Apr 19 14:32:20.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4418" for this suite. @ 04/19/23 14:32:20.181
• [6.106 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 04/19/23 14:32:20.192
  Apr 19 14:32:20.193: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename kubelet-test @ 04/19/23 14:32:20.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:32:20.208
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:32:20.211
  W0419 14:32:20.221235      20 warnings.go:70] would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "agnhost-container" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "agnhost-container" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "agnhost-container" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "agnhost-container" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
  STEP: Waiting for pod completion @ 04/19/23 14:32:20.221
  E0419 14:32:20.741223      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:21.741365      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:22.742448      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  E0419 14:32:23.743192      20 retrywatcher.go:130] "Watch failed" err="context canceled"
  Apr 19 14:32:24.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3725" for this suite. @ 04/19/23 14:32:24.243
• [4.056 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]
test/e2e/apimachinery/resource_quota.go:887
  STEP: Creating a kubernetes client @ 04/19/23 14:32:24.25
  Apr 19 14:32:24.250: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename resourcequota @ 04/19/23 14:32:24.252
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:32:24.265
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:32:24.269
  STEP: Creating a ResourceQuota @ 04/19/23 14:32:24.274
  STEP: Getting a ResourceQuota @ 04/19/23 14:32:24.278
  STEP: Updating a ResourceQuota @ 04/19/23 14:32:24.282
  STEP: Verifying a ResourceQuota was modified @ 04/19/23 14:32:24.287
  STEP: Deleting a ResourceQuota @ 04/19/23 14:32:24.291
  STEP: Verifying the deleted ResourceQuota @ 04/19/23 14:32:24.296
  Apr 19 14:32:24.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3941" for this suite. @ 04/19/23 14:32:24.304
• [0.060 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance]
test/e2e/common/node/secrets.go:154
  STEP: Creating a kubernetes client @ 04/19/23 14:32:24.311
  Apr 19 14:32:24.311: INFO: >>> kubeConfig: /tmp/kubeconfig-4081233856
  STEP: Building a namespace api object, basename secrets @ 04/19/23 14:32:24.313
  STEP: Waiting for a default service account to be provisioned in namespace @ 04/19/23 14:32:24.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 04/19/23 14:32:24.331
  STEP: creating a secret @ 04/19/23 14:32:24.333
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 04/19/23 14:32:24.336
  STEP: patching the secret @ 04/19/23 14:32:24.339
  STEP: deleting the secret using a LabelSelector @ 04/19/23 14:32:24.345
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 04/19/23 14:32:24.35
  Apr 19 14:32:24.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5765" for this suite. @ 04/19/23 14:32:24.356
• [0.049 seconds]
------------------------------
SSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
  Apr 19 14:32:24.361: INFO: Running AfterSuite actions on node 1
  Apr 19 14:32:24.361: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:152
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:593
[ReportAfterSuite] PASSED [0.035 seconds]
------------------------------

Ran 378 of 7207 Specs in 5941.433 seconds
SUCCESS! -- 378 Passed | 0 Failed | 0 Pending | 6829 Skipped
PASS

Ginkgo ran 1 suite in 1h39m1.754865322s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.9.1[0m

