I0824 11:47:13.128673      16 e2e.go:132] Starting e2e run "0c4f61b6-8fad-4e4c-ba74-1edd87952e30" on Ginkgo node 1
{"msg":"Test Suite starting","total":346,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1661341632 - Will randomize all specs
Will run 346 of 7050 specs

Aug 24 11:47:16.527: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 11:47:16.542: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 24 11:47:16.578: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 24 11:47:16.621: INFO: 13 / 13 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 24 11:47:16.621: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Aug 24 11:47:16.621: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 24 11:47:16.627: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Aug 24 11:47:16.627: INFO: e2e test version: v1.23.10
Aug 24 11:47:16.629: INFO: kube-apiserver version: v1.23.10
Aug 24 11:47:16.629: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 11:47:16.634: INFO: Cluster IP family: ipv4
SSSSSS
------------------------------
[sig-node] Security Context 
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:47:16.635: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename security-context
Aug 24 11:47:16.685: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
W0824 11:47:16.684944      16 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Aug 24 11:47:16.713: INFO: Waiting up to 5m0s for pod "security-context-2153ff5d-6b95-499b-9a3c-d0747da3fd0b" in namespace "security-context-732" to be "Succeeded or Failed"
Aug 24 11:47:16.727: INFO: Pod "security-context-2153ff5d-6b95-499b-9a3c-d0747da3fd0b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.297612ms
Aug 24 11:47:18.741: INFO: Pod "security-context-2153ff5d-6b95-499b-9a3c-d0747da3fd0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027517474s
Aug 24 11:47:20.753: INFO: Pod "security-context-2153ff5d-6b95-499b-9a3c-d0747da3fd0b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040497395s
Aug 24 11:47:22.769: INFO: Pod "security-context-2153ff5d-6b95-499b-9a3c-d0747da3fd0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.055914236s
STEP: Saw pod success
Aug 24 11:47:22.769: INFO: Pod "security-context-2153ff5d-6b95-499b-9a3c-d0747da3fd0b" satisfied condition "Succeeded or Failed"
Aug 24 11:47:22.792: INFO: Trying to get logs from node zou9eicaeree-3 pod security-context-2153ff5d-6b95-499b-9a3c-d0747da3fd0b container test-container: <nil>
STEP: delete the pod
Aug 24 11:47:22.915: INFO: Waiting for pod security-context-2153ff5d-6b95-499b-9a3c-d0747da3fd0b to disappear
Aug 24 11:47:22.932: INFO: Pod security-context-2153ff5d-6b95-499b-9a3c-d0747da3fd0b no longer exists
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:47:22.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-732" for this suite.

• [SLOW TEST:6.323 seconds]
[sig-node] Security Context
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":346,"completed":1,"skipped":6,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring 
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:47:22.967: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename endpointslicemirroring
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:39
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: mirroring a new custom Endpoint
Aug 24 11:47:23.062: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint
STEP: mirroring deletion of a custom Endpoint
Aug 24 11:47:25.121: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:47:27.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-1843" for this suite.
•{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","total":346,"completed":2,"skipped":29,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:47:27.156: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Aug 24 11:47:27.200: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Aug 24 11:47:42.577: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 11:47:45.629: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:47:58.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7942" for this suite.

• [SLOW TEST:31.810 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":346,"completed":3,"skipped":33,"failed":0}
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:47:58.967: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name projected-configmap-test-volume-map-2e7a824d-9f91-4c8c-a768-4bee96fad237
STEP: Creating a pod to test consume configMaps
Aug 24 11:47:59.032: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fdee9067-2631-4f39-964c-61a9f6d4a2f1" in namespace "projected-6667" to be "Succeeded or Failed"
Aug 24 11:47:59.038: INFO: Pod "pod-projected-configmaps-fdee9067-2631-4f39-964c-61a9f6d4a2f1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.758333ms
Aug 24 11:48:01.049: INFO: Pod "pod-projected-configmaps-fdee9067-2631-4f39-964c-61a9f6d4a2f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016285526s
Aug 24 11:48:03.061: INFO: Pod "pod-projected-configmaps-fdee9067-2631-4f39-964c-61a9f6d4a2f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028204573s
STEP: Saw pod success
Aug 24 11:48:03.061: INFO: Pod "pod-projected-configmaps-fdee9067-2631-4f39-964c-61a9f6d4a2f1" satisfied condition "Succeeded or Failed"
Aug 24 11:48:03.066: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-projected-configmaps-fdee9067-2631-4f39-964c-61a9f6d4a2f1 container agnhost-container: <nil>
STEP: delete the pod
Aug 24 11:48:03.098: INFO: Waiting for pod pod-projected-configmaps-fdee9067-2631-4f39-964c-61a9f6d4a2f1 to disappear
Aug 24 11:48:03.103: INFO: Pod pod-projected-configmaps-fdee9067-2631-4f39-964c-61a9f6d4a2f1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:48:03.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6667" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":346,"completed":4,"skipped":35,"failed":0}
SSSS
------------------------------
[sig-apps] Deployment 
  should validate Deployment Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:48:03.121: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] should validate Deployment Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a Deployment
Aug 24 11:48:03.173: INFO: Creating simple deployment test-deployment-mhk64
Aug 24 11:48:03.198: INFO: new replicaset for deployment "test-deployment-mhk64" is yet to be created
Aug 24 11:48:05.229: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-mhk64-764bc7c4b7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 11:48:07.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-mhk64-764bc7c4b7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 11:48:09.270: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-mhk64-764bc7c4b7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 11:48:11.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-mhk64-764bc7c4b7\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Getting /status
Aug 24 11:48:13.258: INFO: Deployment test-deployment-mhk64 has Conditions: [{Available True 2022-08-24 11:48:11 +0000 UTC 2022-08-24 11:48:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-08-24 11:48:11 +0000 UTC 2022-08-24 11:48:03 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mhk64-764bc7c4b7" has successfully progressed.}]
STEP: updating Deployment Status
Aug 24 11:48:13.276: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 11, 48, 11, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 11, 48, 11, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 11, 48, 11, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 11, 48, 3, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-mhk64-764bc7c4b7\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated
Aug 24 11:48:13.280: INFO: Observed &Deployment event: ADDED
Aug 24 11:48:13.280: INFO: Observed Deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 11:48:03 +0000 UTC 2022-08-24 11:48:03 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mhk64-764bc7c4b7"}
Aug 24 11:48:13.281: INFO: Observed &Deployment event: MODIFIED
Aug 24 11:48:13.281: INFO: Observed Deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 11:48:03 +0000 UTC 2022-08-24 11:48:03 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mhk64-764bc7c4b7"}
Aug 24 11:48:13.281: INFO: Observed Deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-24 11:48:03 +0000 UTC 2022-08-24 11:48:03 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 24 11:48:13.281: INFO: Observed &Deployment event: MODIFIED
Aug 24 11:48:13.281: INFO: Observed Deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-24 11:48:03 +0000 UTC 2022-08-24 11:48:03 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 24 11:48:13.282: INFO: Observed Deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 11:48:03 +0000 UTC 2022-08-24 11:48:03 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-mhk64-764bc7c4b7" is progressing.}
Aug 24 11:48:13.282: INFO: Observed &Deployment event: MODIFIED
Aug 24 11:48:13.282: INFO: Observed Deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-24 11:48:11 +0000 UTC 2022-08-24 11:48:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 24 11:48:13.282: INFO: Observed Deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 11:48:11 +0000 UTC 2022-08-24 11:48:03 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mhk64-764bc7c4b7" has successfully progressed.}
Aug 24 11:48:13.282: INFO: Observed &Deployment event: MODIFIED
Aug 24 11:48:13.282: INFO: Observed Deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-24 11:48:11 +0000 UTC 2022-08-24 11:48:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 24 11:48:13.282: INFO: Observed Deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 11:48:11 +0000 UTC 2022-08-24 11:48:03 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mhk64-764bc7c4b7" has successfully progressed.}
Aug 24 11:48:13.282: INFO: Found Deployment test-deployment-mhk64 in namespace deployment-1156 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 24 11:48:13.282: INFO: Deployment test-deployment-mhk64 has an updated status
STEP: patching the Statefulset Status
Aug 24 11:48:13.283: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug 24 11:48:13.297: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched
Aug 24 11:48:13.299: INFO: Observed &Deployment event: ADDED
Aug 24 11:48:13.299: INFO: Observed deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 11:48:03 +0000 UTC 2022-08-24 11:48:03 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mhk64-764bc7c4b7"}
Aug 24 11:48:13.300: INFO: Observed &Deployment event: MODIFIED
Aug 24 11:48:13.300: INFO: Observed deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 11:48:03 +0000 UTC 2022-08-24 11:48:03 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-mhk64-764bc7c4b7"}
Aug 24 11:48:13.300: INFO: Observed deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-24 11:48:03 +0000 UTC 2022-08-24 11:48:03 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 24 11:48:13.300: INFO: Observed &Deployment event: MODIFIED
Aug 24 11:48:13.300: INFO: Observed deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-08-24 11:48:03 +0000 UTC 2022-08-24 11:48:03 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Aug 24 11:48:13.300: INFO: Observed deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 11:48:03 +0000 UTC 2022-08-24 11:48:03 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-mhk64-764bc7c4b7" is progressing.}
Aug 24 11:48:13.300: INFO: Observed &Deployment event: MODIFIED
Aug 24 11:48:13.300: INFO: Observed deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-24 11:48:11 +0000 UTC 2022-08-24 11:48:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 24 11:48:13.300: INFO: Observed deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 11:48:11 +0000 UTC 2022-08-24 11:48:03 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mhk64-764bc7c4b7" has successfully progressed.}
Aug 24 11:48:13.301: INFO: Observed &Deployment event: MODIFIED
Aug 24 11:48:13.301: INFO: Observed deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-08-24 11:48:11 +0000 UTC 2022-08-24 11:48:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Aug 24 11:48:13.301: INFO: Observed deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-08-24 11:48:11 +0000 UTC 2022-08-24 11:48:03 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-mhk64-764bc7c4b7" has successfully progressed.}
Aug 24 11:48:13.301: INFO: Observed deployment test-deployment-mhk64 in namespace deployment-1156 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 24 11:48:13.301: INFO: Observed &Deployment event: MODIFIED
Aug 24 11:48:13.301: INFO: Found deployment test-deployment-mhk64 in namespace deployment-1156 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Aug 24 11:48:13.301: INFO: Deployment test-deployment-mhk64 has a patched status
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Aug 24 11:48:13.308: INFO: Deployment "test-deployment-mhk64":
&Deployment{ObjectMeta:{test-deployment-mhk64  deployment-1156  328c88be-55fd-49cb-878c-b64c3a5d2417 19715 1 2022-08-24 11:48:03 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2022-08-24 11:48:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-08-24 11:48:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-08-24 11:48:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004912b98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-mhk64-764bc7c4b7",LastUpdateTime:2022-08-24 11:48:13 +0000 UTC,LastTransitionTime:2022-08-24 11:48:13 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 24 11:48:13.314: INFO: New ReplicaSet "test-deployment-mhk64-764bc7c4b7" of Deployment "test-deployment-mhk64":
&ReplicaSet{ObjectMeta:{test-deployment-mhk64-764bc7c4b7  deployment-1156  936827e0-762f-4551-87cc-addd8ff3b368 19708 1 2022-08-24 11:48:03 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:764bc7c4b7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-mhk64 328c88be-55fd-49cb-878c-b64c3a5d2417 0xc0048e8960 0xc0048e8961}] []  [{kube-controller-manager Update apps/v1 2022-08-24 11:48:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"328c88be-55fd-49cb-878c-b64c3a5d2417\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 11:48:11 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 764bc7c4b7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:764bc7c4b7] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0048e8a18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 24 11:48:13.322: INFO: Pod "test-deployment-mhk64-764bc7c4b7-g4rzr" is available:
&Pod{ObjectMeta:{test-deployment-mhk64-764bc7c4b7-g4rzr test-deployment-mhk64-764bc7c4b7- deployment-1156  ee0fd5db-db29-495f-819b-d25fec1e8c25 19706 0 2022-08-24 11:48:03 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:764bc7c4b7] map[] [{apps/v1 ReplicaSet test-deployment-mhk64-764bc7c4b7 936827e0-762f-4551-87cc-addd8ff3b368 0xc0048e8de0 0xc0048e8de1}] []  [{kube-controller-manager Update v1 2022-08-24 11:48:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"936827e0-762f-4551-87cc-addd8ff3b368\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:48:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.178\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8jdxm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8jdxm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:48:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:48:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:48:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:48:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:10.233.66.178,StartTime:2022-08-24 11:48:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 11:48:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://85680395dee15c1026c5d08893ad015f82052447d001eab28a1304dacbf56fbc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.178,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:48:13.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1156" for this suite.

• [SLOW TEST:10.223 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","total":346,"completed":5,"skipped":39,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:48:13.345: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating secret secrets-6517/secret-test-e4295021-710f-4fa8-a78a-b979efed9fcc
STEP: Creating a pod to test consume secrets
Aug 24 11:48:13.405: INFO: Waiting up to 5m0s for pod "pod-configmaps-8c7f5dff-f6c3-4fcc-91fd-0cab9dea25fe" in namespace "secrets-6517" to be "Succeeded or Failed"
Aug 24 11:48:13.412: INFO: Pod "pod-configmaps-8c7f5dff-f6c3-4fcc-91fd-0cab9dea25fe": Phase="Pending", Reason="", readiness=false. Elapsed: 7.259378ms
Aug 24 11:48:15.429: INFO: Pod "pod-configmaps-8c7f5dff-f6c3-4fcc-91fd-0cab9dea25fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024348041s
Aug 24 11:48:17.441: INFO: Pod "pod-configmaps-8c7f5dff-f6c3-4fcc-91fd-0cab9dea25fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036289364s
STEP: Saw pod success
Aug 24 11:48:17.441: INFO: Pod "pod-configmaps-8c7f5dff-f6c3-4fcc-91fd-0cab9dea25fe" satisfied condition "Succeeded or Failed"
Aug 24 11:48:17.446: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-configmaps-8c7f5dff-f6c3-4fcc-91fd-0cab9dea25fe container env-test: <nil>
STEP: delete the pod
Aug 24 11:48:17.481: INFO: Waiting for pod pod-configmaps-8c7f5dff-f6c3-4fcc-91fd-0cab9dea25fe to disappear
Aug 24 11:48:17.488: INFO: Pod pod-configmaps-8c7f5dff-f6c3-4fcc-91fd-0cab9dea25fe no longer exists
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:48:17.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6517" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":346,"completed":6,"skipped":64,"failed":0}
SS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:48:17.504: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward api env vars
Aug 24 11:48:17.595: INFO: Waiting up to 5m0s for pod "downward-api-d0696a2e-c54a-45b3-99ca-7c073c981975" in namespace "downward-api-3206" to be "Succeeded or Failed"
Aug 24 11:48:17.610: INFO: Pod "downward-api-d0696a2e-c54a-45b3-99ca-7c073c981975": Phase="Pending", Reason="", readiness=false. Elapsed: 14.682211ms
Aug 24 11:48:19.658: INFO: Pod "downward-api-d0696a2e-c54a-45b3-99ca-7c073c981975": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062555168s
Aug 24 11:48:21.675: INFO: Pod "downward-api-d0696a2e-c54a-45b3-99ca-7c073c981975": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.079012346s
STEP: Saw pod success
Aug 24 11:48:21.675: INFO: Pod "downward-api-d0696a2e-c54a-45b3-99ca-7c073c981975" satisfied condition "Succeeded or Failed"
Aug 24 11:48:21.685: INFO: Trying to get logs from node zou9eicaeree-3 pod downward-api-d0696a2e-c54a-45b3-99ca-7c073c981975 container dapi-container: <nil>
STEP: delete the pod
Aug 24 11:48:21.731: INFO: Waiting for pod downward-api-d0696a2e-c54a-45b3-99ca-7c073c981975 to disappear
Aug 24 11:48:21.741: INFO: Pod downward-api-d0696a2e-c54a-45b3-99ca-7c073c981975 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:48:21.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3206" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":346,"completed":7,"skipped":66,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:48:21.773: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating the pod
Aug 24 11:48:21.817: INFO: PodSpec: initContainers in spec.initContainers
Aug 24 11:49:03.934: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-77f22f1d-960f-472b-a65c-88dbec147992", GenerateName:"", Namespace:"init-container-1703", SelfLink:"", UID:"4f1709ef-b2cb-4b68-89ef-6e154bd08f0f", ResourceVersion:"19897", Generation:0, CreationTimestamp:time.Date(2022, time.August, 24, 11, 48, 21, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"817472847"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 24, 11, 48, 21, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0031f3cf8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.August, 24, 11, 48, 22, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0031f3d28), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-tqzps", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc00503e3a0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-tqzps", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-tqzps", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.6", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-tqzps", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004a3c150), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"zou9eicaeree-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0033d6460), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004a3c1e0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004a3c200)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004a3c208), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc004a3c20c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0048e5840), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 24, 11, 48, 21, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 24, 11, 48, 21, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 24, 11, 48, 21, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.August, 24, 11, 48, 21, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.121.108", PodIP:"10.233.66.181", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.66.181"}}, StartTime:time.Date(2022, time.August, 24, 11, 48, 21, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0033d6540)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0033d65b0)}, Ready:false, RestartCount:3, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"k8s.gcr.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"cri-o://66c889ce62682e2b1aead61a458fb0f8a5226da200768bb0243f144e6e38e31a", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00503e420), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00503e400), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.6", ImageID:"", ContainerID:"", Started:(*bool)(0xc004a3c284)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:49:03.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1703" for this suite.

• [SLOW TEST:42.216 seconds]
[sig-node] InitContainer [NodeConformance]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":346,"completed":8,"skipped":79,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:49:03.998: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating service multi-endpoint-test in namespace services-2545
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2545 to expose endpoints map[]
Aug 24 11:49:04.078: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Aug 24 11:49:05.097: INFO: successfully validated that service multi-endpoint-test in namespace services-2545 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-2545
Aug 24 11:49:05.120: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 11:49:07.131: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2545 to expose endpoints map[pod1:[100]]
Aug 24 11:49:07.156: INFO: successfully validated that service multi-endpoint-test in namespace services-2545 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-2545
Aug 24 11:49:07.171: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 11:49:09.182: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 11:49:11.184: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 11:49:13.194: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 11:49:15.189: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2545 to expose endpoints map[pod1:[100] pod2:[101]]
Aug 24 11:49:15.213: INFO: successfully validated that service multi-endpoint-test in namespace services-2545 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods
Aug 24 11:49:15.213: INFO: Creating new exec pod
Aug 24 11:49:18.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2545 exec execpod44224 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Aug 24 11:49:18.833: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Aug 24 11:49:18.833: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 11:49:18.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2545 exec execpod44224 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.42.17 80'
Aug 24 11:49:19.051: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.42.17 80\nConnection to 10.233.42.17 80 port [tcp/http] succeeded!\n"
Aug 24 11:49:19.051: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 11:49:19.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2545 exec execpod44224 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Aug 24 11:49:19.252: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Aug 24 11:49:19.252: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 11:49:19.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2545 exec execpod44224 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.42.17 81'
Aug 24 11:49:19.486: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.42.17 81\nConnection to 10.233.42.17 81 port [tcp/*] succeeded!\n"
Aug 24 11:49:19.486: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-2545
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2545 to expose endpoints map[pod2:[101]]
Aug 24 11:49:19.589: INFO: successfully validated that service multi-endpoint-test in namespace services-2545 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-2545
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2545 to expose endpoints map[]
Aug 24 11:49:20.691: INFO: successfully validated that service multi-endpoint-test in namespace services-2545 exposes endpoints map[]
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:49:20.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2545" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756

• [SLOW TEST:16.761 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":346,"completed":9,"skipped":153,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:49:20.766: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating projection with secret that has name projected-secret-test-1ef854b0-f0b5-41b3-9a6b-bc7191ee20bb
STEP: Creating a pod to test consume secrets
Aug 24 11:49:20.831: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d72c6227-dfae-44e2-bb06-8454100c4ca9" in namespace "projected-6313" to be "Succeeded or Failed"
Aug 24 11:49:20.836: INFO: Pod "pod-projected-secrets-d72c6227-dfae-44e2-bb06-8454100c4ca9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.442942ms
Aug 24 11:49:22.849: INFO: Pod "pod-projected-secrets-d72c6227-dfae-44e2-bb06-8454100c4ca9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018151037s
Aug 24 11:49:24.861: INFO: Pod "pod-projected-secrets-d72c6227-dfae-44e2-bb06-8454100c4ca9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029985898s
STEP: Saw pod success
Aug 24 11:49:24.861: INFO: Pod "pod-projected-secrets-d72c6227-dfae-44e2-bb06-8454100c4ca9" satisfied condition "Succeeded or Failed"
Aug 24 11:49:24.865: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-projected-secrets-d72c6227-dfae-44e2-bb06-8454100c4ca9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 24 11:49:24.898: INFO: Waiting for pod pod-projected-secrets-d72c6227-dfae-44e2-bb06-8454100c4ca9 to disappear
Aug 24 11:49:24.903: INFO: Pod pod-projected-secrets-d72c6227-dfae-44e2-bb06-8454100c4ca9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:49:24.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6313" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":10,"skipped":158,"failed":0}

------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:49:24.918: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating projection with secret that has name projected-secret-test-map-3f008753-aade-4b74-a350-6403546e9594
STEP: Creating a pod to test consume secrets
Aug 24 11:49:24.999: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dd49e240-f862-4ce8-9457-e6e238fce99c" in namespace "projected-3847" to be "Succeeded or Failed"
Aug 24 11:49:25.011: INFO: Pod "pod-projected-secrets-dd49e240-f862-4ce8-9457-e6e238fce99c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.625982ms
Aug 24 11:49:27.022: INFO: Pod "pod-projected-secrets-dd49e240-f862-4ce8-9457-e6e238fce99c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023570053s
Aug 24 11:49:29.035: INFO: Pod "pod-projected-secrets-dd49e240-f862-4ce8-9457-e6e238fce99c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035976279s
STEP: Saw pod success
Aug 24 11:49:29.035: INFO: Pod "pod-projected-secrets-dd49e240-f862-4ce8-9457-e6e238fce99c" satisfied condition "Succeeded or Failed"
Aug 24 11:49:29.040: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-projected-secrets-dd49e240-f862-4ce8-9457-e6e238fce99c container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 24 11:49:29.081: INFO: Waiting for pod pod-projected-secrets-dd49e240-f862-4ce8-9457-e6e238fce99c to disappear
Aug 24 11:49:29.085: INFO: Pod pod-projected-secrets-dd49e240-f862-4ce8-9457-e6e238fce99c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:49:29.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3847" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":11,"skipped":158,"failed":0}
S
------------------------------
[sig-node] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:49:29.104: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating pod
Aug 24 11:49:29.201: INFO: The status of Pod pod-hostip-c3dee2c0-c172-42c6-9320-56eca9682d2e is Pending, waiting for it to be Running (with Ready = true)
Aug 24 11:49:31.213: INFO: The status of Pod pod-hostip-c3dee2c0-c172-42c6-9320-56eca9682d2e is Pending, waiting for it to be Running (with Ready = true)
Aug 24 11:49:33.223: INFO: The status of Pod pod-hostip-c3dee2c0-c172-42c6-9320-56eca9682d2e is Running (Ready = true)
Aug 24 11:49:33.232: INFO: Pod pod-hostip-c3dee2c0-c172-42c6-9320-56eca9682d2e has hostIP: 192.168.121.108
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:49:33.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4204" for this suite.
•{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","total":346,"completed":12,"skipped":159,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:49:33.254: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name configmap-test-volume-map-63bfd2eb-7867-4e81-9ff9-f77b22135037
STEP: Creating a pod to test consume configMaps
Aug 24 11:49:33.325: INFO: Waiting up to 5m0s for pod "pod-configmaps-a96cec33-3959-493c-b0ea-d911c2322d0d" in namespace "configmap-1605" to be "Succeeded or Failed"
Aug 24 11:49:33.345: INFO: Pod "pod-configmaps-a96cec33-3959-493c-b0ea-d911c2322d0d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.015708ms
Aug 24 11:49:35.363: INFO: Pod "pod-configmaps-a96cec33-3959-493c-b0ea-d911c2322d0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03767018s
Aug 24 11:49:37.373: INFO: Pod "pod-configmaps-a96cec33-3959-493c-b0ea-d911c2322d0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047871288s
STEP: Saw pod success
Aug 24 11:49:37.373: INFO: Pod "pod-configmaps-a96cec33-3959-493c-b0ea-d911c2322d0d" satisfied condition "Succeeded or Failed"
Aug 24 11:49:37.378: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-configmaps-a96cec33-3959-493c-b0ea-d911c2322d0d container agnhost-container: <nil>
STEP: delete the pod
Aug 24 11:49:37.410: INFO: Waiting for pod pod-configmaps-a96cec33-3959-493c-b0ea-d911c2322d0d to disappear
Aug 24 11:49:37.415: INFO: Pod pod-configmaps-a96cec33-3959-493c-b0ea-d911c2322d0d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:49:37.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1605" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":13,"skipped":177,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:49:37.435: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug 24 11:49:37.863: INFO: Pod name wrapped-volume-race-a999c5e9-6272-4093-95a0-e7152b326c5c: Found 0 pods out of 5
Aug 24 11:49:42.899: INFO: Pod name wrapped-volume-race-a999c5e9-6272-4093-95a0-e7152b326c5c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a999c5e9-6272-4093-95a0-e7152b326c5c in namespace emptydir-wrapper-8791, will wait for the garbage collector to delete the pods
Aug 24 11:49:53.015: INFO: Deleting ReplicationController wrapped-volume-race-a999c5e9-6272-4093-95a0-e7152b326c5c took: 15.034092ms
Aug 24 11:49:53.117: INFO: Terminating ReplicationController wrapped-volume-race-a999c5e9-6272-4093-95a0-e7152b326c5c pods took: 101.160959ms
STEP: Creating RC which spawns configmap-volume pods
Aug 24 11:49:56.475: INFO: Pod name wrapped-volume-race-896629d1-391d-4a0d-a7d8-bd2eb5f09a6f: Found 0 pods out of 5
Aug 24 11:50:01.533: INFO: Pod name wrapped-volume-race-896629d1-391d-4a0d-a7d8-bd2eb5f09a6f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-896629d1-391d-4a0d-a7d8-bd2eb5f09a6f in namespace emptydir-wrapper-8791, will wait for the garbage collector to delete the pods
Aug 24 11:50:15.677: INFO: Deleting ReplicationController wrapped-volume-race-896629d1-391d-4a0d-a7d8-bd2eb5f09a6f took: 14.94918ms
Aug 24 11:50:15.878: INFO: Terminating ReplicationController wrapped-volume-race-896629d1-391d-4a0d-a7d8-bd2eb5f09a6f pods took: 201.104052ms
STEP: Creating RC which spawns configmap-volume pods
Aug 24 11:50:18.823: INFO: Pod name wrapped-volume-race-099466fb-706f-455a-9d99-ad97ff8a1ffb: Found 0 pods out of 5
Aug 24 11:50:23.852: INFO: Pod name wrapped-volume-race-099466fb-706f-455a-9d99-ad97ff8a1ffb: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-099466fb-706f-455a-9d99-ad97ff8a1ffb in namespace emptydir-wrapper-8791, will wait for the garbage collector to delete the pods
Aug 24 11:50:33.966: INFO: Deleting ReplicationController wrapped-volume-race-099466fb-706f-455a-9d99-ad97ff8a1ffb took: 11.816563ms
Aug 24 11:50:34.066: INFO: Terminating ReplicationController wrapped-volume-race-099466fb-706f-455a-9d99-ad97ff8a1ffb pods took: 100.5977ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:50:37.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8791" for this suite.

• [SLOW TEST:60.243 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":346,"completed":14,"skipped":183,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:50:37.678: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating service in namespace services-6403
Aug 24 11:50:37.739: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Aug 24 11:50:39.758: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Aug 24 11:50:39.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-6403 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Aug 24 11:50:40.042: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Aug 24 11:50:40.042: INFO: stdout: "iptables"
Aug 24 11:50:40.042: INFO: proxyMode: iptables
Aug 24 11:50:40.057: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 24 11:50:40.064: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-6403
STEP: creating replication controller affinity-clusterip-timeout in namespace services-6403
I0824 11:50:40.099383      16 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-6403, replica count: 3
I0824 11:50:43.151012      16 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 11:50:43.179: INFO: Creating new exec pod
Aug 24 11:50:46.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-6403 exec execpod-affinitym54xb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Aug 24 11:50:46.484: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Aug 24 11:50:46.484: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 11:50:46.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-6403 exec execpod-affinitym54xb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.59.180 80'
Aug 24 11:50:46.728: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.59.180 80\nConnection to 10.233.59.180 80 port [tcp/http] succeeded!\n"
Aug 24 11:50:46.729: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 11:50:46.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-6403 exec execpod-affinitym54xb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.59.180:80/ ; done'
Aug 24 11:50:47.076: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n"
Aug 24 11:50:47.077: INFO: stdout: "\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww\naffinity-clusterip-timeout-xb6ww"
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Received response from host: affinity-clusterip-timeout-xb6ww
Aug 24 11:50:47.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-6403 exec execpod-affinitym54xb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.233.59.180:80/'
Aug 24 11:50:47.285: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n"
Aug 24 11:50:47.285: INFO: stdout: "affinity-clusterip-timeout-xb6ww"
Aug 24 11:51:07.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-6403 exec execpod-affinitym54xb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.233.59.180:80/'
Aug 24 11:51:07.486: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n"
Aug 24 11:51:07.486: INFO: stdout: "affinity-clusterip-timeout-xb6ww"
Aug 24 11:51:27.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-6403 exec execpod-affinitym54xb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.233.59.180:80/'
Aug 24 11:51:27.770: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.233.59.180:80/\n"
Aug 24 11:51:27.770: INFO: stdout: "affinity-clusterip-timeout-zz6h9"
Aug 24 11:51:27.770: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-6403, will wait for the garbage collector to delete the pods
Aug 24 11:51:27.880: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 13.190238ms
Aug 24 11:51:27.981: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 101.500903ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:51:30.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6403" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756

• [SLOW TEST:52.480 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","total":346,"completed":15,"skipped":187,"failed":0}
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:51:30.160: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name configmap-test-volume-e6cffa12-3b3c-45e4-8c2f-c79eacec0da0
STEP: Creating a pod to test consume configMaps
Aug 24 11:51:30.239: INFO: Waiting up to 5m0s for pod "pod-configmaps-c2d6ea05-2101-4dda-8e2f-e97f4b7af4ec" in namespace "configmap-1575" to be "Succeeded or Failed"
Aug 24 11:51:30.244: INFO: Pod "pod-configmaps-c2d6ea05-2101-4dda-8e2f-e97f4b7af4ec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.700382ms
Aug 24 11:51:32.257: INFO: Pod "pod-configmaps-c2d6ea05-2101-4dda-8e2f-e97f4b7af4ec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017140412s
Aug 24 11:51:34.269: INFO: Pod "pod-configmaps-c2d6ea05-2101-4dda-8e2f-e97f4b7af4ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029169903s
STEP: Saw pod success
Aug 24 11:51:34.269: INFO: Pod "pod-configmaps-c2d6ea05-2101-4dda-8e2f-e97f4b7af4ec" satisfied condition "Succeeded or Failed"
Aug 24 11:51:34.274: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-configmaps-c2d6ea05-2101-4dda-8e2f-e97f4b7af4ec container agnhost-container: <nil>
STEP: delete the pod
Aug 24 11:51:34.317: INFO: Waiting for pod pod-configmaps-c2d6ea05-2101-4dda-8e2f-e97f4b7af4ec to disappear
Aug 24 11:51:34.326: INFO: Pod pod-configmaps-c2d6ea05-2101-4dda-8e2f-e97f4b7af4ec no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:51:34.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1575" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":16,"skipped":190,"failed":0}
SSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:51:34.362: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 11:51:34.407: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 24 11:51:34.424: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 24 11:51:39.439: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 24 11:51:39.439: INFO: Creating deployment "test-rolling-update-deployment"
Aug 24 11:51:39.448: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 24 11:51:39.460: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 24 11:51:41.477: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 24 11:51:41.482: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Aug 24 11:51:41.495: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-7243  6d562424-ec25-45cf-84cd-bba9f088c036 21379 1 2022-08-24 11:51:39 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2022-08-24 11:51:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 11:51:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004a1c258 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-24 11:51:39 +0000 UTC,LastTransitionTime:2022-08-24 11:51:39 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-8656fc4b57" has successfully progressed.,LastUpdateTime:2022-08-24 11:51:40 +0000 UTC,LastTransitionTime:2022-08-24 11:51:39 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 24 11:51:41.499: INFO: New ReplicaSet "test-rolling-update-deployment-8656fc4b57" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-8656fc4b57  deployment-7243  0128fa48-084a-40c8-8cd3-70123a9acdd6 21369 1 2022-08-24 11:51:39 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:8656fc4b57] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 6d562424-ec25-45cf-84cd-bba9f088c036 0xc004a1c737 0xc004a1c738}] []  [{kube-controller-manager Update apps/v1 2022-08-24 11:51:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6d562424-ec25-45cf-84cd-bba9f088c036\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 11:51:40 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 8656fc4b57,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:8656fc4b57] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004a1c7e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 24 11:51:41.499: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 24 11:51:41.500: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-7243  c93f65b6-ea5a-4007-b3d1-8ea44c54613d 21378 2 2022-08-24 11:51:34 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 6d562424-ec25-45cf-84cd-bba9f088c036 0xc004a1c5f7 0xc004a1c5f8}] []  [{e2e.test Update apps/v1 2022-08-24 11:51:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 11:51:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6d562424-ec25-45cf-84cd-bba9f088c036\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-08-24 11:51:40 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004a1c6c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 24 11:51:41.505: INFO: Pod "test-rolling-update-deployment-8656fc4b57-d5q2p" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-8656fc4b57-d5q2p test-rolling-update-deployment-8656fc4b57- deployment-7243  dac047a2-0322-4a25-9bec-9e0240cb4bd3 21368 0 2022-08-24 11:51:39 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:8656fc4b57] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-8656fc4b57 0128fa48-084a-40c8-8cd3-70123a9acdd6 0xc004a1cc47 0xc004a1cc48}] []  [{kube-controller-manager Update v1 2022-08-24 11:51:39 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0128fa48-084a-40c8-8cd3-70123a9acdd6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:51:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.197\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xnfpf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xnfpf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:10.233.66.197,StartTime:2022-08-24 11:51:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 11:51:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e,ContainerID:cri-o://e6426a8dcdd1437b96a25fe0f9474cb7a7fdc3ae5e56a6545610d03ef3dce0e3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.197,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:51:41.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7243" for this suite.

• [SLOW TEST:7.158 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":346,"completed":17,"skipped":195,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Pods Extended
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:51:41.523: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Pods Set QOS Class
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:150
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [sig-node] Pods Extended
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:51:41.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1463" for this suite.
•{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":346,"completed":18,"skipped":204,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:51:41.666: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 24 11:51:41.731: INFO: Waiting up to 5m0s for pod "pod-4fc8bddf-e5c9-47ee-b0f4-f17bbb5536d8" in namespace "emptydir-4556" to be "Succeeded or Failed"
Aug 24 11:51:41.735: INFO: Pod "pod-4fc8bddf-e5c9-47ee-b0f4-f17bbb5536d8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.615185ms
Aug 24 11:51:43.752: INFO: Pod "pod-4fc8bddf-e5c9-47ee-b0f4-f17bbb5536d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020667566s
Aug 24 11:51:45.768: INFO: Pod "pod-4fc8bddf-e5c9-47ee-b0f4-f17bbb5536d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036704744s
STEP: Saw pod success
Aug 24 11:51:45.768: INFO: Pod "pod-4fc8bddf-e5c9-47ee-b0f4-f17bbb5536d8" satisfied condition "Succeeded or Failed"
Aug 24 11:51:45.772: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-4fc8bddf-e5c9-47ee-b0f4-f17bbb5536d8 container test-container: <nil>
STEP: delete the pod
Aug 24 11:51:45.801: INFO: Waiting for pod pod-4fc8bddf-e5c9-47ee-b0f4-f17bbb5536d8 to disappear
Aug 24 11:51:45.806: INFO: Pod pod-4fc8bddf-e5c9-47ee-b0f4-f17bbb5536d8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:51:45.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4556" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":19,"skipped":207,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:51:45.822: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should support proportional scaling [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 11:51:45.875: INFO: Creating deployment "webserver-deployment"
Aug 24 11:51:45.884: INFO: Waiting for observed generation 1
Aug 24 11:51:47.897: INFO: Waiting for all required pods to come up
Aug 24 11:51:47.904: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug 24 11:51:59.928: INFO: Waiting for deployment "webserver-deployment" to complete
Aug 24 11:51:59.943: INFO: Updating deployment "webserver-deployment" with a non-existent image
Aug 24 11:51:59.963: INFO: Updating deployment webserver-deployment
Aug 24 11:51:59.963: INFO: Waiting for observed generation 2
Aug 24 11:52:01.996: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 24 11:52:02.002: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 24 11:52:02.007: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Aug 24 11:52:02.021: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 24 11:52:02.021: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 24 11:52:02.025: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Aug 24 11:52:02.033: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Aug 24 11:52:02.033: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Aug 24 11:52:02.050: INFO: Updating deployment webserver-deployment
Aug 24 11:52:02.050: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Aug 24 11:52:02.059: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 24 11:52:04.078: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Aug 24 11:52:04.090: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-5920  7d21a4f1-0a3c-4ff0-bfe2-f59e31133cb7 21753 3 2022-08-24 11:51:45 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-08-24 11:51:45 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 11:52:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004c21ae8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-08-24 11:52:02 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-566f96c878" is progressing.,LastUpdateTime:2022-08-24 11:52:02 +0000 UTC,LastTransitionTime:2022-08-24 11:51:45 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Aug 24 11:52:04.096: INFO: New ReplicaSet "webserver-deployment-566f96c878" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-566f96c878  deployment-5920  3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac 21751 3 2022-08-24 11:51:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 7d21a4f1-0a3c-4ff0-bfe2-f59e31133cb7 0xc004c21ee7 0xc004c21ee8}] []  [{kube-controller-manager Update apps/v1 2022-08-24 11:51:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7d21a4f1-0a3c-4ff0-bfe2-f59e31133cb7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 11:52:00 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 566f96c878,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004c21f88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 24 11:52:04.097: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Aug 24 11:52:04.097: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-5d9fdcc779  deployment-5920  eb5d4dea-df00-4ca1-aea8-572010de17bd 21735 3 2022-08-24 11:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 7d21a4f1-0a3c-4ff0-bfe2-f59e31133cb7 0xc004c21fe7 0xc004c21fe8}] []  [{kube-controller-manager Update apps/v1 2022-08-24 11:51:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7d21a4f1-0a3c-4ff0-bfe2-f59e31133cb7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 11:51:47 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 5d9fdcc779,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004314058 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Aug 24 11:52:04.108: INFO: Pod "webserver-deployment-566f96c878-29dtr" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-29dtr webserver-deployment-566f96c878- deployment-5920  2420850d-4e96-48c9-b9fe-4a703828fd3b 21632 0 2022-08-24 11:52:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac 0xc004c80907 0xc004c80908}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6t59f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6t59f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.241,PodIP:,StartTime:2022-08-24 11:52:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.108: INFO: Pod "webserver-deployment-566f96c878-47492" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-47492 webserver-deployment-566f96c878- deployment-5920  564483df-7bcf-406d-bd78-0b50091f2046 21746 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac 0xc004c80af7 0xc004c80af8}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f9kms,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f9kms,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.182,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.108: INFO: Pod "webserver-deployment-566f96c878-7zvpm" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-7zvpm webserver-deployment-566f96c878- deployment-5920  1f66c97e-d889-4567-bd52-8e1be870bc53 21719 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac 0xc004c80ce7 0xc004c80ce8}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w8nb6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w8nb6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.182,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.109: INFO: Pod "webserver-deployment-566f96c878-8h2s2" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-8h2s2 webserver-deployment-566f96c878- deployment-5920  2828dce0-7d0c-4abe-bade-5ae765781a6b 21622 0 2022-08-24 11:51:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac 0xc004c80ed7 0xc004c80ed8}] []  [{kube-controller-manager Update v1 2022-08-24 11:51:59 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mkqkd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mkqkd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:,StartTime:2022-08-24 11:52:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.109: INFO: Pod "webserver-deployment-566f96c878-8jdcw" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-8jdcw webserver-deployment-566f96c878- deployment-5920  0096aec6-7640-4375-94f6-993b572cd922 21627 0 2022-08-24 11:52:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac 0xc004c810c7 0xc004c810c8}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bgfgm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bgfgm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.182,PodIP:,StartTime:2022-08-24 11:52:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.110: INFO: Pod "webserver-deployment-566f96c878-d94f6" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-d94f6 webserver-deployment-566f96c878- deployment-5920  a2743232-1471-4c6f-8826-6590617f8da0 21758 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac 0xc004c812b7 0xc004c812b8}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r5dfb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r5dfb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.241,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.110: INFO: Pod "webserver-deployment-566f96c878-h4dl7" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-h4dl7 webserver-deployment-566f96c878- deployment-5920  b9b53be4-42b7-4e0f-ab32-dc312e469bfe 21718 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac 0xc004c814a7 0xc004c814a8}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zh6kz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zh6kz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.110: INFO: Pod "webserver-deployment-566f96c878-kf92n" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-kf92n webserver-deployment-566f96c878- deployment-5920  c1f42c09-7994-4b6c-889e-1c858f3ed123 21762 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac 0xc004c81620 0xc004c81621}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lxfxc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lxfxc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.241,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.111: INFO: Pod "webserver-deployment-566f96c878-ndd4c" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-ndd4c webserver-deployment-566f96c878- deployment-5920  545b3881-e426-4b41-909d-069da92517ba 21784 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac 0xc004c81807 0xc004c81808}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2mln7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2mln7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.111: INFO: Pod "webserver-deployment-566f96c878-p26xq" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-p26xq webserver-deployment-566f96c878- deployment-5920  1a959101-b66b-445b-b141-d842ed6634d0 21752 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac 0xc004c819f7 0xc004c819f8}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4vkmn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4vkmn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.182,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.112: INFO: Pod "webserver-deployment-566f96c878-sbjw8" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-sbjw8 webserver-deployment-566f96c878- deployment-5920  152af892-a812-41e7-8838-a1484e118384 21653 0 2022-08-24 11:52:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac 0xc004c81bf7 0xc004c81bf8}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tr44h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tr44h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.241,PodIP:,StartTime:2022-08-24 11:52:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.112: INFO: Pod "webserver-deployment-566f96c878-tslxk" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-tslxk webserver-deployment-566f96c878- deployment-5920  a258fd67-0294-4bae-a28e-371ce5a77f28 21651 0 2022-08-24 11:52:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac 0xc004c81de7 0xc004c81de8}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-srn6l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-srn6l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:,StartTime:2022-08-24 11:52:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.113: INFO: Pod "webserver-deployment-566f96c878-txbpv" is not available:
&Pod{ObjectMeta:{webserver-deployment-566f96c878-txbpv webserver-deployment-566f96c878- deployment-5920  ff753e09-38fb-4837-996a-af66de6cc77a 21754 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:566f96c878] map[] [{apps/v1 ReplicaSet webserver-deployment-566f96c878 3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac 0xc004c81fd7 0xc004c81fd8}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a570fdd-1d1a-4ce9-9a5c-1707c6c06bac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cjzmq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cjzmq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.113: INFO: Pod "webserver-deployment-5d9fdcc779-2fkt5" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-2fkt5 webserver-deployment-5d9fdcc779- deployment-5920  6249e72f-761d-4ceb-a0b7-b497f84369a5 21602 0 2022-08-24 11:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc0044865a7 0xc0044865a8}] []  [{kube-controller-manager Update v1 2022-08-24 11:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:51:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.60\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9cfjq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9cfjq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.241,PodIP:10.233.64.60,StartTime:2022-08-24 11:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 11:51:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://0b7ae0aff947492124349870a104cd01de9cd93949b8b93dea4a15e7eaf4525a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.114: INFO: Pod "webserver-deployment-5d9fdcc779-4z56n" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-4z56n webserver-deployment-5d9fdcc779- deployment-5920  e542736e-647e-4cf5-b045-32af4972ce35 21810 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc0044869a7 0xc0044869a8}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bmrl8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bmrl8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.241,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.114: INFO: Pod "webserver-deployment-5d9fdcc779-5d2pq" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-5d2pq webserver-deployment-5d9fdcc779- deployment-5920  05012e48-8057-487f-b52e-c810349287f2 21588 0 2022-08-24 11:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc004486b77 0xc004486b78}] []  [{kube-controller-manager Update v1 2022-08-24 11:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:51:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g7x95,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g7x95,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.182,PodIP:10.233.65.15,StartTime:2022-08-24 11:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 11:51:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://4457ea34aa18fee2d45571fc9834866c9d942613b0fed6192db0df8228297785,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.114: INFO: Pod "webserver-deployment-5d9fdcc779-8vf69" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-8vf69 webserver-deployment-5d9fdcc779- deployment-5920  4fc51ccd-060d-40d6-a397-c2bc8b7bdb06 21570 0 2022-08-24 11:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc004486d67 0xc004486d68}] []  [{kube-controller-manager Update v1 2022-08-24 11:51:45 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:51:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.13\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-px2v2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-px2v2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.182,PodIP:10.233.65.13,StartTime:2022-08-24 11:51:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 11:51:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://46e3f883409a3cb9ab3d166ae767452d6c51b3ce58968d3d40068ce848481846,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.13,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.115: INFO: Pod "webserver-deployment-5d9fdcc779-8xngt" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-8xngt webserver-deployment-5d9fdcc779- deployment-5920  162cc3fd-f0c6-4449-8f78-71b514d69653 21585 0 2022-08-24 11:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc004486f57 0xc004486f58}] []  [{kube-controller-manager Update v1 2022-08-24 11:51:45 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:51:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.58\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vwpdq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vwpdq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.241,PodIP:10.233.64.58,StartTime:2022-08-24 11:51:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 11:51:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://aaef50fa0f7e8c67f2073ae41b41c09845d93c0f7f4d29d3a4487c7c6a6d6eb2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.58,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.116: INFO: Pod "webserver-deployment-5d9fdcc779-b7f78" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-b7f78 webserver-deployment-5d9fdcc779- deployment-5920  1f93d238-210f-469d-8f3f-1beb679d372e 21534 0 2022-08-24 11:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc004487147 0xc004487148}] []  [{kube-controller-manager Update v1 2022-08-24 11:51:45 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:51:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.200\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lq5dl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lq5dl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:10.233.66.200,StartTime:2022-08-24 11:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 11:51:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://252bf48d44367f292928a3b59d665a74969f82c8fa7d2b39dd2295fcc856c7ec,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.200,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.116: INFO: Pod "webserver-deployment-5d9fdcc779-bkppq" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-bkppq webserver-deployment-5d9fdcc779- deployment-5920  c8e8d84f-8a6e-4058-af65-029eb8859079 21779 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc004487337 0xc004487338}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8v778,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8v778,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.241,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.117: INFO: Pod "webserver-deployment-5d9fdcc779-bv97q" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-bv97q webserver-deployment-5d9fdcc779- deployment-5920  055354e9-1b1f-46a1-9e30-e731d1f645f8 21807 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc004487a17 0xc004487a18}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-htkw8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-htkw8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.182,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.118: INFO: Pod "webserver-deployment-5d9fdcc779-kwrts" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-kwrts webserver-deployment-5d9fdcc779- deployment-5920  e5c9f84e-6c86-4a8a-80f3-9cfa6963e759 21785 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc004487be7 0xc004487be8}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mtdqb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mtdqb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.182,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.118: INFO: Pod "webserver-deployment-5d9fdcc779-ltd5j" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-ltd5j webserver-deployment-5d9fdcc779- deployment-5920  fe203da0-0888-4be6-be41-3a96dfe8a0b8 21697 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc00317c037 0xc00317c038}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q99lk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q99lk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.182,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.119: INFO: Pod "webserver-deployment-5d9fdcc779-nb7lf" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-nb7lf webserver-deployment-5d9fdcc779- deployment-5920  879d35a5-e704-4ba8-b316-0860e10ffbc6 21748 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc00317c207 0xc00317c208}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-djvws,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-djvws,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.241,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.120: INFO: Pod "webserver-deployment-5d9fdcc779-nt5t8" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-nt5t8 webserver-deployment-5d9fdcc779- deployment-5920  26004dc3-b2ca-4657-97af-064d2ffee2a6 21571 0 2022-08-24 11:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc00317c3d7 0xc00317c3d8}] []  [{kube-controller-manager Update v1 2022-08-24 11:51:45 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:51:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.14\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f7pm2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f7pm2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.182,PodIP:10.233.65.14,StartTime:2022-08-24 11:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 11:51:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://31da1925b77e4cd710007c368e555e410da7ddc18683cb501f563bc2063491f6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.14,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.121: INFO: Pod "webserver-deployment-5d9fdcc779-q7cj7" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-q7cj7 webserver-deployment-5d9fdcc779- deployment-5920  8dcb904b-c3ad-4743-b9d6-1f90c1651ccf 21792 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc00317c5c7 0xc00317c5c8}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q6mxj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q6mxj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.241,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.121: INFO: Pod "webserver-deployment-5d9fdcc779-rdrk6" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-rdrk6 webserver-deployment-5d9fdcc779- deployment-5920  99df8447-e57d-4fc7-8363-2d49828d9ca4 21732 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc00317c797 0xc00317c798}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kwd74,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kwd74,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.122: INFO: Pod "webserver-deployment-5d9fdcc779-rjbhw" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-rjbhw webserver-deployment-5d9fdcc779- deployment-5920  a98e9b05-ad68-43cc-b596-324e108b84dc 21542 0 2022-08-24 11:51:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc00317c900 0xc00317c901}] []  [{kube-controller-manager Update v1 2022-08-24 11:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:51:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.202\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zqvbx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zqvbx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:10.233.66.202,StartTime:2022-08-24 11:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 11:51:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://72c701beb41ecfa414edfca099ce8081e4da5f8bd555c618b9670b51e46e29b5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.202,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.123: INFO: Pod "webserver-deployment-5d9fdcc779-v6dcq" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-v6dcq webserver-deployment-5d9fdcc779- deployment-5920  c3f45703-59d4-4e2d-a894-085636ab7879 21707 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc00317cae7 0xc00317cae8}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-96mfw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-96mfw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.123: INFO: Pod "webserver-deployment-5d9fdcc779-xpzcq" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-xpzcq webserver-deployment-5d9fdcc779- deployment-5920  d78b3836-28ce-4fb4-84f8-e438102319be 21806 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc00317ccb7 0xc00317ccb8}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2xqv6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2xqv6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.124: INFO: Pod "webserver-deployment-5d9fdcc779-xz7c5" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-xz7c5 webserver-deployment-5d9fdcc779- deployment-5920  9f505d8e-a3ae-4cf8-b6cd-c1d581689f1f 21717 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc00317ce87 0xc00317ce88}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bzzvh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bzzvh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.124: INFO: Pod "webserver-deployment-5d9fdcc779-z7mz5" is not available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-z7mz5 webserver-deployment-5d9fdcc779- deployment-5920  8ee0a310-4795-431e-a552-efb9f7781815 21733 0 2022-08-24 11:52:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc00317cff0 0xc00317cff1}] []  [{kube-controller-manager Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:52:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gtvqm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gtvqm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:52:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:,StartTime:2022-08-24 11:52:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 11:52:04.125: INFO: Pod "webserver-deployment-5d9fdcc779-zfmvk" is available:
&Pod{ObjectMeta:{webserver-deployment-5d9fdcc779-zfmvk webserver-deployment-5d9fdcc779- deployment-5920  c6d9e372-7fc0-43cd-a3ae-f73b5bf0a3db 21595 0 2022-08-24 11:51:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet webserver-deployment-5d9fdcc779 eb5d4dea-df00-4ca1-aea8-572010de17bd 0xc00317d1b7 0xc00317d1b8}] []  [{kube-controller-manager Update v1 2022-08-24 11:51:45 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"eb5d4dea-df00-4ca1-aea8-572010de17bd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 11:51:57 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.59\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d556t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d556t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 11:51:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.241,PodIP:10.233.64.59,StartTime:2022-08-24 11:51:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 11:51:56 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://e8d6a5af8dc019721fcaf01ea3d53e0b5c59ad8ebce96cd3494d6ba2293bfa4d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.59,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:52:04.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5920" for this suite.

• [SLOW TEST:18.338 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":346,"completed":20,"skipped":237,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:52:04.160: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should add annotations for pods in rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating Agnhost RC
Aug 24 11:52:04.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8604 create -f -'
Aug 24 11:52:04.722: INFO: stderr: ""
Aug 24 11:52:04.722: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Aug 24 11:52:05.733: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 11:52:05.733: INFO: Found 0 / 1
Aug 24 11:52:06.731: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 11:52:06.731: INFO: Found 0 / 1
Aug 24 11:52:07.737: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 11:52:07.737: INFO: Found 0 / 1
Aug 24 11:52:08.730: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 11:52:08.731: INFO: Found 1 / 1
Aug 24 11:52:08.731: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 24 11:52:08.736: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 11:52:08.736: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 24 11:52:08.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8604 patch pod agnhost-primary-wkdlg -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 24 11:52:08.878: INFO: stderr: ""
Aug 24 11:52:08.878: INFO: stdout: "pod/agnhost-primary-wkdlg patched\n"
STEP: checking annotations
Aug 24 11:52:08.884: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 11:52:08.884: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:52:08.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8604" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":346,"completed":21,"skipped":254,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:52:08.902: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 11:52:10.424: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Aug 24 11:52:12.462: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 11, 52, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 11, 52, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 11, 52, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 11, 52, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6c69dbd86b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 11:52:14.482: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 11, 52, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 11, 52, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 11, 52, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 11, 52, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-6c69dbd86b\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 11:52:17.499: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:52:17.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9683" for this suite.
STEP: Destroying namespace "webhook-9683-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.905 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":346,"completed":22,"skipped":258,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:52:17.809: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Performing setup for networking test in namespace pod-network-test-3863
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 24 11:52:17.869: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 24 11:52:17.924: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 11:52:19.934: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 11:52:21.940: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 11:52:23.939: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 11:52:25.939: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 11:52:27.946: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 11:52:29.939: INFO: The status of Pod netserver-0 is Running (Ready = true)
Aug 24 11:52:29.951: INFO: The status of Pod netserver-1 is Running (Ready = true)
Aug 24 11:52:29.964: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Aug 24 11:52:32.035: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Aug 24 11:52:32.035: INFO: Going to poll 10.233.64.69 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Aug 24 11:52:32.040: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.64.69:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3863 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 11:52:32.041: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 11:52:32.043: INFO: ExecWithOptions: Clientset creation
Aug 24 11:52:32.043: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3863/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.64.69%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Aug 24 11:52:32.173: INFO: Found all 1 expected endpoints: [netserver-0]
Aug 24 11:52:32.173: INFO: Going to poll 10.233.65.23 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Aug 24 11:52:32.182: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.65.23:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3863 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 11:52:32.182: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 11:52:32.183: INFO: ExecWithOptions: Clientset creation
Aug 24 11:52:32.183: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3863/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.65.23%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Aug 24 11:52:32.305: INFO: Found all 1 expected endpoints: [netserver-1]
Aug 24 11:52:32.305: INFO: Going to poll 10.233.66.215 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Aug 24 11:52:32.311: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.66.215:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3863 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 11:52:32.311: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 11:52:32.313: INFO: ExecWithOptions: Clientset creation
Aug 24 11:52:32.313: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-3863/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.66.215%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Aug 24 11:52:32.410: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:52:32.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3863" for this suite.

• [SLOW TEST:14.629 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":23,"skipped":275,"failed":0}
[sig-node] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:52:32.439: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating the pod
Aug 24 11:52:32.500: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:52:37.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2682" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":346,"completed":24,"skipped":275,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:52:37.110: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating projection with secret that has name secret-emptykey-test-80cb1309-5bf1-4f00-ae37-fc149fb493e2
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:52:37.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5167" for this suite.
•{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","total":346,"completed":25,"skipped":290,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:52:37.219: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should run and stop complex daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 11:52:37.330: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 24 11:52:37.350: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 11:52:37.350: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched.
Aug 24 11:52:37.404: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 11:52:37.404: INFO: Node zou9eicaeree-3 is running 0 daemon pod, expected 1
Aug 24 11:52:38.411: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 11:52:38.411: INFO: Node zou9eicaeree-3 is running 0 daemon pod, expected 1
Aug 24 11:52:39.419: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 24 11:52:39.419: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 24 11:52:39.461: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 24 11:52:39.461: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Aug 24 11:52:40.475: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 11:52:40.475: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 24 11:52:40.500: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 11:52:40.500: INFO: Node zou9eicaeree-3 is running 0 daemon pod, expected 1
Aug 24 11:52:41.510: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 11:52:41.510: INFO: Node zou9eicaeree-3 is running 0 daemon pod, expected 1
Aug 24 11:52:42.523: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 11:52:42.523: INFO: Node zou9eicaeree-3 is running 0 daemon pod, expected 1
Aug 24 11:52:43.508: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 24 11:52:43.508: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3493, will wait for the garbage collector to delete the pods
Aug 24 11:52:43.587: INFO: Deleting DaemonSet.extensions daemon-set took: 10.067941ms
Aug 24 11:52:43.687: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.416937ms
Aug 24 11:52:46.302: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 11:52:46.302: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 24 11:52:46.306: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22462"},"items":null}

Aug 24 11:52:46.311: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22462"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:52:46.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3493" for this suite.

• [SLOW TEST:9.152 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":346,"completed":26,"skipped":306,"failed":0}
SSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:52:46.372: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 24 11:52:49.502: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:52:49.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9086" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]","total":346,"completed":27,"skipped":312,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:52:49.551: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating the pod with failed condition
STEP: updating the pod
Aug 24 11:54:50.186: INFO: Successfully updated pod "var-expansion-bd7f4fb5-f985-4d8d-981c-3492d31e47be"
STEP: waiting for pod running
STEP: deleting the pod gracefully
Aug 24 11:54:52.209: INFO: Deleting pod "var-expansion-bd7f4fb5-f985-4d8d-981c-3492d31e47be" in namespace "var-expansion-4287"
Aug 24 11:54:52.223: INFO: Wait up to 5m0s for pod "var-expansion-bd7f4fb5-f985-4d8d-981c-3492d31e47be" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:55:24.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4287" for this suite.

• [SLOW TEST:154.716 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","total":346,"completed":28,"skipped":320,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:55:24.275: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test substitution in container's command
Aug 24 11:55:24.337: INFO: Waiting up to 5m0s for pod "var-expansion-5c90d914-bf7b-4b08-a83b-9b7fa38ca1a6" in namespace "var-expansion-5676" to be "Succeeded or Failed"
Aug 24 11:55:24.341: INFO: Pod "var-expansion-5c90d914-bf7b-4b08-a83b-9b7fa38ca1a6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.51758ms
Aug 24 11:55:26.356: INFO: Pod "var-expansion-5c90d914-bf7b-4b08-a83b-9b7fa38ca1a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019144624s
Aug 24 11:55:28.367: INFO: Pod "var-expansion-5c90d914-bf7b-4b08-a83b-9b7fa38ca1a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030694328s
STEP: Saw pod success
Aug 24 11:55:28.367: INFO: Pod "var-expansion-5c90d914-bf7b-4b08-a83b-9b7fa38ca1a6" satisfied condition "Succeeded or Failed"
Aug 24 11:55:28.372: INFO: Trying to get logs from node zou9eicaeree-3 pod var-expansion-5c90d914-bf7b-4b08-a83b-9b7fa38ca1a6 container dapi-container: <nil>
STEP: delete the pod
Aug 24 11:55:28.425: INFO: Waiting for pod var-expansion-5c90d914-bf7b-4b08-a83b-9b7fa38ca1a6 to disappear
Aug 24 11:55:28.430: INFO: Pod var-expansion-5c90d914-bf7b-4b08-a83b-9b7fa38ca1a6 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:55:28.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5676" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":346,"completed":29,"skipped":390,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:55:28.457: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating pod pod-subpath-test-configmap-2njf
STEP: Creating a pod to test atomic-volume-subpath
Aug 24 11:55:28.546: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2njf" in namespace "subpath-8791" to be "Succeeded or Failed"
Aug 24 11:55:28.553: INFO: Pod "pod-subpath-test-configmap-2njf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.204122ms
Aug 24 11:55:30.562: INFO: Pod "pod-subpath-test-configmap-2njf": Phase="Running", Reason="", readiness=true. Elapsed: 2.015504704s
Aug 24 11:55:32.576: INFO: Pod "pod-subpath-test-configmap-2njf": Phase="Running", Reason="", readiness=true. Elapsed: 4.029610636s
Aug 24 11:55:34.588: INFO: Pod "pod-subpath-test-configmap-2njf": Phase="Running", Reason="", readiness=true. Elapsed: 6.041534054s
Aug 24 11:55:36.603: INFO: Pod "pod-subpath-test-configmap-2njf": Phase="Running", Reason="", readiness=true. Elapsed: 8.056443825s
Aug 24 11:55:38.622: INFO: Pod "pod-subpath-test-configmap-2njf": Phase="Running", Reason="", readiness=true. Elapsed: 10.075937515s
Aug 24 11:55:40.633: INFO: Pod "pod-subpath-test-configmap-2njf": Phase="Running", Reason="", readiness=true. Elapsed: 12.08637422s
Aug 24 11:55:42.648: INFO: Pod "pod-subpath-test-configmap-2njf": Phase="Running", Reason="", readiness=true. Elapsed: 14.101621563s
Aug 24 11:55:44.661: INFO: Pod "pod-subpath-test-configmap-2njf": Phase="Running", Reason="", readiness=true. Elapsed: 16.114477281s
Aug 24 11:55:46.679: INFO: Pod "pod-subpath-test-configmap-2njf": Phase="Running", Reason="", readiness=true. Elapsed: 18.132334704s
Aug 24 11:55:48.689: INFO: Pod "pod-subpath-test-configmap-2njf": Phase="Running", Reason="", readiness=true. Elapsed: 20.142983144s
Aug 24 11:55:50.697: INFO: Pod "pod-subpath-test-configmap-2njf": Phase="Running", Reason="", readiness=false. Elapsed: 22.150826944s
Aug 24 11:55:52.713: INFO: Pod "pod-subpath-test-configmap-2njf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.166166944s
STEP: Saw pod success
Aug 24 11:55:52.713: INFO: Pod "pod-subpath-test-configmap-2njf" satisfied condition "Succeeded or Failed"
Aug 24 11:55:52.718: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-subpath-test-configmap-2njf container test-container-subpath-configmap-2njf: <nil>
STEP: delete the pod
Aug 24 11:55:52.753: INFO: Waiting for pod pod-subpath-test-configmap-2njf to disappear
Aug 24 11:55:52.758: INFO: Pod pod-subpath-test-configmap-2njf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2njf
Aug 24 11:55:52.758: INFO: Deleting pod "pod-subpath-test-configmap-2njf" in namespace "subpath-8791"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:55:52.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8791" for this suite.

• [SLOW TEST:24.324 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Excluded:WindowsDocker] [Conformance]","total":346,"completed":30,"skipped":407,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:55:52.782: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 11:55:52.822: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:55:53.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6839" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":346,"completed":31,"skipped":409,"failed":0}
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:55:53.419: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating secret with name secret-test-42aee2ff-41d5-4435-9190-19cac5c0f19c
STEP: Creating a pod to test consume secrets
Aug 24 11:55:53.502: INFO: Waiting up to 5m0s for pod "pod-secrets-07ffa971-c3e9-4425-b1a4-958ce9b8fff0" in namespace "secrets-4585" to be "Succeeded or Failed"
Aug 24 11:55:53.509: INFO: Pod "pod-secrets-07ffa971-c3e9-4425-b1a4-958ce9b8fff0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.513869ms
Aug 24 11:55:55.522: INFO: Pod "pod-secrets-07ffa971-c3e9-4425-b1a4-958ce9b8fff0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019694227s
Aug 24 11:55:57.547: INFO: Pod "pod-secrets-07ffa971-c3e9-4425-b1a4-958ce9b8fff0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045194618s
STEP: Saw pod success
Aug 24 11:55:57.547: INFO: Pod "pod-secrets-07ffa971-c3e9-4425-b1a4-958ce9b8fff0" satisfied condition "Succeeded or Failed"
Aug 24 11:55:57.553: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-secrets-07ffa971-c3e9-4425-b1a4-958ce9b8fff0 container secret-volume-test: <nil>
STEP: delete the pod
Aug 24 11:55:57.581: INFO: Waiting for pod pod-secrets-07ffa971-c3e9-4425-b1a4-958ce9b8fff0 to disappear
Aug 24 11:55:57.587: INFO: Pod pod-secrets-07ffa971-c3e9-4425-b1a4-958ce9b8fff0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:55:57.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4585" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":32,"skipped":411,"failed":0}
SSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a volume subpath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:55:57.615: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a volume subpath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test substitution in volume subpath
Aug 24 11:55:57.710: INFO: Waiting up to 5m0s for pod "var-expansion-6e54a25c-d48d-426f-9c3e-ba74507dae33" in namespace "var-expansion-7379" to be "Succeeded or Failed"
Aug 24 11:55:57.726: INFO: Pod "var-expansion-6e54a25c-d48d-426f-9c3e-ba74507dae33": Phase="Pending", Reason="", readiness=false. Elapsed: 15.980176ms
Aug 24 11:55:59.738: INFO: Pod "var-expansion-6e54a25c-d48d-426f-9c3e-ba74507dae33": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027752767s
Aug 24 11:56:01.751: INFO: Pod "var-expansion-6e54a25c-d48d-426f-9c3e-ba74507dae33": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040305971s
STEP: Saw pod success
Aug 24 11:56:01.751: INFO: Pod "var-expansion-6e54a25c-d48d-426f-9c3e-ba74507dae33" satisfied condition "Succeeded or Failed"
Aug 24 11:56:01.755: INFO: Trying to get logs from node zou9eicaeree-3 pod var-expansion-6e54a25c-d48d-426f-9c3e-ba74507dae33 container dapi-container: <nil>
STEP: delete the pod
Aug 24 11:56:01.781: INFO: Waiting for pod var-expansion-6e54a25c-d48d-426f-9c3e-ba74507dae33 to disappear
Aug 24 11:56:01.786: INFO: Pod var-expansion-6e54a25c-d48d-426f-9c3e-ba74507dae33 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:56:01.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7379" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","total":346,"completed":33,"skipped":416,"failed":0}
SS
------------------------------
[sig-node] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:56:01.806: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test env composition
Aug 24 11:56:01.860: INFO: Waiting up to 5m0s for pod "var-expansion-c420436b-8542-42ff-ae81-cf48bb926666" in namespace "var-expansion-8428" to be "Succeeded or Failed"
Aug 24 11:56:01.866: INFO: Pod "var-expansion-c420436b-8542-42ff-ae81-cf48bb926666": Phase="Pending", Reason="", readiness=false. Elapsed: 5.444081ms
Aug 24 11:56:03.886: INFO: Pod "var-expansion-c420436b-8542-42ff-ae81-cf48bb926666": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025205269s
Aug 24 11:56:05.897: INFO: Pod "var-expansion-c420436b-8542-42ff-ae81-cf48bb926666": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036815187s
STEP: Saw pod success
Aug 24 11:56:05.897: INFO: Pod "var-expansion-c420436b-8542-42ff-ae81-cf48bb926666" satisfied condition "Succeeded or Failed"
Aug 24 11:56:05.903: INFO: Trying to get logs from node zou9eicaeree-3 pod var-expansion-c420436b-8542-42ff-ae81-cf48bb926666 container dapi-container: <nil>
STEP: delete the pod
Aug 24 11:56:05.932: INFO: Waiting for pod var-expansion-c420436b-8542-42ff-ae81-cf48bb926666 to disappear
Aug 24 11:56:05.937: INFO: Pod var-expansion-c420436b-8542-42ff-ae81-cf48bb926666 no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:56:05.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8428" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":346,"completed":34,"skipped":418,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:56:05.953: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating projection with configMap that has name projected-configmap-test-upd-24cf61cb-6c4d-449a-b112-b28f7a476c97
STEP: Creating the pod
Aug 24 11:56:06.045: INFO: The status of Pod pod-projected-configmaps-bd2ef48a-91b9-4302-830f-5282bd4bb413 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 11:56:08.056: INFO: The status of Pod pod-projected-configmaps-bd2ef48a-91b9-4302-830f-5282bd4bb413 is Running (Ready = true)
STEP: Updating configmap projected-configmap-test-upd-24cf61cb-6c4d-449a-b112-b28f7a476c97
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:57:18.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5294" for this suite.

• [SLOW TEST:72.733 seconds]
[sig-storage] Projected configMap
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":35,"skipped":425,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:57:18.689: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug 24 11:57:18.769: INFO: Pod name pod-release: Found 0 pods out of 1
Aug 24 11:57:23.785: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:57:24.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3064" for this suite.

• [SLOW TEST:6.154 seconds]
[sig-apps] ReplicationController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":346,"completed":36,"skipped":442,"failed":0}
S
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:57:24.845: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6935.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6935.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6935.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6935.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 24 11:57:38.956: INFO: DNS probes using dns-6935/dns-test-bae413fc-8a57-4e75-91b9-65a203727bb3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 11:57:38.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6935" for this suite.

• [SLOW TEST:14.150 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":346,"completed":37,"skipped":443,"failed":0}
[sig-apps] CronJob 
  should not schedule jobs when suspended [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 11:57:38.996: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not schedule jobs when suspended [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a suspended cronjob
STEP: Ensuring no jobs are scheduled
STEP: Ensuring no job exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:02:39.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2191" for this suite.

• [SLOW TEST:300.120 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","total":346,"completed":38,"skipped":443,"failed":0}
S
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:02:39.119: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:345
Aug 24 12:02:39.170: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 24 12:03:39.211: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:03:39.218: INFO: Starting informer...
STEP: Starting pods...
Aug 24 12:03:39.457: INFO: Pod1 is running on zou9eicaeree-3. Tainting Node
Aug 24 12:03:41.705: INFO: Pod2 is running on zou9eicaeree-3. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Aug 24 12:03:47.541: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Aug 24 12:04:07.618: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:04:07.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-3016" for this suite.

• [SLOW TEST:88.570 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":346,"completed":39,"skipped":444,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:04:07.689: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: getting a starting resourceVersion
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:04:10.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1505" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":346,"completed":40,"skipped":445,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:04:10.610: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating the pod
Aug 24 12:04:10.714: INFO: The status of Pod labelsupdatee52f572e-2faf-453d-a8fd-76ca1a8031bf is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:04:12.735: INFO: The status of Pod labelsupdatee52f572e-2faf-453d-a8fd-76ca1a8031bf is Running (Ready = true)
Aug 24 12:04:13.308: INFO: Successfully updated pod "labelsupdatee52f572e-2faf-453d-a8fd-76ca1a8031bf"
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:04:17.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7180" for this suite.

• [SLOW TEST:6.764 seconds]
[sig-storage] Downward API volume
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":346,"completed":41,"skipped":465,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:04:17.380: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:04:34.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4065" for this suite.

• [SLOW TEST:17.168 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":346,"completed":42,"skipped":495,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:04:34.558: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating the pod
Aug 24 12:04:34.631: INFO: The status of Pod labelsupdate92da64da-7c19-4da5-ae05-d695b98c1f5b is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:04:36.646: INFO: The status of Pod labelsupdate92da64da-7c19-4da5-ae05-d695b98c1f5b is Running (Ready = true)
Aug 24 12:04:37.183: INFO: Successfully updated pod "labelsupdate92da64da-7c19-4da5-ae05-d695b98c1f5b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:04:41.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8931" for this suite.

• [SLOW TEST:6.705 seconds]
[sig-storage] Projected downwardAPI
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":346,"completed":43,"skipped":580,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context 
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:04:41.266: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Aug 24 12:04:41.318: INFO: Waiting up to 5m0s for pod "security-context-33a8e360-4ae7-43d2-93a4-4b247b4fd873" in namespace "security-context-1989" to be "Succeeded or Failed"
Aug 24 12:04:41.324: INFO: Pod "security-context-33a8e360-4ae7-43d2-93a4-4b247b4fd873": Phase="Pending", Reason="", readiness=false. Elapsed: 5.269431ms
Aug 24 12:04:43.339: INFO: Pod "security-context-33a8e360-4ae7-43d2-93a4-4b247b4fd873": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020489486s
Aug 24 12:04:45.350: INFO: Pod "security-context-33a8e360-4ae7-43d2-93a4-4b247b4fd873": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031782639s
STEP: Saw pod success
Aug 24 12:04:45.350: INFO: Pod "security-context-33a8e360-4ae7-43d2-93a4-4b247b4fd873" satisfied condition "Succeeded or Failed"
Aug 24 12:04:45.355: INFO: Trying to get logs from node zou9eicaeree-3 pod security-context-33a8e360-4ae7-43d2-93a4-4b247b4fd873 container test-container: <nil>
STEP: delete the pod
Aug 24 12:04:45.377: INFO: Waiting for pod security-context-33a8e360-4ae7-43d2-93a4-4b247b4fd873 to disappear
Aug 24 12:04:45.382: INFO: Pod security-context-33a8e360-4ae7-43d2-93a4-4b247b4fd873 no longer exists
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:04:45.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-1989" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":346,"completed":44,"skipped":626,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:04:45.401: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:04:45.479: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:04:51.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4623" for this suite.

• [SLOW TEST:6.552 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":346,"completed":45,"skipped":654,"failed":0}
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:04:51.953: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 12:04:52.016: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b5be1471-ea6e-42d3-aa58-063ff9de9556" in namespace "downward-api-4131" to be "Succeeded or Failed"
Aug 24 12:04:52.032: INFO: Pod "downwardapi-volume-b5be1471-ea6e-42d3-aa58-063ff9de9556": Phase="Pending", Reason="", readiness=false. Elapsed: 16.184242ms
Aug 24 12:04:54.044: INFO: Pod "downwardapi-volume-b5be1471-ea6e-42d3-aa58-063ff9de9556": Phase="Running", Reason="", readiness=false. Elapsed: 2.02770442s
Aug 24 12:04:56.057: INFO: Pod "downwardapi-volume-b5be1471-ea6e-42d3-aa58-063ff9de9556": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040647887s
STEP: Saw pod success
Aug 24 12:04:56.057: INFO: Pod "downwardapi-volume-b5be1471-ea6e-42d3-aa58-063ff9de9556" satisfied condition "Succeeded or Failed"
Aug 24 12:04:56.061: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-b5be1471-ea6e-42d3-aa58-063ff9de9556 container client-container: <nil>
STEP: delete the pod
Aug 24 12:04:56.095: INFO: Waiting for pod downwardapi-volume-b5be1471-ea6e-42d3-aa58-063ff9de9556 to disappear
Aug 24 12:04:56.100: INFO: Pod downwardapi-volume-b5be1471-ea6e-42d3-aa58-063ff9de9556 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:04:56.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4131" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":46,"skipped":654,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:04:56.126: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating secret with name secret-test-289f8fa6-8f6a-4111-a3a7-74e7cf86cc62
STEP: Creating a pod to test consume secrets
Aug 24 12:04:56.232: INFO: Waiting up to 5m0s for pod "pod-secrets-dcf27012-16ec-401a-80e3-b91b8e2bf5c5" in namespace "secrets-4729" to be "Succeeded or Failed"
Aug 24 12:04:56.244: INFO: Pod "pod-secrets-dcf27012-16ec-401a-80e3-b91b8e2bf5c5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.693893ms
Aug 24 12:04:58.261: INFO: Pod "pod-secrets-dcf27012-16ec-401a-80e3-b91b8e2bf5c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028977037s
Aug 24 12:05:00.274: INFO: Pod "pod-secrets-dcf27012-16ec-401a-80e3-b91b8e2bf5c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041533917s
STEP: Saw pod success
Aug 24 12:05:00.274: INFO: Pod "pod-secrets-dcf27012-16ec-401a-80e3-b91b8e2bf5c5" satisfied condition "Succeeded or Failed"
Aug 24 12:05:00.278: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-secrets-dcf27012-16ec-401a-80e3-b91b8e2bf5c5 container secret-volume-test: <nil>
STEP: delete the pod
Aug 24 12:05:00.313: INFO: Waiting for pod pod-secrets-dcf27012-16ec-401a-80e3-b91b8e2bf5c5 to disappear
Aug 24 12:05:00.322: INFO: Pod pod-secrets-dcf27012-16ec-401a-80e3-b91b8e2bf5c5 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:05:00.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4729" for this suite.
STEP: Destroying namespace "secret-namespace-4000" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":346,"completed":47,"skipped":697,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:05:00.356: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Create set of events
Aug 24 12:05:00.419: INFO: created test-event-1
Aug 24 12:05:00.428: INFO: created test-event-2
Aug 24 12:05:00.433: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace
STEP: delete collection of events
Aug 24 12:05:00.447: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
Aug 24 12:05:00.497: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:05:00.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7857" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","total":346,"completed":48,"skipped":742,"failed":0}
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:05:00.524: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:05:00.625: INFO: Create a RollingUpdate DaemonSet
Aug 24 12:05:00.634: INFO: Check that daemon pods launch on every node of the cluster
Aug 24 12:05:00.647: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 12:05:00.647: INFO: Node zou9eicaeree-1 is running 0 daemon pod, expected 1
Aug 24 12:05:01.671: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 12:05:01.672: INFO: Node zou9eicaeree-1 is running 0 daemon pod, expected 1
Aug 24 12:05:02.664: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 12:05:02.665: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Aug 24 12:05:02.665: INFO: Update the DaemonSet to trigger a rollout
Aug 24 12:05:02.680: INFO: Updating DaemonSet daemon-set
Aug 24 12:05:05.744: INFO: Roll back the DaemonSet before rollout is complete
Aug 24 12:05:05.768: INFO: Updating DaemonSet daemon-set
Aug 24 12:05:05.768: INFO: Make sure DaemonSet rollback is complete
Aug 24 12:05:05.778: INFO: Wrong image for pod: daemon-set-gwscd. Expected: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Aug 24 12:05:05.778: INFO: Pod daemon-set-gwscd is not available
Aug 24 12:05:10.836: INFO: Pod daemon-set-mvrhp is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5946, will wait for the garbage collector to delete the pods
Aug 24 12:05:10.933: INFO: Deleting DaemonSet.extensions daemon-set took: 9.741688ms
Aug 24 12:05:11.034: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.847227ms
Aug 24 12:05:13.949: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 12:05:13.949: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 24 12:05:13.954: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24589"},"items":null}

Aug 24 12:05:13.958: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24589"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:05:13.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5946" for this suite.

• [SLOW TEST:13.473 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":346,"completed":49,"skipped":745,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:05:13.998: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:164
Aug 24 12:05:14.041: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 24 12:06:14.085: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:06:14.092: INFO: Starting informer...
STEP: Starting pod...
Aug 24 12:06:14.324: INFO: Pod is running on zou9eicaeree-3. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Aug 24 12:06:14.379: INFO: Pod wasn't evicted. Proceeding
Aug 24 12:06:14.379: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Aug 24 12:07:29.420: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:07:29.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-5091" for this suite.

• [SLOW TEST:135.453 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":346,"completed":50,"skipped":770,"failed":0}
SS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:07:29.455: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1048.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1048.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1048.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1048.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 24 12:07:31.642: INFO: DNS probes using dns-1048/dns-test-2fcbec75-6017-4c57-9c5d-d4cad78cb9dc succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:07:31.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1048" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":346,"completed":51,"skipped":772,"failed":0}
SSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:36
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:07:31.756: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:65
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl
STEP: Watching for error events or started pod
STEP: Waiting for pod completion
STEP: Checking that the pod succeeded
STEP: Getting logs from the pod
STEP: Checking that the sysctl is actually updated
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:07:35.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-7964" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":346,"completed":52,"skipped":775,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:07:35.927: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 12:07:36.920: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 12:07:39.957: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Aug 24 12:07:40.012: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:07:40.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8162" for this suite.
STEP: Destroying namespace "webhook-8162-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":346,"completed":53,"skipped":858,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:07:40.217: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 12:07:40.348: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cd8fc73b-1ed6-4532-b70c-5158d67ed527" in namespace "downward-api-6179" to be "Succeeded or Failed"
Aug 24 12:07:40.355: INFO: Pod "downwardapi-volume-cd8fc73b-1ed6-4532-b70c-5158d67ed527": Phase="Pending", Reason="", readiness=false. Elapsed: 6.732811ms
Aug 24 12:07:42.377: INFO: Pod "downwardapi-volume-cd8fc73b-1ed6-4532-b70c-5158d67ed527": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028599207s
Aug 24 12:07:44.404: INFO: Pod "downwardapi-volume-cd8fc73b-1ed6-4532-b70c-5158d67ed527": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055955726s
STEP: Saw pod success
Aug 24 12:07:44.404: INFO: Pod "downwardapi-volume-cd8fc73b-1ed6-4532-b70c-5158d67ed527" satisfied condition "Succeeded or Failed"
Aug 24 12:07:44.409: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-cd8fc73b-1ed6-4532-b70c-5158d67ed527 container client-container: <nil>
STEP: delete the pod
Aug 24 12:07:44.466: INFO: Waiting for pod downwardapi-volume-cd8fc73b-1ed6-4532-b70c-5158d67ed527 to disappear
Aug 24 12:07:44.475: INFO: Pod downwardapi-volume-cd8fc73b-1ed6-4532-b70c-5158d67ed527 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:07:44.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6179" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":54,"skipped":873,"failed":0}
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:07:44.500: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:07:44.549: INFO: Got root ca configmap in namespace "svcaccounts-8499"
Aug 24 12:07:44.557: INFO: Deleted root ca configmap in namespace "svcaccounts-8499"
STEP: waiting for a new root ca configmap created
Aug 24 12:07:45.067: INFO: Recreated root ca configmap in namespace "svcaccounts-8499"
Aug 24 12:07:45.087: INFO: Updated root ca configmap in namespace "svcaccounts-8499"
STEP: waiting for the root ca configmap reconciled
Aug 24 12:07:45.607: INFO: Reconciled root ca configmap in namespace "svcaccounts-8499"
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:07:45.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8499" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","total":346,"completed":55,"skipped":883,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:07:45.656: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Aug 24 12:07:45.715: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Registering the sample API server.
Aug 24 12:07:46.626: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Aug 24 12:07:48.703: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 12:07:50.723: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 12:07:52.718: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 12:07:54.715: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 12:07:56.715: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 12:07:58.713: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 12:08:00.716: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 12:08:02.716: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 7, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7b4b967944\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 12:08:09.557: INFO: Waited 4.822121655s for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}'
STEP: List APIServices
Aug 24 12:08:09.687: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:08:10.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-144" for this suite.

• [SLOW TEST:24.439 seconds]
[sig-api-machinery] Aggregator
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":346,"completed":56,"skipped":917,"failed":0}
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:08:10.097: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 24 12:08:13.244: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:08:13.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5688" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]","total":346,"completed":57,"skipped":924,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:08:13.287: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name configmap-test-volume-1af2eb54-51f5-464a-88aa-822605ffb815
STEP: Creating a pod to test consume configMaps
Aug 24 12:08:13.352: INFO: Waiting up to 5m0s for pod "pod-configmaps-5d89138a-c358-488c-88be-51ccb5dbceab" in namespace "configmap-3635" to be "Succeeded or Failed"
Aug 24 12:08:13.367: INFO: Pod "pod-configmaps-5d89138a-c358-488c-88be-51ccb5dbceab": Phase="Pending", Reason="", readiness=false. Elapsed: 14.871705ms
Aug 24 12:08:15.385: INFO: Pod "pod-configmaps-5d89138a-c358-488c-88be-51ccb5dbceab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033370691s
Aug 24 12:08:17.402: INFO: Pod "pod-configmaps-5d89138a-c358-488c-88be-51ccb5dbceab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049947374s
STEP: Saw pod success
Aug 24 12:08:17.402: INFO: Pod "pod-configmaps-5d89138a-c358-488c-88be-51ccb5dbceab" satisfied condition "Succeeded or Failed"
Aug 24 12:08:17.410: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-configmaps-5d89138a-c358-488c-88be-51ccb5dbceab container agnhost-container: <nil>
STEP: delete the pod
Aug 24 12:08:17.450: INFO: Waiting for pod pod-configmaps-5d89138a-c358-488c-88be-51ccb5dbceab to disappear
Aug 24 12:08:17.456: INFO: Pod pod-configmaps-5d89138a-c358-488c-88be-51ccb5dbceab no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:08:17.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3635" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":58,"skipped":946,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:08:17.477: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:08:17.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9090" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":346,"completed":59,"skipped":960,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:08:17.563: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 24 12:08:17.656: INFO: Waiting up to 5m0s for pod "pod-7d99feab-d268-491c-9e8c-c4466a3f4bcb" in namespace "emptydir-2921" to be "Succeeded or Failed"
Aug 24 12:08:17.660: INFO: Pod "pod-7d99feab-d268-491c-9e8c-c4466a3f4bcb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.566177ms
Aug 24 12:08:19.670: INFO: Pod "pod-7d99feab-d268-491c-9e8c-c4466a3f4bcb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014174656s
Aug 24 12:08:21.683: INFO: Pod "pod-7d99feab-d268-491c-9e8c-c4466a3f4bcb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027409675s
STEP: Saw pod success
Aug 24 12:08:21.684: INFO: Pod "pod-7d99feab-d268-491c-9e8c-c4466a3f4bcb" satisfied condition "Succeeded or Failed"
Aug 24 12:08:21.688: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-7d99feab-d268-491c-9e8c-c4466a3f4bcb container test-container: <nil>
STEP: delete the pod
Aug 24 12:08:21.717: INFO: Waiting for pod pod-7d99feab-d268-491c-9e8c-c4466a3f4bcb to disappear
Aug 24 12:08:21.722: INFO: Pod pod-7d99feab-d268-491c-9e8c-c4466a3f4bcb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:08:21.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2921" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":60,"skipped":978,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:08:21.737: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 24 12:08:21.799: INFO: Waiting up to 5m0s for pod "pod-bff7851d-a07c-49bc-94dc-b5e4eaad22b9" in namespace "emptydir-5336" to be "Succeeded or Failed"
Aug 24 12:08:21.816: INFO: Pod "pod-bff7851d-a07c-49bc-94dc-b5e4eaad22b9": Phase="Pending", Reason="", readiness=false. Elapsed: 17.004674ms
Aug 24 12:08:23.829: INFO: Pod "pod-bff7851d-a07c-49bc-94dc-b5e4eaad22b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030209401s
Aug 24 12:08:25.843: INFO: Pod "pod-bff7851d-a07c-49bc-94dc-b5e4eaad22b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04403918s
STEP: Saw pod success
Aug 24 12:08:25.843: INFO: Pod "pod-bff7851d-a07c-49bc-94dc-b5e4eaad22b9" satisfied condition "Succeeded or Failed"
Aug 24 12:08:25.849: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-bff7851d-a07c-49bc-94dc-b5e4eaad22b9 container test-container: <nil>
STEP: delete the pod
Aug 24 12:08:25.873: INFO: Waiting for pod pod-bff7851d-a07c-49bc-94dc-b5e4eaad22b9 to disappear
Aug 24 12:08:25.879: INFO: Pod pod-bff7851d-a07c-49bc-94dc-b5e4eaad22b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:08:25.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5336" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":61,"skipped":980,"failed":0}
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:08:25.896: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: getting the auto-created API token
Aug 24 12:08:26.493: INFO: created pod pod-service-account-defaultsa
Aug 24 12:08:26.493: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 24 12:08:26.507: INFO: created pod pod-service-account-mountsa
Aug 24 12:08:26.507: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 24 12:08:26.521: INFO: created pod pod-service-account-nomountsa
Aug 24 12:08:26.521: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 24 12:08:26.534: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 24 12:08:26.534: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 24 12:08:26.543: INFO: created pod pod-service-account-mountsa-mountspec
Aug 24 12:08:26.543: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 24 12:08:26.565: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 24 12:08:26.565: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 24 12:08:26.573: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 24 12:08:26.573: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 24 12:08:26.585: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 24 12:08:26.585: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 24 12:08:26.644: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 24 12:08:26.644: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:08:26.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5268" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":346,"completed":62,"skipped":988,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should support CronJob API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:08:26.694: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support CronJob API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a cronjob
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Aug 24 12:08:26.928: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Aug 24 12:08:26.941: INFO: starting watch
STEP: patching
STEP: updating
Aug 24 12:08:27.016: INFO: waiting for watch events with expected annotations
Aug 24 12:08:27.016: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:08:27.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4921" for this suite.
•{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","total":346,"completed":63,"skipped":1032,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:08:27.220: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating the pod
STEP: submitting the pod to kubernetes
Aug 24 12:08:27.424: INFO: The status of Pod pod-update-activedeadlineseconds-1e449398-6a3c-495a-b77f-db2563971b8b is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:08:29.436: INFO: The status of Pod pod-update-activedeadlineseconds-1e449398-6a3c-495a-b77f-db2563971b8b is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 24 12:08:29.968: INFO: Successfully updated pod "pod-update-activedeadlineseconds-1e449398-6a3c-495a-b77f-db2563971b8b"
Aug 24 12:08:29.968: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-1e449398-6a3c-495a-b77f-db2563971b8b" in namespace "pods-3994" to be "terminated due to deadline exceeded"
Aug 24 12:08:29.976: INFO: Pod "pod-update-activedeadlineseconds-1e449398-6a3c-495a-b77f-db2563971b8b": Phase="Running", Reason="", readiness=true. Elapsed: 7.069458ms
Aug 24 12:08:32.001: INFO: Pod "pod-update-activedeadlineseconds-1e449398-6a3c-495a-b77f-db2563971b8b": Phase="Running", Reason="", readiness=true. Elapsed: 2.032551168s
Aug 24 12:08:34.014: INFO: Pod "pod-update-activedeadlineseconds-1e449398-6a3c-495a-b77f-db2563971b8b": Phase="Running", Reason="", readiness=false. Elapsed: 4.04525518s
Aug 24 12:08:36.030: INFO: Pod "pod-update-activedeadlineseconds-1e449398-6a3c-495a-b77f-db2563971b8b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.061745731s
Aug 24 12:08:36.030: INFO: Pod "pod-update-activedeadlineseconds-1e449398-6a3c-495a-b77f-db2563971b8b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:08:36.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3994" for this suite.

• [SLOW TEST:8.833 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":346,"completed":64,"skipped":1046,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:08:36.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating replication controller my-hostname-basic-399bfa0c-c9f4-4c70-b5aa-31926658415b
Aug 24 12:08:36.109: INFO: Pod name my-hostname-basic-399bfa0c-c9f4-4c70-b5aa-31926658415b: Found 0 pods out of 1
Aug 24 12:08:41.123: INFO: Pod name my-hostname-basic-399bfa0c-c9f4-4c70-b5aa-31926658415b: Found 1 pods out of 1
Aug 24 12:08:41.123: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-399bfa0c-c9f4-4c70-b5aa-31926658415b" are running
Aug 24 12:08:41.128: INFO: Pod "my-hostname-basic-399bfa0c-c9f4-4c70-b5aa-31926658415b-w8wsn" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 12:08:36 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 12:08:37 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 12:08:37 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 12:08:36 +0000 UTC Reason: Message:}])
Aug 24 12:08:41.128: INFO: Trying to dial the pod
Aug 24 12:08:46.170: INFO: Controller my-hostname-basic-399bfa0c-c9f4-4c70-b5aa-31926658415b: Got expected result from replica 1 [my-hostname-basic-399bfa0c-c9f4-4c70-b5aa-31926658415b-w8wsn]: "my-hostname-basic-399bfa0c-c9f4-4c70-b5aa-31926658415b-w8wsn", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:08:46.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5232" for this suite.

• [SLOW TEST:10.142 seconds]
[sig-apps] ReplicationController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":346,"completed":65,"skipped":1060,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should run through a ConfigMap lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:08:46.199: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run through a ConfigMap lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a ConfigMap
STEP: fetching the ConfigMap
STEP: patching the ConfigMap
STEP: listing all ConfigMaps in all namespaces with a label selector
STEP: deleting the ConfigMap by collection with a label selector
STEP: listing all ConfigMaps in test namespace
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:08:46.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7613" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","total":346,"completed":66,"skipped":1072,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:08:46.305: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should find a service from listing all namespaces [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:08:46.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5879" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":346,"completed":67,"skipped":1075,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:08:46.377: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name projected-configmap-test-volume-map-fbb124c4-cf1f-4efa-90ba-af3d15c21ac1
STEP: Creating a pod to test consume configMaps
Aug 24 12:08:46.433: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4f5e48db-5fe8-4a48-a213-776bd170b3c8" in namespace "projected-2797" to be "Succeeded or Failed"
Aug 24 12:08:46.440: INFO: Pod "pod-projected-configmaps-4f5e48db-5fe8-4a48-a213-776bd170b3c8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.505947ms
Aug 24 12:08:48.453: INFO: Pod "pod-projected-configmaps-4f5e48db-5fe8-4a48-a213-776bd170b3c8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019216289s
Aug 24 12:08:50.463: INFO: Pod "pod-projected-configmaps-4f5e48db-5fe8-4a48-a213-776bd170b3c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029271694s
STEP: Saw pod success
Aug 24 12:08:50.463: INFO: Pod "pod-projected-configmaps-4f5e48db-5fe8-4a48-a213-776bd170b3c8" satisfied condition "Succeeded or Failed"
Aug 24 12:08:50.468: INFO: Trying to get logs from node zou9eicaeree-1 pod pod-projected-configmaps-4f5e48db-5fe8-4a48-a213-776bd170b3c8 container agnhost-container: <nil>
STEP: delete the pod
Aug 24 12:08:50.516: INFO: Waiting for pod pod-projected-configmaps-4f5e48db-5fe8-4a48-a213-776bd170b3c8 to disappear
Aug 24 12:08:50.521: INFO: Pod pod-projected-configmaps-4f5e48db-5fe8-4a48-a213-776bd170b3c8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:08:50.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2797" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":68,"skipped":1140,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:08:50.538: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename hostport
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/hostport.go:47
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled
Aug 24 12:08:50.617: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:08:52.632: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.121.241 on the node which pod1 resides and expect scheduled
Aug 24 12:08:52.645: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:08:54.659: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.121.241 but use UDP protocol on the node which pod2 resides
Aug 24 12:08:54.681: INFO: The status of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:08:56.700: INFO: The status of Pod pod3 is Running (Ready = true)
Aug 24 12:08:56.721: INFO: The status of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:08:58.733: INFO: The status of Pod e2e-host-exec is Running (Ready = true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323
Aug 24 12:08:58.738: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.121.241 http://127.0.0.1:54323/hostname] Namespace:hostport-3749 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:08:58.738: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:08:58.740: INFO: ExecWithOptions: Clientset creation
Aug 24 12:08:58.740: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-3749/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.121.241+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true %!s(MISSING))
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.241, port: 54323
Aug 24 12:08:58.915: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.121.241:54323/hostname] Namespace:hostport-3749 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:08:58.915: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:08:58.916: INFO: ExecWithOptions: Clientset creation
Aug 24 12:08:58.917: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-3749/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.121.241%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true %!s(MISSING))
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.121.241, port: 54323 UDP
Aug 24 12:08:59.139: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vuz -w 5 192.168.121.241 54323] Namespace:hostport-3749 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:08:59.139: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:08:59.141: INFO: ExecWithOptions: Clientset creation
Aug 24 12:08:59.141: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-3749/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=nc+-vuz+-w+5+192.168.121.241+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true %!s(MISSING))
[AfterEach] [sig-network] HostPort
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:09:04.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-3749" for this suite.

• [SLOW TEST:13.768 seconds]
[sig-network] HostPort
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","total":346,"completed":69,"skipped":1162,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  should run the lifecycle of a Deployment [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:09:04.308: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] should run the lifecycle of a Deployment [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a Deployment
STEP: waiting for Deployment to be created
STEP: waiting for all Replicas to be Ready
Aug 24 12:09:04.400: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 12:09:04.401: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 12:09:04.426: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 12:09:04.426: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 12:09:04.488: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 12:09:04.489: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 12:09:04.532: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 12:09:04.532: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Aug 24 12:09:05.695: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Aug 24 12:09:05.695: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Aug 24 12:09:06.083: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment
Aug 24 12:09:06.105: INFO: observed event type ADDED
STEP: waiting for Replicas to scale
Aug 24 12:09:06.107: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0
Aug 24 12:09:06.107: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0
Aug 24 12:09:06.107: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0
Aug 24 12:09:06.107: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0
Aug 24 12:09:06.107: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0
Aug 24 12:09:06.107: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0
Aug 24 12:09:06.108: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0
Aug 24 12:09:06.108: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 0
Aug 24 12:09:06.108: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1
Aug 24 12:09:06.108: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1
Aug 24 12:09:06.108: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:06.108: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:06.108: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:06.108: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:06.126: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:06.126: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:06.184: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:06.184: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:06.199: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:06.199: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:06.213: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1
Aug 24 12:09:06.213: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1
Aug 24 12:09:07.112: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:07.112: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:07.138: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1
STEP: listing Deployments
Aug 24 12:09:07.147: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment
Aug 24 12:09:07.183: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1
STEP: fetching the DeploymentStatus
Aug 24 12:09:07.197: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 12:09:07.231: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 12:09:07.285: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 12:09:07.332: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 12:09:07.355: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 12:09:08.173: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 12:09:08.222: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 12:09:08.283: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 12:09:08.302: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Aug 24 12:09:09.779: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus
STEP: fetching the DeploymentStatus
Aug 24 12:09:09.913: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1
Aug 24 12:09:09.913: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1
Aug 24 12:09:09.913: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1
Aug 24 12:09:09.914: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1
Aug 24 12:09:09.914: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 1
Aug 24 12:09:09.914: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:09.914: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:09.914: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:09.914: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 2
Aug 24 12:09:09.914: INFO: observed Deployment test-deployment in namespace deployment-2442 with ReadyReplicas 3
STEP: deleting the Deployment
Aug 24 12:09:09.947: INFO: observed event type MODIFIED
Aug 24 12:09:09.948: INFO: observed event type MODIFIED
Aug 24 12:09:09.948: INFO: observed event type MODIFIED
Aug 24 12:09:09.948: INFO: observed event type MODIFIED
Aug 24 12:09:09.948: INFO: observed event type MODIFIED
Aug 24 12:09:09.948: INFO: observed event type MODIFIED
Aug 24 12:09:09.949: INFO: observed event type MODIFIED
Aug 24 12:09:09.949: INFO: observed event type MODIFIED
Aug 24 12:09:09.949: INFO: observed event type MODIFIED
Aug 24 12:09:09.953: INFO: observed event type MODIFIED
Aug 24 12:09:09.953: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Aug 24 12:09:09.973: INFO: Log out all the ReplicaSets if there is no deployment created
Aug 24 12:09:09.986: INFO: ReplicaSet "test-deployment-5ddd8b47d8":
&ReplicaSet{ObjectMeta:{test-deployment-5ddd8b47d8  deployment-2442  cc76e920-e441-42aa-85fb-f0803247a719 25869 4 2022-08-24 12:09:06 +0000 UTC <nil> <nil> map[pod-template-hash:5ddd8b47d8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 6e45b56e-8ee2-4554-86bd-e9bc996661bf 0xc003239e67 0xc003239e68}] []  [{kube-controller-manager Update apps/v1 2022-08-24 12:09:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6e45b56e-8ee2-4554-86bd-e9bc996661bf\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 12:09:09 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 5ddd8b47d8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:5ddd8b47d8 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/pause:3.6 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003239ef0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Aug 24 12:09:10.004: INFO: pod: "test-deployment-5ddd8b47d8-nvh6k":
&Pod{ObjectMeta:{test-deployment-5ddd8b47d8-nvh6k test-deployment-5ddd8b47d8- deployment-2442  ead8d39c-d1ca-4350-bdc6-8c65b1688922 25862 0 2022-08-24 12:09:06 +0000 UTC 2022-08-24 12:09:10 +0000 UTC 0xc004c85438 map[pod-template-hash:5ddd8b47d8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-5ddd8b47d8 cc76e920-e441-42aa-85fb-f0803247a719 0xc004c85467 0xc004c85468}] []  [{kube-controller-manager Update v1 2022-08-24 12:09:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc76e920-e441-42aa-85fb-f0803247a719\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 12:09:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dbwkj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/pause:3.6,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dbwkj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:09:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:09:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:09:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:09:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:10.233.66.3,StartTime:2022-08-24 12:09:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 12:09:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/pause:3.6,ImageID:k8s.gcr.io/pause@sha256:3d380ca8864549e74af4b29c10f9cb0956236dfb01c40ca076fb6c37253234db,ContainerID:cri-o://3dd6b7c9c1b2b1b5c442aff475efa3ca9c0fa90a85eca2997f5af55ab5b66a95,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.3,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Aug 24 12:09:10.005: INFO: ReplicaSet "test-deployment-6d7ffcf7fb":
&ReplicaSet{ObjectMeta:{test-deployment-6d7ffcf7fb  deployment-2442  02035106-dc10-4ce4-8dae-1a52c56733b2 25772 3 2022-08-24 12:09:04 +0000 UTC <nil> <nil> map[pod-template-hash:6d7ffcf7fb test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 6e45b56e-8ee2-4554-86bd-e9bc996661bf 0xc003239f67 0xc003239f68}] []  [{kube-controller-manager Update apps/v1 2022-08-24 12:09:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6e45b56e-8ee2-4554-86bd-e9bc996661bf\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 12:09:07 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 6d7ffcf7fb,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:6d7ffcf7fb test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003239ff0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Aug 24 12:09:10.024: INFO: ReplicaSet "test-deployment-854fdc678":
&ReplicaSet{ObjectMeta:{test-deployment-854fdc678  deployment-2442  baef0d45-9e1c-4c01-b5c0-2eecaecc9bde 25857 2 2022-08-24 12:09:07 +0000 UTC <nil> <nil> map[pod-template-hash:854fdc678 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 6e45b56e-8ee2-4554-86bd-e9bc996661bf 0xc0032bc057 0xc0032bc058}] []  [{kube-controller-manager Update apps/v1 2022-08-24 12:09:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6e45b56e-8ee2-4554-86bd-e9bc996661bf\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 12:09:08 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 854fdc678,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:854fdc678 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032bc0e0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Aug 24 12:09:10.035: INFO: pod: "test-deployment-854fdc678-jd7wh":
&Pod{ObjectMeta:{test-deployment-854fdc678-jd7wh test-deployment-854fdc678- deployment-2442  77ff6664-4bd7-4c04-aa01-ee4d4a0841dc 25856 0 2022-08-24 12:09:08 +0000 UTC <nil> <nil> map[pod-template-hash:854fdc678 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-854fdc678 baef0d45-9e1c-4c01-b5c0-2eecaecc9bde 0xc00536a377 0xc00536a378}] []  [{kube-controller-manager Update v1 2022-08-24 12:09:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"baef0d45-9e1c-4c01-b5c0-2eecaecc9bde\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 12:09:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.28\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xlqbg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xlqbg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:09:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:09:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:09:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:09:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.182,PodIP:10.233.65.28,StartTime:2022-08-24 12:09:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 12:09:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://78bd22ed0fbb98e06c6afc12b0de8a974a5a7943876c3718e7d1a9161309c3e2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.65.28,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Aug 24 12:09:10.035: INFO: pod: "test-deployment-854fdc678-lmw7x":
&Pod{ObjectMeta:{test-deployment-854fdc678-lmw7x test-deployment-854fdc678- deployment-2442  410a996e-a90f-4889-90e9-2578282db710 25807 0 2022-08-24 12:09:07 +0000 UTC <nil> <nil> map[pod-template-hash:854fdc678 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-854fdc678 baef0d45-9e1c-4c01-b5c0-2eecaecc9bde 0xc00536a567 0xc00536a568}] []  [{kube-controller-manager Update v1 2022-08-24 12:09:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"baef0d45-9e1c-4c01-b5c0-2eecaecc9bde\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 12:09:08 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.4\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8b6qd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8b6qd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:09:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:09:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:09:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:09:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:10.233.66.4,StartTime:2022-08-24 12:09:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 12:09:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://c4004e2b5184d6fa80d761923d90ddb74807ad39e05ab3910f37328b40bcbecf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.4,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:09:10.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2442" for this suite.

• [SLOW TEST:5.775 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","total":346,"completed":70,"skipped":1177,"failed":0}
S
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:09:10.085: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:09:22.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5479" for this suite.

• [SLOW TEST:12.165 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":346,"completed":71,"skipped":1178,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:09:22.251: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:09:22.289: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:09:23.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8953" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":346,"completed":72,"skipped":1186,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:09:23.356: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 12:09:23.422: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f1693ec7-2a6e-4c1e-9559-c79fc15d5f1b" in namespace "projected-8120" to be "Succeeded or Failed"
Aug 24 12:09:23.434: INFO: Pod "downwardapi-volume-f1693ec7-2a6e-4c1e-9559-c79fc15d5f1b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.356515ms
Aug 24 12:09:25.453: INFO: Pod "downwardapi-volume-f1693ec7-2a6e-4c1e-9559-c79fc15d5f1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031160327s
Aug 24 12:09:27.469: INFO: Pod "downwardapi-volume-f1693ec7-2a6e-4c1e-9559-c79fc15d5f1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047206916s
STEP: Saw pod success
Aug 24 12:09:27.469: INFO: Pod "downwardapi-volume-f1693ec7-2a6e-4c1e-9559-c79fc15d5f1b" satisfied condition "Succeeded or Failed"
Aug 24 12:09:27.475: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-f1693ec7-2a6e-4c1e-9559-c79fc15d5f1b container client-container: <nil>
STEP: delete the pod
Aug 24 12:09:27.524: INFO: Waiting for pod downwardapi-volume-f1693ec7-2a6e-4c1e-9559-c79fc15d5f1b to disappear
Aug 24 12:09:27.537: INFO: Pod downwardapi-volume-f1693ec7-2a6e-4c1e-9559-c79fc15d5f1b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:09:27.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8120" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":346,"completed":73,"skipped":1204,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:09:27.572: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 24 12:09:27.638: INFO: Waiting up to 5m0s for pod "pod-6abb1e30-56fd-473d-b959-03bdda81a548" in namespace "emptydir-219" to be "Succeeded or Failed"
Aug 24 12:09:27.644: INFO: Pod "pod-6abb1e30-56fd-473d-b959-03bdda81a548": Phase="Pending", Reason="", readiness=false. Elapsed: 5.679541ms
Aug 24 12:09:29.653: INFO: Pod "pod-6abb1e30-56fd-473d-b959-03bdda81a548": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014489552s
Aug 24 12:09:31.668: INFO: Pod "pod-6abb1e30-56fd-473d-b959-03bdda81a548": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029384323s
STEP: Saw pod success
Aug 24 12:09:31.668: INFO: Pod "pod-6abb1e30-56fd-473d-b959-03bdda81a548" satisfied condition "Succeeded or Failed"
Aug 24 12:09:31.673: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-6abb1e30-56fd-473d-b959-03bdda81a548 container test-container: <nil>
STEP: delete the pod
Aug 24 12:09:31.705: INFO: Waiting for pod pod-6abb1e30-56fd-473d-b959-03bdda81a548 to disappear
Aug 24 12:09:31.710: INFO: Pod pod-6abb1e30-56fd-473d-b959-03bdda81a548 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:09:31.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-219" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":74,"skipped":1223,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:09:31.725: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:09:31.767: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3382
I0824 12:09:31.785640      16 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3382, replica count: 1
I0824 12:09:32.837243      16 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0824 12:09:33.838309      16 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 12:09:33.961: INFO: Created: latency-svc-7m25c
Aug 24 12:09:33.987: INFO: Got endpoints: latency-svc-7m25c [47.559814ms]
Aug 24 12:09:34.016: INFO: Created: latency-svc-t8c7x
Aug 24 12:09:34.032: INFO: Created: latency-svc-mms8w
Aug 24 12:09:34.033: INFO: Got endpoints: latency-svc-t8c7x [45.822302ms]
Aug 24 12:09:34.051: INFO: Created: latency-svc-dcxzr
Aug 24 12:09:34.055: INFO: Got endpoints: latency-svc-mms8w [67.321873ms]
Aug 24 12:09:34.064: INFO: Created: latency-svc-222gh
Aug 24 12:09:34.087: INFO: Got endpoints: latency-svc-dcxzr [100.200036ms]
Aug 24 12:09:34.094: INFO: Got endpoints: latency-svc-222gh [105.700541ms]
Aug 24 12:09:34.099: INFO: Created: latency-svc-m7k5r
Aug 24 12:09:34.114: INFO: Created: latency-svc-4ck8t
Aug 24 12:09:34.131: INFO: Got endpoints: latency-svc-m7k5r [143.601727ms]
Aug 24 12:09:34.163: INFO: Created: latency-svc-r8svr
Aug 24 12:09:34.164: INFO: Got endpoints: latency-svc-4ck8t [175.478937ms]
Aug 24 12:09:34.167: INFO: Created: latency-svc-z286r
Aug 24 12:09:34.182: INFO: Got endpoints: latency-svc-z286r [193.409538ms]
Aug 24 12:09:34.192: INFO: Got endpoints: latency-svc-r8svr [203.683944ms]
Aug 24 12:09:34.202: INFO: Created: latency-svc-8dhs2
Aug 24 12:09:34.205: INFO: Got endpoints: latency-svc-8dhs2 [216.868133ms]
Aug 24 12:09:34.217: INFO: Created: latency-svc-qjz7k
Aug 24 12:09:34.233: INFO: Created: latency-svc-45fld
Aug 24 12:09:34.239: INFO: Got endpoints: latency-svc-qjz7k [250.191929ms]
Aug 24 12:09:34.259: INFO: Created: latency-svc-9tm75
Aug 24 12:09:34.264: INFO: Got endpoints: latency-svc-45fld [274.6263ms]
Aug 24 12:09:34.271: INFO: Created: latency-svc-45lhk
Aug 24 12:09:34.275: INFO: Got endpoints: latency-svc-9tm75 [285.926043ms]
Aug 24 12:09:34.284: INFO: Got endpoints: latency-svc-45lhk [294.550695ms]
Aug 24 12:09:34.288: INFO: Created: latency-svc-mkjmg
Aug 24 12:09:34.308: INFO: Got endpoints: latency-svc-mkjmg [318.624602ms]
Aug 24 12:09:34.310: INFO: Created: latency-svc-h5vf4
Aug 24 12:09:34.321: INFO: Created: latency-svc-rsrnm
Aug 24 12:09:34.330: INFO: Got endpoints: latency-svc-h5vf4 [341.361241ms]
Aug 24 12:09:34.355: INFO: Created: latency-svc-g4n47
Aug 24 12:09:34.360: INFO: Got endpoints: latency-svc-rsrnm [326.385437ms]
Aug 24 12:09:34.380: INFO: Got endpoints: latency-svc-g4n47 [324.374504ms]
Aug 24 12:09:34.380: INFO: Created: latency-svc-ljb9x
Aug 24 12:09:34.396: INFO: Got endpoints: latency-svc-ljb9x [308.393472ms]
Aug 24 12:09:34.617: INFO: Created: latency-svc-565w7
Aug 24 12:09:34.625: INFO: Created: latency-svc-hgszv
Aug 24 12:09:34.626: INFO: Created: latency-svc-n4vgl
Aug 24 12:09:34.629: INFO: Created: latency-svc-6jm96
Aug 24 12:09:34.629: INFO: Created: latency-svc-79b54
Aug 24 12:09:34.631: INFO: Created: latency-svc-qvddn
Aug 24 12:09:34.632: INFO: Created: latency-svc-7mx6p
Aug 24 12:09:34.633: INFO: Created: latency-svc-gncxq
Aug 24 12:09:34.644: INFO: Created: latency-svc-c46kj
Aug 24 12:09:34.644: INFO: Created: latency-svc-tzzfh
Aug 24 12:09:34.645: INFO: Created: latency-svc-trk9f
Aug 24 12:09:34.646: INFO: Created: latency-svc-6hltm
Aug 24 12:09:34.647: INFO: Created: latency-svc-qc864
Aug 24 12:09:34.649: INFO: Created: latency-svc-gkd4p
Aug 24 12:09:34.650: INFO: Created: latency-svc-8b8dv
Aug 24 12:09:34.680: INFO: Got endpoints: latency-svc-qvddn [515.329156ms]
Aug 24 12:09:34.680: INFO: Got endpoints: latency-svc-hgszv [487.868006ms]
Aug 24 12:09:34.681: INFO: Got endpoints: latency-svc-gncxq [475.670596ms]
Aug 24 12:09:34.681: INFO: Got endpoints: latency-svc-c46kj [442.070389ms]
Aug 24 12:09:34.682: INFO: Got endpoints: latency-svc-79b54 [550.80338ms]
Aug 24 12:09:34.682: INFO: Got endpoints: latency-svc-n4vgl [374.573141ms]
Aug 24 12:09:34.750: INFO: Got endpoints: latency-svc-gkd4p [390.556008ms]
Aug 24 12:09:34.769: INFO: Got endpoints: latency-svc-565w7 [388.904188ms]
Aug 24 12:09:34.770: INFO: Created: latency-svc-rtbds
Aug 24 12:09:34.783: INFO: Got endpoints: latency-svc-6jm96 [519.18938ms]
Aug 24 12:09:34.783: INFO: Got endpoints: latency-svc-6hltm [601.123163ms]
Aug 24 12:09:34.814: INFO: Got endpoints: latency-svc-7mx6p [417.569613ms]
Aug 24 12:09:34.825: INFO: Created: latency-svc-vr66h
Aug 24 12:09:34.825: INFO: Got endpoints: latency-svc-trk9f [731.547895ms]
Aug 24 12:09:34.826: INFO: Got endpoints: latency-svc-qc864 [542.600667ms]
Aug 24 12:09:34.827: INFO: Got endpoints: latency-svc-tzzfh [496.010729ms]
Aug 24 12:09:34.827: INFO: Got endpoints: latency-svc-8b8dv [551.317829ms]
Aug 24 12:09:34.827: INFO: Got endpoints: latency-svc-rtbds [146.921032ms]
Aug 24 12:09:34.829: INFO: Created: latency-svc-mr8pt
Aug 24 12:09:34.842: INFO: Got endpoints: latency-svc-vr66h [160.794783ms]
Aug 24 12:09:34.848: INFO: Got endpoints: latency-svc-mr8pt [167.65739ms]
Aug 24 12:09:34.854: INFO: Created: latency-svc-ntzh6
Aug 24 12:09:34.866: INFO: Got endpoints: latency-svc-ntzh6 [183.72094ms]
Aug 24 12:09:34.947: INFO: Created: latency-svc-744v4
Aug 24 12:09:34.947: INFO: Created: latency-svc-kwvrk
Aug 24 12:09:34.962: INFO: Created: latency-svc-lgd8t
Aug 24 12:09:34.962: INFO: Created: latency-svc-dfh7k
Aug 24 12:09:34.966: INFO: Got endpoints: latency-svc-kwvrk [151.764972ms]
Aug 24 12:09:34.966: INFO: Created: latency-svc-5jjp2
Aug 24 12:09:34.970: INFO: Created: latency-svc-g8tv4
Aug 24 12:09:34.991: INFO: Created: latency-svc-j79gd
Aug 24 12:09:34.991: INFO: Created: latency-svc-68w8m
Aug 24 12:09:34.991: INFO: Created: latency-svc-7q4xx
Aug 24 12:09:34.991: INFO: Created: latency-svc-9k525
Aug 24 12:09:34.991: INFO: Created: latency-svc-5xfbq
Aug 24 12:09:34.992: INFO: Created: latency-svc-7zlwx
Aug 24 12:09:34.992: INFO: Created: latency-svc-x2kzn
Aug 24 12:09:34.992: INFO: Created: latency-svc-d8gk6
Aug 24 12:09:34.992: INFO: Created: latency-svc-hpp77
Aug 24 12:09:34.995: INFO: Got endpoints: latency-svc-744v4 [167.815445ms]
Aug 24 12:09:34.995: INFO: Got endpoints: latency-svc-5jjp2 [167.858227ms]
Aug 24 12:09:34.995: INFO: Got endpoints: latency-svc-g8tv4 [212.215118ms]
Aug 24 12:09:35.007: INFO: Got endpoints: latency-svc-lgd8t [223.583188ms]
Aug 24 12:09:35.007: INFO: Got endpoints: latency-svc-dfh7k [180.984308ms]
Aug 24 12:09:35.008: INFO: Got endpoints: latency-svc-68w8m [160.204174ms]
Aug 24 12:09:35.009: INFO: Got endpoints: latency-svc-5xfbq [166.655826ms]
Aug 24 12:09:35.028: INFO: Created: latency-svc-hw8h8
Aug 24 12:09:35.034: INFO: Got endpoints: latency-svc-7zlwx [207.199704ms]
Aug 24 12:09:35.035: INFO: Got endpoints: latency-svc-7q4xx [352.573831ms]
Aug 24 12:09:35.036: INFO: Got endpoints: latency-svc-d8gk6 [285.380065ms]
Aug 24 12:09:35.044: INFO: Got endpoints: latency-svc-9k525 [362.550147ms]
Aug 24 12:09:35.055: INFO: Got endpoints: latency-svc-hpp77 [188.680627ms]
Aug 24 12:09:35.075: INFO: Got endpoints: latency-svc-x2kzn [249.536309ms]
Aug 24 12:09:35.135: INFO: Got endpoints: latency-svc-j79gd [366.685923ms]
Aug 24 12:09:35.164: INFO: Created: latency-svc-6lf7c
Aug 24 12:09:35.176: INFO: Created: latency-svc-2752n
Aug 24 12:09:35.179: INFO: Created: latency-svc-6d7l4
Aug 24 12:09:35.181: INFO: Created: latency-svc-swzbk
Aug 24 12:09:35.184: INFO: Created: latency-svc-p6dhw
Aug 24 12:09:35.184: INFO: Created: latency-svc-np56f
Aug 24 12:09:35.191: INFO: Created: latency-svc-kv9md
Aug 24 12:09:35.192: INFO: Created: latency-svc-9g7k7
Aug 24 12:09:35.192: INFO: Created: latency-svc-7rnc6
Aug 24 12:09:35.192: INFO: Created: latency-svc-v28sf
Aug 24 12:09:35.193: INFO: Created: latency-svc-9g7ht
Aug 24 12:09:35.193: INFO: Created: latency-svc-95kfc
Aug 24 12:09:35.193: INFO: Created: latency-svc-shpkw
Aug 24 12:09:35.193: INFO: Created: latency-svc-gc5kn
Aug 24 12:09:35.199: INFO: Got endpoints: latency-svc-hw8h8 [233.608317ms]
Aug 24 12:09:35.224: INFO: Created: latency-svc-sxbtb
Aug 24 12:09:35.230: INFO: Got endpoints: latency-svc-6lf7c [221.028736ms]
Aug 24 12:09:35.246: INFO: Created: latency-svc-xv9jl
Aug 24 12:09:35.275: INFO: Got endpoints: latency-svc-2752n [139.209004ms]
Aug 24 12:09:35.293: INFO: Created: latency-svc-6gwns
Aug 24 12:09:35.330: INFO: Got endpoints: latency-svc-p6dhw [335.274341ms]
Aug 24 12:09:35.350: INFO: Created: latency-svc-vr99f
Aug 24 12:09:35.382: INFO: Got endpoints: latency-svc-swzbk [346.482323ms]
Aug 24 12:09:35.398: INFO: Created: latency-svc-nsgc2
Aug 24 12:09:35.426: INFO: Got endpoints: latency-svc-np56f [417.83591ms]
Aug 24 12:09:35.443: INFO: Created: latency-svc-lbz2j
Aug 24 12:09:35.488: INFO: Got endpoints: latency-svc-6d7l4 [412.714008ms]
Aug 24 12:09:35.506: INFO: Created: latency-svc-lcz5d
Aug 24 12:09:35.523: INFO: Got endpoints: latency-svc-9g7k7 [516.060371ms]
Aug 24 12:09:35.549: INFO: Created: latency-svc-vd2nf
Aug 24 12:09:35.578: INFO: Got endpoints: latency-svc-kv9md [583.189437ms]
Aug 24 12:09:35.596: INFO: Created: latency-svc-t9kcw
Aug 24 12:09:35.625: INFO: Got endpoints: latency-svc-95kfc [570.340991ms]
Aug 24 12:09:35.642: INFO: Created: latency-svc-zrk7w
Aug 24 12:09:35.675: INFO: Got endpoints: latency-svc-v28sf [630.795454ms]
Aug 24 12:09:35.694: INFO: Created: latency-svc-lrcs5
Aug 24 12:09:35.727: INFO: Got endpoints: latency-svc-7rnc6 [731.702006ms]
Aug 24 12:09:35.744: INFO: Created: latency-svc-s8m2b
Aug 24 12:09:35.781: INFO: Got endpoints: latency-svc-9g7ht [774.52516ms]
Aug 24 12:09:35.799: INFO: Created: latency-svc-fv8gw
Aug 24 12:09:35.827: INFO: Got endpoints: latency-svc-gc5kn [792.674793ms]
Aug 24 12:09:35.846: INFO: Created: latency-svc-mb4lg
Aug 24 12:09:35.884: INFO: Got endpoints: latency-svc-shpkw [848.296249ms]
Aug 24 12:09:35.904: INFO: Created: latency-svc-p2276
Aug 24 12:09:35.934: INFO: Got endpoints: latency-svc-sxbtb [734.393802ms]
Aug 24 12:09:35.954: INFO: Created: latency-svc-7lfpw
Aug 24 12:09:35.979: INFO: Got endpoints: latency-svc-xv9jl [749.011721ms]
Aug 24 12:09:35.998: INFO: Created: latency-svc-wzh44
Aug 24 12:09:36.031: INFO: Got endpoints: latency-svc-6gwns [755.761676ms]
Aug 24 12:09:36.048: INFO: Created: latency-svc-7kjz2
Aug 24 12:09:36.079: INFO: Got endpoints: latency-svc-vr99f [748.611005ms]
Aug 24 12:09:36.093: INFO: Created: latency-svc-gb5zs
Aug 24 12:09:36.128: INFO: Got endpoints: latency-svc-nsgc2 [744.92219ms]
Aug 24 12:09:36.148: INFO: Created: latency-svc-kg6f8
Aug 24 12:09:36.176: INFO: Got endpoints: latency-svc-lbz2j [749.842131ms]
Aug 24 12:09:36.192: INFO: Created: latency-svc-hjkr6
Aug 24 12:09:36.229: INFO: Got endpoints: latency-svc-lcz5d [741.529503ms]
Aug 24 12:09:36.243: INFO: Created: latency-svc-h6px2
Aug 24 12:09:36.278: INFO: Got endpoints: latency-svc-vd2nf [754.48581ms]
Aug 24 12:09:36.293: INFO: Created: latency-svc-kzjfr
Aug 24 12:09:36.324: INFO: Got endpoints: latency-svc-t9kcw [745.557401ms]
Aug 24 12:09:36.347: INFO: Created: latency-svc-7dghc
Aug 24 12:09:36.380: INFO: Got endpoints: latency-svc-zrk7w [754.56879ms]
Aug 24 12:09:36.394: INFO: Created: latency-svc-9vd4f
Aug 24 12:09:36.427: INFO: Got endpoints: latency-svc-lrcs5 [752.365071ms]
Aug 24 12:09:36.447: INFO: Created: latency-svc-5wklr
Aug 24 12:09:36.476: INFO: Got endpoints: latency-svc-s8m2b [748.606473ms]
Aug 24 12:09:36.494: INFO: Created: latency-svc-46f5w
Aug 24 12:09:36.527: INFO: Got endpoints: latency-svc-fv8gw [745.307831ms]
Aug 24 12:09:36.541: INFO: Created: latency-svc-6dvlc
Aug 24 12:09:36.581: INFO: Got endpoints: latency-svc-mb4lg [753.577585ms]
Aug 24 12:09:36.601: INFO: Created: latency-svc-v7m78
Aug 24 12:09:36.628: INFO: Got endpoints: latency-svc-p2276 [744.480404ms]
Aug 24 12:09:36.650: INFO: Created: latency-svc-d4rp8
Aug 24 12:09:36.676: INFO: Got endpoints: latency-svc-7lfpw [742.336159ms]
Aug 24 12:09:36.695: INFO: Created: latency-svc-4xrr7
Aug 24 12:09:36.727: INFO: Got endpoints: latency-svc-wzh44 [747.976977ms]
Aug 24 12:09:36.755: INFO: Created: latency-svc-6zq27
Aug 24 12:09:36.775: INFO: Got endpoints: latency-svc-7kjz2 [743.406354ms]
Aug 24 12:09:36.792: INFO: Created: latency-svc-48nb4
Aug 24 12:09:36.828: INFO: Got endpoints: latency-svc-gb5zs [748.833605ms]
Aug 24 12:09:36.846: INFO: Created: latency-svc-wtw8q
Aug 24 12:09:36.880: INFO: Got endpoints: latency-svc-kg6f8 [752.68455ms]
Aug 24 12:09:36.903: INFO: Created: latency-svc-6h4rf
Aug 24 12:09:36.934: INFO: Got endpoints: latency-svc-hjkr6 [757.735093ms]
Aug 24 12:09:36.958: INFO: Created: latency-svc-dmvgb
Aug 24 12:09:36.982: INFO: Got endpoints: latency-svc-h6px2 [752.642136ms]
Aug 24 12:09:37.003: INFO: Created: latency-svc-5dztm
Aug 24 12:09:37.032: INFO: Got endpoints: latency-svc-kzjfr [753.829459ms]
Aug 24 12:09:37.056: INFO: Created: latency-svc-c4945
Aug 24 12:09:37.079: INFO: Got endpoints: latency-svc-7dghc [754.775277ms]
Aug 24 12:09:37.168: INFO: Created: latency-svc-x5jnm
Aug 24 12:09:37.168: INFO: Got endpoints: latency-svc-9vd4f [788.101365ms]
Aug 24 12:09:37.187: INFO: Got endpoints: latency-svc-5wklr [759.13187ms]
Aug 24 12:09:37.233: INFO: Got endpoints: latency-svc-46f5w [757.003636ms]
Aug 24 12:09:37.279: INFO: Got endpoints: latency-svc-6dvlc [752.398713ms]
Aug 24 12:09:37.304: INFO: Created: latency-svc-msz8h
Aug 24 12:09:37.314: INFO: Created: latency-svc-jhq7r
Aug 24 12:09:37.333: INFO: Got endpoints: latency-svc-v7m78 [751.849355ms]
Aug 24 12:09:37.353: INFO: Created: latency-svc-czhlv
Aug 24 12:09:37.405: INFO: Got endpoints: latency-svc-d4rp8 [776.487633ms]
Aug 24 12:09:37.405: INFO: Created: latency-svc-wd8ss
Aug 24 12:09:37.412: INFO: Created: latency-svc-cf4vm
Aug 24 12:09:37.440: INFO: Created: latency-svc-tqz9j
Aug 24 12:09:37.442: INFO: Got endpoints: latency-svc-4xrr7 [765.799117ms]
Aug 24 12:09:37.469: INFO: Created: latency-svc-ndld4
Aug 24 12:09:37.479: INFO: Got endpoints: latency-svc-6zq27 [751.592888ms]
Aug 24 12:09:37.500: INFO: Created: latency-svc-hxslg
Aug 24 12:09:37.525: INFO: Got endpoints: latency-svc-48nb4 [750.625231ms]
Aug 24 12:09:37.558: INFO: Created: latency-svc-xgzbc
Aug 24 12:09:37.594: INFO: Got endpoints: latency-svc-wtw8q [765.870815ms]
Aug 24 12:09:37.637: INFO: Created: latency-svc-6mtsf
Aug 24 12:09:37.637: INFO: Got endpoints: latency-svc-6h4rf [756.899942ms]
Aug 24 12:09:37.659: INFO: Created: latency-svc-lddmj
Aug 24 12:09:37.674: INFO: Got endpoints: latency-svc-dmvgb [739.797079ms]
Aug 24 12:09:37.694: INFO: Created: latency-svc-f9gks
Aug 24 12:09:37.728: INFO: Got endpoints: latency-svc-5dztm [746.076919ms]
Aug 24 12:09:37.751: INFO: Created: latency-svc-mh7hq
Aug 24 12:09:37.782: INFO: Got endpoints: latency-svc-c4945 [749.886604ms]
Aug 24 12:09:37.801: INFO: Created: latency-svc-f97kd
Aug 24 12:09:37.827: INFO: Got endpoints: latency-svc-x5jnm [747.986326ms]
Aug 24 12:09:37.844: INFO: Created: latency-svc-vb6dd
Aug 24 12:09:37.879: INFO: Got endpoints: latency-svc-msz8h [711.074072ms]
Aug 24 12:09:37.899: INFO: Created: latency-svc-5dxsl
Aug 24 12:09:37.925: INFO: Got endpoints: latency-svc-jhq7r [738.120759ms]
Aug 24 12:09:37.945: INFO: Created: latency-svc-74xj8
Aug 24 12:09:37.987: INFO: Got endpoints: latency-svc-czhlv [754.121141ms]
Aug 24 12:09:38.006: INFO: Created: latency-svc-wbpgd
Aug 24 12:09:38.032: INFO: Got endpoints: latency-svc-wd8ss [752.521341ms]
Aug 24 12:09:38.050: INFO: Created: latency-svc-96tq5
Aug 24 12:09:38.076: INFO: Got endpoints: latency-svc-cf4vm [742.877265ms]
Aug 24 12:09:38.097: INFO: Created: latency-svc-828bv
Aug 24 12:09:38.130: INFO: Got endpoints: latency-svc-tqz9j [725.194442ms]
Aug 24 12:09:38.152: INFO: Created: latency-svc-rlfcg
Aug 24 12:09:38.183: INFO: Got endpoints: latency-svc-ndld4 [739.982841ms]
Aug 24 12:09:38.211: INFO: Created: latency-svc-9nx2g
Aug 24 12:09:38.227: INFO: Got endpoints: latency-svc-hxslg [747.567838ms]
Aug 24 12:09:38.239: INFO: Created: latency-svc-khb62
Aug 24 12:09:38.282: INFO: Got endpoints: latency-svc-xgzbc [756.697795ms]
Aug 24 12:09:38.301: INFO: Created: latency-svc-wdsd2
Aug 24 12:09:38.330: INFO: Got endpoints: latency-svc-6mtsf [735.589036ms]
Aug 24 12:09:38.343: INFO: Created: latency-svc-w7mnl
Aug 24 12:09:38.382: INFO: Got endpoints: latency-svc-lddmj [744.225286ms]
Aug 24 12:09:38.397: INFO: Created: latency-svc-5qwd6
Aug 24 12:09:38.425: INFO: Got endpoints: latency-svc-f9gks [750.992961ms]
Aug 24 12:09:38.447: INFO: Created: latency-svc-kqx78
Aug 24 12:09:38.474: INFO: Got endpoints: latency-svc-mh7hq [745.084493ms]
Aug 24 12:09:38.487: INFO: Created: latency-svc-xtp4w
Aug 24 12:09:38.528: INFO: Got endpoints: latency-svc-f97kd [746.158864ms]
Aug 24 12:09:38.545: INFO: Created: latency-svc-kbdz4
Aug 24 12:09:38.577: INFO: Got endpoints: latency-svc-vb6dd [749.567593ms]
Aug 24 12:09:38.593: INFO: Created: latency-svc-c5z8d
Aug 24 12:09:38.628: INFO: Got endpoints: latency-svc-5dxsl [748.220836ms]
Aug 24 12:09:38.650: INFO: Created: latency-svc-59f8s
Aug 24 12:09:38.678: INFO: Got endpoints: latency-svc-74xj8 [752.373174ms]
Aug 24 12:09:38.694: INFO: Created: latency-svc-l97pj
Aug 24 12:09:38.725: INFO: Got endpoints: latency-svc-wbpgd [737.597345ms]
Aug 24 12:09:38.743: INFO: Created: latency-svc-2j4dz
Aug 24 12:09:38.779: INFO: Got endpoints: latency-svc-96tq5 [747.172229ms]
Aug 24 12:09:38.811: INFO: Created: latency-svc-qzcgc
Aug 24 12:09:38.833: INFO: Got endpoints: latency-svc-828bv [756.515783ms]
Aug 24 12:09:38.853: INFO: Created: latency-svc-qb892
Aug 24 12:09:38.882: INFO: Got endpoints: latency-svc-rlfcg [752.147022ms]
Aug 24 12:09:38.897: INFO: Created: latency-svc-8xnpc
Aug 24 12:09:38.922: INFO: Got endpoints: latency-svc-9nx2g [739.038194ms]
Aug 24 12:09:38.948: INFO: Created: latency-svc-gdtq7
Aug 24 12:09:38.974: INFO: Got endpoints: latency-svc-khb62 [747.1188ms]
Aug 24 12:09:38.996: INFO: Created: latency-svc-8whdd
Aug 24 12:09:39.025: INFO: Got endpoints: latency-svc-wdsd2 [742.676401ms]
Aug 24 12:09:39.044: INFO: Created: latency-svc-ptxsw
Aug 24 12:09:39.076: INFO: Got endpoints: latency-svc-w7mnl [746.35066ms]
Aug 24 12:09:39.095: INFO: Created: latency-svc-frzfs
Aug 24 12:09:39.128: INFO: Got endpoints: latency-svc-5qwd6 [746.357267ms]
Aug 24 12:09:39.143: INFO: Created: latency-svc-fqd4m
Aug 24 12:09:39.177: INFO: Got endpoints: latency-svc-kqx78 [751.487198ms]
Aug 24 12:09:39.198: INFO: Created: latency-svc-jz94c
Aug 24 12:09:39.227: INFO: Got endpoints: latency-svc-xtp4w [753.068ms]
Aug 24 12:09:39.253: INFO: Created: latency-svc-t4gms
Aug 24 12:09:39.287: INFO: Got endpoints: latency-svc-kbdz4 [758.958119ms]
Aug 24 12:09:39.304: INFO: Created: latency-svc-njgr4
Aug 24 12:09:39.325: INFO: Got endpoints: latency-svc-c5z8d [747.676303ms]
Aug 24 12:09:39.359: INFO: Created: latency-svc-6l6g9
Aug 24 12:09:39.383: INFO: Got endpoints: latency-svc-59f8s [755.178662ms]
Aug 24 12:09:39.399: INFO: Created: latency-svc-nqvlf
Aug 24 12:09:39.423: INFO: Got endpoints: latency-svc-l97pj [745.306898ms]
Aug 24 12:09:39.442: INFO: Created: latency-svc-mr5nn
Aug 24 12:09:39.476: INFO: Got endpoints: latency-svc-2j4dz [751.500539ms]
Aug 24 12:09:39.492: INFO: Created: latency-svc-fxkv4
Aug 24 12:09:39.522: INFO: Got endpoints: latency-svc-qzcgc [743.232606ms]
Aug 24 12:09:39.539: INFO: Created: latency-svc-x4qk5
Aug 24 12:09:39.576: INFO: Got endpoints: latency-svc-qb892 [743.326673ms]
Aug 24 12:09:39.588: INFO: Created: latency-svc-25x8w
Aug 24 12:09:39.625: INFO: Got endpoints: latency-svc-8xnpc [742.662864ms]
Aug 24 12:09:39.650: INFO: Created: latency-svc-txkkh
Aug 24 12:09:39.677: INFO: Got endpoints: latency-svc-gdtq7 [754.665927ms]
Aug 24 12:09:39.699: INFO: Created: latency-svc-vs9c2
Aug 24 12:09:39.727: INFO: Got endpoints: latency-svc-8whdd [753.467279ms]
Aug 24 12:09:39.744: INFO: Created: latency-svc-lhwqt
Aug 24 12:09:39.778: INFO: Got endpoints: latency-svc-ptxsw [753.284038ms]
Aug 24 12:09:39.797: INFO: Created: latency-svc-gfm58
Aug 24 12:09:39.830: INFO: Got endpoints: latency-svc-frzfs [753.603316ms]
Aug 24 12:09:39.849: INFO: Created: latency-svc-2q68q
Aug 24 12:09:39.880: INFO: Got endpoints: latency-svc-fqd4m [751.443004ms]
Aug 24 12:09:39.901: INFO: Created: latency-svc-46vgk
Aug 24 12:09:39.933: INFO: Got endpoints: latency-svc-jz94c [756.006055ms]
Aug 24 12:09:39.950: INFO: Created: latency-svc-cmtqm
Aug 24 12:09:39.976: INFO: Got endpoints: latency-svc-t4gms [747.791062ms]
Aug 24 12:09:39.997: INFO: Created: latency-svc-7z95x
Aug 24 12:09:40.027: INFO: Got endpoints: latency-svc-njgr4 [739.672894ms]
Aug 24 12:09:40.045: INFO: Created: latency-svc-zpls5
Aug 24 12:09:40.082: INFO: Got endpoints: latency-svc-6l6g9 [757.413ms]
Aug 24 12:09:40.101: INFO: Created: latency-svc-b97pp
Aug 24 12:09:40.129: INFO: Got endpoints: latency-svc-nqvlf [745.54887ms]
Aug 24 12:09:40.155: INFO: Created: latency-svc-dnq9j
Aug 24 12:09:40.182: INFO: Got endpoints: latency-svc-mr5nn [758.654248ms]
Aug 24 12:09:40.205: INFO: Created: latency-svc-tdpvp
Aug 24 12:09:40.226: INFO: Got endpoints: latency-svc-fxkv4 [748.97053ms]
Aug 24 12:09:40.246: INFO: Created: latency-svc-7wbnw
Aug 24 12:09:40.282: INFO: Got endpoints: latency-svc-x4qk5 [759.493874ms]
Aug 24 12:09:40.297: INFO: Created: latency-svc-hjcfl
Aug 24 12:09:40.331: INFO: Got endpoints: latency-svc-25x8w [755.259275ms]
Aug 24 12:09:40.350: INFO: Created: latency-svc-rhwd5
Aug 24 12:09:40.377: INFO: Got endpoints: latency-svc-txkkh [751.764069ms]
Aug 24 12:09:40.393: INFO: Created: latency-svc-nkdmt
Aug 24 12:09:40.430: INFO: Got endpoints: latency-svc-vs9c2 [752.846039ms]
Aug 24 12:09:40.458: INFO: Created: latency-svc-664cm
Aug 24 12:09:40.478: INFO: Got endpoints: latency-svc-lhwqt [750.343269ms]
Aug 24 12:09:40.495: INFO: Created: latency-svc-vjxms
Aug 24 12:09:40.538: INFO: Got endpoints: latency-svc-gfm58 [759.56522ms]
Aug 24 12:09:40.557: INFO: Created: latency-svc-hwkdg
Aug 24 12:09:40.581: INFO: Got endpoints: latency-svc-2q68q [750.965936ms]
Aug 24 12:09:40.597: INFO: Created: latency-svc-ttvmh
Aug 24 12:09:40.635: INFO: Got endpoints: latency-svc-46vgk [755.018585ms]
Aug 24 12:09:40.653: INFO: Created: latency-svc-9l5sf
Aug 24 12:09:40.678: INFO: Got endpoints: latency-svc-cmtqm [744.934706ms]
Aug 24 12:09:40.697: INFO: Created: latency-svc-n8crm
Aug 24 12:09:40.739: INFO: Got endpoints: latency-svc-7z95x [763.439569ms]
Aug 24 12:09:40.757: INFO: Created: latency-svc-9vb9z
Aug 24 12:09:40.779: INFO: Got endpoints: latency-svc-zpls5 [751.157621ms]
Aug 24 12:09:40.802: INFO: Created: latency-svc-8vf4h
Aug 24 12:09:40.834: INFO: Got endpoints: latency-svc-b97pp [751.769371ms]
Aug 24 12:09:40.864: INFO: Created: latency-svc-78xv4
Aug 24 12:09:40.879: INFO: Got endpoints: latency-svc-dnq9j [749.655764ms]
Aug 24 12:09:40.896: INFO: Created: latency-svc-h7fjp
Aug 24 12:09:40.929: INFO: Got endpoints: latency-svc-tdpvp [747.331745ms]
Aug 24 12:09:40.946: INFO: Created: latency-svc-cqrrm
Aug 24 12:09:40.979: INFO: Got endpoints: latency-svc-7wbnw [753.451514ms]
Aug 24 12:09:41.002: INFO: Created: latency-svc-dv55n
Aug 24 12:09:41.026: INFO: Got endpoints: latency-svc-hjcfl [744.147539ms]
Aug 24 12:09:41.047: INFO: Created: latency-svc-ml2bt
Aug 24 12:09:41.079: INFO: Got endpoints: latency-svc-rhwd5 [747.568254ms]
Aug 24 12:09:41.106: INFO: Created: latency-svc-sbxrp
Aug 24 12:09:41.132: INFO: Got endpoints: latency-svc-nkdmt [754.486665ms]
Aug 24 12:09:41.177: INFO: Created: latency-svc-2cqs5
Aug 24 12:09:41.193: INFO: Got endpoints: latency-svc-664cm [763.331614ms]
Aug 24 12:09:41.219: INFO: Created: latency-svc-pfbmr
Aug 24 12:09:41.230: INFO: Got endpoints: latency-svc-vjxms [752.352446ms]
Aug 24 12:09:41.262: INFO: Created: latency-svc-zk2wb
Aug 24 12:09:41.297: INFO: Got endpoints: latency-svc-hwkdg [759.271027ms]
Aug 24 12:09:41.316: INFO: Created: latency-svc-92qqj
Aug 24 12:09:41.331: INFO: Got endpoints: latency-svc-ttvmh [750.284018ms]
Aug 24 12:09:41.357: INFO: Created: latency-svc-mpgx7
Aug 24 12:09:41.385: INFO: Got endpoints: latency-svc-9l5sf [749.909694ms]
Aug 24 12:09:41.408: INFO: Created: latency-svc-tf99v
Aug 24 12:09:41.432: INFO: Got endpoints: latency-svc-n8crm [753.282858ms]
Aug 24 12:09:41.447: INFO: Created: latency-svc-66dkv
Aug 24 12:09:41.476: INFO: Got endpoints: latency-svc-9vb9z [736.466769ms]
Aug 24 12:09:41.494: INFO: Created: latency-svc-tpkvf
Aug 24 12:09:41.524: INFO: Got endpoints: latency-svc-8vf4h [745.629934ms]
Aug 24 12:09:41.542: INFO: Created: latency-svc-bh2qh
Aug 24 12:09:41.586: INFO: Got endpoints: latency-svc-78xv4 [751.557807ms]
Aug 24 12:09:41.614: INFO: Created: latency-svc-5f4cp
Aug 24 12:09:41.634: INFO: Got endpoints: latency-svc-h7fjp [754.468492ms]
Aug 24 12:09:41.650: INFO: Created: latency-svc-h2df7
Aug 24 12:09:41.677: INFO: Got endpoints: latency-svc-cqrrm [747.579476ms]
Aug 24 12:09:41.700: INFO: Created: latency-svc-zsqm5
Aug 24 12:09:41.728: INFO: Got endpoints: latency-svc-dv55n [747.83853ms]
Aug 24 12:09:41.744: INFO: Created: latency-svc-dskt7
Aug 24 12:09:41.776: INFO: Got endpoints: latency-svc-ml2bt [749.160098ms]
Aug 24 12:09:41.794: INFO: Created: latency-svc-g2lv9
Aug 24 12:09:41.831: INFO: Got endpoints: latency-svc-sbxrp [751.74289ms]
Aug 24 12:09:41.882: INFO: Got endpoints: latency-svc-2cqs5 [750.184855ms]
Aug 24 12:09:41.931: INFO: Got endpoints: latency-svc-pfbmr [738.073488ms]
Aug 24 12:09:41.989: INFO: Got endpoints: latency-svc-zk2wb [757.829335ms]
Aug 24 12:09:42.034: INFO: Got endpoints: latency-svc-92qqj [736.752177ms]
Aug 24 12:09:42.084: INFO: Got endpoints: latency-svc-mpgx7 [752.203479ms]
Aug 24 12:09:42.135: INFO: Got endpoints: latency-svc-tf99v [750.272056ms]
Aug 24 12:09:42.180: INFO: Got endpoints: latency-svc-66dkv [747.997343ms]
Aug 24 12:09:42.235: INFO: Got endpoints: latency-svc-tpkvf [759.250051ms]
Aug 24 12:09:42.281: INFO: Got endpoints: latency-svc-bh2qh [755.837888ms]
Aug 24 12:09:42.330: INFO: Got endpoints: latency-svc-5f4cp [744.233527ms]
Aug 24 12:09:42.387: INFO: Got endpoints: latency-svc-h2df7 [753.366974ms]
Aug 24 12:09:42.433: INFO: Got endpoints: latency-svc-zsqm5 [756.121112ms]
Aug 24 12:09:42.478: INFO: Got endpoints: latency-svc-dskt7 [750.44575ms]
Aug 24 12:09:42.527: INFO: Got endpoints: latency-svc-g2lv9 [751.189146ms]
Aug 24 12:09:42.528: INFO: Latencies: [45.822302ms 67.321873ms 100.200036ms 105.700541ms 139.209004ms 143.601727ms 146.921032ms 151.764972ms 160.204174ms 160.794783ms 166.655826ms 167.65739ms 167.815445ms 167.858227ms 175.478937ms 180.984308ms 183.72094ms 188.680627ms 193.409538ms 203.683944ms 207.199704ms 212.215118ms 216.868133ms 221.028736ms 223.583188ms 233.608317ms 249.536309ms 250.191929ms 274.6263ms 285.380065ms 285.926043ms 294.550695ms 308.393472ms 318.624602ms 324.374504ms 326.385437ms 335.274341ms 341.361241ms 346.482323ms 352.573831ms 362.550147ms 366.685923ms 374.573141ms 388.904188ms 390.556008ms 412.714008ms 417.569613ms 417.83591ms 442.070389ms 475.670596ms 487.868006ms 496.010729ms 515.329156ms 516.060371ms 519.18938ms 542.600667ms 550.80338ms 551.317829ms 570.340991ms 583.189437ms 601.123163ms 630.795454ms 711.074072ms 725.194442ms 731.547895ms 731.702006ms 734.393802ms 735.589036ms 736.466769ms 736.752177ms 737.597345ms 738.073488ms 738.120759ms 739.038194ms 739.672894ms 739.797079ms 739.982841ms 741.529503ms 742.336159ms 742.662864ms 742.676401ms 742.877265ms 743.232606ms 743.326673ms 743.406354ms 744.147539ms 744.225286ms 744.233527ms 744.480404ms 744.92219ms 744.934706ms 745.084493ms 745.306898ms 745.307831ms 745.54887ms 745.557401ms 745.629934ms 746.076919ms 746.158864ms 746.35066ms 746.357267ms 747.1188ms 747.172229ms 747.331745ms 747.567838ms 747.568254ms 747.579476ms 747.676303ms 747.791062ms 747.83853ms 747.976977ms 747.986326ms 747.997343ms 748.220836ms 748.606473ms 748.611005ms 748.833605ms 748.97053ms 749.011721ms 749.160098ms 749.567593ms 749.655764ms 749.842131ms 749.886604ms 749.909694ms 750.184855ms 750.272056ms 750.284018ms 750.343269ms 750.44575ms 750.625231ms 750.965936ms 750.992961ms 751.157621ms 751.189146ms 751.443004ms 751.487198ms 751.500539ms 751.557807ms 751.592888ms 751.74289ms 751.764069ms 751.769371ms 751.849355ms 752.147022ms 752.203479ms 752.352446ms 752.365071ms 752.373174ms 752.398713ms 752.521341ms 752.642136ms 752.68455ms 752.846039ms 753.068ms 753.282858ms 753.284038ms 753.366974ms 753.451514ms 753.467279ms 753.577585ms 753.603316ms 753.829459ms 754.121141ms 754.468492ms 754.48581ms 754.486665ms 754.56879ms 754.665927ms 754.775277ms 755.018585ms 755.178662ms 755.259275ms 755.761676ms 755.837888ms 756.006055ms 756.121112ms 756.515783ms 756.697795ms 756.899942ms 757.003636ms 757.413ms 757.735093ms 757.829335ms 758.654248ms 758.958119ms 759.13187ms 759.250051ms 759.271027ms 759.493874ms 759.56522ms 763.331614ms 763.439569ms 765.799117ms 765.870815ms 774.52516ms 776.487633ms 788.101365ms 792.674793ms 848.296249ms]
Aug 24 12:09:42.528: INFO: 50 %ile: 746.357267ms
Aug 24 12:09:42.528: INFO: 90 %ile: 757.003636ms
Aug 24 12:09:42.528: INFO: 99 %ile: 792.674793ms
Aug 24 12:09:42.528: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:09:42.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3382" for this suite.

• [SLOW TEST:10.838 seconds]
[sig-network] Service endpoints latency
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":346,"completed":75,"skipped":1235,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:09:42.567: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Creating a NodePort Service
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota
STEP: Ensuring resource quota status captures service creation
STEP: Deleting Services
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:09:54.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2320" for this suite.

• [SLOW TEST:11.530 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":346,"completed":76,"skipped":1240,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:09:54.104: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward api env vars
Aug 24 12:09:54.215: INFO: Waiting up to 5m0s for pod "downward-api-436195c1-2a4b-4b23-aa9d-deab099b4234" in namespace "downward-api-7262" to be "Succeeded or Failed"
Aug 24 12:09:54.230: INFO: Pod "downward-api-436195c1-2a4b-4b23-aa9d-deab099b4234": Phase="Pending", Reason="", readiness=false. Elapsed: 14.847633ms
Aug 24 12:09:56.244: INFO: Pod "downward-api-436195c1-2a4b-4b23-aa9d-deab099b4234": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028540482s
Aug 24 12:09:58.256: INFO: Pod "downward-api-436195c1-2a4b-4b23-aa9d-deab099b4234": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040530418s
STEP: Saw pod success
Aug 24 12:09:58.256: INFO: Pod "downward-api-436195c1-2a4b-4b23-aa9d-deab099b4234" satisfied condition "Succeeded or Failed"
Aug 24 12:09:58.261: INFO: Trying to get logs from node zou9eicaeree-3 pod downward-api-436195c1-2a4b-4b23-aa9d-deab099b4234 container dapi-container: <nil>
STEP: delete the pod
Aug 24 12:09:58.297: INFO: Waiting for pod downward-api-436195c1-2a4b-4b23-aa9d-deab099b4234 to disappear
Aug 24 12:09:58.302: INFO: Pod downward-api-436195c1-2a4b-4b23-aa9d-deab099b4234 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:09:58.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7262" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":346,"completed":77,"skipped":1260,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:09:58.323: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating the pod
STEP: submitting the pod to kubernetes
Aug 24 12:09:58.387: INFO: The status of Pod pod-update-5491fc7b-b373-4cd7-9117-d18e8861984c is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:10:00.402: INFO: The status of Pod pod-update-5491fc7b-b373-4cd7-9117-d18e8861984c is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:10:02.400: INFO: The status of Pod pod-update-5491fc7b-b373-4cd7-9117-d18e8861984c is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:10:04.402: INFO: The status of Pod pod-update-5491fc7b-b373-4cd7-9117-d18e8861984c is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 24 12:10:04.940: INFO: Successfully updated pod "pod-update-5491fc7b-b373-4cd7-9117-d18e8861984c"
STEP: verifying the updated pod is in kubernetes
Aug 24 12:10:04.950: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:10:04.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9848" for this suite.

• [SLOW TEST:6.645 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","total":346,"completed":78,"skipped":1271,"failed":0}
SS
------------------------------
[sig-api-machinery] server version 
  should find the server version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] server version
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:10:04.969: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename server-version
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should find the server version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Request ServerVersion
STEP: Confirm major version
Aug 24 12:10:05.014: INFO: Major version: 1
STEP: Confirm minor version
Aug 24 12:10:05.014: INFO: cleanMinorVersion: 23
Aug 24 12:10:05.014: INFO: Minor version: 23
[AfterEach] [sig-api-machinery] server version
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:10:05.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-3876" for this suite.
•{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","total":346,"completed":79,"skipped":1273,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:10:05.034: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating pod liveness-683f4d5e-3c7d-4000-8bea-0a10aaefc188 in namespace container-probe-4322
Aug 24 12:10:07.212: INFO: Started pod liveness-683f4d5e-3c7d-4000-8bea-0a10aaefc188 in namespace container-probe-4322
STEP: checking the pod's current state and verifying that restartCount is present
Aug 24 12:10:07.218: INFO: Initial restart count of pod liveness-683f4d5e-3c7d-4000-8bea-0a10aaefc188 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:14:09.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4322" for this suite.

• [SLOW TEST:244.019 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":346,"completed":80,"skipped":1298,"failed":0}
SSSSSSS
------------------------------
[sig-node] Pods 
  should delete a collection of pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:14:09.053: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should delete a collection of pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Create set of pods
Aug 24 12:14:09.175: INFO: created test-pod-1
Aug 24 12:14:09.184: INFO: created test-pod-2
Aug 24 12:14:09.192: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running
Aug 24 12:14:09.192: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-3989' to be running and ready
Aug 24 12:14:09.258: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 24 12:14:09.259: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 24 12:14:09.259: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Aug 24 12:14:09.260: INFO: 0 / 3 pods in namespace 'pods-3989' are running and ready (0 seconds elapsed)
Aug 24 12:14:09.260: INFO: expected 0 pod replicas in namespace 'pods-3989', 0 are Running and Ready.
Aug 24 12:14:09.260: INFO: POD         NODE            PHASE    GRACE  CONDITIONS
Aug 24 12:14:09.260: INFO: test-pod-1  zou9eicaeree-3  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:14:09 +0000 UTC  }]
Aug 24 12:14:09.260: INFO: test-pod-2  zou9eicaeree-3  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:14:09 +0000 UTC  }]
Aug 24 12:14:09.260: INFO: test-pod-3  zou9eicaeree-3  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:14:09 +0000 UTC  }]
Aug 24 12:14:09.260: INFO: 
Aug 24 12:14:11.285: INFO: 3 / 3 pods in namespace 'pods-3989' are running and ready (2 seconds elapsed)
Aug 24 12:14:11.286: INFO: expected 0 pod replicas in namespace 'pods-3989', 0 are Running and Ready.
STEP: waiting for all pods to be deleted
Aug 24 12:14:11.334: INFO: Pod quantity 3 is different from expected quantity 0
Aug 24 12:14:12.343: INFO: Pod quantity 3 is different from expected quantity 0
Aug 24 12:14:13.344: INFO: Pod quantity 2 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:14:14.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3989" for this suite.

• [SLOW TEST:5.333 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","total":346,"completed":81,"skipped":1305,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:14:14.387: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 12:14:14.464: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2fc430d2-600c-4fd3-b7a5-850b8fbf21ae" in namespace "projected-5023" to be "Succeeded or Failed"
Aug 24 12:14:14.482: INFO: Pod "downwardapi-volume-2fc430d2-600c-4fd3-b7a5-850b8fbf21ae": Phase="Pending", Reason="", readiness=false. Elapsed: 18.21829ms
Aug 24 12:14:16.498: INFO: Pod "downwardapi-volume-2fc430d2-600c-4fd3-b7a5-850b8fbf21ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034502836s
Aug 24 12:14:18.512: INFO: Pod "downwardapi-volume-2fc430d2-600c-4fd3-b7a5-850b8fbf21ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047897036s
STEP: Saw pod success
Aug 24 12:14:18.512: INFO: Pod "downwardapi-volume-2fc430d2-600c-4fd3-b7a5-850b8fbf21ae" satisfied condition "Succeeded or Failed"
Aug 24 12:14:18.517: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-2fc430d2-600c-4fd3-b7a5-850b8fbf21ae container client-container: <nil>
STEP: delete the pod
Aug 24 12:14:18.563: INFO: Waiting for pod downwardapi-volume-2fc430d2-600c-4fd3-b7a5-850b8fbf21ae to disappear
Aug 24 12:14:18.568: INFO: Pod downwardapi-volume-2fc430d2-600c-4fd3-b7a5-850b8fbf21ae no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:14:18.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5023" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":82,"skipped":1307,"failed":0}
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:14:18.588: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Aug 24 12:14:18.643: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 24 12:14:18.663: INFO: Waiting for terminating namespaces to be deleted...
Aug 24 12:14:18.669: INFO: 
Logging pods the apiserver thinks is on node zou9eicaeree-1 before test
Aug 24 12:14:18.681: INFO: kube-flannel-ds-7bf94 from kube-flannel started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.681: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 24 12:14:18.681: INFO: coredns-bd6b6df9f-8wkdm from kube-system started at 2022-08-24 12:03:41 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.681: INFO: 	Container coredns ready: true, restart count 0
Aug 24 12:14:18.682: INFO: kube-addon-manager-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.682: INFO: 	Container kube-addon-manager ready: true, restart count 2
Aug 24 12:14:18.682: INFO: kube-apiserver-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.682: INFO: 	Container kube-apiserver ready: true, restart count 3
Aug 24 12:14:18.682: INFO: kube-controller-manager-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.682: INFO: 	Container kube-controller-manager ready: true, restart count 3
Aug 24 12:14:18.682: INFO: kube-proxy-ppn7b from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.682: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 24 12:14:18.682: INFO: kube-scheduler-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.682: INFO: 	Container kube-scheduler ready: true, restart count 3
Aug 24 12:14:18.682: INFO: sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-8pdr5 from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 12:14:18.682: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 12:14:18.682: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 12:14:18.682: INFO: 
Logging pods the apiserver thinks is on node zou9eicaeree-2 before test
Aug 24 12:14:18.700: INFO: kube-flannel-ds-5z9q7 from kube-flannel started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.700: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 24 12:14:18.700: INFO: coredns-bd6b6df9f-cqzkx from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.700: INFO: 	Container coredns ready: true, restart count 0
Aug 24 12:14:18.700: INFO: kube-addon-manager-zou9eicaeree-2 from kube-system started at 2022-08-24 11:41:08 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.700: INFO: 	Container kube-addon-manager ready: true, restart count 2
Aug 24 12:14:18.700: INFO: kube-apiserver-zou9eicaeree-2 from kube-system started at 2022-08-24 09:21:45 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.700: INFO: 	Container kube-apiserver ready: true, restart count 3
Aug 24 12:14:18.700: INFO: kube-controller-manager-zou9eicaeree-2 from kube-system started at 2022-08-24 11:41:08 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.700: INFO: 	Container kube-controller-manager ready: true, restart count 4
Aug 24 12:14:18.700: INFO: kube-proxy-brwdv from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.700: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 24 12:14:18.700: INFO: kube-scheduler-zou9eicaeree-2 from kube-system started at 2022-08-24 11:41:08 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.700: INFO: 	Container kube-scheduler ready: true, restart count 4
Aug 24 12:14:18.700: INFO: sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-549ck from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 12:14:18.700: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 12:14:18.700: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 12:14:18.700: INFO: 
Logging pods the apiserver thinks is on node zou9eicaeree-3 before test
Aug 24 12:14:18.712: INFO: kube-flannel-ds-zt7p4 from kube-flannel started at 2022-08-24 12:06:15 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.712: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 24 12:14:18.712: INFO: kube-proxy-qn7vg from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.712: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 24 12:14:18.712: INFO: sonobuoy from sonobuoy started at 2022-08-24 11:47:10 +0000 UTC (1 container statuses recorded)
Aug 24 12:14:18.712: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 24 12:14:18.712: INFO: sonobuoy-e2e-job-4d9551b899414778 from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 12:14:18.712: INFO: 	Container e2e ready: true, restart count 0
Aug 24 12:14:18.712: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 12:14:18.712: INFO: sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-n4sbd from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 12:14:18.712: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 12:14:18.712: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-bfc40188-2479-4d0b-9b0a-68aa782ede68 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.121.108 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-bfc40188-2479-4d0b-9b0a-68aa782ede68 off the node zou9eicaeree-3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-bfc40188-2479-4d0b-9b0a-68aa782ede68
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:19:22.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6095" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81

• [SLOW TEST:304.374 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":346,"completed":83,"skipped":1314,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:19:22.970: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating secret with name secret-test-map-e5aa04dc-deed-4367-b00c-7f9306d5781c
STEP: Creating a pod to test consume secrets
Aug 24 12:19:23.041: INFO: Waiting up to 5m0s for pod "pod-secrets-d71e3ec0-9ae5-488e-80e9-007d45d0ab57" in namespace "secrets-2971" to be "Succeeded or Failed"
Aug 24 12:19:23.046: INFO: Pod "pod-secrets-d71e3ec0-9ae5-488e-80e9-007d45d0ab57": Phase="Pending", Reason="", readiness=false. Elapsed: 5.759363ms
Aug 24 12:19:25.065: INFO: Pod "pod-secrets-d71e3ec0-9ae5-488e-80e9-007d45d0ab57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024407378s
Aug 24 12:19:27.080: INFO: Pod "pod-secrets-d71e3ec0-9ae5-488e-80e9-007d45d0ab57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039685162s
STEP: Saw pod success
Aug 24 12:19:27.081: INFO: Pod "pod-secrets-d71e3ec0-9ae5-488e-80e9-007d45d0ab57" satisfied condition "Succeeded or Failed"
Aug 24 12:19:27.085: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-secrets-d71e3ec0-9ae5-488e-80e9-007d45d0ab57 container secret-volume-test: <nil>
STEP: delete the pod
Aug 24 12:19:27.150: INFO: Waiting for pod pod-secrets-d71e3ec0-9ae5-488e-80e9-007d45d0ab57 to disappear
Aug 24 12:19:27.161: INFO: Pod pod-secrets-d71e3ec0-9ae5-488e-80e9-007d45d0ab57 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:19:27.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2971" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":84,"skipped":1379,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:19:27.189: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:19:27.254: INFO: The status of Pod test-webserver-9e40867e-abf9-4f9e-9907-5543d5259eee is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:19:29.266: INFO: The status of Pod test-webserver-9e40867e-abf9-4f9e-9907-5543d5259eee is Running (Ready = false)
Aug 24 12:19:31.270: INFO: The status of Pod test-webserver-9e40867e-abf9-4f9e-9907-5543d5259eee is Running (Ready = false)
Aug 24 12:19:33.270: INFO: The status of Pod test-webserver-9e40867e-abf9-4f9e-9907-5543d5259eee is Running (Ready = false)
Aug 24 12:19:35.271: INFO: The status of Pod test-webserver-9e40867e-abf9-4f9e-9907-5543d5259eee is Running (Ready = false)
Aug 24 12:19:37.270: INFO: The status of Pod test-webserver-9e40867e-abf9-4f9e-9907-5543d5259eee is Running (Ready = false)
Aug 24 12:19:39.271: INFO: The status of Pod test-webserver-9e40867e-abf9-4f9e-9907-5543d5259eee is Running (Ready = false)
Aug 24 12:19:41.274: INFO: The status of Pod test-webserver-9e40867e-abf9-4f9e-9907-5543d5259eee is Running (Ready = false)
Aug 24 12:19:43.271: INFO: The status of Pod test-webserver-9e40867e-abf9-4f9e-9907-5543d5259eee is Running (Ready = false)
Aug 24 12:19:45.270: INFO: The status of Pod test-webserver-9e40867e-abf9-4f9e-9907-5543d5259eee is Running (Ready = false)
Aug 24 12:19:47.270: INFO: The status of Pod test-webserver-9e40867e-abf9-4f9e-9907-5543d5259eee is Running (Ready = false)
Aug 24 12:19:49.281: INFO: The status of Pod test-webserver-9e40867e-abf9-4f9e-9907-5543d5259eee is Running (Ready = true)
Aug 24 12:19:49.288: INFO: Container started at 2022-08-24 12:19:27 +0000 UTC, pod became ready at 2022-08-24 12:19:47 +0000 UTC
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:19:49.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-63" for this suite.

• [SLOW TEST:22.117 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":346,"completed":85,"skipped":1400,"failed":0}
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:19:49.306: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:19:49.404: INFO: created pod
Aug 24 12:19:49.404: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-646" to be "Succeeded or Failed"
Aug 24 12:19:49.413: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 8.431549ms
Aug 24 12:19:51.432: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027661034s
Aug 24 12:19:53.447: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042513121s
STEP: Saw pod success
Aug 24 12:19:53.447: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Aug 24 12:20:23.448: INFO: polling logs
Aug 24 12:20:23.466: INFO: Pod logs: 
I0824 12:19:50.203557       1 log.go:195] OK: Got token
I0824 12:19:50.203654       1 log.go:195] validating with in-cluster discovery
I0824 12:19:50.205176       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
I0824 12:19:50.205238       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-646:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1661344189, NotBefore:1661343589, IssuedAt:1661343589, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-646", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"2f543c67-87b0-4e28-bc90-2caedf8bc3e4"}}}
I0824 12:19:50.238367       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
I0824 12:19:50.250265       1 log.go:195] OK: Validated signature on JWT
I0824 12:19:50.250556       1 log.go:195] OK: Got valid claims from token!
I0824 12:19:50.250670       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-646:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1661344189, NotBefore:1661343589, IssuedAt:1661343589, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-646", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"2f543c67-87b0-4e28-bc90-2caedf8bc3e4"}}}

Aug 24 12:20:23.466: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:20:23.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-646" for this suite.

• [SLOW TEST:34.216 seconds]
[sig-auth] ServiceAccounts
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","total":346,"completed":86,"skipped":1410,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints 
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:20:23.527: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Aug 24 12:20:23.619: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 24 12:21:23.668: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:21:23.673: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:679
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:21:23.772: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: Value: Forbidden: may not be changed in an update.
Aug 24 12:21:23.777: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: Value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:21:23.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-4239" for this suite.
[AfterEach] PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:693
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:21:23.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3859" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:60.415 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:673
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","total":346,"completed":87,"skipped":1432,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:21:23.949: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating pod pod-subpath-test-configmap-fmhs
STEP: Creating a pod to test atomic-volume-subpath
Aug 24 12:21:24.019: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-fmhs" in namespace "subpath-6220" to be "Succeeded or Failed"
Aug 24 12:21:24.035: INFO: Pod "pod-subpath-test-configmap-fmhs": Phase="Pending", Reason="", readiness=false. Elapsed: 15.489748ms
Aug 24 12:21:26.054: INFO: Pod "pod-subpath-test-configmap-fmhs": Phase="Running", Reason="", readiness=true. Elapsed: 2.03435868s
Aug 24 12:21:28.068: INFO: Pod "pod-subpath-test-configmap-fmhs": Phase="Running", Reason="", readiness=true. Elapsed: 4.048510868s
Aug 24 12:21:30.095: INFO: Pod "pod-subpath-test-configmap-fmhs": Phase="Running", Reason="", readiness=true. Elapsed: 6.075329166s
Aug 24 12:21:32.109: INFO: Pod "pod-subpath-test-configmap-fmhs": Phase="Running", Reason="", readiness=true. Elapsed: 8.088939344s
Aug 24 12:21:34.124: INFO: Pod "pod-subpath-test-configmap-fmhs": Phase="Running", Reason="", readiness=true. Elapsed: 10.104144387s
Aug 24 12:21:36.140: INFO: Pod "pod-subpath-test-configmap-fmhs": Phase="Running", Reason="", readiness=true. Elapsed: 12.120462386s
Aug 24 12:21:38.152: INFO: Pod "pod-subpath-test-configmap-fmhs": Phase="Running", Reason="", readiness=true. Elapsed: 14.1318886s
Aug 24 12:21:40.164: INFO: Pod "pod-subpath-test-configmap-fmhs": Phase="Running", Reason="", readiness=true. Elapsed: 16.143810467s
Aug 24 12:21:42.181: INFO: Pod "pod-subpath-test-configmap-fmhs": Phase="Running", Reason="", readiness=true. Elapsed: 18.161624974s
Aug 24 12:21:44.197: INFO: Pod "pod-subpath-test-configmap-fmhs": Phase="Running", Reason="", readiness=true. Elapsed: 20.177330409s
Aug 24 12:21:46.210: INFO: Pod "pod-subpath-test-configmap-fmhs": Phase="Running", Reason="", readiness=false. Elapsed: 22.190483004s
Aug 24 12:21:48.230: INFO: Pod "pod-subpath-test-configmap-fmhs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.210037725s
STEP: Saw pod success
Aug 24 12:21:48.230: INFO: Pod "pod-subpath-test-configmap-fmhs" satisfied condition "Succeeded or Failed"
Aug 24 12:21:48.236: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-subpath-test-configmap-fmhs container test-container-subpath-configmap-fmhs: <nil>
STEP: delete the pod
Aug 24 12:21:48.272: INFO: Waiting for pod pod-subpath-test-configmap-fmhs to disappear
Aug 24 12:21:48.277: INFO: Pod pod-subpath-test-configmap-fmhs no longer exists
STEP: Deleting pod pod-subpath-test-configmap-fmhs
Aug 24 12:21:48.277: INFO: Deleting pod "pod-subpath-test-configmap-fmhs" in namespace "subpath-6220"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:21:48.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6220" for this suite.

• [SLOW TEST:24.350 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Excluded:WindowsDocker] [Conformance]","total":346,"completed":88,"skipped":1467,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:21:48.301: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-5790
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5790
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5790
Aug 24 12:21:48.429: INFO: Found 0 stateful pods, waiting for 1
Aug 24 12:21:58.445: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 24 12:21:58.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-5790 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 12:21:58.766: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 12:21:58.766: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 12:21:58.766: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 12:21:58.774: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 24 12:22:08.790: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 12:22:08.790: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 12:22:08.817: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999403s
Aug 24 12:22:09.829: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993272291s
Aug 24 12:22:10.840: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.98118173s
Aug 24 12:22:11.851: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.970464491s
Aug 24 12:22:12.864: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.959633812s
Aug 24 12:22:13.876: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.94652299s
Aug 24 12:22:14.886: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.934559641s
Aug 24 12:22:15.902: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.921535549s
Aug 24 12:22:16.916: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.908005224s
Aug 24 12:22:17.927: INFO: Verifying statefulset ss doesn't scale past 1 for another 893.456656ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5790
Aug 24 12:22:18.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-5790 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 12:22:19.181: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 24 12:22:19.181: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 12:22:19.181: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 12:22:19.189: INFO: Found 1 stateful pods, waiting for 3
Aug 24 12:22:29.208: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 12:22:29.208: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 12:22:29.208: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 24 12:22:29.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-5790 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 12:22:29.440: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 12:22:29.440: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 12:22:29.440: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 12:22:29.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-5790 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 12:22:29.716: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 12:22:29.716: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 12:22:29.716: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 12:22:29.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-5790 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 12:22:29.997: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 12:22:29.997: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 12:22:29.997: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 12:22:29.997: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 12:22:30.006: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 24 12:22:40.040: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 12:22:40.040: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 12:22:40.040: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 12:22:40.072: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999384s
Aug 24 12:22:41.083: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99098294s
Aug 24 12:22:42.098: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.980591636s
Aug 24 12:22:43.111: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.965602446s
Aug 24 12:22:44.126: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.952765894s
Aug 24 12:22:45.138: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.937933641s
Aug 24 12:22:46.152: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.925869314s
Aug 24 12:22:47.167: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.911624552s
Aug 24 12:22:48.178: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.896270025s
Aug 24 12:22:49.190: INFO: Verifying statefulset ss doesn't scale past 3 for another 885.37482ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5790
Aug 24 12:22:50.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-5790 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 12:22:50.454: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 24 12:22:50.454: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 12:22:50.454: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 12:22:50.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-5790 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 12:22:50.664: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 24 12:22:50.664: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 12:22:50.664: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 12:22:50.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-5790 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 12:22:50.924: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 24 12:22:50.924: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 12:22:50.924: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 12:22:50.924: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Aug 24 12:23:00.969: INFO: Deleting all statefulset in ns statefulset-5790
Aug 24 12:23:00.974: INFO: Scaling statefulset ss to 0
Aug 24 12:23:00.996: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 12:23:01.002: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:23:01.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5790" for this suite.

• [SLOW TEST:72.749 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":346,"completed":89,"skipped":1481,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:23:01.052: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:23:01.150: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 24 12:23:01.174: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 12:23:01.174: INFO: Node zou9eicaeree-1 is running 0 daemon pod, expected 1
Aug 24 12:23:02.193: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 24 12:23:02.193: INFO: Node zou9eicaeree-1 is running 0 daemon pod, expected 1
Aug 24 12:23:03.199: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 12:23:03.199: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 24 12:23:03.261: INFO: Wrong image for pod: daemon-set-k46wp. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 12:23:03.261: INFO: Wrong image for pod: daemon-set-md6xw. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 12:23:03.261: INFO: Wrong image for pod: daemon-set-tjmgv. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 12:23:04.282: INFO: Wrong image for pod: daemon-set-k46wp. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 12:23:04.282: INFO: Wrong image for pod: daemon-set-tjmgv. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 12:23:05.282: INFO: Wrong image for pod: daemon-set-k46wp. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 12:23:05.282: INFO: Wrong image for pod: daemon-set-tjmgv. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 12:23:06.288: INFO: Pod daemon-set-bv2pw is not available
Aug 24 12:23:06.288: INFO: Wrong image for pod: daemon-set-k46wp. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 12:23:06.288: INFO: Wrong image for pod: daemon-set-tjmgv. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 12:23:07.282: INFO: Wrong image for pod: daemon-set-k46wp. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 12:23:08.279: INFO: Wrong image for pod: daemon-set-k46wp. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Aug 24 12:23:08.279: INFO: Pod daemon-set-mbtr8 is not available
Aug 24 12:23:09.280: INFO: Pod daemon-set-j5dln is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 24 12:23:09.302: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 24 12:23:09.302: INFO: Node zou9eicaeree-3 is running 0 daemon pod, expected 1
Aug 24 12:23:10.324: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 12:23:10.324: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6931, will wait for the garbage collector to delete the pods
Aug 24 12:23:10.459: INFO: Deleting DaemonSet.extensions daemon-set took: 27.580127ms
Aug 24 12:23:10.659: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.501521ms
Aug 24 12:23:13.276: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 12:23:13.276: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 24 12:23:13.281: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30138"},"items":null}

Aug 24 12:23:13.289: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30138"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:23:13.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6931" for this suite.

• [SLOW TEST:12.287 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":346,"completed":90,"skipped":1520,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API 
  should support creating Ingress API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Ingress API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:23:13.340: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename ingress
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support creating Ingress API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Aug 24 12:23:13.456: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Aug 24 12:23:13.463: INFO: starting watch
STEP: patching
STEP: updating
Aug 24 12:23:13.499: INFO: waiting for watch events with expected annotations
Aug 24 12:23:13.499: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] Ingress API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:23:13.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-9015" for this suite.
•{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","total":346,"completed":91,"skipped":1542,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:23:13.683: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 12:23:14.532: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 12:23:17.587: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Aug 24 12:23:19.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=webhook-1931 attach --namespace=webhook-1931 to-be-attached-pod -i -c=container1'
Aug 24 12:23:19.862: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:23:19.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1931" for this suite.
STEP: Destroying namespace "webhook-1931-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.302 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":346,"completed":92,"skipped":1570,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:23:19.985: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:23:20.058: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Creating first CR 
Aug 24 12:23:22.757: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T12:23:22Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T12:23:22Z]] name:name1 resourceVersion:30291 uid:50cd945c-f467-4218-ac20-d6c963c98bf0] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Aug 24 12:23:32.791: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T12:23:32Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T12:23:32Z]] name:name2 resourceVersion:30334 uid:3f4a1283-90b3-4304-bc44-71502d75e731] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Aug 24 12:23:42.824: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T12:23:22Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T12:23:42Z]] name:name1 resourceVersion:30350 uid:50cd945c-f467-4218-ac20-d6c963c98bf0] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Aug 24 12:23:52.853: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T12:23:32Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T12:23:52Z]] name:name2 resourceVersion:30366 uid:3f4a1283-90b3-4304-bc44-71502d75e731] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Aug 24 12:24:02.889: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T12:23:22Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T12:23:42Z]] name:name1 resourceVersion:30382 uid:50cd945c-f467-4218-ac20-d6c963c98bf0] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Aug 24 12:24:12.924: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-08-24T12:23:32Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-08-24T12:23:52Z]] name:name2 resourceVersion:30398 uid:3f4a1283-90b3-4304-bc44-71502d75e731] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:24:23.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-1394" for this suite.

• [SLOW TEST:63.526 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":346,"completed":93,"skipped":1578,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:24:23.512: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Performing setup for networking test in namespace pod-network-test-299
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 24 12:24:23.564: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 24 12:24:23.626: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:24:25.639: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:24:27.639: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:24:29.642: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:24:31.641: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:24:33.641: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:24:35.655: INFO: The status of Pod netserver-0 is Running (Ready = true)
Aug 24 12:24:35.667: INFO: The status of Pod netserver-1 is Running (Ready = true)
Aug 24 12:24:35.678: INFO: The status of Pod netserver-2 is Running (Ready = false)
Aug 24 12:24:37.692: INFO: The status of Pod netserver-2 is Running (Ready = false)
Aug 24 12:24:39.701: INFO: The status of Pod netserver-2 is Running (Ready = false)
Aug 24 12:24:41.695: INFO: The status of Pod netserver-2 is Running (Ready = false)
Aug 24 12:24:43.693: INFO: The status of Pod netserver-2 is Running (Ready = false)
Aug 24 12:24:45.699: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Aug 24 12:24:47.768: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Aug 24 12:24:47.768: INFO: Going to poll 10.233.64.81 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Aug 24 12:24:47.773: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.64.81 8081 | grep -v '^\s*$'] Namespace:pod-network-test-299 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:24:47.774: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:24:47.775: INFO: ExecWithOptions: Clientset creation
Aug 24 12:24:47.776: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-299/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.64.81+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:24:48.895: INFO: Found all 1 expected endpoints: [netserver-0]
Aug 24 12:24:48.895: INFO: Going to poll 10.233.65.32 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Aug 24 12:24:48.911: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.65.32 8081 | grep -v '^\s*$'] Namespace:pod-network-test-299 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:24:48.911: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:24:48.913: INFO: ExecWithOptions: Clientset creation
Aug 24 12:24:48.913: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-299/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.65.32+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:24:50.027: INFO: Found all 1 expected endpoints: [netserver-1]
Aug 24 12:24:50.027: INFO: Going to poll 10.233.66.29 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Aug 24 12:24:50.038: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.66.29 8081 | grep -v '^\s*$'] Namespace:pod-network-test-299 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:24:50.039: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:24:50.040: INFO: ExecWithOptions: Clientset creation
Aug 24 12:24:50.040: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-299/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.66.29+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:24:51.136: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:24:51.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-299" for this suite.

• [SLOW TEST:27.656 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":94,"skipped":1597,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:24:51.174: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:25:02.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1306" for this suite.

• [SLOW TEST:11.187 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":346,"completed":95,"skipped":1608,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:25:02.365: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 12:25:03.377: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 12:25:06.417: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:25:06.426: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9278-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:25:09.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8799" for this suite.
STEP: Destroying namespace "webhook-8799-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.549 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":346,"completed":96,"skipped":1631,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:25:09.917: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating secret with name secret-test-map-86a93fe7-de17-423d-8d15-f94436bb5425
STEP: Creating a pod to test consume secrets
Aug 24 12:25:10.056: INFO: Waiting up to 5m0s for pod "pod-secrets-e7f719b4-04f1-49ae-8cec-6a694de0194a" in namespace "secrets-8797" to be "Succeeded or Failed"
Aug 24 12:25:10.070: INFO: Pod "pod-secrets-e7f719b4-04f1-49ae-8cec-6a694de0194a": Phase="Pending", Reason="", readiness=false. Elapsed: 13.875922ms
Aug 24 12:25:12.082: INFO: Pod "pod-secrets-e7f719b4-04f1-49ae-8cec-6a694de0194a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026365436s
Aug 24 12:25:14.098: INFO: Pod "pod-secrets-e7f719b4-04f1-49ae-8cec-6a694de0194a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042170932s
STEP: Saw pod success
Aug 24 12:25:14.098: INFO: Pod "pod-secrets-e7f719b4-04f1-49ae-8cec-6a694de0194a" satisfied condition "Succeeded or Failed"
Aug 24 12:25:14.105: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-secrets-e7f719b4-04f1-49ae-8cec-6a694de0194a container secret-volume-test: <nil>
STEP: delete the pod
Aug 24 12:25:14.154: INFO: Waiting for pod pod-secrets-e7f719b4-04f1-49ae-8cec-6a694de0194a to disappear
Aug 24 12:25:14.159: INFO: Pod pod-secrets-e7f719b4-04f1-49ae-8cec-6a694de0194a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:25:14.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8797" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":97,"skipped":1662,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:25:14.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name configmap-test-volume-88e0060b-27ee-4183-a2ba-08d5ce4a78b5
STEP: Creating a pod to test consume configMaps
Aug 24 12:25:14.275: INFO: Waiting up to 5m0s for pod "pod-configmaps-63320bb3-b54d-4146-8433-b655c17c7687" in namespace "configmap-6086" to be "Succeeded or Failed"
Aug 24 12:25:14.282: INFO: Pod "pod-configmaps-63320bb3-b54d-4146-8433-b655c17c7687": Phase="Pending", Reason="", readiness=false. Elapsed: 7.522262ms
Aug 24 12:25:16.295: INFO: Pod "pod-configmaps-63320bb3-b54d-4146-8433-b655c17c7687": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019756504s
Aug 24 12:25:18.307: INFO: Pod "pod-configmaps-63320bb3-b54d-4146-8433-b655c17c7687": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032488825s
STEP: Saw pod success
Aug 24 12:25:18.308: INFO: Pod "pod-configmaps-63320bb3-b54d-4146-8433-b655c17c7687" satisfied condition "Succeeded or Failed"
Aug 24 12:25:18.313: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-configmaps-63320bb3-b54d-4146-8433-b655c17c7687 container agnhost-container: <nil>
STEP: delete the pod
Aug 24 12:25:18.343: INFO: Waiting for pod pod-configmaps-63320bb3-b54d-4146-8433-b655c17c7687 to disappear
Aug 24 12:25:18.347: INFO: Pod pod-configmaps-63320bb3-b54d-4146-8433-b655c17c7687 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:25:18.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6086" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":346,"completed":98,"skipped":1670,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:25:18.368: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:25:18.445: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-d5602a5f-409b-4fdc-8558-5a73620d7dae" in namespace "security-context-test-2576" to be "Succeeded or Failed"
Aug 24 12:25:18.454: INFO: Pod "busybox-readonly-false-d5602a5f-409b-4fdc-8558-5a73620d7dae": Phase="Pending", Reason="", readiness=false. Elapsed: 9.419771ms
Aug 24 12:25:20.473: INFO: Pod "busybox-readonly-false-d5602a5f-409b-4fdc-8558-5a73620d7dae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028378194s
Aug 24 12:25:22.487: INFO: Pod "busybox-readonly-false-d5602a5f-409b-4fdc-8558-5a73620d7dae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042280903s
Aug 24 12:25:22.488: INFO: Pod "busybox-readonly-false-d5602a5f-409b-4fdc-8558-5a73620d7dae" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:25:22.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2576" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":346,"completed":99,"skipped":1691,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:25:22.508: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating pod pod-subpath-test-downwardapi-lzq7
STEP: Creating a pod to test atomic-volume-subpath
Aug 24 12:25:22.629: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-lzq7" in namespace "subpath-2039" to be "Succeeded or Failed"
Aug 24 12:25:22.637: INFO: Pod "pod-subpath-test-downwardapi-lzq7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.325656ms
Aug 24 12:25:24.651: INFO: Pod "pod-subpath-test-downwardapi-lzq7": Phase="Running", Reason="", readiness=true. Elapsed: 2.021774348s
Aug 24 12:25:26.664: INFO: Pod "pod-subpath-test-downwardapi-lzq7": Phase="Running", Reason="", readiness=true. Elapsed: 4.034785256s
Aug 24 12:25:28.679: INFO: Pod "pod-subpath-test-downwardapi-lzq7": Phase="Running", Reason="", readiness=true. Elapsed: 6.049573657s
Aug 24 12:25:30.690: INFO: Pod "pod-subpath-test-downwardapi-lzq7": Phase="Running", Reason="", readiness=true. Elapsed: 8.061184703s
Aug 24 12:25:32.706: INFO: Pod "pod-subpath-test-downwardapi-lzq7": Phase="Running", Reason="", readiness=true. Elapsed: 10.077032902s
Aug 24 12:25:34.720: INFO: Pod "pod-subpath-test-downwardapi-lzq7": Phase="Running", Reason="", readiness=true. Elapsed: 12.090300077s
Aug 24 12:25:36.738: INFO: Pod "pod-subpath-test-downwardapi-lzq7": Phase="Running", Reason="", readiness=true. Elapsed: 14.109016896s
Aug 24 12:25:38.751: INFO: Pod "pod-subpath-test-downwardapi-lzq7": Phase="Running", Reason="", readiness=true. Elapsed: 16.122207616s
Aug 24 12:25:40.764: INFO: Pod "pod-subpath-test-downwardapi-lzq7": Phase="Running", Reason="", readiness=true. Elapsed: 18.134292428s
Aug 24 12:25:42.779: INFO: Pod "pod-subpath-test-downwardapi-lzq7": Phase="Running", Reason="", readiness=true. Elapsed: 20.149478538s
Aug 24 12:25:44.792: INFO: Pod "pod-subpath-test-downwardapi-lzq7": Phase="Running", Reason="", readiness=false. Elapsed: 22.162948243s
Aug 24 12:25:46.805: INFO: Pod "pod-subpath-test-downwardapi-lzq7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.176036706s
STEP: Saw pod success
Aug 24 12:25:46.806: INFO: Pod "pod-subpath-test-downwardapi-lzq7" satisfied condition "Succeeded or Failed"
Aug 24 12:25:46.811: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-subpath-test-downwardapi-lzq7 container test-container-subpath-downwardapi-lzq7: <nil>
STEP: delete the pod
Aug 24 12:25:46.852: INFO: Waiting for pod pod-subpath-test-downwardapi-lzq7 to disappear
Aug 24 12:25:46.857: INFO: Pod pod-subpath-test-downwardapi-lzq7 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-lzq7
Aug 24 12:25:46.858: INFO: Deleting pod "pod-subpath-test-downwardapi-lzq7" in namespace "subpath-2039"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:25:46.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2039" for this suite.

• [SLOW TEST:24.370 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Excluded:WindowsDocker] [Conformance]","total":346,"completed":100,"skipped":1698,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:25:46.886: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Aug 24 12:25:46.942: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying pod deletion was observed
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:25:50.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3740" for this suite.
•{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","total":346,"completed":101,"skipped":1719,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] 
  should support CSR API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:25:50.753: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename certificates
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support CSR API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: getting /apis
STEP: getting /apis/certificates.k8s.io
STEP: getting /apis/certificates.k8s.io/v1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Aug 24 12:25:51.542: INFO: starting watch
STEP: patching
STEP: updating
Aug 24 12:25:51.579: INFO: waiting for watch events with expected annotations
Aug 24 12:25:51.579: INFO: saw patched and updated annotations
STEP: getting /approval
STEP: patching /approval
STEP: updating /approval
STEP: getting /status
STEP: patching /status
STEP: updating /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:25:51.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-1677" for this suite.
•{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","total":346,"completed":102,"skipped":1778,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
   should support RuntimeClasses API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] RuntimeClass
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:25:51.723: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It]  should support RuntimeClasses API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: getting /apis
STEP: getting /apis/node.k8s.io
STEP: getting /apis/node.k8s.io/v1
STEP: creating
STEP: watching
Aug 24 12:25:51.811: INFO: starting watch
STEP: getting
STEP: listing
STEP: patching
STEP: updating
Aug 24 12:25:51.865: INFO: waiting for watch events with expected annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-node] RuntimeClass
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:25:51.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7466" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","total":346,"completed":103,"skipped":1807,"failed":0}
SSSS
------------------------------
[sig-apps] DisruptionController 
  should create a PodDisruptionBudget [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:25:51.949: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should create a PodDisruptionBudget [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating the pdb
STEP: Waiting for the pdb to be processed
STEP: updating the pdb
STEP: Waiting for the pdb to be processed
STEP: patching the pdb
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be deleted
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:25:56.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-801" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","total":346,"completed":104,"skipped":1811,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:25:56.160: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 12:25:56.223: INFO: Waiting up to 5m0s for pod "downwardapi-volume-223ddbfc-22dc-4d11-a339-018bc1cc1214" in namespace "projected-35" to be "Succeeded or Failed"
Aug 24 12:25:56.247: INFO: Pod "downwardapi-volume-223ddbfc-22dc-4d11-a339-018bc1cc1214": Phase="Pending", Reason="", readiness=false. Elapsed: 23.273224ms
Aug 24 12:25:58.262: INFO: Pod "downwardapi-volume-223ddbfc-22dc-4d11-a339-018bc1cc1214": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038404076s
Aug 24 12:26:00.271: INFO: Pod "downwardapi-volume-223ddbfc-22dc-4d11-a339-018bc1cc1214": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047950522s
STEP: Saw pod success
Aug 24 12:26:00.272: INFO: Pod "downwardapi-volume-223ddbfc-22dc-4d11-a339-018bc1cc1214" satisfied condition "Succeeded or Failed"
Aug 24 12:26:00.276: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-223ddbfc-22dc-4d11-a339-018bc1cc1214 container client-container: <nil>
STEP: delete the pod
Aug 24 12:26:00.308: INFO: Waiting for pod downwardapi-volume-223ddbfc-22dc-4d11-a339-018bc1cc1214 to disappear
Aug 24 12:26:00.315: INFO: Pod downwardapi-volume-223ddbfc-22dc-4d11-a339-018bc1cc1214 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:26:00.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-35" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":105,"skipped":1819,"failed":0}
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:26:00.351: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should support rollover [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:26:00.429: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 24 12:26:05.462: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 24 12:26:05.462: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 24 12:26:07.481: INFO: Creating deployment "test-rollover-deployment"
Aug 24 12:26:07.501: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 24 12:26:09.520: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 24 12:26:09.530: INFO: Ensure that both replica sets have 1 created replica
Aug 24 12:26:09.542: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 24 12:26:09.575: INFO: Updating deployment test-rollover-deployment
Aug 24 12:26:09.575: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 24 12:26:11.604: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 24 12:26:11.621: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 24 12:26:11.633: INFO: all replica sets need to contain the pod-template-hash label
Aug 24 12:26:11.633: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 26, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-77db6f9f48\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 12:26:13.653: INFO: all replica sets need to contain the pod-template-hash label
Aug 24 12:26:13.653: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 26, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-77db6f9f48\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 12:26:15.662: INFO: all replica sets need to contain the pod-template-hash label
Aug 24 12:26:15.662: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 26, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-77db6f9f48\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 12:26:17.650: INFO: all replica sets need to contain the pod-template-hash label
Aug 24 12:26:17.650: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 26, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-77db6f9f48\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 12:26:19.648: INFO: all replica sets need to contain the pod-template-hash label
Aug 24 12:26:19.648: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.August, 24, 12, 26, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.August, 24, 12, 26, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-77db6f9f48\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 24 12:26:21.650: INFO: 
Aug 24 12:26:21.650: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Aug 24 12:26:21.677: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-5246  02feb6d8-9dcc-4dd1-bd90-b8b5721ba8d2 31119 2 2022-08-24 12:26:07 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-08-24 12:26:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 12:26:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0041475c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-24 12:26:07 +0000 UTC,LastTransitionTime:2022-08-24 12:26:07 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-77db6f9f48" has successfully progressed.,LastUpdateTime:2022-08-24 12:26:20 +0000 UTC,LastTransitionTime:2022-08-24 12:26:07 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 24 12:26:21.686: INFO: New ReplicaSet "test-rollover-deployment-77db6f9f48" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-77db6f9f48  deployment-5246  163d095b-bd81-44fc-a396-993e5b29cca3 31108 2 2022-08-24 12:26:09 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:77db6f9f48] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 02feb6d8-9dcc-4dd1-bd90-b8b5721ba8d2 0xc004147aa7 0xc004147aa8}] []  [{kube-controller-manager Update apps/v1 2022-08-24 12:26:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"02feb6d8-9dcc-4dd1-bd90-b8b5721ba8d2\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 12:26:20 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 77db6f9f48,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:77db6f9f48] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004147b58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 24 12:26:21.686: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 24 12:26:21.686: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-5246  d292c2b8-9d8a-41c8-a961-f528b57297b0 31117 2 2022-08-24 12:26:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 02feb6d8-9dcc-4dd1-bd90-b8b5721ba8d2 0xc004147977 0xc004147978}] []  [{e2e.test Update apps/v1 2022-08-24 12:26:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 12:26:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"02feb6d8-9dcc-4dd1-bd90-b8b5721ba8d2\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-08-24 12:26:20 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004147a38 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 24 12:26:21.687: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-784bc44b77  deployment-5246  20b357a1-3416-46cd-9b7a-778ba9592277 31078 2 2022-08-24 12:26:07 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:784bc44b77] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 02feb6d8-9dcc-4dd1-bd90-b8b5721ba8d2 0xc004147bc7 0xc004147bc8}] []  [{kube-controller-manager Update apps/v1 2022-08-24 12:26:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"02feb6d8-9dcc-4dd1-bd90-b8b5721ba8d2\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 12:26:09 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 784bc44b77,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:784bc44b77] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004147c78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 24 12:26:21.693: INFO: Pod "test-rollover-deployment-77db6f9f48-tckt5" is available:
&Pod{ObjectMeta:{test-rollover-deployment-77db6f9f48-tckt5 test-rollover-deployment-77db6f9f48- deployment-5246  58be1f5e-8a0b-4260-a023-0977e6a303fe 31089 0 2022-08-24 12:26:09 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:77db6f9f48] map[] [{apps/v1 ReplicaSet test-rollover-deployment-77db6f9f48 163d095b-bd81-44fc-a396-993e5b29cca3 0xc0040f01c7 0xc0040f01c8}] []  [{kube-controller-manager Update v1 2022-08-24 12:26:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"163d095b-bd81-44fc-a396-993e5b29cca3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 12:26:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.40\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qd55p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qd55p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:26:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:26:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:26:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:26:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:10.233.66.40,StartTime:2022-08-24 12:26:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 12:26:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e,ContainerID:cri-o://9651cab36226a3cb7e6f57c7d76398e92846ff6a27c93e0305a64809b59607a6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:26:21.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5246" for this suite.

• [SLOW TEST:21.359 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":346,"completed":106,"skipped":1822,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:26:21.713: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support --unix-socket=/path  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Starting the proxy
Aug 24 12:26:21.753: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-4796 proxy --unix-socket=/tmp/kubectl-proxy-unix902318965/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:26:21.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4796" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":346,"completed":107,"skipped":1823,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:26:21.874: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name projected-configmap-test-volume-cf6e405c-a910-4b15-8ad1-504861fecd54
STEP: Creating a pod to test consume configMaps
Aug 24 12:26:21.938: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-de9b395c-3c4f-4a6c-aeda-cd4d57ec1fe5" in namespace "projected-957" to be "Succeeded or Failed"
Aug 24 12:26:21.956: INFO: Pod "pod-projected-configmaps-de9b395c-3c4f-4a6c-aeda-cd4d57ec1fe5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.068701ms
Aug 24 12:26:23.972: INFO: Pod "pod-projected-configmaps-de9b395c-3c4f-4a6c-aeda-cd4d57ec1fe5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033736082s
Aug 24 12:26:25.986: INFO: Pod "pod-projected-configmaps-de9b395c-3c4f-4a6c-aeda-cd4d57ec1fe5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047778367s
STEP: Saw pod success
Aug 24 12:26:25.986: INFO: Pod "pod-projected-configmaps-de9b395c-3c4f-4a6c-aeda-cd4d57ec1fe5" satisfied condition "Succeeded or Failed"
Aug 24 12:26:25.992: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-projected-configmaps-de9b395c-3c4f-4a6c-aeda-cd4d57ec1fe5 container agnhost-container: <nil>
STEP: delete the pod
Aug 24 12:26:26.024: INFO: Waiting for pod pod-projected-configmaps-de9b395c-3c4f-4a6c-aeda-cd4d57ec1fe5 to disappear
Aug 24 12:26:26.030: INFO: Pod pod-projected-configmaps-de9b395c-3c4f-4a6c-aeda-cd4d57ec1fe5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:26:26.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-957" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":346,"completed":108,"skipped":1851,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should support creating EndpointSlice API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:26:26.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should support creating EndpointSlice API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: getting /apis
STEP: getting /apis/discovery.k8s.io
STEP: getting /apis/discovery.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Aug 24 12:26:26.165: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Aug 24 12:26:26.172: INFO: starting watch
STEP: patching
STEP: updating
Aug 24 12:26:26.201: INFO: waiting for watch events with expected annotations
Aug 24 12:26:26.201: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:26:26.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9753" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","total":346,"completed":109,"skipped":1875,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should observe PodDisruptionBudget status updated [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:26:26.287: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should observe PodDisruptionBudget status updated [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
Aug 24 12:26:28.462: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:26:30.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-3826" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","total":346,"completed":110,"skipped":1910,"failed":0}
S
------------------------------
[sig-node] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:26:30.503: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating pod liveness-4aaea4ed-beb0-4f86-9bab-14a6a7bf61dd in namespace container-probe-3376
Aug 24 12:26:32.597: INFO: Started pod liveness-4aaea4ed-beb0-4f86-9bab-14a6a7bf61dd in namespace container-probe-3376
STEP: checking the pod's current state and verifying that restartCount is present
Aug 24 12:26:32.604: INFO: Initial restart count of pod liveness-4aaea4ed-beb0-4f86-9bab-14a6a7bf61dd is 0
Aug 24 12:26:52.750: INFO: Restart count of pod container-probe-3376/liveness-4aaea4ed-beb0-4f86-9bab-14a6a7bf61dd is now 1 (20.146094179s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:26:52.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3376" for this suite.

• [SLOW TEST:22.306 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":346,"completed":111,"skipped":1911,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:26:52.809: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:26:52.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8032 create -f -'
Aug 24 12:26:54.349: INFO: stderr: ""
Aug 24 12:26:54.349: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Aug 24 12:26:54.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8032 create -f -'
Aug 24 12:26:54.654: INFO: stderr: ""
Aug 24 12:26:54.654: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Aug 24 12:26:55.668: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 12:26:55.668: INFO: Found 0 / 1
Aug 24 12:26:56.672: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 12:26:56.672: INFO: Found 1 / 1
Aug 24 12:26:56.672: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 24 12:26:56.679: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 12:26:56.679: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 24 12:26:56.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8032 describe pod agnhost-primary-qhnjf'
Aug 24 12:26:56.826: INFO: stderr: ""
Aug 24 12:26:56.826: INFO: stdout: "Name:         agnhost-primary-qhnjf\nNamespace:    kubectl-8032\nPriority:     0\nNode:         zou9eicaeree-3/192.168.121.108\nStart Time:   Wed, 24 Aug 2022 12:26:54 +0000\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nStatus:       Running\nIP:           10.233.66.46\nIPs:\n  IP:           10.233.66.46\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   cri-o://b6b78158321840603d296f5e7c9d2c81d34a5864ac4ac012dc7fcfad7e536e59\n    Image:          k8s.gcr.io/e2e-test-images/agnhost:2.39\n    Image ID:       k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 24 Aug 2022 12:26:55 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-dvr9t (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-dvr9t:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-8032/agnhost-primary-qhnjf to zou9eicaeree-3\n  Normal  Pulled     2s    kubelet            Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.39\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Aug 24 12:26:56.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8032 describe rc agnhost-primary'
Aug 24 12:26:56.961: INFO: stderr: ""
Aug 24 12:26:56.961: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-8032\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        k8s.gcr.io/e2e-test-images/agnhost:2.39\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-qhnjf\n"
Aug 24 12:26:56.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8032 describe service agnhost-primary'
Aug 24 12:26:57.086: INFO: stderr: ""
Aug 24 12:26:57.086: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-8032\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.233.61.54\nIPs:               10.233.61.54\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.233.66.46:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 24 12:26:57.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8032 describe node zou9eicaeree-1'
Aug 24 12:26:57.300: INFO: stderr: ""
Aug 24 12:26:57.300: INFO: stdout: "Name:               zou9eicaeree-1\nRoles:              control-plane,master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=zou9eicaeree-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node-role.kubernetes.io/master=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"12:9b:18:43:80:01\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.121.241\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 24 Aug 2022 08:56:50 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  zou9eicaeree-1\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 24 Aug 2022 12:26:49 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 24 Aug 2022 11:41:54 +0000   Wed, 24 Aug 2022 11:41:54 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Wed, 24 Aug 2022 12:25:02 +0000   Wed, 24 Aug 2022 08:56:41 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 24 Aug 2022 12:25:02 +0000   Wed, 24 Aug 2022 08:56:41 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 24 Aug 2022 12:25:02 +0000   Wed, 24 Aug 2022 08:56:41 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 24 Aug 2022 12:25:02 +0000   Wed, 24 Aug 2022 09:10:23 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.121.241\n  Hostname:    zou9eicaeree-1\nCapacity:\n  cpu:                2\n  ephemeral-storage:  122749536Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8140768Ki\n  pods:               110\nAllocatable:\n  cpu:                1600m\n  ephemeral-storage:  119410748528\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3291104Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 45986e2201ef4166a1111d6d63499f91\n  System UUID:                45986e22-01ef-4166-a111-1d6d63499f91\n  Boot ID:                    689b1fe1-c45a-4f30-9def-7c022d991ded\n  Kernel Version:             5.15.0-46-generic\n  OS Image:                   Ubuntu 22.04.1 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  cri-o://1.23.3\n  Kubelet Version:            v1.23.10\n  Kube-Proxy Version:         v1.23.10\nPodCIDR:                      10.233.64.0/24\nPodCIDRs:                     10.233.64.0/24\nNon-terminated Pods:          (8 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-flannel                kube-flannel-ds-7bf94                                      100m (6%)     100m (6%)   50Mi (1%)        50Mi (1%)      45m\n  kube-system                 coredns-bd6b6df9f-8wkdm                                    100m (6%)     0 (0%)      70Mi (2%)        170Mi (5%)     23m\n  kube-system                 kube-addon-manager-zou9eicaeree-1                          5m (0%)       0 (0%)      50Mi (1%)        0 (0%)         45m\n  kube-system                 kube-apiserver-zou9eicaeree-1                              250m (15%)    0 (0%)      0 (0%)           0 (0%)         45m\n  kube-system                 kube-controller-manager-zou9eicaeree-1                     200m (12%)    0 (0%)      0 (0%)           0 (0%)         45m\n  kube-system                 kube-proxy-ppn7b                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         45m\n  kube-system                 kube-scheduler-zou9eicaeree-1                              100m (6%)     0 (0%)      0 (0%)           0 (0%)         45m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-8pdr5    0 (0%)        0 (0%)      0 (0%)           0 (0%)         39m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                755m (47%)  100m (6%)\n  memory             170Mi (5%)  220Mi (6%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From        Message\n  ----    ------                   ----               ----        -------\n  Normal  Starting                 45m                kube-proxy  \n  Normal  Starting                 45m                kube-proxy  \n  Normal  Starting                 45m                kubelet     Starting kubelet.\n  Normal  NodeHasSufficientMemory  45m (x8 over 45m)  kubelet     Node zou9eicaeree-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    45m (x8 over 45m)  kubelet     Node zou9eicaeree-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     45m (x7 over 45m)  kubelet     Node zou9eicaeree-1 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  45m                kubelet     Updated Node Allocatable limit across pods\n"
Aug 24 12:26:57.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8032 describe namespace kubectl-8032'
Aug 24 12:26:57.428: INFO: stderr: ""
Aug 24 12:26:57.428: INFO: stdout: "Name:         kubectl-8032\nLabels:       e2e-framework=kubectl\n              e2e-run=0c4f61b6-8fad-4e4c-ba74-1edd87952e30\n              kubernetes.io/metadata.name=kubectl-8032\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:26:57.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8032" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":346,"completed":112,"skipped":1912,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:26:57.448: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating projection with secret that has name projected-secret-test-0711c8fc-d1f0-42a5-afae-02094ebec7e5
STEP: Creating a pod to test consume secrets
Aug 24 12:26:57.510: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8f8ad244-15b8-4635-a69c-0f5096b76e8b" in namespace "projected-19" to be "Succeeded or Failed"
Aug 24 12:26:57.516: INFO: Pod "pod-projected-secrets-8f8ad244-15b8-4635-a69c-0f5096b76e8b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.032101ms
Aug 24 12:26:59.528: INFO: Pod "pod-projected-secrets-8f8ad244-15b8-4635-a69c-0f5096b76e8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017017259s
Aug 24 12:27:01.552: INFO: Pod "pod-projected-secrets-8f8ad244-15b8-4635-a69c-0f5096b76e8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041105696s
STEP: Saw pod success
Aug 24 12:27:01.552: INFO: Pod "pod-projected-secrets-8f8ad244-15b8-4635-a69c-0f5096b76e8b" satisfied condition "Succeeded or Failed"
Aug 24 12:27:01.577: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-projected-secrets-8f8ad244-15b8-4635-a69c-0f5096b76e8b container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 24 12:27:01.667: INFO: Waiting for pod pod-projected-secrets-8f8ad244-15b8-4635-a69c-0f5096b76e8b to disappear
Aug 24 12:27:01.681: INFO: Pod pod-projected-secrets-8f8ad244-15b8-4635-a69c-0f5096b76e8b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:27:01.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-19" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":113,"skipped":1959,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:27:01.712: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating service in namespace services-7064
Aug 24 12:27:01.815: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:27:03.831: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Aug 24 12:27:03.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-7064 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Aug 24 12:27:04.121: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Aug 24 12:27:04.121: INFO: stdout: "iptables"
Aug 24 12:27:04.121: INFO: proxyMode: iptables
Aug 24 12:27:04.143: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Aug 24 12:27:04.149: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-7064
STEP: creating replication controller affinity-nodeport-timeout in namespace services-7064
I0824 12:27:04.209154      16 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-7064, replica count: 3
I0824 12:27:07.261369      16 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 12:27:07.291: INFO: Creating new exec pod
Aug 24 12:27:10.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-7064 exec execpod-affinityqc5dx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Aug 24 12:27:10.595: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Aug 24 12:27:10.595: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 12:27:10.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-7064 exec execpod-affinityqc5dx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.9.246 80'
Aug 24 12:27:10.814: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.9.246 80\nConnection to 10.233.9.246 80 port [tcp/http] succeeded!\n"
Aug 24 12:27:10.814: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 12:27:10.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-7064 exec execpod-affinityqc5dx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.182 32165'
Aug 24 12:27:11.004: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.182 32165\nConnection to 192.168.121.182 32165 port [tcp/*] succeeded!\n"
Aug 24 12:27:11.004: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 12:27:11.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-7064 exec execpod-affinityqc5dx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.241 32165'
Aug 24 12:27:11.209: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.241 32165\nConnection to 192.168.121.241 32165 port [tcp/*] succeeded!\n"
Aug 24 12:27:11.209: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 12:27:11.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-7064 exec execpod-affinityqc5dx -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.241:32165/ ; done'
Aug 24 12:27:11.626: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n"
Aug 24 12:27:11.626: INFO: stdout: "\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7\naffinity-nodeport-timeout-l2db7"
Aug 24 12:27:11.626: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.626: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.626: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.626: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.626: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.626: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.626: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.626: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.627: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.627: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.627: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.627: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.627: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.627: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.627: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.627: INFO: Received response from host: affinity-nodeport-timeout-l2db7
Aug 24 12:27:11.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-7064 exec execpod-affinityqc5dx -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.121.241:32165/'
Aug 24 12:27:11.857: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n"
Aug 24 12:27:11.857: INFO: stdout: "affinity-nodeport-timeout-l2db7"
Aug 24 12:27:31.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-7064 exec execpod-affinityqc5dx -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.121.241:32165/'
Aug 24 12:27:32.126: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.121.241:32165/\n"
Aug 24 12:27:32.126: INFO: stdout: "affinity-nodeport-timeout-cclqt"
Aug 24 12:27:32.126: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-7064, will wait for the garbage collector to delete the pods
Aug 24 12:27:32.235: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 17.953198ms
Aug 24 12:27:32.436: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 201.146863ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:27:34.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7064" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756

• [SLOW TEST:33.019 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","total":346,"completed":114,"skipped":1963,"failed":0}
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:27:34.731: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-7406
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating stateful set ss in namespace statefulset-7406
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7406
Aug 24 12:27:34.814: INFO: Found 0 stateful pods, waiting for 1
Aug 24 12:27:44.834: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 24 12:27:44.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-7406 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 12:27:45.082: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 12:27:45.082: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 12:27:45.082: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 12:27:45.092: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 24 12:27:55.114: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 12:27:55.114: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 12:27:55.146: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 24 12:27:55.146: INFO: ss-0  zou9eicaeree-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:27:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:27:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:27:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:27:34 +0000 UTC  }]
Aug 24 12:27:55.146: INFO: 
Aug 24 12:27:55.146: INFO: StatefulSet ss has not reached scale 3, at 1
Aug 24 12:27:56.160: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992603423s
Aug 24 12:27:57.173: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978732966s
Aug 24 12:27:58.184: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.965177682s
Aug 24 12:27:59.197: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.954181832s
Aug 24 12:28:00.210: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.941853953s
Aug 24 12:28:01.222: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.928398672s
Aug 24 12:28:02.234: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.916365316s
Aug 24 12:28:03.245: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.904122603s
Aug 24 12:28:04.260: INFO: Verifying statefulset ss doesn't scale past 3 for another 893.315895ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7406
Aug 24 12:28:05.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-7406 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 12:28:05.513: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 24 12:28:05.513: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 12:28:05.513: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 12:28:05.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-7406 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 12:28:05.770: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 24 12:28:05.770: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 12:28:05.770: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 12:28:05.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-7406 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 12:28:06.018: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 24 12:28:06.018: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 12:28:06.018: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 12:28:06.027: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug 24 12:28:16.056: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 12:28:16.056: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 12:28:16.056: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 24 12:28:16.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-7406 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 12:28:16.267: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 12:28:16.267: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 12:28:16.267: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 12:28:16.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-7406 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 12:28:16.486: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 12:28:16.486: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 12:28:16.487: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 12:28:16.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-7406 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 12:28:16.730: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 12:28:16.730: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 12:28:16.730: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 12:28:16.730: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 12:28:16.738: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 24 12:28:26.770: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 12:28:26.770: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 12:28:26.770: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 24 12:28:26.797: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Aug 24 12:28:26.797: INFO: ss-0  zou9eicaeree-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:27:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:28:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:28:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:27:34 +0000 UTC  }]
Aug 24 12:28:26.798: INFO: ss-1  zou9eicaeree-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:27:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:28:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:28:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:27:55 +0000 UTC  }]
Aug 24 12:28:26.798: INFO: ss-2  zou9eicaeree-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:27:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:28:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:28:17 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 12:27:55 +0000 UTC  }]
Aug 24 12:28:26.798: INFO: 
Aug 24 12:28:26.798: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 24 12:28:27.824: INFO: Verifying statefulset ss doesn't scale past 0 for another 8.99138477s
Aug 24 12:28:28.833: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.965596728s
Aug 24 12:28:29.844: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.956991837s
Aug 24 12:28:30.852: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.946032251s
Aug 24 12:28:31.864: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.938432938s
Aug 24 12:28:32.874: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.92582687s
Aug 24 12:28:33.887: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.915893217s
Aug 24 12:28:34.898: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.903015412s
Aug 24 12:28:35.909: INFO: Verifying statefulset ss doesn't scale past 0 for another 892.231351ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7406
Aug 24 12:28:36.920: INFO: Scaling statefulset ss to 0
Aug 24 12:28:36.941: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Aug 24 12:28:36.945: INFO: Deleting all statefulset in ns statefulset-7406
Aug 24 12:28:36.950: INFO: Scaling statefulset ss to 0
Aug 24 12:28:36.969: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 12:28:36.973: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:28:36.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7406" for this suite.

• [SLOW TEST:62.289 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":346,"completed":115,"skipped":1964,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:28:37.023: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:28:37.135: INFO: The status of Pod pod-secrets-2b5727b2-dc8b-460e-9823-c79314e1dde1 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:28:39.147: INFO: The status of Pod pod-secrets-2b5727b2-dc8b-460e-9823-c79314e1dde1 is Running (Ready = true)
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:28:39.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-844" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":346,"completed":116,"skipped":1990,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:28:39.215: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating secret with name secret-test-435d09d6-5e99-47c0-b8e6-934ed5fb6366
STEP: Creating a pod to test consume secrets
Aug 24 12:28:39.310: INFO: Waiting up to 5m0s for pod "pod-secrets-6d766566-b062-48a0-86dd-d7cdd120dc7e" in namespace "secrets-6504" to be "Succeeded or Failed"
Aug 24 12:28:39.316: INFO: Pod "pod-secrets-6d766566-b062-48a0-86dd-d7cdd120dc7e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.171614ms
Aug 24 12:28:41.325: INFO: Pod "pod-secrets-6d766566-b062-48a0-86dd-d7cdd120dc7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014956565s
Aug 24 12:28:43.342: INFO: Pod "pod-secrets-6d766566-b062-48a0-86dd-d7cdd120dc7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031877488s
STEP: Saw pod success
Aug 24 12:28:43.342: INFO: Pod "pod-secrets-6d766566-b062-48a0-86dd-d7cdd120dc7e" satisfied condition "Succeeded or Failed"
Aug 24 12:28:43.351: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-secrets-6d766566-b062-48a0-86dd-d7cdd120dc7e container secret-env-test: <nil>
STEP: delete the pod
Aug 24 12:28:43.403: INFO: Waiting for pod pod-secrets-6d766566-b062-48a0-86dd-d7cdd120dc7e to disappear
Aug 24 12:28:43.411: INFO: Pod pod-secrets-6d766566-b062-48a0-86dd-d7cdd120dc7e no longer exists
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:28:43.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6504" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":346,"completed":117,"skipped":2018,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:28:43.437: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:28:59.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8613" for this suite.

• [SLOW TEST:16.332 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":346,"completed":118,"skipped":2055,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:28:59.781: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:28:59.821: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:29:03.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1357" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":346,"completed":119,"skipped":2142,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:29:03.373: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:29:16.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1333" for this suite.
STEP: Destroying namespace "nsdeletetest-5238" for this suite.
Aug 24 12:29:16.618: INFO: Namespace nsdeletetest-5238 was already deleted
STEP: Destroying namespace "nsdeletetest-6078" for this suite.

• [SLOW TEST:13.258 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":346,"completed":120,"skipped":2152,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount projected service account token [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:29:16.636: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should mount projected service account token [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test service account token: 
Aug 24 12:29:16.712: INFO: Waiting up to 5m0s for pod "test-pod-2b9935fd-30f6-485a-9b3d-2e6a3e258104" in namespace "svcaccounts-7256" to be "Succeeded or Failed"
Aug 24 12:29:16.724: INFO: Pod "test-pod-2b9935fd-30f6-485a-9b3d-2e6a3e258104": Phase="Pending", Reason="", readiness=false. Elapsed: 11.367792ms
Aug 24 12:29:18.762: INFO: Pod "test-pod-2b9935fd-30f6-485a-9b3d-2e6a3e258104": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049991742s
Aug 24 12:29:20.803: INFO: Pod "test-pod-2b9935fd-30f6-485a-9b3d-2e6a3e258104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.09106873s
STEP: Saw pod success
Aug 24 12:29:20.804: INFO: Pod "test-pod-2b9935fd-30f6-485a-9b3d-2e6a3e258104" satisfied condition "Succeeded or Failed"
Aug 24 12:29:20.816: INFO: Trying to get logs from node zou9eicaeree-3 pod test-pod-2b9935fd-30f6-485a-9b3d-2e6a3e258104 container agnhost-container: <nil>
STEP: delete the pod
Aug 24 12:29:20.852: INFO: Waiting for pod test-pod-2b9935fd-30f6-485a-9b3d-2e6a3e258104 to disappear
Aug 24 12:29:20.859: INFO: Pod test-pod-2b9935fd-30f6-485a-9b3d-2e6a3e258104 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:29:20.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7256" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","total":346,"completed":121,"skipped":2176,"failed":0}
SSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:29:20.879: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:30:20.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2898" for this suite.

• [SLOW TEST:60.097 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":346,"completed":122,"skipped":2181,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:30:20.979: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 12:30:22.345: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 12:30:25.383: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:30:25.391: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:30:28.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4025" for this suite.
STEP: Destroying namespace "webhook-4025-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.899 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":346,"completed":123,"skipped":2193,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:30:28.880: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward api env vars
Aug 24 12:30:28.981: INFO: Waiting up to 5m0s for pod "downward-api-095d8f00-21d3-403a-8b5e-26d9a3d7b26c" in namespace "downward-api-9465" to be "Succeeded or Failed"
Aug 24 12:30:28.989: INFO: Pod "downward-api-095d8f00-21d3-403a-8b5e-26d9a3d7b26c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.292035ms
Aug 24 12:30:31.003: INFO: Pod "downward-api-095d8f00-21d3-403a-8b5e-26d9a3d7b26c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02216723s
Aug 24 12:30:33.017: INFO: Pod "downward-api-095d8f00-21d3-403a-8b5e-26d9a3d7b26c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036128763s
STEP: Saw pod success
Aug 24 12:30:33.017: INFO: Pod "downward-api-095d8f00-21d3-403a-8b5e-26d9a3d7b26c" satisfied condition "Succeeded or Failed"
Aug 24 12:30:33.022: INFO: Trying to get logs from node zou9eicaeree-3 pod downward-api-095d8f00-21d3-403a-8b5e-26d9a3d7b26c container dapi-container: <nil>
STEP: delete the pod
Aug 24 12:30:33.076: INFO: Waiting for pod downward-api-095d8f00-21d3-403a-8b5e-26d9a3d7b26c to disappear
Aug 24 12:30:33.081: INFO: Pod downward-api-095d8f00-21d3-403a-8b5e-26d9a3d7b26c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:30:33.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9465" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":346,"completed":124,"skipped":2230,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:30:33.101: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-305
[It] Should recreate evicted statefulset [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-305
STEP: Waiting until pod test-pod will start running in namespace statefulset-305
STEP: Creating statefulset with conflicting port in namespace statefulset-305
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-305
Aug 24 12:30:35.302: INFO: Observed stateful pod in namespace: statefulset-305, name: ss-0, uid: 19a6275c-5144-4972-8913-9f99e2e0eace, status phase: Pending. Waiting for statefulset controller to delete.
Aug 24 12:30:35.329: INFO: Observed stateful pod in namespace: statefulset-305, name: ss-0, uid: 19a6275c-5144-4972-8913-9f99e2e0eace, status phase: Failed. Waiting for statefulset controller to delete.
Aug 24 12:30:35.345: INFO: Observed stateful pod in namespace: statefulset-305, name: ss-0, uid: 19a6275c-5144-4972-8913-9f99e2e0eace, status phase: Failed. Waiting for statefulset controller to delete.
Aug 24 12:30:35.351: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-305
STEP: Removing pod with conflicting port in namespace statefulset-305
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-305 and will be in running state
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Aug 24 12:30:51.543: INFO: Deleting all statefulset in ns statefulset-305
Aug 24 12:30:51.550: INFO: Scaling statefulset ss to 0
Aug 24 12:31:01.646: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 12:31:01.653: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:31:01.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-305" for this suite.

• [SLOW TEST:28.631 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    Should recreate evicted statefulset [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":346,"completed":125,"skipped":2265,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:31:01.734: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 12:31:01.812: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e174992-4ce9-4aa0-a2e6-fcd392f88b61" in namespace "projected-2346" to be "Succeeded or Failed"
Aug 24 12:31:01.830: INFO: Pod "downwardapi-volume-4e174992-4ce9-4aa0-a2e6-fcd392f88b61": Phase="Pending", Reason="", readiness=false. Elapsed: 17.883089ms
Aug 24 12:31:03.842: INFO: Pod "downwardapi-volume-4e174992-4ce9-4aa0-a2e6-fcd392f88b61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030285175s
Aug 24 12:31:05.866: INFO: Pod "downwardapi-volume-4e174992-4ce9-4aa0-a2e6-fcd392f88b61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053866441s
STEP: Saw pod success
Aug 24 12:31:05.866: INFO: Pod "downwardapi-volume-4e174992-4ce9-4aa0-a2e6-fcd392f88b61" satisfied condition "Succeeded or Failed"
Aug 24 12:31:05.871: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-4e174992-4ce9-4aa0-a2e6-fcd392f88b61 container client-container: <nil>
STEP: delete the pod
Aug 24 12:31:05.908: INFO: Waiting for pod downwardapi-volume-4e174992-4ce9-4aa0-a2e6-fcd392f88b61 to disappear
Aug 24 12:31:05.917: INFO: Pod downwardapi-volume-4e174992-4ce9-4aa0-a2e6-fcd392f88b61 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:31:05.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2346" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":346,"completed":126,"skipped":2282,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:31:05.943: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Aug 24 12:31:07.560: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 12:31:10.603: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:31:10.614: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:31:14.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7370" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:8.376 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":346,"completed":127,"skipped":2289,"failed":0}
SSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:31:14.319: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:31:14.450: INFO: Waiting up to 5m0s for pod "busybox-user-65534-52c5293e-f49a-4035-8761-9727b020a8a2" in namespace "security-context-test-8868" to be "Succeeded or Failed"
Aug 24 12:31:14.461: INFO: Pod "busybox-user-65534-52c5293e-f49a-4035-8761-9727b020a8a2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.71521ms
Aug 24 12:31:16.474: INFO: Pod "busybox-user-65534-52c5293e-f49a-4035-8761-9727b020a8a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023600166s
Aug 24 12:31:18.487: INFO: Pod "busybox-user-65534-52c5293e-f49a-4035-8761-9727b020a8a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036318836s
Aug 24 12:31:18.487: INFO: Pod "busybox-user-65534-52c5293e-f49a-4035-8761-9727b020a8a2" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:31:18.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8868" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":128,"skipped":2293,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:31:18.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 24 12:31:18.588: INFO: Waiting up to 5m0s for pod "pod-f06d6a85-8d1d-46a2-a871-d202cd17ebe5" in namespace "emptydir-362" to be "Succeeded or Failed"
Aug 24 12:31:18.603: INFO: Pod "pod-f06d6a85-8d1d-46a2-a871-d202cd17ebe5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.481532ms
Aug 24 12:31:20.614: INFO: Pod "pod-f06d6a85-8d1d-46a2-a871-d202cd17ebe5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025440495s
Aug 24 12:31:22.632: INFO: Pod "pod-f06d6a85-8d1d-46a2-a871-d202cd17ebe5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043216016s
STEP: Saw pod success
Aug 24 12:31:22.632: INFO: Pod "pod-f06d6a85-8d1d-46a2-a871-d202cd17ebe5" satisfied condition "Succeeded or Failed"
Aug 24 12:31:22.643: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-f06d6a85-8d1d-46a2-a871-d202cd17ebe5 container test-container: <nil>
STEP: delete the pod
Aug 24 12:31:22.686: INFO: Waiting for pod pod-f06d6a85-8d1d-46a2-a871-d202cd17ebe5 to disappear
Aug 24 12:31:22.691: INFO: Pod pod-f06d6a85-8d1d-46a2-a871-d202cd17ebe5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:31:22.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-362" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":129,"skipped":2318,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:31:22.732: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 24 12:31:22.830: INFO: Waiting up to 5m0s for pod "pod-bc3ccd67-314d-4cca-be42-3df7b616e2d9" in namespace "emptydir-3819" to be "Succeeded or Failed"
Aug 24 12:31:22.837: INFO: Pod "pod-bc3ccd67-314d-4cca-be42-3df7b616e2d9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.839254ms
Aug 24 12:31:24.850: INFO: Pod "pod-bc3ccd67-314d-4cca-be42-3df7b616e2d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020163052s
Aug 24 12:31:26.864: INFO: Pod "pod-bc3ccd67-314d-4cca-be42-3df7b616e2d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033857237s
STEP: Saw pod success
Aug 24 12:31:26.864: INFO: Pod "pod-bc3ccd67-314d-4cca-be42-3df7b616e2d9" satisfied condition "Succeeded or Failed"
Aug 24 12:31:26.870: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-bc3ccd67-314d-4cca-be42-3df7b616e2d9 container test-container: <nil>
STEP: delete the pod
Aug 24 12:31:26.901: INFO: Waiting for pod pod-bc3ccd67-314d-4cca-be42-3df7b616e2d9 to disappear
Aug 24 12:31:26.906: INFO: Pod pod-bc3ccd67-314d-4cca-be42-3df7b616e2d9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:31:26.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3819" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":130,"skipped":2330,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:31:26.931: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test override arguments
Aug 24 12:31:27.001: INFO: Waiting up to 5m0s for pod "client-containers-e8d5baaa-fd40-4441-9319-7b9c6481cf9a" in namespace "containers-207" to be "Succeeded or Failed"
Aug 24 12:31:27.016: INFO: Pod "client-containers-e8d5baaa-fd40-4441-9319-7b9c6481cf9a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.323627ms
Aug 24 12:31:29.028: INFO: Pod "client-containers-e8d5baaa-fd40-4441-9319-7b9c6481cf9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026668743s
Aug 24 12:31:31.040: INFO: Pod "client-containers-e8d5baaa-fd40-4441-9319-7b9c6481cf9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038995518s
STEP: Saw pod success
Aug 24 12:31:31.041: INFO: Pod "client-containers-e8d5baaa-fd40-4441-9319-7b9c6481cf9a" satisfied condition "Succeeded or Failed"
Aug 24 12:31:31.046: INFO: Trying to get logs from node zou9eicaeree-3 pod client-containers-e8d5baaa-fd40-4441-9319-7b9c6481cf9a container agnhost-container: <nil>
STEP: delete the pod
Aug 24 12:31:31.077: INFO: Waiting for pod client-containers-e8d5baaa-fd40-4441-9319-7b9c6481cf9a to disappear
Aug 24 12:31:31.082: INFO: Pod client-containers-e8d5baaa-fd40-4441-9319-7b9c6481cf9a no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:31:31.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-207" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":346,"completed":131,"skipped":2361,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:31:31.097: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: validating cluster-info
Aug 24 12:31:31.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-7835 cluster-info'
Aug 24 12:31:31.307: INFO: stderr: ""
Aug 24 12:31:31.307: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:31:31.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7835" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","total":346,"completed":132,"skipped":2377,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:31:31.337: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:53
STEP: create the container to handle the HTTPGet hook request.
Aug 24 12:31:31.396: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:31:33.408: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create the pod with lifecycle hook
Aug 24 12:31:33.440: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:31:35.460: INFO: The status of Pod pod-with-poststart-http-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 24 12:31:35.514: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 24 12:31:35.520: INFO: Pod pod-with-poststart-http-hook still exists
Aug 24 12:31:37.521: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 24 12:31:37.534: INFO: Pod pod-with-poststart-http-hook still exists
Aug 24 12:31:39.521: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 24 12:31:39.562: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:31:39.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3114" for this suite.

• [SLOW TEST:8.253 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:44
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":346,"completed":133,"skipped":2391,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should run the lifecycle of PodTemplates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:31:39.592: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run the lifecycle of PodTemplates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[AfterEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:31:39.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-4248" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","total":346,"completed":134,"skipped":2402,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:31:39.727: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/instrumentation/events.go:81
[It] should delete a collection of events [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Create set of events
STEP: get a list of Events with a label in the current namespace
STEP: delete a list of events
Aug 24 12:31:39.827: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
[AfterEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:31:39.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8755" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","total":346,"completed":135,"skipped":2442,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:31:39.910: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 24 12:31:44.042: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:31:44.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-538" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [Excluded:WindowsDocker] [NodeConformance] [Conformance]","total":346,"completed":136,"skipped":2456,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:31:44.097: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 12:31:44.901: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 12:31:47.952: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:31:48.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2338" for this suite.
STEP: Destroying namespace "webhook-2338-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":346,"completed":137,"skipped":2490,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:31:48.170: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name configmap-test-upd-5384a1e8-e8f1-4080-a056-d74c27c8406e
STEP: Creating the pod
Aug 24 12:31:48.265: INFO: The status of Pod pod-configmaps-eaa9ba80-d964-4ee3-ae9b-6c91abf93fb7 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:31:50.278: INFO: The status of Pod pod-configmaps-eaa9ba80-d964-4ee3-ae9b-6c91abf93fb7 is Running (Ready = true)
STEP: Updating configmap configmap-test-upd-5384a1e8-e8f1-4080-a056-d74c27c8406e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:33:16.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2166" for this suite.

• [SLOW TEST:88.859 seconds]
[sig-storage] ConfigMap
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":138,"skipped":2535,"failed":0}
SSSS
------------------------------
[sig-node] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:33:17.032: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:33:17.136: INFO: The status of Pod server-envvars-0aeac22a-fd04-4bdb-a863-e6fc40f71868 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:33:19.152: INFO: The status of Pod server-envvars-0aeac22a-fd04-4bdb-a863-e6fc40f71868 is Running (Ready = true)
Aug 24 12:33:19.206: INFO: Waiting up to 5m0s for pod "client-envvars-70ea001f-af7d-4296-aee3-03ae524fb0bd" in namespace "pods-8759" to be "Succeeded or Failed"
Aug 24 12:33:19.218: INFO: Pod "client-envvars-70ea001f-af7d-4296-aee3-03ae524fb0bd": Phase="Pending", Reason="", readiness=false. Elapsed: 11.634613ms
Aug 24 12:33:21.244: INFO: Pod "client-envvars-70ea001f-af7d-4296-aee3-03ae524fb0bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037129003s
Aug 24 12:33:23.257: INFO: Pod "client-envvars-70ea001f-af7d-4296-aee3-03ae524fb0bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050617158s
STEP: Saw pod success
Aug 24 12:33:23.258: INFO: Pod "client-envvars-70ea001f-af7d-4296-aee3-03ae524fb0bd" satisfied condition "Succeeded or Failed"
Aug 24 12:33:23.267: INFO: Trying to get logs from node zou9eicaeree-3 pod client-envvars-70ea001f-af7d-4296-aee3-03ae524fb0bd container env3cont: <nil>
STEP: delete the pod
Aug 24 12:33:23.309: INFO: Waiting for pod client-envvars-70ea001f-af7d-4296-aee3-03ae524fb0bd to disappear
Aug 24 12:33:23.317: INFO: Pod client-envvars-70ea001f-af7d-4296-aee3-03ae524fb0bd no longer exists
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:33:23.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8759" for this suite.

• [SLOW TEST:6.322 seconds]
[sig-node] Pods
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":346,"completed":139,"skipped":2539,"failed":0}
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:33:23.356: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating projection with secret that has name projected-secret-test-06c3179c-4ea5-4145-b470-98b30a1977a4
STEP: Creating a pod to test consume secrets
Aug 24 12:33:23.461: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4678c5a1-8ea7-4bf1-8cf7-5f3b418f1067" in namespace "projected-2333" to be "Succeeded or Failed"
Aug 24 12:33:23.469: INFO: Pod "pod-projected-secrets-4678c5a1-8ea7-4bf1-8cf7-5f3b418f1067": Phase="Pending", Reason="", readiness=false. Elapsed: 8.187726ms
Aug 24 12:33:25.481: INFO: Pod "pod-projected-secrets-4678c5a1-8ea7-4bf1-8cf7-5f3b418f1067": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019476779s
Aug 24 12:33:27.501: INFO: Pod "pod-projected-secrets-4678c5a1-8ea7-4bf1-8cf7-5f3b418f1067": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040293308s
STEP: Saw pod success
Aug 24 12:33:27.502: INFO: Pod "pod-projected-secrets-4678c5a1-8ea7-4bf1-8cf7-5f3b418f1067" satisfied condition "Succeeded or Failed"
Aug 24 12:33:27.510: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-projected-secrets-4678c5a1-8ea7-4bf1-8cf7-5f3b418f1067 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 24 12:33:27.545: INFO: Waiting for pod pod-projected-secrets-4678c5a1-8ea7-4bf1-8cf7-5f3b418f1067 to disappear
Aug 24 12:33:27.552: INFO: Pod pod-projected-secrets-4678c5a1-8ea7-4bf1-8cf7-5f3b418f1067 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:33:27.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2333" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":140,"skipped":2540,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:33:27.582: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-4936
[It] should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating statefulset ss in namespace statefulset-4936
Aug 24 12:33:27.683: INFO: Found 0 stateful pods, waiting for 1
Aug 24 12:33:37.699: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
STEP: Patch a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Aug 24 12:33:37.768: INFO: Deleting all statefulset in ns statefulset-4936
Aug 24 12:33:37.775: INFO: Scaling statefulset ss to 0
Aug 24 12:33:47.849: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 12:33:47.855: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:33:47.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4936" for this suite.

• [SLOW TEST:20.313 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should have a working scale subresource [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":346,"completed":141,"skipped":2556,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected combined
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:33:47.901: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name configmap-projected-all-test-volume-13bdc4c7-8954-4d6c-a99d-ddf15ec21304
STEP: Creating secret with name secret-projected-all-test-volume-84b0f6b7-c8a4-46da-928f-f3f5f3370d94
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 24 12:33:47.976: INFO: Waiting up to 5m0s for pod "projected-volume-de35955c-6e85-42d4-b5ec-9d61db2882cd" in namespace "projected-9544" to be "Succeeded or Failed"
Aug 24 12:33:47.982: INFO: Pod "projected-volume-de35955c-6e85-42d4-b5ec-9d61db2882cd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.567699ms
Aug 24 12:33:50.010: INFO: Pod "projected-volume-de35955c-6e85-42d4-b5ec-9d61db2882cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032952111s
Aug 24 12:33:52.024: INFO: Pod "projected-volume-de35955c-6e85-42d4-b5ec-9d61db2882cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047113096s
STEP: Saw pod success
Aug 24 12:33:52.024: INFO: Pod "projected-volume-de35955c-6e85-42d4-b5ec-9d61db2882cd" satisfied condition "Succeeded or Failed"
Aug 24 12:33:52.029: INFO: Trying to get logs from node zou9eicaeree-3 pod projected-volume-de35955c-6e85-42d4-b5ec-9d61db2882cd container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 24 12:33:52.055: INFO: Waiting for pod projected-volume-de35955c-6e85-42d4-b5ec-9d61db2882cd to disappear
Aug 24 12:33:52.059: INFO: Pod projected-volume-de35955c-6e85-42d4-b5ec-9d61db2882cd no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:33:52.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9544" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":346,"completed":142,"skipped":2592,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:33:52.083: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Aug 24 12:33:52.873: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 12:33:55.934: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:33:55.953: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:33:59.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3258" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:7.605 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":346,"completed":143,"skipped":2648,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:33:59.692: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 24 12:34:02.846: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:34:02.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4519" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":346,"completed":144,"skipped":2686,"failed":0}
SSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:34:02.898: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
Aug 24 12:34:02.988: INFO: The status of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:34:04.996: INFO: The status of Pod test-pod is Running (Ready = true)
STEP: Creating hostNetwork=true pod
Aug 24 12:34:05.032: INFO: The status of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:34:07.044: INFO: The status of Pod test-host-network-pod is Running (Ready = true)
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 24 12:34:07.049: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3733 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:34:07.049: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:34:07.050: INFO: ExecWithOptions: Clientset creation
Aug 24 12:34:07.050: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3733/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:34:07.179: INFO: Exec stderr: ""
Aug 24 12:34:07.179: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3733 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:34:07.179: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:34:07.181: INFO: ExecWithOptions: Clientset creation
Aug 24 12:34:07.181: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3733/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:34:07.281: INFO: Exec stderr: ""
Aug 24 12:34:07.281: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3733 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:34:07.281: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:34:07.284: INFO: ExecWithOptions: Clientset creation
Aug 24 12:34:07.284: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3733/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:34:07.395: INFO: Exec stderr: ""
Aug 24 12:34:07.395: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3733 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:34:07.395: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:34:07.398: INFO: ExecWithOptions: Clientset creation
Aug 24 12:34:07.398: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3733/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:34:07.504: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 24 12:34:07.504: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3733 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:34:07.504: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:34:07.506: INFO: ExecWithOptions: Clientset creation
Aug 24 12:34:07.506: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3733/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:34:07.590: INFO: Exec stderr: ""
Aug 24 12:34:07.590: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3733 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:34:07.591: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:34:07.593: INFO: ExecWithOptions: Clientset creation
Aug 24 12:34:07.593: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3733/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:34:07.684: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 24 12:34:07.684: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3733 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:34:07.684: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:34:07.686: INFO: ExecWithOptions: Clientset creation
Aug 24 12:34:07.686: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3733/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:34:07.769: INFO: Exec stderr: ""
Aug 24 12:34:07.769: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3733 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:34:07.769: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:34:07.770: INFO: ExecWithOptions: Clientset creation
Aug 24 12:34:07.771: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3733/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:34:07.852: INFO: Exec stderr: ""
Aug 24 12:34:07.852: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3733 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:34:07.852: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:34:07.855: INFO: ExecWithOptions: Clientset creation
Aug 24 12:34:07.855: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3733/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:34:07.969: INFO: Exec stderr: ""
Aug 24 12:34:07.970: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3733 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:34:07.970: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:34:07.972: INFO: ExecWithOptions: Clientset creation
Aug 24 12:34:07.973: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-3733/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:34:08.068: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:34:08.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3733" for this suite.

• [SLOW TEST:5.195 seconds]
[sig-node] KubeletManagedEtcHosts
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":145,"skipped":2694,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:34:08.093: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:34:08.193: INFO: The status of Pod busybox-readonly-fs64d4b011-862b-4bae-88d4-6f066f4cbd1c is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:34:10.208: INFO: The status of Pod busybox-readonly-fs64d4b011-862b-4bae-88d4-6f066f4cbd1c is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:34:10.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7674" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":146,"skipped":2704,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:34:10.242: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: set up a multi version CRD
Aug 24 12:34:10.289: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:34:31.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5951" for this suite.

• [SLOW TEST:21.761 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":346,"completed":147,"skipped":2706,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:34:32.004: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating secret with name secret-test-52c61209-b60d-48ea-9adf-bda3e66cf47e
STEP: Creating a pod to test consume secrets
Aug 24 12:34:32.081: INFO: Waiting up to 5m0s for pod "pod-secrets-aa8b6019-5314-4fc1-9765-dc2b00ab93bb" in namespace "secrets-8258" to be "Succeeded or Failed"
Aug 24 12:34:32.089: INFO: Pod "pod-secrets-aa8b6019-5314-4fc1-9765-dc2b00ab93bb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.570579ms
Aug 24 12:34:34.098: INFO: Pod "pod-secrets-aa8b6019-5314-4fc1-9765-dc2b00ab93bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016842373s
Aug 24 12:34:36.103: INFO: Pod "pod-secrets-aa8b6019-5314-4fc1-9765-dc2b00ab93bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022243642s
STEP: Saw pod success
Aug 24 12:34:36.103: INFO: Pod "pod-secrets-aa8b6019-5314-4fc1-9765-dc2b00ab93bb" satisfied condition "Succeeded or Failed"
Aug 24 12:34:36.109: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-secrets-aa8b6019-5314-4fc1-9765-dc2b00ab93bb container secret-volume-test: <nil>
STEP: delete the pod
Aug 24 12:34:36.161: INFO: Waiting for pod pod-secrets-aa8b6019-5314-4fc1-9765-dc2b00ab93bb to disappear
Aug 24 12:34:36.165: INFO: Pod pod-secrets-aa8b6019-5314-4fc1-9765-dc2b00ab93bb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:34:36.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8258" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":148,"skipped":2714,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:34:36.184: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] deployment should delete old replica sets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:34:36.255: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 24 12:34:41.291: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 24 12:34:41.291: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Aug 24 12:34:41.335: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-1916  d698ade5-5c1b-4acf-823b-f0a59b30d1a1 33798 1 2022-08-24 12:34:41 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2022-08-24 12:34:41 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0055ac398 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Aug 24 12:34:41.340: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:34:41.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1916" for this suite.

• [SLOW TEST:5.195 seconds]
[sig-apps] Deployment
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":346,"completed":149,"skipped":2724,"failed":0}
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:34:41.380: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Aug 24 12:34:41.449: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:34:45.045: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:35:00.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5514" for this suite.

• [SLOW TEST:19.373 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":346,"completed":150,"skipped":2724,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:35:00.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:35:00.815: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Aug 24 12:35:04.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-5228 --namespace=crd-publish-openapi-5228 create -f -'
Aug 24 12:35:05.555: INFO: stderr: ""
Aug 24 12:35:05.555: INFO: stdout: "e2e-test-crd-publish-openapi-8304-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Aug 24 12:35:05.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-5228 --namespace=crd-publish-openapi-5228 delete e2e-test-crd-publish-openapi-8304-crds test-cr'
Aug 24 12:35:06.023: INFO: stderr: ""
Aug 24 12:35:06.023: INFO: stdout: "e2e-test-crd-publish-openapi-8304-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Aug 24 12:35:06.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-5228 --namespace=crd-publish-openapi-5228 apply -f -'
Aug 24 12:35:06.344: INFO: stderr: ""
Aug 24 12:35:06.344: INFO: stdout: "e2e-test-crd-publish-openapi-8304-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Aug 24 12:35:06.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-5228 --namespace=crd-publish-openapi-5228 delete e2e-test-crd-publish-openapi-8304-crds test-cr'
Aug 24 12:35:06.477: INFO: stderr: ""
Aug 24 12:35:06.477: INFO: stdout: "e2e-test-crd-publish-openapi-8304-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Aug 24 12:35:06.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-5228 explain e2e-test-crd-publish-openapi-8304-crds'
Aug 24 12:35:07.258: INFO: stderr: ""
Aug 24 12:35:07.258: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8304-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:35:10.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5228" for this suite.

• [SLOW TEST:9.861 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":346,"completed":151,"skipped":2758,"failed":0}
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:35:10.616: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should adopt matching pods on creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Given a Pod with a 'name' label pod-adoption is created
Aug 24 12:35:10.713: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:35:12.723: INFO: The status of Pod pod-adoption is Running (Ready = true)
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:35:13.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2791" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":346,"completed":152,"skipped":2759,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:35:13.791: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 12:35:14.678: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 12:35:17.712: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:35:17.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-249" for this suite.
STEP: Destroying namespace "webhook-249-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":346,"completed":153,"skipped":2794,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:35:17.980: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:35:24.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1497" for this suite.
STEP: Destroying namespace "nsdeletetest-1031" for this suite.
Aug 24 12:35:24.238: INFO: Namespace nsdeletetest-1031 was already deleted
STEP: Destroying namespace "nsdeletetest-2677" for this suite.

• [SLOW TEST:6.269 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":346,"completed":154,"skipped":2815,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:35:24.264: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:35:35.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5234" for this suite.

• [SLOW TEST:11.155 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":346,"completed":155,"skipped":2868,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:35:35.423: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating secret with name s-test-opt-del-f31da462-c7e2-4e1c-b668-f9c359ccdcca
STEP: Creating secret with name s-test-opt-upd-05f1f496-f1c5-4032-9094-6616ff435bc5
STEP: Creating the pod
Aug 24 12:35:35.524: INFO: The status of Pod pod-secrets-bd8b530f-e73c-403a-9e7a-73ac5593c4bb is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:35:37.541: INFO: The status of Pod pod-secrets-bd8b530f-e73c-403a-9e7a-73ac5593c4bb is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-f31da462-c7e2-4e1c-b668-f9c359ccdcca
STEP: Updating secret s-test-opt-upd-05f1f496-f1c5-4032-9094-6616ff435bc5
STEP: Creating secret with name s-test-opt-create-fc1fd4a4-a0f0-4fce-a668-981f5b970dc2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:35:39.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8191" for this suite.
•{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":156,"skipped":2896,"failed":0}
SS
------------------------------
[sig-apps] CronJob 
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:35:39.747: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a ForbidConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring no more jobs are scheduled
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:41:01.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-776" for this suite.

• [SLOW TEST:322.173 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","total":346,"completed":157,"skipped":2898,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:41:01.923: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/instrumentation/events.go:81
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
STEP: listing events with field selection filtering on source
STEP: listing events with field selection filtering on reportingController
STEP: getting the test event
STEP: patching the test event
STEP: getting the test event
STEP: updating the test event
STEP: getting the test event
STEP: deleting the test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
[AfterEach] [sig-instrumentation] Events API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:41:02.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6262" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":346,"completed":158,"skipped":2913,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:41:02.139: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 12:41:03.156: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 12:41:06.239: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:41:06.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5177" for this suite.
STEP: Destroying namespace "webhook-5177-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":346,"completed":159,"skipped":2914,"failed":0}

------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:41:06.558: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Performing setup for networking test in namespace pod-network-test-412
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 24 12:41:06.620: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 24 12:41:06.701: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:41:08.712: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:41:10.714: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:41:12.721: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:41:14.721: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:41:16.713: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:41:18.711: INFO: The status of Pod netserver-0 is Running (Ready = true)
Aug 24 12:41:18.721: INFO: The status of Pod netserver-1 is Running (Ready = true)
Aug 24 12:41:18.732: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Aug 24 12:41:20.785: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Aug 24 12:41:20.785: INFO: Breadth first check of 10.233.64.84 on host 192.168.121.241...
Aug 24 12:41:20.790: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.87:9080/dial?request=hostname&protocol=http&host=10.233.64.84&port=8083&tries=1'] Namespace:pod-network-test-412 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:41:20.790: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:41:20.791: INFO: ExecWithOptions: Clientset creation
Aug 24 12:41:20.791: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-412/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.87%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.64.84%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:41:20.999: INFO: Waiting for responses: map[]
Aug 24 12:41:20.999: INFO: reached 10.233.64.84 after 0/1 tries
Aug 24 12:41:20.999: INFO: Breadth first check of 10.233.65.38 on host 192.168.121.182...
Aug 24 12:41:21.007: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.87:9080/dial?request=hostname&protocol=http&host=10.233.65.38&port=8083&tries=1'] Namespace:pod-network-test-412 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:41:21.007: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:41:21.009: INFO: ExecWithOptions: Clientset creation
Aug 24 12:41:21.009: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-412/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.87%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.65.38%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:41:21.145: INFO: Waiting for responses: map[]
Aug 24 12:41:21.145: INFO: reached 10.233.65.38 after 0/1 tries
Aug 24 12:41:21.145: INFO: Breadth first check of 10.233.66.86 on host 192.168.121.108...
Aug 24 12:41:21.181: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.87:9080/dial?request=hostname&protocol=http&host=10.233.66.86&port=8083&tries=1'] Namespace:pod-network-test-412 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:41:21.181: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:41:21.182: INFO: ExecWithOptions: Clientset creation
Aug 24 12:41:21.182: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-412/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.87%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.66.86%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:41:21.306: INFO: Waiting for responses: map[]
Aug 24 12:41:21.306: INFO: reached 10.233.66.86 after 0/1 tries
Aug 24 12:41:21.306: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:41:21.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-412" for this suite.

• [SLOW TEST:14.771 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":346,"completed":160,"skipped":2914,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:41:21.336: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:41:21.376: INFO: Creating deployment "test-recreate-deployment"
Aug 24 12:41:21.384: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 24 12:41:21.398: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug 24 12:41:23.414: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 24 12:41:23.419: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 24 12:41:23.438: INFO: Updating deployment test-recreate-deployment
Aug 24 12:41:23.438: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Aug 24 12:41:23.604: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-9083  d899f080-bcd1-4020-8f51-c4bc5806de49 34946 2 2022-08-24 12:41:21 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-08-24 12:41:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 12:41:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00448b1e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-08-24 12:41:23 +0000 UTC,LastTransitionTime:2022-08-24 12:41:23 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5b99bd5487" is progressing.,LastUpdateTime:2022-08-24 12:41:23 +0000 UTC,LastTransitionTime:2022-08-24 12:41:21 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Aug 24 12:41:23.611: INFO: New ReplicaSet "test-recreate-deployment-5b99bd5487" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5b99bd5487  deployment-9083  6495fcb0-e87e-49a4-bc7a-7894477783c7 34943 1 2022-08-24 12:41:23 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5b99bd5487] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment d899f080-bcd1-4020-8f51-c4bc5806de49 0xc00448b707 0xc00448b708}] []  [{kube-controller-manager Update apps/v1 2022-08-24 12:41:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d899f080-bcd1-4020-8f51-c4bc5806de49\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 12:41:23 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5b99bd5487,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5b99bd5487] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00448b7a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 24 12:41:23.611: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 24 12:41:23.612: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-594f666cd9  deployment-9083  b1f78df5-3a91-4604-bd9c-2aeb6a6a4114 34934 2 2022-08-24 12:41:21 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:594f666cd9] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment d899f080-bcd1-4020-8f51-c4bc5806de49 0xc00448b5e7 0xc00448b5e8}] []  [{kube-controller-manager Update apps/v1 2022-08-24 12:41:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d899f080-bcd1-4020-8f51-c4bc5806de49\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 12:41:23 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 594f666cd9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:594f666cd9] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00448b698 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Aug 24 12:41:23.618: INFO: Pod "test-recreate-deployment-5b99bd5487-2tww5" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5b99bd5487-2tww5 test-recreate-deployment-5b99bd5487- deployment-9083  39fb1994-95d1-4c87-8ed2-a9206ac83a12 34944 0 2022-08-24 12:41:23 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5b99bd5487] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5b99bd5487 6495fcb0-e87e-49a4-bc7a-7894477783c7 0xc007adcbc7 0xc007adcbc8}] []  [{kube-controller-manager Update v1 2022-08-24 12:41:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"6495fcb0-e87e-49a4-bc7a-7894477783c7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 12:41:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mzqck,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mzqck,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:41:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:41:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:41:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 12:41:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:,StartTime:2022-08-24 12:41:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:41:23.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9083" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":346,"completed":161,"skipped":3019,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:41:23.638: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating pod liveness-50f3ecab-16e6-4c49-b5dc-2ce1ec5866e2 in namespace container-probe-7309
Aug 24 12:41:25.726: INFO: Started pod liveness-50f3ecab-16e6-4c49-b5dc-2ce1ec5866e2 in namespace container-probe-7309
STEP: checking the pod's current state and verifying that restartCount is present
Aug 24 12:41:25.732: INFO: Initial restart count of pod liveness-50f3ecab-16e6-4c49-b5dc-2ce1ec5866e2 is 0
Aug 24 12:41:45.848: INFO: Restart count of pod container-probe-7309/liveness-50f3ecab-16e6-4c49-b5dc-2ce1ec5866e2 is now 1 (20.116006793s elapsed)
Aug 24 12:42:05.998: INFO: Restart count of pod container-probe-7309/liveness-50f3ecab-16e6-4c49-b5dc-2ce1ec5866e2 is now 2 (40.266363891s elapsed)
Aug 24 12:42:26.131: INFO: Restart count of pod container-probe-7309/liveness-50f3ecab-16e6-4c49-b5dc-2ce1ec5866e2 is now 3 (1m0.398880773s elapsed)
Aug 24 12:42:46.268: INFO: Restart count of pod container-probe-7309/liveness-50f3ecab-16e6-4c49-b5dc-2ce1ec5866e2 is now 4 (1m20.53600932s elapsed)
Aug 24 12:43:58.725: INFO: Restart count of pod container-probe-7309/liveness-50f3ecab-16e6-4c49-b5dc-2ce1ec5866e2 is now 5 (2m32.993420996s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:43:58.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7309" for this suite.

• [SLOW TEST:155.144 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":346,"completed":162,"skipped":3037,"failed":0}
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should test the lifecycle of a ReplicationController [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:43:58.783: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should test the lifecycle of a ReplicationController [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a ReplicationController
STEP: waiting for RC to be added
STEP: waiting for available Replicas
STEP: patching ReplicationController
STEP: waiting for RC to be modified
STEP: patching ReplicationController status
STEP: waiting for RC to be modified
STEP: waiting for available Replicas
STEP: fetching ReplicationController status
STEP: patching ReplicationController scale
STEP: waiting for RC to be modified
STEP: waiting for ReplicationController's scale to be the max amount
STEP: fetching ReplicationController; ensuring that it's patched
STEP: updating ReplicationController status
STEP: waiting for RC to be modified
STEP: listing all ReplicationControllers
STEP: checking that ReplicationController has expected values
STEP: deleting ReplicationControllers by collection
STEP: waiting for ReplicationController to have a DELETED watchEvent
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:44:01.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9836" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","total":346,"completed":163,"skipped":3044,"failed":0}
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:44:01.838: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating secret with name secret-test-12868e15-bd62-41d9-8189-72fc23452e58
STEP: Creating a pod to test consume secrets
Aug 24 12:44:01.933: INFO: Waiting up to 5m0s for pod "pod-secrets-0d167525-9fdf-4f5f-91ec-4a9a81763109" in namespace "secrets-1161" to be "Succeeded or Failed"
Aug 24 12:44:01.940: INFO: Pod "pod-secrets-0d167525-9fdf-4f5f-91ec-4a9a81763109": Phase="Pending", Reason="", readiness=false. Elapsed: 6.763049ms
Aug 24 12:44:03.951: INFO: Pod "pod-secrets-0d167525-9fdf-4f5f-91ec-4a9a81763109": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017699701s
Aug 24 12:44:05.970: INFO: Pod "pod-secrets-0d167525-9fdf-4f5f-91ec-4a9a81763109": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036622866s
STEP: Saw pod success
Aug 24 12:44:05.970: INFO: Pod "pod-secrets-0d167525-9fdf-4f5f-91ec-4a9a81763109" satisfied condition "Succeeded or Failed"
Aug 24 12:44:05.977: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-secrets-0d167525-9fdf-4f5f-91ec-4a9a81763109 container secret-volume-test: <nil>
STEP: delete the pod
Aug 24 12:44:06.030: INFO: Waiting for pod pod-secrets-0d167525-9fdf-4f5f-91ec-4a9a81763109 to disappear
Aug 24 12:44:06.036: INFO: Pod pod-secrets-0d167525-9fdf-4f5f-91ec-4a9a81763109 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:44:06.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1161" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":164,"skipped":3045,"failed":0}
S
------------------------------
[sig-apps] ReplicaSet 
  should validate Replicaset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:44:06.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should validate Replicaset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Create a Replicaset
STEP: Verify that the required pods have come up.
Aug 24 12:44:06.130: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 24 12:44:11.142: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Getting /status
Aug 24 12:44:11.150: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status
Aug 24 12:44:11.167: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated
Aug 24 12:44:11.170: INFO: Observed &ReplicaSet event: ADDED
Aug 24 12:44:11.170: INFO: Observed &ReplicaSet event: MODIFIED
Aug 24 12:44:11.170: INFO: Observed &ReplicaSet event: MODIFIED
Aug 24 12:44:11.170: INFO: Observed &ReplicaSet event: MODIFIED
Aug 24 12:44:11.170: INFO: Found replicaset test-rs in namespace replicaset-6428 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 24 12:44:11.170: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status
Aug 24 12:44:11.171: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug 24 12:44:11.183: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched
Aug 24 12:44:11.186: INFO: Observed &ReplicaSet event: ADDED
Aug 24 12:44:11.186: INFO: Observed &ReplicaSet event: MODIFIED
Aug 24 12:44:11.187: INFO: Observed &ReplicaSet event: MODIFIED
Aug 24 12:44:11.187: INFO: Observed &ReplicaSet event: MODIFIED
Aug 24 12:44:11.187: INFO: Observed replicaset test-rs in namespace replicaset-6428 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 24 12:44:11.187: INFO: Observed &ReplicaSet event: MODIFIED
Aug 24 12:44:11.188: INFO: Found replicaset test-rs in namespace replicaset-6428 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Aug 24 12:44:11.188: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:44:11.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6428" for this suite.

• [SLOW TEST:5.152 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","total":346,"completed":165,"skipped":3046,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:44:11.211: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:44:13.285: INFO: Deleting pod "var-expansion-36883112-26ca-43e2-b361-6f7b6a947e9d" in namespace "var-expansion-225"
Aug 24 12:44:13.301: INFO: Wait up to 5m0s for pod "var-expansion-36883112-26ca-43e2-b361-6f7b6a947e9d" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:44:15.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-225" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","total":346,"completed":166,"skipped":3186,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:44:15.339: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name cm-test-opt-del-f4bbc05f-e235-4e78-a98b-f2db2f7a4cb3
STEP: Creating configMap with name cm-test-opt-upd-3fc7bdac-e1ee-4d41-ad2f-ad037432c473
STEP: Creating the pod
Aug 24 12:44:15.446: INFO: The status of Pod pod-projected-configmaps-e2f81e3b-5cc8-41c9-8ece-c39f51a620ed is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:44:17.455: INFO: The status of Pod pod-projected-configmaps-e2f81e3b-5cc8-41c9-8ece-c39f51a620ed is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-f4bbc05f-e235-4e78-a98b-f2db2f7a4cb3
STEP: Updating configmap cm-test-opt-upd-3fc7bdac-e1ee-4d41-ad2f-ad037432c473
STEP: Creating configMap with name cm-test-opt-create-5cf36034-94d1-4386-a313-48702a956023
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:44:19.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9321" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":167,"skipped":3194,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:44:19.613: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test override all
Aug 24 12:44:19.686: INFO: Waiting up to 5m0s for pod "client-containers-51b1c2e0-2401-4146-b446-d13793280c31" in namespace "containers-1238" to be "Succeeded or Failed"
Aug 24 12:44:19.691: INFO: Pod "client-containers-51b1c2e0-2401-4146-b446-d13793280c31": Phase="Pending", Reason="", readiness=false. Elapsed: 4.980042ms
Aug 24 12:44:21.702: INFO: Pod "client-containers-51b1c2e0-2401-4146-b446-d13793280c31": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016135995s
Aug 24 12:44:23.714: INFO: Pod "client-containers-51b1c2e0-2401-4146-b446-d13793280c31": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028229145s
STEP: Saw pod success
Aug 24 12:44:23.714: INFO: Pod "client-containers-51b1c2e0-2401-4146-b446-d13793280c31" satisfied condition "Succeeded or Failed"
Aug 24 12:44:23.719: INFO: Trying to get logs from node zou9eicaeree-3 pod client-containers-51b1c2e0-2401-4146-b446-d13793280c31 container agnhost-container: <nil>
STEP: delete the pod
Aug 24 12:44:23.757: INFO: Waiting for pod client-containers-51b1c2e0-2401-4146-b446-d13793280c31 to disappear
Aug 24 12:44:23.766: INFO: Pod client-containers-51b1c2e0-2401-4146-b446-d13793280c31 no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:44:23.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1238" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":346,"completed":168,"skipped":3211,"failed":0}
SSSSSS
------------------------------
[sig-node] PodTemplates 
  should delete a collection of pod templates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:44:23.792: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a collection of pod templates [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Create set of pod templates
Aug 24 12:44:23.845: INFO: created test-podtemplate-1
Aug 24 12:44:23.858: INFO: created test-podtemplate-2
Aug 24 12:44:23.865: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace
STEP: delete collection of pod templates
Aug 24 12:44:23.872: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity
Aug 24 12:44:23.905: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:44:23.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-4107" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","total":346,"completed":169,"skipped":3217,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:44:23.935: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:44:24.004: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-81a63d27-c8ee-4319-8647-3fb8c14ddf0d" in namespace "security-context-test-8814" to be "Succeeded or Failed"
Aug 24 12:44:24.010: INFO: Pod "alpine-nnp-false-81a63d27-c8ee-4319-8647-3fb8c14ddf0d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.789767ms
Aug 24 12:44:26.028: INFO: Pod "alpine-nnp-false-81a63d27-c8ee-4319-8647-3fb8c14ddf0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023733615s
Aug 24 12:44:28.041: INFO: Pod "alpine-nnp-false-81a63d27-c8ee-4319-8647-3fb8c14ddf0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036771868s
Aug 24 12:44:30.052: INFO: Pod "alpine-nnp-false-81a63d27-c8ee-4319-8647-3fb8c14ddf0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.047215775s
Aug 24 12:44:30.052: INFO: Pod "alpine-nnp-false-81a63d27-c8ee-4319-8647-3fb8c14ddf0d" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:44:30.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8814" for this suite.

• [SLOW TEST:6.148 seconds]
[sig-node] Security Context
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:296
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":170,"skipped":3228,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:44:30.083: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating the pod
Aug 24 12:44:30.145: INFO: The status of Pod annotationupdate6c602acf-f72c-491a-b83e-6352583f1cbf is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:44:32.157: INFO: The status of Pod annotationupdate6c602acf-f72c-491a-b83e-6352583f1cbf is Running (Ready = true)
Aug 24 12:44:32.694: INFO: Successfully updated pod "annotationupdate6c602acf-f72c-491a-b83e-6352583f1cbf"
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:44:36.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8527" for this suite.

• [SLOW TEST:6.680 seconds]
[sig-storage] Downward API volume
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":346,"completed":171,"skipped":3229,"failed":0}
SS
------------------------------
[sig-network] Services 
  should complete a service status lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:44:36.765: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should complete a service status lifecycle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a Service
STEP: watching for the Service to be added
Aug 24 12:44:36.832: INFO: Found Service test-service-lz8nx in namespace services-184 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Aug 24 12:44:36.832: INFO: Service test-service-lz8nx created
STEP: Getting /status
Aug 24 12:44:36.839: INFO: Service test-service-lz8nx has LoadBalancer: {[]}
STEP: patching the ServiceStatus
STEP: watching for the Service to be patched
Aug 24 12:44:36.852: INFO: observed Service test-service-lz8nx in namespace services-184 with annotations: map[] & LoadBalancer: {[]}
Aug 24 12:44:36.852: INFO: Found Service test-service-lz8nx in namespace services-184 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Aug 24 12:44:36.852: INFO: Service test-service-lz8nx has service status patched
STEP: updating the ServiceStatus
Aug 24 12:44:36.875: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated
Aug 24 12:44:36.878: INFO: Observed Service test-service-lz8nx in namespace services-184 with annotations: map[] & Conditions: {[]}
Aug 24 12:44:36.878: INFO: Observed event: &Service{ObjectMeta:{test-service-lz8nx  services-184  e96dd598-fc6e-43e0-a63a-001fb47f787d 35660 0 2022-08-24 12:44:36 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] []  [{e2e.test Update v1 2022-08-24 12:44:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-08-24 12:44:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.233.17.147,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.233.17.147],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Aug 24 12:44:36.878: INFO: Found Service test-service-lz8nx in namespace services-184 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 24 12:44:36.879: INFO: Service test-service-lz8nx has service status updated
STEP: patching the service
STEP: watching for the Service to be patched
Aug 24 12:44:36.912: INFO: observed Service test-service-lz8nx in namespace services-184 with labels: map[test-service-static:true]
Aug 24 12:44:36.913: INFO: observed Service test-service-lz8nx in namespace services-184 with labels: map[test-service-static:true]
Aug 24 12:44:36.913: INFO: observed Service test-service-lz8nx in namespace services-184 with labels: map[test-service-static:true]
Aug 24 12:44:36.913: INFO: Found Service test-service-lz8nx in namespace services-184 with labels: map[test-service:patched test-service-static:true]
Aug 24 12:44:36.913: INFO: Service test-service-lz8nx patched
STEP: deleting the service
STEP: watching for the Service to be deleted
Aug 24 12:44:36.935: INFO: Observed event: ADDED
Aug 24 12:44:36.935: INFO: Observed event: MODIFIED
Aug 24 12:44:36.935: INFO: Observed event: MODIFIED
Aug 24 12:44:36.936: INFO: Observed event: MODIFIED
Aug 24 12:44:36.937: INFO: Found Service test-service-lz8nx in namespace services-184 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Aug 24 12:44:36.937: INFO: Service test-service-lz8nx deleted
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:44:36.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-184" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756
•{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","total":346,"completed":172,"skipped":3231,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:44:36.965: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name projected-configmap-test-volume-bb611b87-09f1-455f-bf69-97a9d6144130
STEP: Creating a pod to test consume configMaps
Aug 24 12:44:37.054: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d1bdfb7d-227e-4675-8e68-3882c519fa5c" in namespace "projected-2073" to be "Succeeded or Failed"
Aug 24 12:44:37.059: INFO: Pod "pod-projected-configmaps-d1bdfb7d-227e-4675-8e68-3882c519fa5c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.920515ms
Aug 24 12:44:39.067: INFO: Pod "pod-projected-configmaps-d1bdfb7d-227e-4675-8e68-3882c519fa5c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01302931s
Aug 24 12:44:41.079: INFO: Pod "pod-projected-configmaps-d1bdfb7d-227e-4675-8e68-3882c519fa5c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02494306s
STEP: Saw pod success
Aug 24 12:44:41.080: INFO: Pod "pod-projected-configmaps-d1bdfb7d-227e-4675-8e68-3882c519fa5c" satisfied condition "Succeeded or Failed"
Aug 24 12:44:41.085: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-projected-configmaps-d1bdfb7d-227e-4675-8e68-3882c519fa5c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 24 12:44:41.122: INFO: Waiting for pod pod-projected-configmaps-d1bdfb7d-227e-4675-8e68-3882c519fa5c to disappear
Aug 24 12:44:41.134: INFO: Pod pod-projected-configmaps-d1bdfb7d-227e-4675-8e68-3882c519fa5c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:44:41.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2073" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":346,"completed":173,"skipped":3241,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:44:41.158: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:44:43.248: INFO: Deleting pod "var-expansion-29234741-81cc-4611-820b-8b9e004e3cf5" in namespace "var-expansion-9187"
Aug 24 12:44:43.259: INFO: Wait up to 5m0s for pod "var-expansion-29234741-81cc-4611-820b-8b9e004e3cf5" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:44:45.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9187" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","total":346,"completed":174,"skipped":3282,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:44:45.297: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 12:44:45.403: INFO: Waiting up to 5m0s for pod "downwardapi-volume-00067f23-43a4-4f63-9250-79328d7b74be" in namespace "downward-api-7751" to be "Succeeded or Failed"
Aug 24 12:44:45.409: INFO: Pod "downwardapi-volume-00067f23-43a4-4f63-9250-79328d7b74be": Phase="Pending", Reason="", readiness=false. Elapsed: 6.304767ms
Aug 24 12:44:47.419: INFO: Pod "downwardapi-volume-00067f23-43a4-4f63-9250-79328d7b74be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015831381s
Aug 24 12:44:49.433: INFO: Pod "downwardapi-volume-00067f23-43a4-4f63-9250-79328d7b74be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029914528s
STEP: Saw pod success
Aug 24 12:44:49.433: INFO: Pod "downwardapi-volume-00067f23-43a4-4f63-9250-79328d7b74be" satisfied condition "Succeeded or Failed"
Aug 24 12:44:49.439: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-00067f23-43a4-4f63-9250-79328d7b74be container client-container: <nil>
STEP: delete the pod
Aug 24 12:44:49.469: INFO: Waiting for pod downwardapi-volume-00067f23-43a4-4f63-9250-79328d7b74be to disappear
Aug 24 12:44:49.473: INFO: Pod downwardapi-volume-00067f23-43a4-4f63-9250-79328d7b74be no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:44:49.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7751" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":175,"skipped":3297,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:44:49.494: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name configmap-test-volume-7d6fa8aa-2796-487e-b759-450f1342bb3e
STEP: Creating a pod to test consume configMaps
Aug 24 12:44:49.603: INFO: Waiting up to 5m0s for pod "pod-configmaps-236ca8fa-8f09-4acd-9bb7-3b0c4a65c479" in namespace "configmap-2339" to be "Succeeded or Failed"
Aug 24 12:44:49.608: INFO: Pod "pod-configmaps-236ca8fa-8f09-4acd-9bb7-3b0c4a65c479": Phase="Pending", Reason="", readiness=false. Elapsed: 5.260233ms
Aug 24 12:44:51.619: INFO: Pod "pod-configmaps-236ca8fa-8f09-4acd-9bb7-3b0c4a65c479": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015693871s
Aug 24 12:44:53.634: INFO: Pod "pod-configmaps-236ca8fa-8f09-4acd-9bb7-3b0c4a65c479": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031032634s
STEP: Saw pod success
Aug 24 12:44:53.634: INFO: Pod "pod-configmaps-236ca8fa-8f09-4acd-9bb7-3b0c4a65c479" satisfied condition "Succeeded or Failed"
Aug 24 12:44:53.641: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-configmaps-236ca8fa-8f09-4acd-9bb7-3b0c4a65c479 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 24 12:44:53.689: INFO: Waiting for pod pod-configmaps-236ca8fa-8f09-4acd-9bb7-3b0c4a65c479 to disappear
Aug 24 12:44:53.697: INFO: Pod pod-configmaps-236ca8fa-8f09-4acd-9bb7-3b0c4a65c479 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:44:53.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2339" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":346,"completed":176,"skipped":3310,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:44:53.716: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:45:00.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8493" for this suite.

• [SLOW TEST:7.128 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":346,"completed":177,"skipped":3315,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:45:00.849: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl run pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1539
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Aug 24 12:45:00.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-2 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2'
Aug 24 12:45:01.158: INFO: stderr: ""
Aug 24 12:45:01.158: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1543
Aug 24 12:45:01.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-2 delete pods e2e-test-httpd-pod'
Aug 24 12:45:03.000: INFO: stderr: ""
Aug 24 12:45:03.000: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:45:03.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":346,"completed":178,"skipped":3326,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:45:03.022: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 24 12:45:03.105: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3012  f46f32fb-60c1-4b71-b5de-1c9b2cb92be3 35874 0 2022-08-24 12:45:03 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-08-24 12:45:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 12:45:03.105: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3012  f46f32fb-60c1-4b71-b5de-1c9b2cb92be3 35875 0 2022-08-24 12:45:03 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-08-24 12:45:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:45:03.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3012" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":346,"completed":179,"skipped":3348,"failed":0}
SSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:45:03.126: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:46
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:45:03.183: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-b258e09c-f7ad-4568-b141-daa8c359bb55" in namespace "security-context-test-9379" to be "Succeeded or Failed"
Aug 24 12:45:03.191: INFO: Pod "busybox-privileged-false-b258e09c-f7ad-4568-b141-daa8c359bb55": Phase="Pending", Reason="", readiness=false. Elapsed: 8.051128ms
Aug 24 12:45:05.206: INFO: Pod "busybox-privileged-false-b258e09c-f7ad-4568-b141-daa8c359bb55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02362125s
Aug 24 12:45:07.213: INFO: Pod "busybox-privileged-false-b258e09c-f7ad-4568-b141-daa8c359bb55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03061138s
Aug 24 12:45:09.229: INFO: Pod "busybox-privileged-false-b258e09c-f7ad-4568-b141-daa8c359bb55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.046460178s
Aug 24 12:45:09.229: INFO: Pod "busybox-privileged-false-b258e09c-f7ad-4568-b141-daa8c359bb55" satisfied condition "Succeeded or Failed"
Aug 24 12:45:09.240: INFO: Got logs for pod "busybox-privileged-false-b258e09c-f7ad-4568-b141-daa8c359bb55": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:45:09.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9379" for this suite.

• [SLOW TEST:6.131 seconds]
[sig-node] Security Context
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/security_context.go:232
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":180,"skipped":3352,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:45:09.258: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:45:09.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3984" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":346,"completed":181,"skipped":3389,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:45:09.368: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [sig-node] Container Runtime
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:45:36.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7029" for this suite.

• [SLOW TEST:27.559 seconds]
[sig-node] Container Runtime
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  blackbox test
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/runtime.go:41
    when starting a container that exits
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/runtime.go:42
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":346,"completed":182,"skipped":3399,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should schedule multiple jobs concurrently [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:45:36.928: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule multiple jobs concurrently [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a cronjob
STEP: Ensuring more than one job is running at a time
STEP: Ensuring at least two running jobs exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:47:01.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9681" for this suite.

• [SLOW TEST:84.105 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","total":346,"completed":183,"skipped":3413,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:47:01.035: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 12:47:02.446: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 12:47:05.481: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:47:15.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4041" for this suite.
STEP: Destroying namespace "webhook-4041-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:14.774 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":346,"completed":184,"skipped":3449,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:47:15.812: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Aug 24 12:47:15.878: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7302  f8a72676-2dc0-4e57-9a9e-deb5df53a2c3 36337 0 2022-08-24 12:47:15 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2022-08-24 12:47:15 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pndgj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pndgj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 12:47:15.885: INFO: The status of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:47:17.896: INFO: The status of Pod test-dns-nameservers is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Aug 24 12:47:17.896: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7302 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:47:17.896: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:47:17.897: INFO: ExecWithOptions: Clientset creation
Aug 24 12:47:17.897: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-7302/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
STEP: Verifying customized DNS server is configured on pod...
Aug 24 12:47:18.030: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7302 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:47:18.030: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:47:18.031: INFO: ExecWithOptions: Clientset creation
Aug 24 12:47:18.031: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-7302/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:47:18.132: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:47:18.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7302" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":346,"completed":185,"skipped":3479,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run 
  should check if kubectl can dry-run update Pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:47:18.176: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl can dry-run update Pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Aug 24 12:47:18.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-7478 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Aug 24 12:47:18.440: INFO: stderr: ""
Aug 24 12:47:18.440: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run
Aug 24 12:47:18.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-7478 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "k8s.gcr.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Aug 24 12:47:18.767: INFO: stderr: ""
Aug 24 12:47:18.767: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Aug 24 12:47:18.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-7478 delete pods e2e-test-httpd-pod'
Aug 24 12:47:20.495: INFO: stderr: ""
Aug 24 12:47:20.495: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:47:20.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7478" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","total":346,"completed":186,"skipped":3494,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:47:20.519: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:47:20.587: INFO: Endpoints addresses: [192.168.121.182 192.168.121.241] , ports: [6443]
Aug 24 12:47:20.587: INFO: EndpointSlices addresses: [192.168.121.182 192.168.121.241] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:47:20.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-459" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","total":346,"completed":187,"skipped":3504,"failed":0}

------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:47:20.603: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a Namespace
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:47:20.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9063" for this suite.
STEP: Destroying namespace "nspatchtest-d6780eff-3f69-45ed-9b83-aea2fe5ab47f-8859" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":346,"completed":188,"skipped":3504,"failed":0}

------------------------------
[sig-node] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:47:20.755: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test override command
Aug 24 12:47:20.815: INFO: Waiting up to 5m0s for pod "client-containers-e5c62068-8ecf-4d48-9283-69eb2a7c7d8a" in namespace "containers-9942" to be "Succeeded or Failed"
Aug 24 12:47:20.823: INFO: Pod "client-containers-e5c62068-8ecf-4d48-9283-69eb2a7c7d8a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.497773ms
Aug 24 12:47:22.835: INFO: Pod "client-containers-e5c62068-8ecf-4d48-9283-69eb2a7c7d8a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019578995s
Aug 24 12:47:24.848: INFO: Pod "client-containers-e5c62068-8ecf-4d48-9283-69eb2a7c7d8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032833445s
STEP: Saw pod success
Aug 24 12:47:24.848: INFO: Pod "client-containers-e5c62068-8ecf-4d48-9283-69eb2a7c7d8a" satisfied condition "Succeeded or Failed"
Aug 24 12:47:24.854: INFO: Trying to get logs from node zou9eicaeree-3 pod client-containers-e5c62068-8ecf-4d48-9283-69eb2a7c7d8a container agnhost-container: <nil>
STEP: delete the pod
Aug 24 12:47:24.894: INFO: Waiting for pod client-containers-e5c62068-8ecf-4d48-9283-69eb2a7c7d8a to disappear
Aug 24 12:47:24.898: INFO: Pod client-containers-e5c62068-8ecf-4d48-9283-69eb2a7c7d8a no longer exists
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:47:24.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9942" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":346,"completed":189,"skipped":3504,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:47:24.914: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Aug 24 12:47:24.975: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Aug 24 12:47:24.984: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Aug 24 12:47:24.984: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Aug 24 12:47:24.997: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Aug 24 12:47:24.997: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Aug 24 12:47:25.012: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Aug 24 12:47:25.012: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Aug 24 12:47:32.086: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:47:32.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-8470" for this suite.

• [SLOW TEST:7.223 seconds]
[sig-scheduling] LimitRange
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":346,"completed":190,"skipped":3567,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:47:32.138: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 24 12:47:32.221: INFO: Waiting up to 5m0s for pod "pod-188157ac-5157-438f-8b8e-99608fab208e" in namespace "emptydir-2425" to be "Succeeded or Failed"
Aug 24 12:47:32.228: INFO: Pod "pod-188157ac-5157-438f-8b8e-99608fab208e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.736289ms
Aug 24 12:47:34.240: INFO: Pod "pod-188157ac-5157-438f-8b8e-99608fab208e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018767819s
Aug 24 12:47:36.252: INFO: Pod "pod-188157ac-5157-438f-8b8e-99608fab208e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031219164s
STEP: Saw pod success
Aug 24 12:47:36.252: INFO: Pod "pod-188157ac-5157-438f-8b8e-99608fab208e" satisfied condition "Succeeded or Failed"
Aug 24 12:47:36.259: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-188157ac-5157-438f-8b8e-99608fab208e container test-container: <nil>
STEP: delete the pod
Aug 24 12:47:36.287: INFO: Waiting for pod pod-188157ac-5157-438f-8b8e-99608fab208e to disappear
Aug 24 12:47:36.291: INFO: Pod pod-188157ac-5157-438f-8b8e-99608fab208e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:47:36.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2425" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":191,"skipped":3580,"failed":0}
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:47:36.308: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:53
STEP: create the container to handle the HTTPGet hook request.
Aug 24 12:47:36.378: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:47:38.386: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create the pod with lifecycle hook
Aug 24 12:47:38.405: INFO: The status of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:47:40.414: INFO: The status of Pod pod-with-prestop-exec-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Aug 24 12:47:40.431: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 24 12:47:40.438: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 24 12:47:42.439: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 24 12:47:42.446: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 24 12:47:44.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 24 12:47:44.451: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:47:44.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6580" for this suite.

• [SLOW TEST:8.176 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:44
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":346,"completed":192,"skipped":3587,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:47:44.486: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap configmap-176/configmap-test-d14fcb15-4cfe-45a8-876b-f884c2249038
STEP: Creating a pod to test consume configMaps
Aug 24 12:47:44.547: INFO: Waiting up to 5m0s for pod "pod-configmaps-68ec94dc-ffc2-4566-94df-0ee5013e1e7c" in namespace "configmap-176" to be "Succeeded or Failed"
Aug 24 12:47:44.555: INFO: Pod "pod-configmaps-68ec94dc-ffc2-4566-94df-0ee5013e1e7c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.540198ms
Aug 24 12:47:46.569: INFO: Pod "pod-configmaps-68ec94dc-ffc2-4566-94df-0ee5013e1e7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02160358s
Aug 24 12:47:48.584: INFO: Pod "pod-configmaps-68ec94dc-ffc2-4566-94df-0ee5013e1e7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036547523s
STEP: Saw pod success
Aug 24 12:47:48.584: INFO: Pod "pod-configmaps-68ec94dc-ffc2-4566-94df-0ee5013e1e7c" satisfied condition "Succeeded or Failed"
Aug 24 12:47:48.591: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-configmaps-68ec94dc-ffc2-4566-94df-0ee5013e1e7c container env-test: <nil>
STEP: delete the pod
Aug 24 12:47:48.623: INFO: Waiting for pod pod-configmaps-68ec94dc-ffc2-4566-94df-0ee5013e1e7c to disappear
Aug 24 12:47:48.627: INFO: Pod pod-configmaps-68ec94dc-ffc2-4566-94df-0ee5013e1e7c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:47:48.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-176" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":346,"completed":193,"skipped":3630,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:47:48.649: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 24 12:47:48.706: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3297  884d9e59-9146-4378-b0af-81df2e5b7396 36662 0 2022-08-24 12:47:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-24 12:47:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 12:47:48.707: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3297  884d9e59-9146-4378-b0af-81df2e5b7396 36662 0 2022-08-24 12:47:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-24 12:47:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 24 12:47:48.718: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3297  884d9e59-9146-4378-b0af-81df2e5b7396 36664 0 2022-08-24 12:47:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-24 12:47:48 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 12:47:48.719: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3297  884d9e59-9146-4378-b0af-81df2e5b7396 36664 0 2022-08-24 12:47:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-24 12:47:48 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 24 12:47:48.729: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3297  884d9e59-9146-4378-b0af-81df2e5b7396 36665 0 2022-08-24 12:47:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-24 12:47:48 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 12:47:48.730: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3297  884d9e59-9146-4378-b0af-81df2e5b7396 36665 0 2022-08-24 12:47:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-24 12:47:48 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 24 12:47:48.738: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3297  884d9e59-9146-4378-b0af-81df2e5b7396 36666 0 2022-08-24 12:47:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-24 12:47:48 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 12:47:48.739: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3297  884d9e59-9146-4378-b0af-81df2e5b7396 36666 0 2022-08-24 12:47:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-08-24 12:47:48 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 24 12:47:48.747: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3297  ac5f3479-32e1-4a53-b622-c4487f0bd4f3 36667 0 2022-08-24 12:47:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-08-24 12:47:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 12:47:48.747: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3297  ac5f3479-32e1-4a53-b622-c4487f0bd4f3 36667 0 2022-08-24 12:47:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-08-24 12:47:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 24 12:47:58.765: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3297  ac5f3479-32e1-4a53-b622-c4487f0bd4f3 36710 0 2022-08-24 12:47:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-08-24 12:47:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 12:47:58.765: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3297  ac5f3479-32e1-4a53-b622-c4487f0bd4f3 36710 0 2022-08-24 12:47:48 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-08-24 12:47:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:48:08.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3297" for this suite.

• [SLOW TEST:20.149 seconds]
[sig-api-machinery] Watchers
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":346,"completed":194,"skipped":3653,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery 
  should validate PreferredVersion for each APIGroup [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:48:08.801: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename discovery
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:39
STEP: Setting up server cert
[It] should validate PreferredVersion for each APIGroup [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:48:09.983: INFO: Checking APIGroup: apiregistration.k8s.io
Aug 24 12:48:09.986: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Aug 24 12:48:09.986: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Aug 24 12:48:09.986: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Aug 24 12:48:09.986: INFO: Checking APIGroup: apps
Aug 24 12:48:09.987: INFO: PreferredVersion.GroupVersion: apps/v1
Aug 24 12:48:09.987: INFO: Versions found [{apps/v1 v1}]
Aug 24 12:48:09.987: INFO: apps/v1 matches apps/v1
Aug 24 12:48:09.988: INFO: Checking APIGroup: events.k8s.io
Aug 24 12:48:09.990: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Aug 24 12:48:09.990: INFO: Versions found [{events.k8s.io/v1 v1} {events.k8s.io/v1beta1 v1beta1}]
Aug 24 12:48:09.990: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Aug 24 12:48:09.990: INFO: Checking APIGroup: authentication.k8s.io
Aug 24 12:48:09.991: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Aug 24 12:48:09.991: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Aug 24 12:48:09.991: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Aug 24 12:48:09.991: INFO: Checking APIGroup: authorization.k8s.io
Aug 24 12:48:09.993: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Aug 24 12:48:09.993: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Aug 24 12:48:09.993: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Aug 24 12:48:09.993: INFO: Checking APIGroup: autoscaling
Aug 24 12:48:09.995: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Aug 24 12:48:09.996: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta1 v2beta1} {autoscaling/v2beta2 v2beta2}]
Aug 24 12:48:09.996: INFO: autoscaling/v2 matches autoscaling/v2
Aug 24 12:48:09.996: INFO: Checking APIGroup: batch
Aug 24 12:48:09.998: INFO: PreferredVersion.GroupVersion: batch/v1
Aug 24 12:48:09.998: INFO: Versions found [{batch/v1 v1} {batch/v1beta1 v1beta1}]
Aug 24 12:48:09.998: INFO: batch/v1 matches batch/v1
Aug 24 12:48:09.998: INFO: Checking APIGroup: certificates.k8s.io
Aug 24 12:48:10.000: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Aug 24 12:48:10.000: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Aug 24 12:48:10.000: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Aug 24 12:48:10.000: INFO: Checking APIGroup: networking.k8s.io
Aug 24 12:48:10.002: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Aug 24 12:48:10.002: INFO: Versions found [{networking.k8s.io/v1 v1}]
Aug 24 12:48:10.002: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Aug 24 12:48:10.002: INFO: Checking APIGroup: policy
Aug 24 12:48:10.004: INFO: PreferredVersion.GroupVersion: policy/v1
Aug 24 12:48:10.004: INFO: Versions found [{policy/v1 v1} {policy/v1beta1 v1beta1}]
Aug 24 12:48:10.004: INFO: policy/v1 matches policy/v1
Aug 24 12:48:10.004: INFO: Checking APIGroup: rbac.authorization.k8s.io
Aug 24 12:48:10.005: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Aug 24 12:48:10.005: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Aug 24 12:48:10.005: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Aug 24 12:48:10.006: INFO: Checking APIGroup: storage.k8s.io
Aug 24 12:48:10.007: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Aug 24 12:48:10.007: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Aug 24 12:48:10.008: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Aug 24 12:48:10.008: INFO: Checking APIGroup: admissionregistration.k8s.io
Aug 24 12:48:10.009: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Aug 24 12:48:10.010: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Aug 24 12:48:10.010: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Aug 24 12:48:10.010: INFO: Checking APIGroup: apiextensions.k8s.io
Aug 24 12:48:10.011: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Aug 24 12:48:10.011: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Aug 24 12:48:10.011: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Aug 24 12:48:10.011: INFO: Checking APIGroup: scheduling.k8s.io
Aug 24 12:48:10.013: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Aug 24 12:48:10.013: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Aug 24 12:48:10.013: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Aug 24 12:48:10.013: INFO: Checking APIGroup: coordination.k8s.io
Aug 24 12:48:10.015: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Aug 24 12:48:10.015: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Aug 24 12:48:10.015: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Aug 24 12:48:10.016: INFO: Checking APIGroup: node.k8s.io
Aug 24 12:48:10.017: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Aug 24 12:48:10.018: INFO: Versions found [{node.k8s.io/v1 v1} {node.k8s.io/v1beta1 v1beta1}]
Aug 24 12:48:10.018: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Aug 24 12:48:10.018: INFO: Checking APIGroup: discovery.k8s.io
Aug 24 12:48:10.020: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Aug 24 12:48:10.020: INFO: Versions found [{discovery.k8s.io/v1 v1} {discovery.k8s.io/v1beta1 v1beta1}]
Aug 24 12:48:10.020: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Aug 24 12:48:10.020: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Aug 24 12:48:10.021: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Aug 24 12:48:10.021: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Aug 24 12:48:10.022: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
[AfterEach] [sig-api-machinery] Discovery
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:48:10.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-7388" for this suite.
•{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","total":346,"completed":195,"skipped":3672,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should delete a collection of services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:48:10.049: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should delete a collection of services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a collection of services
Aug 24 12:48:10.096: INFO: Creating e2e-svc-a-jj89k
Aug 24 12:48:10.119: INFO: Creating e2e-svc-b-t8sgt
Aug 24 12:48:10.155: INFO: Creating e2e-svc-c-249c7
STEP: deleting service collection
Aug 24 12:48:10.253: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:48:10.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1243" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756
•{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","total":346,"completed":196,"skipped":3700,"failed":0}

------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:48:10.280: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/rc.go:54
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:48:10.361: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Aug 24 12:48:12.445: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:48:13.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2816" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":346,"completed":197,"skipped":3700,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:48:13.490: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating Pod
STEP: Reading file content from the nginx-container
Aug 24 12:48:15.584: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-533 PodName:pod-sharedvolume-71713774-01c4-4819-90e5-4676cd1caeb5 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:48:15.584: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:48:15.586: INFO: ExecWithOptions: Clientset creation
Aug 24 12:48:15.586: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/emptydir-533/pods/pod-sharedvolume-71713774-01c4-4819-90e5-4676cd1caeb5/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:48:15.711: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:48:15.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-533" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":346,"completed":198,"skipped":3708,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:48:15.733: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward api env vars
Aug 24 12:48:15.796: INFO: Waiting up to 5m0s for pod "downward-api-242eba5b-3920-4600-a948-154ccb1f7065" in namespace "downward-api-5476" to be "Succeeded or Failed"
Aug 24 12:48:15.801: INFO: Pod "downward-api-242eba5b-3920-4600-a948-154ccb1f7065": Phase="Pending", Reason="", readiness=false. Elapsed: 4.469389ms
Aug 24 12:48:17.809: INFO: Pod "downward-api-242eba5b-3920-4600-a948-154ccb1f7065": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01281532s
Aug 24 12:48:19.822: INFO: Pod "downward-api-242eba5b-3920-4600-a948-154ccb1f7065": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025540164s
STEP: Saw pod success
Aug 24 12:48:19.822: INFO: Pod "downward-api-242eba5b-3920-4600-a948-154ccb1f7065" satisfied condition "Succeeded or Failed"
Aug 24 12:48:19.827: INFO: Trying to get logs from node zou9eicaeree-3 pod downward-api-242eba5b-3920-4600-a948-154ccb1f7065 container dapi-container: <nil>
STEP: delete the pod
Aug 24 12:48:19.864: INFO: Waiting for pod downward-api-242eba5b-3920-4600-a948-154ccb1f7065 to disappear
Aug 24 12:48:19.870: INFO: Pod downward-api-242eba5b-3920-4600-a948-154ccb1f7065 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:48:19.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5476" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":346,"completed":199,"skipped":3802,"failed":0}

------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:48:19.892: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name projected-configmap-test-volume-map-c7137629-d9d8-4ec0-b60e-c8144b8cb6f6
STEP: Creating a pod to test consume configMaps
Aug 24 12:48:19.978: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7d61c454-2dc4-452c-9ee5-ada52ce91053" in namespace "projected-2457" to be "Succeeded or Failed"
Aug 24 12:48:19.984: INFO: Pod "pod-projected-configmaps-7d61c454-2dc4-452c-9ee5-ada52ce91053": Phase="Pending", Reason="", readiness=false. Elapsed: 6.513891ms
Aug 24 12:48:21.996: INFO: Pod "pod-projected-configmaps-7d61c454-2dc4-452c-9ee5-ada52ce91053": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018330508s
Aug 24 12:48:24.016: INFO: Pod "pod-projected-configmaps-7d61c454-2dc4-452c-9ee5-ada52ce91053": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03835145s
STEP: Saw pod success
Aug 24 12:48:24.017: INFO: Pod "pod-projected-configmaps-7d61c454-2dc4-452c-9ee5-ada52ce91053" satisfied condition "Succeeded or Failed"
Aug 24 12:48:24.022: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-projected-configmaps-7d61c454-2dc4-452c-9ee5-ada52ce91053 container agnhost-container: <nil>
STEP: delete the pod
Aug 24 12:48:24.054: INFO: Waiting for pod pod-projected-configmaps-7d61c454-2dc4-452c-9ee5-ada52ce91053 to disappear
Aug 24 12:48:24.060: INFO: Pod pod-projected-configmaps-7d61c454-2dc4-452c-9ee5-ada52ce91053 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:48:24.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2457" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":200,"skipped":3802,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:48:24.085: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating service endpoint-test2 in namespace services-2976
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2976 to expose endpoints map[]
Aug 24 12:48:24.185: INFO: successfully validated that service endpoint-test2 in namespace services-2976 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-2976
Aug 24 12:48:24.212: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:48:26.229: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2976 to expose endpoints map[pod1:[80]]
Aug 24 12:48:26.255: INFO: successfully validated that service endpoint-test2 in namespace services-2976 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1
Aug 24 12:48:26.256: INFO: Creating new exec pod
Aug 24 12:48:29.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2976 exec execpodwlsk8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug 24 12:48:29.589: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug 24 12:48:29.589: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 12:48:29.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2976 exec execpodwlsk8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.40.128 80'
Aug 24 12:48:29.814: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.40.128 80\nConnection to 10.233.40.128 80 port [tcp/http] succeeded!\n"
Aug 24 12:48:29.814: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-2976
Aug 24 12:48:29.844: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:48:31.856: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2976 to expose endpoints map[pod1:[80] pod2:[80]]
Aug 24 12:48:31.883: INFO: successfully validated that service endpoint-test2 in namespace services-2976 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2
Aug 24 12:48:32.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2976 exec execpodwlsk8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug 24 12:48:33.120: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug 24 12:48:33.120: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 12:48:33.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2976 exec execpodwlsk8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.40.128 80'
Aug 24 12:48:33.333: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.40.128 80\nConnection to 10.233.40.128 80 port [tcp/http] succeeded!\n"
Aug 24 12:48:33.333: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-2976
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2976 to expose endpoints map[pod2:[80]]
Aug 24 12:48:34.394: INFO: successfully validated that service endpoint-test2 in namespace services-2976 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2
Aug 24 12:48:35.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2976 exec execpodwlsk8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Aug 24 12:48:35.658: INFO: stderr: "+ + echo hostName\nnc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Aug 24 12:48:35.658: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 12:48:35.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2976 exec execpodwlsk8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.40.128 80'
Aug 24 12:48:35.865: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.40.128 80\nConnection to 10.233.40.128 80 port [tcp/http] succeeded!\n"
Aug 24 12:48:35.865: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-2976
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2976 to expose endpoints map[]
Aug 24 12:48:35.971: INFO: successfully validated that service endpoint-test2 in namespace services-2976 exposes endpoints map[]
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:48:36.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2976" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756

• [SLOW TEST:11.953 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":346,"completed":201,"skipped":3844,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:48:36.042: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2313
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-2313
I0824 12:48:36.163838      16 runners.go:193] Created replication controller with name: externalname-service, namespace: services-2313, replica count: 2
Aug 24 12:48:39.216: INFO: Creating new exec pod
I0824 12:48:39.215990      16 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 12:48:42.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2313 exec execpodwmzd5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 24 12:48:42.513: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 24 12:48:42.514: INFO: stdout: ""
Aug 24 12:48:43.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2313 exec execpodwmzd5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 24 12:48:43.769: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 24 12:48:43.769: INFO: stdout: ""
Aug 24 12:48:44.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2313 exec execpodwmzd5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 24 12:48:44.731: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 24 12:48:44.731: INFO: stdout: "externalname-service-wstzg"
Aug 24 12:48:44.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2313 exec execpodwmzd5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.40.246 80'
Aug 24 12:48:44.946: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.40.246 80\nConnection to 10.233.40.246 80 port [tcp/http] succeeded!\n"
Aug 24 12:48:44.946: INFO: stdout: "externalname-service-ftnvw"
Aug 24 12:48:44.946: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:48:44.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2313" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756

• [SLOW TEST:8.960 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":346,"completed":202,"skipped":3870,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:48:45.003: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-58 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-58;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-58 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-58;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-58.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-58.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-58.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-58.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-58.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-58.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-58.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-58.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-58.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-58.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-58.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-58.svc;check="$$(dig +notcp +noall +answer +search 33.14.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.14.33_udp@PTR;check="$$(dig +tcp +noall +answer +search 33.14.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.14.33_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-58 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-58;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-58 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-58;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-58.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-58.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-58.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-58.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-58.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-58.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-58.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-58.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-58.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-58.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-58.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-58.svc;check="$$(dig +notcp +noall +answer +search 33.14.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.14.33_udp@PTR;check="$$(dig +tcp +noall +answer +search 33.14.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.14.33_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 24 12:48:47.167: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.174: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.183: INFO: Unable to read wheezy_udp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.190: INFO: Unable to read wheezy_tcp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.198: INFO: Unable to read wheezy_udp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.204: INFO: Unable to read wheezy_tcp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.209: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.214: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.245: INFO: Unable to read jessie_udp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.252: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.260: INFO: Unable to read jessie_udp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.265: INFO: Unable to read jessie_tcp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.272: INFO: Unable to read jessie_udp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.280: INFO: Unable to read jessie_tcp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.285: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.289: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:47.309: INFO: Lookups using dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-58 wheezy_tcp@dns-test-service.dns-58 wheezy_udp@dns-test-service.dns-58.svc wheezy_tcp@dns-test-service.dns-58.svc wheezy_udp@_http._tcp.dns-test-service.dns-58.svc wheezy_tcp@_http._tcp.dns-test-service.dns-58.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-58 jessie_tcp@dns-test-service.dns-58 jessie_udp@dns-test-service.dns-58.svc jessie_tcp@dns-test-service.dns-58.svc jessie_udp@_http._tcp.dns-test-service.dns-58.svc jessie_tcp@_http._tcp.dns-test-service.dns-58.svc]

Aug 24 12:48:52.323: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:52.334: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:52.341: INFO: Unable to read wheezy_udp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:52.350: INFO: Unable to read wheezy_tcp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:52.363: INFO: Unable to read wheezy_udp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:52.370: INFO: Unable to read wheezy_tcp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:52.436: INFO: Unable to read jessie_udp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:52.447: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:52.458: INFO: Unable to read jessie_udp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:52.463: INFO: Unable to read jessie_tcp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:52.469: INFO: Unable to read jessie_udp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:52.478: INFO: Unable to read jessie_tcp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:52.536: INFO: Lookups using dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-58 wheezy_tcp@dns-test-service.dns-58 wheezy_udp@dns-test-service.dns-58.svc wheezy_tcp@dns-test-service.dns-58.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-58 jessie_tcp@dns-test-service.dns-58 jessie_udp@dns-test-service.dns-58.svc jessie_tcp@dns-test-service.dns-58.svc]

Aug 24 12:48:57.319: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:57.324: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:57.330: INFO: Unable to read wheezy_udp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:57.350: INFO: Unable to read wheezy_tcp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:57.357: INFO: Unable to read wheezy_udp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:57.364: INFO: Unable to read wheezy_tcp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:57.411: INFO: Unable to read jessie_udp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:57.417: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:57.428: INFO: Unable to read jessie_udp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:57.432: INFO: Unable to read jessie_tcp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:57.440: INFO: Unable to read jessie_udp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:57.448: INFO: Unable to read jessie_tcp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:48:57.488: INFO: Lookups using dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-58 wheezy_tcp@dns-test-service.dns-58 wheezy_udp@dns-test-service.dns-58.svc wheezy_tcp@dns-test-service.dns-58.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-58 jessie_tcp@dns-test-service.dns-58 jessie_udp@dns-test-service.dns-58.svc jessie_tcp@dns-test-service.dns-58.svc]

Aug 24 12:49:02.318: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:02.337: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:02.344: INFO: Unable to read wheezy_udp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:02.354: INFO: Unable to read wheezy_tcp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:02.363: INFO: Unable to read wheezy_udp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:02.368: INFO: Unable to read wheezy_tcp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:02.424: INFO: Unable to read jessie_udp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:02.430: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:02.436: INFO: Unable to read jessie_udp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:02.447: INFO: Unable to read jessie_tcp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:02.456: INFO: Unable to read jessie_udp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:02.462: INFO: Unable to read jessie_tcp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:02.503: INFO: Lookups using dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-58 wheezy_tcp@dns-test-service.dns-58 wheezy_udp@dns-test-service.dns-58.svc wheezy_tcp@dns-test-service.dns-58.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-58 jessie_tcp@dns-test-service.dns-58 jessie_udp@dns-test-service.dns-58.svc jessie_tcp@dns-test-service.dns-58.svc]

Aug 24 12:49:07.318: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:07.331: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:07.344: INFO: Unable to read wheezy_udp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:07.351: INFO: Unable to read wheezy_tcp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:07.359: INFO: Unable to read wheezy_udp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:07.367: INFO: Unable to read wheezy_tcp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:07.416: INFO: Unable to read jessie_udp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:07.433: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:07.442: INFO: Unable to read jessie_udp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:07.447: INFO: Unable to read jessie_tcp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:07.451: INFO: Unable to read jessie_udp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:07.460: INFO: Unable to read jessie_tcp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:07.503: INFO: Lookups using dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-58 wheezy_tcp@dns-test-service.dns-58 wheezy_udp@dns-test-service.dns-58.svc wheezy_tcp@dns-test-service.dns-58.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-58 jessie_tcp@dns-test-service.dns-58 jessie_udp@dns-test-service.dns-58.svc jessie_tcp@dns-test-service.dns-58.svc]

Aug 24 12:49:12.321: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:12.327: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:12.338: INFO: Unable to read wheezy_udp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:12.346: INFO: Unable to read wheezy_tcp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:12.350: INFO: Unable to read wheezy_udp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:12.357: INFO: Unable to read wheezy_tcp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:12.413: INFO: Unable to read jessie_udp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:12.422: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:12.428: INFO: Unable to read jessie_udp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:12.436: INFO: Unable to read jessie_tcp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:12.442: INFO: Unable to read jessie_udp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:12.452: INFO: Unable to read jessie_tcp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:12.502: INFO: Lookups using dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-58 wheezy_tcp@dns-test-service.dns-58 wheezy_udp@dns-test-service.dns-58.svc wheezy_tcp@dns-test-service.dns-58.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-58 jessie_tcp@dns-test-service.dns-58 jessie_udp@dns-test-service.dns-58.svc jessie_tcp@dns-test-service.dns-58.svc]

Aug 24 12:49:17.318: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:17.324: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:17.330: INFO: Unable to read wheezy_udp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:17.336: INFO: Unable to read wheezy_tcp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:17.341: INFO: Unable to read wheezy_udp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:17.348: INFO: Unable to read wheezy_tcp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:17.387: INFO: Unable to read jessie_udp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:17.393: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:17.399: INFO: Unable to read jessie_udp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:17.405: INFO: Unable to read jessie_tcp@dns-test-service.dns-58 from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:17.411: INFO: Unable to read jessie_udp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:17.416: INFO: Unable to read jessie_tcp@dns-test-service.dns-58.svc from pod dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f: the server could not find the requested resource (get pods dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f)
Aug 24 12:49:17.464: INFO: Lookups using dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-58 wheezy_tcp@dns-test-service.dns-58 wheezy_udp@dns-test-service.dns-58.svc wheezy_tcp@dns-test-service.dns-58.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-58 jessie_tcp@dns-test-service.dns-58 jessie_udp@dns-test-service.dns-58.svc jessie_tcp@dns-test-service.dns-58.svc]

Aug 24 12:49:22.506: INFO: DNS probes using dns-58/dns-test-b57ca88c-cfc0-4715-bd6a-77a0c994730f succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:49:22.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-58" for this suite.

• [SLOW TEST:37.677 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":346,"completed":203,"skipped":3911,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:49:22.682: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 12:49:23.954: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 12:49:27.014: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:49:27.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6861" for this suite.
STEP: Destroying namespace "webhook-6861-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":346,"completed":204,"skipped":3912,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:49:27.229: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 24 12:49:27.345: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2121  00639177-5ad3-415d-9bd7-19260c89859a 37337 0 2022-08-24 12:49:27 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-08-24 12:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 12:49:27.345: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2121  00639177-5ad3-415d-9bd7-19260c89859a 37340 0 2022-08-24 12:49:27 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-08-24 12:49:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 12:49:27.346: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2121  00639177-5ad3-415d-9bd7-19260c89859a 37341 0 2022-08-24 12:49:27 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-08-24 12:49:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 24 12:49:37.399: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2121  00639177-5ad3-415d-9bd7-19260c89859a 37396 0 2022-08-24 12:49:27 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-08-24 12:49:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 12:49:37.400: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2121  00639177-5ad3-415d-9bd7-19260c89859a 37397 0 2022-08-24 12:49:27 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-08-24 12:49:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 12:49:37.400: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2121  00639177-5ad3-415d-9bd7-19260c89859a 37398 0 2022-08-24 12:49:27 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-08-24 12:49:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:49:37.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2121" for this suite.

• [SLOW TEST:10.193 seconds]
[sig-api-machinery] Watchers
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":346,"completed":205,"skipped":3922,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:49:37.435: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a test event
STEP: listing all events in all namespaces
STEP: patching the test event
STEP: fetching the test event
STEP: deleting the test event
STEP: listing all events in all namespaces
[AfterEach] [sig-instrumentation] Events
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:49:37.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-174" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":346,"completed":206,"skipped":3989,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:49:37.551: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:49:37.632: INFO: Creating pod...
Aug 24 12:49:37.690: INFO: Pod Quantity: 1 Status: Pending
Aug 24 12:49:38.704: INFO: Pod Quantity: 1 Status: Pending
Aug 24 12:49:39.700: INFO: Pod Status: Running
Aug 24 12:49:39.700: INFO: Creating service...
Aug 24 12:49:39.716: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-6474/pods/agnhost/proxy/some/path/with/DELETE
Aug 24 12:49:39.742: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug 24 12:49:39.742: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-6474/pods/agnhost/proxy/some/path/with/GET
Aug 24 12:49:39.748: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Aug 24 12:49:39.749: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-6474/pods/agnhost/proxy/some/path/with/HEAD
Aug 24 12:49:39.753: INFO: http.Client request:HEAD | StatusCode:200
Aug 24 12:49:39.754: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-6474/pods/agnhost/proxy/some/path/with/OPTIONS
Aug 24 12:49:39.760: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug 24 12:49:39.760: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-6474/pods/agnhost/proxy/some/path/with/PATCH
Aug 24 12:49:39.766: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug 24 12:49:39.766: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-6474/pods/agnhost/proxy/some/path/with/POST
Aug 24 12:49:39.771: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug 24 12:49:39.771: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-6474/pods/agnhost/proxy/some/path/with/PUT
Aug 24 12:49:39.777: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Aug 24 12:49:39.777: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-6474/services/test-service/proxy/some/path/with/DELETE
Aug 24 12:49:39.785: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Aug 24 12:49:39.785: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-6474/services/test-service/proxy/some/path/with/GET
Aug 24 12:49:39.795: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Aug 24 12:49:39.795: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-6474/services/test-service/proxy/some/path/with/HEAD
Aug 24 12:49:39.807: INFO: http.Client request:HEAD | StatusCode:200
Aug 24 12:49:39.807: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-6474/services/test-service/proxy/some/path/with/OPTIONS
Aug 24 12:49:39.815: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Aug 24 12:49:39.815: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-6474/services/test-service/proxy/some/path/with/PATCH
Aug 24 12:49:39.827: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Aug 24 12:49:39.827: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-6474/services/test-service/proxy/some/path/with/POST
Aug 24 12:49:39.841: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Aug 24 12:49:39.841: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-6474/services/test-service/proxy/some/path/with/PUT
Aug 24 12:49:39.848: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:49:39.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6474" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","total":346,"completed":207,"skipped":4059,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API 
   should support creating IngressClass API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:49:39.873: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename ingressclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/ingressclass.go:186
[It]  should support creating IngressClass API operations [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Aug 24 12:49:39.974: INFO: starting watch
STEP: patching
STEP: updating
Aug 24 12:49:39.998: INFO: waiting for watch events with expected annotations
Aug 24 12:49:39.998: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] IngressClass API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:49:40.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-6082" for this suite.
•{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","total":346,"completed":208,"skipped":4091,"failed":0}

------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:49:40.066: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name cm-test-opt-del-12a87df7-6858-4bcc-b122-86de483811ce
STEP: Creating configMap with name cm-test-opt-upd-34c1ce2f-f8fb-437a-9252-7c37de96feb1
STEP: Creating the pod
Aug 24 12:49:40.161: INFO: The status of Pod pod-configmaps-1a34160d-d164-4d1a-bddd-b8a1cd38973b is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:49:42.175: INFO: The status of Pod pod-configmaps-1a34160d-d164-4d1a-bddd-b8a1cd38973b is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-12a87df7-6858-4bcc-b122-86de483811ce
STEP: Updating configmap cm-test-opt-upd-34c1ce2f-f8fb-437a-9252-7c37de96feb1
STEP: Creating configMap with name cm-test-opt-create-5a65acce-2094-4360-b13c-efd3b5bebf6e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:50:54.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9973" for this suite.

• [SLOW TEST:74.781 seconds]
[sig-storage] ConfigMap
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":209,"skipped":4091,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:50:54.846: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Aug 24 12:50:56.039: INFO: The status of Pod kube-controller-manager-zou9eicaeree-2 is Running (Ready = true)
Aug 24 12:50:56.157: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:50:56.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7133" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":346,"completed":210,"skipped":4161,"failed":0}
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:50:56.183: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Aug 24 12:50:56.219: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 24 12:50:56.234: INFO: Waiting for terminating namespaces to be deleted...
Aug 24 12:50:56.243: INFO: 
Logging pods the apiserver thinks is on node zou9eicaeree-1 before test
Aug 24 12:50:56.259: INFO: simpletest.deployment-84bf5b8887-lvjbq from gc-7133 started at 2022-08-24 12:50:55 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.259: INFO: 	Container nginx ready: false, restart count 0
Aug 24 12:50:56.259: INFO: kube-flannel-ds-7bf94 from kube-flannel started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.259: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 24 12:50:56.259: INFO: coredns-bd6b6df9f-8wkdm from kube-system started at 2022-08-24 12:03:41 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.259: INFO: 	Container coredns ready: true, restart count 0
Aug 24 12:50:56.259: INFO: kube-addon-manager-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.259: INFO: 	Container kube-addon-manager ready: true, restart count 2
Aug 24 12:50:56.259: INFO: kube-apiserver-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.259: INFO: 	Container kube-apiserver ready: true, restart count 3
Aug 24 12:50:56.259: INFO: kube-controller-manager-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.259: INFO: 	Container kube-controller-manager ready: true, restart count 3
Aug 24 12:50:56.259: INFO: kube-proxy-ppn7b from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.260: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 24 12:50:56.260: INFO: kube-scheduler-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.260: INFO: 	Container kube-scheduler ready: true, restart count 3
Aug 24 12:50:56.260: INFO: sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-8pdr5 from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 12:50:56.260: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 12:50:56.260: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 12:50:56.260: INFO: 
Logging pods the apiserver thinks is on node zou9eicaeree-2 before test
Aug 24 12:50:56.271: INFO: kube-flannel-ds-5z9q7 from kube-flannel started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.271: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 24 12:50:56.271: INFO: coredns-bd6b6df9f-cqzkx from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.271: INFO: 	Container coredns ready: true, restart count 0
Aug 24 12:50:56.271: INFO: kube-addon-manager-zou9eicaeree-2 from kube-system started at 2022-08-24 11:41:08 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.271: INFO: 	Container kube-addon-manager ready: true, restart count 2
Aug 24 12:50:56.271: INFO: kube-apiserver-zou9eicaeree-2 from kube-system started at 2022-08-24 09:21:45 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.272: INFO: 	Container kube-apiserver ready: true, restart count 3
Aug 24 12:50:56.272: INFO: kube-controller-manager-zou9eicaeree-2 from kube-system started at 2022-08-24 11:41:08 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.272: INFO: 	Container kube-controller-manager ready: true, restart count 4
Aug 24 12:50:56.272: INFO: kube-proxy-brwdv from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.272: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 24 12:50:56.272: INFO: kube-scheduler-zou9eicaeree-2 from kube-system started at 2022-08-24 11:41:08 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.272: INFO: 	Container kube-scheduler ready: true, restart count 4
Aug 24 12:50:56.272: INFO: sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-549ck from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 12:50:56.272: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 12:50:56.272: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 12:50:56.272: INFO: 
Logging pods the apiserver thinks is on node zou9eicaeree-3 before test
Aug 24 12:50:56.287: INFO: pod-configmaps-1a34160d-d164-4d1a-bddd-b8a1cd38973b from configmap-9973 started at 2022-08-24 12:49:40 +0000 UTC (3 container statuses recorded)
Aug 24 12:50:56.287: INFO: 	Container createcm-volume-test ready: true, restart count 0
Aug 24 12:50:56.287: INFO: 	Container delcm-volume-test ready: true, restart count 0
Aug 24 12:50:56.287: INFO: 	Container updcm-volume-test ready: true, restart count 0
Aug 24 12:50:56.287: INFO: simpletest.deployment-84bf5b8887-nbgb4 from gc-7133 started at 2022-08-24 12:50:54 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.287: INFO: 	Container nginx ready: false, restart count 0
Aug 24 12:50:56.287: INFO: kube-flannel-ds-zt7p4 from kube-flannel started at 2022-08-24 12:06:15 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.287: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 24 12:50:56.287: INFO: kube-proxy-qn7vg from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.287: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 24 12:50:56.287: INFO: sonobuoy from sonobuoy started at 2022-08-24 11:47:10 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.287: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 24 12:50:56.287: INFO: sonobuoy-e2e-job-4d9551b899414778 from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 12:50:56.287: INFO: 	Container e2e ready: true, restart count 0
Aug 24 12:50:56.287: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 12:50:56.287: INFO: sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-n4sbd from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 12:50:56.287: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 12:50:56.287: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 12:50:56.287: INFO: webhook-to-be-mutated from webhook-6861 started at 2022-08-24 12:49:27 +0000 UTC (1 container statuses recorded)
Aug 24 12:50:56.287: INFO: 	Container example ready: false, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.170e48e3eea5ac85], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:50:57.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2150" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":346,"completed":211,"skipped":4164,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:50:57.377: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 24 12:50:57.459: INFO: Waiting up to 5m0s for pod "pod-9a370dce-07ec-4800-b14e-682d151c958e" in namespace "emptydir-3883" to be "Succeeded or Failed"
Aug 24 12:50:57.472: INFO: Pod "pod-9a370dce-07ec-4800-b14e-682d151c958e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.676601ms
Aug 24 12:50:59.487: INFO: Pod "pod-9a370dce-07ec-4800-b14e-682d151c958e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028631781s
Aug 24 12:51:01.522: INFO: Pod "pod-9a370dce-07ec-4800-b14e-682d151c958e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063051072s
STEP: Saw pod success
Aug 24 12:51:01.522: INFO: Pod "pod-9a370dce-07ec-4800-b14e-682d151c958e" satisfied condition "Succeeded or Failed"
Aug 24 12:51:01.532: INFO: Trying to get logs from node zou9eicaeree-2 pod pod-9a370dce-07ec-4800-b14e-682d151c958e container test-container: <nil>
STEP: delete the pod
Aug 24 12:51:01.595: INFO: Waiting for pod pod-9a370dce-07ec-4800-b14e-682d151c958e to disappear
Aug 24 12:51:01.600: INFO: Pod pod-9a370dce-07ec-4800-b14e-682d151c958e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:51:01.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3883" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":212,"skipped":4175,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:51:01.632: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:51:01.707: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: creating the pod
STEP: submitting the pod to kubernetes
Aug 24 12:51:01.736: INFO: The status of Pod pod-exec-websocket-ed9ba2d2-cae3-47db-abf2-b6cb685da41e is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:51:03.744: INFO: The status of Pod pod-exec-websocket-ed9ba2d2-cae3-47db-abf2-b6cb685da41e is Running (Ready = true)
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:51:03.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5131" for this suite.
•{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":346,"completed":213,"skipped":4186,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:51:03.837: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:51:03.942: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b216cb88-e2d6-4efb-bab1-15f76f530d84", Controller:(*bool)(0xc004a5fa76), BlockOwnerDeletion:(*bool)(0xc004a5fa77)}}
Aug 24 12:51:03.955: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"38bb9956-8462-4fd0-a4e5-4e873200ceb6", Controller:(*bool)(0xc004a5fcc6), BlockOwnerDeletion:(*bool)(0xc004a5fcc7)}}
Aug 24 12:51:03.968: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"00138ca9-7273-452f-8785-d0f884a025c8", Controller:(*bool)(0xc004a5ff0e), BlockOwnerDeletion:(*bool)(0xc004a5ff0f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:51:08.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3531" for this suite.

• [SLOW TEST:5.177 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":346,"completed":214,"skipped":4229,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:51:09.017: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:51:09.059: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Aug 24 12:51:12.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-7874 --namespace=crd-publish-openapi-7874 create -f -'
Aug 24 12:51:13.956: INFO: stderr: ""
Aug 24 12:51:13.956: INFO: stdout: "e2e-test-crd-publish-openapi-4019-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Aug 24 12:51:13.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-7874 --namespace=crd-publish-openapi-7874 delete e2e-test-crd-publish-openapi-4019-crds test-cr'
Aug 24 12:51:14.080: INFO: stderr: ""
Aug 24 12:51:14.080: INFO: stdout: "e2e-test-crd-publish-openapi-4019-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Aug 24 12:51:14.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-7874 --namespace=crd-publish-openapi-7874 apply -f -'
Aug 24 12:51:14.338: INFO: stderr: ""
Aug 24 12:51:14.338: INFO: stdout: "e2e-test-crd-publish-openapi-4019-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Aug 24 12:51:14.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-7874 --namespace=crd-publish-openapi-7874 delete e2e-test-crd-publish-openapi-4019-crds test-cr'
Aug 24 12:51:14.501: INFO: stderr: ""
Aug 24 12:51:14.501: INFO: stdout: "e2e-test-crd-publish-openapi-4019-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Aug 24 12:51:14.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-7874 explain e2e-test-crd-publish-openapi-4019-crds'
Aug 24 12:51:14.750: INFO: stderr: ""
Aug 24 12:51:14.750: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4019-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:51:17.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7874" for this suite.

• [SLOW TEST:8.872 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":346,"completed":215,"skipped":4237,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:51:17.894: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8035
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-8035
I0824 12:51:18.003817      16 runners.go:193] Created replication controller with name: externalname-service, namespace: services-8035, replica count: 2
I0824 12:51:21.055486      16 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 12:51:21.055: INFO: Creating new exec pod
Aug 24 12:51:24.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8035 exec execpodnbxf6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 24 12:51:24.323: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 24 12:51:24.323: INFO: stdout: ""
Aug 24 12:51:25.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8035 exec execpodnbxf6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Aug 24 12:51:25.579: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Aug 24 12:51:25.579: INFO: stdout: "externalname-service-ns6bh"
Aug 24 12:51:25.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8035 exec execpodnbxf6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.44.235 80'
Aug 24 12:51:25.778: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.44.235 80\nConnection to 10.233.44.235 80 port [tcp/http] succeeded!\n"
Aug 24 12:51:25.779: INFO: stdout: "externalname-service-ns6bh"
Aug 24 12:51:25.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8035 exec execpodnbxf6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.108 32462'
Aug 24 12:51:25.955: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.108 32462\nConnection to 192.168.121.108 32462 port [tcp/*] succeeded!\n"
Aug 24 12:51:25.955: INFO: stdout: "externalname-service-77pnm"
Aug 24 12:51:25.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8035 exec execpodnbxf6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.182 32462'
Aug 24 12:51:26.138: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.182 32462\nConnection to 192.168.121.182 32462 port [tcp/*] succeeded!\n"
Aug 24 12:51:26.138: INFO: stdout: ""
Aug 24 12:51:27.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8035 exec execpodnbxf6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.182 32462'
Aug 24 12:51:27.328: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.182 32462\nConnection to 192.168.121.182 32462 port [tcp/*] succeeded!\n"
Aug 24 12:51:27.328: INFO: stdout: "externalname-service-77pnm"
Aug 24 12:51:27.328: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:51:27.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8035" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756

• [SLOW TEST:9.532 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":346,"completed":216,"skipped":4266,"failed":0}
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:51:27.426: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-7835
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a new StatefulSet
Aug 24 12:51:27.514: INFO: Found 0 stateful pods, waiting for 3
Aug 24 12:51:37.526: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 12:51:37.527: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 12:51:37.527: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 12:51:37.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-7835 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 12:51:37.823: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 12:51:37.823: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 12:51:37.823: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Aug 24 12:51:47.880: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 24 12:51:57.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-7835 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 12:51:58.118: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 24 12:51:58.118: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 12:51:58.118: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Aug 24 12:52:08.159: INFO: Waiting for StatefulSet statefulset-7835/ss2 to complete update
Aug 24 12:52:08.159: INFO: Waiting for Pod statefulset-7835/ss2-0 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
Aug 24 12:52:08.159: INFO: Waiting for Pod statefulset-7835/ss2-1 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
Aug 24 12:52:18.176: INFO: Waiting for StatefulSet statefulset-7835/ss2 to complete update
Aug 24 12:52:18.176: INFO: Waiting for Pod statefulset-7835/ss2-0 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
Aug 24 12:52:28.176: INFO: Waiting for StatefulSet statefulset-7835/ss2 to complete update
STEP: Rolling back to a previous revision
Aug 24 12:52:38.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-7835 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Aug 24 12:52:38.462: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Aug 24 12:52:38.462: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Aug 24 12:52:38.462: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Aug 24 12:52:48.521: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 24 12:52:58.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=statefulset-7835 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Aug 24 12:52:58.845: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Aug 24 12:52:58.845: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Aug 24 12:52:58.845: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Aug 24 12:53:08.891: INFO: Deleting all statefulset in ns statefulset-7835
Aug 24 12:53:08.896: INFO: Scaling statefulset ss2 to 0
Aug 24 12:53:18.930: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 12:53:18.938: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:53:18.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7835" for this suite.

• [SLOW TEST:111.550 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":346,"completed":217,"skipped":4267,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:53:18.977: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 24 12:53:19.047: INFO: Waiting up to 5m0s for pod "pod-e759653b-a3d1-4817-9dcc-deaf65c5914c" in namespace "emptydir-9087" to be "Succeeded or Failed"
Aug 24 12:53:19.054: INFO: Pod "pod-e759653b-a3d1-4817-9dcc-deaf65c5914c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.278229ms
Aug 24 12:53:21.064: INFO: Pod "pod-e759653b-a3d1-4817-9dcc-deaf65c5914c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016522109s
Aug 24 12:53:23.076: INFO: Pod "pod-e759653b-a3d1-4817-9dcc-deaf65c5914c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029006542s
STEP: Saw pod success
Aug 24 12:53:23.076: INFO: Pod "pod-e759653b-a3d1-4817-9dcc-deaf65c5914c" satisfied condition "Succeeded or Failed"
Aug 24 12:53:23.086: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-e759653b-a3d1-4817-9dcc-deaf65c5914c container test-container: <nil>
STEP: delete the pod
Aug 24 12:53:23.136: INFO: Waiting for pod pod-e759653b-a3d1-4817-9dcc-deaf65c5914c to disappear
Aug 24 12:53:23.145: INFO: Pod pod-e759653b-a3d1-4817-9dcc-deaf65c5914c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:53:23.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9087" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":218,"skipped":4273,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:53:23.164: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 12:53:23.233: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6ad64d05-acba-4fa5-9e6c-04734effa815" in namespace "projected-4484" to be "Succeeded or Failed"
Aug 24 12:53:23.240: INFO: Pod "downwardapi-volume-6ad64d05-acba-4fa5-9e6c-04734effa815": Phase="Pending", Reason="", readiness=false. Elapsed: 7.341622ms
Aug 24 12:53:25.253: INFO: Pod "downwardapi-volume-6ad64d05-acba-4fa5-9e6c-04734effa815": Phase="Running", Reason="", readiness=false. Elapsed: 2.019914599s
Aug 24 12:53:27.265: INFO: Pod "downwardapi-volume-6ad64d05-acba-4fa5-9e6c-04734effa815": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031873151s
STEP: Saw pod success
Aug 24 12:53:27.265: INFO: Pod "downwardapi-volume-6ad64d05-acba-4fa5-9e6c-04734effa815" satisfied condition "Succeeded or Failed"
Aug 24 12:53:27.269: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-6ad64d05-acba-4fa5-9e6c-04734effa815 container client-container: <nil>
STEP: delete the pod
Aug 24 12:53:27.301: INFO: Waiting for pod downwardapi-volume-6ad64d05-acba-4fa5-9e6c-04734effa815 to disappear
Aug 24 12:53:27.308: INFO: Pod downwardapi-volume-6ad64d05-acba-4fa5-9e6c-04734effa815 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:53:27.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4484" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":346,"completed":219,"skipped":4320,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:53:27.331: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating the pod
Aug 24 12:53:27.365: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:53:32.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6148" for this suite.

• [SLOW TEST:5.686 seconds]
[sig-node] InitContainer [NodeConformance]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":346,"completed":220,"skipped":4330,"failed":0}
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:53:33.018: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap that has name configmap-test-emptyKey-a10e02b6-ce9b-47f8-b45e-b8512469f29a
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:53:33.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4592" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":346,"completed":221,"skipped":4336,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:53:33.088: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:53:33.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9779" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":346,"completed":222,"skipped":4365,"failed":0}
SSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:53:33.165: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:53:37.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6834" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":346,"completed":223,"skipped":4371,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:53:37.306: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name projected-configmap-test-volume-3a601ea8-63e7-4b7b-930a-faf1f5e8cbf8
STEP: Creating a pod to test consume configMaps
Aug 24 12:53:37.375: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e2593119-fe15-49fd-b32d-3c2a969d39ff" in namespace "projected-3401" to be "Succeeded or Failed"
Aug 24 12:53:37.381: INFO: Pod "pod-projected-configmaps-e2593119-fe15-49fd-b32d-3c2a969d39ff": Phase="Pending", Reason="", readiness=false. Elapsed: 5.485976ms
Aug 24 12:53:39.392: INFO: Pod "pod-projected-configmaps-e2593119-fe15-49fd-b32d-3c2a969d39ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016507214s
Aug 24 12:53:41.404: INFO: Pod "pod-projected-configmaps-e2593119-fe15-49fd-b32d-3c2a969d39ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028618089s
STEP: Saw pod success
Aug 24 12:53:41.405: INFO: Pod "pod-projected-configmaps-e2593119-fe15-49fd-b32d-3c2a969d39ff" satisfied condition "Succeeded or Failed"
Aug 24 12:53:41.411: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-projected-configmaps-e2593119-fe15-49fd-b32d-3c2a969d39ff container agnhost-container: <nil>
STEP: delete the pod
Aug 24 12:53:41.441: INFO: Waiting for pod pod-projected-configmaps-e2593119-fe15-49fd-b32d-3c2a969d39ff to disappear
Aug 24 12:53:41.445: INFO: Pod pod-projected-configmaps-e2593119-fe15-49fd-b32d-3c2a969d39ff no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:53:41.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3401" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":224,"skipped":4372,"failed":0}
SSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates lower priority pod preemption by critical pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:53:41.469: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Aug 24 12:53:41.533: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 24 12:54:41.580: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Create pods that use 4/5 of node resources.
Aug 24 12:54:41.651: INFO: Created pod: pod0-0-sched-preemption-low-priority
Aug 24 12:54:41.663: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Aug 24 12:54:41.714: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Aug 24 12:54:41.729: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Aug 24 12:54:41.758: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Aug 24 12:54:41.769: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a critical pod that use same resources as that of a lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:54:57.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-6647" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:76.547 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","total":346,"completed":225,"skipped":4377,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:54:58.018: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: set up a multi version CRD
Aug 24 12:54:58.063: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:55:18.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2900" for this suite.

• [SLOW TEST:20.219 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":346,"completed":226,"skipped":4402,"failed":0}
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:55:18.239: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 12:55:18.296: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a80ae410-a47b-4b1f-a3f1-2e7629556fd7" in namespace "projected-1120" to be "Succeeded or Failed"
Aug 24 12:55:18.300: INFO: Pod "downwardapi-volume-a80ae410-a47b-4b1f-a3f1-2e7629556fd7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.222217ms
Aug 24 12:55:20.312: INFO: Pod "downwardapi-volume-a80ae410-a47b-4b1f-a3f1-2e7629556fd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016074012s
Aug 24 12:55:22.324: INFO: Pod "downwardapi-volume-a80ae410-a47b-4b1f-a3f1-2e7629556fd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028127115s
STEP: Saw pod success
Aug 24 12:55:22.325: INFO: Pod "downwardapi-volume-a80ae410-a47b-4b1f-a3f1-2e7629556fd7" satisfied condition "Succeeded or Failed"
Aug 24 12:55:22.328: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-a80ae410-a47b-4b1f-a3f1-2e7629556fd7 container client-container: <nil>
STEP: delete the pod
Aug 24 12:55:22.394: INFO: Waiting for pod downwardapi-volume-a80ae410-a47b-4b1f-a3f1-2e7629556fd7 to disappear
Aug 24 12:55:22.400: INFO: Pod downwardapi-volume-a80ae410-a47b-4b1f-a3f1-2e7629556fd7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:55:22.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1120" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":227,"skipped":4405,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  Replicaset should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:55:22.420: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] Replicaset should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota
Aug 24 12:55:22.507: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 24 12:55:27.529: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the replicaset Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:55:27.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2411" for this suite.

• [SLOW TEST:5.202 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","total":346,"completed":228,"skipped":4423,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:55:27.629: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Performing setup for networking test in namespace pod-network-test-9618
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 24 12:55:27.684: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 24 12:55:27.778: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:55:29.794: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:55:31.787: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:55:33.796: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:55:35.796: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:55:37.797: INFO: The status of Pod netserver-0 is Running (Ready = false)
Aug 24 12:55:39.792: INFO: The status of Pod netserver-0 is Running (Ready = true)
Aug 24 12:55:39.804: INFO: The status of Pod netserver-1 is Running (Ready = true)
Aug 24 12:55:39.818: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Aug 24 12:55:41.863: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Aug 24 12:55:41.863: INFO: Breadth first check of 10.233.64.93 on host 192.168.121.241...
Aug 24 12:55:41.868: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.147:9080/dial?request=hostname&protocol=udp&host=10.233.64.93&port=8081&tries=1'] Namespace:pod-network-test-9618 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:55:41.868: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:55:41.869: INFO: ExecWithOptions: Clientset creation
Aug 24 12:55:41.869: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9618/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.147%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.64.93%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:55:42.006: INFO: Waiting for responses: map[]
Aug 24 12:55:42.007: INFO: reached 10.233.64.93 after 0/1 tries
Aug 24 12:55:42.007: INFO: Breadth first check of 10.233.65.49 on host 192.168.121.182...
Aug 24 12:55:42.013: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.147:9080/dial?request=hostname&protocol=udp&host=10.233.65.49&port=8081&tries=1'] Namespace:pod-network-test-9618 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:55:42.013: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:55:42.014: INFO: ExecWithOptions: Clientset creation
Aug 24 12:55:42.014: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9618/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.147%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.65.49%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:55:42.119: INFO: Waiting for responses: map[]
Aug 24 12:55:42.119: INFO: reached 10.233.65.49 after 0/1 tries
Aug 24 12:55:42.119: INFO: Breadth first check of 10.233.66.146 on host 192.168.121.108...
Aug 24 12:55:42.126: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.66.147:9080/dial?request=hostname&protocol=udp&host=10.233.66.146&port=8081&tries=1'] Namespace:pod-network-test-9618 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:55:42.126: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:55:42.127: INFO: ExecWithOptions: Clientset creation
Aug 24 12:55:42.127: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9618/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.66.147%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.66.146%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true %!s(MISSING))
Aug 24 12:55:42.241: INFO: Waiting for responses: map[]
Aug 24 12:55:42.241: INFO: reached 10.233.66.146 after 0/1 tries
Aug 24 12:55:42.242: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:55:42.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9618" for this suite.

• [SLOW TEST:14.634 seconds]
[sig-network] Networking
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/network/networking.go:30
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":346,"completed":229,"skipped":4453,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:55:42.263: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:55:42.299: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: creating the pod
STEP: submitting the pod to kubernetes
Aug 24 12:55:42.321: INFO: The status of Pod pod-logs-websocket-c7069a17-b53a-47ec-85c3-7b2421a87740 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 12:55:44.342: INFO: The status of Pod pod-logs-websocket-c7069a17-b53a-47ec-85c3-7b2421a87740 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:55:44.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-149" for this suite.
•{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":346,"completed":230,"skipped":4510,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:55:44.392: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating service nodeport-test with type=NodePort in namespace services-4795
STEP: creating replication controller nodeport-test in namespace services-4795
I0824 12:55:44.483481      16 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-4795, replica count: 2
I0824 12:55:47.535626      16 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 12:55:47.536: INFO: Creating new exec pod
Aug 24 12:55:50.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-4795 exec execpod9zczv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Aug 24 12:55:50.862: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Aug 24 12:55:50.862: INFO: stdout: ""
Aug 24 12:55:51.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-4795 exec execpod9zczv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Aug 24 12:55:52.083: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Aug 24 12:55:52.083: INFO: stdout: ""
Aug 24 12:55:52.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-4795 exec execpod9zczv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Aug 24 12:55:53.173: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Aug 24 12:55:53.173: INFO: stdout: "nodeport-test-kqgv2"
Aug 24 12:55:53.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-4795 exec execpod9zczv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.21.230 80'
Aug 24 12:55:53.393: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.21.230 80\nConnection to 10.233.21.230 80 port [tcp/http] succeeded!\n"
Aug 24 12:55:53.393: INFO: stdout: "nodeport-test-qr5mh"
Aug 24 12:55:53.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-4795 exec execpod9zczv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.108 31832'
Aug 24 12:55:53.630: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.108 31832\nConnection to 192.168.121.108 31832 port [tcp/*] succeeded!\n"
Aug 24 12:55:53.630: INFO: stdout: "nodeport-test-qr5mh"
Aug 24 12:55:53.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-4795 exec execpod9zczv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.182 31832'
Aug 24 12:55:53.855: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.182 31832\nConnection to 192.168.121.182 31832 port [tcp/*] succeeded!\n"
Aug 24 12:55:53.855: INFO: stdout: "nodeport-test-qr5mh"
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:55:53.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4795" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756

• [SLOW TEST:9.487 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":346,"completed":231,"skipped":4526,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:55:53.880: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 12:55:53.935: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e62ba243-e710-42b2-a598-e4894889335c" in namespace "projected-2888" to be "Succeeded or Failed"
Aug 24 12:55:53.940: INFO: Pod "downwardapi-volume-e62ba243-e710-42b2-a598-e4894889335c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.739348ms
Aug 24 12:55:55.959: INFO: Pod "downwardapi-volume-e62ba243-e710-42b2-a598-e4894889335c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023874869s
Aug 24 12:55:57.976: INFO: Pod "downwardapi-volume-e62ba243-e710-42b2-a598-e4894889335c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041284063s
STEP: Saw pod success
Aug 24 12:55:57.976: INFO: Pod "downwardapi-volume-e62ba243-e710-42b2-a598-e4894889335c" satisfied condition "Succeeded or Failed"
Aug 24 12:55:57.981: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-e62ba243-e710-42b2-a598-e4894889335c container client-container: <nil>
STEP: delete the pod
Aug 24 12:55:58.017: INFO: Waiting for pod downwardapi-volume-e62ba243-e710-42b2-a598-e4894889335c to disappear
Aug 24 12:55:58.022: INFO: Pod downwardapi-volume-e62ba243-e710-42b2-a598-e4894889335c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:55:58.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2888" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":346,"completed":232,"skipped":4536,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:55:58.046: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test substitution in container's args
Aug 24 12:55:58.107: INFO: Waiting up to 5m0s for pod "var-expansion-e263d3f1-ab64-4b10-a135-61c592352acb" in namespace "var-expansion-3105" to be "Succeeded or Failed"
Aug 24 12:55:58.114: INFO: Pod "var-expansion-e263d3f1-ab64-4b10-a135-61c592352acb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.30651ms
Aug 24 12:56:00.150: INFO: Pod "var-expansion-e263d3f1-ab64-4b10-a135-61c592352acb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04272791s
Aug 24 12:56:02.166: INFO: Pod "var-expansion-e263d3f1-ab64-4b10-a135-61c592352acb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058983532s
STEP: Saw pod success
Aug 24 12:56:02.167: INFO: Pod "var-expansion-e263d3f1-ab64-4b10-a135-61c592352acb" satisfied condition "Succeeded or Failed"
Aug 24 12:56:02.173: INFO: Trying to get logs from node zou9eicaeree-3 pod var-expansion-e263d3f1-ab64-4b10-a135-61c592352acb container dapi-container: <nil>
STEP: delete the pod
Aug 24 12:56:02.207: INFO: Waiting for pod var-expansion-e263d3f1-ab64-4b10-a135-61c592352acb to disappear
Aug 24 12:56:02.212: INFO: Pod var-expansion-e263d3f1-ab64-4b10-a135-61c592352acb no longer exists
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:56:02.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3105" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":346,"completed":233,"skipped":4544,"failed":0}

------------------------------
[sig-apps] ReplicaSet 
  Replace and Patch tests [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:56:02.228: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] Replace and Patch tests [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:56:02.297: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 24 12:56:07.319: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Scaling up "test-rs" replicaset 
Aug 24 12:56:07.372: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet
Aug 24 12:56:07.480: INFO: observed ReplicaSet test-rs in namespace replicaset-7536 with ReadyReplicas 1, AvailableReplicas 1
Aug 24 12:56:07.513: INFO: observed ReplicaSet test-rs in namespace replicaset-7536 with ReadyReplicas 1, AvailableReplicas 1
Aug 24 12:56:07.590: INFO: observed ReplicaSet test-rs in namespace replicaset-7536 with ReadyReplicas 1, AvailableReplicas 1
Aug 24 12:56:07.618: INFO: observed ReplicaSet test-rs in namespace replicaset-7536 with ReadyReplicas 1, AvailableReplicas 1
Aug 24 12:56:08.498: INFO: observed ReplicaSet test-rs in namespace replicaset-7536 with ReadyReplicas 2, AvailableReplicas 2
Aug 24 12:56:09.105: INFO: observed Replicaset test-rs in namespace replicaset-7536 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:56:09.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7536" for this suite.

• [SLOW TEST:6.910 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","total":346,"completed":234,"skipped":4544,"failed":0}
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:56:09.139: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap configmap-4576/configmap-test-76eb771b-dd47-44ea-ac57-6355a3d32251
STEP: Creating a pod to test consume configMaps
Aug 24 12:56:09.209: INFO: Waiting up to 5m0s for pod "pod-configmaps-7dbd170b-80d3-4d4d-a25c-6b8f350fbf6f" in namespace "configmap-4576" to be "Succeeded or Failed"
Aug 24 12:56:09.218: INFO: Pod "pod-configmaps-7dbd170b-80d3-4d4d-a25c-6b8f350fbf6f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.584911ms
Aug 24 12:56:11.239: INFO: Pod "pod-configmaps-7dbd170b-80d3-4d4d-a25c-6b8f350fbf6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029940498s
Aug 24 12:56:13.253: INFO: Pod "pod-configmaps-7dbd170b-80d3-4d4d-a25c-6b8f350fbf6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044047877s
STEP: Saw pod success
Aug 24 12:56:13.253: INFO: Pod "pod-configmaps-7dbd170b-80d3-4d4d-a25c-6b8f350fbf6f" satisfied condition "Succeeded or Failed"
Aug 24 12:56:13.258: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-configmaps-7dbd170b-80d3-4d4d-a25c-6b8f350fbf6f container env-test: <nil>
STEP: delete the pod
Aug 24 12:56:13.308: INFO: Waiting for pod pod-configmaps-7dbd170b-80d3-4d4d-a25c-6b8f350fbf6f to disappear
Aug 24 12:56:13.313: INFO: Pod pod-configmaps-7dbd170b-80d3-4d4d-a25c-6b8f350fbf6f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:56:13.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4576" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":346,"completed":235,"skipped":4545,"failed":0}
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:56:13.340: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name configmap-test-volume-map-df0a08ac-2c9f-459c-9319-a6f24605f9c2
STEP: Creating a pod to test consume configMaps
Aug 24 12:56:13.418: INFO: Waiting up to 5m0s for pod "pod-configmaps-6201d45b-0045-469e-90bb-97c928675265" in namespace "configmap-4247" to be "Succeeded or Failed"
Aug 24 12:56:13.424: INFO: Pod "pod-configmaps-6201d45b-0045-469e-90bb-97c928675265": Phase="Pending", Reason="", readiness=false. Elapsed: 5.202221ms
Aug 24 12:56:15.438: INFO: Pod "pod-configmaps-6201d45b-0045-469e-90bb-97c928675265": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020126101s
Aug 24 12:56:17.454: INFO: Pod "pod-configmaps-6201d45b-0045-469e-90bb-97c928675265": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035925971s
STEP: Saw pod success
Aug 24 12:56:17.454: INFO: Pod "pod-configmaps-6201d45b-0045-469e-90bb-97c928675265" satisfied condition "Succeeded or Failed"
Aug 24 12:56:17.459: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-configmaps-6201d45b-0045-469e-90bb-97c928675265 container agnhost-container: <nil>
STEP: delete the pod
Aug 24 12:56:17.494: INFO: Waiting for pod pod-configmaps-6201d45b-0045-469e-90bb-97c928675265 to disappear
Aug 24 12:56:17.500: INFO: Pod pod-configmaps-6201d45b-0045-469e-90bb-97c928675265 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:56:17.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4247" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":236,"skipped":4550,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should list and delete a collection of DaemonSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:56:17.523: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should list and delete a collection of DaemonSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 24 12:56:17.638: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 12:56:17.638: INFO: Node zou9eicaeree-1 is running 0 daemon pod, expected 1
Aug 24 12:56:18.662: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 24 12:56:18.662: INFO: Node zou9eicaeree-2 is running 0 daemon pod, expected 1
Aug 24 12:56:19.656: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 12:56:19.656: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets
STEP: DeleteCollection of the DaemonSets
STEP: Verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
Aug 24 12:56:19.718: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"39676"},"items":null}

Aug 24 12:56:19.726: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"39676"},"items":[{"metadata":{"name":"daemon-set-bvdrk","generateName":"daemon-set-","namespace":"daemonsets-630","uid":"3fb2d6f6-579b-4fbf-9ace-bbd315418165","resourceVersion":"39664","creationTimestamp":"2022-08-24T12:56:17Z","labels":{"controller-revision-hash":"5b46c58f6f","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"86cddaee-9c69-44ab-8082-e07965385a9d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-24T12:56:17Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"86cddaee-9c69-44ab-8082-e07965385a9d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-24T12:56:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.96\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-9ptm5","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-9ptm5","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"zou9eicaeree-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["zou9eicaeree-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T12:56:17Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T12:56:18Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T12:56:18Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T12:56:17Z"}],"hostIP":"192.168.121.241","podIP":"10.233.64.96","podIPs":[{"ip":"10.233.64.96"}],"startTime":"2022-08-24T12:56:17Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-24T12:56:18Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"cri-o://f2d0e60405a4b63c6e85d6dce34764f7f576d6b0df1c2e016b484cc74b8738f6","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-hdztz","generateName":"daemon-set-","namespace":"daemonsets-630","uid":"ace243e0-d6c5-4095-987b-788cb2949ddb","resourceVersion":"39673","creationTimestamp":"2022-08-24T12:56:17Z","labels":{"controller-revision-hash":"5b46c58f6f","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"86cddaee-9c69-44ab-8082-e07965385a9d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-24T12:56:17Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"86cddaee-9c69-44ab-8082-e07965385a9d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-24T12:56:19Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.65.51\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-tl7c4","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-tl7c4","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"zou9eicaeree-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["zou9eicaeree-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T12:56:17Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T12:56:19Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T12:56:19Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T12:56:17Z"}],"hostIP":"192.168.121.182","podIP":"10.233.65.51","podIPs":[{"ip":"10.233.65.51"}],"startTime":"2022-08-24T12:56:17Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-24T12:56:18Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"cri-o://dc53fb9224fcf92bd6b26e7c4c9148c8b56b42f85eca1cec9874b16df5cc0901","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-n7bnm","generateName":"daemon-set-","namespace":"daemonsets-630","uid":"39fed10b-c9e0-4c0e-8112-c9ebb43610e0","resourceVersion":"39670","creationTimestamp":"2022-08-24T12:56:17Z","labels":{"controller-revision-hash":"5b46c58f6f","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"86cddaee-9c69-44ab-8082-e07965385a9d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-08-24T12:56:17Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"86cddaee-9c69-44ab-8082-e07965385a9d\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-08-24T12:56:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.156\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-fn75x","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-fn75x","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"zou9eicaeree-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["zou9eicaeree-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T12:56:17Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T12:56:18Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T12:56:18Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-08-24T12:56:17Z"}],"hostIP":"192.168.121.108","podIP":"10.233.66.156","podIPs":[{"ip":"10.233.66.156"}],"startTime":"2022-08-24T12:56:17Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-08-24T12:56:18Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"cri-o://b21d19bc7e0a933ac9ee7489bb51f0aed698532ad486208c5757d8d5d522f79a","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:56:19.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-630" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","total":346,"completed":237,"skipped":4569,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should test the lifecycle of an Endpoint [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:56:19.788: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should test the lifecycle of an Endpoint [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating an Endpoint
STEP: waiting for available Endpoint
STEP: listing all Endpoints
STEP: updating the Endpoint
STEP: fetching the Endpoint
STEP: patching the Endpoint
STEP: fetching the Endpoint
STEP: deleting the Endpoint by Collection
STEP: waiting for Endpoint deletion
STEP: fetching the Endpoint
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:56:19.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8154" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756
•{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","total":346,"completed":238,"skipped":4605,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:56:19.945: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check is all data is printed  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:56:19.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-9827 version'
Aug 24 12:56:20.088: INFO: stderr: ""
Aug 24 12:56:20.088: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"23\", GitVersion:\"v1.23.10\", GitCommit:\"7e54d50d3012cf3389e43b096ba35300f36e0817\", GitTreeState:\"clean\", BuildDate:\"2022-08-17T18:32:54Z\", GoVersion:\"go1.17.13\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"23\", GitVersion:\"v1.23.10\", GitCommit:\"7e54d50d3012cf3389e43b096ba35300f36e0817\", GitTreeState:\"clean\", BuildDate:\"2022-08-17T18:26:59Z\", GoVersion:\"go1.17.13\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:56:20.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9827" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":346,"completed":239,"skipped":4639,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:56:20.110: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should retry creating failed daemon pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 24 12:56:20.196: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 12:56:20.196: INFO: Node zou9eicaeree-1 is running 0 daemon pod, expected 1
Aug 24 12:56:21.217: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Aug 24 12:56:21.217: INFO: Node zou9eicaeree-1 is running 0 daemon pod, expected 1
Aug 24 12:56:22.217: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 12:56:22.217: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 24 12:56:22.253: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 12:56:22.253: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3444, will wait for the garbage collector to delete the pods
Aug 24 12:56:23.350: INFO: Deleting DaemonSet.extensions daemon-set took: 14.505014ms
Aug 24 12:56:23.451: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.093906ms
Aug 24 12:56:26.265: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 12:56:26.266: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 24 12:56:26.270: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"39840"},"items":null}

Aug 24 12:56:26.273: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"39840"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:56:26.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3444" for this suite.

• [SLOW TEST:6.197 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":346,"completed":240,"skipped":4664,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:56:26.317: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 12:56:27.150: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 12:56:30.227: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:56:42.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4182" for this suite.
STEP: Destroying namespace "webhook-4182-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:16.313 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":346,"completed":241,"skipped":4689,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:56:42.631: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:56:55.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8089" for this suite.

• [SLOW TEST:13.250 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":346,"completed":242,"skipped":4699,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:56:55.885: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 12:56:55.928: INFO: Creating ReplicaSet my-hostname-basic-3544bf59-021b-4285-96e8-f43cdf9f2649
Aug 24 12:56:55.944: INFO: Pod name my-hostname-basic-3544bf59-021b-4285-96e8-f43cdf9f2649: Found 0 pods out of 1
Aug 24 12:57:00.985: INFO: Pod name my-hostname-basic-3544bf59-021b-4285-96e8-f43cdf9f2649: Found 1 pods out of 1
Aug 24 12:57:00.985: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-3544bf59-021b-4285-96e8-f43cdf9f2649" is running
Aug 24 12:57:00.993: INFO: Pod "my-hostname-basic-3544bf59-021b-4285-96e8-f43cdf9f2649-rkkvz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 12:56:55 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 12:56:56 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 12:56:56 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-24 12:56:55 +0000 UTC Reason: Message:}])
Aug 24 12:57:00.994: INFO: Trying to dial the pod
Aug 24 12:57:06.050: INFO: Controller my-hostname-basic-3544bf59-021b-4285-96e8-f43cdf9f2649: Got expected result from replica 1 [my-hostname-basic-3544bf59-021b-4285-96e8-f43cdf9f2649-rkkvz]: "my-hostname-basic-3544bf59-021b-4285-96e8-f43cdf9f2649-rkkvz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:57:06.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1760" for this suite.

• [SLOW TEST:10.192 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":346,"completed":243,"skipped":4747,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:57:06.078: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:57:22.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8700" for this suite.

• [SLOW TEST:16.328 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":346,"completed":244,"skipped":4769,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff 
  should check if kubectl diff finds a difference for Deployments [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:57:22.407: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create deployment with httpd image
Aug 24 12:57:22.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-9408 create -f -'
Aug 24 12:57:23.006: INFO: stderr: ""
Aug 24 12:57:23.006: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image
Aug 24 12:57:23.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-9408 diff -f -'
Aug 24 12:57:24.096: INFO: rc: 1
Aug 24 12:57:24.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-9408 delete -f -'
Aug 24 12:57:24.196: INFO: stderr: ""
Aug 24 12:57:24.196: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:57:24.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9408" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","total":346,"completed":245,"skipped":4779,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should list and delete a collection of ReplicaSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:57:24.218: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should list and delete a collection of ReplicaSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Create a ReplicaSet
STEP: Verify that the required pods have come up
Aug 24 12:57:24.274: INFO: Pod name sample-pod: Found 0 pods out of 3
Aug 24 12:57:29.302: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running
Aug 24 12:57:29.310: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets
STEP: DeleteCollection of the ReplicaSets
STEP: After DeleteCollection verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:57:29.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3205" for this suite.

• [SLOW TEST:5.151 seconds]
[sig-apps] ReplicaSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","total":346,"completed":246,"skipped":4789,"failed":0}
SSSSS
------------------------------
[sig-node] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:57:29.370: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[AfterEach] [sig-node] Docker Containers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:57:31.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3757" for this suite.
•{"msg":"PASSED [sig-node] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":346,"completed":247,"skipped":4794,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:57:31.544: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 12:57:32.494: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 12:57:35.560: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:57:35.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3214" for this suite.
STEP: Destroying namespace "webhook-3214-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":346,"completed":248,"skipped":4823,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:57:36.016: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name configmap-test-volume-map-9c382098-4619-4090-b33c-660e4b2971a6
STEP: Creating a pod to test consume configMaps
Aug 24 12:57:36.119: INFO: Waiting up to 5m0s for pod "pod-configmaps-53141b3c-0f15-4a86-9ea8-23641449dd56" in namespace "configmap-2497" to be "Succeeded or Failed"
Aug 24 12:57:36.128: INFO: Pod "pod-configmaps-53141b3c-0f15-4a86-9ea8-23641449dd56": Phase="Pending", Reason="", readiness=false. Elapsed: 8.910926ms
Aug 24 12:57:38.160: INFO: Pod "pod-configmaps-53141b3c-0f15-4a86-9ea8-23641449dd56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040966156s
Aug 24 12:57:40.174: INFO: Pod "pod-configmaps-53141b3c-0f15-4a86-9ea8-23641449dd56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054942126s
STEP: Saw pod success
Aug 24 12:57:40.174: INFO: Pod "pod-configmaps-53141b3c-0f15-4a86-9ea8-23641449dd56" satisfied condition "Succeeded or Failed"
Aug 24 12:57:40.179: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-configmaps-53141b3c-0f15-4a86-9ea8-23641449dd56 container agnhost-container: <nil>
STEP: delete the pod
Aug 24 12:57:40.209: INFO: Waiting for pod pod-configmaps-53141b3c-0f15-4a86-9ea8-23641449dd56 to disappear
Aug 24 12:57:40.215: INFO: Pod pod-configmaps-53141b3c-0f15-4a86-9ea8-23641449dd56 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:57:40.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2497" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":346,"completed":249,"skipped":4831,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:57:40.232: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 24 12:57:40.307: INFO: Waiting up to 5m0s for pod "pod-e91da486-f034-4baf-bffa-1e12bd60b7d6" in namespace "emptydir-2353" to be "Succeeded or Failed"
Aug 24 12:57:40.313: INFO: Pod "pod-e91da486-f034-4baf-bffa-1e12bd60b7d6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.105706ms
Aug 24 12:57:42.342: INFO: Pod "pod-e91da486-f034-4baf-bffa-1e12bd60b7d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034706813s
Aug 24 12:57:44.357: INFO: Pod "pod-e91da486-f034-4baf-bffa-1e12bd60b7d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049407814s
STEP: Saw pod success
Aug 24 12:57:44.357: INFO: Pod "pod-e91da486-f034-4baf-bffa-1e12bd60b7d6" satisfied condition "Succeeded or Failed"
Aug 24 12:57:44.361: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-e91da486-f034-4baf-bffa-1e12bd60b7d6 container test-container: <nil>
STEP: delete the pod
Aug 24 12:57:44.395: INFO: Waiting for pod pod-e91da486-f034-4baf-bffa-1e12bd60b7d6 to disappear
Aug 24 12:57:44.399: INFO: Pod pod-e91da486-f034-4baf-bffa-1e12bd60b7d6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:57:44.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2353" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":250,"skipped":4834,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:57:44.414: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1573
[It] should update a single-container pod's image  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Aug 24 12:57:44.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-4359 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Aug 24 12:57:44.597: INFO: stderr: ""
Aug 24 12:57:44.598: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Aug 24 12:57:49.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-4359 get pod e2e-test-httpd-pod -o json'
Aug 24 12:57:49.774: INFO: stderr: ""
Aug 24 12:57:49.774: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2022-08-24T12:57:44Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-4359\",\n        \"resourceVersion\": \"40460\",\n        \"uid\": \"12d8fcad-2912-417c-844a-6e000c0f8bb4\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-qhrxc\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"zou9eicaeree-3\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-qhrxc\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-24T12:57:44Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-24T12:57:46Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-24T12:57:46Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-24T12:57:44Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://a8c09ac65d98e0ef1516743b4d302e5f997c448e4d15a6ef7a31ab716d6ea156\",\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-08-24T12:57:45Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.121.108\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.66.166\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.66.166\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-08-24T12:57:44Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 24 12:57:49.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-4359 replace -f -'
Aug 24 12:57:50.179: INFO: stderr: ""
Aug 24 12:57:50.179: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/busybox:1.29-2
[AfterEach] Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1577
Aug 24 12:57:50.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-4359 delete pods e2e-test-httpd-pod'
Aug 24 12:57:52.201: INFO: stderr: ""
Aug 24 12:57:52.201: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:57:52.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4359" for this suite.

• [SLOW TEST:7.813 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1570
    should update a single-container pod's image  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":346,"completed":251,"skipped":4847,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:57:52.228: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Aug 24 12:57:52.282: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 24 12:57:52.301: INFO: Waiting for terminating namespaces to be deleted...
Aug 24 12:57:52.306: INFO: 
Logging pods the apiserver thinks is on node zou9eicaeree-1 before test
Aug 24 12:57:52.317: INFO: kube-flannel-ds-7bf94 from kube-flannel started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.317: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 24 12:57:52.317: INFO: coredns-bd6b6df9f-8wkdm from kube-system started at 2022-08-24 12:03:41 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.317: INFO: 	Container coredns ready: true, restart count 0
Aug 24 12:57:52.317: INFO: kube-addon-manager-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.317: INFO: 	Container kube-addon-manager ready: true, restart count 2
Aug 24 12:57:52.317: INFO: kube-apiserver-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.317: INFO: 	Container kube-apiserver ready: true, restart count 3
Aug 24 12:57:52.317: INFO: kube-controller-manager-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.317: INFO: 	Container kube-controller-manager ready: true, restart count 3
Aug 24 12:57:52.317: INFO: kube-proxy-ppn7b from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.317: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 24 12:57:52.317: INFO: kube-scheduler-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.317: INFO: 	Container kube-scheduler ready: true, restart count 3
Aug 24 12:57:52.317: INFO: sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-8pdr5 from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 12:57:52.317: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 12:57:52.317: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 12:57:52.317: INFO: 
Logging pods the apiserver thinks is on node zou9eicaeree-2 before test
Aug 24 12:57:52.328: INFO: kube-flannel-ds-5z9q7 from kube-flannel started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.328: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 24 12:57:52.328: INFO: coredns-bd6b6df9f-cqzkx from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.328: INFO: 	Container coredns ready: true, restart count 0
Aug 24 12:57:52.328: INFO: kube-addon-manager-zou9eicaeree-2 from kube-system started at 2022-08-24 11:41:08 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.328: INFO: 	Container kube-addon-manager ready: true, restart count 2
Aug 24 12:57:52.328: INFO: kube-apiserver-zou9eicaeree-2 from kube-system started at 2022-08-24 09:21:45 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.328: INFO: 	Container kube-apiserver ready: true, restart count 3
Aug 24 12:57:52.328: INFO: kube-controller-manager-zou9eicaeree-2 from kube-system started at 2022-08-24 11:41:08 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.328: INFO: 	Container kube-controller-manager ready: true, restart count 4
Aug 24 12:57:52.328: INFO: kube-proxy-brwdv from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.328: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 24 12:57:52.328: INFO: kube-scheduler-zou9eicaeree-2 from kube-system started at 2022-08-24 11:41:08 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.328: INFO: 	Container kube-scheduler ready: true, restart count 4
Aug 24 12:57:52.328: INFO: sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-549ck from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 12:57:52.328: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 12:57:52.328: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 12:57:52.328: INFO: 
Logging pods the apiserver thinks is on node zou9eicaeree-3 before test
Aug 24 12:57:52.338: INFO: kube-flannel-ds-zt7p4 from kube-flannel started at 2022-08-24 12:06:15 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.338: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 24 12:57:52.338: INFO: kube-proxy-qn7vg from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.338: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 24 12:57:52.339: INFO: sonobuoy from sonobuoy started at 2022-08-24 11:47:10 +0000 UTC (1 container statuses recorded)
Aug 24 12:57:52.339: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 24 12:57:52.339: INFO: sonobuoy-e2e-job-4d9551b899414778 from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 12:57:52.339: INFO: 	Container e2e ready: true, restart count 0
Aug 24 12:57:52.339: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 12:57:52.339: INFO: sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-n4sbd from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 12:57:52.339: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 12:57:52.339: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: verifying the node has the label node zou9eicaeree-1
STEP: verifying the node has the label node zou9eicaeree-2
STEP: verifying the node has the label node zou9eicaeree-3
Aug 24 12:57:52.429: INFO: Pod kube-flannel-ds-5z9q7 requesting resource cpu=100m on Node zou9eicaeree-2
Aug 24 12:57:52.429: INFO: Pod kube-flannel-ds-7bf94 requesting resource cpu=100m on Node zou9eicaeree-1
Aug 24 12:57:52.429: INFO: Pod kube-flannel-ds-zt7p4 requesting resource cpu=100m on Node zou9eicaeree-3
Aug 24 12:57:52.429: INFO: Pod coredns-bd6b6df9f-8wkdm requesting resource cpu=100m on Node zou9eicaeree-1
Aug 24 12:57:52.430: INFO: Pod coredns-bd6b6df9f-cqzkx requesting resource cpu=100m on Node zou9eicaeree-2
Aug 24 12:57:52.430: INFO: Pod kube-addon-manager-zou9eicaeree-1 requesting resource cpu=5m on Node zou9eicaeree-1
Aug 24 12:57:52.430: INFO: Pod kube-addon-manager-zou9eicaeree-2 requesting resource cpu=5m on Node zou9eicaeree-2
Aug 24 12:57:52.430: INFO: Pod kube-apiserver-zou9eicaeree-1 requesting resource cpu=250m on Node zou9eicaeree-1
Aug 24 12:57:52.430: INFO: Pod kube-apiserver-zou9eicaeree-2 requesting resource cpu=250m on Node zou9eicaeree-2
Aug 24 12:57:52.430: INFO: Pod kube-controller-manager-zou9eicaeree-1 requesting resource cpu=200m on Node zou9eicaeree-1
Aug 24 12:57:52.430: INFO: Pod kube-controller-manager-zou9eicaeree-2 requesting resource cpu=200m on Node zou9eicaeree-2
Aug 24 12:57:52.430: INFO: Pod kube-proxy-brwdv requesting resource cpu=0m on Node zou9eicaeree-2
Aug 24 12:57:52.430: INFO: Pod kube-proxy-ppn7b requesting resource cpu=0m on Node zou9eicaeree-1
Aug 24 12:57:52.430: INFO: Pod kube-proxy-qn7vg requesting resource cpu=0m on Node zou9eicaeree-3
Aug 24 12:57:52.430: INFO: Pod kube-scheduler-zou9eicaeree-1 requesting resource cpu=100m on Node zou9eicaeree-1
Aug 24 12:57:52.430: INFO: Pod kube-scheduler-zou9eicaeree-2 requesting resource cpu=100m on Node zou9eicaeree-2
Aug 24 12:57:52.430: INFO: Pod sonobuoy requesting resource cpu=0m on Node zou9eicaeree-3
Aug 24 12:57:52.430: INFO: Pod sonobuoy-e2e-job-4d9551b899414778 requesting resource cpu=0m on Node zou9eicaeree-3
Aug 24 12:57:52.430: INFO: Pod sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-549ck requesting resource cpu=0m on Node zou9eicaeree-2
Aug 24 12:57:52.430: INFO: Pod sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-8pdr5 requesting resource cpu=0m on Node zou9eicaeree-1
Aug 24 12:57:52.430: INFO: Pod sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-n4sbd requesting resource cpu=0m on Node zou9eicaeree-3
STEP: Starting Pods to consume most of the cluster CPU.
Aug 24 12:57:52.430: INFO: Creating a pod which consumes cpu=591m on Node zou9eicaeree-1
Aug 24 12:57:52.443: INFO: Creating a pod which consumes cpu=591m on Node zou9eicaeree-2
Aug 24 12:57:52.455: INFO: Creating a pod which consumes cpu=1050m on Node zou9eicaeree-3
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-027b9a04-afad-490f-b9b4-40e0ef24ae66.170e4944d2c4e393], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8784/filler-pod-027b9a04-afad-490f-b9b4-40e0ef24ae66 to zou9eicaeree-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-027b9a04-afad-490f-b9b4-40e0ef24ae66.170e4944f1b905bc], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.6" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-027b9a04-afad-490f-b9b4-40e0ef24ae66.170e4944f8f16535], Reason = [Created], Message = [Created container filler-pod-027b9a04-afad-490f-b9b4-40e0ef24ae66]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-027b9a04-afad-490f-b9b4-40e0ef24ae66.170e4944fa884529], Reason = [Started], Message = [Started container filler-pod-027b9a04-afad-490f-b9b4-40e0ef24ae66]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3ba60c78-786a-40fa-b96e-18217fa1e2f9.170e4944d2cbcaeb], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8784/filler-pod-3ba60c78-786a-40fa-b96e-18217fa1e2f9 to zou9eicaeree-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3ba60c78-786a-40fa-b96e-18217fa1e2f9.170e4944f019c669], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.6" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3ba60c78-786a-40fa-b96e-18217fa1e2f9.170e4944f70d877c], Reason = [Created], Message = [Created container filler-pod-3ba60c78-786a-40fa-b96e-18217fa1e2f9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3ba60c78-786a-40fa-b96e-18217fa1e2f9.170e4944f85a46bc], Reason = [Started], Message = [Started container filler-pod-3ba60c78-786a-40fa-b96e-18217fa1e2f9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d1d666df-9c24-4867-b310-dd695893d731.170e4944d2b6a4c9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8784/filler-pod-d1d666df-9c24-4867-b310-dd695893d731 to zou9eicaeree-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d1d666df-9c24-4867-b310-dd695893d731.170e4944f30767e0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.6" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d1d666df-9c24-4867-b310-dd695893d731.170e494500d0b0d5], Reason = [Created], Message = [Created container filler-pod-d1d666df-9c24-4867-b310-dd695893d731]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d1d666df-9c24-4867-b310-dd695893d731.170e494503767c44], Reason = [Started], Message = [Started container filler-pod-d1d666df-9c24-4867-b310-dd695893d731]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.170e49454be7ab1e], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node zou9eicaeree-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node zou9eicaeree-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node zou9eicaeree-3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:57:55.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8784" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":346,"completed":252,"skipped":4878,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:57:55.635: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create and stop a working application  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating all guestbook components
Aug 24 12:57:55.686: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Aug 24 12:57:55.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-3165 create -f -'
Aug 24 12:57:55.971: INFO: stderr: ""
Aug 24 12:57:55.971: INFO: stdout: "service/agnhost-replica created\n"
Aug 24 12:57:55.972: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Aug 24 12:57:55.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-3165 create -f -'
Aug 24 12:57:56.315: INFO: stderr: ""
Aug 24 12:57:56.315: INFO: stdout: "service/agnhost-primary created\n"
Aug 24 12:57:56.315: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 24 12:57:56.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-3165 create -f -'
Aug 24 12:57:56.582: INFO: stderr: ""
Aug 24 12:57:56.582: INFO: stdout: "service/frontend created\n"
Aug 24 12:57:56.583: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Aug 24 12:57:56.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-3165 create -f -'
Aug 24 12:57:56.813: INFO: stderr: ""
Aug 24 12:57:56.813: INFO: stdout: "deployment.apps/frontend created\n"
Aug 24 12:57:56.813: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 24 12:57:56.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-3165 create -f -'
Aug 24 12:57:57.134: INFO: stderr: ""
Aug 24 12:57:57.134: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Aug 24 12:57:57.134: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 24 12:57:57.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-3165 create -f -'
Aug 24 12:57:57.505: INFO: stderr: ""
Aug 24 12:57:57.505: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app
Aug 24 12:57:57.505: INFO: Waiting for all frontend pods to be Running.
Aug 24 12:58:02.556: INFO: Waiting for frontend to serve content.
Aug 24 12:58:02.579: INFO: Trying to add a new entry to the guestbook.
Aug 24 12:58:02.596: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug 24 12:58:02.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-3165 delete --grace-period=0 --force -f -'
Aug 24 12:58:02.755: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 12:58:02.756: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources
Aug 24 12:58:02.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-3165 delete --grace-period=0 --force -f -'
Aug 24 12:58:02.918: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 12:58:02.918: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Aug 24 12:58:02.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-3165 delete --grace-period=0 --force -f -'
Aug 24 12:58:03.111: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 12:58:03.111: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 24 12:58:03.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-3165 delete --grace-period=0 --force -f -'
Aug 24 12:58:03.242: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 12:58:03.242: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 24 12:58:03.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-3165 delete --grace-period=0 --force -f -'
Aug 24 12:58:03.453: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 12:58:03.453: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Aug 24 12:58:03.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-3165 delete --grace-period=0 --force -f -'
Aug 24 12:58:03.644: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 12:58:03.644: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:58:03.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3165" for this suite.

• [SLOW TEST:8.032 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:339
    should create and stop a working application  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":346,"completed":253,"skipped":4881,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:58:03.667: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5961
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-5961
STEP: creating replication controller externalsvc in namespace services-5961
I0824 12:58:03.858594      16 runners.go:193] Created replication controller with name: externalsvc, namespace: services-5961, replica count: 2
I0824 12:58:06.909765      16 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Aug 24 12:58:06.957: INFO: Creating new exec pod
Aug 24 12:58:09.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-5961 exec execpodscp6x -- /bin/sh -x -c nslookup clusterip-service.services-5961.svc.cluster.local'
Aug 24 12:58:09.372: INFO: stderr: "+ nslookup clusterip-service.services-5961.svc.cluster.local\n"
Aug 24 12:58:09.372: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nclusterip-service.services-5961.svc.cluster.local\tcanonical name = externalsvc.services-5961.svc.cluster.local.\nName:\texternalsvc.services-5961.svc.cluster.local\nAddress: 10.233.24.70\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5961, will wait for the garbage collector to delete the pods
Aug 24 12:58:09.441: INFO: Deleting ReplicationController externalsvc took: 11.851196ms
Aug 24 12:58:09.542: INFO: Terminating ReplicationController externalsvc pods took: 100.60511ms
Aug 24 12:58:11.483: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:58:11.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5961" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756

• [SLOW TEST:7.885 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":346,"completed":254,"skipped":4907,"failed":0}
SS
------------------------------
[sig-network] Services 
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:58:11.554: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating service in namespace services-8149
STEP: creating service affinity-nodeport in namespace services-8149
STEP: creating replication controller affinity-nodeport in namespace services-8149
I0824 12:58:11.648680      16 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-8149, replica count: 3
I0824 12:58:14.700192      16 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 12:58:14.730: INFO: Creating new exec pod
Aug 24 12:58:17.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8149 exec execpod-affinityg88df -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Aug 24 12:58:17.985: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Aug 24 12:58:17.985: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 12:58:17.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8149 exec execpod-affinityg88df -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.21.57 80'
Aug 24 12:58:18.195: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.21.57 80\nConnection to 10.233.21.57 80 port [tcp/http] succeeded!\n"
Aug 24 12:58:18.195: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 12:58:18.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8149 exec execpod-affinityg88df -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.182 30877'
Aug 24 12:58:18.436: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.182 30877\nConnection to 192.168.121.182 30877 port [tcp/*] succeeded!\n"
Aug 24 12:58:18.436: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 12:58:18.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8149 exec execpod-affinityg88df -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.241 30877'
Aug 24 12:58:20.655: INFO: rc: 1
Aug 24 12:58:20.655: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8149 exec execpod-affinityg88df -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.241 30877:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 192.168.121.241 30877
nc: connect to 192.168.121.241 port 30877 (tcp) timed out: Operation in progress
command terminated with exit code 1

error:
exit status 1
Retrying...
Aug 24 12:58:21.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8149 exec execpod-affinityg88df -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.241 30877'
Aug 24 12:58:23.893: INFO: rc: 1
Aug 24 12:58:23.893: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8149 exec execpod-affinityg88df -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.241 30877:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 192.168.121.241 30877
nc: connect to 192.168.121.241 port 30877 (tcp) timed out: Operation in progress
command terminated with exit code 1

error:
exit status 1
Retrying...
Aug 24 12:58:24.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8149 exec execpod-affinityg88df -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.241 30877'
Aug 24 12:58:26.903: INFO: rc: 1
Aug 24 12:58:26.903: INFO: Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8149 exec execpod-affinityg88df -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.241 30877:
Command stdout:

stderr:
+ echo hostName
+ nc -v -t -w 2 192.168.121.241 30877
nc: connect to 192.168.121.241 port 30877 (tcp) timed out: Operation in progress
command terminated with exit code 1

error:
exit status 1
Retrying...
Aug 24 12:58:27.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8149 exec execpod-affinityg88df -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.241 30877'
Aug 24 12:58:27.865: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.241 30877\nConnection to 192.168.121.241 30877 port [tcp/*] succeeded!\n"
Aug 24 12:58:27.865: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 12:58:27.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-8149 exec execpod-affinityg88df -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.241:30877/ ; done'
Aug 24 12:58:28.260: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30877/\n"
Aug 24 12:58:28.260: INFO: stdout: "\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc\naffinity-nodeport-sgsrc"
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Received response from host: affinity-nodeport-sgsrc
Aug 24 12:58:28.260: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-8149, will wait for the garbage collector to delete the pods
Aug 24 12:58:28.353: INFO: Deleting ReplicationController affinity-nodeport took: 12.056202ms
Aug 24 12:58:28.453: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.496347ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:58:30.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8149" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756

• [SLOW TEST:19.278 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","total":346,"completed":255,"skipped":4909,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should succeed in writing subpaths in container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:58:30.834: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating the pod
STEP: waiting for pod running
STEP: creating a file in subpath
Aug 24 12:58:32.948: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-5816 PodName:var-expansion-144dde57-620b-46ec-a572-a15151b1d853 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:58:32.949: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:58:32.950: INFO: ExecWithOptions: Clientset creation
Aug 24 12:58:32.950: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-5816/pods/var-expansion-144dde57-620b-46ec-a572-a15151b1d853/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true %!s(MISSING))
STEP: test for file in mounted path
Aug 24 12:58:33.068: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-5816 PodName:var-expansion-144dde57-620b-46ec-a572-a15151b1d853 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Aug 24 12:58:33.068: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 12:58:33.069: INFO: ExecWithOptions: Clientset creation
Aug 24 12:58:33.069: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-5816/pods/var-expansion-144dde57-620b-46ec-a572-a15151b1d853/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true %!s(MISSING))
STEP: updating the annotation value
Aug 24 12:58:33.702: INFO: Successfully updated pod "var-expansion-144dde57-620b-46ec-a572-a15151b1d853"
STEP: waiting for annotated pod running
STEP: deleting the pod gracefully
Aug 24 12:58:33.709: INFO: Deleting pod "var-expansion-144dde57-620b-46ec-a572-a15151b1d853" in namespace "var-expansion-5816"
Aug 24 12:58:33.720: INFO: Wait up to 5m0s for pod "var-expansion-144dde57-620b-46ec-a572-a15151b1d853" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:59:07.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5816" for this suite.

• [SLOW TEST:36.961 seconds]
[sig-node] Variable Expansion
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","total":346,"completed":256,"skipped":4918,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:59:07.797: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 12:59:07.922: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e078e8cd-112e-4583-a3ed-de9096a394de" in namespace "projected-8073" to be "Succeeded or Failed"
Aug 24 12:59:07.928: INFO: Pod "downwardapi-volume-e078e8cd-112e-4583-a3ed-de9096a394de": Phase="Pending", Reason="", readiness=false. Elapsed: 5.745633ms
Aug 24 12:59:09.947: INFO: Pod "downwardapi-volume-e078e8cd-112e-4583-a3ed-de9096a394de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024912554s
Aug 24 12:59:11.961: INFO: Pod "downwardapi-volume-e078e8cd-112e-4583-a3ed-de9096a394de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039227711s
STEP: Saw pod success
Aug 24 12:59:11.961: INFO: Pod "downwardapi-volume-e078e8cd-112e-4583-a3ed-de9096a394de" satisfied condition "Succeeded or Failed"
Aug 24 12:59:11.968: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-e078e8cd-112e-4583-a3ed-de9096a394de container client-container: <nil>
STEP: delete the pod
Aug 24 12:59:11.999: INFO: Waiting for pod downwardapi-volume-e078e8cd-112e-4583-a3ed-de9096a394de to disappear
Aug 24 12:59:12.008: INFO: Pod downwardapi-volume-e078e8cd-112e-4583-a3ed-de9096a394de no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:59:12.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8073" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":346,"completed":257,"skipped":4928,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:59:12.031: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a service nodeport-service with the type=NodePort in namespace services-4890
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-4890
STEP: creating replication controller externalsvc in namespace services-4890
I0824 12:59:12.165145      16 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4890, replica count: 2
I0824 12:59:15.217131      16 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Aug 24 12:59:15.261: INFO: Creating new exec pod
Aug 24 12:59:17.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-4890 exec execpodsqgvn -- /bin/sh -x -c nslookup nodeport-service.services-4890.svc.cluster.local'
Aug 24 12:59:17.706: INFO: stderr: "+ nslookup nodeport-service.services-4890.svc.cluster.local\n"
Aug 24 12:59:17.706: INFO: stdout: "Server:\t\t10.233.0.10\nAddress:\t10.233.0.10#53\n\nnodeport-service.services-4890.svc.cluster.local\tcanonical name = externalsvc.services-4890.svc.cluster.local.\nName:\texternalsvc.services-4890.svc.cluster.local\nAddress: 10.233.32.7\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4890, will wait for the garbage collector to delete the pods
Aug 24 12:59:17.779: INFO: Deleting ReplicationController externalsvc took: 11.587705ms
Aug 24 12:59:17.880: INFO: Terminating ReplicationController externalsvc pods took: 101.032ms
Aug 24 12:59:20.320: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:59:20.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4890" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756

• [SLOW TEST:8.345 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":346,"completed":258,"skipped":4956,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:59:20.376: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 24 12:59:20.459: INFO: Waiting up to 5m0s for pod "pod-92a5b033-56cd-437a-b1b6-244209f67cd1" in namespace "emptydir-3267" to be "Succeeded or Failed"
Aug 24 12:59:20.464: INFO: Pod "pod-92a5b033-56cd-437a-b1b6-244209f67cd1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.478759ms
Aug 24 12:59:22.478: INFO: Pod "pod-92a5b033-56cd-437a-b1b6-244209f67cd1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018939036s
Aug 24 12:59:24.490: INFO: Pod "pod-92a5b033-56cd-437a-b1b6-244209f67cd1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030857987s
STEP: Saw pod success
Aug 24 12:59:24.490: INFO: Pod "pod-92a5b033-56cd-437a-b1b6-244209f67cd1" satisfied condition "Succeeded or Failed"
Aug 24 12:59:24.495: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-92a5b033-56cd-437a-b1b6-244209f67cd1 container test-container: <nil>
STEP: delete the pod
Aug 24 12:59:24.524: INFO: Waiting for pod pod-92a5b033-56cd-437a-b1b6-244209f67cd1 to disappear
Aug 24 12:59:24.529: INFO: Pod pod-92a5b033-56cd-437a-b1b6-244209f67cd1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:59:24.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3267" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":259,"skipped":4973,"failed":0}
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:59:24.549: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 24 12:59:24.652: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9872  cffe3f85-9f29-4f70-b97a-079043f2c5a7 41320 0 2022-08-24 12:59:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-08-24 12:59:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 12:59:24.652: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9872  cffe3f85-9f29-4f70-b97a-079043f2c5a7 41321 0 2022-08-24 12:59:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-08-24 12:59:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 24 12:59:24.693: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9872  cffe3f85-9f29-4f70-b97a-079043f2c5a7 41322 0 2022-08-24 12:59:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-08-24 12:59:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Aug 24 12:59:24.694: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9872  cffe3f85-9f29-4f70-b97a-079043f2c5a7 41323 0 2022-08-24 12:59:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-08-24 12:59:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 12:59:24.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9872" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":346,"completed":260,"skipped":4976,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 12:59:24.724: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1413.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1413.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1413.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1413.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1413.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1413.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1413.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1413.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1413.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1413.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 130.32.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.32.130_udp@PTR;check="$$(dig +tcp +noall +answer +search 130.32.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.32.130_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1413.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1413.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1413.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1413.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1413.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1413.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1413.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1413.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1413.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1413.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 130.32.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.32.130_udp@PTR;check="$$(dig +tcp +noall +answer +search 130.32.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.32.130_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 24 12:59:26.873: INFO: Unable to read wheezy_udp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:26.879: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:26.885: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:26.890: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:26.947: INFO: Unable to read jessie_udp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:26.959: INFO: Unable to read jessie_tcp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:26.965: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:26.971: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:26.992: INFO: Lookups using dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160 failed for: [wheezy_udp@dns-test-service.dns-1413.svc.cluster.local wheezy_tcp@dns-test-service.dns-1413.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local jessie_udp@dns-test-service.dns-1413.svc.cluster.local jessie_tcp@dns-test-service.dns-1413.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local]

Aug 24 12:59:32.003: INFO: Unable to read wheezy_udp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:32.010: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:32.015: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:32.020: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:32.044: INFO: Unable to read jessie_udp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:32.051: INFO: Unable to read jessie_tcp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:32.057: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:32.063: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:32.085: INFO: Lookups using dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160 failed for: [wheezy_udp@dns-test-service.dns-1413.svc.cluster.local wheezy_tcp@dns-test-service.dns-1413.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local jessie_udp@dns-test-service.dns-1413.svc.cluster.local jessie_tcp@dns-test-service.dns-1413.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local]

Aug 24 12:59:37.003: INFO: Unable to read wheezy_udp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:37.010: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:37.017: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:37.035: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:37.134: INFO: Unable to read jessie_udp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:37.143: INFO: Unable to read jessie_tcp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:37.155: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:37.191: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:37.252: INFO: Lookups using dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160 failed for: [wheezy_udp@dns-test-service.dns-1413.svc.cluster.local wheezy_tcp@dns-test-service.dns-1413.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local jessie_udp@dns-test-service.dns-1413.svc.cluster.local jessie_tcp@dns-test-service.dns-1413.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local]

Aug 24 12:59:42.002: INFO: Unable to read wheezy_udp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:42.009: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:42.017: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:42.022: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:42.053: INFO: Unable to read jessie_udp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:42.059: INFO: Unable to read jessie_tcp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:42.066: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:42.074: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:42.100: INFO: Lookups using dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160 failed for: [wheezy_udp@dns-test-service.dns-1413.svc.cluster.local wheezy_tcp@dns-test-service.dns-1413.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local jessie_udp@dns-test-service.dns-1413.svc.cluster.local jessie_tcp@dns-test-service.dns-1413.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local]

Aug 24 12:59:47.002: INFO: Unable to read wheezy_udp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:47.008: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:47.017: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:47.024: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:47.061: INFO: Unable to read jessie_udp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:47.069: INFO: Unable to read jessie_tcp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:47.082: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:47.089: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:47.112: INFO: Lookups using dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160 failed for: [wheezy_udp@dns-test-service.dns-1413.svc.cluster.local wheezy_tcp@dns-test-service.dns-1413.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local jessie_udp@dns-test-service.dns-1413.svc.cluster.local jessie_tcp@dns-test-service.dns-1413.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local]

Aug 24 12:59:52.001: INFO: Unable to read wheezy_udp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:52.007: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:52.014: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:52.019: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:52.051: INFO: Unable to read jessie_udp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:52.059: INFO: Unable to read jessie_tcp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:52.064: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:52.069: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:52.097: INFO: Lookups using dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160 failed for: [wheezy_udp@dns-test-service.dns-1413.svc.cluster.local wheezy_tcp@dns-test-service.dns-1413.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local jessie_udp@dns-test-service.dns-1413.svc.cluster.local jessie_tcp@dns-test-service.dns-1413.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1413.svc.cluster.local]

Aug 24 12:59:57.002: INFO: Unable to read wheezy_udp@dns-test-service.dns-1413.svc.cluster.local from pod dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160: the server could not find the requested resource (get pods dns-test-954bf39d-9156-43d0-bb3c-362669672160)
Aug 24 12:59:57.158: INFO: Lookups using dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160 failed for: [wheezy_udp@dns-test-service.dns-1413.svc.cluster.local]

Aug 24 13:00:02.081: INFO: DNS probes using dns-1413/dns-test-954bf39d-9156-43d0-bb3c-362669672160 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:00:02.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1413" for this suite.

• [SLOW TEST:37.592 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":346,"completed":261,"skipped":4999,"failed":0}
S
------------------------------
[sig-node] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:00:02.316: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating pod busybox-77041b8c-5b3b-4df7-9b3c-c23330bffa4e in namespace container-probe-6376
Aug 24 13:00:04.463: INFO: Started pod busybox-77041b8c-5b3b-4df7-9b3c-c23330bffa4e in namespace container-probe-6376
STEP: checking the pod's current state and verifying that restartCount is present
Aug 24 13:00:04.469: INFO: Initial restart count of pod busybox-77041b8c-5b3b-4df7-9b3c-c23330bffa4e is 0
Aug 24 13:00:54.841: INFO: Restart count of pod container-probe-6376/busybox-77041b8c-5b3b-4df7-9b3c-c23330bffa4e is now 1 (50.37176281s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:00:54.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6376" for this suite.

• [SLOW TEST:52.566 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":346,"completed":262,"skipped":5000,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:00:54.895: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating pod test-webserver-ab4fe110-6c83-4593-9871-9c9ff612833e in namespace container-probe-9372
Aug 24 13:00:56.984: INFO: Started pod test-webserver-ab4fe110-6c83-4593-9871-9c9ff612833e in namespace container-probe-9372
STEP: checking the pod's current state and verifying that restartCount is present
Aug 24 13:00:56.991: INFO: Initial restart count of pod test-webserver-ab4fe110-6c83-4593-9871-9c9ff612833e is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:04:58.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9372" for this suite.

• [SLOW TEST:243.927 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":346,"completed":263,"skipped":5124,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:04:58.823: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating secret with name s-test-opt-del-33b5ee9c-0995-42e9-ba5f-234461eeede2
STEP: Creating secret with name s-test-opt-upd-b85c9a81-7dee-4ee1-9fe2-4870524ef122
STEP: Creating the pod
Aug 24 13:04:58.953: INFO: The status of Pod pod-projected-secrets-1cd1affc-5540-4584-b9b0-36879e26c2f1 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 13:05:00.972: INFO: The status of Pod pod-projected-secrets-1cd1affc-5540-4584-b9b0-36879e26c2f1 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-33b5ee9c-0995-42e9-ba5f-234461eeede2
STEP: Updating secret s-test-opt-upd-b85c9a81-7dee-4ee1-9fe2-4870524ef122
STEP: Creating secret with name s-test-opt-create-e11ea31c-7b31-4a1a-a8bb-c51c7181d592
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:05:05.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6885" for this suite.

• [SLOW TEST:6.331 seconds]
[sig-storage] Projected secret
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":264,"skipped":5135,"failed":0}
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:05:05.155: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create services for rc  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating Agnhost RC
Aug 24 13:05:05.190: INFO: namespace kubectl-4632
Aug 24 13:05:05.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-4632 create -f -'
Aug 24 13:05:05.720: INFO: stderr: ""
Aug 24 13:05:05.720: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Aug 24 13:05:06.733: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 13:05:06.733: INFO: Found 0 / 1
Aug 24 13:05:07.733: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 13:05:07.733: INFO: Found 1 / 1
Aug 24 13:05:07.733: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 24 13:05:07.738: INFO: Selector matched 1 pods for map[app:agnhost]
Aug 24 13:05:07.738: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 24 13:05:07.738: INFO: wait on agnhost-primary startup in kubectl-4632 
Aug 24 13:05:07.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-4632 logs agnhost-primary-xlr5p agnhost-primary'
Aug 24 13:05:07.866: INFO: stderr: ""
Aug 24 13:05:07.866: INFO: stdout: "Paused\n"
STEP: exposing RC
Aug 24 13:05:07.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-4632 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Aug 24 13:05:08.012: INFO: stderr: ""
Aug 24 13:05:08.012: INFO: stdout: "service/rm2 exposed\n"
Aug 24 13:05:08.028: INFO: Service rm2 in namespace kubectl-4632 found.
STEP: exposing service
Aug 24 13:05:10.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-4632 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Aug 24 13:05:10.192: INFO: stderr: ""
Aug 24 13:05:10.192: INFO: stdout: "service/rm3 exposed\n"
Aug 24 13:05:10.206: INFO: Service rm3 in namespace kubectl-4632 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:05:12.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4632" for this suite.

• [SLOW TEST:7.096 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1248
    should create services for rc  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":346,"completed":265,"skipped":5135,"failed":0}
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should run through the lifecycle of a ServiceAccount [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:05:12.251: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a ServiceAccount
STEP: watching for the ServiceAccount to be added
STEP: patching the ServiceAccount
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector)
STEP: deleting the ServiceAccount
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:05:12.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9311" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","total":346,"completed":266,"skipped":5141,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath 
  runs ReplicaSets to verify preemption running path [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:05:12.371: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Aug 24 13:05:12.435: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 24 13:06:12.491: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:06:12.497: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:488
STEP: Finding an available node
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
Aug 24 13:06:14.641: INFO: found a healthy node: zou9eicaeree-3
[It] runs ReplicaSets to verify preemption running path [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 13:06:22.825: INFO: pods created so far: [1 1 1]
Aug 24 13:06:22.825: INFO: length of pods created so far: 3
Aug 24 13:06:24.846: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:06:31.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-4953" for this suite.
[AfterEach] PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:462
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:06:31.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-696" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:79.673 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:451
    runs ReplicaSets to verify preemption running path [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","total":346,"completed":267,"skipped":5163,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:06:32.048: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 13:06:32.665: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 13:06:35.707: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:06:35.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2017" for this suite.
STEP: Destroying namespace "webhook-2017-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":346,"completed":268,"skipped":5173,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should block an eviction until the PDB is updated to allow it [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:06:35.945: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pdb that targets all three pods in a test replica set
STEP: Waiting for the pdb to be processed
STEP: First trying to evict a pod which shouldn't be evictable
STEP: Waiting for all pods to be running
Aug 24 13:06:36.033: INFO: pods: 0 < 3
STEP: locating a running pod
STEP: Updating the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
STEP: Waiting for the pdb to observed all healthy pods
STEP: Patching the pdb to disallow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
STEP: locating a running pod
STEP: Deleting the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be deleted
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:06:42.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4837" for this suite.

• [SLOW TEST:6.417 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","total":346,"completed":269,"skipped":5194,"failed":0}
SS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:06:42.361: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:06:42.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3430" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":346,"completed":270,"skipped":5196,"failed":0}
S
------------------------------
[sig-apps] CronJob 
  should replace jobs when ReplaceConcurrent [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:06:42.485: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should replace jobs when ReplaceConcurrent [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a ReplaceConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring the job is replaced with a new one
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:08:00.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4408" for this suite.

• [SLOW TEST:78.128 seconds]
[sig-apps] CronJob
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","total":346,"completed":271,"skipped":5197,"failed":0}
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:08:00.616: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 13:08:00.685: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fdb1e66d-8731-47eb-a8f5-f883817bb982" in namespace "projected-8132" to be "Succeeded or Failed"
Aug 24 13:08:00.696: INFO: Pod "downwardapi-volume-fdb1e66d-8731-47eb-a8f5-f883817bb982": Phase="Pending", Reason="", readiness=false. Elapsed: 11.149495ms
Aug 24 13:08:02.715: INFO: Pod "downwardapi-volume-fdb1e66d-8731-47eb-a8f5-f883817bb982": Phase="Running", Reason="", readiness=false. Elapsed: 2.030220409s
Aug 24 13:08:04.730: INFO: Pod "downwardapi-volume-fdb1e66d-8731-47eb-a8f5-f883817bb982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045538555s
STEP: Saw pod success
Aug 24 13:08:04.731: INFO: Pod "downwardapi-volume-fdb1e66d-8731-47eb-a8f5-f883817bb982" satisfied condition "Succeeded or Failed"
Aug 24 13:08:04.736: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-fdb1e66d-8731-47eb-a8f5-f883817bb982 container client-container: <nil>
STEP: delete the pod
Aug 24 13:08:04.784: INFO: Waiting for pod downwardapi-volume-fdb1e66d-8731-47eb-a8f5-f883817bb982 to disappear
Aug 24 13:08:04.790: INFO: Pod downwardapi-volume-fdb1e66d-8731-47eb-a8f5-f883817bb982 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:08:04.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8132" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":272,"skipped":5201,"failed":0}
SSS
------------------------------
[sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:08:04.818: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:157
[It] should call prestop when killing a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating server pod server in namespace prestop-402
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-402
STEP: Deleting pre-stop pod
Aug 24 13:08:13.947: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [sig-node] PreStop
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:08:13.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-402" for this suite.

• [SLOW TEST:9.199 seconds]
[sig-node] PreStop
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":346,"completed":273,"skipped":5204,"failed":0}
SS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates basic preemption works [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:08:14.018: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:90
Aug 24 13:08:14.093: INFO: Waiting up to 1m0s for all nodes to be ready
Aug 24 13:09:14.177: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Create pods that use 4/5 of node resources.
Aug 24 13:09:14.224: INFO: Created pod: pod0-0-sched-preemption-low-priority
Aug 24 13:09:14.234: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Aug 24 13:09:14.269: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Aug 24 13:09:14.297: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Aug 24 13:09:14.337: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Aug 24 13:09:14.350: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a high priority pod that has same requirements as that of lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:09:28.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7964" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/preemption.go:78

• [SLOW TEST:74.575 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","total":346,"completed":274,"skipped":5206,"failed":0}
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:09:28.593: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 13:09:28.644: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ab49714e-4276-4c99-9496-205cc903957b" in namespace "downward-api-4682" to be "Succeeded or Failed"
Aug 24 13:09:28.651: INFO: Pod "downwardapi-volume-ab49714e-4276-4c99-9496-205cc903957b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.253291ms
Aug 24 13:09:30.663: INFO: Pod "downwardapi-volume-ab49714e-4276-4c99-9496-205cc903957b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018991654s
Aug 24 13:09:32.678: INFO: Pod "downwardapi-volume-ab49714e-4276-4c99-9496-205cc903957b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033554515s
STEP: Saw pod success
Aug 24 13:09:32.678: INFO: Pod "downwardapi-volume-ab49714e-4276-4c99-9496-205cc903957b" satisfied condition "Succeeded or Failed"
Aug 24 13:09:32.682: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-ab49714e-4276-4c99-9496-205cc903957b container client-container: <nil>
STEP: delete the pod
Aug 24 13:09:32.714: INFO: Waiting for pod downwardapi-volume-ab49714e-4276-4c99-9496-205cc903957b to disappear
Aug 24 13:09:32.718: INFO: Pod downwardapi-volume-ab49714e-4276-4c99-9496-205cc903957b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:09:32.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4682" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":346,"completed":275,"skipped":5211,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:09:32.743: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 24 13:09:32.820: INFO: Waiting up to 5m0s for pod "pod-078a6a99-936d-4c5e-8392-926e2ac2c9e5" in namespace "emptydir-5164" to be "Succeeded or Failed"
Aug 24 13:09:32.834: INFO: Pod "pod-078a6a99-936d-4c5e-8392-926e2ac2c9e5": Phase="Pending", Reason="", readiness=false. Elapsed: 13.607706ms
Aug 24 13:09:34.848: INFO: Pod "pod-078a6a99-936d-4c5e-8392-926e2ac2c9e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027142922s
Aug 24 13:09:36.862: INFO: Pod "pod-078a6a99-936d-4c5e-8392-926e2ac2c9e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04178792s
STEP: Saw pod success
Aug 24 13:09:36.863: INFO: Pod "pod-078a6a99-936d-4c5e-8392-926e2ac2c9e5" satisfied condition "Succeeded or Failed"
Aug 24 13:09:36.869: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-078a6a99-936d-4c5e-8392-926e2ac2c9e5 container test-container: <nil>
STEP: delete the pod
Aug 24 13:09:36.902: INFO: Waiting for pod pod-078a6a99-936d-4c5e-8392-926e2ac2c9e5 to disappear
Aug 24 13:09:36.909: INFO: Pod pod-078a6a99-936d-4c5e-8392-926e2ac2c9e5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:09:36.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5164" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":276,"skipped":5254,"failed":0}
SSS
------------------------------
[sig-apps] DisruptionController 
  should update/patch PodDisruptionBudget status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:09:36.933: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[It] should update/patch PodDisruptionBudget status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Waiting for the pdb to be processed
STEP: Updating PodDisruptionBudget status
STEP: Waiting for all pods to be running
Aug 24 13:09:39.051: INFO: running pods: 0 < 1
STEP: locating a running pod
STEP: Waiting for the pdb to be processed
STEP: Patching PodDisruptionBudget status
STEP: Waiting for the pdb to be processed
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:09:41.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-7712" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","total":346,"completed":277,"skipped":5257,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:09:41.169: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name configmap-test-upd-7fca256d-28db-4c78-8fdd-067732497faf
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:09:43.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9943" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":346,"completed":278,"skipped":5271,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:09:43.325: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl label
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1333
STEP: creating the pod
Aug 24 13:09:43.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-7811 create -f -'
Aug 24 13:09:43.811: INFO: stderr: ""
Aug 24 13:09:43.811: INFO: stdout: "pod/pause created\n"
Aug 24 13:09:43.811: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 24 13:09:43.811: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7811" to be "running and ready"
Aug 24 13:09:43.819: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.485199ms
Aug 24 13:09:45.840: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.028431061s
Aug 24 13:09:45.840: INFO: Pod "pause" satisfied condition "running and ready"
Aug 24 13:09:45.840: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 24 13:09:45.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-7811 label pods pause testing-label=testing-label-value'
Aug 24 13:09:45.954: INFO: stderr: ""
Aug 24 13:09:45.954: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 24 13:09:45.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-7811 get pod pause -L testing-label'
Aug 24 13:09:46.070: INFO: stderr: ""
Aug 24 13:09:46.070: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 24 13:09:46.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-7811 label pods pause testing-label-'
Aug 24 13:09:46.186: INFO: stderr: ""
Aug 24 13:09:46.187: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 24 13:09:46.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-7811 get pod pause -L testing-label'
Aug 24 13:09:46.311: INFO: stderr: ""
Aug 24 13:09:46.311: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1339
STEP: using delete to clean up resources
Aug 24 13:09:46.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-7811 delete --grace-period=0 --force -f -'
Aug 24 13:09:46.454: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 13:09:46.454: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 24 13:09:46.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-7811 get rc,svc -l name=pause --no-headers'
Aug 24 13:09:46.654: INFO: stderr: "No resources found in kubectl-7811 namespace.\n"
Aug 24 13:09:46.654: INFO: stdout: ""
Aug 24 13:09:46.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-7811 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 24 13:09:46.804: INFO: stderr: ""
Aug 24 13:09:46.805: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:09:46.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7811" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":346,"completed":279,"skipped":5306,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:09:46.827: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/init_container.go:162
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating the pod
Aug 24 13:09:46.907: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:09:49.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6434" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":346,"completed":280,"skipped":5337,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:09:49.916: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 24 13:09:49.976: INFO: Waiting up to 5m0s for pod "pod-4e1c5d30-20a1-453b-bdb5-24a01a141619" in namespace "emptydir-5290" to be "Succeeded or Failed"
Aug 24 13:09:49.991: INFO: Pod "pod-4e1c5d30-20a1-453b-bdb5-24a01a141619": Phase="Pending", Reason="", readiness=false. Elapsed: 14.648341ms
Aug 24 13:09:52.015: INFO: Pod "pod-4e1c5d30-20a1-453b-bdb5-24a01a141619": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038512716s
Aug 24 13:09:54.027: INFO: Pod "pod-4e1c5d30-20a1-453b-bdb5-24a01a141619": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050510048s
STEP: Saw pod success
Aug 24 13:09:54.027: INFO: Pod "pod-4e1c5d30-20a1-453b-bdb5-24a01a141619" satisfied condition "Succeeded or Failed"
Aug 24 13:09:54.032: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-4e1c5d30-20a1-453b-bdb5-24a01a141619 container test-container: <nil>
STEP: delete the pod
Aug 24 13:09:54.063: INFO: Waiting for pod pod-4e1c5d30-20a1-453b-bdb5-24a01a141619 to disappear
Aug 24 13:09:54.069: INFO: Pod pod-4e1c5d30-20a1-453b-bdb5-24a01a141619 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:09:54.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5290" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":281,"skipped":5340,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:09:54.094: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:53
STEP: create the container to handle the HTTPGet hook request.
Aug 24 13:09:54.179: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 24 13:09:56.192: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create the pod with lifecycle hook
Aug 24 13:09:56.211: INFO: The status of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 24 13:09:58.225: INFO: The status of Pod pod-with-prestop-http-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Aug 24 13:09:58.241: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 24 13:09:58.248: INFO: Pod pod-with-prestop-http-hook still exists
Aug 24 13:10:00.248: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 24 13:10:00.260: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:10:00.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8082" for this suite.

• [SLOW TEST:6.213 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:44
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":346,"completed":282,"skipped":5349,"failed":0}
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:10:00.307: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Aug 24 13:10:10.483: INFO: The status of Pod kube-controller-manager-zou9eicaeree-2 is Running (Ready = true)
Aug 24 13:10:10.581: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:10:10.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6932" for this suite.

• [SLOW TEST:10.296 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":346,"completed":283,"skipped":5350,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:10:10.605: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 13:10:10.658: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0d544b1-328f-42d1-ac9d-7241ad49fa14" in namespace "downward-api-2072" to be "Succeeded or Failed"
Aug 24 13:10:10.666: INFO: Pod "downwardapi-volume-c0d544b1-328f-42d1-ac9d-7241ad49fa14": Phase="Pending", Reason="", readiness=false. Elapsed: 7.140892ms
Aug 24 13:10:12.682: INFO: Pod "downwardapi-volume-c0d544b1-328f-42d1-ac9d-7241ad49fa14": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023337622s
Aug 24 13:10:14.699: INFO: Pod "downwardapi-volume-c0d544b1-328f-42d1-ac9d-7241ad49fa14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040426679s
STEP: Saw pod success
Aug 24 13:10:14.699: INFO: Pod "downwardapi-volume-c0d544b1-328f-42d1-ac9d-7241ad49fa14" satisfied condition "Succeeded or Failed"
Aug 24 13:10:14.706: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-c0d544b1-328f-42d1-ac9d-7241ad49fa14 container client-container: <nil>
STEP: delete the pod
Aug 24 13:10:14.744: INFO: Waiting for pod downwardapi-volume-c0d544b1-328f-42d1-ac9d-7241ad49fa14 to disappear
Aug 24 13:10:14.749: INFO: Pod downwardapi-volume-c0d544b1-328f-42d1-ac9d-7241ad49fa14 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:10:14.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2072" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":346,"completed":284,"skipped":5367,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:10:14.768: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:10:14.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6499" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","total":346,"completed":285,"skipped":5394,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:10:14.943: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:296
[It] should scale a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a replication controller
Aug 24 13:10:14.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 create -f -'
Aug 24 13:10:15.354: INFO: stderr: ""
Aug 24 13:10:15.354: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 24 13:10:15.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 13:10:15.507: INFO: stderr: ""
Aug 24 13:10:15.507: INFO: stdout: "update-demo-nautilus-cldsg update-demo-nautilus-jbt94 "
Aug 24 13:10:15.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods update-demo-nautilus-cldsg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 13:10:15.631: INFO: stderr: ""
Aug 24 13:10:15.631: INFO: stdout: ""
Aug 24 13:10:15.631: INFO: update-demo-nautilus-cldsg is created but not running
Aug 24 13:10:20.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 13:10:20.795: INFO: stderr: ""
Aug 24 13:10:20.795: INFO: stdout: "update-demo-nautilus-cldsg update-demo-nautilus-jbt94 "
Aug 24 13:10:20.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods update-demo-nautilus-cldsg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 13:10:20.947: INFO: stderr: ""
Aug 24 13:10:20.947: INFO: stdout: ""
Aug 24 13:10:20.947: INFO: update-demo-nautilus-cldsg is created but not running
Aug 24 13:10:25.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 13:10:26.089: INFO: stderr: ""
Aug 24 13:10:26.089: INFO: stdout: "update-demo-nautilus-cldsg update-demo-nautilus-jbt94 "
Aug 24 13:10:26.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods update-demo-nautilus-cldsg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 13:10:26.197: INFO: stderr: ""
Aug 24 13:10:26.197: INFO: stdout: "true"
Aug 24 13:10:26.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods update-demo-nautilus-cldsg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 24 13:10:26.315: INFO: stderr: ""
Aug 24 13:10:26.315: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug 24 13:10:26.315: INFO: validating pod update-demo-nautilus-cldsg
Aug 24 13:10:26.338: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 24 13:10:26.338: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 24 13:10:26.338: INFO: update-demo-nautilus-cldsg is verified up and running
Aug 24 13:10:26.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods update-demo-nautilus-jbt94 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 13:10:26.454: INFO: stderr: ""
Aug 24 13:10:26.454: INFO: stdout: "true"
Aug 24 13:10:26.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods update-demo-nautilus-jbt94 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 24 13:10:26.560: INFO: stderr: ""
Aug 24 13:10:26.560: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug 24 13:10:26.560: INFO: validating pod update-demo-nautilus-jbt94
Aug 24 13:10:26.570: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 24 13:10:26.570: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 24 13:10:26.570: INFO: update-demo-nautilus-jbt94 is verified up and running
STEP: scaling down the replication controller
Aug 24 13:10:26.584: INFO: scanned /root for discovery docs: <nil>
Aug 24 13:10:26.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Aug 24 13:10:27.727: INFO: stderr: ""
Aug 24 13:10:27.727: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 24 13:10:27.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 13:10:27.839: INFO: stderr: ""
Aug 24 13:10:27.839: INFO: stdout: "update-demo-nautilus-cldsg update-demo-nautilus-jbt94 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 24 13:10:32.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 13:10:32.954: INFO: stderr: ""
Aug 24 13:10:32.954: INFO: stdout: "update-demo-nautilus-jbt94 "
Aug 24 13:10:32.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods update-demo-nautilus-jbt94 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 13:10:33.098: INFO: stderr: ""
Aug 24 13:10:33.098: INFO: stdout: "true"
Aug 24 13:10:33.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods update-demo-nautilus-jbt94 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 24 13:10:33.219: INFO: stderr: ""
Aug 24 13:10:33.219: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug 24 13:10:33.219: INFO: validating pod update-demo-nautilus-jbt94
Aug 24 13:10:33.230: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 24 13:10:33.230: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 24 13:10:33.231: INFO: update-demo-nautilus-jbt94 is verified up and running
STEP: scaling up the replication controller
Aug 24 13:10:33.248: INFO: scanned /root for discovery docs: <nil>
Aug 24 13:10:33.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Aug 24 13:10:34.413: INFO: stderr: ""
Aug 24 13:10:34.413: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 24 13:10:34.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 13:10:34.518: INFO: stderr: ""
Aug 24 13:10:34.519: INFO: stdout: "update-demo-nautilus-682ts update-demo-nautilus-jbt94 "
Aug 24 13:10:34.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods update-demo-nautilus-682ts -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 13:10:34.612: INFO: stderr: ""
Aug 24 13:10:34.612: INFO: stdout: ""
Aug 24 13:10:34.612: INFO: update-demo-nautilus-682ts is created but not running
Aug 24 13:10:39.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 13:10:39.745: INFO: stderr: ""
Aug 24 13:10:39.745: INFO: stdout: "update-demo-nautilus-682ts update-demo-nautilus-jbt94 "
Aug 24 13:10:39.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods update-demo-nautilus-682ts -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 13:10:39.865: INFO: stderr: ""
Aug 24 13:10:39.865: INFO: stdout: ""
Aug 24 13:10:39.865: INFO: update-demo-nautilus-682ts is created but not running
Aug 24 13:10:44.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 13:10:45.017: INFO: stderr: ""
Aug 24 13:10:45.017: INFO: stdout: "update-demo-nautilus-682ts update-demo-nautilus-jbt94 "
Aug 24 13:10:45.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods update-demo-nautilus-682ts -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 13:10:45.144: INFO: stderr: ""
Aug 24 13:10:45.144: INFO: stdout: "true"
Aug 24 13:10:45.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods update-demo-nautilus-682ts -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 24 13:10:45.269: INFO: stderr: ""
Aug 24 13:10:45.270: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug 24 13:10:45.270: INFO: validating pod update-demo-nautilus-682ts
Aug 24 13:10:45.287: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 24 13:10:45.287: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 24 13:10:45.288: INFO: update-demo-nautilus-682ts is verified up and running
Aug 24 13:10:45.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods update-demo-nautilus-jbt94 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 13:10:45.393: INFO: stderr: ""
Aug 24 13:10:45.393: INFO: stdout: "true"
Aug 24 13:10:45.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods update-demo-nautilus-jbt94 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 24 13:10:45.508: INFO: stderr: ""
Aug 24 13:10:45.508: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug 24 13:10:45.508: INFO: validating pod update-demo-nautilus-jbt94
Aug 24 13:10:45.519: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 24 13:10:45.519: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 24 13:10:45.519: INFO: update-demo-nautilus-jbt94 is verified up and running
STEP: using delete to clean up resources
Aug 24 13:10:45.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 delete --grace-period=0 --force -f -'
Aug 24 13:10:45.675: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 13:10:45.676: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 24 13:10:45.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get rc,svc -l name=update-demo --no-headers'
Aug 24 13:10:45.859: INFO: stderr: "No resources found in kubectl-8324 namespace.\n"
Aug 24 13:10:45.859: INFO: stdout: ""
Aug 24 13:10:45.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-8324 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 24 13:10:46.014: INFO: stderr: ""
Aug 24 13:10:46.014: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:10:46.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8324" for this suite.

• [SLOW TEST:31.101 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:294
    should scale a replication controller  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":346,"completed":286,"skipped":5399,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:10:46.044: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 13:10:46.094: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Aug 24 13:10:49.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2006 --namespace=crd-publish-openapi-2006 create -f -'
Aug 24 13:10:50.843: INFO: stderr: ""
Aug 24 13:10:50.843: INFO: stdout: "e2e-test-crd-publish-openapi-9030-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Aug 24 13:10:50.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2006 --namespace=crd-publish-openapi-2006 delete e2e-test-crd-publish-openapi-9030-crds test-cr'
Aug 24 13:10:51.097: INFO: stderr: ""
Aug 24 13:10:51.097: INFO: stdout: "e2e-test-crd-publish-openapi-9030-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Aug 24 13:10:51.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2006 --namespace=crd-publish-openapi-2006 apply -f -'
Aug 24 13:10:51.395: INFO: stderr: ""
Aug 24 13:10:51.395: INFO: stdout: "e2e-test-crd-publish-openapi-9030-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Aug 24 13:10:51.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2006 --namespace=crd-publish-openapi-2006 delete e2e-test-crd-publish-openapi-9030-crds test-cr'
Aug 24 13:10:51.542: INFO: stderr: ""
Aug 24 13:10:51.542: INFO: stdout: "e2e-test-crd-publish-openapi-9030-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Aug 24 13:10:51.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2006 explain e2e-test-crd-publish-openapi-9030-crds'
Aug 24 13:10:52.469: INFO: stderr: ""
Aug 24 13:10:52.469: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9030-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:10:55.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2006" for this suite.

• [SLOW TEST:9.695 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":346,"completed":287,"skipped":5402,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should validate Statefulset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:10:55.746: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-5051
[It] should validate Statefulset Status endpoints [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating statefulset ss in namespace statefulset-5051
Aug 24 13:10:55.857: INFO: Found 0 stateful pods, waiting for 1
Aug 24 13:11:05.878: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug 24 13:11:15.881: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label
STEP: Getting /status
Aug 24 13:11:15.920: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status
Aug 24 13:11:15.936: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated
Aug 24 13:11:15.940: INFO: Observed &StatefulSet event: ADDED
Aug 24 13:11:15.940: INFO: Found Statefulset ss in namespace statefulset-5051 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Aug 24 13:11:15.940: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status
Aug 24 13:11:15.940: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Aug 24 13:11:15.952: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched
Aug 24 13:11:15.958: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Aug 24 13:11:15.958: INFO: Deleting all statefulset in ns statefulset-5051
Aug 24 13:11:15.963: INFO: Scaling statefulset ss to 0
Aug 24 13:11:26.023: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 13:11:26.031: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:11:26.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5051" for this suite.

• [SLOW TEST:30.346 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should validate Statefulset Status endpoints [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","total":346,"completed":288,"skipped":5430,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:11:26.093: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should run and stop simple daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 24 13:11:26.223: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 13:11:26.223: INFO: Node zou9eicaeree-1 is running 0 daemon pod, expected 1
Aug 24 13:11:27.245: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 13:11:27.246: INFO: Node zou9eicaeree-1 is running 0 daemon pod, expected 1
Aug 24 13:11:28.244: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 13:11:28.244: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 24 13:11:28.287: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 24 13:11:28.287: INFO: Node zou9eicaeree-3 is running 0 daemon pod, expected 1
Aug 24 13:11:29.307: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 24 13:11:29.307: INFO: Node zou9eicaeree-3 is running 0 daemon pod, expected 1
Aug 24 13:11:30.306: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 24 13:11:30.307: INFO: Node zou9eicaeree-3 is running 0 daemon pod, expected 1
Aug 24 13:11:31.306: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Aug 24 13:11:31.306: INFO: Node zou9eicaeree-3 is running 0 daemon pod, expected 1
Aug 24 13:11:32.307: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 13:11:32.307: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8343, will wait for the garbage collector to delete the pods
Aug 24 13:11:32.388: INFO: Deleting DaemonSet.extensions daemon-set took: 19.559103ms
Aug 24 13:11:32.489: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.266167ms
Aug 24 13:11:34.703: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 13:11:34.703: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 24 13:11:34.707: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"44071"},"items":null}

Aug 24 13:11:34.712: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"44071"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:11:34.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8343" for this suite.

• [SLOW TEST:8.658 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":346,"completed":289,"skipped":5472,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:11:34.753: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:296
[It] should create and stop a replication controller  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a replication controller
Aug 24 13:11:34.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-381 create -f -'
Aug 24 13:11:35.122: INFO: stderr: ""
Aug 24 13:11:35.122: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 24 13:11:35.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-381 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 13:11:35.293: INFO: stderr: ""
Aug 24 13:11:35.293: INFO: stdout: "update-demo-nautilus-6k268 update-demo-nautilus-sclnz "
Aug 24 13:11:35.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-381 get pods update-demo-nautilus-6k268 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 13:11:35.434: INFO: stderr: ""
Aug 24 13:11:35.434: INFO: stdout: ""
Aug 24 13:11:35.434: INFO: update-demo-nautilus-6k268 is created but not running
Aug 24 13:11:40.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-381 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Aug 24 13:11:40.557: INFO: stderr: ""
Aug 24 13:11:40.557: INFO: stdout: "update-demo-nautilus-6k268 update-demo-nautilus-sclnz "
Aug 24 13:11:40.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-381 get pods update-demo-nautilus-6k268 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 13:11:40.686: INFO: stderr: ""
Aug 24 13:11:40.686: INFO: stdout: "true"
Aug 24 13:11:40.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-381 get pods update-demo-nautilus-6k268 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 24 13:11:40.789: INFO: stderr: ""
Aug 24 13:11:40.789: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug 24 13:11:40.789: INFO: validating pod update-demo-nautilus-6k268
Aug 24 13:11:40.810: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 24 13:11:40.810: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 24 13:11:40.810: INFO: update-demo-nautilus-6k268 is verified up and running
Aug 24 13:11:40.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-381 get pods update-demo-nautilus-sclnz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Aug 24 13:11:40.936: INFO: stderr: ""
Aug 24 13:11:40.936: INFO: stdout: "true"
Aug 24 13:11:40.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-381 get pods update-demo-nautilus-sclnz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Aug 24 13:11:41.054: INFO: stderr: ""
Aug 24 13:11:41.054: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Aug 24 13:11:41.054: INFO: validating pod update-demo-nautilus-sclnz
Aug 24 13:11:41.072: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 24 13:11:41.072: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 24 13:11:41.072: INFO: update-demo-nautilus-sclnz is verified up and running
STEP: using delete to clean up resources
Aug 24 13:11:41.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-381 delete --grace-period=0 --force -f -'
Aug 24 13:11:41.192: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 24 13:11:41.192: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 24 13:11:41.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-381 get rc,svc -l name=update-demo --no-headers'
Aug 24 13:11:41.397: INFO: stderr: "No resources found in kubectl-381 namespace.\n"
Aug 24 13:11:41.397: INFO: stdout: ""
Aug 24 13:11:41.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-381 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 24 13:11:41.549: INFO: stderr: ""
Aug 24 13:11:41.549: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:11:41.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-381" for this suite.

• [SLOW TEST:6.817 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:294
    should create and stop a replication controller  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":346,"completed":290,"skipped":5473,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should list, patch and delete a collection of StatefulSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:11:41.571: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-6433
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 13:11:41.680: INFO: Found 0 stateful pods, waiting for 1
Aug 24 13:11:51.692: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet
Aug 24 13:11:51.732: INFO: Found 1 stateful pods, waiting for 2
Aug 24 13:12:01.747: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 13:12:01.747: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets
STEP: Delete all of the StatefulSets
STEP: Verify that StatefulSets have been deleted
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Aug 24 13:12:01.791: INFO: Deleting all statefulset in ns statefulset-6433
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:12:01.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6433" for this suite.

• [SLOW TEST:20.331 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should list, patch and delete a collection of StatefulSets [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","total":346,"completed":291,"skipped":5536,"failed":0}
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:12:01.902: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Aug 24 13:12:42.239: INFO: The status of Pod kube-controller-manager-zou9eicaeree-2 is Running (Ready = true)
Aug 24 13:12:42.344: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Aug 24 13:12:42.345: INFO: Deleting pod "simpletest.rc-22k4j" in namespace "gc-4720"
Aug 24 13:12:42.403: INFO: Deleting pod "simpletest.rc-25jvr" in namespace "gc-4720"
Aug 24 13:12:42.445: INFO: Deleting pod "simpletest.rc-29wbn" in namespace "gc-4720"
Aug 24 13:12:42.477: INFO: Deleting pod "simpletest.rc-2gw62" in namespace "gc-4720"
Aug 24 13:12:42.514: INFO: Deleting pod "simpletest.rc-2jpsc" in namespace "gc-4720"
Aug 24 13:12:42.566: INFO: Deleting pod "simpletest.rc-2k9ms" in namespace "gc-4720"
Aug 24 13:12:42.604: INFO: Deleting pod "simpletest.rc-2z6dr" in namespace "gc-4720"
Aug 24 13:12:42.705: INFO: Deleting pod "simpletest.rc-49p8x" in namespace "gc-4720"
Aug 24 13:12:42.752: INFO: Deleting pod "simpletest.rc-4j6r9" in namespace "gc-4720"
Aug 24 13:12:42.790: INFO: Deleting pod "simpletest.rc-4sx7m" in namespace "gc-4720"
Aug 24 13:12:42.839: INFO: Deleting pod "simpletest.rc-529bs" in namespace "gc-4720"
Aug 24 13:12:42.887: INFO: Deleting pod "simpletest.rc-567q4" in namespace "gc-4720"
Aug 24 13:12:42.946: INFO: Deleting pod "simpletest.rc-5nd2w" in namespace "gc-4720"
Aug 24 13:12:42.999: INFO: Deleting pod "simpletest.rc-6hkvd" in namespace "gc-4720"
Aug 24 13:12:43.063: INFO: Deleting pod "simpletest.rc-6prl7" in namespace "gc-4720"
Aug 24 13:12:43.159: INFO: Deleting pod "simpletest.rc-6qdht" in namespace "gc-4720"
Aug 24 13:12:43.205: INFO: Deleting pod "simpletest.rc-6v6pn" in namespace "gc-4720"
Aug 24 13:12:43.287: INFO: Deleting pod "simpletest.rc-72h78" in namespace "gc-4720"
Aug 24 13:12:43.321: INFO: Deleting pod "simpletest.rc-72ts8" in namespace "gc-4720"
Aug 24 13:12:43.369: INFO: Deleting pod "simpletest.rc-779zm" in namespace "gc-4720"
Aug 24 13:12:43.398: INFO: Deleting pod "simpletest.rc-7rkv6" in namespace "gc-4720"
Aug 24 13:12:43.464: INFO: Deleting pod "simpletest.rc-8jpc8" in namespace "gc-4720"
Aug 24 13:12:43.497: INFO: Deleting pod "simpletest.rc-98qrz" in namespace "gc-4720"
Aug 24 13:12:43.537: INFO: Deleting pod "simpletest.rc-99j52" in namespace "gc-4720"
Aug 24 13:12:43.578: INFO: Deleting pod "simpletest.rc-9cxdx" in namespace "gc-4720"
Aug 24 13:12:43.618: INFO: Deleting pod "simpletest.rc-9jwwm" in namespace "gc-4720"
Aug 24 13:12:43.651: INFO: Deleting pod "simpletest.rc-9ns6b" in namespace "gc-4720"
Aug 24 13:12:43.701: INFO: Deleting pod "simpletest.rc-9q6xc" in namespace "gc-4720"
Aug 24 13:12:43.725: INFO: Deleting pod "simpletest.rc-b6q4s" in namespace "gc-4720"
Aug 24 13:12:43.784: INFO: Deleting pod "simpletest.rc-bbd8b" in namespace "gc-4720"
Aug 24 13:12:43.835: INFO: Deleting pod "simpletest.rc-bqf9k" in namespace "gc-4720"
Aug 24 13:12:43.874: INFO: Deleting pod "simpletest.rc-bzzqv" in namespace "gc-4720"
Aug 24 13:12:43.905: INFO: Deleting pod "simpletest.rc-c2fql" in namespace "gc-4720"
Aug 24 13:12:43.964: INFO: Deleting pod "simpletest.rc-c6q98" in namespace "gc-4720"
Aug 24 13:12:44.011: INFO: Deleting pod "simpletest.rc-cvm5h" in namespace "gc-4720"
Aug 24 13:12:44.038: INFO: Deleting pod "simpletest.rc-cvmnc" in namespace "gc-4720"
Aug 24 13:12:44.061: INFO: Deleting pod "simpletest.rc-cvx5t" in namespace "gc-4720"
Aug 24 13:12:44.106: INFO: Deleting pod "simpletest.rc-dphvs" in namespace "gc-4720"
Aug 24 13:12:44.139: INFO: Deleting pod "simpletest.rc-ds5z9" in namespace "gc-4720"
Aug 24 13:12:44.170: INFO: Deleting pod "simpletest.rc-dsr8c" in namespace "gc-4720"
Aug 24 13:12:44.219: INFO: Deleting pod "simpletest.rc-dwrrb" in namespace "gc-4720"
Aug 24 13:12:44.254: INFO: Deleting pod "simpletest.rc-fc6td" in namespace "gc-4720"
Aug 24 13:12:44.306: INFO: Deleting pod "simpletest.rc-fjc57" in namespace "gc-4720"
Aug 24 13:12:44.349: INFO: Deleting pod "simpletest.rc-fxj25" in namespace "gc-4720"
Aug 24 13:12:44.412: INFO: Deleting pod "simpletest.rc-fzwzh" in namespace "gc-4720"
Aug 24 13:12:44.494: INFO: Deleting pod "simpletest.rc-gjkwd" in namespace "gc-4720"
Aug 24 13:12:44.692: INFO: Deleting pod "simpletest.rc-gk9ll" in namespace "gc-4720"
Aug 24 13:12:44.795: INFO: Deleting pod "simpletest.rc-gkcw6" in namespace "gc-4720"
Aug 24 13:12:44.858: INFO: Deleting pod "simpletest.rc-gmhf9" in namespace "gc-4720"
Aug 24 13:12:44.896: INFO: Deleting pod "simpletest.rc-gn87f" in namespace "gc-4720"
Aug 24 13:12:44.985: INFO: Deleting pod "simpletest.rc-gplkw" in namespace "gc-4720"
Aug 24 13:12:45.022: INFO: Deleting pod "simpletest.rc-gpql6" in namespace "gc-4720"
Aug 24 13:12:45.059: INFO: Deleting pod "simpletest.rc-hc88z" in namespace "gc-4720"
Aug 24 13:12:45.279: INFO: Deleting pod "simpletest.rc-jl5sq" in namespace "gc-4720"
Aug 24 13:12:45.368: INFO: Deleting pod "simpletest.rc-jmcjx" in namespace "gc-4720"
Aug 24 13:12:45.481: INFO: Deleting pod "simpletest.rc-jrljc" in namespace "gc-4720"
Aug 24 13:12:45.554: INFO: Deleting pod "simpletest.rc-k4l9j" in namespace "gc-4720"
Aug 24 13:12:45.652: INFO: Deleting pod "simpletest.rc-klzb8" in namespace "gc-4720"
Aug 24 13:12:45.761: INFO: Deleting pod "simpletest.rc-ktzw9" in namespace "gc-4720"
Aug 24 13:12:45.832: INFO: Deleting pod "simpletest.rc-l4jlg" in namespace "gc-4720"
Aug 24 13:12:45.951: INFO: Deleting pod "simpletest.rc-m4w8t" in namespace "gc-4720"
Aug 24 13:12:46.036: INFO: Deleting pod "simpletest.rc-m8wb5" in namespace "gc-4720"
Aug 24 13:12:46.063: INFO: Deleting pod "simpletest.rc-mnvnz" in namespace "gc-4720"
Aug 24 13:12:46.139: INFO: Deleting pod "simpletest.rc-mszfj" in namespace "gc-4720"
Aug 24 13:12:46.190: INFO: Deleting pod "simpletest.rc-n7548" in namespace "gc-4720"
Aug 24 13:12:46.224: INFO: Deleting pod "simpletest.rc-ntr4m" in namespace "gc-4720"
Aug 24 13:12:46.258: INFO: Deleting pod "simpletest.rc-pbfkt" in namespace "gc-4720"
Aug 24 13:12:46.300: INFO: Deleting pod "simpletest.rc-pcj7v" in namespace "gc-4720"
Aug 24 13:12:46.349: INFO: Deleting pod "simpletest.rc-pjc6m" in namespace "gc-4720"
Aug 24 13:12:46.402: INFO: Deleting pod "simpletest.rc-prgqs" in namespace "gc-4720"
Aug 24 13:12:46.610: INFO: Deleting pod "simpletest.rc-ptm7c" in namespace "gc-4720"
Aug 24 13:12:46.753: INFO: Deleting pod "simpletest.rc-px2ls" in namespace "gc-4720"
Aug 24 13:12:46.808: INFO: Deleting pod "simpletest.rc-qcp8f" in namespace "gc-4720"
Aug 24 13:12:46.868: INFO: Deleting pod "simpletest.rc-qzwd9" in namespace "gc-4720"
Aug 24 13:12:46.919: INFO: Deleting pod "simpletest.rc-r87f7" in namespace "gc-4720"
Aug 24 13:12:47.015: INFO: Deleting pod "simpletest.rc-rdb42" in namespace "gc-4720"
Aug 24 13:12:47.073: INFO: Deleting pod "simpletest.rc-rwmhv" in namespace "gc-4720"
Aug 24 13:12:47.102: INFO: Deleting pod "simpletest.rc-rxdlk" in namespace "gc-4720"
Aug 24 13:12:47.139: INFO: Deleting pod "simpletest.rc-sh7k5" in namespace "gc-4720"
Aug 24 13:12:47.188: INFO: Deleting pod "simpletest.rc-srbhz" in namespace "gc-4720"
Aug 24 13:12:47.229: INFO: Deleting pod "simpletest.rc-sthcv" in namespace "gc-4720"
Aug 24 13:12:47.250: INFO: Deleting pod "simpletest.rc-svz6l" in namespace "gc-4720"
Aug 24 13:12:47.297: INFO: Deleting pod "simpletest.rc-swbn9" in namespace "gc-4720"
Aug 24 13:12:47.344: INFO: Deleting pod "simpletest.rc-sws2x" in namespace "gc-4720"
Aug 24 13:12:47.408: INFO: Deleting pod "simpletest.rc-tp86m" in namespace "gc-4720"
Aug 24 13:12:47.430: INFO: Deleting pod "simpletest.rc-tqk2k" in namespace "gc-4720"
Aug 24 13:12:47.465: INFO: Deleting pod "simpletest.rc-trxfb" in namespace "gc-4720"
Aug 24 13:12:47.510: INFO: Deleting pod "simpletest.rc-tzzhl" in namespace "gc-4720"
Aug 24 13:12:47.558: INFO: Deleting pod "simpletest.rc-v272m" in namespace "gc-4720"
Aug 24 13:12:47.606: INFO: Deleting pod "simpletest.rc-v64j5" in namespace "gc-4720"
Aug 24 13:12:47.706: INFO: Deleting pod "simpletest.rc-vjgjx" in namespace "gc-4720"
Aug 24 13:12:47.767: INFO: Deleting pod "simpletest.rc-w6rmm" in namespace "gc-4720"
Aug 24 13:12:47.836: INFO: Deleting pod "simpletest.rc-x75p9" in namespace "gc-4720"
Aug 24 13:12:47.881: INFO: Deleting pod "simpletest.rc-xqbmz" in namespace "gc-4720"
Aug 24 13:12:47.911: INFO: Deleting pod "simpletest.rc-xr8rx" in namespace "gc-4720"
Aug 24 13:12:47.948: INFO: Deleting pod "simpletest.rc-z2gcf" in namespace "gc-4720"
Aug 24 13:12:48.019: INFO: Deleting pod "simpletest.rc-z5cvr" in namespace "gc-4720"
Aug 24 13:12:48.042: INFO: Deleting pod "simpletest.rc-z5gc8" in namespace "gc-4720"
Aug 24 13:12:48.080: INFO: Deleting pod "simpletest.rc-zbjx2" in namespace "gc-4720"
Aug 24 13:12:48.143: INFO: Deleting pod "simpletest.rc-zsgns" in namespace "gc-4720"
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:12:48.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4720" for this suite.

• [SLOW TEST:46.308 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":346,"completed":292,"skipped":5536,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should patch a secret [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:12:48.212: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-node] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:12:48.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-749" for this suite.
•{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","total":346,"completed":293,"skipped":5583,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Lease 
  lease API should be available [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Lease
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:12:48.528: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[AfterEach] [sig-node] Lease
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:12:48.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-2242" for this suite.
•{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","total":346,"completed":294,"skipped":5597,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces 
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:12:48.869: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:69
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:12:48.911: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename disruption-2
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: listing a collection of PDBs across all namespaces
STEP: listing a collection of PDBs in namespace disruption-8887
STEP: deleting a collection of PDBs
STEP: Waiting for the PDB collection to be deleted
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:12:55.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-3659" for this suite.
[AfterEach] [sig-apps] DisruptionController
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:12:55.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8887" for this suite.

• [SLOW TEST:6.295 seconds]
[sig-apps] DisruptionController
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/disruption.go:75
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","total":346,"completed":295,"skipped":5606,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:12:55.166: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Aug 24 13:12:55.245: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
Aug 24 13:13:01.003: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:13:15.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4059" for this suite.

• [SLOW TEST:20.851 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":346,"completed":296,"skipped":5673,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:13:16.018: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 13:13:17.073: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 13:13:20.116: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:13:20.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8262" for this suite.
STEP: Destroying namespace "webhook-8262-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":346,"completed":297,"skipped":5684,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:13:20.585: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1411
STEP: creating an pod
Aug 24 13:13:20.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-5194 run logs-generator --image=k8s.gcr.io/e2e-test-images/agnhost:2.39 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Aug 24 13:13:20.772: INFO: stderr: ""
Aug 24 13:13:20.772: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Waiting for log generator to start.
Aug 24 13:13:20.772: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Aug 24 13:13:20.772: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-5194" to be "running and ready, or succeeded"
Aug 24 13:13:20.781: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 8.937695ms
Aug 24 13:13:22.795: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.023089857s
Aug 24 13:13:22.795: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Aug 24 13:13:22.795: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Aug 24 13:13:22.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-5194 logs logs-generator logs-generator'
Aug 24 13:13:23.004: INFO: stderr: ""
Aug 24 13:13:23.004: INFO: stdout: "I0824 13:13:21.524368       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/qb99 284\nI0824 13:13:21.724734       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/2wbr 263\nI0824 13:13:21.925151       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/r9s5 450\nI0824 13:13:22.124462       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/bhr 409\nI0824 13:13:22.324847       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/jjh 266\nI0824 13:13:22.525318       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/5fw 479\nI0824 13:13:22.724715       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/qs4 301\nI0824 13:13:22.924985       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/fdqm 482\n"
STEP: limiting log lines
Aug 24 13:13:23.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-5194 logs logs-generator logs-generator --tail=1'
Aug 24 13:13:23.124: INFO: stderr: ""
Aug 24 13:13:23.124: INFO: stdout: "I0824 13:13:22.924985       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/fdqm 482\n"
Aug 24 13:13:23.124: INFO: got output "I0824 13:13:22.924985       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/fdqm 482\n"
STEP: limiting log bytes
Aug 24 13:13:23.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-5194 logs logs-generator logs-generator --limit-bytes=1'
Aug 24 13:13:23.257: INFO: stderr: ""
Aug 24 13:13:23.258: INFO: stdout: "I"
Aug 24 13:13:23.258: INFO: got output "I"
STEP: exposing timestamps
Aug 24 13:13:23.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-5194 logs logs-generator logs-generator --tail=1 --timestamps'
Aug 24 13:13:23.380: INFO: stderr: ""
Aug 24 13:13:23.380: INFO: stdout: "2022-08-24T13:13:23.325015710Z I0824 13:13:23.324919       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/666h 504\n"
Aug 24 13:13:23.380: INFO: got output "2022-08-24T13:13:23.325015710Z I0824 13:13:23.324919       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/666h 504\n"
STEP: restricting to a time range
Aug 24 13:13:25.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-5194 logs logs-generator logs-generator --since=1s'
Aug 24 13:13:26.033: INFO: stderr: ""
Aug 24 13:13:26.033: INFO: stdout: "I0824 13:13:25.125221       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/dkp 580\nI0824 13:13:25.324609       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/nmf 292\nI0824 13:13:25.525117       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/xxr 236\nI0824 13:13:25.724341       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/dd62 343\nI0824 13:13:25.924832       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/ns/pods/xhx 330\n"
Aug 24 13:13:26.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-5194 logs logs-generator logs-generator --since=24h'
Aug 24 13:13:26.151: INFO: stderr: ""
Aug 24 13:13:26.151: INFO: stdout: "I0824 13:13:21.524368       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/qb99 284\nI0824 13:13:21.724734       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/2wbr 263\nI0824 13:13:21.925151       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/r9s5 450\nI0824 13:13:22.124462       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/bhr 409\nI0824 13:13:22.324847       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/jjh 266\nI0824 13:13:22.525318       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/5fw 479\nI0824 13:13:22.724715       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/qs4 301\nI0824 13:13:22.924985       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/fdqm 482\nI0824 13:13:23.124635       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/tp8z 364\nI0824 13:13:23.324919       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/666h 504\nI0824 13:13:23.524393       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/mgr 439\nI0824 13:13:23.724850       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/ttf 386\nI0824 13:13:23.925044       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/zgb4 219\nI0824 13:13:24.124350       1 logs_generator.go:76] 13 GET /api/v1/namespaces/default/pods/f7m 253\nI0824 13:13:24.325817       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/4sg 573\nI0824 13:13:24.525218       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/8vrp 266\nI0824 13:13:24.724482       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/zqnk 323\nI0824 13:13:24.924900       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/mrn 565\nI0824 13:13:25.125221       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/dkp 580\nI0824 13:13:25.324609       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/nmf 292\nI0824 13:13:25.525117       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/xxr 236\nI0824 13:13:25.724341       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/dd62 343\nI0824 13:13:25.924832       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/ns/pods/xhx 330\nI0824 13:13:26.126400       1 logs_generator.go:76] 23 GET /api/v1/namespaces/default/pods/phv 421\n"
[AfterEach] Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1416
Aug 24 13:13:26.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-5194 delete pod logs-generator'
Aug 24 13:13:26.701: INFO: stderr: ""
Aug 24 13:13:26.701: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:13:26.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5194" for this suite.

• [SLOW TEST:6.134 seconds]
[sig-cli] Kubectl client
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1408
    should be able to retrieve and filter logs  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":346,"completed":298,"skipped":5717,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:13:26.719: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward api env vars
Aug 24 13:13:26.771: INFO: Waiting up to 5m0s for pod "downward-api-1114384e-698e-4b78-9563-e08646317a0a" in namespace "downward-api-7183" to be "Succeeded or Failed"
Aug 24 13:13:26.777: INFO: Pod "downward-api-1114384e-698e-4b78-9563-e08646317a0a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.980625ms
Aug 24 13:13:28.792: INFO: Pod "downward-api-1114384e-698e-4b78-9563-e08646317a0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020274039s
Aug 24 13:13:30.805: INFO: Pod "downward-api-1114384e-698e-4b78-9563-e08646317a0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034054137s
STEP: Saw pod success
Aug 24 13:13:30.806: INFO: Pod "downward-api-1114384e-698e-4b78-9563-e08646317a0a" satisfied condition "Succeeded or Failed"
Aug 24 13:13:30.811: INFO: Trying to get logs from node zou9eicaeree-3 pod downward-api-1114384e-698e-4b78-9563-e08646317a0a container dapi-container: <nil>
STEP: delete the pod
Aug 24 13:13:30.839: INFO: Waiting for pod downward-api-1114384e-698e-4b78-9563-e08646317a0a to disappear
Aug 24 13:13:30.845: INFO: Pod downward-api-1114384e-698e-4b78-9563-e08646317a0a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:13:30.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7183" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":346,"completed":299,"skipped":5742,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:13:30.866: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating pod busybox-5f1e6657-2c60-43fe-9cb9-b8928b3a0b60 in namespace container-probe-7545
Aug 24 13:13:32.950: INFO: Started pod busybox-5f1e6657-2c60-43fe-9cb9-b8928b3a0b60 in namespace container-probe-7545
STEP: checking the pod's current state and verifying that restartCount is present
Aug 24 13:13:32.955: INFO: Initial restart count of pod busybox-5f1e6657-2c60-43fe-9cb9-b8928b3a0b60 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:17:34.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7545" for this suite.

• [SLOW TEST:243.975 seconds]
[sig-node] Probing container
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":346,"completed":300,"skipped":5752,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:17:34.847: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: referencing a single matching pod
STEP: referencing matching pods with named port
STEP: creating empty Endpoints and EndpointSlices for no matching Pods
STEP: recreating EndpointSlices after they've been deleted
Aug 24 13:17:55.255: INFO: EndpointSlice for Service endpointslice-2148/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:18:05.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-2148" for this suite.

• [SLOW TEST:30.471 seconds]
[sig-network] EndpointSlice
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","total":346,"completed":301,"skipped":5838,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:18:05.326: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating secret with name secret-test-771f4395-ce33-4f67-bab0-6c3da49294a2
STEP: Creating a pod to test consume secrets
Aug 24 13:18:05.393: INFO: Waiting up to 5m0s for pod "pod-secrets-83e3bb7e-5cce-4012-bb97-694f4d557fb6" in namespace "secrets-4000" to be "Succeeded or Failed"
Aug 24 13:18:05.401: INFO: Pod "pod-secrets-83e3bb7e-5cce-4012-bb97-694f4d557fb6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.909488ms
Aug 24 13:18:07.416: INFO: Pod "pod-secrets-83e3bb7e-5cce-4012-bb97-694f4d557fb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022685501s
Aug 24 13:18:09.430: INFO: Pod "pod-secrets-83e3bb7e-5cce-4012-bb97-694f4d557fb6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036819241s
STEP: Saw pod success
Aug 24 13:18:09.430: INFO: Pod "pod-secrets-83e3bb7e-5cce-4012-bb97-694f4d557fb6" satisfied condition "Succeeded or Failed"
Aug 24 13:18:09.435: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-secrets-83e3bb7e-5cce-4012-bb97-694f4d557fb6 container secret-volume-test: <nil>
STEP: delete the pod
Aug 24 13:18:09.482: INFO: Waiting for pod pod-secrets-83e3bb7e-5cce-4012-bb97-694f4d557fb6 to disappear
Aug 24 13:18:09.487: INFO: Pod pod-secrets-83e3bb7e-5cce-4012-bb97-694f4d557fb6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:18:09.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4000" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":346,"completed":302,"skipped":5886,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:18:09.506: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 13:18:09.550: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Aug 24 13:18:13.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2266 --namespace=crd-publish-openapi-2266 create -f -'
Aug 24 13:18:14.775: INFO: stderr: ""
Aug 24 13:18:14.775: INFO: stdout: "e2e-test-crd-publish-openapi-5543-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Aug 24 13:18:14.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2266 --namespace=crd-publish-openapi-2266 delete e2e-test-crd-publish-openapi-5543-crds test-foo'
Aug 24 13:18:15.041: INFO: stderr: ""
Aug 24 13:18:15.041: INFO: stdout: "e2e-test-crd-publish-openapi-5543-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Aug 24 13:18:15.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2266 --namespace=crd-publish-openapi-2266 apply -f -'
Aug 24 13:18:15.860: INFO: stderr: ""
Aug 24 13:18:15.860: INFO: stdout: "e2e-test-crd-publish-openapi-5543-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Aug 24 13:18:15.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2266 --namespace=crd-publish-openapi-2266 delete e2e-test-crd-publish-openapi-5543-crds test-foo'
Aug 24 13:18:15.985: INFO: stderr: ""
Aug 24 13:18:15.985: INFO: stdout: "e2e-test-crd-publish-openapi-5543-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with value outside defined enum values
Aug 24 13:18:15.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2266 --namespace=crd-publish-openapi-2266 create -f -'
Aug 24 13:18:16.299: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Aug 24 13:18:16.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2266 --namespace=crd-publish-openapi-2266 create -f -'
Aug 24 13:18:16.613: INFO: rc: 1
Aug 24 13:18:16.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2266 --namespace=crd-publish-openapi-2266 apply -f -'
Aug 24 13:18:16.951: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Aug 24 13:18:16.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2266 --namespace=crd-publish-openapi-2266 create -f -'
Aug 24 13:18:17.279: INFO: rc: 1
Aug 24 13:18:17.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2266 --namespace=crd-publish-openapi-2266 apply -f -'
Aug 24 13:18:17.548: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Aug 24 13:18:17.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2266 explain e2e-test-crd-publish-openapi-5543-crds'
Aug 24 13:18:17.812: INFO: stderr: ""
Aug 24 13:18:17.812: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5543-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Aug 24 13:18:17.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2266 explain e2e-test-crd-publish-openapi-5543-crds.metadata'
Aug 24 13:18:18.081: INFO: stderr: ""
Aug 24 13:18:18.081: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5543-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     NOT return a 409 - instead, it will either return 201 Created or 500 with\n     Reason ServerTimeout indicating a unique name could not be found in the\n     time allotted, and the client should retry (optionally after the time\n     indicated in the Retry-After header).\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only.\n\n     DEPRECATED Kubernetes will stop propagating this field in 1.20 release and\n     the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Aug 24 13:18:18.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2266 explain e2e-test-crd-publish-openapi-5543-crds.spec'
Aug 24 13:18:18.435: INFO: stderr: ""
Aug 24 13:18:18.435: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5543-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Aug 24 13:18:18.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2266 explain e2e-test-crd-publish-openapi-5543-crds.spec.bars'
Aug 24 13:18:18.766: INFO: stderr: ""
Aug 24 13:18:18.766: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5543-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Aug 24 13:18:18.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=crd-publish-openapi-2266 explain e2e-test-crd-publish-openapi-5543-crds.spec.bars2'
Aug 24 13:18:19.062: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:18:23.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2266" for this suite.

• [SLOW TEST:14.420 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":346,"completed":303,"skipped":5897,"failed":0}
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:18:23.929: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 13:18:23.998: INFO: Waiting up to 5m0s for pod "downwardapi-volume-55d9ffd1-6121-452c-9fb0-eff464d06d8a" in namespace "downward-api-5166" to be "Succeeded or Failed"
Aug 24 13:18:24.002: INFO: Pod "downwardapi-volume-55d9ffd1-6121-452c-9fb0-eff464d06d8a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.998393ms
Aug 24 13:18:26.013: INFO: Pod "downwardapi-volume-55d9ffd1-6121-452c-9fb0-eff464d06d8a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014582212s
Aug 24 13:18:28.029: INFO: Pod "downwardapi-volume-55d9ffd1-6121-452c-9fb0-eff464d06d8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030799224s
STEP: Saw pod success
Aug 24 13:18:28.029: INFO: Pod "downwardapi-volume-55d9ffd1-6121-452c-9fb0-eff464d06d8a" satisfied condition "Succeeded or Failed"
Aug 24 13:18:28.035: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-55d9ffd1-6121-452c-9fb0-eff464d06d8a container client-container: <nil>
STEP: delete the pod
Aug 24 13:18:28.079: INFO: Waiting for pod downwardapi-volume-55d9ffd1-6121-452c-9fb0-eff464d06d8a to disappear
Aug 24 13:18:28.087: INFO: Pod downwardapi-volume-55d9ffd1-6121-452c-9fb0-eff464d06d8a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:18:28.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5166" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":346,"completed":304,"skipped":5903,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:18:28.109: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating service in namespace services-5704
STEP: creating service affinity-clusterip in namespace services-5704
STEP: creating replication controller affinity-clusterip in namespace services-5704
I0824 13:18:28.215210      16 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-5704, replica count: 3
I0824 13:18:31.266646      16 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 13:18:31.286: INFO: Creating new exec pod
Aug 24 13:18:34.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-5704 exec execpod-affinity8kxrn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Aug 24 13:18:34.665: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Aug 24 13:18:34.665: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 13:18:34.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-5704 exec execpod-affinity8kxrn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.2.49 80'
Aug 24 13:18:34.896: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.2.49 80\nConnection to 10.233.2.49 80 port [tcp/http] succeeded!\n"
Aug 24 13:18:34.896: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 13:18:34.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-5704 exec execpod-affinity8kxrn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.2.49:80/ ; done'
Aug 24 13:18:35.354: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.2.49:80/\n"
Aug 24 13:18:35.354: INFO: stdout: "\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz\naffinity-clusterip-d85cz"
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Received response from host: affinity-clusterip-d85cz
Aug 24 13:18:35.354: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-5704, will wait for the garbage collector to delete the pods
Aug 24 13:18:35.495: INFO: Deleting ReplicationController affinity-clusterip took: 17.301115ms
Aug 24 13:18:35.696: INFO: Terminating ReplicationController affinity-clusterip pods took: 200.475171ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:18:37.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5704" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756

• [SLOW TEST:9.767 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","total":346,"completed":305,"skipped":5922,"failed":0}
S
------------------------------
[sig-network] Services 
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:18:37.878: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating service in namespace services-7747
STEP: creating service affinity-nodeport-transition in namespace services-7747
STEP: creating replication controller affinity-nodeport-transition in namespace services-7747
I0824 13:18:37.989249      16 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-7747, replica count: 3
I0824 13:18:41.041372      16 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 13:18:41.072: INFO: Creating new exec pod
Aug 24 13:18:44.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-7747 exec execpod-affinity9nvcc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Aug 24 13:18:44.353: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Aug 24 13:18:44.353: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 13:18:44.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-7747 exec execpod-affinity9nvcc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.14.184 80'
Aug 24 13:18:44.557: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.14.184 80\nConnection to 10.233.14.184 80 port [tcp/http] succeeded!\n"
Aug 24 13:18:44.557: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 13:18:44.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-7747 exec execpod-affinity9nvcc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.241 30651'
Aug 24 13:18:44.761: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.241 30651\nConnection to 192.168.121.241 30651 port [tcp/*] succeeded!\n"
Aug 24 13:18:44.761: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 13:18:44.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-7747 exec execpod-affinity9nvcc -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.121.108 30651'
Aug 24 13:18:44.958: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.121.108 30651\nConnection to 192.168.121.108 30651 port [tcp/*] succeeded!\n"
Aug 24 13:18:44.958: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 13:18:44.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-7747 exec execpod-affinity9nvcc -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.241:30651/ ; done'
Aug 24 13:18:45.419: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n"
Aug 24 13:18:45.419: INFO: stdout: "\naffinity-nodeport-transition-sht97\naffinity-nodeport-transition-sht97\naffinity-nodeport-transition-sht97\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-sht97\naffinity-nodeport-transition-sht97\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-hzswl\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-hzswl\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-hzswl\naffinity-nodeport-transition-sht97\naffinity-nodeport-transition-hzswl"
Aug 24 13:18:45.419: INFO: Received response from host: affinity-nodeport-transition-sht97
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-sht97
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-sht97
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-sht97
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-sht97
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-hzswl
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-hzswl
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-hzswl
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-sht97
Aug 24 13:18:45.420: INFO: Received response from host: affinity-nodeport-transition-hzswl
Aug 24 13:18:45.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-7747 exec execpod-affinity9nvcc -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.121.241:30651/ ; done'
Aug 24 13:18:45.852: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.121.241:30651/\n"
Aug 24 13:18:45.852: INFO: stdout: "\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f\naffinity-nodeport-transition-vxl2f"
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Received response from host: affinity-nodeport-transition-vxl2f
Aug 24 13:18:45.852: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-7747, will wait for the garbage collector to delete the pods
Aug 24 13:18:45.952: INFO: Deleting ReplicationController affinity-nodeport-transition took: 10.798403ms
Aug 24 13:18:46.053: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.683268ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:18:48.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7747" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756

• [SLOW TEST:10.379 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","total":346,"completed":306,"skipped":5923,"failed":0}
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should verify changes to a daemon set status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:18:48.258: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:143
[It] should verify changes to a daemon set status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 24 13:18:48.415: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 13:18:48.415: INFO: Node zou9eicaeree-1 is running 0 daemon pod, expected 1
Aug 24 13:18:49.440: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 13:18:49.440: INFO: Node zou9eicaeree-1 is running 0 daemon pod, expected 1
Aug 24 13:18:50.435: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Aug 24 13:18:50.435: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status
Aug 24 13:18:50.447: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status
Aug 24 13:18:50.463: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated
Aug 24 13:18:50.468: INFO: Observed &DaemonSet event: ADDED
Aug 24 13:18:50.468: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 13:18:50.468: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 13:18:50.469: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 13:18:50.469: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 13:18:50.470: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 13:18:50.470: INFO: Found daemon set daemon-set in namespace daemonsets-5766 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 24 13:18:50.470: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status
STEP: watching for the daemon set status to be patched
Aug 24 13:18:50.488: INFO: Observed &DaemonSet event: ADDED
Aug 24 13:18:50.489: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 13:18:50.489: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 13:18:50.490: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 13:18:50.491: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 13:18:50.492: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 13:18:50.492: INFO: Observed daemon set daemon-set in namespace daemonsets-5766 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Aug 24 13:18:50.493: INFO: Observed &DaemonSet event: MODIFIED
Aug 24 13:18:50.493: INFO: Found daemon set daemon-set in namespace daemonsets-5766 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Aug 24 13:18:50.494: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:109
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5766, will wait for the garbage collector to delete the pods
Aug 24 13:18:50.577: INFO: Deleting DaemonSet.extensions daemon-set took: 12.844748ms
Aug 24 13:18:50.678: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.090236ms
Aug 24 13:18:53.198: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Aug 24 13:18:53.198: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Aug 24 13:18:53.252: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"47416"},"items":null}

Aug 24 13:18:53.259: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"47416"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:18:53.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5766" for this suite.

• [SLOW TEST:5.059 seconds]
[sig-apps] Daemon set [Serial]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","total":346,"completed":307,"skipped":5925,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:18:53.322: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating pod pod-subpath-test-secret-pfp4
STEP: Creating a pod to test atomic-volume-subpath
Aug 24 13:18:53.401: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-pfp4" in namespace "subpath-2083" to be "Succeeded or Failed"
Aug 24 13:18:53.406: INFO: Pod "pod-subpath-test-secret-pfp4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.602747ms
Aug 24 13:18:55.416: INFO: Pod "pod-subpath-test-secret-pfp4": Phase="Running", Reason="", readiness=true. Elapsed: 2.014347375s
Aug 24 13:18:57.431: INFO: Pod "pod-subpath-test-secret-pfp4": Phase="Running", Reason="", readiness=true. Elapsed: 4.02999941s
Aug 24 13:18:59.450: INFO: Pod "pod-subpath-test-secret-pfp4": Phase="Running", Reason="", readiness=true. Elapsed: 6.049089189s
Aug 24 13:19:01.466: INFO: Pod "pod-subpath-test-secret-pfp4": Phase="Running", Reason="", readiness=true. Elapsed: 8.064497959s
Aug 24 13:19:03.480: INFO: Pod "pod-subpath-test-secret-pfp4": Phase="Running", Reason="", readiness=true. Elapsed: 10.079047324s
Aug 24 13:19:05.492: INFO: Pod "pod-subpath-test-secret-pfp4": Phase="Running", Reason="", readiness=true. Elapsed: 12.090509421s
Aug 24 13:19:07.508: INFO: Pod "pod-subpath-test-secret-pfp4": Phase="Running", Reason="", readiness=true. Elapsed: 14.106288613s
Aug 24 13:19:09.524: INFO: Pod "pod-subpath-test-secret-pfp4": Phase="Running", Reason="", readiness=true. Elapsed: 16.122278944s
Aug 24 13:19:11.537: INFO: Pod "pod-subpath-test-secret-pfp4": Phase="Running", Reason="", readiness=true. Elapsed: 18.13583463s
Aug 24 13:19:13.552: INFO: Pod "pod-subpath-test-secret-pfp4": Phase="Running", Reason="", readiness=true. Elapsed: 20.151044859s
Aug 24 13:19:15.572: INFO: Pod "pod-subpath-test-secret-pfp4": Phase="Running", Reason="", readiness=false. Elapsed: 22.170711215s
Aug 24 13:19:17.588: INFO: Pod "pod-subpath-test-secret-pfp4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.187143098s
STEP: Saw pod success
Aug 24 13:19:17.589: INFO: Pod "pod-subpath-test-secret-pfp4" satisfied condition "Succeeded or Failed"
Aug 24 13:19:17.603: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-subpath-test-secret-pfp4 container test-container-subpath-secret-pfp4: <nil>
STEP: delete the pod
Aug 24 13:19:17.645: INFO: Waiting for pod pod-subpath-test-secret-pfp4 to disappear
Aug 24 13:19:17.651: INFO: Pod pod-subpath-test-secret-pfp4 no longer exists
STEP: Deleting pod pod-subpath-test-secret-pfp4
Aug 24 13:19:17.652: INFO: Deleting pod "pod-subpath-test-secret-pfp4" in namespace "subpath-2083"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:19:17.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2083" for this suite.

• [SLOW TEST:24.357 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Excluded:WindowsDocker] [Conformance]","total":346,"completed":308,"skipped":5939,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:19:17.681: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-5185, will wait for the garbage collector to delete the pods
Aug 24 13:19:19.833: INFO: Deleting Job.batch foo took: 17.013881ms
Aug 24 13:19:19.934: INFO: Terminating Job.batch foo pods took: 100.784915ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:19:52.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5185" for this suite.

• [SLOW TEST:34.507 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":346,"completed":309,"skipped":5976,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  Deployment should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:19:52.195: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:89
[It] Deployment should have a working scale subresource [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 13:19:52.251: INFO: Creating simple deployment test-new-deployment
Aug 24 13:19:52.286: INFO: new replicaset for deployment "test-new-deployment" is yet to be created
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the deployment Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:83
Aug 24 13:19:54.417: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-5319  38ea9477-679b-4ab3-9015-2533452fcc57 47656 3 2022-08-24 13:19:52 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-08-24 13:19:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 13:19:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc008b0ac88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-08-24 13:19:54 +0000 UTC,LastTransitionTime:2022-08-24 13:19:54 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-5d9fdcc779" has successfully progressed.,LastUpdateTime:2022-08-24 13:19:54 +0000 UTC,LastTransitionTime:2022-08-24 13:19:52 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Aug 24 13:19:54.471: INFO: New ReplicaSet "test-new-deployment-5d9fdcc779" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-5d9fdcc779  deployment-5319  660d5314-df00-4909-9e4b-512281a1ae57 47659 3 2022-08-24 13:19:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 38ea9477-679b-4ab3-9015-2533452fcc57 0xc008b0b087 0xc008b0b088}] []  [{kube-controller-manager Update apps/v1 2022-08-24 13:19:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"38ea9477-679b-4ab3-9015-2533452fcc57\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-08-24 13:19:54 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 5d9fdcc779,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc008b0b118 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Aug 24 13:19:54.505: INFO: Pod "test-new-deployment-5d9fdcc779-j8hfj" is available:
&Pod{ObjectMeta:{test-new-deployment-5d9fdcc779-j8hfj test-new-deployment-5d9fdcc779- deployment-5319  161c82ed-1106-49a4-a5be-a81b025c354c 47651 0 2022-08-24 13:19:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet test-new-deployment-5d9fdcc779 660d5314-df00-4909-9e4b-512281a1ae57 0xc008a71807 0xc008a71808}] []  [{kube-controller-manager Update v1 2022-08-24 13:19:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"660d5314-df00-4909-9e4b-512281a1ae57\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 13:19:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.66.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rfp2v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rfp2v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 13:19:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 13:19:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 13:19:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 13:19:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.108,PodIP:10.233.66.18,StartTime:2022-08-24 13:19:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-08-24 13:19:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:cri-o://ddd9bcfb54453e3bc21ce4a5bd48615e1330c32aa7140ad0898a3c0bad4e4bce,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.66.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Aug 24 13:19:54.506: INFO: Pod "test-new-deployment-5d9fdcc779-rswwj" is not available:
&Pod{ObjectMeta:{test-new-deployment-5d9fdcc779-rswwj test-new-deployment-5d9fdcc779- deployment-5319  1dc561a4-dad8-4a04-82b4-60863ab98d3a 47665 0 2022-08-24 13:19:54 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5d9fdcc779] map[] [{apps/v1 ReplicaSet test-new-deployment-5d9fdcc779 660d5314-df00-4909-9e4b-512281a1ae57 0xc008a719f7 0xc008a719f8}] []  [{kube-controller-manager Update v1 2022-08-24 13:19:54 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"660d5314-df00-4909-9e4b-512281a1ae57\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-08-24 13:19:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2h5ch,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2h5ch,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:zou9eicaeree-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 13:19:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 13:19:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 13:19:54 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-08-24 13:19:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.121.241,PodIP:,StartTime:2022-08-24 13:19:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:19:54.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5319" for this suite.
•{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","total":346,"completed":310,"skipped":6012,"failed":0}
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:19:54.532: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Given a Pod with a 'name' label pod-adoption-release is created
Aug 24 13:19:54.675: INFO: The status of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Aug 24 13:19:56.686: INFO: The status of Pod pod-adoption-release is Running (Ready = true)
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug 24 13:19:57.748: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:19:58.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2287" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":346,"completed":311,"skipped":6017,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:19:58.835: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Aug 24 13:20:00.069: INFO: The status of Pod kube-controller-manager-zou9eicaeree-2 is Running (Ready = true)
Aug 24 13:20:00.186: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:20:00.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3303" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":346,"completed":312,"skipped":6033,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:20:00.213: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 13:20:01.945: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 13:20:05.000: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 13:20:05.011: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7656-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:20:08.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7236" for this suite.
STEP: Destroying namespace "webhook-7236-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.726 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":346,"completed":313,"skipped":6041,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:20:08.941: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:94
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:109
STEP: Creating service test in namespace statefulset-8412
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a new StatefulSet
Aug 24 13:20:09.071: INFO: Found 0 stateful pods, waiting for 3
Aug 24 13:20:19.097: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 13:20:19.097: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 13:20:19.097: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Aug 24 13:20:19.148: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 24 13:20:29.220: INFO: Updating stateful set ss2
Aug 24 13:20:29.241: INFO: Waiting for Pod statefulset-8412/ss2-2 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
STEP: Restoring Pods to the correct revision when they are deleted
Aug 24 13:20:39.381: INFO: Found 1 stateful pods, waiting for 3
Aug 24 13:20:49.401: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 13:20:49.401: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 24 13:20:49.401: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 24 13:20:49.444: INFO: Updating stateful set ss2
Aug 24 13:20:49.459: INFO: Waiting for Pod statefulset-8412/ss2-1 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
Aug 24 13:20:59.514: INFO: Updating stateful set ss2
Aug 24 13:20:59.526: INFO: Waiting for StatefulSet statefulset-8412/ss2 to complete update
Aug 24 13:20:59.526: INFO: Waiting for Pod statefulset-8412/ss2-0 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:120
Aug 24 13:21:09.553: INFO: Deleting all statefulset in ns statefulset-8412
Aug 24 13:21:09.558: INFO: Scaling statefulset ss2 to 0
Aug 24 13:21:19.600: INFO: Waiting for statefulset status.replicas updated to 0
Aug 24 13:21:19.606: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:21:19.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8412" for this suite.

• [SLOW TEST:70.732 seconds]
[sig-apps] StatefulSet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":346,"completed":314,"skipped":6058,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:21:19.678: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:53
STEP: create the container to handle the HTTPGet hook request.
Aug 24 13:21:19.769: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Aug 24 13:21:21.783: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create the pod with lifecycle hook
Aug 24 13:21:21.826: INFO: The status of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Aug 24 13:21:23.838: INFO: The status of Pod pod-with-poststart-exec-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 24 13:21:23.873: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 24 13:21:23.881: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 24 13:21:25.881: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 24 13:21:25.897: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 24 13:21:27.881: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 24 13:21:27.893: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:21:27.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5550" for this suite.

• [SLOW TEST:8.240 seconds]
[sig-node] Container Lifecycle Hook
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:44
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":346,"completed":315,"skipped":6084,"failed":0}
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:21:27.918: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
Aug 24 13:21:40.435: INFO: 69 pods remaining
Aug 24 13:21:40.447: INFO: 69 pods has nil DeletionTimestamp
Aug 24 13:21:40.447: INFO: 
STEP: Gathering metrics
Aug 24 13:21:45.527: INFO: The status of Pod kube-controller-manager-zou9eicaeree-2 is Running (Ready = true)
Aug 24 13:21:45.689: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Aug 24 13:21:45.689: INFO: Deleting pod "simpletest-rc-to-be-deleted-24rq5" in namespace "gc-6750"
Aug 24 13:21:45.726: INFO: Deleting pod "simpletest-rc-to-be-deleted-28828" in namespace "gc-6750"
Aug 24 13:21:45.777: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hfjw" in namespace "gc-6750"
Aug 24 13:21:45.834: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hl76" in namespace "gc-6750"
Aug 24 13:21:45.857: INFO: Deleting pod "simpletest-rc-to-be-deleted-2kfzs" in namespace "gc-6750"
Aug 24 13:21:45.881: INFO: Deleting pod "simpletest-rc-to-be-deleted-468bf" in namespace "gc-6750"
Aug 24 13:21:45.915: INFO: Deleting pod "simpletest-rc-to-be-deleted-498jv" in namespace "gc-6750"
Aug 24 13:21:46.000: INFO: Deleting pod "simpletest-rc-to-be-deleted-4t4lm" in namespace "gc-6750"
Aug 24 13:21:46.080: INFO: Deleting pod "simpletest-rc-to-be-deleted-52hbx" in namespace "gc-6750"
Aug 24 13:21:46.127: INFO: Deleting pod "simpletest-rc-to-be-deleted-55d5w" in namespace "gc-6750"
Aug 24 13:21:46.155: INFO: Deleting pod "simpletest-rc-to-be-deleted-5h6wg" in namespace "gc-6750"
Aug 24 13:21:46.192: INFO: Deleting pod "simpletest-rc-to-be-deleted-5n44b" in namespace "gc-6750"
Aug 24 13:21:46.243: INFO: Deleting pod "simpletest-rc-to-be-deleted-64mfj" in namespace "gc-6750"
Aug 24 13:21:46.378: INFO: Deleting pod "simpletest-rc-to-be-deleted-69w2k" in namespace "gc-6750"
Aug 24 13:21:46.429: INFO: Deleting pod "simpletest-rc-to-be-deleted-6kmhs" in namespace "gc-6750"
Aug 24 13:21:46.472: INFO: Deleting pod "simpletest-rc-to-be-deleted-6vjwk" in namespace "gc-6750"
Aug 24 13:21:46.549: INFO: Deleting pod "simpletest-rc-to-be-deleted-7rhcz" in namespace "gc-6750"
Aug 24 13:21:46.586: INFO: Deleting pod "simpletest-rc-to-be-deleted-7rn45" in namespace "gc-6750"
Aug 24 13:21:46.649: INFO: Deleting pod "simpletest-rc-to-be-deleted-7wqcl" in namespace "gc-6750"
Aug 24 13:21:46.719: INFO: Deleting pod "simpletest-rc-to-be-deleted-7x6jk" in namespace "gc-6750"
Aug 24 13:21:46.749: INFO: Deleting pod "simpletest-rc-to-be-deleted-86krh" in namespace "gc-6750"
Aug 24 13:21:46.773: INFO: Deleting pod "simpletest-rc-to-be-deleted-87hz4" in namespace "gc-6750"
Aug 24 13:21:46.807: INFO: Deleting pod "simpletest-rc-to-be-deleted-8t8bw" in namespace "gc-6750"
Aug 24 13:21:46.906: INFO: Deleting pod "simpletest-rc-to-be-deleted-966jp" in namespace "gc-6750"
Aug 24 13:21:46.934: INFO: Deleting pod "simpletest-rc-to-be-deleted-97fj8" in namespace "gc-6750"
Aug 24 13:21:46.961: INFO: Deleting pod "simpletest-rc-to-be-deleted-9z7rc" in namespace "gc-6750"
Aug 24 13:21:46.988: INFO: Deleting pod "simpletest-rc-to-be-deleted-bq5nf" in namespace "gc-6750"
Aug 24 13:21:47.061: INFO: Deleting pod "simpletest-rc-to-be-deleted-cg4sg" in namespace "gc-6750"
Aug 24 13:21:47.115: INFO: Deleting pod "simpletest-rc-to-be-deleted-cl9xh" in namespace "gc-6750"
Aug 24 13:21:47.191: INFO: Deleting pod "simpletest-rc-to-be-deleted-cmt8c" in namespace "gc-6750"
Aug 24 13:21:47.243: INFO: Deleting pod "simpletest-rc-to-be-deleted-csl9g" in namespace "gc-6750"
Aug 24 13:21:47.278: INFO: Deleting pod "simpletest-rc-to-be-deleted-d74zb" in namespace "gc-6750"
Aug 24 13:21:47.367: INFO: Deleting pod "simpletest-rc-to-be-deleted-d8jsr" in namespace "gc-6750"
Aug 24 13:21:47.405: INFO: Deleting pod "simpletest-rc-to-be-deleted-dc2h4" in namespace "gc-6750"
Aug 24 13:21:47.434: INFO: Deleting pod "simpletest-rc-to-be-deleted-dccgd" in namespace "gc-6750"
Aug 24 13:21:47.516: INFO: Deleting pod "simpletest-rc-to-be-deleted-dpbgg" in namespace "gc-6750"
Aug 24 13:21:47.550: INFO: Deleting pod "simpletest-rc-to-be-deleted-dq6pq" in namespace "gc-6750"
Aug 24 13:21:47.592: INFO: Deleting pod "simpletest-rc-to-be-deleted-f54ct" in namespace "gc-6750"
Aug 24 13:21:47.625: INFO: Deleting pod "simpletest-rc-to-be-deleted-fbt8l" in namespace "gc-6750"
Aug 24 13:21:47.652: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjxk2" in namespace "gc-6750"
Aug 24 13:21:47.675: INFO: Deleting pod "simpletest-rc-to-be-deleted-flgq8" in namespace "gc-6750"
Aug 24 13:21:47.713: INFO: Deleting pod "simpletest-rc-to-be-deleted-fq6lf" in namespace "gc-6750"
Aug 24 13:21:47.771: INFO: Deleting pod "simpletest-rc-to-be-deleted-ftbtf" in namespace "gc-6750"
Aug 24 13:21:47.804: INFO: Deleting pod "simpletest-rc-to-be-deleted-fv78j" in namespace "gc-6750"
Aug 24 13:21:47.850: INFO: Deleting pod "simpletest-rc-to-be-deleted-g68tg" in namespace "gc-6750"
Aug 24 13:21:47.888: INFO: Deleting pod "simpletest-rc-to-be-deleted-gptcl" in namespace "gc-6750"
Aug 24 13:21:47.919: INFO: Deleting pod "simpletest-rc-to-be-deleted-gwx6k" in namespace "gc-6750"
Aug 24 13:21:47.950: INFO: Deleting pod "simpletest-rc-to-be-deleted-j26zh" in namespace "gc-6750"
Aug 24 13:21:47.988: INFO: Deleting pod "simpletest-rc-to-be-deleted-jbnqs" in namespace "gc-6750"
Aug 24 13:21:48.008: INFO: Deleting pod "simpletest-rc-to-be-deleted-jfgf9" in namespace "gc-6750"
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:21:48.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6750" for this suite.

• [SLOW TEST:20.155 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":346,"completed":316,"skipped":6086,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:21:48.076: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[AfterEach] [sig-storage] ConfigMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:21:48.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7964" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","total":346,"completed":317,"skipped":6120,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:21:48.377: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating projection with secret that has name projected-secret-test-map-24c7989d-0926-4c26-b352-9d8b15e13899
STEP: Creating a pod to test consume secrets
Aug 24 13:21:48.471: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-77a09292-ffe5-4554-9a07-90f8b83c2e1d" in namespace "projected-456" to be "Succeeded or Failed"
Aug 24 13:21:48.478: INFO: Pod "pod-projected-secrets-77a09292-ffe5-4554-9a07-90f8b83c2e1d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.355386ms
Aug 24 13:21:50.494: INFO: Pod "pod-projected-secrets-77a09292-ffe5-4554-9a07-90f8b83c2e1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02294768s
Aug 24 13:21:52.515: INFO: Pod "pod-projected-secrets-77a09292-ffe5-4554-9a07-90f8b83c2e1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043889667s
STEP: Saw pod success
Aug 24 13:21:52.515: INFO: Pod "pod-projected-secrets-77a09292-ffe5-4554-9a07-90f8b83c2e1d" satisfied condition "Succeeded or Failed"
Aug 24 13:21:52.522: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-projected-secrets-77a09292-ffe5-4554-9a07-90f8b83c2e1d container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 24 13:21:52.576: INFO: Waiting for pod pod-projected-secrets-77a09292-ffe5-4554-9a07-90f8b83c2e1d to disappear
Aug 24 13:21:52.584: INFO: Pod pod-projected-secrets-77a09292-ffe5-4554-9a07-90f8b83c2e1d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:21:52.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-456" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":346,"completed":318,"skipped":6142,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:21:52.613: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 13:21:52.739: INFO: Waiting up to 5m0s for pod "downwardapi-volume-34cee034-8583-489d-a197-810f3dfd35f4" in namespace "downward-api-4539" to be "Succeeded or Failed"
Aug 24 13:21:52.777: INFO: Pod "downwardapi-volume-34cee034-8583-489d-a197-810f3dfd35f4": Phase="Pending", Reason="", readiness=false. Elapsed: 38.470266ms
Aug 24 13:21:54.792: INFO: Pod "downwardapi-volume-34cee034-8583-489d-a197-810f3dfd35f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053542744s
Aug 24 13:21:56.810: INFO: Pod "downwardapi-volume-34cee034-8583-489d-a197-810f3dfd35f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.070900428s
STEP: Saw pod success
Aug 24 13:21:56.810: INFO: Pod "downwardapi-volume-34cee034-8583-489d-a197-810f3dfd35f4" satisfied condition "Succeeded or Failed"
Aug 24 13:21:56.816: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-34cee034-8583-489d-a197-810f3dfd35f4 container client-container: <nil>
STEP: delete the pod
Aug 24 13:21:56.845: INFO: Waiting for pod downwardapi-volume-34cee034-8583-489d-a197-810f3dfd35f4 to disappear
Aug 24 13:21:56.852: INFO: Pod downwardapi-volume-34cee034-8583-489d-a197-810f3dfd35f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:21:56.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4539" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":346,"completed":319,"skipped":6180,"failed":0}
SSSSS
------------------------------
[sig-network] EndpointSlice 
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:21:56.872: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/endpointslice.go:49
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[AfterEach] [sig-network] EndpointSlice
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:21:57.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7312" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","total":346,"completed":320,"skipped":6185,"failed":0}
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:21:57.121: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: getting the auto-created API token
STEP: reading a file in the container
Aug 24 13:21:59.813: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6191 pod-service-account-a1718dd6-d262-426a-94af-bb5b3522e889 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Aug 24 13:22:00.138: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6191 pod-service-account-a1718dd6-d262-426a-94af-bb5b3522e889 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Aug 24 13:22:00.417: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6191 pod-service-account-a1718dd6-d262-426a-94af-bb5b3522e889 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:22:00.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6191" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":346,"completed":321,"skipped":6194,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:22:00.703: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should provide secure master service  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:22:00.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4307" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":346,"completed":322,"skipped":6215,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:22:00.818: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support proxy with --port 0  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: starting the proxy server
Aug 24 13:22:00.864: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-2468 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:22:00.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2468" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":346,"completed":323,"skipped":6232,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:22:00.996: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating configMap with name projected-configmap-test-volume-63cfb65e-6400-48fd-a968-e4ecb80be39b
STEP: Creating a pod to test consume configMaps
Aug 24 13:22:01.078: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fd9611de-b84c-4f82-84dc-767a6f896a21" in namespace "projected-7563" to be "Succeeded or Failed"
Aug 24 13:22:01.084: INFO: Pod "pod-projected-configmaps-fd9611de-b84c-4f82-84dc-767a6f896a21": Phase="Pending", Reason="", readiness=false. Elapsed: 5.998465ms
Aug 24 13:22:03.096: INFO: Pod "pod-projected-configmaps-fd9611de-b84c-4f82-84dc-767a6f896a21": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017994797s
Aug 24 13:22:05.132: INFO: Pod "pod-projected-configmaps-fd9611de-b84c-4f82-84dc-767a6f896a21": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053434529s
STEP: Saw pod success
Aug 24 13:22:05.132: INFO: Pod "pod-projected-configmaps-fd9611de-b84c-4f82-84dc-767a6f896a21" satisfied condition "Succeeded or Failed"
Aug 24 13:22:05.138: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-projected-configmaps-fd9611de-b84c-4f82-84dc-767a6f896a21 container agnhost-container: <nil>
STEP: delete the pod
Aug 24 13:22:05.172: INFO: Waiting for pod pod-projected-configmaps-fd9611de-b84c-4f82-84dc-767a6f896a21 to disappear
Aug 24 13:22:05.179: INFO: Pod pod-projected-configmaps-fd9611de-b84c-4f82-84dc-767a6f896a21 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:22:05.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7563" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":346,"completed":324,"skipped":6243,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:22:05.211: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 24 13:22:05.358: INFO: Waiting up to 5m0s for pod "pod-643b1ae7-52da-48aa-b2fd-474051d3f9a9" in namespace "emptydir-9607" to be "Succeeded or Failed"
Aug 24 13:22:05.370: INFO: Pod "pod-643b1ae7-52da-48aa-b2fd-474051d3f9a9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.975912ms
Aug 24 13:22:07.383: INFO: Pod "pod-643b1ae7-52da-48aa-b2fd-474051d3f9a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025123158s
Aug 24 13:22:09.397: INFO: Pod "pod-643b1ae7-52da-48aa-b2fd-474051d3f9a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038697611s
STEP: Saw pod success
Aug 24 13:22:09.397: INFO: Pod "pod-643b1ae7-52da-48aa-b2fd-474051d3f9a9" satisfied condition "Succeeded or Failed"
Aug 24 13:22:09.402: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-643b1ae7-52da-48aa-b2fd-474051d3f9a9 container test-container: <nil>
STEP: delete the pod
Aug 24 13:22:09.444: INFO: Waiting for pod pod-643b1ae7-52da-48aa-b2fd-474051d3f9a9 to disappear
Aug 24 13:22:09.449: INFO: Pod pod-643b1ae7-52da-48aa-b2fd-474051d3f9a9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:22:09.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9607" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":325,"skipped":6260,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:22:09.472: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Aug 24 13:22:12.106: INFO: Successfully updated pod "adopt-release-7nfvh"
STEP: Checking that the Job readopts the Pod
Aug 24 13:22:12.106: INFO: Waiting up to 15m0s for pod "adopt-release-7nfvh" in namespace "job-8746" to be "adopted"
Aug 24 13:22:12.115: INFO: Pod "adopt-release-7nfvh": Phase="Running", Reason="", readiness=true. Elapsed: 9.6002ms
Aug 24 13:22:14.130: INFO: Pod "adopt-release-7nfvh": Phase="Running", Reason="", readiness=true. Elapsed: 2.023746565s
Aug 24 13:22:14.130: INFO: Pod "adopt-release-7nfvh" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Aug 24 13:22:14.659: INFO: Successfully updated pod "adopt-release-7nfvh"
STEP: Checking that the Job releases the Pod
Aug 24 13:22:14.659: INFO: Waiting up to 15m0s for pod "adopt-release-7nfvh" in namespace "job-8746" to be "released"
Aug 24 13:22:14.665: INFO: Pod "adopt-release-7nfvh": Phase="Running", Reason="", readiness=true. Elapsed: 6.239288ms
Aug 24 13:22:16.679: INFO: Pod "adopt-release-7nfvh": Phase="Running", Reason="", readiness=true. Elapsed: 2.01996252s
Aug 24 13:22:16.679: INFO: Pod "adopt-release-7nfvh" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:22:16.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8746" for this suite.

• [SLOW TEST:7.223 seconds]
[sig-apps] Job
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":346,"completed":326,"skipped":6277,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:22:16.697: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Aug 24 13:22:23.101: INFO: 80 pods remaining
Aug 24 13:22:23.101: INFO: 80 pods has nil DeletionTimestamp
Aug 24 13:22:23.101: INFO: 
Aug 24 13:22:23.972: INFO: 69 pods remaining
Aug 24 13:22:23.972: INFO: 69 pods has nil DeletionTimestamp
Aug 24 13:22:23.972: INFO: 
Aug 24 13:22:24.979: INFO: 60 pods remaining
Aug 24 13:22:24.979: INFO: 60 pods has nil DeletionTimestamp
Aug 24 13:22:24.979: INFO: 
Aug 24 13:22:26.060: INFO: 42 pods remaining
Aug 24 13:22:26.060: INFO: 42 pods has nil DeletionTimestamp
Aug 24 13:22:26.060: INFO: 
Aug 24 13:22:26.963: INFO: 32 pods remaining
Aug 24 13:22:26.963: INFO: 31 pods has nil DeletionTimestamp
Aug 24 13:22:26.963: INFO: 
Aug 24 13:22:27.959: INFO: 19 pods remaining
Aug 24 13:22:27.960: INFO: 19 pods has nil DeletionTimestamp
Aug 24 13:22:27.960: INFO: 
Aug 24 13:22:28.996: INFO: 0 pods remaining
Aug 24 13:22:28.996: INFO: 0 pods has nil DeletionTimestamp
Aug 24 13:22:28.996: INFO: 
STEP: Gathering metrics
Aug 24 13:22:30.076: INFO: The status of Pod kube-controller-manager-zou9eicaeree-2 is Running (Ready = true)
Aug 24 13:22:30.312: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:22:30.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4129" for this suite.

• [SLOW TEST:13.654 seconds]
[sig-api-machinery] Garbage collector
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":346,"completed":327,"skipped":6302,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:22:30.355: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 13:22:30.558: INFO: The status of Pod busybox-scheduling-754e116c-2e04-45d7-a0e2-8cf76c076dd6 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 13:22:32.572: INFO: The status of Pod busybox-scheduling-754e116c-2e04-45d7-a0e2-8cf76c076dd6 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 13:22:34.572: INFO: The status of Pod busybox-scheduling-754e116c-2e04-45d7-a0e2-8cf76c076dd6 is Pending, waiting for it to be Running (with Ready = true)
Aug 24 13:22:36.572: INFO: The status of Pod busybox-scheduling-754e116c-2e04-45d7-a0e2-8cf76c076dd6 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:22:36.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8923" for this suite.

• [SLOW TEST:6.264 seconds]
[sig-node] Kubelet
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:41
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":346,"completed":328,"skipped":6333,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:22:36.620: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 13:22:36.754: INFO: Waiting up to 5m0s for pod "downwardapi-volume-973772f4-9cb0-439c-8274-1a46c3cc8d35" in namespace "downward-api-2993" to be "Succeeded or Failed"
Aug 24 13:22:36.761: INFO: Pod "downwardapi-volume-973772f4-9cb0-439c-8274-1a46c3cc8d35": Phase="Pending", Reason="", readiness=false. Elapsed: 6.794424ms
Aug 24 13:22:38.772: INFO: Pod "downwardapi-volume-973772f4-9cb0-439c-8274-1a46c3cc8d35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01838428s
Aug 24 13:22:40.801: INFO: Pod "downwardapi-volume-973772f4-9cb0-439c-8274-1a46c3cc8d35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046708339s
STEP: Saw pod success
Aug 24 13:22:40.801: INFO: Pod "downwardapi-volume-973772f4-9cb0-439c-8274-1a46c3cc8d35" satisfied condition "Succeeded or Failed"
Aug 24 13:22:40.807: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-973772f4-9cb0-439c-8274-1a46c3cc8d35 container client-container: <nil>
STEP: delete the pod
Aug 24 13:22:40.856: INFO: Waiting for pod downwardapi-volume-973772f4-9cb0-439c-8274-1a46c3cc8d35 to disappear
Aug 24 13:22:40.862: INFO: Pod downwardapi-volume-973772f4-9cb0-439c-8274-1a46c3cc8d35 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:22:40.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2993" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":346,"completed":329,"skipped":6342,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Pods 
  should run through the lifecycle of Pods and PodStatus [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:22:40.888: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/pods.go:189
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating a Pod with a static label
STEP: watching for Pod to be ready
Aug 24 13:22:40.981: INFO: observed Pod pod-test in namespace pods-9463 in phase Pending with labels: map[test-pod-static:true] & conditions []
Aug 24 13:22:40.998: INFO: observed Pod pod-test in namespace pods-9463 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 13:22:40 +0000 UTC  }]
Aug 24 13:22:41.021: INFO: observed Pod pod-test in namespace pods-9463 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 13:22:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 13:22:40 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-24 13:22:40 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 13:22:40 +0000 UTC  }]
Aug 24 13:22:42.080: INFO: Found Pod pod-test in namespace pods-9463 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 13:22:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 13:22:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 13:22:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-24 13:22:40 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data
Aug 24 13:22:42.109: INFO: observed event type ADDED
STEP: getting the Pod and ensuring that it's patched
STEP: replacing the Pod's status Ready condition to False
STEP: check the Pod again to ensure its Ready conditions are False
STEP: deleting the Pod via a Collection with a LabelSelector
STEP: watching for the Pod to be deleted
Aug 24 13:22:42.165: INFO: observed event type ADDED
Aug 24 13:22:42.165: INFO: observed event type MODIFIED
Aug 24 13:22:42.166: INFO: observed event type MODIFIED
Aug 24 13:22:42.166: INFO: observed event type MODIFIED
Aug 24 13:22:42.166: INFO: observed event type MODIFIED
Aug 24 13:22:42.166: INFO: observed event type MODIFIED
Aug 24 13:22:42.166: INFO: observed event type MODIFIED
Aug 24 13:22:44.095: INFO: observed event type MODIFIED
Aug 24 13:22:45.098: INFO: observed event type MODIFIED
Aug 24 13:22:45.109: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:22:45.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9463" for this suite.
•{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","total":346,"completed":330,"skipped":6350,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:22:45.163: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 13:22:46.511: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 13:22:49.542: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 13:22:49.564: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8551-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:22:53.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1577" for this suite.
STEP: Destroying namespace "webhook-1577-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:8.003 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":346,"completed":331,"skipped":6357,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:22:53.169: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating secret with name projected-secret-test-d2caa7f3-b72f-4e89-a0c6-f05e17b0d1ba
STEP: Creating a pod to test consume secrets
Aug 24 13:22:53.370: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2771a020-bf8c-4c5a-9a31-e6daab3c51b6" in namespace "projected-407" to be "Succeeded or Failed"
Aug 24 13:22:53.375: INFO: Pod "pod-projected-secrets-2771a020-bf8c-4c5a-9a31-e6daab3c51b6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.383716ms
Aug 24 13:22:55.389: INFO: Pod "pod-projected-secrets-2771a020-bf8c-4c5a-9a31-e6daab3c51b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019422078s
Aug 24 13:22:57.401: INFO: Pod "pod-projected-secrets-2771a020-bf8c-4c5a-9a31-e6daab3c51b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031494218s
STEP: Saw pod success
Aug 24 13:22:57.401: INFO: Pod "pod-projected-secrets-2771a020-bf8c-4c5a-9a31-e6daab3c51b6" satisfied condition "Succeeded or Failed"
Aug 24 13:22:57.406: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-projected-secrets-2771a020-bf8c-4c5a-9a31-e6daab3c51b6 container secret-volume-test: <nil>
STEP: delete the pod
Aug 24 13:22:57.453: INFO: Waiting for pod pod-projected-secrets-2771a020-bf8c-4c5a-9a31-e6daab3c51b6 to disappear
Aug 24 13:22:57.459: INFO: Pod pod-projected-secrets-2771a020-bf8c-4c5a-9a31-e6daab3c51b6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:22:57.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-407" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":346,"completed":332,"skipped":6372,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:22:57.479: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: validating api versions
Aug 24 13:22:57.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=kubectl-9816 api-versions'
Aug 24 13:22:57.683: INFO: stderr: ""
Aug 24 13:22:57.683: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1\nevents.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nnetworking.k8s.io/v1\nnode.k8s.io/v1\nnode.k8s.io/v1beta1\npolicy/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:22:57.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9816" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":346,"completed":333,"skipped":6393,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:22:57.707: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 24 13:22:59.822: INFO: DNS probes using dns-5497/dns-test-d160bfff-cfb4-47c5-9ff5-962ff627a28b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:22:59.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5497" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":346,"completed":334,"skipped":6483,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:22:59.861: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8496.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8496.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8496.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8496.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 24 13:23:01.968: INFO: DNS probes using dns-test-d6d4dbc1-9ecd-4a1b-a74a-a4f41918df81 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8496.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8496.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8496.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8496.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 24 13:23:04.086: INFO: File jessie_udp@dns-test-service-3.dns-8496.svc.cluster.local from pod  dns-8496/dns-test-b7f69653-3527-4cc7-a786-673c09f7d4ed contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 13:23:04.086: INFO: Lookups using dns-8496/dns-test-b7f69653-3527-4cc7-a786-673c09f7d4ed failed for: [jessie_udp@dns-test-service-3.dns-8496.svc.cluster.local]

Aug 24 13:23:09.107: INFO: File jessie_udp@dns-test-service-3.dns-8496.svc.cluster.local from pod  dns-8496/dns-test-b7f69653-3527-4cc7-a786-673c09f7d4ed contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 13:23:09.107: INFO: Lookups using dns-8496/dns-test-b7f69653-3527-4cc7-a786-673c09f7d4ed failed for: [jessie_udp@dns-test-service-3.dns-8496.svc.cluster.local]

Aug 24 13:23:14.095: INFO: File wheezy_udp@dns-test-service-3.dns-8496.svc.cluster.local from pod  dns-8496/dns-test-b7f69653-3527-4cc7-a786-673c09f7d4ed contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 13:23:14.102: INFO: Lookups using dns-8496/dns-test-b7f69653-3527-4cc7-a786-673c09f7d4ed failed for: [wheezy_udp@dns-test-service-3.dns-8496.svc.cluster.local]

Aug 24 13:23:19.102: INFO: File jessie_udp@dns-test-service-3.dns-8496.svc.cluster.local from pod  dns-8496/dns-test-b7f69653-3527-4cc7-a786-673c09f7d4ed contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 13:23:19.102: INFO: Lookups using dns-8496/dns-test-b7f69653-3527-4cc7-a786-673c09f7d4ed failed for: [jessie_udp@dns-test-service-3.dns-8496.svc.cluster.local]

Aug 24 13:23:24.095: INFO: File wheezy_udp@dns-test-service-3.dns-8496.svc.cluster.local from pod  dns-8496/dns-test-b7f69653-3527-4cc7-a786-673c09f7d4ed contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 13:23:24.104: INFO: File jessie_udp@dns-test-service-3.dns-8496.svc.cluster.local from pod  dns-8496/dns-test-b7f69653-3527-4cc7-a786-673c09f7d4ed contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 13:23:24.105: INFO: Lookups using dns-8496/dns-test-b7f69653-3527-4cc7-a786-673c09f7d4ed failed for: [wheezy_udp@dns-test-service-3.dns-8496.svc.cluster.local jessie_udp@dns-test-service-3.dns-8496.svc.cluster.local]

Aug 24 13:23:29.094: INFO: File wheezy_udp@dns-test-service-3.dns-8496.svc.cluster.local from pod  dns-8496/dns-test-b7f69653-3527-4cc7-a786-673c09f7d4ed contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 24 13:23:29.099: INFO: Lookups using dns-8496/dns-test-b7f69653-3527-4cc7-a786-673c09f7d4ed failed for: [wheezy_udp@dns-test-service-3.dns-8496.svc.cluster.local]

Aug 24 13:23:34.103: INFO: DNS probes using dns-test-b7f69653-3527-4cc7-a786-673c09f7d4ed succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8496.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8496.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8496.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8496.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 24 13:23:36.289: INFO: File jessie_udp@dns-test-service-3.dns-8496.svc.cluster.local from pod  dns-8496/dns-test-3b177511-c03e-4d46-a9a5-72d5521dd649 contains '' instead of '10.233.34.36'
Aug 24 13:23:36.289: INFO: Lookups using dns-8496/dns-test-3b177511-c03e-4d46-a9a5-72d5521dd649 failed for: [jessie_udp@dns-test-service-3.dns-8496.svc.cluster.local]

Aug 24 13:23:41.305: INFO: DNS probes using dns-test-3b177511-c03e-4d46-a9a5-72d5521dd649 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:23:41.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8496" for this suite.

• [SLOW TEST:41.564 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":346,"completed":335,"skipped":6492,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:23:41.429: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-v5hgb in namespace proxy-5339
I0824 13:23:41.553102      16 runners.go:193] Created replication controller with name: proxy-service-v5hgb, namespace: proxy-5339, replica count: 1
I0824 13:23:42.605590      16 runners.go:193] proxy-service-v5hgb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0824 13:23:43.606532      16 runners.go:193] proxy-service-v5hgb Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 13:23:43.619: INFO: setup took 2.12094748s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 24 13:23:43.660: INFO: (0) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 40.397922ms)
Aug 24 13:23:43.660: INFO: (0) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 39.534113ms)
Aug 24 13:23:43.667: INFO: (0) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 46.272595ms)
Aug 24 13:23:43.667: INFO: (0) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 46.686931ms)
Aug 24 13:23:43.667: INFO: (0) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 47.61661ms)
Aug 24 13:23:43.667: INFO: (0) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 46.209732ms)
Aug 24 13:23:43.667: INFO: (0) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 47.111912ms)
Aug 24 13:23:43.667: INFO: (0) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 47.646233ms)
Aug 24 13:23:43.667: INFO: (0) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 46.698065ms)
Aug 24 13:23:43.669: INFO: (0) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 48.660246ms)
Aug 24 13:23:43.669: INFO: (0) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 48.830408ms)
Aug 24 13:23:43.672: INFO: (0) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 51.73844ms)
Aug 24 13:23:43.672: INFO: (0) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 52.298714ms)
Aug 24 13:23:43.672: INFO: (0) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 52.250014ms)
Aug 24 13:23:43.672: INFO: (0) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 52.016315ms)
Aug 24 13:23:43.673: INFO: (0) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 52.211804ms)
Aug 24 13:23:43.688: INFO: (1) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 14.715161ms)
Aug 24 13:23:43.688: INFO: (1) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 14.450549ms)
Aug 24 13:23:43.691: INFO: (1) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 14.374435ms)
Aug 24 13:23:43.691: INFO: (1) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 16.191633ms)
Aug 24 13:23:43.693: INFO: (1) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 18.114002ms)
Aug 24 13:23:43.693: INFO: (1) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 16.313978ms)
Aug 24 13:23:43.695: INFO: (1) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 19.45308ms)
Aug 24 13:23:43.695: INFO: (1) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 18.482415ms)
Aug 24 13:23:43.698: INFO: (1) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 19.993948ms)
Aug 24 13:23:43.698: INFO: (1) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 20.713384ms)
Aug 24 13:23:43.700: INFO: (1) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 22.804644ms)
Aug 24 13:23:43.700: INFO: (1) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 22.706109ms)
Aug 24 13:23:43.701: INFO: (1) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 25.39059ms)
Aug 24 13:23:43.701: INFO: (1) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 24.336677ms)
Aug 24 13:23:43.712: INFO: (1) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 35.941142ms)
Aug 24 13:23:43.712: INFO: (1) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 34.508208ms)
Aug 24 13:23:43.722: INFO: (2) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 9.691859ms)
Aug 24 13:23:43.723: INFO: (2) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 10.336355ms)
Aug 24 13:23:43.729: INFO: (2) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 16.568084ms)
Aug 24 13:23:43.729: INFO: (2) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 15.736511ms)
Aug 24 13:23:43.729: INFO: (2) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 16.363322ms)
Aug 24 13:23:43.730: INFO: (2) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 16.5736ms)
Aug 24 13:23:43.730: INFO: (2) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 15.989307ms)
Aug 24 13:23:43.731: INFO: (2) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 17.643609ms)
Aug 24 13:23:43.731: INFO: (2) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 17.310495ms)
Aug 24 13:23:43.739: INFO: (2) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 24.321839ms)
Aug 24 13:23:43.740: INFO: (2) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 25.443139ms)
Aug 24 13:23:43.740: INFO: (2) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 26.571577ms)
Aug 24 13:23:43.742: INFO: (2) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 27.68007ms)
Aug 24 13:23:43.743: INFO: (2) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 29.721231ms)
Aug 24 13:23:43.743: INFO: (2) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 29.038016ms)
Aug 24 13:23:43.743: INFO: (2) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 29.398634ms)
Aug 24 13:23:43.754: INFO: (3) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 9.458217ms)
Aug 24 13:23:43.755: INFO: (3) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 10.680044ms)
Aug 24 13:23:43.759: INFO: (3) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 14.574899ms)
Aug 24 13:23:43.761: INFO: (3) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 14.183717ms)
Aug 24 13:23:43.761: INFO: (3) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 14.07979ms)
Aug 24 13:23:43.762: INFO: (3) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 17.736229ms)
Aug 24 13:23:43.766: INFO: (3) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 20.681825ms)
Aug 24 13:23:43.767: INFO: (3) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 22.186349ms)
Aug 24 13:23:43.767: INFO: (3) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 20.784688ms)
Aug 24 13:23:43.767: INFO: (3) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 20.77609ms)
Aug 24 13:23:43.767: INFO: (3) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 20.278128ms)
Aug 24 13:23:43.767: INFO: (3) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 21.695883ms)
Aug 24 13:23:43.767: INFO: (3) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 21.320751ms)
Aug 24 13:23:43.767: INFO: (3) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 20.536927ms)
Aug 24 13:23:43.768: INFO: (3) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 22.347221ms)
Aug 24 13:23:43.770: INFO: (3) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 24.206053ms)
Aug 24 13:23:43.781: INFO: (4) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 11.457201ms)
Aug 24 13:23:43.787: INFO: (4) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 16.362063ms)
Aug 24 13:23:43.787: INFO: (4) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 15.461794ms)
Aug 24 13:23:43.787: INFO: (4) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 16.059884ms)
Aug 24 13:23:43.789: INFO: (4) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 17.657608ms)
Aug 24 13:23:43.789: INFO: (4) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 17.948595ms)
Aug 24 13:23:43.789: INFO: (4) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 17.901313ms)
Aug 24 13:23:43.791: INFO: (4) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 20.014507ms)
Aug 24 13:23:43.791: INFO: (4) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 20.058465ms)
Aug 24 13:23:43.791: INFO: (4) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 19.954778ms)
Aug 24 13:23:43.792: INFO: (4) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 20.973549ms)
Aug 24 13:23:43.793: INFO: (4) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 21.468461ms)
Aug 24 13:23:43.794: INFO: (4) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 22.894526ms)
Aug 24 13:23:43.795: INFO: (4) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 23.880243ms)
Aug 24 13:23:43.795: INFO: (4) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 24.811507ms)
Aug 24 13:23:43.796: INFO: (4) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 25.360606ms)
Aug 24 13:23:43.803: INFO: (5) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 6.544722ms)
Aug 24 13:23:43.806: INFO: (5) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 9.563929ms)
Aug 24 13:23:43.806: INFO: (5) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 10.093285ms)
Aug 24 13:23:43.807: INFO: (5) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 9.600027ms)
Aug 24 13:23:43.811: INFO: (5) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 12.991584ms)
Aug 24 13:23:43.815: INFO: (5) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 16.658566ms)
Aug 24 13:23:43.816: INFO: (5) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 19.188181ms)
Aug 24 13:23:43.817: INFO: (5) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 19.872044ms)
Aug 24 13:23:43.817: INFO: (5) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 20.560266ms)
Aug 24 13:23:43.817: INFO: (5) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 19.558756ms)
Aug 24 13:23:43.817: INFO: (5) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 19.519265ms)
Aug 24 13:23:43.818: INFO: (5) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 20.220402ms)
Aug 24 13:23:43.819: INFO: (5) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 21.775173ms)
Aug 24 13:23:43.819: INFO: (5) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 20.892803ms)
Aug 24 13:23:43.819: INFO: (5) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 22.562734ms)
Aug 24 13:23:43.821: INFO: (5) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 22.840041ms)
Aug 24 13:23:43.837: INFO: (6) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 15.653418ms)
Aug 24 13:23:43.837: INFO: (6) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 15.2833ms)
Aug 24 13:23:43.839: INFO: (6) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 16.961635ms)
Aug 24 13:23:43.852: INFO: (6) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 30.002014ms)
Aug 24 13:23:43.852: INFO: (6) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 30.487825ms)
Aug 24 13:23:43.852: INFO: (6) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 29.792511ms)
Aug 24 13:23:43.854: INFO: (6) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 31.853371ms)
Aug 24 13:23:43.854: INFO: (6) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 32.504438ms)
Aug 24 13:23:43.858: INFO: (6) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 35.808094ms)
Aug 24 13:23:43.859: INFO: (6) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 36.462151ms)
Aug 24 13:23:43.859: INFO: (6) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 36.976144ms)
Aug 24 13:23:43.859: INFO: (6) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 37.06561ms)
Aug 24 13:23:43.860: INFO: (6) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 38.374473ms)
Aug 24 13:23:43.861: INFO: (6) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 38.683617ms)
Aug 24 13:23:43.862: INFO: (6) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 40.135379ms)
Aug 24 13:23:43.864: INFO: (6) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 42.148735ms)
Aug 24 13:23:43.876: INFO: (7) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 10.864613ms)
Aug 24 13:23:43.877: INFO: (7) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 11.871769ms)
Aug 24 13:23:43.879: INFO: (7) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 13.256733ms)
Aug 24 13:23:43.880: INFO: (7) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 13.698009ms)
Aug 24 13:23:43.881: INFO: (7) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 16.340215ms)
Aug 24 13:23:43.882: INFO: (7) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 16.723999ms)
Aug 24 13:23:43.882: INFO: (7) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 16.182643ms)
Aug 24 13:23:43.883: INFO: (7) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 18.042639ms)
Aug 24 13:23:43.886: INFO: (7) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 19.5143ms)
Aug 24 13:23:43.886: INFO: (7) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 20.939437ms)
Aug 24 13:23:43.887: INFO: (7) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 21.817227ms)
Aug 24 13:23:43.888: INFO: (7) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 22.081022ms)
Aug 24 13:23:43.888: INFO: (7) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 22.101538ms)
Aug 24 13:23:43.889: INFO: (7) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 22.389422ms)
Aug 24 13:23:43.889: INFO: (7) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 23.242624ms)
Aug 24 13:23:43.889: INFO: (7) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 24.289106ms)
Aug 24 13:23:43.900: INFO: (8) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 10.50246ms)
Aug 24 13:23:43.902: INFO: (8) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 11.996151ms)
Aug 24 13:23:43.902: INFO: (8) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 11.528572ms)
Aug 24 13:23:43.902: INFO: (8) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 12.55547ms)
Aug 24 13:23:43.904: INFO: (8) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 13.335371ms)
Aug 24 13:23:43.904: INFO: (8) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 13.098141ms)
Aug 24 13:23:43.904: INFO: (8) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 12.843631ms)
Aug 24 13:23:43.905: INFO: (8) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 14.718476ms)
Aug 24 13:23:43.907: INFO: (8) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 16.539628ms)
Aug 24 13:23:43.908: INFO: (8) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 16.495976ms)
Aug 24 13:23:43.908: INFO: (8) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 17.555188ms)
Aug 24 13:23:43.912: INFO: (8) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 20.956514ms)
Aug 24 13:23:43.914: INFO: (8) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 23.590678ms)
Aug 24 13:23:43.914: INFO: (8) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 22.796792ms)
Aug 24 13:23:43.914: INFO: (8) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 22.723989ms)
Aug 24 13:23:43.915: INFO: (8) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 23.84554ms)
Aug 24 13:23:43.928: INFO: (9) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 11.653132ms)
Aug 24 13:23:43.928: INFO: (9) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 12.89213ms)
Aug 24 13:23:43.928: INFO: (9) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 11.633058ms)
Aug 24 13:23:43.928: INFO: (9) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 13.456694ms)
Aug 24 13:23:43.930: INFO: (9) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 13.176135ms)
Aug 24 13:23:43.930: INFO: (9) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 13.820178ms)
Aug 24 13:23:43.931: INFO: (9) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 13.954726ms)
Aug 24 13:23:43.931: INFO: (9) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 15.746478ms)
Aug 24 13:23:43.932: INFO: (9) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 15.150531ms)
Aug 24 13:23:43.934: INFO: (9) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 16.940035ms)
Aug 24 13:23:43.935: INFO: (9) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 17.799078ms)
Aug 24 13:23:43.938: INFO: (9) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 21.892097ms)
Aug 24 13:23:43.938: INFO: (9) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 22.265354ms)
Aug 24 13:23:43.938: INFO: (9) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 22.399193ms)
Aug 24 13:23:43.938: INFO: (9) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 22.562833ms)
Aug 24 13:23:43.939: INFO: (9) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 22.047316ms)
Aug 24 13:23:43.952: INFO: (10) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 12.101785ms)
Aug 24 13:23:43.955: INFO: (10) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 15.224013ms)
Aug 24 13:23:43.955: INFO: (10) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 15.977745ms)
Aug 24 13:23:43.959: INFO: (10) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 18.841714ms)
Aug 24 13:23:43.961: INFO: (10) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 20.457257ms)
Aug 24 13:23:43.964: INFO: (10) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 23.46759ms)
Aug 24 13:23:43.964: INFO: (10) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 24.123999ms)
Aug 24 13:23:43.965: INFO: (10) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 23.805972ms)
Aug 24 13:23:43.965: INFO: (10) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 24.222946ms)
Aug 24 13:23:43.965: INFO: (10) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 24.536945ms)
Aug 24 13:23:43.965: INFO: (10) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 24.593037ms)
Aug 24 13:23:43.966: INFO: (10) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 23.741066ms)
Aug 24 13:23:43.969: INFO: (10) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 28.116545ms)
Aug 24 13:23:43.969: INFO: (10) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 28.270035ms)
Aug 24 13:23:43.969: INFO: (10) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 28.4082ms)
Aug 24 13:23:43.972: INFO: (10) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 31.057344ms)
Aug 24 13:23:43.988: INFO: (11) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 14.760047ms)
Aug 24 13:23:43.989: INFO: (11) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 17.204996ms)
Aug 24 13:23:43.989: INFO: (11) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 15.858103ms)
Aug 24 13:23:43.989: INFO: (11) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 16.253246ms)
Aug 24 13:23:43.990: INFO: (11) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 15.892834ms)
Aug 24 13:23:43.991: INFO: (11) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 19.047987ms)
Aug 24 13:23:43.993: INFO: (11) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 17.492272ms)
Aug 24 13:23:43.993: INFO: (11) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 17.909311ms)
Aug 24 13:23:43.993: INFO: (11) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 17.736936ms)
Aug 24 13:23:43.994: INFO: (11) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 21.280873ms)
Aug 24 13:23:43.995: INFO: (11) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 20.930244ms)
Aug 24 13:23:43.996: INFO: (11) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 13.684893ms)
Aug 24 13:23:43.996: INFO: (11) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 16.148639ms)
Aug 24 13:23:43.996: INFO: (11) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 21.941028ms)
Aug 24 13:23:43.998: INFO: (11) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 23.917731ms)
Aug 24 13:23:43.998: INFO: (11) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 23.249338ms)
Aug 24 13:23:44.014: INFO: (12) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 15.221014ms)
Aug 24 13:23:44.015: INFO: (12) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 15.769508ms)
Aug 24 13:23:44.015: INFO: (12) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 16.08603ms)
Aug 24 13:23:44.020: INFO: (12) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 21.364763ms)
Aug 24 13:23:44.020: INFO: (12) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 20.340255ms)
Aug 24 13:23:44.020: INFO: (12) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 21.185294ms)
Aug 24 13:23:44.021: INFO: (12) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 21.070758ms)
Aug 24 13:23:44.021: INFO: (12) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 20.321225ms)
Aug 24 13:23:44.023: INFO: (12) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 22.666307ms)
Aug 24 13:23:44.023: INFO: (12) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 22.605564ms)
Aug 24 13:23:44.023: INFO: (12) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 22.858834ms)
Aug 24 13:23:44.023: INFO: (12) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 23.394463ms)
Aug 24 13:23:44.023: INFO: (12) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 24.118638ms)
Aug 24 13:23:44.024: INFO: (12) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 23.626807ms)
Aug 24 13:23:44.027: INFO: (12) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 26.297148ms)
Aug 24 13:23:44.029: INFO: (12) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 28.449437ms)
Aug 24 13:23:44.042: INFO: (13) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 12.77512ms)
Aug 24 13:23:44.043: INFO: (13) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 12.337067ms)
Aug 24 13:23:44.048: INFO: (13) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 16.801436ms)
Aug 24 13:23:44.049: INFO: (13) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 18.398584ms)
Aug 24 13:23:44.049: INFO: (13) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 19.292988ms)
Aug 24 13:23:44.048: INFO: (13) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 17.008677ms)
Aug 24 13:23:44.052: INFO: (13) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 22.093368ms)
Aug 24 13:23:44.052: INFO: (13) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 22.67931ms)
Aug 24 13:23:44.052: INFO: (13) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 21.548419ms)
Aug 24 13:23:44.053: INFO: (13) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 20.137405ms)
Aug 24 13:23:44.055: INFO: (13) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 23.114852ms)
Aug 24 13:23:44.059: INFO: (13) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 27.707915ms)
Aug 24 13:23:44.060: INFO: (13) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 28.56085ms)
Aug 24 13:23:44.060: INFO: (13) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 30.552313ms)
Aug 24 13:23:44.061: INFO: (13) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 28.112272ms)
Aug 24 13:23:44.060: INFO: (13) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 28.262871ms)
Aug 24 13:23:44.072: INFO: (14) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 11.208933ms)
Aug 24 13:23:44.073: INFO: (14) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 11.944971ms)
Aug 24 13:23:44.088: INFO: (14) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 26.045152ms)
Aug 24 13:23:44.088: INFO: (14) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 26.407442ms)
Aug 24 13:23:44.088: INFO: (14) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 25.689163ms)
Aug 24 13:23:44.088: INFO: (14) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 26.811813ms)
Aug 24 13:23:44.088: INFO: (14) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 27.262387ms)
Aug 24 13:23:44.088: INFO: (14) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 26.512143ms)
Aug 24 13:23:44.089: INFO: (14) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 26.804015ms)
Aug 24 13:23:44.089: INFO: (14) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 27.238969ms)
Aug 24 13:23:44.089: INFO: (14) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 26.760189ms)
Aug 24 13:23:44.089: INFO: (14) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 27.031134ms)
Aug 24 13:23:44.089: INFO: (14) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 27.258602ms)
Aug 24 13:23:44.089: INFO: (14) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 27.253074ms)
Aug 24 13:23:44.089: INFO: (14) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 27.105167ms)
Aug 24 13:23:44.089: INFO: (14) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 26.97438ms)
Aug 24 13:23:44.102: INFO: (15) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 11.392563ms)
Aug 24 13:23:44.102: INFO: (15) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 12.945007ms)
Aug 24 13:23:44.102: INFO: (15) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 13.037783ms)
Aug 24 13:23:44.105: INFO: (15) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 15.298034ms)
Aug 24 13:23:44.105: INFO: (15) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 14.838949ms)
Aug 24 13:23:44.107: INFO: (15) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 16.196752ms)
Aug 24 13:23:44.107: INFO: (15) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 17.086265ms)
Aug 24 13:23:44.109: INFO: (15) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 18.410625ms)
Aug 24 13:23:44.111: INFO: (15) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 20.787417ms)
Aug 24 13:23:44.111: INFO: (15) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 20.545785ms)
Aug 24 13:23:44.111: INFO: (15) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 21.794387ms)
Aug 24 13:23:44.112: INFO: (15) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 21.921812ms)
Aug 24 13:23:44.112: INFO: (15) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 21.603056ms)
Aug 24 13:23:44.113: INFO: (15) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 23.162156ms)
Aug 24 13:23:44.114: INFO: (15) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 23.440503ms)
Aug 24 13:23:44.114: INFO: (15) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 24.153406ms)
Aug 24 13:23:44.124: INFO: (16) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 9.499402ms)
Aug 24 13:23:44.124: INFO: (16) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 10.194205ms)
Aug 24 13:23:44.133: INFO: (16) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 17.672189ms)
Aug 24 13:23:44.135: INFO: (16) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 20.07227ms)
Aug 24 13:23:44.136: INFO: (16) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 20.462166ms)
Aug 24 13:23:44.136: INFO: (16) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 21.339979ms)
Aug 24 13:23:44.137: INFO: (16) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 22.005357ms)
Aug 24 13:23:44.137: INFO: (16) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 21.600892ms)
Aug 24 13:23:44.140: INFO: (16) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 25.424801ms)
Aug 24 13:23:44.140: INFO: (16) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 25.839075ms)
Aug 24 13:23:44.141: INFO: (16) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 25.513881ms)
Aug 24 13:23:44.141: INFO: (16) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 25.341913ms)
Aug 24 13:23:44.141: INFO: (16) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 26.064434ms)
Aug 24 13:23:44.142: INFO: (16) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 27.116726ms)
Aug 24 13:23:44.142: INFO: (16) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 26.487484ms)
Aug 24 13:23:44.142: INFO: (16) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 27.011704ms)
Aug 24 13:23:44.156: INFO: (17) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 13.314169ms)
Aug 24 13:23:44.161: INFO: (17) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 17.953074ms)
Aug 24 13:23:44.161: INFO: (17) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 18.773949ms)
Aug 24 13:23:44.162: INFO: (17) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 19.488265ms)
Aug 24 13:23:44.164: INFO: (17) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 20.740635ms)
Aug 24 13:23:44.164: INFO: (17) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 20.977684ms)
Aug 24 13:23:44.164: INFO: (17) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 21.688649ms)
Aug 24 13:23:44.164: INFO: (17) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 21.073905ms)
Aug 24 13:23:44.168: INFO: (17) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 25.195585ms)
Aug 24 13:23:44.168: INFO: (17) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 25.204748ms)
Aug 24 13:23:44.169: INFO: (17) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 25.408457ms)
Aug 24 13:23:44.169: INFO: (17) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 25.880684ms)
Aug 24 13:23:44.169: INFO: (17) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 25.914048ms)
Aug 24 13:23:44.169: INFO: (17) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 25.823369ms)
Aug 24 13:23:44.169: INFO: (17) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 26.291572ms)
Aug 24 13:23:44.169: INFO: (17) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 26.704272ms)
Aug 24 13:23:44.188: INFO: (18) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 17.656841ms)
Aug 24 13:23:44.189: INFO: (18) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 19.208367ms)
Aug 24 13:23:44.191: INFO: (18) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 20.260293ms)
Aug 24 13:23:44.191: INFO: (18) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 19.737479ms)
Aug 24 13:23:44.191: INFO: (18) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 18.367831ms)
Aug 24 13:23:44.192: INFO: (18) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 19.308108ms)
Aug 24 13:23:44.193: INFO: (18) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 22.40272ms)
Aug 24 13:23:44.193: INFO: (18) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 21.737167ms)
Aug 24 13:23:44.194: INFO: (18) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 22.497801ms)
Aug 24 13:23:44.194: INFO: (18) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 21.081658ms)
Aug 24 13:23:44.196: INFO: (18) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 24.13854ms)
Aug 24 13:23:44.197: INFO: (18) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 24.743975ms)
Aug 24 13:23:44.199: INFO: (18) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 29.360476ms)
Aug 24 13:23:44.199: INFO: (18) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 28.033187ms)
Aug 24 13:23:44.200: INFO: (18) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 28.78541ms)
Aug 24 13:23:44.200: INFO: (18) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 29.769307ms)
Aug 24 13:23:44.214: INFO: (19) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname2/proxy/: tls qux (200; 14.244871ms)
Aug 24 13:23:44.215: INFO: (19) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 15.080575ms)
Aug 24 13:23:44.220: INFO: (19) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">... (200; 19.069386ms)
Aug 24 13:23:44.220: INFO: (19) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:1080/proxy/rewriteme">test<... (200; 19.237563ms)
Aug 24 13:23:44.220: INFO: (19) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:162/proxy/: bar (200; 19.45316ms)
Aug 24 13:23:44.222: INFO: (19) /api/v1/namespaces/proxy-5339/services/https:proxy-service-v5hgb:tlsportname1/proxy/: tls baz (200; 21.410894ms)
Aug 24 13:23:44.222: INFO: (19) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:460/proxy/: tls baz (200; 20.998131ms)
Aug 24 13:23:44.222: INFO: (19) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname1/proxy/: foo (200; 21.558063ms)
Aug 24 13:23:44.223: INFO: (19) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:443/proxy/tlsrewritem... (200; 22.083638ms)
Aug 24 13:23:44.223: INFO: (19) /api/v1/namespaces/proxy-5339/pods/https:proxy-service-v5hgb-dz5sk:462/proxy/: tls qux (200; 22.643092ms)
Aug 24 13:23:44.225: INFO: (19) /api/v1/namespaces/proxy-5339/pods/http:proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 24.242624ms)
Aug 24 13:23:44.226: INFO: (19) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk:160/proxy/: foo (200; 24.521452ms)
Aug 24 13:23:44.225: INFO: (19) /api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/: <a href="/api/v1/namespaces/proxy-5339/pods/proxy-service-v5hgb-dz5sk/proxy/rewriteme">test</a> (200; 24.654622ms)
Aug 24 13:23:44.229: INFO: (19) /api/v1/namespaces/proxy-5339/services/http:proxy-service-v5hgb:portname2/proxy/: bar (200; 28.550802ms)
Aug 24 13:23:44.230: INFO: (19) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname1/proxy/: foo (200; 28.62312ms)
Aug 24 13:23:44.230: INFO: (19) /api/v1/namespaces/proxy-5339/services/proxy-service-v5hgb:portname2/proxy/: bar (200; 28.616941ms)
STEP: deleting ReplicationController proxy-service-v5hgb in namespace proxy-5339, will wait for the garbage collector to delete the pods
Aug 24 13:23:44.303: INFO: Deleting ReplicationController proxy-service-v5hgb took: 15.24493ms
Aug 24 13:23:44.403: INFO: Terminating ReplicationController proxy-service-v5hgb pods took: 100.586594ms
[AfterEach] version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:23:46.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5339" for this suite.

• [SLOW TEST:5.211 seconds]
[sig-network] Proxy
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  version v1
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":346,"completed":336,"skipped":6509,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:23:46.643: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-549.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-549.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-549.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-549.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-549.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-549.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-549.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-549.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 24 13:23:48.796: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:48.805: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:48.812: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:48.819: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:48.825: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:48.831: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:48.837: INFO: Unable to read jessie_udp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:48.843: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:48.843: INFO: Lookups using dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local wheezy_udp@dns-test-service-2.dns-549.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-549.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local jessie_udp@dns-test-service-2.dns-549.svc.cluster.local jessie_tcp@dns-test-service-2.dns-549.svc.cluster.local]

Aug 24 13:23:53.854: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:53.859: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:53.864: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:53.869: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:53.874: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:53.882: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:53.887: INFO: Unable to read jessie_udp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:53.897: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:53.897: INFO: Lookups using dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local wheezy_udp@dns-test-service-2.dns-549.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-549.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local jessie_udp@dns-test-service-2.dns-549.svc.cluster.local jessie_tcp@dns-test-service-2.dns-549.svc.cluster.local]

Aug 24 13:23:58.852: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:58.858: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:58.863: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:58.868: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:58.873: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:58.878: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:58.883: INFO: Unable to read jessie_udp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:58.888: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:23:58.888: INFO: Lookups using dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local wheezy_udp@dns-test-service-2.dns-549.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-549.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local jessie_udp@dns-test-service-2.dns-549.svc.cluster.local jessie_tcp@dns-test-service-2.dns-549.svc.cluster.local]

Aug 24 13:24:03.851: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:03.858: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:03.865: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:03.871: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:03.877: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:03.883: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:03.889: INFO: Unable to read jessie_udp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:03.895: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:03.895: INFO: Lookups using dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local wheezy_udp@dns-test-service-2.dns-549.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-549.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local jessie_udp@dns-test-service-2.dns-549.svc.cluster.local jessie_tcp@dns-test-service-2.dns-549.svc.cluster.local]

Aug 24 13:24:08.853: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:08.858: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:08.863: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:08.870: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:08.875: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:08.879: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:08.885: INFO: Unable to read jessie_udp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:08.891: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:08.891: INFO: Lookups using dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local wheezy_udp@dns-test-service-2.dns-549.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-549.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local jessie_udp@dns-test-service-2.dns-549.svc.cluster.local jessie_tcp@dns-test-service-2.dns-549.svc.cluster.local]

Aug 24 13:24:13.854: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:13.862: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:13.869: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:13.876: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:13.885: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:13.896: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:13.909: INFO: Unable to read jessie_udp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:13.919: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-549.svc.cluster.local from pod dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d: the server could not find the requested resource (get pods dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d)
Aug 24 13:24:13.919: INFO: Lookups using dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local wheezy_udp@dns-test-service-2.dns-549.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-549.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-549.svc.cluster.local jessie_udp@dns-test-service-2.dns-549.svc.cluster.local jessie_tcp@dns-test-service-2.dns-549.svc.cluster.local]

Aug 24 13:24:18.884: INFO: DNS probes using dns-549/dns-test-ad23b30d-3d67-46f0-917d-82e99093f66d succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:24:18.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-549" for this suite.

• [SLOW TEST:32.361 seconds]
[sig-network] DNS
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":346,"completed":337,"skipped":6512,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:36
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:24:19.005: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/sysctl.go:65
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod with one valid and two invalid sysctls
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:24:19.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-8005" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":346,"completed":338,"skipped":6530,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:24:19.069: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/node/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
Aug 24 13:24:19.131: INFO: The status of Pod busybox-host-aliases4c4b20f6-49c2-439a-9dcf-5297c7b41ade is Pending, waiting for it to be Running (with Ready = true)
Aug 24 13:24:21.152: INFO: The status of Pod busybox-host-aliases4c4b20f6-49c2-439a-9dcf-5297c7b41ade is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:24:21.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1606" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":346,"completed":339,"skipped":6538,"failed":0}
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:24:21.209: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:90
Aug 24 13:24:21.261: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 24 13:24:21.282: INFO: Waiting for terminating namespaces to be deleted...
Aug 24 13:24:21.288: INFO: 
Logging pods the apiserver thinks is on node zou9eicaeree-1 before test
Aug 24 13:24:21.299: INFO: kube-flannel-ds-7bf94 from kube-flannel started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.299: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 24 13:24:21.299: INFO: coredns-bd6b6df9f-8wkdm from kube-system started at 2022-08-24 12:03:41 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.299: INFO: 	Container coredns ready: true, restart count 0
Aug 24 13:24:21.299: INFO: kube-addon-manager-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.299: INFO: 	Container kube-addon-manager ready: true, restart count 2
Aug 24 13:24:21.299: INFO: kube-apiserver-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.299: INFO: 	Container kube-apiserver ready: true, restart count 3
Aug 24 13:24:21.299: INFO: kube-controller-manager-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.299: INFO: 	Container kube-controller-manager ready: true, restart count 3
Aug 24 13:24:21.299: INFO: kube-proxy-ppn7b from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.299: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 24 13:24:21.299: INFO: kube-scheduler-zou9eicaeree-1 from kube-system started at 2022-08-24 11:41:07 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.300: INFO: 	Container kube-scheduler ready: true, restart count 3
Aug 24 13:24:21.300: INFO: sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-8pdr5 from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 13:24:21.300: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 13:24:21.300: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 13:24:21.300: INFO: 
Logging pods the apiserver thinks is on node zou9eicaeree-2 before test
Aug 24 13:24:21.312: INFO: kube-flannel-ds-5z9q7 from kube-flannel started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.312: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 24 13:24:21.312: INFO: coredns-bd6b6df9f-cqzkx from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.312: INFO: 	Container coredns ready: true, restart count 0
Aug 24 13:24:21.312: INFO: kube-addon-manager-zou9eicaeree-2 from kube-system started at 2022-08-24 11:41:08 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.312: INFO: 	Container kube-addon-manager ready: true, restart count 2
Aug 24 13:24:21.312: INFO: kube-apiserver-zou9eicaeree-2 from kube-system started at 2022-08-24 09:21:45 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.312: INFO: 	Container kube-apiserver ready: true, restart count 3
Aug 24 13:24:21.312: INFO: kube-controller-manager-zou9eicaeree-2 from kube-system started at 2022-08-24 11:41:08 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.312: INFO: 	Container kube-controller-manager ready: true, restart count 4
Aug 24 13:24:21.312: INFO: kube-proxy-brwdv from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.312: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 24 13:24:21.312: INFO: kube-scheduler-zou9eicaeree-2 from kube-system started at 2022-08-24 11:41:08 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.312: INFO: 	Container kube-scheduler ready: true, restart count 4
Aug 24 13:24:21.312: INFO: sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-549ck from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 13:24:21.312: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 13:24:21.312: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 24 13:24:21.312: INFO: 
Logging pods the apiserver thinks is on node zou9eicaeree-3 before test
Aug 24 13:24:21.328: INFO: kube-flannel-ds-zt7p4 from kube-flannel started at 2022-08-24 12:06:15 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.328: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 24 13:24:21.328: INFO: kube-proxy-qn7vg from kube-system started at 2022-08-24 11:41:50 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.328: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 24 13:24:21.328: INFO: busybox-host-aliases4c4b20f6-49c2-439a-9dcf-5297c7b41ade from kubelet-test-1606 started at 2022-08-24 13:24:19 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.328: INFO: 	Container busybox-host-aliases4c4b20f6-49c2-439a-9dcf-5297c7b41ade ready: true, restart count 0
Aug 24 13:24:21.328: INFO: sonobuoy from sonobuoy started at 2022-08-24 11:47:10 +0000 UTC (1 container statuses recorded)
Aug 24 13:24:21.328: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 24 13:24:21.328: INFO: sonobuoy-e2e-job-4d9551b899414778 from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 13:24:21.328: INFO: 	Container e2e ready: true, restart count 0
Aug 24 13:24:21.328: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 13:24:21.328: INFO: sonobuoy-systemd-logs-daemon-set-aa45357d809148bb-n4sbd from sonobuoy started at 2022-08-24 11:47:11 +0000 UTC (2 container statuses recorded)
Aug 24 13:24:21.328: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 24 13:24:21.328: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-91e0e6d7-41ca-45b9-a450-b1d4f8dbd6ac 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-91e0e6d7-41ca-45b9-a450-b1d4f8dbd6ac off the node zou9eicaeree-3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-91e0e6d7-41ca-45b9-a450-b1d4f8dbd6ac
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:24:25.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3497" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":346,"completed":340,"skipped":6541,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:24:25.515: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Aug 24 13:24:27.144: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Aug 24 13:24:30.201: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:24:30.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-424" for this suite.
STEP: Destroying namespace "webhook-424-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":346,"completed":341,"skipped":6600,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:24:30.342: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:41
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating the pod
Aug 24 13:24:30.422: INFO: The status of Pod annotationupdatea7a23503-9974-4710-91c9-14b949d8fdbf is Pending, waiting for it to be Running (with Ready = true)
Aug 24 13:24:32.438: INFO: The status of Pod annotationupdatea7a23503-9974-4710-91c9-14b949d8fdbf is Running (Ready = true)
Aug 24 13:24:32.981: INFO: Successfully updated pod "annotationupdatea7a23503-9974-4710-91c9-14b949d8fdbf"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:24:37.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-431" for this suite.

• [SLOW TEST:6.719 seconds]
[sig-storage] Projected downwardAPI
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":346,"completed":342,"skipped":6621,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:24:37.062: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Excluded:WindowsDocker] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating pod pod-subpath-test-projected-27ms
STEP: Creating a pod to test atomic-volume-subpath
Aug 24 13:24:37.172: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-27ms" in namespace "subpath-6422" to be "Succeeded or Failed"
Aug 24 13:24:37.181: INFO: Pod "pod-subpath-test-projected-27ms": Phase="Pending", Reason="", readiness=false. Elapsed: 8.183917ms
Aug 24 13:24:39.190: INFO: Pod "pod-subpath-test-projected-27ms": Phase="Running", Reason="", readiness=true. Elapsed: 2.017426855s
Aug 24 13:24:41.206: INFO: Pod "pod-subpath-test-projected-27ms": Phase="Running", Reason="", readiness=true. Elapsed: 4.03369406s
Aug 24 13:24:43.221: INFO: Pod "pod-subpath-test-projected-27ms": Phase="Running", Reason="", readiness=true. Elapsed: 6.048244818s
Aug 24 13:24:45.233: INFO: Pod "pod-subpath-test-projected-27ms": Phase="Running", Reason="", readiness=true. Elapsed: 8.060137249s
Aug 24 13:24:47.249: INFO: Pod "pod-subpath-test-projected-27ms": Phase="Running", Reason="", readiness=true. Elapsed: 10.076586174s
Aug 24 13:24:49.258: INFO: Pod "pod-subpath-test-projected-27ms": Phase="Running", Reason="", readiness=true. Elapsed: 12.08583326s
Aug 24 13:24:51.273: INFO: Pod "pod-subpath-test-projected-27ms": Phase="Running", Reason="", readiness=true. Elapsed: 14.100395877s
Aug 24 13:24:53.287: INFO: Pod "pod-subpath-test-projected-27ms": Phase="Running", Reason="", readiness=true. Elapsed: 16.114984021s
Aug 24 13:24:55.300: INFO: Pod "pod-subpath-test-projected-27ms": Phase="Running", Reason="", readiness=true. Elapsed: 18.127220602s
Aug 24 13:24:57.315: INFO: Pod "pod-subpath-test-projected-27ms": Phase="Running", Reason="", readiness=true. Elapsed: 20.142477584s
Aug 24 13:24:59.325: INFO: Pod "pod-subpath-test-projected-27ms": Phase="Running", Reason="", readiness=false. Elapsed: 22.152387515s
Aug 24 13:25:01.339: INFO: Pod "pod-subpath-test-projected-27ms": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.166180102s
STEP: Saw pod success
Aug 24 13:25:01.339: INFO: Pod "pod-subpath-test-projected-27ms" satisfied condition "Succeeded or Failed"
Aug 24 13:25:01.345: INFO: Trying to get logs from node zou9eicaeree-3 pod pod-subpath-test-projected-27ms container test-container-subpath-projected-27ms: <nil>
STEP: delete the pod
Aug 24 13:25:01.383: INFO: Waiting for pod pod-subpath-test-projected-27ms to disappear
Aug 24 13:25:01.388: INFO: Pod pod-subpath-test-projected-27ms no longer exists
STEP: Deleting pod pod-subpath-test-projected-27ms
Aug 24 13:25:01.389: INFO: Deleting pod "pod-subpath-test-projected-27ms" in namespace "subpath-6422"
[AfterEach] [sig-storage] Subpath
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:25:01.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6422" for this suite.

• [SLOW TEST:24.358 seconds]
[sig-storage] Subpath
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Excluded:WindowsDocker] [Conformance]
    /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Excluded:WindowsDocker] [Conformance]","total":346,"completed":343,"skipped":6644,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:25:01.422: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:752
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: creating service in namespace services-2884
STEP: creating service affinity-clusterip-transition in namespace services-2884
STEP: creating replication controller affinity-clusterip-transition in namespace services-2884
I0824 13:25:01.569906      16 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2884, replica count: 3
I0824 13:25:04.621114      16 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 24 13:25:04.653: INFO: Creating new exec pod
Aug 24 13:25:07.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2884 exec execpod-affinityzp6pj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Aug 24 13:25:07.973: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Aug 24 13:25:07.973: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 13:25:07.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2884 exec execpod-affinityzp6pj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.52.226 80'
Aug 24 13:25:08.204: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.52.226 80\nConnection to 10.233.52.226 80 port [tcp/http] succeeded!\n"
Aug 24 13:25:08.204: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Aug 24 13:25:08.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2884 exec execpod-affinityzp6pj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.52.226:80/ ; done'
Aug 24 13:25:08.737: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n"
Aug 24 13:25:08.738: INFO: stdout: "\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-gnz7n\naffinity-clusterip-transition-558wx\naffinity-clusterip-transition-gnz7n\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-558wx\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-gnz7n\naffinity-clusterip-transition-558wx\naffinity-clusterip-transition-558wx\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr"
Aug 24 13:25:08.738: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:08.738: INFO: Received response from host: affinity-clusterip-transition-gnz7n
Aug 24 13:25:08.738: INFO: Received response from host: affinity-clusterip-transition-558wx
Aug 24 13:25:08.738: INFO: Received response from host: affinity-clusterip-transition-gnz7n
Aug 24 13:25:08.738: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:08.738: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:08.738: INFO: Received response from host: affinity-clusterip-transition-558wx
Aug 24 13:25:08.738: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:08.738: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:08.738: INFO: Received response from host: affinity-clusterip-transition-gnz7n
Aug 24 13:25:08.738: INFO: Received response from host: affinity-clusterip-transition-558wx
Aug 24 13:25:08.738: INFO: Received response from host: affinity-clusterip-transition-558wx
Aug 24 13:25:08.739: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:08.739: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:08.739: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:08.739: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:08.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1983584402 --namespace=services-2884 exec execpod-affinityzp6pj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.52.226:80/ ; done'
Aug 24 13:25:09.193: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.52.226:80/\n"
Aug 24 13:25:09.193: INFO: stdout: "\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr\naffinity-clusterip-transition-sgcnr"
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Received response from host: affinity-clusterip-transition-sgcnr
Aug 24 13:25:09.193: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2884, will wait for the garbage collector to delete the pods
Aug 24 13:25:09.322: INFO: Deleting ReplicationController affinity-clusterip-transition took: 10.975739ms
Aug 24 13:25:09.423: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.036245ms
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:25:11.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2884" for this suite.
[AfterEach] [sig-network] Services
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:756

• [SLOW TEST:10.299 seconds]
[sig-network] Services
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","total":346,"completed":344,"skipped":6658,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:25:11.722: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:41
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Creating a pod to test downward API volume plugin
Aug 24 13:25:11.796: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec0f389d-10ff-4e2a-8d39-c9a3c2f7900f" in namespace "downward-api-8917" to be "Succeeded or Failed"
Aug 24 13:25:11.814: INFO: Pod "downwardapi-volume-ec0f389d-10ff-4e2a-8d39-c9a3c2f7900f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.25401ms
Aug 24 13:25:13.827: INFO: Pod "downwardapi-volume-ec0f389d-10ff-4e2a-8d39-c9a3c2f7900f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031042722s
Aug 24 13:25:15.843: INFO: Pod "downwardapi-volume-ec0f389d-10ff-4e2a-8d39-c9a3c2f7900f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047544955s
STEP: Saw pod success
Aug 24 13:25:15.843: INFO: Pod "downwardapi-volume-ec0f389d-10ff-4e2a-8d39-c9a3c2f7900f" satisfied condition "Succeeded or Failed"
Aug 24 13:25:15.850: INFO: Trying to get logs from node zou9eicaeree-3 pod downwardapi-volume-ec0f389d-10ff-4e2a-8d39-c9a3c2f7900f container client-container: <nil>
STEP: delete the pod
Aug 24 13:25:15.883: INFO: Waiting for pod downwardapi-volume-ec0f389d-10ff-4e2a-8d39-c9a3c2f7900f to disappear
Aug 24 13:25:15.889: INFO: Pod downwardapi-volume-ec0f389d-10ff-4e2a-8d39-c9a3c2f7900f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:25:15.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8917" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":346,"completed":345,"skipped":6695,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:185
STEP: Creating a kubernetes client
Aug 24 13:25:15.909: INFO: >>> kubeConfig: /tmp/kubeconfig-1983584402
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:186
Aug 24 13:25:44.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1101" for this suite.

• [SLOW TEST:28.185 seconds]
[sig-api-machinery] ResourceQuota
/workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:633
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":346,"completed":346,"skipped":6703,"failed":0}
SAug 24 13:25:44.095: INFO: Running AfterSuite actions on all nodes
Aug 24 13:25:44.095: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func18.2
Aug 24 13:25:44.095: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func8.2
Aug 24 13:25:44.096: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func7.2
Aug 24 13:25:44.096: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Aug 24 13:25:44.096: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Aug 24 13:25:44.096: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Aug 24 13:25:44.096: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
Aug 24 13:25:44.096: INFO: Running AfterSuite actions on node 1
Aug 24 13:25:44.096: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/sonobuoy/results/junit_01.xml
{"msg":"Test Suite completed","total":346,"completed":346,"skipped":6704,"failed":0}

Ran 346 of 7050 Specs in 5907.577 seconds
SUCCESS! -- 346 Passed | 0 Failed | 0 Pending | 6704 Skipped
PASS

Ginkgo ran 1 suite in 1h38m32.125662575s
Test Suite Passed
