I1025 01:39:53.192558      18 e2e.go:129] Starting e2e run "00d69ad5-ea54-47cd-b701-0540ff718100" on Ginkgo node 1
{"msg":"Test Suite starting","total":356,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1666661993 - Will randomize all specs
Will run 356 of 6973 specs

Oct 25 01:39:54.659: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 01:39:54.661: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
E1025 01:39:54.662018      18 progress.go:119] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
Oct 25 01:39:55.771: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct 25 01:40:01.445: INFO: The status of Pod openstack-cloud-controller-manager-27jr7 is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct 25 01:40:01.445: INFO: 45 / 46 pods in namespace 'kube-system' are running and ready (5 seconds elapsed)
Oct 25 01:40:01.445: INFO: expected 7 pod replicas in namespace 'kube-system', 7 are Running and Ready.
Oct 25 01:40:01.445: INFO: POD                                       NODE               PHASE    GRACE  CONDITIONS
Oct 25 01:40:01.445: INFO: openstack-cloud-controller-manager-27jr7  lab1-k8s-master-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-24 11:12:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:39:58 +0000 UTC ContainersNotReady containers with unready status: [openstack-cloud-controller-manager]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:39:58 +0000 UTC ContainersNotReady containers with unready status: [openstack-cloud-controller-manager]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-24 11:12:57 +0000 UTC  }]
Oct 25 01:40:01.446: INFO: 
Oct 25 01:40:03.953: INFO: 46 / 46 pods in namespace 'kube-system' are running and ready (8 seconds elapsed)
Oct 25 01:40:03.953: INFO: expected 7 pod replicas in namespace 'kube-system', 7 are Running and Ready.
Oct 25 01:40:03.953: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct 25 01:40:03.962: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Oct 25 01:40:03.963: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'csi-cinder-nodeplugin' (0 seconds elapsed)
Oct 25 01:40:03.963: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Oct 25 01:40:03.963: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'nodelocaldns' (0 seconds elapsed)
Oct 25 01:40:03.963: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'openstack-cloud-controller-manager' (0 seconds elapsed)
Oct 25 01:40:03.963: INFO: e2e test version: v1.24.6
Oct 25 01:40:03.964: INFO: kube-apiserver version: v1.24.6
Oct 25 01:40:03.964: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 01:40:03.970: INFO: Cluster IP family: ipv4
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:40:03.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
W1025 01:40:04.018643      18 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
Oct 25 01:40:04.018: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-0cd27d83-dffd-470d-96d8-e070d82c17be
STEP: Creating a pod to test consume secrets
Oct 25 01:40:04.054: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7d35f69a-f55a-4866-aab0-3a20b1494ef2" in namespace "projected-9537" to be "Succeeded or Failed"
Oct 25 01:40:04.062: INFO: Pod "pod-projected-secrets-7d35f69a-f55a-4866-aab0-3a20b1494ef2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.196237ms
Oct 25 01:40:06.077: INFO: Pod "pod-projected-secrets-7d35f69a-f55a-4866-aab0-3a20b1494ef2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022792538s
Oct 25 01:40:08.090: INFO: Pod "pod-projected-secrets-7d35f69a-f55a-4866-aab0-3a20b1494ef2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035510607s
Oct 25 01:40:10.100: INFO: Pod "pod-projected-secrets-7d35f69a-f55a-4866-aab0-3a20b1494ef2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.045891466s
Oct 25 01:40:12.114: INFO: Pod "pod-projected-secrets-7d35f69a-f55a-4866-aab0-3a20b1494ef2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.059298325s
STEP: Saw pod success
Oct 25 01:40:12.114: INFO: Pod "pod-projected-secrets-7d35f69a-f55a-4866-aab0-3a20b1494ef2" satisfied condition "Succeeded or Failed"
Oct 25 01:40:12.120: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-projected-secrets-7d35f69a-f55a-4866-aab0-3a20b1494ef2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 25 01:40:12.174: INFO: Waiting for pod pod-projected-secrets-7d35f69a-f55a-4866-aab0-3a20b1494ef2 to disappear
Oct 25 01:40:12.181: INFO: Pod pod-projected-secrets-7d35f69a-f55a-4866-aab0-3a20b1494ef2 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Oct 25 01:40:12.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9537" for this suite.

• [SLOW TEST:8.241 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":1,"skipped":0,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:40:12.211: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 01:40:12.607: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 01:40:15.664: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 01:40:15.673: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 01:40:23.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4199" for this suite.
STEP: Destroying namespace "webhook-4199-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:11.800 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":356,"completed":2,"skipped":7,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Security Context 
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:40:24.011: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Oct 25 01:40:24.069: INFO: Waiting up to 5m0s for pod "security-context-3aa4c29d-c0ae-4b51-bb58-ae63bb828d1f" in namespace "security-context-3705" to be "Succeeded or Failed"
Oct 25 01:40:24.075: INFO: Pod "security-context-3aa4c29d-c0ae-4b51-bb58-ae63bb828d1f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.353759ms
Oct 25 01:40:26.088: INFO: Pod "security-context-3aa4c29d-c0ae-4b51-bb58-ae63bb828d1f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018335178s
Oct 25 01:40:28.101: INFO: Pod "security-context-3aa4c29d-c0ae-4b51-bb58-ae63bb828d1f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031734625s
Oct 25 01:40:30.113: INFO: Pod "security-context-3aa4c29d-c0ae-4b51-bb58-ae63bb828d1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043429237s
STEP: Saw pod success
Oct 25 01:40:30.113: INFO: Pod "security-context-3aa4c29d-c0ae-4b51-bb58-ae63bb828d1f" satisfied condition "Succeeded or Failed"
Oct 25 01:40:30.118: INFO: Trying to get logs from node lab1-k8s-node-3 pod security-context-3aa4c29d-c0ae-4b51-bb58-ae63bb828d1f container test-container: <nil>
STEP: delete the pod
Oct 25 01:40:30.177: INFO: Waiting for pod security-context-3aa4c29d-c0ae-4b51-bb58-ae63bb828d1f to disappear
Oct 25 01:40:30.183: INFO: Pod security-context-3aa4c29d-c0ae-4b51-bb58-ae63bb828d1f no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Oct 25 01:40:30.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-3705" for this suite.

• [SLOW TEST:7.787 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":356,"completed":3,"skipped":18,"failed":0}
SSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:40:31.798: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with one valid and two invalid sysctls
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:188
Oct 25 01:40:40.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-8839" for this suite.

• [SLOW TEST:8.814 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":356,"completed":4,"skipped":22,"failed":0}
[sig-node] RuntimeClass 
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:40:40.612: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Oct 25 01:40:42.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7692" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","total":356,"completed":5,"skipped":22,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:40:42.791: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-map-05e40ba5-7381-4691-b3eb-e6b98aa313d7
STEP: Creating a pod to test consume secrets
Oct 25 01:40:42.857: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5c053fb9-3f09-4ab8-b602-2312f1395a64" in namespace "projected-2268" to be "Succeeded or Failed"
Oct 25 01:40:42.866: INFO: Pod "pod-projected-secrets-5c053fb9-3f09-4ab8-b602-2312f1395a64": Phase="Pending", Reason="", readiness=false. Elapsed: 8.63442ms
Oct 25 01:40:44.878: INFO: Pod "pod-projected-secrets-5c053fb9-3f09-4ab8-b602-2312f1395a64": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021569703s
Oct 25 01:40:46.897: INFO: Pod "pod-projected-secrets-5c053fb9-3f09-4ab8-b602-2312f1395a64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039756997s
STEP: Saw pod success
Oct 25 01:40:46.897: INFO: Pod "pod-projected-secrets-5c053fb9-3f09-4ab8-b602-2312f1395a64" satisfied condition "Succeeded or Failed"
Oct 25 01:40:46.903: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-projected-secrets-5c053fb9-3f09-4ab8-b602-2312f1395a64 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 25 01:40:46.937: INFO: Waiting for pod pod-projected-secrets-5c053fb9-3f09-4ab8-b602-2312f1395a64 to disappear
Oct 25 01:40:46.944: INFO: Pod pod-projected-secrets-5c053fb9-3f09-4ab8-b602-2312f1395a64 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Oct 25 01:40:46.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2268" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":6,"skipped":46,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:40:46.969: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5445
[It] should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating statefulset ss in namespace statefulset-5445
Oct 25 01:40:47.054: INFO: Found 0 stateful pods, waiting for 1
Oct 25 01:40:57.084: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
STEP: Patch a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct 25 01:40:57.165: INFO: Deleting all statefulset in ns statefulset-5445
Oct 25 01:40:57.171: INFO: Scaling statefulset ss to 0
Oct 25 01:41:07.257: INFO: Waiting for statefulset status.replicas updated to 0
Oct 25 01:41:07.262: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Oct 25 01:41:07.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5445" for this suite.

• [SLOW TEST:20.345 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":356,"completed":7,"skipped":56,"failed":0}
SSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:41:07.314: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:297
[It] should scale a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a replication controller
Oct 25 01:41:07.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 create -f -'
Oct 25 01:41:08.740: INFO: stderr: ""
Oct 25 01:41:08.740: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 25 01:41:08.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 25 01:41:08.805: INFO: stderr: ""
Oct 25 01:41:08.805: INFO: stdout: "update-demo-nautilus-8jzrx update-demo-nautilus-z9lnk "
Oct 25 01:41:08.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods update-demo-nautilus-8jzrx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 25 01:41:08.876: INFO: stderr: ""
Oct 25 01:41:08.876: INFO: stdout: ""
Oct 25 01:41:08.876: INFO: update-demo-nautilus-8jzrx is created but not running
Oct 25 01:41:13.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 25 01:41:13.940: INFO: stderr: ""
Oct 25 01:41:13.941: INFO: stdout: "update-demo-nautilus-8jzrx update-demo-nautilus-z9lnk "
Oct 25 01:41:13.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods update-demo-nautilus-8jzrx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 25 01:41:14.003: INFO: stderr: ""
Oct 25 01:41:14.003: INFO: stdout: "true"
Oct 25 01:41:14.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods update-demo-nautilus-8jzrx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct 25 01:41:14.071: INFO: stderr: ""
Oct 25 01:41:14.071: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Oct 25 01:41:14.071: INFO: validating pod update-demo-nautilus-8jzrx
Oct 25 01:41:14.081: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 25 01:41:14.081: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 25 01:41:14.081: INFO: update-demo-nautilus-8jzrx is verified up and running
Oct 25 01:41:14.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods update-demo-nautilus-z9lnk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 25 01:41:14.134: INFO: stderr: ""
Oct 25 01:41:14.134: INFO: stdout: "true"
Oct 25 01:41:14.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods update-demo-nautilus-z9lnk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct 25 01:41:14.189: INFO: stderr: ""
Oct 25 01:41:14.189: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Oct 25 01:41:14.189: INFO: validating pod update-demo-nautilus-z9lnk
Oct 25 01:41:14.199: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 25 01:41:14.199: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 25 01:41:14.199: INFO: update-demo-nautilus-z9lnk is verified up and running
STEP: scaling down the replication controller
Oct 25 01:41:14.200: INFO: scanned /root for discovery docs: <nil>
Oct 25 01:41:14.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Oct 25 01:41:15.293: INFO: stderr: ""
Oct 25 01:41:15.293: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 25 01:41:15.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 25 01:41:15.385: INFO: stderr: ""
Oct 25 01:41:15.385: INFO: stdout: "update-demo-nautilus-8jzrx update-demo-nautilus-z9lnk "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 25 01:41:20.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 25 01:41:20.456: INFO: stderr: ""
Oct 25 01:41:20.456: INFO: stdout: "update-demo-nautilus-z9lnk "
Oct 25 01:41:20.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods update-demo-nautilus-z9lnk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 25 01:41:20.517: INFO: stderr: ""
Oct 25 01:41:20.517: INFO: stdout: "true"
Oct 25 01:41:20.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods update-demo-nautilus-z9lnk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct 25 01:41:20.581: INFO: stderr: ""
Oct 25 01:41:20.581: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Oct 25 01:41:20.581: INFO: validating pod update-demo-nautilus-z9lnk
Oct 25 01:41:20.589: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 25 01:41:20.589: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 25 01:41:20.589: INFO: update-demo-nautilus-z9lnk is verified up and running
STEP: scaling up the replication controller
Oct 25 01:41:20.590: INFO: scanned /root for discovery docs: <nil>
Oct 25 01:41:20.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Oct 25 01:41:21.686: INFO: stderr: ""
Oct 25 01:41:21.686: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 25 01:41:21.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 25 01:41:21.753: INFO: stderr: ""
Oct 25 01:41:21.753: INFO: stdout: "update-demo-nautilus-jwrx9 update-demo-nautilus-z9lnk "
Oct 25 01:41:21.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods update-demo-nautilus-jwrx9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 25 01:41:21.817: INFO: stderr: ""
Oct 25 01:41:21.817: INFO: stdout: ""
Oct 25 01:41:21.817: INFO: update-demo-nautilus-jwrx9 is created but not running
Oct 25 01:41:26.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 25 01:41:26.889: INFO: stderr: ""
Oct 25 01:41:26.889: INFO: stdout: "update-demo-nautilus-jwrx9 update-demo-nautilus-z9lnk "
Oct 25 01:41:26.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods update-demo-nautilus-jwrx9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 25 01:41:26.960: INFO: stderr: ""
Oct 25 01:41:26.960: INFO: stdout: "true"
Oct 25 01:41:26.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods update-demo-nautilus-jwrx9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct 25 01:41:27.041: INFO: stderr: ""
Oct 25 01:41:27.041: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Oct 25 01:41:27.041: INFO: validating pod update-demo-nautilus-jwrx9
Oct 25 01:41:27.054: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 25 01:41:27.054: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 25 01:41:27.054: INFO: update-demo-nautilus-jwrx9 is verified up and running
Oct 25 01:41:27.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods update-demo-nautilus-z9lnk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 25 01:41:27.113: INFO: stderr: ""
Oct 25 01:41:27.113: INFO: stdout: "true"
Oct 25 01:41:27.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods update-demo-nautilus-z9lnk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct 25 01:41:27.172: INFO: stderr: ""
Oct 25 01:41:27.172: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Oct 25 01:41:27.172: INFO: validating pod update-demo-nautilus-z9lnk
Oct 25 01:41:27.180: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 25 01:41:27.180: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 25 01:41:27.180: INFO: update-demo-nautilus-z9lnk is verified up and running
STEP: using delete to clean up resources
Oct 25 01:41:27.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 delete --grace-period=0 --force -f -'
Oct 25 01:41:27.248: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 25 01:41:27.248: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 25 01:41:27.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get rc,svc -l name=update-demo --no-headers'
Oct 25 01:41:27.332: INFO: stderr: "No resources found in kubectl-3220 namespace.\n"
Oct 25 01:41:27.332: INFO: stdout: ""
Oct 25 01:41:27.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3220 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 25 01:41:27.463: INFO: stderr: ""
Oct 25 01:41:27.463: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 01:41:27.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3220" for this suite.

• [SLOW TEST:20.180 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:295
    should scale a replication controller  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":356,"completed":8,"skipped":63,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:41:27.495: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Oct 25 01:41:37.665: INFO: The status of Pod kube-controller-manager-lab1-k8s-master-3 is Running (Ready = true)
Oct 25 01:41:37.755: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Oct 25 01:41:37.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1559" for this suite.

• [SLOW TEST:10.290 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":356,"completed":9,"skipped":111,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:41:37.785: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1334
STEP: creating the pod
Oct 25 01:41:37.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6661 create -f -'
Oct 25 01:41:38.692: INFO: stderr: ""
Oct 25 01:41:38.692: INFO: stdout: "pod/pause created\n"
Oct 25 01:41:38.692: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct 25 01:41:38.693: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6661" to be "running and ready"
Oct 25 01:41:38.706: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 13.496611ms
Oct 25 01:41:40.714: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021728575s
Oct 25 01:41:42.727: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.03480633s
Oct 25 01:41:42.727: INFO: Pod "pause" satisfied condition "running and ready"
Oct 25 01:41:42.727: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/framework/framework.go:652
STEP: adding the label testing-label with value testing-label-value to a pod
Oct 25 01:41:42.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6661 label pods pause testing-label=testing-label-value'
Oct 25 01:41:42.804: INFO: stderr: ""
Oct 25 01:41:42.804: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct 25 01:41:42.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6661 get pod pause -L testing-label'
Oct 25 01:41:42.864: INFO: stderr: ""
Oct 25 01:41:42.864: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct 25 01:41:42.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6661 label pods pause testing-label-'
Oct 25 01:41:42.937: INFO: stderr: ""
Oct 25 01:41:42.937: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct 25 01:41:42.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6661 get pod pause -L testing-label'
Oct 25 01:41:43.002: INFO: stderr: ""
Oct 25 01:41:43.002: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1340
STEP: using delete to clean up resources
Oct 25 01:41:43.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6661 delete --grace-period=0 --force -f -'
Oct 25 01:41:43.090: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 25 01:41:43.090: INFO: stdout: "pod \"pause\" force deleted\n"
Oct 25 01:41:43.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6661 get rc,svc -l name=pause --no-headers'
Oct 25 01:41:43.154: INFO: stderr: "No resources found in kubectl-6661 namespace.\n"
Oct 25 01:41:43.154: INFO: stdout: ""
Oct 25 01:41:43.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6661 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 25 01:41:43.220: INFO: stderr: ""
Oct 25 01:41:43.220: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 01:41:43.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6661" for this suite.

• [SLOW TEST:5.458 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1332
    should update the label on a resource  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":356,"completed":10,"skipped":139,"failed":0}
SSSSS
------------------------------
[sig-node] Pods 
  should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:41:43.243: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of pods
Oct 25 01:41:43.294: INFO: created test-pod-1
Oct 25 01:41:43.309: INFO: created test-pod-2
Oct 25 01:41:43.326: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running
Oct 25 01:41:43.326: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-2147' to be running and ready
Oct 25 01:41:43.362: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct 25 01:41:43.362: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct 25 01:41:43.362: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct 25 01:41:43.363: INFO: 0 / 3 pods in namespace 'pods-2147' are running and ready (0 seconds elapsed)
Oct 25 01:41:43.364: INFO: expected 0 pod replicas in namespace 'pods-2147', 0 are Running and Ready.
Oct 25 01:41:43.364: INFO: POD         NODE             PHASE    GRACE  CONDITIONS
Oct 25 01:41:43.364: INFO: test-pod-1  lab1-k8s-node-3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:41:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:41:43 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:41:43 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:41:43 +0000 UTC  }]
Oct 25 01:41:43.364: INFO: test-pod-2  lab1-k8s-node-3  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:41:43 +0000 UTC  }]
Oct 25 01:41:43.364: INFO: test-pod-3  lab1-k8s-node-2  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:41:43 +0000 UTC  }]
Oct 25 01:41:43.364: INFO: 
Oct 25 01:41:45.387: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct 25 01:41:45.387: INFO: 2 / 3 pods in namespace 'pods-2147' are running and ready (2 seconds elapsed)
Oct 25 01:41:45.387: INFO: expected 0 pod replicas in namespace 'pods-2147', 0 are Running and Ready.
Oct 25 01:41:45.387: INFO: POD         NODE             PHASE    GRACE  CONDITIONS
Oct 25 01:41:45.387: INFO: test-pod-3  lab1-k8s-node-2  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:41:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:41:43 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:41:43 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:41:43 +0000 UTC  }]
Oct 25 01:41:45.387: INFO: 
Oct 25 01:41:47.396: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Oct 25 01:41:47.396: INFO: 2 / 3 pods in namespace 'pods-2147' are running and ready (4 seconds elapsed)
Oct 25 01:41:47.396: INFO: expected 0 pod replicas in namespace 'pods-2147', 0 are Running and Ready.
Oct 25 01:41:47.396: INFO: POD         NODE             PHASE    GRACE  CONDITIONS
Oct 25 01:41:47.396: INFO: test-pod-3  lab1-k8s-node-2  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:41:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:41:43 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:41:43 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:41:43 +0000 UTC  }]
Oct 25 01:41:47.396: INFO: 
Oct 25 01:41:49.387: INFO: 3 / 3 pods in namespace 'pods-2147' are running and ready (6 seconds elapsed)
Oct 25 01:41:49.387: INFO: expected 0 pod replicas in namespace 'pods-2147', 0 are Running and Ready.
STEP: waiting for all pods to be deleted
Oct 25 01:41:49.440: INFO: Pod quantity 3 is different from expected quantity 0
Oct 25 01:41:50.451: INFO: Pod quantity 2 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Oct 25 01:41:51.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2147" for this suite.

• [SLOW TEST:8.230 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","total":356,"completed":11,"skipped":144,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:41:51.477: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-c9cb9168-1e8d-4508-87b8-965145796696
STEP: Creating a pod to test consume secrets
Oct 25 01:41:51.531: INFO: Waiting up to 5m0s for pod "pod-secrets-a7f8a1fb-01e3-4321-8da6-19bf8de9433d" in namespace "secrets-9770" to be "Succeeded or Failed"
Oct 25 01:41:51.538: INFO: Pod "pod-secrets-a7f8a1fb-01e3-4321-8da6-19bf8de9433d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.536488ms
Oct 25 01:41:53.550: INFO: Pod "pod-secrets-a7f8a1fb-01e3-4321-8da6-19bf8de9433d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018744805s
Oct 25 01:41:55.562: INFO: Pod "pod-secrets-a7f8a1fb-01e3-4321-8da6-19bf8de9433d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030710918s
STEP: Saw pod success
Oct 25 01:41:55.562: INFO: Pod "pod-secrets-a7f8a1fb-01e3-4321-8da6-19bf8de9433d" satisfied condition "Succeeded or Failed"
Oct 25 01:41:55.568: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-secrets-a7f8a1fb-01e3-4321-8da6-19bf8de9433d container secret-volume-test: <nil>
STEP: delete the pod
Oct 25 01:41:55.605: INFO: Waiting for pod pod-secrets-a7f8a1fb-01e3-4321-8da6-19bf8de9433d to disappear
Oct 25 01:41:55.612: INFO: Pod pod-secrets-a7f8a1fb-01e3-4321-8da6-19bf8de9433d no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Oct 25 01:41:55.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9770" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":12,"skipped":157,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:41:55.636: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Oct 25 01:42:06.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9172" for this suite.

• [SLOW TEST:11.164 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":356,"completed":13,"skipped":162,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:42:06.803: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in container's args
Oct 25 01:42:06.864: INFO: Waiting up to 5m0s for pod "var-expansion-65b3d484-0782-42b7-8a5c-c429989430a6" in namespace "var-expansion-8337" to be "Succeeded or Failed"
Oct 25 01:42:06.870: INFO: Pod "var-expansion-65b3d484-0782-42b7-8a5c-c429989430a6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.569825ms
Oct 25 01:42:08.883: INFO: Pod "var-expansion-65b3d484-0782-42b7-8a5c-c429989430a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01931347s
Oct 25 01:42:10.895: INFO: Pod "var-expansion-65b3d484-0782-42b7-8a5c-c429989430a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030661599s
STEP: Saw pod success
Oct 25 01:42:10.895: INFO: Pod "var-expansion-65b3d484-0782-42b7-8a5c-c429989430a6" satisfied condition "Succeeded or Failed"
Oct 25 01:42:10.901: INFO: Trying to get logs from node lab1-k8s-node-3 pod var-expansion-65b3d484-0782-42b7-8a5c-c429989430a6 container dapi-container: <nil>
STEP: delete the pod
Oct 25 01:42:10.940: INFO: Waiting for pod var-expansion-65b3d484-0782-42b7-8a5c-c429989430a6 to disappear
Oct 25 01:42:10.945: INFO: Pod var-expansion-65b3d484-0782-42b7-8a5c-c429989430a6 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Oct 25 01:42:10.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8337" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":356,"completed":14,"skipped":191,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:42:10.973: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 25 01:42:11.111: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 01:42:11.111: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:42:12.132: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 01:42:12.132: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:42:13.134: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 25 01:42:13.134: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:42:14.137: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 25 01:42:14.137: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:42:15.140: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 25 01:42:15.140: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:42:16.885: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Oct 25 01:42:16.885: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:42:17.146: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct 25 01:42:17.146: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:42:18.133: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct 25 01:42:18.133: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:42:19.130: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Oct 25 01:42:19.130: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:42:20.138: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Oct 25 01:42:20.138: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:42:21.130: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 6
Oct 25 01:42:21.130: INFO: Number of running nodes: 6, number of available pods: 6 in daemonset daemon-set
STEP: Getting /status
Oct 25 01:42:21.144: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status
Oct 25 01:42:21.166: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated
Oct 25 01:42:21.169: INFO: Observed &DaemonSet event: ADDED
Oct 25 01:42:21.169: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.169: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.170: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.170: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.170: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.170: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.170: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.170: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.170: INFO: Found daemon set daemon-set in namespace daemonsets-4286 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Oct 25 01:42:21.170: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status
STEP: watching for the daemon set status to be patched
Oct 25 01:42:21.182: INFO: Observed &DaemonSet event: ADDED
Oct 25 01:42:21.183: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.183: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.183: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.183: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.183: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.183: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.184: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.184: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.184: INFO: Observed daemon set daemon-set in namespace daemonsets-4286 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Oct 25 01:42:21.184: INFO: Observed &DaemonSet event: MODIFIED
Oct 25 01:42:21.184: INFO: Found daemon set daemon-set in namespace daemonsets-4286 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Oct 25 01:42:21.184: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4286, will wait for the garbage collector to delete the pods
Oct 25 01:42:21.265: INFO: Deleting DaemonSet.extensions daemon-set took: 15.857709ms
Oct 25 01:42:21.366: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.09533ms
Oct 25 01:42:28.794: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 01:42:28.794: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct 25 01:42:28.800: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"204294"},"items":null}

Oct 25 01:42:28.806: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"204294"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Oct 25 01:42:28.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4286" for this suite.

• [SLOW TEST:17.902 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","total":356,"completed":15,"skipped":217,"failed":0}
S
------------------------------
[sig-node] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:42:28.874: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test env composition
Oct 25 01:42:28.938: INFO: Waiting up to 5m0s for pod "var-expansion-d7eac1c9-76fb-47d4-8daf-843b0631ac15" in namespace "var-expansion-2897" to be "Succeeded or Failed"
Oct 25 01:42:28.957: INFO: Pod "var-expansion-d7eac1c9-76fb-47d4-8daf-843b0631ac15": Phase="Pending", Reason="", readiness=false. Elapsed: 18.84034ms
Oct 25 01:42:30.968: INFO: Pod "var-expansion-d7eac1c9-76fb-47d4-8daf-843b0631ac15": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029898852s
Oct 25 01:42:32.981: INFO: Pod "var-expansion-d7eac1c9-76fb-47d4-8daf-843b0631ac15": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042283382s
STEP: Saw pod success
Oct 25 01:42:32.981: INFO: Pod "var-expansion-d7eac1c9-76fb-47d4-8daf-843b0631ac15" satisfied condition "Succeeded or Failed"
Oct 25 01:42:32.986: INFO: Trying to get logs from node lab1-k8s-node-3 pod var-expansion-d7eac1c9-76fb-47d4-8daf-843b0631ac15 container dapi-container: <nil>
STEP: delete the pod
Oct 25 01:42:33.032: INFO: Waiting for pod var-expansion-d7eac1c9-76fb-47d4-8daf-843b0631ac15 to disappear
Oct 25 01:42:33.038: INFO: Pod var-expansion-d7eac1c9-76fb-47d4-8daf-843b0631ac15 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Oct 25 01:42:33.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2897" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":356,"completed":16,"skipped":218,"failed":0}

------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:42:33.063: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
STEP: set up a multi version CRD
Oct 25 01:42:33.109: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 01:42:58.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8331" for this suite.

• [SLOW TEST:25.011 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":356,"completed":17,"skipped":218,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:42:58.075: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: reading a file in the container
Oct 25 01:43:00.156: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1748 pod-service-account-ed260a9d-a26b-4d4d-8fea-85df1c8e0fa2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct 25 01:43:00.302: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1748 pod-service-account-ed260a9d-a26b-4d4d-8fea-85df1c8e0fa2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct 25 01:43:00.434: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1748 pod-service-account-ed260a9d-a26b-4d4d-8fea-85df1c8e0fa2 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Oct 25 01:43:00.568: INFO: Got root ca configmap in namespace "svcaccounts-1748"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Oct 25 01:43:00.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1748" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":356,"completed":18,"skipped":237,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:43:00.593: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-d7f6f926-a45a-4ef6-a81a-0c0f2e78038c in namespace container-probe-1520
Oct 25 01:43:02.655: INFO: Started pod liveness-d7f6f926-a45a-4ef6-a81a-0c0f2e78038c in namespace container-probe-1520
STEP: checking the pod's current state and verifying that restartCount is present
Oct 25 01:43:02.659: INFO: Initial restart count of pod liveness-d7f6f926-a45a-4ef6-a81a-0c0f2e78038c is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Oct 25 01:47:03.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1520" for this suite.

• [SLOW TEST:243.302 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":356,"completed":19,"skipped":253,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:47:03.897: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 01:47:03.941: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 01:47:12.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6630" for this suite.

• [SLOW TEST:8.246 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":356,"completed":20,"skipped":266,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:47:12.144: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:84
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Oct 25 01:47:16.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6255" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":356,"completed":21,"skipped":274,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:47:16.232: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should create services for rc  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating Agnhost RC
Oct 25 01:47:16.271: INFO: namespace kubectl-7180
Oct 25 01:47:16.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-7180 create -f -'
Oct 25 01:47:17.493: INFO: stderr: ""
Oct 25 01:47:17.493: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Oct 25 01:47:18.503: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 25 01:47:18.503: INFO: Found 0 / 1
Oct 25 01:47:19.502: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 25 01:47:19.502: INFO: Found 1 / 1
Oct 25 01:47:19.502: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 25 01:47:19.507: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 25 01:47:19.507: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 25 01:47:19.507: INFO: wait on agnhost-primary startup in kubectl-7180 
Oct 25 01:47:19.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-7180 logs agnhost-primary-8knjm agnhost-primary'
Oct 25 01:47:19.597: INFO: stderr: ""
Oct 25 01:47:19.597: INFO: stdout: "Paused\n"
STEP: exposing RC
Oct 25 01:47:19.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-7180 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Oct 25 01:47:19.699: INFO: stderr: ""
Oct 25 01:47:19.699: INFO: stdout: "service/rm2 exposed\n"
Oct 25 01:47:19.709: INFO: Service rm2 in namespace kubectl-7180 found.
STEP: exposing service
Oct 25 01:47:21.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-7180 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Oct 25 01:47:21.825: INFO: stderr: ""
Oct 25 01:47:21.825: INFO: stdout: "service/rm3 exposed\n"
Oct 25 01:47:21.836: INFO: Service rm3 in namespace kubectl-7180 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 01:47:23.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7180" for this suite.

• [SLOW TEST:7.642 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1249
    should create services for rc  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":356,"completed":22,"skipped":274,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:47:23.875: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-e678c1cf-25cc-41cc-ba2d-b550f619256f
STEP: Creating a pod to test consume configMaps
Oct 25 01:47:23.933: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e404aa29-ba1c-459a-9f8c-1c25c4ece557" in namespace "projected-5702" to be "Succeeded or Failed"
Oct 25 01:47:23.938: INFO: Pod "pod-projected-configmaps-e404aa29-ba1c-459a-9f8c-1c25c4ece557": Phase="Pending", Reason="", readiness=false. Elapsed: 5.159323ms
Oct 25 01:47:25.948: INFO: Pod "pod-projected-configmaps-e404aa29-ba1c-459a-9f8c-1c25c4ece557": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015297013s
Oct 25 01:47:27.955: INFO: Pod "pod-projected-configmaps-e404aa29-ba1c-459a-9f8c-1c25c4ece557": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022848995s
STEP: Saw pod success
Oct 25 01:47:27.956: INFO: Pod "pod-projected-configmaps-e404aa29-ba1c-459a-9f8c-1c25c4ece557" satisfied condition "Succeeded or Failed"
Oct 25 01:47:27.961: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-projected-configmaps-e404aa29-ba1c-459a-9f8c-1c25c4ece557 container agnhost-container: <nil>
STEP: delete the pod
Oct 25 01:47:27.994: INFO: Waiting for pod pod-projected-configmaps-e404aa29-ba1c-459a-9f8c-1c25c4ece557 to disappear
Oct 25 01:47:28.000: INFO: Pod pod-projected-configmaps-e404aa29-ba1c-459a-9f8c-1c25c4ece557 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Oct 25 01:47:28.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5702" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":23,"skipped":288,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:47:28.023: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct 25 01:47:28.470: INFO: Pod name wrapped-volume-race-d2e91f6e-52b4-417c-86b2-ec49502b4218: Found 0 pods out of 5
Oct 25 01:47:33.487: INFO: Pod name wrapped-volume-race-d2e91f6e-52b4-417c-86b2-ec49502b4218: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d2e91f6e-52b4-417c-86b2-ec49502b4218 in namespace emptydir-wrapper-9543, will wait for the garbage collector to delete the pods
Oct 25 01:47:43.603: INFO: Deleting ReplicationController wrapped-volume-race-d2e91f6e-52b4-417c-86b2-ec49502b4218 took: 10.70231ms
Oct 25 01:47:43.703: INFO: Terminating ReplicationController wrapped-volume-race-d2e91f6e-52b4-417c-86b2-ec49502b4218 pods took: 100.278892ms
STEP: Creating RC which spawns configmap-volume pods
Oct 25 01:47:47.651: INFO: Pod name wrapped-volume-race-635fd74e-3b95-4940-9efa-8f8967ba6252: Found 0 pods out of 5
Oct 25 01:47:52.664: INFO: Pod name wrapped-volume-race-635fd74e-3b95-4940-9efa-8f8967ba6252: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-635fd74e-3b95-4940-9efa-8f8967ba6252 in namespace emptydir-wrapper-9543, will wait for the garbage collector to delete the pods
Oct 25 01:48:04.808: INFO: Deleting ReplicationController wrapped-volume-race-635fd74e-3b95-4940-9efa-8f8967ba6252 took: 33.041794ms
Oct 25 01:48:04.908: INFO: Terminating ReplicationController wrapped-volume-race-635fd74e-3b95-4940-9efa-8f8967ba6252 pods took: 100.75187ms
STEP: Creating RC which spawns configmap-volume pods
Oct 25 01:48:08.192: INFO: Pod name wrapped-volume-race-31b3a4e9-b9a3-4068-a7e2-2143b4143f28: Found 0 pods out of 5
Oct 25 01:48:13.208: INFO: Pod name wrapped-volume-race-31b3a4e9-b9a3-4068-a7e2-2143b4143f28: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-31b3a4e9-b9a3-4068-a7e2-2143b4143f28 in namespace emptydir-wrapper-9543, will wait for the garbage collector to delete the pods
Oct 25 01:48:25.323: INFO: Deleting ReplicationController wrapped-volume-race-31b3a4e9-b9a3-4068-a7e2-2143b4143f28 took: 13.461829ms
Oct 25 01:48:25.424: INFO: Terminating ReplicationController wrapped-volume-race-31b3a4e9-b9a3-4068-a7e2-2143b4143f28 pods took: 100.915202ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:188
Oct 25 01:48:28.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9543" for this suite.

• [SLOW TEST:60.787 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":356,"completed":24,"skipped":308,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:48:28.810: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-498f63c9-65a1-4f55-83b1-e20ce8b98451
STEP: Creating a pod to test consume configMaps
Oct 25 01:48:28.876: INFO: Waiting up to 5m0s for pod "pod-configmaps-9f5f596c-7ee2-455e-bb3e-0c5ef0bfcd8e" in namespace "configmap-7300" to be "Succeeded or Failed"
Oct 25 01:48:28.881: INFO: Pod "pod-configmaps-9f5f596c-7ee2-455e-bb3e-0c5ef0bfcd8e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.125795ms
Oct 25 01:48:30.890: INFO: Pod "pod-configmaps-9f5f596c-7ee2-455e-bb3e-0c5ef0bfcd8e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014490134s
Oct 25 01:48:32.897: INFO: Pod "pod-configmaps-9f5f596c-7ee2-455e-bb3e-0c5ef0bfcd8e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021091122s
STEP: Saw pod success
Oct 25 01:48:32.897: INFO: Pod "pod-configmaps-9f5f596c-7ee2-455e-bb3e-0c5ef0bfcd8e" satisfied condition "Succeeded or Failed"
Oct 25 01:48:32.904: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-configmaps-9f5f596c-7ee2-455e-bb3e-0c5ef0bfcd8e container agnhost-container: <nil>
STEP: delete the pod
Oct 25 01:48:32.932: INFO: Waiting for pod pod-configmaps-9f5f596c-7ee2-455e-bb3e-0c5ef0bfcd8e to disappear
Oct 25 01:48:32.941: INFO: Pod pod-configmaps-9f5f596c-7ee2-455e-bb3e-0c5ef0bfcd8e no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 01:48:32.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7300" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":25,"skipped":323,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:48:32.965: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-2ea87731-ab90-4648-ab93-f8ad64cf209e
STEP: Creating a pod to test consume secrets
Oct 25 01:48:33.021: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-43800554-5da5-4bb5-8b08-383633558e11" in namespace "projected-4553" to be "Succeeded or Failed"
Oct 25 01:48:33.026: INFO: Pod "pod-projected-secrets-43800554-5da5-4bb5-8b08-383633558e11": Phase="Pending", Reason="", readiness=false. Elapsed: 5.050326ms
Oct 25 01:48:35.037: INFO: Pod "pod-projected-secrets-43800554-5da5-4bb5-8b08-383633558e11": Phase="Running", Reason="", readiness=false. Elapsed: 2.015739662s
Oct 25 01:48:37.047: INFO: Pod "pod-projected-secrets-43800554-5da5-4bb5-8b08-383633558e11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026015338s
STEP: Saw pod success
Oct 25 01:48:37.047: INFO: Pod "pod-projected-secrets-43800554-5da5-4bb5-8b08-383633558e11" satisfied condition "Succeeded or Failed"
Oct 25 01:48:37.055: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-projected-secrets-43800554-5da5-4bb5-8b08-383633558e11 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 25 01:48:37.085: INFO: Waiting for pod pod-projected-secrets-43800554-5da5-4bb5-8b08-383633558e11 to disappear
Oct 25 01:48:37.090: INFO: Pod pod-projected-secrets-43800554-5da5-4bb5-8b08-383633558e11 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Oct 25 01:48:37.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4553" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":26,"skipped":341,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:48:37.114: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Pod with a static label
STEP: watching for Pod to be ready
Oct 25 01:48:37.175: INFO: observed Pod pod-test in namespace pods-980 in phase Pending with labels: map[test-pod-static:true] & conditions []
Oct 25 01:48:37.187: INFO: observed Pod pod-test in namespace pods-980 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:37 +0000 UTC  }]
Oct 25 01:48:37.212: INFO: observed Pod pod-test in namespace pods-980 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:37 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:37 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:37 +0000 UTC  }]
Oct 25 01:48:37.780: INFO: observed Pod pod-test in namespace pods-980 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:37 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:37 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:37 +0000 UTC  }]
Oct 25 01:48:38.858: INFO: Found Pod pod-test in namespace pods-980 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:37 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data
STEP: getting the Pod and ensuring that it's patched
STEP: replacing the Pod's status Ready condition to False
STEP: check the Pod again to ensure its Ready conditions are False
STEP: deleting the Pod via a Collection with a LabelSelector
STEP: watching for the Pod to be deleted
Oct 25 01:48:38.934: INFO: observed event type MODIFIED
Oct 25 01:48:40.859: INFO: observed event type MODIFIED
Oct 25 01:48:41.012: INFO: observed event type MODIFIED
Oct 25 01:48:41.862: INFO: observed event type MODIFIED
Oct 25 01:48:41.877: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Oct 25 01:48:41.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-980" for this suite.
•{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","total":356,"completed":27,"skipped":403,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:48:41.921: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2318
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating stateful set ss in namespace statefulset-2318
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2318
Oct 25 01:48:41.985: INFO: Found 0 stateful pods, waiting for 1
Oct 25 01:48:51.997: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct 25 01:48:52.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-2318 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 25 01:48:52.161: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 25 01:48:52.161: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 25 01:48:52.161: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 25 01:48:52.167: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 25 01:49:02.178: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 25 01:49:02.178: INFO: Waiting for statefulset status.replicas updated to 0
Oct 25 01:49:02.208: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Oct 25 01:49:02.208: INFO: ss-0  lab1-k8s-node-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:42 +0000 UTC  }]
Oct 25 01:49:02.208: INFO: 
Oct 25 01:49:02.208: INFO: StatefulSet ss has not reached scale 3, at 1
Oct 25 01:49:03.217: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993424152s
Oct 25 01:49:04.228: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.983866531s
Oct 25 01:49:05.236: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.973632461s
Oct 25 01:49:06.245: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.965261821s
Oct 25 01:49:07.259: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.955512321s
Oct 25 01:49:08.267: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.941439379s
Oct 25 01:49:09.277: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.933757262s
Oct 25 01:49:10.284: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.92366013s
Oct 25 01:49:11.293: INFO: Verifying statefulset ss doesn't scale past 3 for another 917.116069ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2318
Oct 25 01:49:12.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-2318 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 25 01:49:12.441: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 25 01:49:12.441: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 25 01:49:12.441: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 25 01:49:12.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-2318 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 25 01:49:12.600: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 25 01:49:12.600: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 25 01:49:12.600: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 25 01:49:12.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-2318 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 25 01:49:12.743: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 25 01:49:12.743: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 25 01:49:12.743: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 25 01:49:12.750: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Oct 25 01:49:22.757: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 25 01:49:22.757: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 25 01:49:22.757: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct 25 01:49:22.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-2318 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 25 01:49:22.914: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 25 01:49:22.914: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 25 01:49:22.914: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 25 01:49:22.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-2318 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 25 01:49:23.050: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 25 01:49:23.050: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 25 01:49:23.050: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 25 01:49:23.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-2318 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 25 01:49:23.199: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 25 01:49:23.199: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 25 01:49:23.199: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 25 01:49:23.199: INFO: Waiting for statefulset status.replicas updated to 0
Oct 25 01:49:23.205: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Oct 25 01:49:33.224: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 25 01:49:33.224: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 25 01:49:33.224: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 25 01:49:33.245: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Oct 25 01:49:33.245: INFO: ss-0  lab1-k8s-node-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:42 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:49:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:49:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:48:42 +0000 UTC  }]
Oct 25 01:49:33.246: INFO: ss-1  lab1-k8s-node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:49:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:49:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:49:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:49:02 +0000 UTC  }]
Oct 25 01:49:33.246: INFO: ss-2  lab1-k8s-node-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:49:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:49:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:49:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-10-25 01:49:02 +0000 UTC  }]
Oct 25 01:49:33.246: INFO: 
Oct 25 01:49:33.246: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 25 01:49:34.254: INFO: Verifying statefulset ss doesn't scale past 0 for another 8.993302214s
Oct 25 01:49:35.266: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.985219768s
Oct 25 01:49:36.274: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.973433006s
Oct 25 01:49:37.281: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.965329591s
Oct 25 01:49:38.290: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.957165653s
Oct 25 01:49:39.302: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.949275472s
Oct 25 01:49:40.311: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.937424293s
Oct 25 01:49:41.319: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.927873991s
Oct 25 01:49:42.328: INFO: Verifying statefulset ss doesn't scale past 0 for another 919.878224ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2318
Oct 25 01:49:43.336: INFO: Scaling statefulset ss to 0
Oct 25 01:49:43.353: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct 25 01:49:43.359: INFO: Deleting all statefulset in ns statefulset-2318
Oct 25 01:49:43.364: INFO: Scaling statefulset ss to 0
Oct 25 01:49:43.383: INFO: Waiting for statefulset status.replicas updated to 0
Oct 25 01:49:43.388: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Oct 25 01:49:43.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2318" for this suite.

• [SLOW TEST:61.518 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":356,"completed":28,"skipped":510,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:49:43.443: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/framework/framework.go:652
STEP: validating cluster-info
Oct 25 01:49:43.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-2844 cluster-info'
Oct 25 01:49:43.534: INFO: stderr: ""
Oct 25 01:49:43.534: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 01:49:43.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2844" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","total":356,"completed":29,"skipped":543,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:49:43.555: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod busybox-cd304701-199b-4e7c-a3e4-d39f5adb2bde in namespace container-probe-2342
Oct 25 01:49:45.620: INFO: Started pod busybox-cd304701-199b-4e7c-a3e4-d39f5adb2bde in namespace container-probe-2342
STEP: checking the pod's current state and verifying that restartCount is present
Oct 25 01:49:45.626: INFO: Initial restart count of pod busybox-cd304701-199b-4e7c-a3e4-d39f5adb2bde is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Oct 25 01:53:46.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2342" for this suite.

• [SLOW TEST:243.331 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":356,"completed":30,"skipped":561,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:53:46.888: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
Oct 25 01:53:49.018: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Oct 25 01:53:51.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6865" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","total":356,"completed":31,"skipped":569,"failed":0}

------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:53:51.056: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting a starting resourceVersion
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Oct 25 01:53:53.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8908" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":356,"completed":32,"skipped":569,"failed":0}
SSSSSSS
------------------------------
[sig-network] Services 
  should delete a collection of services [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:53:53.921: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a collection of services
Oct 25 01:53:53.956: INFO: Creating e2e-svc-a-fbpq9
Oct 25 01:53:53.973: INFO: Creating e2e-svc-b-9cbgf
Oct 25 01:53:53.997: INFO: Creating e2e-svc-c-gc2mw
STEP: deleting service collection
Oct 25 01:53:54.081: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 01:53:54.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7705" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","total":356,"completed":33,"skipped":576,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:53:54.103: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 25 01:53:54.217: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 01:53:54.217: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:53:55.247: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 01:53:55.247: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:53:56.232: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Oct 25 01:53:56.233: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:53:57.235: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 6
Oct 25 01:53:57.235: INFO: Number of running nodes: 6, number of available pods: 6 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct 25 01:53:57.283: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Oct 25 01:53:57.283: INFO: Node lab1-k8s-node-1 is running 0 daemon pod, expected 1
Oct 25 01:53:58.302: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Oct 25 01:53:58.303: INFO: Node lab1-k8s-node-1 is running 0 daemon pod, expected 1
Oct 25 01:53:59.306: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 6
Oct 25 01:53:59.306: INFO: Number of running nodes: 6, number of available pods: 6 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5916, will wait for the garbage collector to delete the pods
Oct 25 01:53:59.390: INFO: Deleting DaemonSet.extensions daemon-set took: 14.295315ms
Oct 25 01:53:59.491: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.208991ms
Oct 25 01:54:01.702: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 01:54:01.702: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct 25 01:54:01.707: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"208336"},"items":null}

Oct 25 01:54:01.712: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"208336"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Oct 25 01:54:01.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5916" for this suite.

• [SLOW TEST:7.685 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":356,"completed":34,"skipped":601,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:54:01.789: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 01:54:01.853: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c52bb7b9-6072-406a-a007-c3017f4544cd" in namespace "downward-api-6912" to be "Succeeded or Failed"
Oct 25 01:54:01.868: INFO: Pod "downwardapi-volume-c52bb7b9-6072-406a-a007-c3017f4544cd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.722472ms
Oct 25 01:54:03.881: INFO: Pod "downwardapi-volume-c52bb7b9-6072-406a-a007-c3017f4544cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027221047s
Oct 25 01:54:05.892: INFO: Pod "downwardapi-volume-c52bb7b9-6072-406a-a007-c3017f4544cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038543618s
STEP: Saw pod success
Oct 25 01:54:05.892: INFO: Pod "downwardapi-volume-c52bb7b9-6072-406a-a007-c3017f4544cd" satisfied condition "Succeeded or Failed"
Oct 25 01:54:05.898: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-c52bb7b9-6072-406a-a007-c3017f4544cd container client-container: <nil>
STEP: delete the pod
Oct 25 01:54:05.941: INFO: Waiting for pod downwardapi-volume-c52bb7b9-6072-406a-a007-c3017f4544cd to disappear
Oct 25 01:54:05.945: INFO: Pod downwardapi-volume-c52bb7b9-6072-406a-a007-c3017f4544cd no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Oct 25 01:54:05.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6912" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":356,"completed":35,"skipped":612,"failed":0}
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:54:05.967: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-2b52b31d-e121-45a0-83bd-bf225f27dd67
STEP: Creating a pod to test consume secrets
Oct 25 01:54:06.022: INFO: Waiting up to 5m0s for pod "pod-secrets-3f512277-76f4-4d88-b3d5-73f37bdc3722" in namespace "secrets-1731" to be "Succeeded or Failed"
Oct 25 01:54:06.030: INFO: Pod "pod-secrets-3f512277-76f4-4d88-b3d5-73f37bdc3722": Phase="Pending", Reason="", readiness=false. Elapsed: 7.475706ms
Oct 25 01:54:08.037: INFO: Pod "pod-secrets-3f512277-76f4-4d88-b3d5-73f37bdc3722": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01498635s
Oct 25 01:54:10.050: INFO: Pod "pod-secrets-3f512277-76f4-4d88-b3d5-73f37bdc3722": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028238968s
STEP: Saw pod success
Oct 25 01:54:10.051: INFO: Pod "pod-secrets-3f512277-76f4-4d88-b3d5-73f37bdc3722" satisfied condition "Succeeded or Failed"
Oct 25 01:54:10.056: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-secrets-3f512277-76f4-4d88-b3d5-73f37bdc3722 container secret-volume-test: <nil>
STEP: delete the pod
Oct 25 01:54:10.091: INFO: Waiting for pod pod-secrets-3f512277-76f4-4d88-b3d5-73f37bdc3722 to disappear
Oct 25 01:54:10.096: INFO: Pod pod-secrets-3f512277-76f4-4d88-b3d5-73f37bdc3722 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Oct 25 01:54:10.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1731" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":356,"completed":36,"skipped":618,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should complete a service status lifecycle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:54:10.117: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Service
STEP: watching for the Service to be added
Oct 25 01:54:10.177: INFO: Found Service test-service-l6xdr in namespace services-7041 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Oct 25 01:54:10.177: INFO: Service test-service-l6xdr created
STEP: Getting /status
Oct 25 01:54:10.188: INFO: Service test-service-l6xdr has LoadBalancer: {[]}
STEP: patching the ServiceStatus
STEP: watching for the Service to be patched
Oct 25 01:54:10.201: INFO: observed Service test-service-l6xdr in namespace services-7041 with annotations: map[] & LoadBalancer: {[]}
Oct 25 01:54:10.201: INFO: Found Service test-service-l6xdr in namespace services-7041 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Oct 25 01:54:10.201: INFO: Service test-service-l6xdr has service status patched
STEP: updating the ServiceStatus
Oct 25 01:54:10.215: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated
Oct 25 01:54:10.217: INFO: Observed Service test-service-l6xdr in namespace services-7041 with annotations: map[] & Conditions: {[]}
Oct 25 01:54:10.218: INFO: Observed event: &Service{ObjectMeta:{test-service-l6xdr  services-7041  57fa2aab-6294-4ace-b011-ff55e3508d70 208461 0 2022-10-25 01:54:10 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] []  [{e2e.test Update v1 2022-10-25 01:54:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-10-25 01:54:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.233.46.150,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.233.46.150],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Oct 25 01:54:10.218: INFO: Found Service test-service-l6xdr in namespace services-7041 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Oct 25 01:54:10.218: INFO: Service test-service-l6xdr has service status updated
STEP: patching the service
STEP: watching for the Service to be patched
Oct 25 01:54:10.236: INFO: observed Service test-service-l6xdr in namespace services-7041 with labels: map[test-service-static:true]
Oct 25 01:54:10.236: INFO: observed Service test-service-l6xdr in namespace services-7041 with labels: map[test-service-static:true]
Oct 25 01:54:10.236: INFO: observed Service test-service-l6xdr in namespace services-7041 with labels: map[test-service-static:true]
Oct 25 01:54:10.236: INFO: Found Service test-service-l6xdr in namespace services-7041 with labels: map[test-service:patched test-service-static:true]
Oct 25 01:54:10.237: INFO: Service test-service-l6xdr patched
STEP: deleting the service
STEP: watching for the Service to be deleted
Oct 25 01:54:10.265: INFO: Observed event: ADDED
Oct 25 01:54:10.265: INFO: Observed event: MODIFIED
Oct 25 01:54:10.265: INFO: Observed event: MODIFIED
Oct 25 01:54:10.265: INFO: Observed event: MODIFIED
Oct 25 01:54:10.265: INFO: Found Service test-service-l6xdr in namespace services-7041 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Oct 25 01:54:10.265: INFO: Service test-service-l6xdr deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 01:54:10.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7041" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","total":356,"completed":37,"skipped":632,"failed":0}
SSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:54:10.286: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 01:54:10.333: INFO: Waiting up to 5m0s for pod "busybox-user-65534-68accf12-6547-4110-bdea-7554eaf4c2d0" in namespace "security-context-test-5181" to be "Succeeded or Failed"
Oct 25 01:54:10.343: INFO: Pod "busybox-user-65534-68accf12-6547-4110-bdea-7554eaf4c2d0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.055857ms
Oct 25 01:54:12.351: INFO: Pod "busybox-user-65534-68accf12-6547-4110-bdea-7554eaf4c2d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017621512s
Oct 25 01:54:14.361: INFO: Pod "busybox-user-65534-68accf12-6547-4110-bdea-7554eaf4c2d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027704198s
Oct 25 01:54:14.361: INFO: Pod "busybox-user-65534-68accf12-6547-4110-bdea-7554eaf4c2d0" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Oct 25 01:54:14.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5181" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":38,"skipped":637,"failed":0}
SS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:54:14.383: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 01:54:14.415: INFO: Creating deployment "webserver-deployment"
Oct 25 01:54:14.424: INFO: Waiting for observed generation 1
Oct 25 01:54:16.448: INFO: Waiting for all required pods to come up
Oct 25 01:54:16.456: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct 25 01:54:18.474: INFO: Waiting for deployment "webserver-deployment" to complete
Oct 25 01:54:18.485: INFO: Updating deployment "webserver-deployment" with a non-existent image
Oct 25 01:54:18.504: INFO: Updating deployment webserver-deployment
Oct 25 01:54:18.504: INFO: Waiting for observed generation 2
Oct 25 01:54:20.527: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct 25 01:54:20.533: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct 25 01:54:20.538: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Oct 25 01:54:20.554: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct 25 01:54:20.554: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct 25 01:54:20.560: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Oct 25 01:54:20.570: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Oct 25 01:54:20.570: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Oct 25 01:54:20.589: INFO: Updating deployment webserver-deployment
Oct 25 01:54:20.589: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Oct 25 01:54:20.606: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct 25 01:54:20.625: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 25 01:54:20.702: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-732  113f7db1-4354-4b85-8ce2-89df889f59e7 208813 3 2022-10-25 01:54:14 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-10-25 01:54:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 01:54:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0025a3af8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-57ccb67bb8" is progressing.,LastUpdateTime:2022-10-25 01:54:18 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-10-25 01:54:20 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Oct 25 01:54:20.758: INFO: New ReplicaSet "webserver-deployment-57ccb67bb8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-57ccb67bb8  deployment-732  77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8 208834 3 2022-10-25 01:54:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 113f7db1-4354-4b85-8ce2-89df889f59e7 0xc002948017 0xc002948018}] []  [{kube-controller-manager Update apps/v1 2022-10-25 01:54:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"113f7db1-4354-4b85-8ce2-89df889f59e7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 01:54:18 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 57ccb67bb8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0029480b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 25 01:54:20.758: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Oct 25 01:54:20.758: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-55df494869  deployment-732  cc345db5-274d-431d-91e0-f4de2f9adf05 208828 3 2022-10-25 01:54:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 113f7db1-4354-4b85-8ce2-89df889f59e7 0xc0025a3f27 0xc0025a3f28}] []  [{kube-controller-manager Update apps/v1 2022-10-25 01:54:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"113f7db1-4354-4b85-8ce2-89df889f59e7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 01:54:15 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 55df494869,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0025a3fb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Oct 25 01:54:20.810: INFO: Pod "webserver-deployment-55df494869-258xx" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-258xx webserver-deployment-55df494869- deployment-732  121c7a01-0297-47dd-a88d-42e03725c611 208837 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc002c96b17 0xc002c96b18}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8zqhd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8zqhd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.2.108,PodIP:,StartTime:2022-10-25 01:54:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.810: INFO: Pod "webserver-deployment-55df494869-2p8zn" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-2p8zn webserver-deployment-55df494869- deployment-732  a05becb1-44f7-4e8e-be1a-8596ab8c5f1f 208829 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc002c96cd7 0xc002c96cd8}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xwvfz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xwvfz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.178,PodIP:,StartTime:2022-10-25 01:54:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.810: INFO: Pod "webserver-deployment-55df494869-2zmks" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-2zmks webserver-deployment-55df494869- deployment-732  2885d60e-fecc-4779-bb2f-68e59961598a 208815 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc002c96ea7 0xc002c96ea8}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dhnng,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dhnng,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.811: INFO: Pod "webserver-deployment-55df494869-4ms47" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-4ms47 webserver-deployment-55df494869- deployment-732  3100e07d-e49b-4dea-90a4-88689a1aa0ab 208674 0 2022-10-25 01:54:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:f95091912ca68f98ce87db0a3d1117100189aa394d11c536dbe3b73f424dddae cni.projectcalico.org/podIP:10.233.107.14/32 cni.projectcalico.org/podIPs:10.233.107.14/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc002c97010 0xc002c97011}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-10-25 01:54:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-25 01:54:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.107.14\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nzcgr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nzcgr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-master-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.2.74,PodIP:10.233.107.14,StartTime:2022-10-25 01:54:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 01:54:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://bfda8fc2b8a360af1f8d3a697d16529033bfbef7f3f547dadbda10ce314bad9f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.107.14,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.811: INFO: Pod "webserver-deployment-55df494869-54svw" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-54svw webserver-deployment-55df494869- deployment-732  68c3d34e-5989-43a5-9381-042be59fcb07 208851 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc002c97737 0xc002c97738}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kwlvh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kwlvh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.811: INFO: Pod "webserver-deployment-55df494869-84kq9" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-84kq9 webserver-deployment-55df494869- deployment-732  a5083825-54c4-43aa-a960-534a2c4066ac 208816 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc002c97d90 0xc002c97d91}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8ts7q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8ts7q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.811: INFO: Pod "webserver-deployment-55df494869-bc56s" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-bc56s webserver-deployment-55df494869- deployment-732  f763e4ce-3214-405a-91fd-b38b7fc681f6 208675 0 2022-10-25 01:54:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:4a1b5f30600bfe09fe6841c168183e9e834a31313b637ecb0eebd95c2d0a0f3f cni.projectcalico.org/podIP:10.233.74.47/32 cni.projectcalico.org/podIPs:10.233.74.47/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc002c97f00 0xc002c97f01}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-10-25 01:54:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-25 01:54:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.74.47\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ddfm5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ddfm5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.178,PodIP:10.233.74.47,StartTime:2022-10-25 01:54:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 01:54:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://62862f087cf30b7a973d33d112c1312ae00d2c90d4135aa364e963635ec89762,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.74.47,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.811: INFO: Pod "webserver-deployment-55df494869-cjpnf" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-cjpnf webserver-deployment-55df494869- deployment-732  c018c013-2e0d-4559-9f04-0be733ea1d07 208843 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc003596117 0xc003596118}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dxvfv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dxvfv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.811: INFO: Pod "webserver-deployment-55df494869-d297l" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-d297l webserver-deployment-55df494869- deployment-732  ec71e885-56d1-41ce-ba77-5a4f5f7075c1 208804 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc003596280 0xc003596281}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8nq42,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8nq42,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.178,PodIP:,StartTime:2022-10-25 01:54:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.811: INFO: Pod "webserver-deployment-55df494869-dcb4m" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-dcb4m webserver-deployment-55df494869- deployment-732  28bc43e9-bd56-4401-a0eb-593235a8ae4b 208840 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc003596447 0xc003596448}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fx6r9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fx6r9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-master-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.2.74,PodIP:,StartTime:2022-10-25 01:54:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.812: INFO: Pod "webserver-deployment-55df494869-f6w6w" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-f6w6w webserver-deployment-55df494869- deployment-732  176d27b6-bfa3-4563-9b22-4de41020812a 208663 0 2022-10-25 01:54:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:4e8f73870cba06517739f4a15e94aca904f2e857b3068e306b034f0dfda34138 cni.projectcalico.org/podIP:10.233.105.12/32 cni.projectcalico.org/podIPs:10.233.105.12/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc003596627 0xc003596628}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-10-25 01:54:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-25 01:54:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.105.12\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xmzzx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xmzzx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.2.108,PodIP:10.233.105.12,StartTime:2022-10-25 01:54:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 01:54:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b7fbff3331dd37afc8f476eff899014658a79bb06eed9658d22141c30e030ccf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.105.12,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.812: INFO: Pod "webserver-deployment-55df494869-fkx8c" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-fkx8c webserver-deployment-55df494869- deployment-732  2ff365a3-a93d-4876-bbd0-46aa64720bf6 208644 0 2022-10-25 01:54:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:3ea56d4fe385b6d0ec9c3c684688d05ffb1b9e4d7637564ccf96bc4d02340eda cni.projectcalico.org/podIP:10.233.95.11/32 cni.projectcalico.org/podIPs:10.233.95.11/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc003596847 0xc003596848}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-10-25 01:54:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-25 01:54:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.95.11\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wd4jb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wd4jb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.213,PodIP:10.233.95.11,StartTime:2022-10-25 01:54:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 01:54:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8e8d221faaa6b83b0e618cb44d169e21102e4af623a81ef6658f21a1a4c19734,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.95.11,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.812: INFO: Pod "webserver-deployment-55df494869-hhm9j" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-hhm9j webserver-deployment-55df494869- deployment-732  73c360af-a1e5-4f89-a360-aa2d26e943dc 208812 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc003596a57 0xc003596a58}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f9gnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f9gnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.812: INFO: Pod "webserver-deployment-55df494869-m77wt" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-m77wt webserver-deployment-55df494869- deployment-732  7e03da07-0336-4f3e-9a47-e8c8b5296f2a 208680 0 2022-10-25 01:54:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:de6e1a2ba0f76bf1414d5556f798f6db51ff8c0006221d919f0bdc629082c6f9 cni.projectcalico.org/podIP:10.233.95.12/32 cni.projectcalico.org/podIPs:10.233.95.12/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc003596bc0 0xc003596bc1}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-10-25 01:54:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-25 01:54:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.95.12\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qfjdh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qfjdh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.213,PodIP:10.233.95.12,StartTime:2022-10-25 01:54:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 01:54:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2e71768a3ac1a5ce47eb7efff12f8439a172ce21016e4c67e3ada7b0afb040d7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.95.12,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.812: INFO: Pod "webserver-deployment-55df494869-ng22p" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-ng22p webserver-deployment-55df494869- deployment-732  cfbd0b79-ae7b-4906-90ae-78cb6746c5b8 208844 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc003596dd7 0xc003596dd8}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r7mw4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r7mw4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.213,PodIP:,StartTime:2022-10-25 01:54:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.812: INFO: Pod "webserver-deployment-55df494869-qjtnf" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-qjtnf webserver-deployment-55df494869- deployment-732  4cfef88a-3d12-479b-9731-bfb679302158 208827 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc003596fa7 0xc003596fa8}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rgvbv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rgvbv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-master-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.176,PodIP:,StartTime:2022-10-25 01:54:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.812: INFO: Pod "webserver-deployment-55df494869-qk67n" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-qk67n webserver-deployment-55df494869- deployment-732  1aee0556-a045-401c-ab2b-8856879b0cc6 208635 0 2022-10-25 01:54:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:356bc49236055e5102d9527d9e338f3fd29eacaa9292b44c09e81a0cbabff09a cni.projectcalico.org/podIP:10.233.64.23/32 cni.projectcalico.org/podIPs:10.233.64.23/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc003597187 0xc003597188}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-10-25 01:54:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-25 01:54:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-65r54,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-65r54,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.121,PodIP:10.233.64.23,StartTime:2022-10-25 01:54:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 01:54:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b0927e439650c8e5bdf1cf553897ecee13b3fdc6f836f9dcac10eea9d089d352,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.813: INFO: Pod "webserver-deployment-55df494869-rlj75" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-rlj75 webserver-deployment-55df494869- deployment-732  bfc86a57-4804-46d3-b6d1-84927593766e 208642 0 2022-10-25 01:54:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:c5f62f819320a547fdca03800651ac26ace434276988aa3d77feb92b554443b1 cni.projectcalico.org/podIP:10.233.64.24/32 cni.projectcalico.org/podIPs:10.233.64.24/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc0035973b7 0xc0035973b8}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-10-25 01:54:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-25 01:54:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.24\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kzr9k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kzr9k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.121,PodIP:10.233.64.24,StartTime:2022-10-25 01:54:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 01:54:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://d426aa9dd1e7fec100bcb837db199addc9a9d025ec691ba3f408ee94c218cd4b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.24,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.813: INFO: Pod "webserver-deployment-55df494869-rphb6" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-rphb6 webserver-deployment-55df494869- deployment-732  a785fadb-c8fd-456a-9376-4679e2ad7f72 208668 0 2022-10-25 01:54:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:68db1ae69f0d4b806100cc176993b932fe5756f61c2fdf222c66d3fcee3a1d43 cni.projectcalico.org/podIP:10.233.99.16/32 cni.projectcalico.org/podIPs:10.233.99.16/32] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc0035975e7 0xc0035975e8}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-10-25 01:54:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-25 01:54:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.99.16\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vjhs2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vjhs2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-master-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.176,PodIP:10.233.99.16,StartTime:2022-10-25 01:54:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 01:54:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ce43ef6154b9b05c2a57998e428e74168c77c0213e04aa5bca009bac10260949,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.99.16,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.813: INFO: Pod "webserver-deployment-55df494869-vvvbw" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-vvvbw webserver-deployment-55df494869- deployment-732  30a54ecb-5460-4d44-97e8-c4d1516084d9 208820 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet webserver-deployment-55df494869 cc345db5-274d-431d-91e0-f4de2f9adf05 0xc0035977e7 0xc0035977e8}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc345db5-274d-431d-91e0-f4de2f9adf05\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lshlr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lshlr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.121,PodIP:,StartTime:2022-10-25 01:54:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.813: INFO: Pod "webserver-deployment-57ccb67bb8-25xd4" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-25xd4 webserver-deployment-57ccb67bb8- deployment-732  f03433ba-072f-4c37-9010-cafa0dc2f50c 208836 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8 0xc0035979b7 0xc0035979b8}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v94s5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v94s5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.813: INFO: Pod "webserver-deployment-57ccb67bb8-9t6t9" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-9t6t9 webserver-deployment-57ccb67bb8- deployment-732  8598bc3a-e0e3-4fcb-a9ba-7b7fde3542a7 208751 0 2022-10-25 01:54:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:d521678c8e4ba509117efd42c82bf783b0db0d36fb24fb3878a6629e132f8d45 cni.projectcalico.org/podIP:10.233.64.25/32 cni.projectcalico.org/podIPs:10.233.64.25/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8 0xc003597b50 0xc003597b51}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-10-25 01:54:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-b96tn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-b96tn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.121,PodIP:,StartTime:2022-10-25 01:54:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.813: INFO: Pod "webserver-deployment-57ccb67bb8-fl5z8" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-fl5z8 webserver-deployment-57ccb67bb8- deployment-732  4953cf04-f998-440a-ba3a-f7b875a3980c 208841 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8 0xc003597d67 0xc003597d68}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d6s58,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d6s58,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.121,PodIP:,StartTime:2022-10-25 01:54:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.813: INFO: Pod "webserver-deployment-57ccb67bb8-gdrjl" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-gdrjl webserver-deployment-57ccb67bb8- deployment-732  7272a100-295b-4392-910c-86ea5ebc3815 208831 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8 0xc003597f67 0xc003597f68}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vzhbg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vzhbg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.813: INFO: Pod "webserver-deployment-57ccb67bb8-jxnf2" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-jxnf2 webserver-deployment-57ccb67bb8- deployment-732  f1db52eb-0c98-4f71-a8dc-93c93032b127 208826 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8 0xc003a420e0 0xc003a420e1}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wrbkg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wrbkg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-master-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.2.74,PodIP:,StartTime:2022-10-25 01:54:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.814: INFO: Pod "webserver-deployment-57ccb67bb8-qb47k" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-qb47k webserver-deployment-57ccb67bb8- deployment-732  435e40ee-5da8-4471-b278-eeb858db8a4a 208765 0 2022-10-25 01:54:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:76489fd8ac38828a52bbbd203aa4ab984690a2efc1d9692911dd078bf2bedefb cni.projectcalico.org/podIP:10.233.99.17/32 cni.projectcalico.org/podIPs:10.233.99.17/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8 0xc003a422d0 0xc003a422d1}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-10-25 01:54:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d9l8j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d9l8j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-master-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.176,PodIP:,StartTime:2022-10-25 01:54:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.814: INFO: Pod "webserver-deployment-57ccb67bb8-rrd74" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-rrd74 webserver-deployment-57ccb67bb8- deployment-732  7abd7b88-d243-458a-8bb9-c19ad25704ed 208832 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8 0xc003a424e7 0xc003a424e8}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qqhj2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qqhj2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.814: INFO: Pod "webserver-deployment-57ccb67bb8-rvtzx" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-rvtzx webserver-deployment-57ccb67bb8- deployment-732  008161b0-9d20-4e04-81e8-0f34878721ca 208750 0 2022-10-25 01:54:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:0e42edfec30ad57801f19d066c0c68d89679d63e0cfde8724109e2bcc71c87fd cni.projectcalico.org/podIP:10.233.95.13/32 cni.projectcalico.org/podIPs:10.233.95.13/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8 0xc003a42670 0xc003a42671}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-10-25 01:54:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dgwvf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dgwvf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.213,PodIP:,StartTime:2022-10-25 01:54:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.814: INFO: Pod "webserver-deployment-57ccb67bb8-tf8n7" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-tf8n7 webserver-deployment-57ccb67bb8- deployment-732  d0795341-f4f6-4a19-8256-b9b398406299 208756 0 2022-10-25 01:54:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:f73c109f8dba537d707c28c3156046b5aab745acc6e75fd774ce3dfba5f63269 cni.projectcalico.org/podIP:10.233.74.48/32 cni.projectcalico.org/podIPs:10.233.74.48/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8 0xc003a428a7 0xc003a428a8}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-10-25 01:54:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t2mph,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t2mph,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.178,PodIP:,StartTime:2022-10-25 01:54:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.814: INFO: Pod "webserver-deployment-57ccb67bb8-vrktl" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-vrktl webserver-deployment-57ccb67bb8- deployment-732  cdec78b2-2ddc-41b9-8477-5f3337d320a1 208757 0 2022-10-25 01:54:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[cni.projectcalico.org/containerID:6415c442f8f70799b8cd68a3c0f764c28df0ef8dc7c4cd04cb9a599017937129 cni.projectcalico.org/podIP:10.233.105.13/32 cni.projectcalico.org/podIPs:10.233.105.13/32] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8 0xc003a42ae7 0xc003a42ae8}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-10-25 01:54:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sknps,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sknps,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-master-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.2.108,PodIP:,StartTime:2022-10-25 01:54:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.814: INFO: Pod "webserver-deployment-57ccb67bb8-whp58" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-whp58 webserver-deployment-57ccb67bb8- deployment-732  72674545-3e97-4a1f-8d3d-8805e37a9b2f 208850 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8 0xc003a42d07 0xc003a42d08}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2nvbl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2nvbl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.178,PodIP:,StartTime:2022-10-25 01:54:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.814: INFO: Pod "webserver-deployment-57ccb67bb8-zttgs" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-zttgs webserver-deployment-57ccb67bb8- deployment-732  90c7892f-8116-4c20-89ab-f709565a7ba5 208821 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8 0xc003a42f07 0xc003a42f08}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dgqvk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dgqvk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 01:54:20.814: INFO: Pod "webserver-deployment-57ccb67bb8-zwm94" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-zwm94 webserver-deployment-57ccb67bb8- deployment-732  505b4258-f6fd-4a06-98bd-1a1691736144 208835 0 2022-10-25 01:54:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8 0xc003a43080 0xc003a43081}] []  [{kube-controller-manager Update v1 2022-10-25 01:54:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77e36ba4-b84b-4bbc-9e3f-068d1fdf73d8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ccwsm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ccwsm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-master-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 01:54:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Oct 25 01:54:20.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-732" for this suite.

• [SLOW TEST:6.474 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":356,"completed":39,"skipped":639,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:54:20.859: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 01:54:20.895: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties
Oct 25 01:54:29.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-9749 --namespace=crd-publish-openapi-9749 create -f -'
Oct 25 01:54:30.169: INFO: stderr: ""
Oct 25 01:54:30.169: INFO: stdout: "e2e-test-crd-publish-openapi-5702-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Oct 25 01:54:30.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-9749 --namespace=crd-publish-openapi-9749 delete e2e-test-crd-publish-openapi-5702-crds test-foo'
Oct 25 01:54:30.291: INFO: stderr: ""
Oct 25 01:54:30.291: INFO: stdout: "e2e-test-crd-publish-openapi-5702-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Oct 25 01:54:30.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-9749 --namespace=crd-publish-openapi-9749 apply -f -'
Oct 25 01:54:30.838: INFO: stderr: ""
Oct 25 01:54:30.838: INFO: stdout: "e2e-test-crd-publish-openapi-5702-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Oct 25 01:54:30.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-9749 --namespace=crd-publish-openapi-9749 delete e2e-test-crd-publish-openapi-5702-crds test-foo'
Oct 25 01:54:30.916: INFO: stderr: ""
Oct 25 01:54:30.916: INFO: stdout: "e2e-test-crd-publish-openapi-5702-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values
Oct 25 01:54:30.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-9749 --namespace=crd-publish-openapi-9749 create -f -'
Oct 25 01:54:31.693: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Oct 25 01:54:31.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-9749 --namespace=crd-publish-openapi-9749 create -f -'
Oct 25 01:54:31.822: INFO: rc: 1
Oct 25 01:54:31.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-9749 --namespace=crd-publish-openapi-9749 apply -f -'
Oct 25 01:54:31.958: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties
Oct 25 01:54:31.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-9749 --namespace=crd-publish-openapi-9749 create -f -'
Oct 25 01:54:32.112: INFO: rc: 1
Oct 25 01:54:32.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-9749 --namespace=crd-publish-openapi-9749 apply -f -'
Oct 25 01:54:32.241: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Oct 25 01:54:32.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-9749 explain e2e-test-crd-publish-openapi-5702-crds'
Oct 25 01:54:32.379: INFO: stderr: ""
Oct 25 01:54:32.379: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5702-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Oct 25 01:54:32.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-9749 explain e2e-test-crd-publish-openapi-5702-crds.metadata'
Oct 25 01:54:32.530: INFO: stderr: ""
Oct 25 01:54:32.530: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5702-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     Deprecated: ClusterName is a legacy field that was always cleared by the\n     system and never used; it will be removed completely in 1.25.\n\n     The name in the go struct is changed to help clients detect accidental use.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Oct 25 01:54:32.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-9749 explain e2e-test-crd-publish-openapi-5702-crds.spec'
Oct 25 01:54:32.670: INFO: stderr: ""
Oct 25 01:54:32.670: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5702-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Oct 25 01:54:32.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-9749 explain e2e-test-crd-publish-openapi-5702-crds.spec.bars'
Oct 25 01:54:32.814: INFO: stderr: ""
Oct 25 01:54:32.814: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5702-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Oct 25 01:54:32.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-9749 explain e2e-test-crd-publish-openapi-5702-crds.spec.bars2'
Oct 25 01:54:32.950: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 01:54:35.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9749" for this suite.

• [SLOW TEST:14.957 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":356,"completed":40,"skipped":652,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:54:35.818: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 01:54:35.892: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ae6c68a-a32f-4d79-9fb2-825de0a9be7e" in namespace "projected-8085" to be "Succeeded or Failed"
Oct 25 01:54:35.901: INFO: Pod "downwardapi-volume-0ae6c68a-a32f-4d79-9fb2-825de0a9be7e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.79343ms
Oct 25 01:54:37.925: INFO: Pod "downwardapi-volume-0ae6c68a-a32f-4d79-9fb2-825de0a9be7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032198993s
Oct 25 01:54:39.939: INFO: Pod "downwardapi-volume-0ae6c68a-a32f-4d79-9fb2-825de0a9be7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046878512s
STEP: Saw pod success
Oct 25 01:54:39.940: INFO: Pod "downwardapi-volume-0ae6c68a-a32f-4d79-9fb2-825de0a9be7e" satisfied condition "Succeeded or Failed"
Oct 25 01:54:39.946: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-0ae6c68a-a32f-4d79-9fb2-825de0a9be7e container client-container: <nil>
STEP: delete the pod
Oct 25 01:54:39.993: INFO: Waiting for pod downwardapi-volume-0ae6c68a-a32f-4d79-9fb2-825de0a9be7e to disappear
Oct 25 01:54:40.001: INFO: Pod downwardapi-volume-0ae6c68a-a32f-4d79-9fb2-825de0a9be7e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Oct 25 01:54:40.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8085" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":356,"completed":41,"skipped":674,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:54:40.020: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7176
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a new StatefulSet
Oct 25 01:54:40.097: INFO: Found 0 stateful pods, waiting for 3
Oct 25 01:54:50.123: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 25 01:54:50.123: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 25 01:54:50.123: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Oct 25 01:54:50.170: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct 25 01:55:00.246: INFO: Updating stateful set ss2
Oct 25 01:55:00.263: INFO: Waiting for Pod statefulset-7176/ss2-2 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
STEP: Restoring Pods to the correct revision when they are deleted
Oct 25 01:55:10.354: INFO: Found 2 stateful pods, waiting for 3
Oct 25 01:55:20.362: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 25 01:55:20.363: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 25 01:55:20.363: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct 25 01:55:20.405: INFO: Updating stateful set ss2
Oct 25 01:55:20.423: INFO: Waiting for Pod statefulset-7176/ss2-1 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
Oct 25 01:55:30.467: INFO: Updating stateful set ss2
Oct 25 01:55:30.486: INFO: Waiting for StatefulSet statefulset-7176/ss2 to complete update
Oct 25 01:55:30.486: INFO: Waiting for Pod statefulset-7176/ss2-0 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct 25 01:55:40.509: INFO: Deleting all statefulset in ns statefulset-7176
Oct 25 01:55:40.519: INFO: Scaling statefulset ss2 to 0
Oct 25 01:55:50.555: INFO: Waiting for statefulset status.replicas updated to 0
Oct 25 01:55:50.561: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Oct 25 01:55:50.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7176" for this suite.

• [SLOW TEST:70.595 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":356,"completed":42,"skipped":695,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:55:50.615: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Oct 25 01:55:50.656: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 25 01:55:50.674: INFO: Waiting for terminating namespaces to be deleted...
Oct 25 01:55:50.679: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-master-1 before test
Oct 25 01:55:50.695: INFO: calico-node-p96g7 from kube-system started at 2022-10-24 13:36:57 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.695: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 01:55:50.695: INFO: csi-cinder-nodeplugin-rpg8q from kube-system started at 2022-10-24 13:24:56 +0000 UTC (3 container statuses recorded)
Oct 25 01:55:50.695: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 01:55:50.695: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 01:55:50.695: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 01:55:50.695: INFO: kube-apiserver-lab1-k8s-master-1 from kube-system started at 2022-10-24 13:25:02 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.695: INFO: 	Container kube-apiserver ready: true, restart count 0
Oct 25 01:55:50.695: INFO: kube-controller-manager-lab1-k8s-master-1 from kube-system started at 2022-10-24 13:25:02 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.695: INFO: 	Container kube-controller-manager ready: true, restart count 2
Oct 25 01:55:50.695: INFO: kube-proxy-s6wnk from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.695: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 01:55:50.695: INFO: kube-scheduler-lab1-k8s-master-1 from kube-system started at 2022-10-24 13:25:02 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.695: INFO: 	Container kube-scheduler ready: true, restart count 1
Oct 25 01:55:50.695: INFO: metrics-server-54d48d8c7-mcnqp from kube-system started at 2022-10-24 13:25:08 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.695: INFO: 	Container metrics-server ready: true, restart count 0
Oct 25 01:55:50.695: INFO: nodelocaldns-lkpsg from kube-system started at 2022-10-24 13:24:07 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.695: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 01:55:50.695: INFO: openstack-cloud-controller-manager-dv986 from kube-system started at 2022-10-24 10:53:46 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.695: INFO: 	Container openstack-cloud-controller-manager ready: true, restart count 2
Oct 25 01:55:50.695: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-mshb5 from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 01:55:50.695: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 01:55:50.695: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 01:55:50.695: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-master-2 before test
Oct 25 01:55:50.713: INFO: calico-node-vqr8k from kube-system started at 2022-10-24 13:35:46 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.713: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 01:55:50.713: INFO: coredns-74d6c5659f-dcc4x from kube-system started at 2022-10-24 13:36:35 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.713: INFO: 	Container coredns ready: true, restart count 0
Oct 25 01:55:50.713: INFO: csi-cinder-nodeplugin-qw5tr from kube-system started at 2022-10-24 13:24:51 +0000 UTC (3 container statuses recorded)
Oct 25 01:55:50.713: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 01:55:50.713: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 01:55:50.713: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 01:55:50.713: INFO: dns-autoscaler-78676459f6-7hpdl from kube-system started at 2022-10-24 13:29:51 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.713: INFO: 	Container autoscaler ready: true, restart count 0
Oct 25 01:55:50.713: INFO: kube-apiserver-lab1-k8s-master-2 from kube-system started at 2022-10-24 13:29:45 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.713: INFO: 	Container kube-apiserver ready: true, restart count 0
Oct 25 01:55:50.713: INFO: kube-controller-manager-lab1-k8s-master-2 from kube-system started at 2022-10-24 11:16:13 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.713: INFO: 	Container kube-controller-manager ready: true, restart count 0
Oct 25 01:55:50.713: INFO: kube-proxy-vrr69 from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.713: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 01:55:50.713: INFO: kube-scheduler-lab1-k8s-master-2 from kube-system started at 2022-10-24 13:15:08 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.713: INFO: 	Container kube-scheduler ready: true, restart count 0
Oct 25 01:55:50.713: INFO: nodelocaldns-xr5sh from kube-system started at 2022-10-24 13:24:05 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.713: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 01:55:50.713: INFO: openstack-cloud-controller-manager-27jr7 from kube-system started at 2022-10-24 11:12:57 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.713: INFO: 	Container openstack-cloud-controller-manager ready: true, restart count 2
Oct 25 01:55:50.713: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-pr8xq from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 01:55:50.713: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 01:55:50.713: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 01:55:50.713: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-master-3 before test
Oct 25 01:55:50.733: INFO: calico-node-bp6ts from kube-system started at 2022-10-24 13:34:44 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.733: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 01:55:50.733: INFO: coredns-74d6c5659f-m6zm9 from kube-system started at 2022-10-24 13:36:27 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.733: INFO: 	Container coredns ready: true, restart count 0
Oct 25 01:55:50.733: INFO: csi-cinder-nodeplugin-x2dl8 from kube-system started at 2022-10-24 13:24:53 +0000 UTC (3 container statuses recorded)
Oct 25 01:55:50.733: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 01:55:50.733: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 01:55:50.733: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 01:55:50.733: INFO: kube-apiserver-lab1-k8s-master-3 from kube-system started at 2022-10-24 13:34:08 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.733: INFO: 	Container kube-apiserver ready: true, restart count 0
Oct 25 01:55:50.733: INFO: kube-controller-manager-lab1-k8s-master-3 from kube-system started at 2022-10-24 13:31:36 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.733: INFO: 	Container kube-controller-manager ready: true, restart count 0
Oct 25 01:55:50.733: INFO: kube-proxy-4fvsp from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.733: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 01:55:50.733: INFO: kube-scheduler-lab1-k8s-master-3 from kube-system started at 2022-10-24 13:34:07 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.733: INFO: 	Container kube-scheduler ready: true, restart count 1
Oct 25 01:55:50.733: INFO: nodelocaldns-2lsxm from kube-system started at 2022-10-24 13:24:05 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.733: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 01:55:50.733: INFO: openstack-cloud-controller-manager-4jzsk from kube-system started at 2022-10-24 11:44:40 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.733: INFO: 	Container openstack-cloud-controller-manager ready: true, restart count 1
Oct 25 01:55:50.733: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-8w5gv from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 01:55:50.733: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 01:55:50.733: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 01:55:50.733: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-node-1 before test
Oct 25 01:55:50.745: INFO: calico-node-5ddpv from kube-system started at 2022-10-24 13:44:52 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.745: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 01:55:50.745: INFO: csi-cinder-controllerplugin-5f5b5c795f-lrxvf from kube-system started at 2022-10-24 13:46:01 +0000 UTC (6 container statuses recorded)
Oct 25 01:55:50.745: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 01:55:50.745: INFO: 	Container csi-attacher ready: true, restart count 0
Oct 25 01:55:50.745: INFO: 	Container csi-provisioner ready: true, restart count 0
Oct 25 01:55:50.745: INFO: 	Container csi-resizer ready: true, restart count 0
Oct 25 01:55:50.745: INFO: 	Container csi-snapshotter ready: true, restart count 0
Oct 25 01:55:50.745: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 01:55:50.745: INFO: csi-cinder-nodeplugin-l5nps from kube-system started at 2022-10-24 13:44:52 +0000 UTC (3 container statuses recorded)
Oct 25 01:55:50.745: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 01:55:50.745: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 01:55:50.745: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 01:55:50.745: INFO: kube-proxy-ltn2j from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.745: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 01:55:50.745: INFO: nginx-proxy-lab1-k8s-node-1 from kube-system started at 2022-10-24 13:45:14 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.745: INFO: 	Container nginx-proxy ready: true, restart count 0
Oct 25 01:55:50.745: INFO: nodelocaldns-22vhv from kube-system started at 2022-10-24 13:44:52 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.746: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 01:55:50.746: INFO: snapshot-controller-59c7b5464b-hgf7x from kube-system started at 2022-10-24 13:46:01 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.746: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 25 01:55:50.746: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-z9z72 from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 01:55:50.746: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 01:55:50.746: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 01:55:50.746: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-node-2 before test
Oct 25 01:55:50.765: INFO: calico-kube-controllers-8ff9fbd88-qkxfb from kube-system started at 2022-10-24 13:52:38 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.765: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 25 01:55:50.765: INFO: calico-node-t24sg from kube-system started at 2022-10-24 13:51:29 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.765: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 01:55:50.765: INFO: csi-cinder-nodeplugin-6lwfv from kube-system started at 2022-10-24 13:51:29 +0000 UTC (3 container statuses recorded)
Oct 25 01:55:50.765: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 01:55:50.765: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 01:55:50.765: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 01:55:50.765: INFO: kube-proxy-9z7jt from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.765: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 01:55:50.765: INFO: nginx-proxy-lab1-k8s-node-2 from kube-system started at 2022-10-24 13:51:52 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.765: INFO: 	Container nginx-proxy ready: true, restart count 0
Oct 25 01:55:50.765: INFO: nodelocaldns-hf2sj from kube-system started at 2022-10-24 13:51:29 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.765: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 01:55:50.765: INFO: sonobuoy-e2e-job-a74b57dba1144d0b from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 01:55:50.765: INFO: 	Container e2e ready: true, restart count 0
Oct 25 01:55:50.765: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 01:55:50.765: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-vwzzz from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 01:55:50.765: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 01:55:50.765: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 01:55:50.765: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-node-3 before test
Oct 25 01:55:50.779: INFO: calico-node-rnp6v from kube-system started at 2022-10-24 13:57:49 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.779: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 01:55:50.779: INFO: csi-cinder-nodeplugin-s2s7w from kube-system started at 2022-10-24 13:57:49 +0000 UTC (3 container statuses recorded)
Oct 25 01:55:50.779: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 01:55:50.779: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 01:55:50.779: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 01:55:50.779: INFO: kube-proxy-dfcgm from kube-system started at 2022-10-24 13:57:49 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.779: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 01:55:50.779: INFO: nginx-proxy-lab1-k8s-node-3 from kube-system started at 2022-10-24 13:58:11 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.779: INFO: 	Container nginx-proxy ready: true, restart count 0
Oct 25 01:55:50.779: INFO: nodelocaldns-2qn67 from kube-system started at 2022-10-24 13:57:49 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.779: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 01:55:50.779: INFO: sonobuoy from sonobuoy started at 2022-10-25 01:39:35 +0000 UTC (1 container statuses recorded)
Oct 25 01:55:50.779: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 25 01:55:50.779: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-ttkt7 from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 01:55:50.779: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 01:55:50.779: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.17212d1f9838958a], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match Pod's node affinity/selector. preemption: 0/6 nodes are available: 6 Preemption is not helpful for scheduling.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Oct 25 01:55:51.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2667" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":356,"completed":43,"skipped":717,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context 
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:55:51.865: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename security-context
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Oct 25 01:55:51.920: INFO: Waiting up to 5m0s for pod "security-context-dc0dab6e-080b-45a8-8828-17ee2f483297" in namespace "security-context-3344" to be "Succeeded or Failed"
Oct 25 01:55:51.931: INFO: Pod "security-context-dc0dab6e-080b-45a8-8828-17ee2f483297": Phase="Pending", Reason="", readiness=false. Elapsed: 10.992369ms
Oct 25 01:55:53.941: INFO: Pod "security-context-dc0dab6e-080b-45a8-8828-17ee2f483297": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021059531s
Oct 25 01:55:55.952: INFO: Pod "security-context-dc0dab6e-080b-45a8-8828-17ee2f483297": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03152278s
STEP: Saw pod success
Oct 25 01:55:55.952: INFO: Pod "security-context-dc0dab6e-080b-45a8-8828-17ee2f483297" satisfied condition "Succeeded or Failed"
Oct 25 01:55:55.960: INFO: Trying to get logs from node lab1-k8s-node-3 pod security-context-dc0dab6e-080b-45a8-8828-17ee2f483297 container test-container: <nil>
STEP: delete the pod
Oct 25 01:55:56.011: INFO: Waiting for pod security-context-dc0dab6e-080b-45a8-8828-17ee2f483297 to disappear
Oct 25 01:55:56.020: INFO: Pod security-context-dc0dab6e-080b-45a8-8828-17ee2f483297 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Oct 25 01:55:56.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-3344" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":356,"completed":44,"skipped":735,"failed":0}
S
------------------------------
[sig-node] PodTemplates 
  should delete a collection of pod templates [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:55:56.049: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a collection of pod templates [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of pod templates
Oct 25 01:55:56.097: INFO: created test-podtemplate-1
Oct 25 01:55:56.109: INFO: created test-podtemplate-2
Oct 25 01:55:56.118: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace
STEP: delete collection of pod templates
Oct 25 01:55:56.130: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity
Oct 25 01:55:56.170: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Oct 25 01:55:56.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-8826" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","total":356,"completed":45,"skipped":736,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:55:56.206: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 01:55:56.711: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 01:55:59.759: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 01:55:59.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-49-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 01:56:08.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6902" for this suite.
STEP: Destroying namespace "webhook-6902-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:11.978 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":356,"completed":46,"skipped":802,"failed":0}
SSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:56:08.186: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 25 01:56:12.315: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Oct 25 01:56:12.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8600" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":47,"skipped":806,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:56:12.375: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 01:56:12.421: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 01:56:18.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-507" for this suite.

• [SLOW TEST:5.669 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":356,"completed":48,"skipped":814,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:56:18.044: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 01:56:18.347: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 01:56:21.393: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Oct 25 01:56:21.428: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 01:56:21.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5410" for this suite.
STEP: Destroying namespace "webhook-5410-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":356,"completed":49,"skipped":820,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:56:21.578: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Oct 25 01:56:22.026: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Oct 25 01:56:24.054: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 25, 1, 56, 22, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 1, 56, 22, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 1, 56, 22, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 1, 56, 22, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-656754656d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 01:56:27.081: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 01:56:27.088: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 01:56:35.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2709" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139

• [SLOW TEST:13.981 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":356,"completed":50,"skipped":841,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:56:35.560: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 01:56:36.179: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 01:56:39.225: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 01:56:51.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5497" for this suite.
STEP: Destroying namespace "webhook-5497-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:16.035 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":356,"completed":51,"skipped":882,"failed":0}
SSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:56:51.597: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name cm-test-opt-del-e0673aa7-087f-48a5-92ab-ab0971a73d8c
STEP: Creating configMap with name cm-test-opt-upd-cff67d38-dc3f-43ad-bfb8-abe2c13985d3
STEP: Creating the pod
Oct 25 01:56:51.727: INFO: The status of Pod pod-projected-configmaps-ee990d9c-ba2f-45e2-b234-28100b0ee44a is Pending, waiting for it to be Running (with Ready = true)
Oct 25 01:56:53.746: INFO: The status of Pod pod-projected-configmaps-ee990d9c-ba2f-45e2-b234-28100b0ee44a is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-e0673aa7-087f-48a5-92ab-ab0971a73d8c
STEP: Updating configmap cm-test-opt-upd-cff67d38-dc3f-43ad-bfb8-abe2c13985d3
STEP: Creating configMap with name cm-test-opt-create-e4108ab0-e606-4349-bc7e-f9570b8c659d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Oct 25 01:56:55.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8962" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":52,"skipped":886,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:56:55.890: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 25 01:56:56.028: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 01:56:56.028: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:56:57.062: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Oct 25 01:56:57.062: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 01:56:58.068: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 6
Oct 25 01:56:58.068: INFO: Number of running nodes: 6, number of available pods: 6 in daemonset daemon-set
STEP: listing all DeamonSets
STEP: DeleteCollection of the DaemonSets
STEP: Verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Oct 25 01:56:58.122: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"210551"},"items":null}

Oct 25 01:56:58.130: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"210551"},"items":[{"metadata":{"name":"daemon-set-6nwh9","generateName":"daemon-set-","namespace":"daemonsets-4772","uid":"5a9b6729-7bdf-47b8-ac19-551879fe2a53","resourceVersion":"210545","creationTimestamp":"2022-10-25T01:56:56Z","labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"7f73f8bd408efd66669e531acdd489a71b92b8236c7cef80a0cdc2ead1adfcd1","cni.projectcalico.org/podIP":"10.233.64.28/32","cni.projectcalico.org/podIPs":"10.233.64.28/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"38f5b54d-ba8d-4b2e-941d-f7e7752b8d1a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:56Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:56Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"38f5b54d-ba8d-4b2e-941d-f7e7752b8d1a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:57Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.28\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-2h7wx","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-2h7wx","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"lab1-k8s-node-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["lab1-k8s-node-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:56Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:57Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:57Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:56Z"}],"hostIP":"10.128.1.121","podIP":"10.233.64.28","podIPs":[{"ip":"10.233.64.28"}],"startTime":"2022-10-25T01:56:56Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-10-25T01:56:56Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://a966552b3b95262524d8389fa237e8afca76fa245d34c2239d841e4507aacf96","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-6r646","generateName":"daemon-set-","namespace":"daemonsets-4772","uid":"cde6ad58-ff6a-4aa2-96e4-e76b593e714a","resourceVersion":"210547","creationTimestamp":"2022-10-25T01:56:56Z","labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"f12d204156d6d966f29f5ad67ffa5a4618109b632c217fe1606d17eed38474c8","cni.projectcalico.org/podIP":"10.233.107.16/32","cni.projectcalico.org/podIPs":"10.233.107.16/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"38f5b54d-ba8d-4b2e-941d-f7e7752b8d1a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:56Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:56Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"38f5b54d-ba8d-4b2e-941d-f7e7752b8d1a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:57Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.107.16\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-pbd7k","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-pbd7k","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"lab1-k8s-master-2","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["lab1-k8s-master-2"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:56Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:57Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:57Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:56Z"}],"hostIP":"10.128.2.74","podIP":"10.233.107.16","podIPs":[{"ip":"10.233.107.16"}],"startTime":"2022-10-25T01:56:56Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-10-25T01:56:57Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://5bf82ce84947dc4c420e89d0b25b01b812e3de530339dfc60941f10b9546c266","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-9qndl","generateName":"daemon-set-","namespace":"daemonsets-4772","uid":"4605266e-77a5-4dd6-9a02-90bdabbf3eb5","resourceVersion":"210510","creationTimestamp":"2022-10-25T01:56:56Z","labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"8bbe1dd23b7df5cb5eb52fb6d385586ffa19cb2ce52ab3e233b6f8bcf72391d2","cni.projectcalico.org/podIP":"10.233.74.61/32","cni.projectcalico.org/podIPs":"10.233.74.61/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"38f5b54d-ba8d-4b2e-941d-f7e7752b8d1a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:56Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:56Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"38f5b54d-ba8d-4b2e-941d-f7e7752b8d1a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:56Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.74.61\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-2vtd6","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-2vtd6","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"lab1-k8s-node-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["lab1-k8s-node-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:56Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:56Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:56Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:56Z"}],"hostIP":"10.128.1.178","podIP":"10.233.74.61","podIPs":[{"ip":"10.233.74.61"}],"startTime":"2022-10-25T01:56:56Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-10-25T01:56:56Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://30e04f76f2bd486f76ae6e4fe56cc3fd1fdfe07b25306c834747f946b1c79249","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-btdf7","generateName":"daemon-set-","namespace":"daemonsets-4772","uid":"a99f1bcc-d0d0-4ea1-8fb7-9b7336473795","resourceVersion":"210535","creationTimestamp":"2022-10-25T01:56:56Z","labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"c689379b67d4e6b467ba8a83b7f5e5e7bfdd3c2a99ac9b34b60b6999285de2f2","cni.projectcalico.org/podIP":"10.233.105.14/32","cni.projectcalico.org/podIPs":"10.233.105.14/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"38f5b54d-ba8d-4b2e-941d-f7e7752b8d1a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:56Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:56Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"38f5b54d-ba8d-4b2e-941d-f7e7752b8d1a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:57Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.105.14\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-pg84d","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-pg84d","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"lab1-k8s-master-3","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["lab1-k8s-master-3"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:56Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:57Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:57Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:56Z"}],"hostIP":"10.128.2.108","podIP":"10.233.105.14","podIPs":[{"ip":"10.233.105.14"}],"startTime":"2022-10-25T01:56:56Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-10-25T01:56:57Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://aa879f711d7970c72fd9468c132f753f8e329d2c469c335980c2eee1add2a48b","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-s8k29","generateName":"daemon-set-","namespace":"daemonsets-4772","uid":"9d866fc2-309e-4e24-9af4-4551e160daaf","resourceVersion":"210521","creationTimestamp":"2022-10-25T01:56:56Z","labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"6ca6865349dabfe039484885eac30b00c3a27214731337410b7813de36c2b0d4","cni.projectcalico.org/podIP":"10.233.95.19/32","cni.projectcalico.org/podIPs":"10.233.95.19/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"38f5b54d-ba8d-4b2e-941d-f7e7752b8d1a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:56Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:56Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"38f5b54d-ba8d-4b2e-941d-f7e7752b8d1a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:57Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.95.19\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-gqjdg","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-gqjdg","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"lab1-k8s-node-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["lab1-k8s-node-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:56Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:57Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:57Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:56Z"}],"hostIP":"10.128.1.213","podIP":"10.233.95.19","podIPs":[{"ip":"10.233.95.19"}],"startTime":"2022-10-25T01:56:56Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-10-25T01:56:57Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://be8963701e20dc2d835ebce6033b23777b5a670597951348a14778372474127c","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-srnpb","generateName":"daemon-set-","namespace":"daemonsets-4772","uid":"f3c36e6b-74ca-4054-8804-ccd3618cab20","resourceVersion":"210549","creationTimestamp":"2022-10-25T01:56:56Z","labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"91e6a926fed67bceffb09d008f3c463b089db4f393031d6993a0e14efdf52dcd","cni.projectcalico.org/podIP":"10.233.99.18/32","cni.projectcalico.org/podIPs":"10.233.99.18/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"38f5b54d-ba8d-4b2e-941d-f7e7752b8d1a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:56Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:56Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"38f5b54d-ba8d-4b2e-941d-f7e7752b8d1a\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-10-25T01:56:58Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.99.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-t6q89","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-t6q89","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"lab1-k8s-master-1","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["lab1-k8s-master-1"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:56Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:58Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:58Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-10-25T01:56:56Z"}],"hostIP":"10.128.0.176","podIP":"10.233.99.18","podIPs":[{"ip":"10.233.99.18"}],"startTime":"2022-10-25T01:56:56Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-10-25T01:56:57Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://7ae71b09099d33a6d5c86d18f32d824ec782b5ef201cfd90479cd95197f6a0f8","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Oct 25 01:56:58.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4772" for this suite.
•{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","total":356,"completed":53,"skipped":902,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:56:58.230: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 25 01:56:58.290: INFO: Waiting up to 5m0s for pod "pod-c69cda33-dfbb-4cda-b4cc-0751b6f64a1e" in namespace "emptydir-3793" to be "Succeeded or Failed"
Oct 25 01:56:58.304: INFO: Pod "pod-c69cda33-dfbb-4cda-b4cc-0751b6f64a1e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.778058ms
Oct 25 01:57:00.314: INFO: Pod "pod-c69cda33-dfbb-4cda-b4cc-0751b6f64a1e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023429964s
Oct 25 01:57:02.324: INFO: Pod "pod-c69cda33-dfbb-4cda-b4cc-0751b6f64a1e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033521731s
STEP: Saw pod success
Oct 25 01:57:02.324: INFO: Pod "pod-c69cda33-dfbb-4cda-b4cc-0751b6f64a1e" satisfied condition "Succeeded or Failed"
Oct 25 01:57:02.332: INFO: Trying to get logs from node lab1-k8s-node-2 pod pod-c69cda33-dfbb-4cda-b4cc-0751b6f64a1e container test-container: <nil>
STEP: delete the pod
Oct 25 01:57:02.384: INFO: Waiting for pod pod-c69cda33-dfbb-4cda-b4cc-0751b6f64a1e to disappear
Oct 25 01:57:02.396: INFO: Pod pod-c69cda33-dfbb-4cda-b4cc-0751b6f64a1e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 01:57:02.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3793" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":54,"skipped":909,"failed":0}
SSSS
------------------------------
[sig-storage] Secrets 
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:57:02.425: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Oct 25 01:57:02.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7279" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","total":356,"completed":55,"skipped":913,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:57:02.596: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 01:57:03.057: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 01:57:06.108: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 01:57:06.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3478" for this suite.
STEP: Destroying namespace "webhook-3478-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":356,"completed":56,"skipped":929,"failed":0}
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:57:06.253: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ServiceAccount
STEP: watching for the ServiceAccount to be added
STEP: patching the ServiceAccount
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector)
STEP: deleting the ServiceAccount
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Oct 25 01:57:06.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9780" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","total":356,"completed":57,"skipped":932,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:57:06.383: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Oct 25 01:57:06.423: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 01:57:16.145: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 01:57:33.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-321" for this suite.

• [SLOW TEST:27.564 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":356,"completed":58,"skipped":947,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:57:33.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Creating a NodePort Service
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota
STEP: Ensuring resource quota status captures service creation
STEP: Deleting Services
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Oct 25 01:57:45.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5512" for this suite.

• [SLOW TEST:11.309 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":356,"completed":59,"skipped":948,"failed":0}
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:57:45.258: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name projected-secret-test-b9eec2bc-f7f8-4626-a1d5-261eaee96756
STEP: Creating a pod to test consume secrets
Oct 25 01:57:45.320: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9e84a3ad-e1c0-426e-9281-cb49edafd3f7" in namespace "projected-4234" to be "Succeeded or Failed"
Oct 25 01:57:45.327: INFO: Pod "pod-projected-secrets-9e84a3ad-e1c0-426e-9281-cb49edafd3f7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.761724ms
Oct 25 01:57:47.339: INFO: Pod "pod-projected-secrets-9e84a3ad-e1c0-426e-9281-cb49edafd3f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01927626s
Oct 25 01:57:49.350: INFO: Pod "pod-projected-secrets-9e84a3ad-e1c0-426e-9281-cb49edafd3f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030179285s
STEP: Saw pod success
Oct 25 01:57:49.350: INFO: Pod "pod-projected-secrets-9e84a3ad-e1c0-426e-9281-cb49edafd3f7" satisfied condition "Succeeded or Failed"
Oct 25 01:57:49.356: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-projected-secrets-9e84a3ad-e1c0-426e-9281-cb49edafd3f7 container secret-volume-test: <nil>
STEP: delete the pod
Oct 25 01:57:49.393: INFO: Waiting for pod pod-projected-secrets-9e84a3ad-e1c0-426e-9281-cb49edafd3f7 to disappear
Oct 25 01:57:49.399: INFO: Pod pod-projected-secrets-9e84a3ad-e1c0-426e-9281-cb49edafd3f7 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Oct 25 01:57:49.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4234" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":356,"completed":60,"skipped":948,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:57:49.423: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 01:57:49.812: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 01:57:52.854: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 01:57:52.860: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2614-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 01:58:01.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2340" for this suite.
STEP: Destroying namespace "webhook-2340-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:11.709 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":356,"completed":61,"skipped":955,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:58:01.133: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 01:58:01.501: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 01:58:04.538: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 01:58:04.547: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5546-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 01:58:12.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5402" for this suite.
STEP: Destroying namespace "webhook-5402-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:11.643 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":356,"completed":62,"skipped":1007,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:58:12.780: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-1512cbec-418f-4a9e-a82a-5d430d021f8a
STEP: Creating a pod to test consume configMaps
Oct 25 01:58:12.845: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c2271c45-baf8-485c-81f9-ca8e16ca8e91" in namespace "projected-3484" to be "Succeeded or Failed"
Oct 25 01:58:12.851: INFO: Pod "pod-projected-configmaps-c2271c45-baf8-485c-81f9-ca8e16ca8e91": Phase="Pending", Reason="", readiness=false. Elapsed: 5.417148ms
Oct 25 01:58:14.861: INFO: Pod "pod-projected-configmaps-c2271c45-baf8-485c-81f9-ca8e16ca8e91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01563263s
Oct 25 01:58:16.872: INFO: Pod "pod-projected-configmaps-c2271c45-baf8-485c-81f9-ca8e16ca8e91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026419062s
STEP: Saw pod success
Oct 25 01:58:16.872: INFO: Pod "pod-projected-configmaps-c2271c45-baf8-485c-81f9-ca8e16ca8e91" satisfied condition "Succeeded or Failed"
Oct 25 01:58:16.879: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-projected-configmaps-c2271c45-baf8-485c-81f9-ca8e16ca8e91 container agnhost-container: <nil>
STEP: delete the pod
Oct 25 01:58:16.916: INFO: Waiting for pod pod-projected-configmaps-c2271c45-baf8-485c-81f9-ca8e16ca8e91 to disappear
Oct 25 01:58:16.921: INFO: Pod pod-projected-configmaps-c2271c45-baf8-485c-81f9-ca8e16ca8e91 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Oct 25 01:58:16.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3484" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":356,"completed":63,"skipped":1060,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:58:16.941: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:84
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Oct 25 01:58:17.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3762" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":356,"completed":64,"skipped":1071,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 01:58:17.040: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ReplaceConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring the job is replaced with a new one
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Oct 25 02:00:01.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4799" for this suite.

• [SLOW TEST:104.118 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","total":356,"completed":65,"skipped":1084,"failed":0}
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:00:01.159: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Oct 25 02:00:01.202: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 25 02:00:01.218: INFO: Waiting for terminating namespaces to be deleted...
Oct 25 02:00:01.224: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-master-1 before test
Oct 25 02:00:01.236: INFO: calico-node-p96g7 from kube-system started at 2022-10-24 13:36:57 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.236: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 02:00:01.236: INFO: csi-cinder-nodeplugin-rpg8q from kube-system started at 2022-10-24 13:24:56 +0000 UTC (3 container statuses recorded)
Oct 25 02:00:01.236: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 02:00:01.236: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 02:00:01.236: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 02:00:01.236: INFO: kube-apiserver-lab1-k8s-master-1 from kube-system started at 2022-10-24 13:25:02 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.236: INFO: 	Container kube-apiserver ready: true, restart count 0
Oct 25 02:00:01.236: INFO: kube-controller-manager-lab1-k8s-master-1 from kube-system started at 2022-10-24 13:25:02 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.236: INFO: 	Container kube-controller-manager ready: true, restart count 2
Oct 25 02:00:01.237: INFO: kube-proxy-s6wnk from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.237: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 02:00:01.237: INFO: kube-scheduler-lab1-k8s-master-1 from kube-system started at 2022-10-24 13:25:02 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.237: INFO: 	Container kube-scheduler ready: true, restart count 1
Oct 25 02:00:01.237: INFO: metrics-server-54d48d8c7-mcnqp from kube-system started at 2022-10-24 13:25:08 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.237: INFO: 	Container metrics-server ready: true, restart count 0
Oct 25 02:00:01.237: INFO: nodelocaldns-lkpsg from kube-system started at 2022-10-24 13:24:07 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.237: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 02:00:01.237: INFO: openstack-cloud-controller-manager-dv986 from kube-system started at 2022-10-24 10:53:46 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.237: INFO: 	Container openstack-cloud-controller-manager ready: true, restart count 2
Oct 25 02:00:01.237: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-mshb5 from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 02:00:01.237: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 02:00:01.237: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 02:00:01.237: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-master-2 before test
Oct 25 02:00:01.253: INFO: calico-node-vqr8k from kube-system started at 2022-10-24 13:35:46 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.253: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 02:00:01.253: INFO: coredns-74d6c5659f-dcc4x from kube-system started at 2022-10-24 13:36:35 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.253: INFO: 	Container coredns ready: true, restart count 0
Oct 25 02:00:01.253: INFO: csi-cinder-nodeplugin-qw5tr from kube-system started at 2022-10-24 13:24:51 +0000 UTC (3 container statuses recorded)
Oct 25 02:00:01.253: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 02:00:01.253: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 02:00:01.253: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 02:00:01.253: INFO: dns-autoscaler-78676459f6-7hpdl from kube-system started at 2022-10-24 13:29:51 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.253: INFO: 	Container autoscaler ready: true, restart count 0
Oct 25 02:00:01.254: INFO: kube-apiserver-lab1-k8s-master-2 from kube-system started at 2022-10-24 13:29:45 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.254: INFO: 	Container kube-apiserver ready: true, restart count 0
Oct 25 02:00:01.254: INFO: kube-controller-manager-lab1-k8s-master-2 from kube-system started at 2022-10-24 11:16:13 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.254: INFO: 	Container kube-controller-manager ready: true, restart count 0
Oct 25 02:00:01.254: INFO: kube-proxy-vrr69 from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.254: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 02:00:01.254: INFO: kube-scheduler-lab1-k8s-master-2 from kube-system started at 2022-10-24 13:15:08 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.254: INFO: 	Container kube-scheduler ready: true, restart count 0
Oct 25 02:00:01.254: INFO: nodelocaldns-xr5sh from kube-system started at 2022-10-24 13:24:05 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.254: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 02:00:01.254: INFO: openstack-cloud-controller-manager-27jr7 from kube-system started at 2022-10-24 11:12:57 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.254: INFO: 	Container openstack-cloud-controller-manager ready: true, restart count 2
Oct 25 02:00:01.254: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-pr8xq from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 02:00:01.254: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 02:00:01.254: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 02:00:01.254: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-master-3 before test
Oct 25 02:00:01.273: INFO: calico-node-bp6ts from kube-system started at 2022-10-24 13:34:44 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.273: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 02:00:01.273: INFO: coredns-74d6c5659f-m6zm9 from kube-system started at 2022-10-24 13:36:27 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.273: INFO: 	Container coredns ready: true, restart count 0
Oct 25 02:00:01.273: INFO: csi-cinder-nodeplugin-x2dl8 from kube-system started at 2022-10-24 13:24:53 +0000 UTC (3 container statuses recorded)
Oct 25 02:00:01.273: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 02:00:01.273: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 02:00:01.273: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 02:00:01.273: INFO: kube-apiserver-lab1-k8s-master-3 from kube-system started at 2022-10-24 13:34:08 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.273: INFO: 	Container kube-apiserver ready: true, restart count 0
Oct 25 02:00:01.273: INFO: kube-controller-manager-lab1-k8s-master-3 from kube-system started at 2022-10-24 13:31:36 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.273: INFO: 	Container kube-controller-manager ready: true, restart count 0
Oct 25 02:00:01.273: INFO: kube-proxy-4fvsp from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.273: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 02:00:01.273: INFO: kube-scheduler-lab1-k8s-master-3 from kube-system started at 2022-10-24 13:34:07 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.273: INFO: 	Container kube-scheduler ready: true, restart count 1
Oct 25 02:00:01.273: INFO: nodelocaldns-2lsxm from kube-system started at 2022-10-24 13:24:05 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.273: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 02:00:01.273: INFO: openstack-cloud-controller-manager-4jzsk from kube-system started at 2022-10-24 11:44:40 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.273: INFO: 	Container openstack-cloud-controller-manager ready: true, restart count 1
Oct 25 02:00:01.273: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-8w5gv from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 02:00:01.273: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 02:00:01.273: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 02:00:01.273: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-node-1 before test
Oct 25 02:00:01.325: INFO: calico-node-5ddpv from kube-system started at 2022-10-24 13:44:52 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.325: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 02:00:01.325: INFO: csi-cinder-controllerplugin-5f5b5c795f-lrxvf from kube-system started at 2022-10-24 13:46:01 +0000 UTC (6 container statuses recorded)
Oct 25 02:00:01.325: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 02:00:01.325: INFO: 	Container csi-attacher ready: true, restart count 0
Oct 25 02:00:01.325: INFO: 	Container csi-provisioner ready: true, restart count 0
Oct 25 02:00:01.325: INFO: 	Container csi-resizer ready: true, restart count 0
Oct 25 02:00:01.325: INFO: 	Container csi-snapshotter ready: true, restart count 0
Oct 25 02:00:01.325: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 02:00:01.325: INFO: csi-cinder-nodeplugin-l5nps from kube-system started at 2022-10-24 13:44:52 +0000 UTC (3 container statuses recorded)
Oct 25 02:00:01.326: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 02:00:01.326: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 02:00:01.326: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 02:00:01.326: INFO: kube-proxy-ltn2j from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.326: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 02:00:01.326: INFO: nginx-proxy-lab1-k8s-node-1 from kube-system started at 2022-10-24 13:45:14 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.326: INFO: 	Container nginx-proxy ready: true, restart count 0
Oct 25 02:00:01.326: INFO: nodelocaldns-22vhv from kube-system started at 2022-10-24 13:44:52 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.326: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 02:00:01.326: INFO: snapshot-controller-59c7b5464b-hgf7x from kube-system started at 2022-10-24 13:46:01 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.326: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 25 02:00:01.326: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-z9z72 from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 02:00:01.326: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 02:00:01.326: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 02:00:01.326: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-node-2 before test
Oct 25 02:00:01.338: INFO: calico-kube-controllers-8ff9fbd88-qkxfb from kube-system started at 2022-10-24 13:52:38 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.339: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 25 02:00:01.339: INFO: calico-node-t24sg from kube-system started at 2022-10-24 13:51:29 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.339: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 02:00:01.339: INFO: csi-cinder-nodeplugin-6lwfv from kube-system started at 2022-10-24 13:51:29 +0000 UTC (3 container statuses recorded)
Oct 25 02:00:01.339: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 02:00:01.339: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 02:00:01.339: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 02:00:01.339: INFO: kube-proxy-9z7jt from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.339: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 02:00:01.339: INFO: nginx-proxy-lab1-k8s-node-2 from kube-system started at 2022-10-24 13:51:52 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.339: INFO: 	Container nginx-proxy ready: true, restart count 0
Oct 25 02:00:01.339: INFO: nodelocaldns-hf2sj from kube-system started at 2022-10-24 13:51:29 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.339: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 02:00:01.339: INFO: sonobuoy-e2e-job-a74b57dba1144d0b from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 02:00:01.339: INFO: 	Container e2e ready: true, restart count 0
Oct 25 02:00:01.339: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 02:00:01.339: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-vwzzz from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 02:00:01.339: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 02:00:01.339: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 02:00:01.339: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-node-3 before test
Oct 25 02:00:01.354: INFO: replace-27777719-j8cnf from cronjob-4799 started at 2022-10-25 01:59:00 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.354: INFO: 	Container c ready: true, restart count 0
Oct 25 02:00:01.354: INFO: replace-27777720-6t5mb from cronjob-4799 started at 2022-10-25 02:00:00 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.354: INFO: 	Container c ready: true, restart count 0
Oct 25 02:00:01.354: INFO: calico-node-rnp6v from kube-system started at 2022-10-24 13:57:49 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.354: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 02:00:01.354: INFO: csi-cinder-nodeplugin-s2s7w from kube-system started at 2022-10-24 13:57:49 +0000 UTC (3 container statuses recorded)
Oct 25 02:00:01.354: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 02:00:01.354: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 02:00:01.354: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 02:00:01.354: INFO: kube-proxy-dfcgm from kube-system started at 2022-10-24 13:57:49 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.354: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 02:00:01.354: INFO: nginx-proxy-lab1-k8s-node-3 from kube-system started at 2022-10-24 13:58:11 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.354: INFO: 	Container nginx-proxy ready: true, restart count 0
Oct 25 02:00:01.354: INFO: nodelocaldns-2qn67 from kube-system started at 2022-10-24 13:57:49 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.355: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 02:00:01.355: INFO: sonobuoy from sonobuoy started at 2022-10-25 01:39:35 +0000 UTC (1 container statuses recorded)
Oct 25 02:00:01.355: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 25 02:00:01.355: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-ttkt7 from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 02:00:01.355: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 02:00:01.355: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-9b94eeb1-d12a-4a75-873d-ffb4397597d2 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-9b94eeb1-d12a-4a75-873d-ffb4397597d2 off the node lab1-k8s-node-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-9b94eeb1-d12a-4a75-873d-ffb4397597d2
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:00:05.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5226" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":356,"completed":66,"skipped":1089,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:00:05.546: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating secret secrets-3498/secret-test-bf427b0c-763b-464e-9461-d49ab91d7692
STEP: Creating a pod to test consume secrets
Oct 25 02:00:05.607: INFO: Waiting up to 5m0s for pod "pod-configmaps-7ea47b08-c11e-42b0-9a5a-242a018d13cb" in namespace "secrets-3498" to be "Succeeded or Failed"
Oct 25 02:00:05.618: INFO: Pod "pod-configmaps-7ea47b08-c11e-42b0-9a5a-242a018d13cb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.934384ms
Oct 25 02:00:07.629: INFO: Pod "pod-configmaps-7ea47b08-c11e-42b0-9a5a-242a018d13cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021820596s
Oct 25 02:00:09.639: INFO: Pod "pod-configmaps-7ea47b08-c11e-42b0-9a5a-242a018d13cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031653416s
STEP: Saw pod success
Oct 25 02:00:09.639: INFO: Pod "pod-configmaps-7ea47b08-c11e-42b0-9a5a-242a018d13cb" satisfied condition "Succeeded or Failed"
Oct 25 02:00:09.645: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-configmaps-7ea47b08-c11e-42b0-9a5a-242a018d13cb container env-test: <nil>
STEP: delete the pod
Oct 25 02:00:09.680: INFO: Waiting for pod pod-configmaps-7ea47b08-c11e-42b0-9a5a-242a018d13cb to disappear
Oct 25 02:00:09.685: INFO: Pod pod-configmaps-7ea47b08-c11e-42b0-9a5a-242a018d13cb no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Oct 25 02:00:09.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3498" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":356,"completed":67,"skipped":1107,"failed":0}
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:00:09.709: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 02:00:09.755: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bfb4d850-0b20-45f1-9d55-aee2c1d68c6a" in namespace "downward-api-3276" to be "Succeeded or Failed"
Oct 25 02:00:09.764: INFO: Pod "downwardapi-volume-bfb4d850-0b20-45f1-9d55-aee2c1d68c6a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.641715ms
Oct 25 02:00:11.775: INFO: Pod "downwardapi-volume-bfb4d850-0b20-45f1-9d55-aee2c1d68c6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019670534s
Oct 25 02:00:13.784: INFO: Pod "downwardapi-volume-bfb4d850-0b20-45f1-9d55-aee2c1d68c6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028124822s
STEP: Saw pod success
Oct 25 02:00:13.784: INFO: Pod "downwardapi-volume-bfb4d850-0b20-45f1-9d55-aee2c1d68c6a" satisfied condition "Succeeded or Failed"
Oct 25 02:00:13.789: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-bfb4d850-0b20-45f1-9d55-aee2c1d68c6a container client-container: <nil>
STEP: delete the pod
Oct 25 02:00:13.835: INFO: Waiting for pod downwardapi-volume-bfb4d850-0b20-45f1-9d55-aee2c1d68c6a to disappear
Oct 25 02:00:13.840: INFO: Pod downwardapi-volume-bfb4d850-0b20-45f1-9d55-aee2c1d68c6a no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Oct 25 02:00:13.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3276" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":68,"skipped":1111,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:00:13.870: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Oct 25 02:00:13.917: INFO: Waiting up to 5m0s for pod "downward-api-d1bf0a53-b129-4c0e-b368-a5f1f2ce4ba5" in namespace "downward-api-1534" to be "Succeeded or Failed"
Oct 25 02:00:13.923: INFO: Pod "downward-api-d1bf0a53-b129-4c0e-b368-a5f1f2ce4ba5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.726278ms
Oct 25 02:00:15.936: INFO: Pod "downward-api-d1bf0a53-b129-4c0e-b368-a5f1f2ce4ba5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018439639s
Oct 25 02:00:17.945: INFO: Pod "downward-api-d1bf0a53-b129-4c0e-b368-a5f1f2ce4ba5": Phase="Running", Reason="", readiness=false. Elapsed: 4.027641277s
Oct 25 02:00:19.957: INFO: Pod "downward-api-d1bf0a53-b129-4c0e-b368-a5f1f2ce4ba5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039563293s
STEP: Saw pod success
Oct 25 02:00:19.957: INFO: Pod "downward-api-d1bf0a53-b129-4c0e-b368-a5f1f2ce4ba5" satisfied condition "Succeeded or Failed"
Oct 25 02:00:19.963: INFO: Trying to get logs from node lab1-k8s-node-2 pod downward-api-d1bf0a53-b129-4c0e-b368-a5f1f2ce4ba5 container dapi-container: <nil>
STEP: delete the pod
Oct 25 02:00:20.009: INFO: Waiting for pod downward-api-d1bf0a53-b129-4c0e-b368-a5f1f2ce4ba5 to disappear
Oct 25 02:00:20.013: INFO: Pod downward-api-d1bf0a53-b129-4c0e-b368-a5f1f2ce4ba5 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Oct 25 02:00:20.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1534" for this suite.

• [SLOW TEST:6.162 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":356,"completed":69,"skipped":1215,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:00:20.034: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 02:00:20.081: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1a2efaeb-cd64-445e-a53e-125109e1b960" in namespace "projected-8628" to be "Succeeded or Failed"
Oct 25 02:00:20.094: INFO: Pod "downwardapi-volume-1a2efaeb-cd64-445e-a53e-125109e1b960": Phase="Pending", Reason="", readiness=false. Elapsed: 12.840872ms
Oct 25 02:00:22.106: INFO: Pod "downwardapi-volume-1a2efaeb-cd64-445e-a53e-125109e1b960": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025332856s
Oct 25 02:00:24.115: INFO: Pod "downwardapi-volume-1a2efaeb-cd64-445e-a53e-125109e1b960": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03386738s
STEP: Saw pod success
Oct 25 02:00:24.115: INFO: Pod "downwardapi-volume-1a2efaeb-cd64-445e-a53e-125109e1b960" satisfied condition "Succeeded or Failed"
Oct 25 02:00:24.121: INFO: Trying to get logs from node lab1-k8s-node-2 pod downwardapi-volume-1a2efaeb-cd64-445e-a53e-125109e1b960 container client-container: <nil>
STEP: delete the pod
Oct 25 02:00:24.154: INFO: Waiting for pod downwardapi-volume-1a2efaeb-cd64-445e-a53e-125109e1b960 to disappear
Oct 25 02:00:24.159: INFO: Pod downwardapi-volume-1a2efaeb-cd64-445e-a53e-125109e1b960 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Oct 25 02:00:24.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8628" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":356,"completed":70,"skipped":1239,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:00:24.181: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename sysctl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl
STEP: Watching for error events or started pod
STEP: Waiting for pod completion
STEP: Checking that the pod succeeded
STEP: Getting logs from the pod
STEP: Checking that the sysctl is actually updated
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:188
Oct 25 02:00:28.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-4728" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":356,"completed":71,"skipped":1299,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:00:28.298: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:00:30.378: INFO: Deleting pod "var-expansion-e3d6146c-6ae6-4f39-a871-1c29781b60b1" in namespace "var-expansion-5858"
Oct 25 02:00:30.392: INFO: Wait up to 5m0s for pod "var-expansion-e3d6146c-6ae6-4f39-a871-1c29781b60b1" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Oct 25 02:00:32.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5858" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","total":356,"completed":72,"skipped":1340,"failed":0}

------------------------------
[sig-architecture] Conformance Tests 
  should have at least two untainted nodes [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:00:32.434: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename conformance-tests
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should have at least two untainted nodes [Conformance]
  test/e2e/framework/framework.go:652
STEP: Getting node addresses
Oct 25 02:00:32.473: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:188
Oct 25 02:00:32.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-401" for this suite.
•{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","total":356,"completed":73,"skipped":1340,"failed":0}
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:00:32.513: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Oct 25 02:00:39.064: INFO: 80 pods remaining
Oct 25 02:00:39.064: INFO: 80 pods has nil DeletionTimestamp
Oct 25 02:00:39.064: INFO: 
Oct 25 02:00:40.447: INFO: 75 pods remaining
Oct 25 02:00:40.447: INFO: 68 pods has nil DeletionTimestamp
Oct 25 02:00:40.447: INFO: 
Oct 25 02:00:40.832: INFO: 55 pods remaining
Oct 25 02:00:40.833: INFO: 55 pods has nil DeletionTimestamp
Oct 25 02:00:40.833: INFO: 
Oct 25 02:00:41.942: INFO: 45 pods remaining
Oct 25 02:00:41.942: INFO: 42 pods has nil DeletionTimestamp
Oct 25 02:00:41.942: INFO: 
Oct 25 02:00:42.896: INFO: 34 pods remaining
Oct 25 02:00:42.896: INFO: 33 pods has nil DeletionTimestamp
Oct 25 02:00:42.896: INFO: 
Oct 25 02:00:43.816: INFO: 15 pods remaining
Oct 25 02:00:43.816: INFO: 15 pods has nil DeletionTimestamp
Oct 25 02:00:43.816: INFO: 
Oct 25 02:00:44.915: INFO: 0 pods remaining
Oct 25 02:00:44.915: INFO: 0 pods has nil DeletionTimestamp
Oct 25 02:00:44.915: INFO: 
STEP: Gathering metrics
Oct 25 02:00:45.956: INFO: The status of Pod kube-controller-manager-lab1-k8s-master-3 is Running (Ready = true)
Oct 25 02:00:46.085: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Oct 25 02:00:46.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5923" for this suite.

• [SLOW TEST:13.654 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":356,"completed":74,"skipped":1343,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:00:46.167: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Oct 25 02:00:46.300: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:00:48.314: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:00:50.315: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Oct 25 02:00:50.341: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:00:52.357: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:00:54.349: INFO: The status of Pod pod-with-poststart-http-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 25 02:00:54.380: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 25 02:00:54.387: INFO: Pod pod-with-poststart-http-hook still exists
Oct 25 02:00:56.388: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 25 02:00:56.397: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Oct 25 02:00:56.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6006" for this suite.

• [SLOW TEST:10.253 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":356,"completed":75,"skipped":1369,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:00:56.420: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a Replicaset
STEP: Verify that the required pods have come up.
Oct 25 02:00:56.471: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 25 02:01:01.492: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Getting /status
Oct 25 02:01:01.509: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status
Oct 25 02:01:01.525: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated
Oct 25 02:01:01.528: INFO: Observed &ReplicaSet event: ADDED
Oct 25 02:01:01.528: INFO: Observed &ReplicaSet event: MODIFIED
Oct 25 02:01:01.528: INFO: Observed &ReplicaSet event: MODIFIED
Oct 25 02:01:01.528: INFO: Observed &ReplicaSet event: MODIFIED
Oct 25 02:01:01.532: INFO: Found replicaset test-rs in namespace replicaset-6803 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Oct 25 02:01:01.532: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status
Oct 25 02:01:01.533: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Oct 25 02:01:01.576: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched
Oct 25 02:01:01.579: INFO: Observed &ReplicaSet event: ADDED
Oct 25 02:01:01.579: INFO: Observed &ReplicaSet event: MODIFIED
Oct 25 02:01:01.579: INFO: Observed &ReplicaSet event: MODIFIED
Oct 25 02:01:01.579: INFO: Observed &ReplicaSet event: MODIFIED
Oct 25 02:01:01.579: INFO: Observed replicaset test-rs in namespace replicaset-6803 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Oct 25 02:01:01.580: INFO: Observed &ReplicaSet event: MODIFIED
Oct 25 02:01:01.580: INFO: Found replicaset test-rs in namespace replicaset-6803 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Oct 25 02:01:01.580: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Oct 25 02:01:01.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6803" for this suite.

• [SLOW TEST:5.190 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","total":356,"completed":76,"skipped":1385,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:01:01.611: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:01:01.650: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Oct 25 02:01:11.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-6273 --namespace=crd-publish-openapi-6273 create -f -'
Oct 25 02:01:12.177: INFO: stderr: ""
Oct 25 02:01:12.177: INFO: stdout: "e2e-test-crd-publish-openapi-904-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Oct 25 02:01:12.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-6273 --namespace=crd-publish-openapi-6273 delete e2e-test-crd-publish-openapi-904-crds test-cr'
Oct 25 02:01:12.302: INFO: stderr: ""
Oct 25 02:01:12.302: INFO: stdout: "e2e-test-crd-publish-openapi-904-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Oct 25 02:01:12.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-6273 --namespace=crd-publish-openapi-6273 apply -f -'
Oct 25 02:01:12.881: INFO: stderr: ""
Oct 25 02:01:12.881: INFO: stdout: "e2e-test-crd-publish-openapi-904-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Oct 25 02:01:12.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-6273 --namespace=crd-publish-openapi-6273 delete e2e-test-crd-publish-openapi-904-crds test-cr'
Oct 25 02:01:12.965: INFO: stderr: ""
Oct 25 02:01:12.965: INFO: stdout: "e2e-test-crd-publish-openapi-904-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Oct 25 02:01:12.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-6273 explain e2e-test-crd-publish-openapi-904-crds'
Oct 25 02:01:13.729: INFO: stderr: ""
Oct 25 02:01:13.729: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-904-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:01:16.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6273" for this suite.

• [SLOW TEST:15.124 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":356,"completed":77,"skipped":1401,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:01:16.737: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-downwardapi-hmxm
STEP: Creating a pod to test atomic-volume-subpath
Oct 25 02:01:16.814: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-hmxm" in namespace "subpath-51" to be "Succeeded or Failed"
Oct 25 02:01:16.826: INFO: Pod "pod-subpath-test-downwardapi-hmxm": Phase="Pending", Reason="", readiness=false. Elapsed: 11.79274ms
Oct 25 02:01:18.839: INFO: Pod "pod-subpath-test-downwardapi-hmxm": Phase="Running", Reason="", readiness=true. Elapsed: 2.025222096s
Oct 25 02:01:20.863: INFO: Pod "pod-subpath-test-downwardapi-hmxm": Phase="Running", Reason="", readiness=true. Elapsed: 4.049393806s
Oct 25 02:01:22.874: INFO: Pod "pod-subpath-test-downwardapi-hmxm": Phase="Running", Reason="", readiness=true. Elapsed: 6.060643176s
Oct 25 02:01:24.888: INFO: Pod "pod-subpath-test-downwardapi-hmxm": Phase="Running", Reason="", readiness=true. Elapsed: 8.074608624s
Oct 25 02:01:26.902: INFO: Pod "pod-subpath-test-downwardapi-hmxm": Phase="Running", Reason="", readiness=true. Elapsed: 10.088080017s
Oct 25 02:01:28.918: INFO: Pod "pod-subpath-test-downwardapi-hmxm": Phase="Running", Reason="", readiness=true. Elapsed: 12.104353527s
Oct 25 02:01:30.927: INFO: Pod "pod-subpath-test-downwardapi-hmxm": Phase="Running", Reason="", readiness=true. Elapsed: 14.113546319s
Oct 25 02:01:32.942: INFO: Pod "pod-subpath-test-downwardapi-hmxm": Phase="Running", Reason="", readiness=true. Elapsed: 16.128112419s
Oct 25 02:01:34.955: INFO: Pod "pod-subpath-test-downwardapi-hmxm": Phase="Running", Reason="", readiness=true. Elapsed: 18.140762118s
Oct 25 02:01:36.965: INFO: Pod "pod-subpath-test-downwardapi-hmxm": Phase="Running", Reason="", readiness=true. Elapsed: 20.151036195s
Oct 25 02:01:38.971: INFO: Pod "pod-subpath-test-downwardapi-hmxm": Phase="Running", Reason="", readiness=false. Elapsed: 22.15714782s
Oct 25 02:01:40.982: INFO: Pod "pod-subpath-test-downwardapi-hmxm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.168545261s
STEP: Saw pod success
Oct 25 02:01:40.982: INFO: Pod "pod-subpath-test-downwardapi-hmxm" satisfied condition "Succeeded or Failed"
Oct 25 02:01:40.990: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-subpath-test-downwardapi-hmxm container test-container-subpath-downwardapi-hmxm: <nil>
STEP: delete the pod
Oct 25 02:01:41.036: INFO: Waiting for pod pod-subpath-test-downwardapi-hmxm to disappear
Oct 25 02:01:41.042: INFO: Pod pod-subpath-test-downwardapi-hmxm no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-hmxm
Oct 25 02:01:41.042: INFO: Deleting pod "pod-subpath-test-downwardapi-hmxm" in namespace "subpath-51"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Oct 25 02:01:41.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-51" for this suite.

• [SLOW TEST:24.341 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","total":356,"completed":78,"skipped":1429,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:01:41.078: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Oct 25 02:02:41.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2081" for this suite.

• [SLOW TEST:60.114 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":356,"completed":79,"skipped":1445,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:02:41.194: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:02:41.260: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-253c773f-7edd-4446-b30a-35ab538e331e" in namespace "security-context-test-1583" to be "Succeeded or Failed"
Oct 25 02:02:41.269: INFO: Pod "busybox-privileged-false-253c773f-7edd-4446-b30a-35ab538e331e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.685445ms
Oct 25 02:02:43.283: INFO: Pod "busybox-privileged-false-253c773f-7edd-4446-b30a-35ab538e331e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02246492s
Oct 25 02:02:45.295: INFO: Pod "busybox-privileged-false-253c773f-7edd-4446-b30a-35ab538e331e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034774985s
Oct 25 02:02:45.295: INFO: Pod "busybox-privileged-false-253c773f-7edd-4446-b30a-35ab538e331e" satisfied condition "Succeeded or Failed"
Oct 25 02:02:45.308: INFO: Got logs for pod "busybox-privileged-false-253c773f-7edd-4446-b30a-35ab538e331e": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Oct 25 02:02:45.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1583" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":80,"skipped":1459,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:02:45.334: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:02:45.383: INFO: Got root ca configmap in namespace "svcaccounts-1092"
Oct 25 02:02:45.395: INFO: Deleted root ca configmap in namespace "svcaccounts-1092"
STEP: waiting for a new root ca configmap created
Oct 25 02:02:45.904: INFO: Recreated root ca configmap in namespace "svcaccounts-1092"
Oct 25 02:02:45.912: INFO: Updated root ca configmap in namespace "svcaccounts-1092"
STEP: waiting for the root ca configmap reconciled
Oct 25 02:02:46.423: INFO: Reconciled root ca configmap in namespace "svcaccounts-1092"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Oct 25 02:02:46.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1092" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","total":356,"completed":81,"skipped":1498,"failed":0}
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:02:46.448: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Oct 25 02:02:46.489: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 25 02:02:46.508: INFO: Waiting for terminating namespaces to be deleted...
Oct 25 02:02:46.516: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-master-1 before test
Oct 25 02:02:46.532: INFO: calico-node-p96g7 from kube-system started at 2022-10-24 13:36:57 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.532: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 02:02:46.532: INFO: csi-cinder-nodeplugin-rpg8q from kube-system started at 2022-10-24 13:24:56 +0000 UTC (3 container statuses recorded)
Oct 25 02:02:46.532: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 02:02:46.532: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 02:02:46.532: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 02:02:46.532: INFO: kube-apiserver-lab1-k8s-master-1 from kube-system started at 2022-10-24 13:25:02 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.532: INFO: 	Container kube-apiserver ready: true, restart count 0
Oct 25 02:02:46.532: INFO: kube-controller-manager-lab1-k8s-master-1 from kube-system started at 2022-10-24 13:25:02 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.532: INFO: 	Container kube-controller-manager ready: true, restart count 2
Oct 25 02:02:46.532: INFO: kube-proxy-s6wnk from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.532: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 02:02:46.532: INFO: kube-scheduler-lab1-k8s-master-1 from kube-system started at 2022-10-24 13:25:02 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.532: INFO: 	Container kube-scheduler ready: true, restart count 1
Oct 25 02:02:46.532: INFO: metrics-server-54d48d8c7-mcnqp from kube-system started at 2022-10-24 13:25:08 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.532: INFO: 	Container metrics-server ready: true, restart count 0
Oct 25 02:02:46.532: INFO: nodelocaldns-lkpsg from kube-system started at 2022-10-24 13:24:07 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.532: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 02:02:46.532: INFO: openstack-cloud-controller-manager-dv986 from kube-system started at 2022-10-24 10:53:46 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.532: INFO: 	Container openstack-cloud-controller-manager ready: true, restart count 2
Oct 25 02:02:46.532: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-mshb5 from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 02:02:46.532: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 02:02:46.532: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 02:02:46.532: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-master-2 before test
Oct 25 02:02:46.559: INFO: calico-node-vqr8k from kube-system started at 2022-10-24 13:35:46 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.559: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 02:02:46.559: INFO: coredns-74d6c5659f-dcc4x from kube-system started at 2022-10-24 13:36:35 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.559: INFO: 	Container coredns ready: true, restart count 0
Oct 25 02:02:46.559: INFO: csi-cinder-nodeplugin-qw5tr from kube-system started at 2022-10-24 13:24:51 +0000 UTC (3 container statuses recorded)
Oct 25 02:02:46.559: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 02:02:46.559: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 02:02:46.559: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 02:02:46.559: INFO: dns-autoscaler-78676459f6-7hpdl from kube-system started at 2022-10-24 13:29:51 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.559: INFO: 	Container autoscaler ready: true, restart count 0
Oct 25 02:02:46.559: INFO: kube-apiserver-lab1-k8s-master-2 from kube-system started at 2022-10-24 13:29:45 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.559: INFO: 	Container kube-apiserver ready: true, restart count 0
Oct 25 02:02:46.559: INFO: kube-controller-manager-lab1-k8s-master-2 from kube-system started at 2022-10-24 11:16:13 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.559: INFO: 	Container kube-controller-manager ready: true, restart count 0
Oct 25 02:02:46.559: INFO: kube-proxy-vrr69 from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.559: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 02:02:46.559: INFO: kube-scheduler-lab1-k8s-master-2 from kube-system started at 2022-10-24 13:15:08 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.559: INFO: 	Container kube-scheduler ready: true, restart count 0
Oct 25 02:02:46.559: INFO: nodelocaldns-xr5sh from kube-system started at 2022-10-24 13:24:05 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.559: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 02:02:46.559: INFO: openstack-cloud-controller-manager-27jr7 from kube-system started at 2022-10-24 11:12:57 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.559: INFO: 	Container openstack-cloud-controller-manager ready: true, restart count 2
Oct 25 02:02:46.559: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-pr8xq from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 02:02:46.559: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 02:02:46.559: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 02:02:46.559: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-master-3 before test
Oct 25 02:02:46.584: INFO: calico-node-bp6ts from kube-system started at 2022-10-24 13:34:44 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.585: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 02:02:46.585: INFO: coredns-74d6c5659f-m6zm9 from kube-system started at 2022-10-24 13:36:27 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.585: INFO: 	Container coredns ready: true, restart count 0
Oct 25 02:02:46.585: INFO: csi-cinder-nodeplugin-x2dl8 from kube-system started at 2022-10-24 13:24:53 +0000 UTC (3 container statuses recorded)
Oct 25 02:02:46.585: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 02:02:46.585: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 02:02:46.585: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 02:02:46.585: INFO: kube-apiserver-lab1-k8s-master-3 from kube-system started at 2022-10-24 13:34:08 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.585: INFO: 	Container kube-apiserver ready: true, restart count 0
Oct 25 02:02:46.585: INFO: kube-controller-manager-lab1-k8s-master-3 from kube-system started at 2022-10-24 13:31:36 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.585: INFO: 	Container kube-controller-manager ready: true, restart count 0
Oct 25 02:02:46.585: INFO: kube-proxy-4fvsp from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.585: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 02:02:46.585: INFO: kube-scheduler-lab1-k8s-master-3 from kube-system started at 2022-10-24 13:34:07 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.585: INFO: 	Container kube-scheduler ready: true, restart count 1
Oct 25 02:02:46.585: INFO: nodelocaldns-2lsxm from kube-system started at 2022-10-24 13:24:05 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.585: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 02:02:46.585: INFO: openstack-cloud-controller-manager-4jzsk from kube-system started at 2022-10-24 11:44:40 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.585: INFO: 	Container openstack-cloud-controller-manager ready: true, restart count 1
Oct 25 02:02:46.585: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-8w5gv from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 02:02:46.585: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 02:02:46.585: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 02:02:46.585: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-node-1 before test
Oct 25 02:02:46.615: INFO: calico-node-5ddpv from kube-system started at 2022-10-24 13:44:52 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.615: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 02:02:46.615: INFO: csi-cinder-controllerplugin-5f5b5c795f-lrxvf from kube-system started at 2022-10-24 13:46:01 +0000 UTC (6 container statuses recorded)
Oct 25 02:02:46.615: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 02:02:46.615: INFO: 	Container csi-attacher ready: true, restart count 0
Oct 25 02:02:46.615: INFO: 	Container csi-provisioner ready: true, restart count 0
Oct 25 02:02:46.615: INFO: 	Container csi-resizer ready: true, restart count 0
Oct 25 02:02:46.615: INFO: 	Container csi-snapshotter ready: true, restart count 0
Oct 25 02:02:46.615: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 02:02:46.615: INFO: csi-cinder-nodeplugin-l5nps from kube-system started at 2022-10-24 13:44:52 +0000 UTC (3 container statuses recorded)
Oct 25 02:02:46.615: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 02:02:46.615: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 02:02:46.615: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 02:02:46.615: INFO: kube-proxy-ltn2j from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.615: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 02:02:46.615: INFO: nginx-proxy-lab1-k8s-node-1 from kube-system started at 2022-10-24 13:45:14 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.615: INFO: 	Container nginx-proxy ready: true, restart count 0
Oct 25 02:02:46.615: INFO: nodelocaldns-22vhv from kube-system started at 2022-10-24 13:44:52 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.615: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 02:02:46.615: INFO: snapshot-controller-59c7b5464b-hgf7x from kube-system started at 2022-10-24 13:46:01 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.615: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 25 02:02:46.615: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-z9z72 from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 02:02:46.615: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 02:02:46.615: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 02:02:46.615: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-node-2 before test
Oct 25 02:02:46.631: INFO: calico-kube-controllers-8ff9fbd88-qkxfb from kube-system started at 2022-10-24 13:52:38 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.631: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 25 02:02:46.631: INFO: calico-node-t24sg from kube-system started at 2022-10-24 13:51:29 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.631: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 02:02:46.631: INFO: csi-cinder-nodeplugin-6lwfv from kube-system started at 2022-10-24 13:51:29 +0000 UTC (3 container statuses recorded)
Oct 25 02:02:46.632: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 02:02:46.632: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 02:02:46.632: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 02:02:46.632: INFO: kube-proxy-9z7jt from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.632: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 02:02:46.632: INFO: nginx-proxy-lab1-k8s-node-2 from kube-system started at 2022-10-24 13:51:52 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.632: INFO: 	Container nginx-proxy ready: true, restart count 0
Oct 25 02:02:46.632: INFO: nodelocaldns-hf2sj from kube-system started at 2022-10-24 13:51:29 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.632: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 02:02:46.632: INFO: sonobuoy-e2e-job-a74b57dba1144d0b from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 02:02:46.632: INFO: 	Container e2e ready: true, restart count 0
Oct 25 02:02:46.632: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 02:02:46.632: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-vwzzz from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 02:02:46.632: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 02:02:46.632: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 02:02:46.632: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-node-3 before test
Oct 25 02:02:46.651: INFO: test-webserver-a5cfdf1d-6022-46cb-9dbc-2499ca30ce9b from container-probe-2081 started at 2022-10-25 02:01:41 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.651: INFO: 	Container test-webserver ready: false, restart count 0
Oct 25 02:02:46.651: INFO: calico-node-rnp6v from kube-system started at 2022-10-24 13:57:49 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.651: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 02:02:46.651: INFO: csi-cinder-nodeplugin-s2s7w from kube-system started at 2022-10-24 13:57:49 +0000 UTC (3 container statuses recorded)
Oct 25 02:02:46.651: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 02:02:46.651: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 02:02:46.651: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 02:02:46.651: INFO: kube-proxy-dfcgm from kube-system started at 2022-10-24 13:57:49 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.651: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 02:02:46.651: INFO: nginx-proxy-lab1-k8s-node-3 from kube-system started at 2022-10-24 13:58:11 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.651: INFO: 	Container nginx-proxy ready: true, restart count 0
Oct 25 02:02:46.651: INFO: nodelocaldns-2qn67 from kube-system started at 2022-10-24 13:57:49 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.651: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 02:02:46.651: INFO: busybox-privileged-false-253c773f-7edd-4446-b30a-35ab538e331e from security-context-test-1583 started at 2022-10-25 02:02:41 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.651: INFO: 	Container busybox-privileged-false-253c773f-7edd-4446-b30a-35ab538e331e ready: false, restart count 0
Oct 25 02:02:46.651: INFO: sonobuoy from sonobuoy started at 2022-10-25 01:39:35 +0000 UTC (1 container statuses recorded)
Oct 25 02:02:46.651: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 25 02:02:46.651: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-ttkt7 from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 02:02:46.651: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 02:02:46.651: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
STEP: verifying the node has the label node lab1-k8s-master-1
STEP: verifying the node has the label node lab1-k8s-master-2
STEP: verifying the node has the label node lab1-k8s-master-3
STEP: verifying the node has the label node lab1-k8s-node-1
STEP: verifying the node has the label node lab1-k8s-node-2
STEP: verifying the node has the label node lab1-k8s-node-3
Oct 25 02:02:46.898: INFO: Pod test-webserver-a5cfdf1d-6022-46cb-9dbc-2499ca30ce9b requesting resource cpu=0m on Node lab1-k8s-node-3
Oct 25 02:02:46.898: INFO: Pod calico-kube-controllers-8ff9fbd88-qkxfb requesting resource cpu=30m on Node lab1-k8s-node-2
Oct 25 02:02:46.898: INFO: Pod calico-node-5ddpv requesting resource cpu=150m on Node lab1-k8s-node-1
Oct 25 02:02:46.898: INFO: Pod calico-node-bp6ts requesting resource cpu=150m on Node lab1-k8s-master-3
Oct 25 02:02:46.898: INFO: Pod calico-node-p96g7 requesting resource cpu=150m on Node lab1-k8s-master-1
Oct 25 02:02:46.898: INFO: Pod calico-node-rnp6v requesting resource cpu=150m on Node lab1-k8s-node-3
Oct 25 02:02:46.899: INFO: Pod calico-node-t24sg requesting resource cpu=150m on Node lab1-k8s-node-2
Oct 25 02:02:46.899: INFO: Pod calico-node-vqr8k requesting resource cpu=150m on Node lab1-k8s-master-2
Oct 25 02:02:46.899: INFO: Pod coredns-74d6c5659f-dcc4x requesting resource cpu=100m on Node lab1-k8s-master-2
Oct 25 02:02:46.899: INFO: Pod coredns-74d6c5659f-m6zm9 requesting resource cpu=100m on Node lab1-k8s-master-3
Oct 25 02:02:46.899: INFO: Pod csi-cinder-controllerplugin-5f5b5c795f-lrxvf requesting resource cpu=0m on Node lab1-k8s-node-1
Oct 25 02:02:46.899: INFO: Pod csi-cinder-nodeplugin-6lwfv requesting resource cpu=0m on Node lab1-k8s-node-2
Oct 25 02:02:46.899: INFO: Pod csi-cinder-nodeplugin-l5nps requesting resource cpu=0m on Node lab1-k8s-node-1
Oct 25 02:02:46.899: INFO: Pod csi-cinder-nodeplugin-qw5tr requesting resource cpu=0m on Node lab1-k8s-master-2
Oct 25 02:02:46.899: INFO: Pod csi-cinder-nodeplugin-rpg8q requesting resource cpu=0m on Node lab1-k8s-master-1
Oct 25 02:02:46.899: INFO: Pod csi-cinder-nodeplugin-s2s7w requesting resource cpu=0m on Node lab1-k8s-node-3
Oct 25 02:02:46.899: INFO: Pod csi-cinder-nodeplugin-x2dl8 requesting resource cpu=0m on Node lab1-k8s-master-3
Oct 25 02:02:46.899: INFO: Pod dns-autoscaler-78676459f6-7hpdl requesting resource cpu=20m on Node lab1-k8s-master-2
Oct 25 02:02:46.899: INFO: Pod kube-apiserver-lab1-k8s-master-1 requesting resource cpu=250m on Node lab1-k8s-master-1
Oct 25 02:02:46.899: INFO: Pod kube-apiserver-lab1-k8s-master-2 requesting resource cpu=250m on Node lab1-k8s-master-2
Oct 25 02:02:46.899: INFO: Pod kube-apiserver-lab1-k8s-master-3 requesting resource cpu=250m on Node lab1-k8s-master-3
Oct 25 02:02:46.899: INFO: Pod kube-controller-manager-lab1-k8s-master-1 requesting resource cpu=200m on Node lab1-k8s-master-1
Oct 25 02:02:46.899: INFO: Pod kube-controller-manager-lab1-k8s-master-2 requesting resource cpu=200m on Node lab1-k8s-master-2
Oct 25 02:02:46.899: INFO: Pod kube-controller-manager-lab1-k8s-master-3 requesting resource cpu=200m on Node lab1-k8s-master-3
Oct 25 02:02:46.899: INFO: Pod kube-proxy-4fvsp requesting resource cpu=0m on Node lab1-k8s-master-3
Oct 25 02:02:46.899: INFO: Pod kube-proxy-9z7jt requesting resource cpu=0m on Node lab1-k8s-node-2
Oct 25 02:02:46.899: INFO: Pod kube-proxy-dfcgm requesting resource cpu=0m on Node lab1-k8s-node-3
Oct 25 02:02:46.899: INFO: Pod kube-proxy-ltn2j requesting resource cpu=0m on Node lab1-k8s-node-1
Oct 25 02:02:46.899: INFO: Pod kube-proxy-s6wnk requesting resource cpu=0m on Node lab1-k8s-master-1
Oct 25 02:02:46.899: INFO: Pod kube-proxy-vrr69 requesting resource cpu=0m on Node lab1-k8s-master-2
Oct 25 02:02:46.899: INFO: Pod kube-scheduler-lab1-k8s-master-1 requesting resource cpu=100m on Node lab1-k8s-master-1
Oct 25 02:02:46.899: INFO: Pod kube-scheduler-lab1-k8s-master-2 requesting resource cpu=100m on Node lab1-k8s-master-2
Oct 25 02:02:46.899: INFO: Pod kube-scheduler-lab1-k8s-master-3 requesting resource cpu=100m on Node lab1-k8s-master-3
Oct 25 02:02:46.899: INFO: Pod metrics-server-54d48d8c7-mcnqp requesting resource cpu=100m on Node lab1-k8s-master-1
Oct 25 02:02:46.899: INFO: Pod nginx-proxy-lab1-k8s-node-1 requesting resource cpu=25m on Node lab1-k8s-node-1
Oct 25 02:02:46.899: INFO: Pod nginx-proxy-lab1-k8s-node-2 requesting resource cpu=25m on Node lab1-k8s-node-2
Oct 25 02:02:46.899: INFO: Pod nginx-proxy-lab1-k8s-node-3 requesting resource cpu=25m on Node lab1-k8s-node-3
Oct 25 02:02:46.899: INFO: Pod nodelocaldns-22vhv requesting resource cpu=100m on Node lab1-k8s-node-1
Oct 25 02:02:46.899: INFO: Pod nodelocaldns-2lsxm requesting resource cpu=100m on Node lab1-k8s-master-3
Oct 25 02:02:46.899: INFO: Pod nodelocaldns-2qn67 requesting resource cpu=100m on Node lab1-k8s-node-3
Oct 25 02:02:46.899: INFO: Pod nodelocaldns-hf2sj requesting resource cpu=100m on Node lab1-k8s-node-2
Oct 25 02:02:46.899: INFO: Pod nodelocaldns-lkpsg requesting resource cpu=100m on Node lab1-k8s-master-1
Oct 25 02:02:46.899: INFO: Pod nodelocaldns-xr5sh requesting resource cpu=100m on Node lab1-k8s-master-2
Oct 25 02:02:46.899: INFO: Pod openstack-cloud-controller-manager-27jr7 requesting resource cpu=200m on Node lab1-k8s-master-2
Oct 25 02:02:46.899: INFO: Pod openstack-cloud-controller-manager-4jzsk requesting resource cpu=200m on Node lab1-k8s-master-3
Oct 25 02:02:46.899: INFO: Pod openstack-cloud-controller-manager-dv986 requesting resource cpu=200m on Node lab1-k8s-master-1
Oct 25 02:02:46.899: INFO: Pod snapshot-controller-59c7b5464b-hgf7x requesting resource cpu=0m on Node lab1-k8s-node-1
Oct 25 02:02:46.899: INFO: Pod sonobuoy requesting resource cpu=0m on Node lab1-k8s-node-3
Oct 25 02:02:46.899: INFO: Pod sonobuoy-e2e-job-a74b57dba1144d0b requesting resource cpu=0m on Node lab1-k8s-node-2
Oct 25 02:02:46.899: INFO: Pod sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-8w5gv requesting resource cpu=0m on Node lab1-k8s-master-3
Oct 25 02:02:46.899: INFO: Pod sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-mshb5 requesting resource cpu=0m on Node lab1-k8s-master-1
Oct 25 02:02:46.899: INFO: Pod sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-pr8xq requesting resource cpu=0m on Node lab1-k8s-master-2
Oct 25 02:02:46.899: INFO: Pod sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-ttkt7 requesting resource cpu=0m on Node lab1-k8s-node-3
Oct 25 02:02:46.899: INFO: Pod sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-vwzzz requesting resource cpu=0m on Node lab1-k8s-node-2
Oct 25 02:02:46.899: INFO: Pod sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-z9z72 requesting resource cpu=0m on Node lab1-k8s-node-1
STEP: Starting Pods to consume most of the cluster CPU.
Oct 25 02:02:46.899: INFO: Creating a pod which consumes cpu=315m on Node lab1-k8s-master-1
Oct 25 02:02:46.917: INFO: Creating a pod which consumes cpu=301m on Node lab1-k8s-master-2
Oct 25 02:02:46.930: INFO: Creating a pod which consumes cpu=315m on Node lab1-k8s-master-3
Oct 25 02:02:46.949: INFO: Creating a pod which consumes cpu=787m on Node lab1-k8s-node-1
Oct 25 02:02:46.965: INFO: Creating a pod which consumes cpu=766m on Node lab1-k8s-node-2
Oct 25 02:02:46.990: INFO: Creating a pod which consumes cpu=787m on Node lab1-k8s-node-3
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-484c67f2-991c-4533-9a12-14f74641f8e9.17212d807fb514d3], Reason = [Scheduled], Message = [Successfully assigned sched-pred-525/filler-pod-484c67f2-991c-4533-9a12-14f74641f8e9 to lab1-k8s-node-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-484c67f2-991c-4533-9a12-14f74641f8e9.17212d80ac87a03b], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.7"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-484c67f2-991c-4533-9a12-14f74641f8e9.17212d80f8da8acf], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.7" in 1.280476738s]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-484c67f2-991c-4533-9a12-14f74641f8e9.17212d80f9dcf030], Reason = [Created], Message = [Created container filler-pod-484c67f2-991c-4533-9a12-14f74641f8e9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-484c67f2-991c-4533-9a12-14f74641f8e9.17212d8100102a85], Reason = [Started], Message = [Started container filler-pod-484c67f2-991c-4533-9a12-14f74641f8e9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6080fff6-5cd1-451c-824b-11fb2d3239b1.17212d807ccc4bbe], Reason = [Scheduled], Message = [Successfully assigned sched-pred-525/filler-pod-6080fff6-5cd1-451c-824b-11fb2d3239b1 to lab1-k8s-master-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6080fff6-5cd1-451c-824b-11fb2d3239b1.17212d80b69a3938], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.7"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6080fff6-5cd1-451c-824b-11fb2d3239b1.17212d80d58de79d], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.7" in 519.267774ms]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6080fff6-5cd1-451c-824b-11fb2d3239b1.17212d80d7cb2922], Reason = [Created], Message = [Created container filler-pod-6080fff6-5cd1-451c-824b-11fb2d3239b1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6080fff6-5cd1-451c-824b-11fb2d3239b1.17212d80ddf338f7], Reason = [Started], Message = [Started container filler-pod-6080fff6-5cd1-451c-824b-11fb2d3239b1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8c1cae7d-264b-4f8c-9854-86b4869f99db.17212d807afa328d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-525/filler-pod-8c1cae7d-264b-4f8c-9854-86b4869f99db to lab1-k8s-master-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8c1cae7d-264b-4f8c-9854-86b4869f99db.17212d80bbf7a1e4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.7" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8c1cae7d-264b-4f8c-9854-86b4869f99db.17212d80be1d6c95], Reason = [Created], Message = [Created container filler-pod-8c1cae7d-264b-4f8c-9854-86b4869f99db]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8c1cae7d-264b-4f8c-9854-86b4869f99db.17212d80c59dbd4f], Reason = [Started], Message = [Started container filler-pod-8c1cae7d-264b-4f8c-9854-86b4869f99db]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae4ce07a-f956-4f6b-ac2c-7834ce647e56.17212d807fbc7541], Reason = [Scheduled], Message = [Successfully assigned sched-pred-525/filler-pod-ae4ce07a-f956-4f6b-ac2c-7834ce647e56 to lab1-k8s-node-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae4ce07a-f956-4f6b-ac2c-7834ce647e56.17212d80ac4c9dde], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.7" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae4ce07a-f956-4f6b-ac2c-7834ce647e56.17212d80ace6ecac], Reason = [Created], Message = [Created container filler-pod-ae4ce07a-f956-4f6b-ac2c-7834ce647e56]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ae4ce07a-f956-4f6b-ac2c-7834ce647e56.17212d80b165a60e], Reason = [Started], Message = [Started container filler-pod-ae4ce07a-f956-4f6b-ac2c-7834ce647e56]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f8f6e2b4-cc90-4d0b-bd06-7d8a3d3133dc.17212d808180e58b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-525/filler-pod-f8f6e2b4-cc90-4d0b-bd06-7d8a3d3133dc to lab1-k8s-node-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f8f6e2b4-cc90-4d0b-bd06-7d8a3d3133dc.17212d80b0d50b54], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.7" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f8f6e2b4-cc90-4d0b-bd06-7d8a3d3133dc.17212d80b1aca7e9], Reason = [Created], Message = [Created container filler-pod-f8f6e2b4-cc90-4d0b-bd06-7d8a3d3133dc]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f8f6e2b4-cc90-4d0b-bd06-7d8a3d3133dc.17212d80b63ab392], Reason = [Started], Message = [Started container filler-pod-f8f6e2b4-cc90-4d0b-bd06-7d8a3d3133dc]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fdbcf802-4402-4e47-8fd3-66c5c6e440f6.17212d807d8caa5d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-525/filler-pod-fdbcf802-4402-4e47-8fd3-66c5c6e440f6 to lab1-k8s-master-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fdbcf802-4402-4e47-8fd3-66c5c6e440f6.17212d80ae5bcf1a], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.7"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fdbcf802-4402-4e47-8fd3-66c5c6e440f6.17212d80d6d5f560], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.7" in 679.080783ms]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fdbcf802-4402-4e47-8fd3-66c5c6e440f6.17212d80d89702ea], Reason = [Created], Message = [Created container filler-pod-fdbcf802-4402-4e47-8fd3-66c5c6e440f6]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fdbcf802-4402-4e47-8fd3-66c5c6e440f6.17212d80dd72bb22], Reason = [Started], Message = [Started container filler-pod-fdbcf802-4402-4e47-8fd3-66c5c6e440f6]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.17212d81759c087a], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 Insufficient cpu. preemption: 0/6 nodes are available: 6 No preemption victims found for incoming pod.]
STEP: removing the label node off the node lab1-k8s-master-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node lab1-k8s-master-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node lab1-k8s-master-3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node lab1-k8s-node-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node lab1-k8s-node-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node lab1-k8s-node-3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:02:52.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-525" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83

• [SLOW TEST:6.015 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":356,"completed":82,"skipped":1502,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:02:52.466: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:02:52.511: INFO: Creating ReplicaSet my-hostname-basic-c1676ee9-7730-4e1a-8aa5-7ee06af7f165
Oct 25 02:02:52.538: INFO: Pod name my-hostname-basic-c1676ee9-7730-4e1a-8aa5-7ee06af7f165: Found 0 pods out of 1
Oct 25 02:02:57.551: INFO: Pod name my-hostname-basic-c1676ee9-7730-4e1a-8aa5-7ee06af7f165: Found 1 pods out of 1
Oct 25 02:02:57.551: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-c1676ee9-7730-4e1a-8aa5-7ee06af7f165" is running
Oct 25 02:02:57.559: INFO: Pod "my-hostname-basic-c1676ee9-7730-4e1a-8aa5-7ee06af7f165-phsts" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-25 02:02:52 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-25 02:02:53 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-25 02:02:53 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-25 02:02:52 +0000 UTC Reason: Message:}])
Oct 25 02:02:57.559: INFO: Trying to dial the pod
Oct 25 02:03:02.597: INFO: Controller my-hostname-basic-c1676ee9-7730-4e1a-8aa5-7ee06af7f165: Got expected result from replica 1 [my-hostname-basic-c1676ee9-7730-4e1a-8aa5-7ee06af7f165-phsts]: "my-hostname-basic-c1676ee9-7730-4e1a-8aa5-7ee06af7f165-phsts", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Oct 25 02:03:02.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4277" for this suite.

• [SLOW TEST:10.162 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":356,"completed":83,"skipped":1541,"failed":0}
SSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:03:02.630: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Oct 25 02:03:02.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-8687" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","total":356,"completed":84,"skipped":1548,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:03:02.733: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 02:03:02.817: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3598b320-3a39-4dce-8863-ffb11fe07571" in namespace "projected-4445" to be "Succeeded or Failed"
Oct 25 02:03:02.826: INFO: Pod "downwardapi-volume-3598b320-3a39-4dce-8863-ffb11fe07571": Phase="Pending", Reason="", readiness=false. Elapsed: 9.370585ms
Oct 25 02:03:04.840: INFO: Pod "downwardapi-volume-3598b320-3a39-4dce-8863-ffb11fe07571": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022790211s
Oct 25 02:03:06.850: INFO: Pod "downwardapi-volume-3598b320-3a39-4dce-8863-ffb11fe07571": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033479887s
STEP: Saw pod success
Oct 25 02:03:06.851: INFO: Pod "downwardapi-volume-3598b320-3a39-4dce-8863-ffb11fe07571" satisfied condition "Succeeded or Failed"
Oct 25 02:03:06.857: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-3598b320-3a39-4dce-8863-ffb11fe07571 container client-container: <nil>
STEP: delete the pod
Oct 25 02:03:06.893: INFO: Waiting for pod downwardapi-volume-3598b320-3a39-4dce-8863-ffb11fe07571 to disappear
Oct 25 02:03:06.898: INFO: Pod downwardapi-volume-3598b320-3a39-4dce-8863-ffb11fe07571 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Oct 25 02:03:06.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4445" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":85,"skipped":1568,"failed":0}
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:03:06.926: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-2432
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 25 02:03:06.979: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Oct 25 02:03:07.125: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:03:09.138: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:03:11.137: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:03:13.133: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:03:18.625: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:03:19.137: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:03:21.137: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:03:23.134: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:03:25.137: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:03:27.137: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:03:29.139: INFO: The status of Pod netserver-0 is Running (Ready = true)
Oct 25 02:03:29.153: INFO: The status of Pod netserver-1 is Running (Ready = true)
Oct 25 02:03:29.164: INFO: The status of Pod netserver-2 is Running (Ready = true)
Oct 25 02:03:29.179: INFO: The status of Pod netserver-3 is Running (Ready = true)
Oct 25 02:03:29.194: INFO: The status of Pod netserver-4 is Running (Ready = true)
Oct 25 02:03:29.207: INFO: The status of Pod netserver-5 is Running (Ready = true)
STEP: Creating test pods
Oct 25 02:03:31.255: INFO: Setting MaxTries for pod polling to 66 for networking test based on endpoint count 6
Oct 25 02:03:31.255: INFO: Breadth first check of 10.233.99.35 on host 10.128.0.176...
Oct 25 02:03:31.262: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.74.100:9080/dial?request=hostname&protocol=http&host=10.233.99.35&port=8083&tries=1'] Namespace:pod-network-test-2432 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:03:31.262: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:03:31.263: INFO: ExecWithOptions: Clientset creation
Oct 25 02:03:31.263: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2432/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.74.100%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.99.35%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 25 02:03:31.335: INFO: Waiting for responses: map[]
Oct 25 02:03:31.335: INFO: reached 10.233.99.35 after 0/1 tries
Oct 25 02:03:31.336: INFO: Breadth first check of 10.233.107.32 on host 10.128.2.74...
Oct 25 02:03:31.343: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.74.100:9080/dial?request=hostname&protocol=http&host=10.233.107.32&port=8083&tries=1'] Namespace:pod-network-test-2432 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:03:31.343: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:03:31.343: INFO: ExecWithOptions: Clientset creation
Oct 25 02:03:31.343: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2432/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.74.100%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.107.32%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 25 02:03:31.416: INFO: Waiting for responses: map[]
Oct 25 02:03:31.416: INFO: reached 10.233.107.32 after 0/1 tries
Oct 25 02:03:31.416: INFO: Breadth first check of 10.233.105.31 on host 10.128.2.108...
Oct 25 02:03:31.427: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.74.100:9080/dial?request=hostname&protocol=http&host=10.233.105.31&port=8083&tries=1'] Namespace:pod-network-test-2432 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:03:31.427: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:03:31.427: INFO: ExecWithOptions: Clientset creation
Oct 25 02:03:31.427: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2432/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.74.100%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.105.31%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 25 02:03:31.514: INFO: Waiting for responses: map[]
Oct 25 02:03:31.514: INFO: reached 10.233.105.31 after 0/1 tries
Oct 25 02:03:31.514: INFO: Breadth first check of 10.233.95.39 on host 10.128.1.213...
Oct 25 02:03:31.521: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.74.100:9080/dial?request=hostname&protocol=http&host=10.233.95.39&port=8083&tries=1'] Namespace:pod-network-test-2432 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:03:31.522: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:03:31.522: INFO: ExecWithOptions: Clientset creation
Oct 25 02:03:31.522: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2432/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.74.100%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.95.39%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 25 02:03:31.597: INFO: Waiting for responses: map[]
Oct 25 02:03:31.597: INFO: reached 10.233.95.39 after 0/1 tries
Oct 25 02:03:31.597: INFO: Breadth first check of 10.233.64.56 on host 10.128.1.121...
Oct 25 02:03:31.605: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.74.100:9080/dial?request=hostname&protocol=http&host=10.233.64.56&port=8083&tries=1'] Namespace:pod-network-test-2432 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:03:31.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:03:31.606: INFO: ExecWithOptions: Clientset creation
Oct 25 02:03:31.606: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2432/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.74.100%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.64.56%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 25 02:03:31.688: INFO: Waiting for responses: map[]
Oct 25 02:03:31.688: INFO: reached 10.233.64.56 after 0/1 tries
Oct 25 02:03:31.688: INFO: Breadth first check of 10.233.74.99 on host 10.128.1.178...
Oct 25 02:03:31.694: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.74.100:9080/dial?request=hostname&protocol=http&host=10.233.74.99&port=8083&tries=1'] Namespace:pod-network-test-2432 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:03:31.695: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:03:31.695: INFO: ExecWithOptions: Clientset creation
Oct 25 02:03:31.695: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-2432/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.74.100%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.233.74.99%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 25 02:03:31.776: INFO: Waiting for responses: map[]
Oct 25 02:03:31.776: INFO: reached 10.233.74.99 after 0/1 tries
Oct 25 02:03:31.776: INFO: Going to retry 0 out of 6 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Oct 25 02:03:31.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2432" for this suite.

• [SLOW TEST:24.876 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":356,"completed":86,"skipped":1574,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:03:31.802: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:03:31.858: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-304d4a25-d213-4521-8b20-f0886e7aee71" in namespace "security-context-test-6888" to be "Succeeded or Failed"
Oct 25 02:03:31.864: INFO: Pod "busybox-readonly-false-304d4a25-d213-4521-8b20-f0886e7aee71": Phase="Pending", Reason="", readiness=false. Elapsed: 5.758676ms
Oct 25 02:03:33.879: INFO: Pod "busybox-readonly-false-304d4a25-d213-4521-8b20-f0886e7aee71": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020214559s
Oct 25 02:03:35.893: INFO: Pod "busybox-readonly-false-304d4a25-d213-4521-8b20-f0886e7aee71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034618813s
Oct 25 02:03:35.893: INFO: Pod "busybox-readonly-false-304d4a25-d213-4521-8b20-f0886e7aee71" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Oct 25 02:03:35.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6888" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":356,"completed":87,"skipped":1587,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath 
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:03:35.916: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Oct 25 02:03:35.983: INFO: Waiting up to 1m0s for all nodes to be ready
Oct 25 02:04:36.049: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:04:36.060: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
Oct 25 02:04:38.175: INFO: found a healthy node: lab1-k8s-node-3
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:04:46.342: INFO: pods created so far: [1 1 1]
Oct 25 02:04:46.342: INFO: length of pods created so far: 3
Oct 25 02:04:48.373: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:188
Oct 25 02:04:55.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-938" for this suite.
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:04:55.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7754" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:79.735 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","total":356,"completed":88,"skipped":1609,"failed":0}
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:04:55.653: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Oct 25 02:05:23.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6047" for this suite.

• [SLOW TEST:28.173 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":356,"completed":89,"skipped":1609,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring 
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:05:23.832: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename endpointslicemirroring
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
STEP: mirroring a new custom Endpoint
Oct 25 02:05:23.917: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint
Oct 25 02:05:25.958: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint
Oct 25 02:05:28.006: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:188
Oct 25 02:05:30.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-7751" for this suite.

• [SLOW TEST:6.220 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","total":356,"completed":90,"skipped":1635,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Secrets 
  should patch a secret [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:05:30.053: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should patch a secret [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Oct 25 02:05:30.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5996" for this suite.
•{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","total":356,"completed":91,"skipped":1643,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:05:30.201: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 02:05:30.666: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 02:05:33.731: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Oct 25 02:05:35.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=webhook-7122 attach --namespace=webhook-7122 to-be-attached-pod -i -c=container1'
Oct 25 02:05:35.884: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:05:35.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7122" for this suite.
STEP: Destroying namespace "webhook-7122-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:5.820 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":356,"completed":92,"skipped":1659,"failed":0}
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:05:36.020: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-cfee84d3-5eab-42fc-a526-91b9f6b9a13a
STEP: Creating a pod to test consume secrets
Oct 25 02:05:36.100: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-76e66168-0aee-4f96-ab68-80990d748122" in namespace "projected-4517" to be "Succeeded or Failed"
Oct 25 02:05:36.112: INFO: Pod "pod-projected-secrets-76e66168-0aee-4f96-ab68-80990d748122": Phase="Pending", Reason="", readiness=false. Elapsed: 11.331631ms
Oct 25 02:05:38.123: INFO: Pod "pod-projected-secrets-76e66168-0aee-4f96-ab68-80990d748122": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022873723s
Oct 25 02:05:40.137: INFO: Pod "pod-projected-secrets-76e66168-0aee-4f96-ab68-80990d748122": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036802005s
STEP: Saw pod success
Oct 25 02:05:40.137: INFO: Pod "pod-projected-secrets-76e66168-0aee-4f96-ab68-80990d748122" satisfied condition "Succeeded or Failed"
Oct 25 02:05:40.144: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-projected-secrets-76e66168-0aee-4f96-ab68-80990d748122 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 25 02:05:40.199: INFO: Waiting for pod pod-projected-secrets-76e66168-0aee-4f96-ab68-80990d748122 to disappear
Oct 25 02:05:40.205: INFO: Pod pod-projected-secrets-76e66168-0aee-4f96-ab68-80990d748122 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Oct 25 02:05:40.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4517" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":93,"skipped":1660,"failed":0}
SSSSSSS
------------------------------
[sig-network] Ingress API 
  should support creating Ingress API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:05:40.234: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename ingress
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support creating Ingress API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Oct 25 02:05:40.323: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Oct 25 02:05:40.334: INFO: starting watch
STEP: patching
STEP: updating
Oct 25 02:05:40.364: INFO: waiting for watch events with expected annotations
Oct 25 02:05:40.364: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:188
Oct 25 02:05:40.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-7680" for this suite.
•{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","total":356,"completed":94,"skipped":1667,"failed":0}
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:05:40.497: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:05:40.541: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3829
I1025 02:05:40.556822      18 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3829, replica count: 1
I1025 02:05:41.607445      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1025 02:05:42.608561      18 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 25 02:05:42.730: INFO: Created: latency-svc-tkqfk
Oct 25 02:05:42.744: INFO: Got endpoints: latency-svc-tkqfk [34.230881ms]
Oct 25 02:05:42.798: INFO: Created: latency-svc-8mbk6
Oct 25 02:05:42.811: INFO: Got endpoints: latency-svc-8mbk6 [66.371077ms]
Oct 25 02:05:42.828: INFO: Created: latency-svc-kwb8p
Oct 25 02:05:42.829: INFO: Got endpoints: latency-svc-kwb8p [84.022473ms]
Oct 25 02:05:42.832: INFO: Created: latency-svc-gtkxw
Oct 25 02:05:42.841: INFO: Got endpoints: latency-svc-gtkxw [95.563977ms]
Oct 25 02:05:42.871: INFO: Created: latency-svc-nkqcd
Oct 25 02:05:42.871: INFO: Got endpoints: latency-svc-nkqcd [125.757576ms]
Oct 25 02:05:42.880: INFO: Created: latency-svc-mzw6q
Oct 25 02:05:42.885: INFO: Got endpoints: latency-svc-mzw6q [139.469075ms]
Oct 25 02:05:42.896: INFO: Created: latency-svc-klcjs
Oct 25 02:05:42.904: INFO: Got endpoints: latency-svc-klcjs [158.392221ms]
Oct 25 02:05:42.927: INFO: Created: latency-svc-gbmhk
Oct 25 02:05:42.927: INFO: Got endpoints: latency-svc-gbmhk [181.71165ms]
Oct 25 02:05:42.938: INFO: Created: latency-svc-c4pjt
Oct 25 02:05:42.942: INFO: Got endpoints: latency-svc-c4pjt [196.991013ms]
Oct 25 02:05:42.962: INFO: Created: latency-svc-lr8cm
Oct 25 02:05:42.968: INFO: Got endpoints: latency-svc-lr8cm [222.282413ms]
Oct 25 02:05:42.982: INFO: Created: latency-svc-6kjsm
Oct 25 02:05:42.986: INFO: Got endpoints: latency-svc-6kjsm [240.872054ms]
Oct 25 02:05:42.991: INFO: Created: latency-svc-6j72x
Oct 25 02:05:43.016: INFO: Got endpoints: latency-svc-6j72x [270.330231ms]
Oct 25 02:05:43.032: INFO: Created: latency-svc-xv492
Oct 25 02:05:43.056: INFO: Got endpoints: latency-svc-xv492 [310.952332ms]
Oct 25 02:05:43.064: INFO: Created: latency-svc-49shs
Oct 25 02:05:43.070: INFO: Got endpoints: latency-svc-49shs [324.465322ms]
Oct 25 02:05:43.101: INFO: Created: latency-svc-2z4dc
Oct 25 02:05:43.102: INFO: Created: latency-svc-c9x9d
Oct 25 02:05:43.102: INFO: Got endpoints: latency-svc-c9x9d [356.152368ms]
Oct 25 02:05:43.117: INFO: Got endpoints: latency-svc-2z4dc [371.769326ms]
Oct 25 02:05:43.132: INFO: Created: latency-svc-g4mhn
Oct 25 02:05:43.134: INFO: Got endpoints: latency-svc-g4mhn [322.228879ms]
Oct 25 02:05:43.165: INFO: Created: latency-svc-wj8b6
Oct 25 02:05:43.165: INFO: Got endpoints: latency-svc-wj8b6 [335.636531ms]
Oct 25 02:05:43.176: INFO: Created: latency-svc-ht8vf
Oct 25 02:05:43.183: INFO: Got endpoints: latency-svc-ht8vf [341.718839ms]
Oct 25 02:05:43.208: INFO: Created: latency-svc-8rvqp
Oct 25 02:05:43.208: INFO: Got endpoints: latency-svc-8rvqp [336.900346ms]
Oct 25 02:05:43.220: INFO: Created: latency-svc-v4p2s
Oct 25 02:05:43.223: INFO: Got endpoints: latency-svc-v4p2s [337.524575ms]
Oct 25 02:05:43.234: INFO: Created: latency-svc-f5m4d
Oct 25 02:05:43.234: INFO: Got endpoints: latency-svc-f5m4d [329.903452ms]
Oct 25 02:05:43.255: INFO: Created: latency-svc-gmlsk
Oct 25 02:05:43.263: INFO: Got endpoints: latency-svc-gmlsk [335.695371ms]
Oct 25 02:05:43.274: INFO: Created: latency-svc-gdbmz
Oct 25 02:05:43.278: INFO: Got endpoints: latency-svc-gdbmz [336.136327ms]
Oct 25 02:05:43.291: INFO: Created: latency-svc-lvmgv
Oct 25 02:05:43.307: INFO: Got endpoints: latency-svc-lvmgv [338.292417ms]
Oct 25 02:05:43.318: INFO: Created: latency-svc-kxm47
Oct 25 02:05:43.321: INFO: Got endpoints: latency-svc-kxm47 [334.321819ms]
Oct 25 02:05:43.339: INFO: Created: latency-svc-k8mgr
Oct 25 02:05:43.343: INFO: Got endpoints: latency-svc-k8mgr [327.457813ms]
Oct 25 02:05:43.369: INFO: Created: latency-svc-vpzld
Oct 25 02:05:43.370: INFO: Got endpoints: latency-svc-vpzld [313.207004ms]
Oct 25 02:05:43.403: INFO: Created: latency-svc-j5q6v
Oct 25 02:05:43.403: INFO: Got endpoints: latency-svc-j5q6v [333.199756ms]
Oct 25 02:05:43.412: INFO: Created: latency-svc-tmctt
Oct 25 02:05:43.437: INFO: Got endpoints: latency-svc-tmctt [334.848619ms]
Oct 25 02:05:43.445: INFO: Created: latency-svc-sdj79
Oct 25 02:05:43.454: INFO: Got endpoints: latency-svc-sdj79 [335.738672ms]
Oct 25 02:05:43.464: INFO: Created: latency-svc-fkpfs
Oct 25 02:05:43.478: INFO: Created: latency-svc-5gxww
Oct 25 02:05:43.479: INFO: Got endpoints: latency-svc-fkpfs [345.119974ms]
Oct 25 02:05:43.486: INFO: Got endpoints: latency-svc-5gxww [321.131367ms]
Oct 25 02:05:43.507: INFO: Created: latency-svc-6pf9r
Oct 25 02:05:43.518: INFO: Got endpoints: latency-svc-6pf9r [333.454001ms]
Oct 25 02:05:43.529: INFO: Created: latency-svc-bh5xl
Oct 25 02:05:43.533: INFO: Got endpoints: latency-svc-bh5xl [324.740835ms]
Oct 25 02:05:43.540: INFO: Created: latency-svc-qjtnt
Oct 25 02:05:43.547: INFO: Got endpoints: latency-svc-qjtnt [324.156105ms]
Oct 25 02:05:43.563: INFO: Created: latency-svc-hk6ck
Oct 25 02:05:43.570: INFO: Got endpoints: latency-svc-hk6ck [335.455026ms]
Oct 25 02:05:43.590: INFO: Created: latency-svc-nk4wn
Oct 25 02:05:43.593: INFO: Got endpoints: latency-svc-nk4wn [329.277893ms]
Oct 25 02:05:43.776: INFO: Created: latency-svc-k7rhs
Oct 25 02:05:43.776: INFO: Created: latency-svc-knxdv
Oct 25 02:05:43.776: INFO: Created: latency-svc-5fh48
Oct 25 02:05:43.788: INFO: Created: latency-svc-679km
Oct 25 02:05:43.810: INFO: Created: latency-svc-ccwkf
Oct 25 02:05:43.811: INFO: Created: latency-svc-v5rs7
Oct 25 02:05:43.811: INFO: Created: latency-svc-bmjsp
Oct 25 02:05:43.812: INFO: Created: latency-svc-s9h8j
Oct 25 02:05:43.812: INFO: Created: latency-svc-7sn2x
Oct 25 02:05:43.812: INFO: Created: latency-svc-tcg9j
Oct 25 02:05:43.813: INFO: Created: latency-svc-npccp
Oct 25 02:05:43.816: INFO: Created: latency-svc-w5b2x
Oct 25 02:05:43.816: INFO: Created: latency-svc-ckj67
Oct 25 02:05:43.816: INFO: Created: latency-svc-r7j7b
Oct 25 02:05:43.816: INFO: Got endpoints: latency-svc-knxdv [471.435525ms]
Oct 25 02:05:43.816: INFO: Got endpoints: latency-svc-bmjsp [329.501857ms]
Oct 25 02:05:43.816: INFO: Got endpoints: latency-svc-5fh48 [378.254026ms]
Oct 25 02:05:43.818: INFO: Created: latency-svc-qdjtv
Oct 25 02:05:43.818: INFO: Got endpoints: latency-svc-tcg9j [225.397804ms]
Oct 25 02:05:43.818: INFO: Got endpoints: latency-svc-ccwkf [270.948335ms]
Oct 25 02:05:43.830: INFO: Got endpoints: latency-svc-ckj67 [426.161514ms]
Oct 25 02:05:43.830: INFO: Got endpoints: latency-svc-qdjtv [296.555191ms]
Oct 25 02:05:43.839: INFO: Got endpoints: latency-svc-s9h8j [360.224342ms]
Oct 25 02:05:43.847: INFO: Got endpoints: latency-svc-k7rhs [525.519682ms]
Oct 25 02:05:43.850: INFO: Got endpoints: latency-svc-v5rs7 [479.887841ms]
Oct 25 02:05:43.850: INFO: Got endpoints: latency-svc-r7j7b [396.37306ms]
Oct 25 02:05:43.851: INFO: Got endpoints: latency-svc-w5b2x [280.396396ms]
Oct 25 02:05:43.851: INFO: Got endpoints: latency-svc-7sn2x [332.750328ms]
Oct 25 02:05:43.861: INFO: Got endpoints: latency-svc-npccp [553.780813ms]
Oct 25 02:05:43.869: INFO: Created: latency-svc-mh2s9
Oct 25 02:05:43.892: INFO: Created: latency-svc-q2vnm
Oct 25 02:05:43.904: INFO: Got endpoints: latency-svc-679km [625.000814ms]
Oct 25 02:05:43.908: INFO: Created: latency-svc-d8wgk
Oct 25 02:05:43.921: INFO: Created: latency-svc-zwngh
Oct 25 02:05:43.929: INFO: Created: latency-svc-df228
Oct 25 02:05:43.944: INFO: Created: latency-svc-2l4v4
Oct 25 02:05:43.957: INFO: Got endpoints: latency-svc-mh2s9 [140.598185ms]
Oct 25 02:05:43.966: INFO: Created: latency-svc-nxwkw
Oct 25 02:05:43.977: INFO: Created: latency-svc-rcr4t
Oct 25 02:05:43.998: INFO: Created: latency-svc-pvdq6
Oct 25 02:05:44.011: INFO: Got endpoints: latency-svc-q2vnm [192.807021ms]
Oct 25 02:05:44.028: INFO: Created: latency-svc-4tjrz
Oct 25 02:05:44.040: INFO: Created: latency-svc-mf5ws
Oct 25 02:05:44.052: INFO: Got endpoints: latency-svc-d8wgk [234.762386ms]
Oct 25 02:05:44.061: INFO: Created: latency-svc-x5wvk
Oct 25 02:05:44.063: INFO: Created: latency-svc-d49bz
Oct 25 02:05:44.075: INFO: Created: latency-svc-c9762
Oct 25 02:05:44.097: INFO: Created: latency-svc-xtlnj
Oct 25 02:05:44.098: INFO: Created: latency-svc-rg5wp
Oct 25 02:05:44.114: INFO: Got endpoints: latency-svc-zwngh [284.323384ms]
Oct 25 02:05:44.116: INFO: Created: latency-svc-q2zpp
Oct 25 02:05:44.123: INFO: Created: latency-svc-b9cjg
Oct 25 02:05:44.138: INFO: Created: latency-svc-fpxqd
Oct 25 02:05:44.157: INFO: Got endpoints: latency-svc-df228 [338.901666ms]
Oct 25 02:05:44.190: INFO: Created: latency-svc-dvtzp
Oct 25 02:05:44.202: INFO: Got endpoints: latency-svc-2l4v4 [372.562931ms]
Oct 25 02:05:44.232: INFO: Created: latency-svc-pf6f6
Oct 25 02:05:44.254: INFO: Got endpoints: latency-svc-nxwkw [414.732159ms]
Oct 25 02:05:44.280: INFO: Created: latency-svc-sw8fw
Oct 25 02:05:44.304: INFO: Got endpoints: latency-svc-rcr4t [457.032842ms]
Oct 25 02:05:44.328: INFO: Created: latency-svc-gl9bb
Oct 25 02:05:44.352: INFO: Got endpoints: latency-svc-pvdq6 [502.03285ms]
Oct 25 02:05:44.378: INFO: Created: latency-svc-fjk2l
Oct 25 02:05:44.404: INFO: Got endpoints: latency-svc-4tjrz [552.892885ms]
Oct 25 02:05:44.427: INFO: Created: latency-svc-dshxb
Oct 25 02:05:44.455: INFO: Got endpoints: latency-svc-mf5ws [604.128587ms]
Oct 25 02:05:44.478: INFO: Created: latency-svc-z6jws
Oct 25 02:05:44.501: INFO: Got endpoints: latency-svc-d49bz [640.543839ms]
Oct 25 02:05:44.530: INFO: Created: latency-svc-5jvnn
Oct 25 02:05:44.551: INFO: Got endpoints: latency-svc-x5wvk [735.079771ms]
Oct 25 02:05:44.583: INFO: Created: latency-svc-l5959
Oct 25 02:05:44.607: INFO: Got endpoints: latency-svc-c9762 [703.553023ms]
Oct 25 02:05:44.631: INFO: Created: latency-svc-89m7x
Oct 25 02:05:44.655: INFO: Got endpoints: latency-svc-xtlnj [697.863561ms]
Oct 25 02:05:44.681: INFO: Created: latency-svc-f7bz9
Oct 25 02:05:44.700: INFO: Got endpoints: latency-svc-rg5wp [850.300006ms]
Oct 25 02:05:44.721: INFO: Created: latency-svc-6z66d
Oct 25 02:05:44.753: INFO: Got endpoints: latency-svc-q2zpp [741.642145ms]
Oct 25 02:05:44.777: INFO: Created: latency-svc-nmgwr
Oct 25 02:05:44.802: INFO: Got endpoints: latency-svc-b9cjg [750.241475ms]
Oct 25 02:05:44.829: INFO: Created: latency-svc-hz84n
Oct 25 02:05:44.853: INFO: Got endpoints: latency-svc-fpxqd [739.166455ms]
Oct 25 02:05:44.875: INFO: Created: latency-svc-w76tv
Oct 25 02:05:44.903: INFO: Got endpoints: latency-svc-dvtzp [745.471933ms]
Oct 25 02:05:44.922: INFO: Created: latency-svc-dx5cz
Oct 25 02:05:44.951: INFO: Got endpoints: latency-svc-pf6f6 [748.58301ms]
Oct 25 02:05:44.984: INFO: Created: latency-svc-qnc25
Oct 25 02:05:45.006: INFO: Got endpoints: latency-svc-sw8fw [752.120312ms]
Oct 25 02:05:45.028: INFO: Created: latency-svc-jt8j7
Oct 25 02:05:45.051: INFO: Got endpoints: latency-svc-gl9bb [746.82225ms]
Oct 25 02:05:45.070: INFO: Created: latency-svc-jsbxf
Oct 25 02:05:45.103: INFO: Got endpoints: latency-svc-fjk2l [750.779011ms]
Oct 25 02:05:45.126: INFO: Created: latency-svc-z52ml
Oct 25 02:05:45.152: INFO: Got endpoints: latency-svc-dshxb [748.531462ms]
Oct 25 02:05:45.175: INFO: Created: latency-svc-qf2l5
Oct 25 02:05:45.201: INFO: Got endpoints: latency-svc-z6jws [745.664885ms]
Oct 25 02:05:45.231: INFO: Created: latency-svc-f6gk4
Oct 25 02:05:45.264: INFO: Got endpoints: latency-svc-5jvnn [762.290622ms]
Oct 25 02:05:45.290: INFO: Created: latency-svc-xnwp4
Oct 25 02:05:45.304: INFO: Got endpoints: latency-svc-l5959 [752.302983ms]
Oct 25 02:05:45.331: INFO: Created: latency-svc-dlbhk
Oct 25 02:05:45.352: INFO: Got endpoints: latency-svc-89m7x [744.565995ms]
Oct 25 02:05:45.374: INFO: Created: latency-svc-dmlqq
Oct 25 02:05:45.401: INFO: Got endpoints: latency-svc-f7bz9 [746.519475ms]
Oct 25 02:05:45.435: INFO: Created: latency-svc-7cfm5
Oct 25 02:05:45.450: INFO: Got endpoints: latency-svc-6z66d [750.103599ms]
Oct 25 02:05:45.473: INFO: Created: latency-svc-dhrxz
Oct 25 02:05:45.503: INFO: Got endpoints: latency-svc-nmgwr [750.095276ms]
Oct 25 02:05:45.524: INFO: Created: latency-svc-wfg7p
Oct 25 02:05:45.558: INFO: Got endpoints: latency-svc-hz84n [755.771827ms]
Oct 25 02:05:45.589: INFO: Created: latency-svc-5b4jj
Oct 25 02:05:45.605: INFO: Got endpoints: latency-svc-w76tv [750.986706ms]
Oct 25 02:05:45.627: INFO: Created: latency-svc-crc2c
Oct 25 02:05:45.651: INFO: Got endpoints: latency-svc-dx5cz [747.924522ms]
Oct 25 02:05:45.672: INFO: Created: latency-svc-pbclb
Oct 25 02:05:45.702: INFO: Got endpoints: latency-svc-qnc25 [751.419102ms]
Oct 25 02:05:45.731: INFO: Created: latency-svc-rf54w
Oct 25 02:05:45.752: INFO: Got endpoints: latency-svc-jt8j7 [746.105897ms]
Oct 25 02:05:45.775: INFO: Created: latency-svc-7gl29
Oct 25 02:05:45.805: INFO: Got endpoints: latency-svc-jsbxf [754.110046ms]
Oct 25 02:05:45.829: INFO: Created: latency-svc-f5t6h
Oct 25 02:05:45.850: INFO: Got endpoints: latency-svc-z52ml [747.052084ms]
Oct 25 02:05:45.887: INFO: Created: latency-svc-xx4pl
Oct 25 02:05:45.902: INFO: Got endpoints: latency-svc-qf2l5 [749.883052ms]
Oct 25 02:05:45.931: INFO: Created: latency-svc-hbnxd
Oct 25 02:05:45.953: INFO: Got endpoints: latency-svc-f6gk4 [751.886324ms]
Oct 25 02:05:45.973: INFO: Created: latency-svc-bp92t
Oct 25 02:05:46.001: INFO: Got endpoints: latency-svc-xnwp4 [736.394984ms]
Oct 25 02:05:46.026: INFO: Created: latency-svc-7zkd2
Oct 25 02:05:46.051: INFO: Got endpoints: latency-svc-dlbhk [747.303544ms]
Oct 25 02:05:46.076: INFO: Created: latency-svc-7xbbt
Oct 25 02:05:46.101: INFO: Got endpoints: latency-svc-dmlqq [748.994212ms]
Oct 25 02:05:46.126: INFO: Created: latency-svc-gqk9s
Oct 25 02:05:46.150: INFO: Got endpoints: latency-svc-7cfm5 [748.930306ms]
Oct 25 02:05:46.178: INFO: Created: latency-svc-j22nk
Oct 25 02:05:46.203: INFO: Got endpoints: latency-svc-dhrxz [752.25477ms]
Oct 25 02:05:46.229: INFO: Created: latency-svc-flqtl
Oct 25 02:05:46.257: INFO: Got endpoints: latency-svc-wfg7p [753.464186ms]
Oct 25 02:05:46.280: INFO: Created: latency-svc-c5479
Oct 25 02:05:46.300: INFO: Got endpoints: latency-svc-5b4jj [741.777847ms]
Oct 25 02:05:46.328: INFO: Created: latency-svc-qkdmk
Oct 25 02:05:46.353: INFO: Got endpoints: latency-svc-crc2c [748.583451ms]
Oct 25 02:05:46.377: INFO: Created: latency-svc-mvzt2
Oct 25 02:05:46.408: INFO: Got endpoints: latency-svc-pbclb [757.119317ms]
Oct 25 02:05:46.427: INFO: Created: latency-svc-krl99
Oct 25 02:05:46.451: INFO: Got endpoints: latency-svc-rf54w [748.507751ms]
Oct 25 02:05:46.481: INFO: Created: latency-svc-zc62s
Oct 25 02:05:46.502: INFO: Got endpoints: latency-svc-7gl29 [749.566893ms]
Oct 25 02:05:46.526: INFO: Created: latency-svc-v9kcg
Oct 25 02:05:46.554: INFO: Got endpoints: latency-svc-f5t6h [748.586714ms]
Oct 25 02:05:46.575: INFO: Created: latency-svc-2vkxr
Oct 25 02:05:46.601: INFO: Got endpoints: latency-svc-xx4pl [750.719863ms]
Oct 25 02:05:46.623: INFO: Created: latency-svc-6xlw2
Oct 25 02:05:46.651: INFO: Got endpoints: latency-svc-hbnxd [749.237835ms]
Oct 25 02:05:46.677: INFO: Created: latency-svc-6f2dz
Oct 25 02:05:46.702: INFO: Got endpoints: latency-svc-bp92t [749.028285ms]
Oct 25 02:05:46.726: INFO: Created: latency-svc-hdwtx
Oct 25 02:05:46.753: INFO: Got endpoints: latency-svc-7zkd2 [751.328515ms]
Oct 25 02:05:46.777: INFO: Created: latency-svc-cqjvz
Oct 25 02:05:46.803: INFO: Got endpoints: latency-svc-7xbbt [751.906486ms]
Oct 25 02:05:46.834: INFO: Created: latency-svc-7qh8n
Oct 25 02:05:46.850: INFO: Got endpoints: latency-svc-gqk9s [749.110392ms]
Oct 25 02:05:46.870: INFO: Created: latency-svc-twpcx
Oct 25 02:05:46.901: INFO: Got endpoints: latency-svc-j22nk [750.413074ms]
Oct 25 02:05:46.928: INFO: Created: latency-svc-4bsmk
Oct 25 02:05:46.952: INFO: Got endpoints: latency-svc-flqtl [749.073425ms]
Oct 25 02:05:46.989: INFO: Created: latency-svc-5lh42
Oct 25 02:05:47.006: INFO: Got endpoints: latency-svc-c5479 [749.162554ms]
Oct 25 02:05:47.027: INFO: Created: latency-svc-7cdnn
Oct 25 02:05:47.056: INFO: Got endpoints: latency-svc-qkdmk [755.246152ms]
Oct 25 02:05:47.110: INFO: Got endpoints: latency-svc-mvzt2 [756.681616ms]
Oct 25 02:05:47.112: INFO: Created: latency-svc-w95tb
Oct 25 02:05:47.135: INFO: Created: latency-svc-2cxfk
Oct 25 02:05:47.154: INFO: Got endpoints: latency-svc-krl99 [746.487225ms]
Oct 25 02:05:47.177: INFO: Created: latency-svc-t5mzn
Oct 25 02:05:47.202: INFO: Got endpoints: latency-svc-zc62s [751.4428ms]
Oct 25 02:05:47.232: INFO: Created: latency-svc-kgrvx
Oct 25 02:05:47.251: INFO: Got endpoints: latency-svc-v9kcg [749.083212ms]
Oct 25 02:05:47.273: INFO: Created: latency-svc-9nflm
Oct 25 02:05:47.306: INFO: Got endpoints: latency-svc-2vkxr [752.750247ms]
Oct 25 02:05:47.329: INFO: Created: latency-svc-98vrb
Oct 25 02:05:47.353: INFO: Got endpoints: latency-svc-6xlw2 [751.54563ms]
Oct 25 02:05:47.379: INFO: Created: latency-svc-8r4p8
Oct 25 02:05:47.400: INFO: Got endpoints: latency-svc-6f2dz [748.895883ms]
Oct 25 02:05:47.427: INFO: Created: latency-svc-bgbsv
Oct 25 02:05:47.454: INFO: Got endpoints: latency-svc-hdwtx [751.901208ms]
Oct 25 02:05:47.481: INFO: Created: latency-svc-mbvcf
Oct 25 02:05:47.506: INFO: Got endpoints: latency-svc-cqjvz [752.478962ms]
Oct 25 02:05:47.539: INFO: Created: latency-svc-jqx49
Oct 25 02:05:47.553: INFO: Got endpoints: latency-svc-7qh8n [749.597955ms]
Oct 25 02:05:47.583: INFO: Created: latency-svc-qg84l
Oct 25 02:05:47.611: INFO: Got endpoints: latency-svc-twpcx [760.560397ms]
Oct 25 02:05:47.654: INFO: Created: latency-svc-xd8hf
Oct 25 02:05:47.657: INFO: Got endpoints: latency-svc-4bsmk [755.692887ms]
Oct 25 02:05:47.732: INFO: Got endpoints: latency-svc-5lh42 [780.342649ms]
Oct 25 02:05:47.758: INFO: Created: latency-svc-p2gmf
Oct 25 02:05:47.763: INFO: Got endpoints: latency-svc-7cdnn [756.673761ms]
Oct 25 02:05:47.768: INFO: Created: latency-svc-26lvw
Oct 25 02:05:47.784: INFO: Created: latency-svc-2ddcs
Oct 25 02:05:47.802: INFO: Got endpoints: latency-svc-w95tb [746.627124ms]
Oct 25 02:05:47.835: INFO: Created: latency-svc-skq5k
Oct 25 02:05:47.855: INFO: Got endpoints: latency-svc-2cxfk [744.285554ms]
Oct 25 02:05:47.879: INFO: Created: latency-svc-rpnxd
Oct 25 02:05:47.900: INFO: Got endpoints: latency-svc-t5mzn [745.624876ms]
Oct 25 02:05:47.919: INFO: Created: latency-svc-pl87p
Oct 25 02:05:47.953: INFO: Got endpoints: latency-svc-kgrvx [750.076982ms]
Oct 25 02:05:47.981: INFO: Created: latency-svc-jvcsk
Oct 25 02:05:48.002: INFO: Got endpoints: latency-svc-9nflm [750.769209ms]
Oct 25 02:05:48.025: INFO: Created: latency-svc-2929p
Oct 25 02:05:48.052: INFO: Got endpoints: latency-svc-98vrb [745.41855ms]
Oct 25 02:05:48.076: INFO: Created: latency-svc-scmxd
Oct 25 02:05:48.107: INFO: Got endpoints: latency-svc-8r4p8 [753.894399ms]
Oct 25 02:05:48.129: INFO: Created: latency-svc-f924s
Oct 25 02:05:48.152: INFO: Got endpoints: latency-svc-bgbsv [751.003559ms]
Oct 25 02:05:48.180: INFO: Created: latency-svc-wccmc
Oct 25 02:05:48.203: INFO: Got endpoints: latency-svc-mbvcf [749.325162ms]
Oct 25 02:05:48.222: INFO: Created: latency-svc-b48x8
Oct 25 02:05:48.250: INFO: Got endpoints: latency-svc-jqx49 [743.71574ms]
Oct 25 02:05:48.278: INFO: Created: latency-svc-shsg9
Oct 25 02:05:48.306: INFO: Got endpoints: latency-svc-qg84l [752.70543ms]
Oct 25 02:05:48.331: INFO: Created: latency-svc-77sqq
Oct 25 02:05:48.355: INFO: Got endpoints: latency-svc-xd8hf [743.723507ms]
Oct 25 02:05:48.379: INFO: Created: latency-svc-d6c48
Oct 25 02:05:48.401: INFO: Got endpoints: latency-svc-p2gmf [741.932572ms]
Oct 25 02:05:48.431: INFO: Created: latency-svc-5fjlt
Oct 25 02:05:48.451: INFO: Got endpoints: latency-svc-26lvw [718.676622ms]
Oct 25 02:05:48.474: INFO: Created: latency-svc-prfqx
Oct 25 02:05:48.507: INFO: Got endpoints: latency-svc-2ddcs [743.256667ms]
Oct 25 02:05:48.527: INFO: Created: latency-svc-s6ps9
Oct 25 02:05:48.551: INFO: Got endpoints: latency-svc-skq5k [749.003497ms]
Oct 25 02:05:48.575: INFO: Created: latency-svc-vwkjg
Oct 25 02:05:48.605: INFO: Got endpoints: latency-svc-rpnxd [749.834606ms]
Oct 25 02:05:48.642: INFO: Created: latency-svc-7xbpp
Oct 25 02:05:48.657: INFO: Got endpoints: latency-svc-pl87p [756.360945ms]
Oct 25 02:05:48.682: INFO: Created: latency-svc-plb9j
Oct 25 02:05:48.702: INFO: Got endpoints: latency-svc-jvcsk [749.413307ms]
Oct 25 02:05:48.730: INFO: Created: latency-svc-rc5nn
Oct 25 02:05:48.750: INFO: Got endpoints: latency-svc-2929p [747.719465ms]
Oct 25 02:05:48.774: INFO: Created: latency-svc-tmw4k
Oct 25 02:05:48.800: INFO: Got endpoints: latency-svc-scmxd [747.483831ms]
Oct 25 02:05:48.821: INFO: Created: latency-svc-kq69x
Oct 25 02:05:48.850: INFO: Got endpoints: latency-svc-f924s [743.175365ms]
Oct 25 02:05:48.876: INFO: Created: latency-svc-7kjs6
Oct 25 02:05:48.906: INFO: Got endpoints: latency-svc-wccmc [753.737716ms]
Oct 25 02:05:48.932: INFO: Created: latency-svc-57tjv
Oct 25 02:05:48.952: INFO: Got endpoints: latency-svc-b48x8 [748.94997ms]
Oct 25 02:05:48.972: INFO: Created: latency-svc-5m4xh
Oct 25 02:05:49.002: INFO: Got endpoints: latency-svc-shsg9 [752.281784ms]
Oct 25 02:05:49.028: INFO: Created: latency-svc-b2pkx
Oct 25 02:05:49.051: INFO: Got endpoints: latency-svc-77sqq [745.000059ms]
Oct 25 02:05:49.077: INFO: Created: latency-svc-fx5wh
Oct 25 02:05:49.103: INFO: Got endpoints: latency-svc-d6c48 [747.745527ms]
Oct 25 02:05:49.123: INFO: Created: latency-svc-zp5qc
Oct 25 02:05:49.162: INFO: Got endpoints: latency-svc-5fjlt [761.182043ms]
Oct 25 02:05:49.185: INFO: Created: latency-svc-gl55j
Oct 25 02:05:49.203: INFO: Got endpoints: latency-svc-prfqx [751.63257ms]
Oct 25 02:05:49.235: INFO: Created: latency-svc-kdk2k
Oct 25 02:05:49.254: INFO: Got endpoints: latency-svc-s6ps9 [747.9438ms]
Oct 25 02:05:49.273: INFO: Created: latency-svc-t6kwr
Oct 25 02:05:49.303: INFO: Got endpoints: latency-svc-vwkjg [751.262908ms]
Oct 25 02:05:49.327: INFO: Created: latency-svc-tdbm8
Oct 25 02:05:49.354: INFO: Got endpoints: latency-svc-7xbpp [749.406872ms]
Oct 25 02:05:49.376: INFO: Created: latency-svc-ff7kw
Oct 25 02:05:49.401: INFO: Got endpoints: latency-svc-plb9j [743.956948ms]
Oct 25 02:05:49.422: INFO: Created: latency-svc-9nq9w
Oct 25 02:05:49.453: INFO: Got endpoints: latency-svc-rc5nn [750.89683ms]
Oct 25 02:05:49.484: INFO: Created: latency-svc-2r62b
Oct 25 02:05:49.506: INFO: Got endpoints: latency-svc-tmw4k [755.5936ms]
Oct 25 02:05:49.533: INFO: Created: latency-svc-fpf5l
Oct 25 02:05:49.556: INFO: Got endpoints: latency-svc-kq69x [755.061643ms]
Oct 25 02:05:49.589: INFO: Created: latency-svc-qhcbf
Oct 25 02:05:49.604: INFO: Got endpoints: latency-svc-7kjs6 [753.917799ms]
Oct 25 02:05:49.640: INFO: Created: latency-svc-x7jsk
Oct 25 02:05:49.652: INFO: Got endpoints: latency-svc-57tjv [746.330026ms]
Oct 25 02:05:49.682: INFO: Created: latency-svc-vhv79
Oct 25 02:05:49.706: INFO: Got endpoints: latency-svc-5m4xh [753.475889ms]
Oct 25 02:05:49.730: INFO: Created: latency-svc-wgcwp
Oct 25 02:05:49.750: INFO: Got endpoints: latency-svc-b2pkx [747.991285ms]
Oct 25 02:05:49.783: INFO: Created: latency-svc-sx6jn
Oct 25 02:05:49.802: INFO: Got endpoints: latency-svc-fx5wh [750.581746ms]
Oct 25 02:05:49.823: INFO: Created: latency-svc-2jkdv
Oct 25 02:05:49.855: INFO: Got endpoints: latency-svc-zp5qc [751.757251ms]
Oct 25 02:05:49.877: INFO: Created: latency-svc-rz2ht
Oct 25 02:05:49.900: INFO: Got endpoints: latency-svc-gl55j [737.91402ms]
Oct 25 02:05:49.932: INFO: Created: latency-svc-xrxlz
Oct 25 02:05:49.953: INFO: Got endpoints: latency-svc-kdk2k [749.680626ms]
Oct 25 02:05:49.979: INFO: Created: latency-svc-9p2n5
Oct 25 02:05:50.005: INFO: Got endpoints: latency-svc-t6kwr [750.025915ms]
Oct 25 02:05:50.028: INFO: Created: latency-svc-xgtkn
Oct 25 02:05:50.051: INFO: Got endpoints: latency-svc-tdbm8 [748.431542ms]
Oct 25 02:05:50.083: INFO: Created: latency-svc-vzlj5
Oct 25 02:05:50.110: INFO: Got endpoints: latency-svc-ff7kw [756.010396ms]
Oct 25 02:05:50.135: INFO: Created: latency-svc-bk6jx
Oct 25 02:05:50.153: INFO: Got endpoints: latency-svc-9nq9w [751.793622ms]
Oct 25 02:05:50.178: INFO: Created: latency-svc-npsrg
Oct 25 02:05:50.203: INFO: Got endpoints: latency-svc-2r62b [749.981557ms]
Oct 25 02:05:50.229: INFO: Created: latency-svc-lppcm
Oct 25 02:05:50.255: INFO: Got endpoints: latency-svc-fpf5l [748.780215ms]
Oct 25 02:05:50.280: INFO: Created: latency-svc-j26hr
Oct 25 02:05:50.303: INFO: Got endpoints: latency-svc-qhcbf [746.979813ms]
Oct 25 02:05:50.321: INFO: Created: latency-svc-8njs5
Oct 25 02:05:50.354: INFO: Got endpoints: latency-svc-x7jsk [749.901354ms]
Oct 25 02:05:50.379: INFO: Created: latency-svc-bxq2f
Oct 25 02:05:50.399: INFO: Got endpoints: latency-svc-vhv79 [745.908025ms]
Oct 25 02:05:50.422: INFO: Created: latency-svc-7j6lv
Oct 25 02:05:50.455: INFO: Got endpoints: latency-svc-wgcwp [748.181857ms]
Oct 25 02:05:50.472: INFO: Created: latency-svc-g8gg7
Oct 25 02:05:50.502: INFO: Got endpoints: latency-svc-sx6jn [751.976205ms]
Oct 25 02:05:50.527: INFO: Created: latency-svc-8csrt
Oct 25 02:05:50.550: INFO: Got endpoints: latency-svc-2jkdv [747.184556ms]
Oct 25 02:05:50.573: INFO: Created: latency-svc-bkk2g
Oct 25 02:05:50.609: INFO: Got endpoints: latency-svc-rz2ht [753.359385ms]
Oct 25 02:05:50.653: INFO: Got endpoints: latency-svc-xrxlz [753.084308ms]
Oct 25 02:05:50.704: INFO: Got endpoints: latency-svc-9p2n5 [750.624147ms]
Oct 25 02:05:50.752: INFO: Got endpoints: latency-svc-xgtkn [747.113947ms]
Oct 25 02:05:50.801: INFO: Got endpoints: latency-svc-vzlj5 [748.80879ms]
Oct 25 02:05:50.849: INFO: Got endpoints: latency-svc-bk6jx [738.15395ms]
Oct 25 02:05:50.902: INFO: Got endpoints: latency-svc-npsrg [748.953048ms]
Oct 25 02:05:50.952: INFO: Got endpoints: latency-svc-lppcm [748.790121ms]
Oct 25 02:05:51.000: INFO: Got endpoints: latency-svc-j26hr [744.143455ms]
Oct 25 02:05:51.054: INFO: Got endpoints: latency-svc-8njs5 [751.158131ms]
Oct 25 02:05:51.104: INFO: Got endpoints: latency-svc-bxq2f [750.020437ms]
Oct 25 02:05:51.151: INFO: Got endpoints: latency-svc-7j6lv [752.679643ms]
Oct 25 02:05:51.200: INFO: Got endpoints: latency-svc-g8gg7 [745.156418ms]
Oct 25 02:05:51.257: INFO: Got endpoints: latency-svc-8csrt [754.306238ms]
Oct 25 02:05:51.301: INFO: Got endpoints: latency-svc-bkk2g [751.371105ms]
Oct 25 02:05:51.302: INFO: Latencies: [66.371077ms 84.022473ms 95.563977ms 125.757576ms 139.469075ms 140.598185ms 158.392221ms 181.71165ms 192.807021ms 196.991013ms 222.282413ms 225.397804ms 234.762386ms 240.872054ms 270.330231ms 270.948335ms 280.396396ms 284.323384ms 296.555191ms 310.952332ms 313.207004ms 321.131367ms 322.228879ms 324.156105ms 324.465322ms 324.740835ms 327.457813ms 329.277893ms 329.501857ms 329.903452ms 332.750328ms 333.199756ms 333.454001ms 334.321819ms 334.848619ms 335.455026ms 335.636531ms 335.695371ms 335.738672ms 336.136327ms 336.900346ms 337.524575ms 338.292417ms 338.901666ms 341.718839ms 345.119974ms 356.152368ms 360.224342ms 371.769326ms 372.562931ms 378.254026ms 396.37306ms 414.732159ms 426.161514ms 457.032842ms 471.435525ms 479.887841ms 502.03285ms 525.519682ms 552.892885ms 553.780813ms 604.128587ms 625.000814ms 640.543839ms 697.863561ms 703.553023ms 718.676622ms 735.079771ms 736.394984ms 737.91402ms 738.15395ms 739.166455ms 741.642145ms 741.777847ms 741.932572ms 743.175365ms 743.256667ms 743.71574ms 743.723507ms 743.956948ms 744.143455ms 744.285554ms 744.565995ms 745.000059ms 745.156418ms 745.41855ms 745.471933ms 745.624876ms 745.664885ms 745.908025ms 746.105897ms 746.330026ms 746.487225ms 746.519475ms 746.627124ms 746.82225ms 746.979813ms 747.052084ms 747.113947ms 747.184556ms 747.303544ms 747.483831ms 747.719465ms 747.745527ms 747.924522ms 747.9438ms 747.991285ms 748.181857ms 748.431542ms 748.507751ms 748.531462ms 748.58301ms 748.583451ms 748.586714ms 748.780215ms 748.790121ms 748.80879ms 748.895883ms 748.930306ms 748.94997ms 748.953048ms 748.994212ms 749.003497ms 749.028285ms 749.073425ms 749.083212ms 749.110392ms 749.162554ms 749.237835ms 749.325162ms 749.406872ms 749.413307ms 749.566893ms 749.597955ms 749.680626ms 749.834606ms 749.883052ms 749.901354ms 749.981557ms 750.020437ms 750.025915ms 750.076982ms 750.095276ms 750.103599ms 750.241475ms 750.413074ms 750.581746ms 750.624147ms 750.719863ms 750.769209ms 750.779011ms 750.89683ms 750.986706ms 751.003559ms 751.158131ms 751.262908ms 751.328515ms 751.371105ms 751.419102ms 751.4428ms 751.54563ms 751.63257ms 751.757251ms 751.793622ms 751.886324ms 751.901208ms 751.906486ms 751.976205ms 752.120312ms 752.25477ms 752.281784ms 752.302983ms 752.478962ms 752.679643ms 752.70543ms 752.750247ms 753.084308ms 753.359385ms 753.464186ms 753.475889ms 753.737716ms 753.894399ms 753.917799ms 754.110046ms 754.306238ms 755.061643ms 755.246152ms 755.5936ms 755.692887ms 755.771827ms 756.010396ms 756.360945ms 756.673761ms 756.681616ms 757.119317ms 760.560397ms 761.182043ms 762.290622ms 780.342649ms 850.300006ms]
Oct 25 02:05:51.302: INFO: 50 %ile: 747.303544ms
Oct 25 02:05:51.302: INFO: 90 %ile: 753.737716ms
Oct 25 02:05:51.302: INFO: 99 %ile: 780.342649ms
Oct 25 02:05:51.302: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:188
Oct 25 02:05:51.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3829" for this suite.

• [SLOW TEST:10.855 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":356,"completed":95,"skipped":1668,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:05:51.358: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod test-webserver-ab45ddba-ff7b-4041-8312-a34608d88cb7 in namespace container-probe-5432
Oct 25 02:05:53.438: INFO: Started pod test-webserver-ab45ddba-ff7b-4041-8312-a34608d88cb7 in namespace container-probe-5432
STEP: checking the pod's current state and verifying that restartCount is present
Oct 25 02:05:53.443: INFO: Initial restart count of pod test-webserver-ab45ddba-ff7b-4041-8312-a34608d88cb7 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Oct 25 02:09:54.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5432" for this suite.

• [SLOW TEST:243.647 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":356,"completed":96,"skipped":1710,"failed":0}
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:09:55.005: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-1693
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 25 02:09:55.058: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Oct 25 02:09:55.247: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:09:57.260: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:09:59.260: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:10:01.258: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:10:03.257: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:10:05.258: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:10:07.258: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:10:09.260: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:10:11.261: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:10:13.255: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:10:15.263: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 02:10:17.263: INFO: The status of Pod netserver-0 is Running (Ready = true)
Oct 25 02:10:17.274: INFO: The status of Pod netserver-1 is Running (Ready = true)
Oct 25 02:10:17.288: INFO: The status of Pod netserver-2 is Running (Ready = true)
Oct 25 02:10:17.300: INFO: The status of Pod netserver-3 is Running (Ready = true)
Oct 25 02:10:17.311: INFO: The status of Pod netserver-4 is Running (Ready = true)
Oct 25 02:10:17.326: INFO: The status of Pod netserver-5 is Running (Ready = true)
STEP: Creating test pods
Oct 25 02:10:19.390: INFO: Setting MaxTries for pod polling to 66 for networking test based on endpoint count 6
Oct 25 02:10:19.390: INFO: Going to poll 10.233.99.36 on port 8083 at least 0 times, with a maximum of 66 tries before failing
Oct 25 02:10:19.395: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.99.36:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1693 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:10:19.395: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:10:19.395: INFO: ExecWithOptions: Clientset creation
Oct 25 02:10:19.396: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-1693/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.99.36%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 25 02:10:19.492: INFO: Found all 1 expected endpoints: [netserver-0]
Oct 25 02:10:19.493: INFO: Going to poll 10.233.107.33 on port 8083 at least 0 times, with a maximum of 66 tries before failing
Oct 25 02:10:19.503: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.107.33:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1693 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:10:19.503: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:10:19.503: INFO: ExecWithOptions: Clientset creation
Oct 25 02:10:19.503: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-1693/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.107.33%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 25 02:10:19.582: INFO: Found all 1 expected endpoints: [netserver-1]
Oct 25 02:10:19.582: INFO: Going to poll 10.233.105.32 on port 8083 at least 0 times, with a maximum of 66 tries before failing
Oct 25 02:10:19.589: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.105.32:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1693 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:10:19.589: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:10:19.590: INFO: ExecWithOptions: Clientset creation
Oct 25 02:10:19.590: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-1693/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.105.32%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 25 02:10:19.666: INFO: Found all 1 expected endpoints: [netserver-2]
Oct 25 02:10:19.666: INFO: Going to poll 10.233.95.40 on port 8083 at least 0 times, with a maximum of 66 tries before failing
Oct 25 02:10:19.677: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.95.40:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1693 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:10:19.677: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:10:19.677: INFO: ExecWithOptions: Clientset creation
Oct 25 02:10:19.677: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-1693/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.95.40%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 25 02:10:19.770: INFO: Found all 1 expected endpoints: [netserver-3]
Oct 25 02:10:19.770: INFO: Going to poll 10.233.64.57 on port 8083 at least 0 times, with a maximum of 66 tries before failing
Oct 25 02:10:19.778: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.64.57:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1693 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:10:19.778: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:10:19.778: INFO: ExecWithOptions: Clientset creation
Oct 25 02:10:19.778: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-1693/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.64.57%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 25 02:10:19.854: INFO: Found all 1 expected endpoints: [netserver-4]
Oct 25 02:10:19.854: INFO: Going to poll 10.233.74.112 on port 8083 at least 0 times, with a maximum of 66 tries before failing
Oct 25 02:10:19.862: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.233.74.112:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1693 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:10:19.863: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:10:19.863: INFO: ExecWithOptions: Clientset creation
Oct 25 02:10:19.863: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-1693/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.233.74.112%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 25 02:10:19.940: INFO: Found all 1 expected endpoints: [netserver-5]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Oct 25 02:10:19.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1693" for this suite.

• [SLOW TEST:24.958 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":97,"skipped":1715,"failed":0}
SSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:10:19.963: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Oct 25 02:10:20.005: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Oct 25 02:10:24.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8193" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":356,"completed":98,"skipped":1721,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:10:24.689: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Oct 25 02:10:24.754: INFO: Waiting up to 5m0s for pod "downward-api-97e27615-8aa6-492a-8ae8-34de1ad59dd0" in namespace "downward-api-7018" to be "Succeeded or Failed"
Oct 25 02:10:24.760: INFO: Pod "downward-api-97e27615-8aa6-492a-8ae8-34de1ad59dd0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.153219ms
Oct 25 02:10:26.785: INFO: Pod "downward-api-97e27615-8aa6-492a-8ae8-34de1ad59dd0": Phase="Running", Reason="", readiness=false. Elapsed: 2.030350219s
Oct 25 02:10:28.797: INFO: Pod "downward-api-97e27615-8aa6-492a-8ae8-34de1ad59dd0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042048746s
STEP: Saw pod success
Oct 25 02:10:28.797: INFO: Pod "downward-api-97e27615-8aa6-492a-8ae8-34de1ad59dd0" satisfied condition "Succeeded or Failed"
Oct 25 02:10:28.803: INFO: Trying to get logs from node lab1-k8s-node-2 pod downward-api-97e27615-8aa6-492a-8ae8-34de1ad59dd0 container dapi-container: <nil>
STEP: delete the pod
Oct 25 02:10:28.856: INFO: Waiting for pod downward-api-97e27615-8aa6-492a-8ae8-34de1ad59dd0 to disappear
Oct 25 02:10:28.861: INFO: Pod downward-api-97e27615-8aa6-492a-8ae8-34de1ad59dd0 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Oct 25 02:10:28.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7018" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":356,"completed":99,"skipped":1736,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:10:28.890: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7976
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-7976
I1025 02:10:29.004132      18 runners.go:193] Created replication controller with name: externalname-service, namespace: services-7976, replica count: 2
I1025 02:10:32.055079      18 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 25 02:10:32.055: INFO: Creating new exec pod
Oct 25 02:10:35.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-7976 exec execpodnqk8p -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Oct 25 02:10:35.240: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct 25 02:10:35.240: INFO: stdout: ""
Oct 25 02:10:36.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-7976 exec execpodnqk8p -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Oct 25 02:10:36.388: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct 25 02:10:36.388: INFO: stdout: "externalname-service-wpwwf"
Oct 25 02:10:36.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-7976 exec execpodnqk8p -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.33.58 80'
Oct 25 02:10:36.549: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.33.58 80\nConnection to 10.233.33.58 80 port [tcp/http] succeeded!\n"
Oct 25 02:10:36.549: INFO: stdout: ""
Oct 25 02:10:37.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-7976 exec execpodnqk8p -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.33.58 80'
Oct 25 02:10:37.704: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.33.58 80\nConnection to 10.233.33.58 80 port [tcp/http] succeeded!\n"
Oct 25 02:10:37.704: INFO: stdout: "externalname-service-wpwwf"
Oct 25 02:10:37.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-7976 exec execpodnqk8p -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.1.213 30235'
Oct 25 02:10:37.852: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.128.1.213 30235\nConnection to 10.128.1.213 30235 port [tcp/*] succeeded!\n"
Oct 25 02:10:37.852: INFO: stdout: "externalname-service-fpjsl"
Oct 25 02:10:37.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-7976 exec execpodnqk8p -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.2.74 30235'
Oct 25 02:10:38.014: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.128.2.74 30235\nConnection to 10.128.2.74 30235 port [tcp/*] succeeded!\n"
Oct 25 02:10:38.014: INFO: stdout: "externalname-service-fpjsl"
Oct 25 02:10:38.014: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 02:10:38.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7976" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:9.201 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":356,"completed":100,"skipped":1759,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:10:38.091: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating Agnhost RC
Oct 25 02:10:38.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-1440 create -f -'
Oct 25 02:10:38.899: INFO: stderr: ""
Oct 25 02:10:38.899: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Oct 25 02:10:39.909: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 25 02:10:39.909: INFO: Found 1 / 1
Oct 25 02:10:39.909: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct 25 02:10:39.917: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 25 02:10:39.917: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 25 02:10:39.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-1440 patch pod agnhost-primary-97mgw -p {"metadata":{"annotations":{"x":"y"}}}'
Oct 25 02:10:39.989: INFO: stderr: ""
Oct 25 02:10:39.989: INFO: stdout: "pod/agnhost-primary-97mgw patched\n"
STEP: checking annotations
Oct 25 02:10:39.997: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 25 02:10:39.997: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 02:10:39.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1440" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":356,"completed":101,"skipped":1771,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:10:40.023: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 02:10:40.079: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93234513-a57c-4e60-a8f9-076b4dfbd4bd" in namespace "projected-7711" to be "Succeeded or Failed"
Oct 25 02:10:40.087: INFO: Pod "downwardapi-volume-93234513-a57c-4e60-a8f9-076b4dfbd4bd": Phase="Pending", Reason="", readiness=false. Elapsed: 7.912394ms
Oct 25 02:10:42.096: INFO: Pod "downwardapi-volume-93234513-a57c-4e60-a8f9-076b4dfbd4bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017059501s
Oct 25 02:10:44.109: INFO: Pod "downwardapi-volume-93234513-a57c-4e60-a8f9-076b4dfbd4bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029888457s
STEP: Saw pod success
Oct 25 02:10:44.109: INFO: Pod "downwardapi-volume-93234513-a57c-4e60-a8f9-076b4dfbd4bd" satisfied condition "Succeeded or Failed"
Oct 25 02:10:44.117: INFO: Trying to get logs from node lab1-k8s-node-2 pod downwardapi-volume-93234513-a57c-4e60-a8f9-076b4dfbd4bd container client-container: <nil>
STEP: delete the pod
Oct 25 02:10:44.155: INFO: Waiting for pod downwardapi-volume-93234513-a57c-4e60-a8f9-076b4dfbd4bd to disappear
Oct 25 02:10:44.162: INFO: Pod downwardapi-volume-93234513-a57c-4e60-a8f9-076b4dfbd4bd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Oct 25 02:10:44.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7711" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":356,"completed":102,"skipped":1792,"failed":0}

------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:10:44.192: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name s-test-opt-del-919f26df-0d0a-4632-bc10-57445aabc5f3
STEP: Creating secret with name s-test-opt-upd-40346d66-8f83-4fd8-a053-25e99e023fbc
STEP: Creating the pod
Oct 25 02:10:44.302: INFO: The status of Pod pod-secrets-355146a9-f101-4ff9-b0d2-fcbd3639c4ed is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:10:46.315: INFO: The status of Pod pod-secrets-355146a9-f101-4ff9-b0d2-fcbd3639c4ed is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-919f26df-0d0a-4632-bc10-57445aabc5f3
STEP: Updating secret s-test-opt-upd-40346d66-8f83-4fd8-a053-25e99e023fbc
STEP: Creating secret with name s-test-opt-create-4534b142-a1a8-4981-a792-293043f8cf4b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Oct 25 02:10:48.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9963" for this suite.
•{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":103,"skipped":1792,"failed":0}
SSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:10:48.487: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service nodeport-test with type=NodePort in namespace services-2955
STEP: creating replication controller nodeport-test in namespace services-2955
I1025 02:10:48.583252      18 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-2955, replica count: 2
Oct 25 02:10:51.635: INFO: Creating new exec pod
I1025 02:10:51.635035      18 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 25 02:10:54.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-2955 exec execpodwxbp9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Oct 25 02:10:54.844: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Oct 25 02:10:54.844: INFO: stdout: "nodeport-test-cmtdj"
Oct 25 02:10:54.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-2955 exec execpodwxbp9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.57.173 80'
Oct 25 02:10:55.003: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.57.173 80\nConnection to 10.233.57.173 80 port [tcp/http] succeeded!\n"
Oct 25 02:10:55.003: INFO: stdout: "nodeport-test-24rfm"
Oct 25 02:10:55.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-2955 exec execpodwxbp9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.0.176 30451'
Oct 25 02:10:55.135: INFO: stderr: "+ nc -v -t -w 2 10.128.0.176 30451\n+ echo hostName\nConnection to 10.128.0.176 30451 port [tcp/*] succeeded!\n"
Oct 25 02:10:55.135: INFO: stdout: "nodeport-test-cmtdj"
Oct 25 02:10:55.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-2955 exec execpodwxbp9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.2.74 30451'
Oct 25 02:10:55.281: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.128.2.74 30451\nConnection to 10.128.2.74 30451 port [tcp/*] succeeded!\n"
Oct 25 02:10:55.281: INFO: stdout: "nodeport-test-cmtdj"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 02:10:55.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2955" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:6.824 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":356,"completed":104,"skipped":1798,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:10:55.312: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:10:55.394: INFO: created pod pod-service-account-defaultsa
Oct 25 02:10:55.394: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct 25 02:10:55.404: INFO: created pod pod-service-account-mountsa
Oct 25 02:10:55.404: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct 25 02:10:55.422: INFO: created pod pod-service-account-nomountsa
Oct 25 02:10:55.422: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct 25 02:10:55.442: INFO: created pod pod-service-account-defaultsa-mountspec
Oct 25 02:10:55.442: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct 25 02:10:55.463: INFO: created pod pod-service-account-mountsa-mountspec
Oct 25 02:10:55.463: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct 25 02:10:55.482: INFO: created pod pod-service-account-nomountsa-mountspec
Oct 25 02:10:55.482: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct 25 02:10:55.501: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct 25 02:10:55.501: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct 25 02:10:55.521: INFO: created pod pod-service-account-mountsa-nomountspec
Oct 25 02:10:55.521: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct 25 02:10:55.533: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct 25 02:10:55.533: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Oct 25 02:10:55.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3354" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":356,"completed":105,"skipped":1869,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:10:55.566: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-6568
STEP: creating service affinity-clusterip-transition in namespace services-6568
STEP: creating replication controller affinity-clusterip-transition in namespace services-6568
I1025 02:10:55.632515      18 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-6568, replica count: 3
I1025 02:10:58.684907      18 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1025 02:11:01.686186      18 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 25 02:11:01.716: INFO: Creating new exec pod
Oct 25 02:11:04.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-6568 exec execpod-affinitydbffs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Oct 25 02:11:04.918: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Oct 25 02:11:04.918: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 02:11:04.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-6568 exec execpod-affinitydbffs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.40.70 80'
Oct 25 02:11:05.063: INFO: stderr: "+ nc -v -t -w 2 10.233.40.70 80\n+ echo hostName\nConnection to 10.233.40.70 80 port [tcp/http] succeeded!\n"
Oct 25 02:11:05.063: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 02:11:05.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-6568 exec execpod-affinitydbffs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.40.70:80/ ; done'
Oct 25 02:11:05.344: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n"
Oct 25 02:11:05.344: INFO: stdout: "\naffinity-clusterip-transition-hjkwp\naffinity-clusterip-transition-7kbph\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-hjkwp\naffinity-clusterip-transition-7kbph\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-hjkwp\naffinity-clusterip-transition-7kbph\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-hjkwp\naffinity-clusterip-transition-7kbph\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-hjkwp\naffinity-clusterip-transition-7kbph\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-hjkwp"
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-hjkwp
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-7kbph
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-hjkwp
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-7kbph
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-hjkwp
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-7kbph
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-hjkwp
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-7kbph
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-hjkwp
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-7kbph
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.344: INFO: Received response from host: affinity-clusterip-transition-hjkwp
Oct 25 02:11:05.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-6568 exec execpod-affinitydbffs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.40.70:80/ ; done'
Oct 25 02:11:05.625: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.40.70:80/\n"
Oct 25 02:11:05.625: INFO: stdout: "\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw\naffinity-clusterip-transition-lwhjw"
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.625: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.626: INFO: Received response from host: affinity-clusterip-transition-lwhjw
Oct 25 02:11:05.626: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-6568, will wait for the garbage collector to delete the pods
Oct 25 02:11:05.728: INFO: Deleting ReplicationController affinity-clusterip-transition took: 12.495461ms
Oct 25 02:11:05.830: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.106623ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 02:11:07.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6568" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:12.434 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":106,"skipped":1936,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:11:08.004: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Oct 25 02:11:08.049: INFO: Waiting up to 1m0s for all nodes to be ready
Oct 25 02:12:08.107: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:12:08.115: INFO: Starting informer...
STEP: Starting pod...
Oct 25 02:12:08.347: INFO: Pod is running on lab1-k8s-node-3. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Oct 25 02:12:08.380: INFO: Pod wasn't evicted. Proceeding
Oct 25 02:12:08.380: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Oct 25 02:13:23.441: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:13:23.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-6064" for this suite.

• [SLOW TEST:135.464 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":356,"completed":107,"skipped":1954,"failed":0}
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:13:23.468: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 02:13:23.527: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2dbb909-4e98-44ee-98fb-7f766087cac2" in namespace "projected-1976" to be "Succeeded or Failed"
Oct 25 02:13:23.540: INFO: Pod "downwardapi-volume-a2dbb909-4e98-44ee-98fb-7f766087cac2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.203703ms
Oct 25 02:13:25.551: INFO: Pod "downwardapi-volume-a2dbb909-4e98-44ee-98fb-7f766087cac2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023315246s
Oct 25 02:13:27.565: INFO: Pod "downwardapi-volume-a2dbb909-4e98-44ee-98fb-7f766087cac2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037208386s
STEP: Saw pod success
Oct 25 02:13:27.565: INFO: Pod "downwardapi-volume-a2dbb909-4e98-44ee-98fb-7f766087cac2" satisfied condition "Succeeded or Failed"
Oct 25 02:13:27.572: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-a2dbb909-4e98-44ee-98fb-7f766087cac2 container client-container: <nil>
STEP: delete the pod
Oct 25 02:13:27.622: INFO: Waiting for pod downwardapi-volume-a2dbb909-4e98-44ee-98fb-7f766087cac2 to disappear
Oct 25 02:13:27.645: INFO: Pod downwardapi-volume-a2dbb909-4e98-44ee-98fb-7f766087cac2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Oct 25 02:13:27.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1976" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":108,"skipped":1954,"failed":0}

------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:13:27.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 25 02:13:27.812: INFO: Waiting up to 5m0s for pod "pod-11575431-d1ed-40ce-af71-797e320b41de" in namespace "emptydir-2901" to be "Succeeded or Failed"
Oct 25 02:13:27.824: INFO: Pod "pod-11575431-d1ed-40ce-af71-797e320b41de": Phase="Pending", Reason="", readiness=false. Elapsed: 12.097461ms
Oct 25 02:13:29.837: INFO: Pod "pod-11575431-d1ed-40ce-af71-797e320b41de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024937638s
Oct 25 02:13:31.850: INFO: Pod "pod-11575431-d1ed-40ce-af71-797e320b41de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037943111s
STEP: Saw pod success
Oct 25 02:13:31.850: INFO: Pod "pod-11575431-d1ed-40ce-af71-797e320b41de" satisfied condition "Succeeded or Failed"
Oct 25 02:13:31.856: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-11575431-d1ed-40ce-af71-797e320b41de container test-container: <nil>
STEP: delete the pod
Oct 25 02:13:31.888: INFO: Waiting for pod pod-11575431-d1ed-40ce-af71-797e320b41de to disappear
Oct 25 02:13:31.894: INFO: Pod pod-11575431-d1ed-40ce-af71-797e320b41de no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 02:13:31.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2901" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":109,"skipped":1954,"failed":0}
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:13:31.919: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 25 02:13:32.072: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:13:32.072: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 02:13:33.095: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Oct 25 02:13:33.095: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 02:13:34.094: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Oct 25 02:13:34.094: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 02:13:35.090: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 6
Oct 25 02:13:35.090: INFO: Number of running nodes: 6, number of available pods: 6 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct 25 02:13:35.136: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Oct 25 02:13:35.136: INFO: Node lab1-k8s-node-1 is running 0 daemon pod, expected 1
Oct 25 02:13:36.167: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Oct 25 02:13:36.167: INFO: Node lab1-k8s-node-1 is running 0 daemon pod, expected 1
Oct 25 02:13:37.163: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 6
Oct 25 02:13:37.163: INFO: Number of running nodes: 6, number of available pods: 6 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-926, will wait for the garbage collector to delete the pods
Oct 25 02:13:37.241: INFO: Deleting DaemonSet.extensions daemon-set took: 12.26475ms
Oct 25 02:13:37.442: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.781624ms
Oct 25 02:13:40.257: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:13:40.257: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct 25 02:13:40.264: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"220364"},"items":null}

Oct 25 02:13:40.271: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"220364"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:13:40.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-926" for this suite.

• [SLOW TEST:8.428 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":356,"completed":110,"skipped":1959,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:13:40.347: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct 25 02:13:40.413: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5439  323aa037-77f8-49c6-8a50-a771ff0be1ac 220369 0 2022-10-25 02:13:40 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-10-25 02:13:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 25 02:13:40.417: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5439  323aa037-77f8-49c6-8a50-a771ff0be1ac 220370 0 2022-10-25 02:13:40 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-10-25 02:13:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct 25 02:13:40.459: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5439  323aa037-77f8-49c6-8a50-a771ff0be1ac 220371 0 2022-10-25 02:13:40 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-10-25 02:13:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 25 02:13:40.459: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5439  323aa037-77f8-49c6-8a50-a771ff0be1ac 220372 0 2022-10-25 02:13:40 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-10-25 02:13:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Oct 25 02:13:40.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5439" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":356,"completed":111,"skipped":1960,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:13:40.488: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Oct 25 02:13:40.521: INFO: PodSpec: initContainers in spec.initContainers
Oct 25 02:14:27.260: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-411c8a92-c367-431a-b70d-3f8f79aac32f", GenerateName:"", Namespace:"init-container-5727", SelfLink:"", UID:"51039755-8761-4a99-938b-be6a540b9723", ResourceVersion:"220603", Generation:0, CreationTimestamp:time.Date(2022, time.October, 25, 2, 13, 40, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"521346075"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"5ffc1a388b2eb7dc15aa847d39d91b6d205c5d0add3d36f6e46ba1e6c509e1d8", "cni.projectcalico.org/podIP":"10.233.74.127/32", "cni.projectcalico.org/podIPs":"10.233.74.127/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.October, 25, 2, 13, 40, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0017eb230), Subresource:""}, v1.ManagedFieldsEntry{Manager:"Go-http-client", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.October, 25, 2, 13, 41, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0017eb4d0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.October, 25, 2, 13, 42, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0017eb500), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-q8x76", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc002176060), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-q8x76", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-q8x76", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.7", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-q8x76", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003bf29e0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"lab1-k8s-node-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0028c9e30), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003bf2a70)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003bf2a90)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003bf2a98), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003bf2a9c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc003b3b870), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.October, 25, 2, 13, 40, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.October, 25, 2, 13, 40, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.October, 25, 2, 13, 40, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.October, 25, 2, 13, 40, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.128.1.178", PodIP:"10.233.74.127", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.233.74.127"}}, StartTime:time.Date(2022, time.October, 25, 2, 13, 40, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003364000)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003364070)}, Ready:false, RestartCount:3, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"k8s.gcr.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://e03a2ca170ed51bfa81a0657eefc537d3f5046afbe8eff19af2aa2ec73d2037b", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002176280), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0021761e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.7", ImageID:"", ContainerID:"", Started:(*bool)(0xc003bf2b1f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Oct 25 02:14:27.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5727" for this suite.

• [SLOW TEST:46.812 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":356,"completed":112,"skipped":1989,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should support CronJob API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:14:27.301: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support CronJob API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a cronjob
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Oct 25 02:14:27.376: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Oct 25 02:14:27.387: INFO: starting watch
STEP: patching
STEP: updating
Oct 25 02:14:27.424: INFO: waiting for watch events with expected annotations
Oct 25 02:14:27.424: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Oct 25 02:14:27.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9280" for this suite.
•{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","total":356,"completed":113,"skipped":2005,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:14:27.536: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not conflict [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:14:27.630: INFO: The status of Pod pod-secrets-cb9a6525-0cb0-4c36-a248-8b352cefe11d is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:14:29.641: INFO: The status of Pod pod-secrets-cb9a6525-0cb0-4c36-a248-8b352cefe11d is Running (Ready = true)
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:188
Oct 25 02:14:29.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4962" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":356,"completed":114,"skipped":2050,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:14:29.742: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 02:14:30.377: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 02:14:33.426: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:14:33.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5637" for this suite.
STEP: Destroying namespace "webhook-5637-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":356,"completed":115,"skipped":2113,"failed":0}
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:14:33.877: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-map-a75cab46-d1f4-4904-a4eb-dec9a107c462
STEP: Creating a pod to test consume secrets
Oct 25 02:14:33.970: INFO: Waiting up to 5m0s for pod "pod-secrets-f6bf2a55-cbac-41f5-a5ac-b61594557377" in namespace "secrets-9517" to be "Succeeded or Failed"
Oct 25 02:14:33.979: INFO: Pod "pod-secrets-f6bf2a55-cbac-41f5-a5ac-b61594557377": Phase="Pending", Reason="", readiness=false. Elapsed: 9.726253ms
Oct 25 02:14:35.989: INFO: Pod "pod-secrets-f6bf2a55-cbac-41f5-a5ac-b61594557377": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019637907s
Oct 25 02:14:38.007: INFO: Pod "pod-secrets-f6bf2a55-cbac-41f5-a5ac-b61594557377": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037156513s
STEP: Saw pod success
Oct 25 02:14:38.007: INFO: Pod "pod-secrets-f6bf2a55-cbac-41f5-a5ac-b61594557377" satisfied condition "Succeeded or Failed"
Oct 25 02:14:38.015: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-secrets-f6bf2a55-cbac-41f5-a5ac-b61594557377 container secret-volume-test: <nil>
STEP: delete the pod
Oct 25 02:14:38.061: INFO: Waiting for pod pod-secrets-f6bf2a55-cbac-41f5-a5ac-b61594557377 to disappear
Oct 25 02:14:38.066: INFO: Pod pod-secrets-f6bf2a55-cbac-41f5-a5ac-b61594557377 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Oct 25 02:14:38.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9517" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":116,"skipped":2114,"failed":0}
SSS
------------------------------
[sig-apps] DisruptionController 
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:14:38.093: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Updating PodDisruptionBudget status
STEP: Waiting for all pods to be running
Oct 25 02:14:38.184: INFO: running pods: 0 < 1
STEP: locating a running pod
STEP: Waiting for the pdb to be processed
STEP: Patching PodDisruptionBudget status
STEP: Waiting for the pdb to be processed
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Oct 25 02:14:40.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-5866" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","total":356,"completed":117,"skipped":2117,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:14:40.276: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: waiting for pod running
STEP: creating a file in subpath
Oct 25 02:14:42.353: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-6707 PodName:var-expansion-2e60f90a-d2cd-45e4-ba5e-9a1801c91e1f ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:14:42.353: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:14:42.353: INFO: ExecWithOptions: Clientset creation
Oct 25 02:14:42.353: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-6707/pods/var-expansion-2e60f90a-d2cd-45e4-ba5e-9a1801c91e1f/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path
Oct 25 02:14:42.442: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-6707 PodName:var-expansion-2e60f90a-d2cd-45e4-ba5e-9a1801c91e1f ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:14:42.442: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:14:42.443: INFO: ExecWithOptions: Clientset creation
Oct 25 02:14:42.443: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/var-expansion-6707/pods/var-expansion-2e60f90a-d2cd-45e4-ba5e-9a1801c91e1f/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value
Oct 25 02:14:43.041: INFO: Successfully updated pod "var-expansion-2e60f90a-d2cd-45e4-ba5e-9a1801c91e1f"
STEP: waiting for annotated pod running
STEP: deleting the pod gracefully
Oct 25 02:14:43.053: INFO: Deleting pod "var-expansion-2e60f90a-d2cd-45e4-ba5e-9a1801c91e1f" in namespace "var-expansion-6707"
Oct 25 02:14:43.070: INFO: Wait up to 5m0s for pod "var-expansion-2e60f90a-d2cd-45e4-ba5e-9a1801c91e1f" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Oct 25 02:15:17.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6707" for this suite.

• [SLOW TEST:36.842 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","total":356,"completed":118,"skipped":2164,"failed":0}
SSSSSSS
------------------------------
[sig-network] IngressClass API 
   should support creating IngressClass API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:15:17.119: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename ingressclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:188
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Oct 25 02:15:17.220: INFO: starting watch
STEP: patching
STEP: updating
Oct 25 02:15:17.240: INFO: waiting for watch events with expected annotations
Oct 25 02:15:17.240: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:188
Oct 25 02:15:17.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-1387" for this suite.
•{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","total":356,"completed":119,"skipped":2171,"failed":0}
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:15:17.319: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should create and stop a working application  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating all guestbook components
Oct 25 02:15:17.359: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Oct 25 02:15:17.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-8879 create -f -'
Oct 25 02:15:17.525: INFO: stderr: ""
Oct 25 02:15:17.525: INFO: stdout: "service/agnhost-replica created\n"
Oct 25 02:15:17.525: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Oct 25 02:15:17.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-8879 create -f -'
Oct 25 02:15:18.445: INFO: stderr: ""
Oct 25 02:15:18.445: INFO: stdout: "service/agnhost-primary created\n"
Oct 25 02:15:18.445: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct 25 02:15:18.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-8879 create -f -'
Oct 25 02:15:18.961: INFO: stderr: ""
Oct 25 02:15:18.961: INFO: stdout: "service/frontend created\n"
Oct 25 02:15:18.961: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Oct 25 02:15:18.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-8879 create -f -'
Oct 25 02:15:19.127: INFO: stderr: ""
Oct 25 02:15:19.127: INFO: stdout: "deployment.apps/frontend created\n"
Oct 25 02:15:19.127: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 25 02:15:19.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-8879 create -f -'
Oct 25 02:15:19.289: INFO: stderr: ""
Oct 25 02:15:19.289: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Oct 25 02:15:19.290: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 25 02:15:19.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-8879 create -f -'
Oct 25 02:15:19.430: INFO: stderr: ""
Oct 25 02:15:19.430: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app
Oct 25 02:15:19.430: INFO: Waiting for all frontend pods to be Running.
Oct 25 02:15:24.482: INFO: Waiting for frontend to serve content.
Oct 25 02:15:24.499: INFO: Trying to add a new entry to the guestbook.
Oct 25 02:15:24.516: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct 25 02:15:24.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-8879 delete --grace-period=0 --force -f -'
Oct 25 02:15:24.629: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 25 02:15:24.629: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources
Oct 25 02:15:24.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-8879 delete --grace-period=0 --force -f -'
Oct 25 02:15:24.761: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 25 02:15:24.761: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Oct 25 02:15:24.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-8879 delete --grace-period=0 --force -f -'
Oct 25 02:15:24.878: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 25 02:15:24.878: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 25 02:15:24.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-8879 delete --grace-period=0 --force -f -'
Oct 25 02:15:24.970: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 25 02:15:24.970: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 25 02:15:24.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-8879 delete --grace-period=0 --force -f -'
Oct 25 02:15:25.054: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 25 02:15:25.054: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Oct 25 02:15:25.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-8879 delete --grace-period=0 --force -f -'
Oct 25 02:15:25.171: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 25 02:15:25.171: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 02:15:25.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8879" for this suite.

• [SLOW TEST:7.892 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:340
    should create and stop a working application  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":356,"completed":120,"skipped":2179,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:15:25.211: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 02:15:25.742: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 25 02:15:27.772: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 25, 2, 15, 25, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 15, 25, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 15, 25, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 15, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-68c7bd4684\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 02:15:30.808: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:15:31.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6780" for this suite.
STEP: Destroying namespace "webhook-6780-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.065 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":356,"completed":121,"skipped":2199,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:15:31.281: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap configmap-5779/configmap-test-7259e039-26f2-4d7d-9b4a-c599eb9c675e
STEP: Creating a pod to test consume configMaps
Oct 25 02:15:31.350: INFO: Waiting up to 5m0s for pod "pod-configmaps-b1770745-6c82-4e61-ad02-3a18020a36c6" in namespace "configmap-5779" to be "Succeeded or Failed"
Oct 25 02:15:31.359: INFO: Pod "pod-configmaps-b1770745-6c82-4e61-ad02-3a18020a36c6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.770114ms
Oct 25 02:15:33.370: INFO: Pod "pod-configmaps-b1770745-6c82-4e61-ad02-3a18020a36c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020328852s
Oct 25 02:15:35.384: INFO: Pod "pod-configmaps-b1770745-6c82-4e61-ad02-3a18020a36c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034170084s
STEP: Saw pod success
Oct 25 02:15:35.384: INFO: Pod "pod-configmaps-b1770745-6c82-4e61-ad02-3a18020a36c6" satisfied condition "Succeeded or Failed"
Oct 25 02:15:35.393: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-configmaps-b1770745-6c82-4e61-ad02-3a18020a36c6 container env-test: <nil>
STEP: delete the pod
Oct 25 02:15:35.433: INFO: Waiting for pod pod-configmaps-b1770745-6c82-4e61-ad02-3a18020a36c6 to disappear
Oct 25 02:15:35.438: INFO: Pod pod-configmaps-b1770745-6c82-4e61-ad02-3a18020a36c6 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 02:15:35.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5779" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":356,"completed":122,"skipped":2230,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:15:35.473: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:15:35.548: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct 25 02:15:40.567: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 25 02:15:40.567: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 25 02:15:40.614: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-3257  8425d4e0-2beb-4388-9674-32fe98decce7 221485 1 2022-10-25 02:15:40 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  [{e2e.test Update apps/v1 2022-10-25 02:15:40 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00428ab28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Oct 25 02:15:40.625: INFO: New ReplicaSet "test-cleanup-deployment-6755c7b765" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-6755c7b765  deployment-3257  19bf1156-9d7d-4c99-8139-cf1b3910ae66 221488 1 2022-10-25 02:15:40 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:6755c7b765] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 8425d4e0-2beb-4388-9674-32fe98decce7 0xc004392737 0xc004392738}] []  [{kube-controller-manager Update apps/v1 2022-10-25 02:15:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8425d4e0-2beb-4388-9674-32fe98decce7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 6755c7b765,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:6755c7b765] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0043927c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 25 02:15:40.625: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Oct 25 02:15:40.625: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-3257  1c884374-51e4-40df-9d73-21cab662f0f6 221486 1 2022-10-25 02:15:35 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 8425d4e0-2beb-4388-9674-32fe98decce7 0xc004392607 0xc004392608}] []  [{e2e.test Update apps/v1 2022-10-25 02:15:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 02:15:36 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-10-25 02:15:40 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"8425d4e0-2beb-4388-9674-32fe98decce7\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0043926c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 25 02:15:40.638: INFO: Pod "test-cleanup-controller-zmx48" is available:
&Pod{ObjectMeta:{test-cleanup-controller-zmx48 test-cleanup-controller- deployment-3257  9650ce5f-a091-47cf-a424-308b920a495d 221471 0 2022-10-25 02:15:35 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/containerID:ec9c8da20f19aa11315a276bb4c034ba7f743ee3e0c27c8a519adf0ea1ae38e6 cni.projectcalico.org/podIP:10.233.74.136/32 cni.projectcalico.org/podIPs:10.233.74.136/32] [{apps/v1 ReplicaSet test-cleanup-controller 1c884374-51e4-40df-9d73-21cab662f0f6 0xc004392c17 0xc004392c18}] []  [{kube-controller-manager Update v1 2022-10-25 02:15:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1c884374-51e4-40df-9d73-21cab662f0f6\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-10-25 02:15:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-25 02:15:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.74.136\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-psrns,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-psrns,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:15:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:15:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:15:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:15:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.178,PodIP:10.233.74.136,StartTime:2022-10-25 02:15:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 02:15:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c4d25b57476c45f9212abec229cd1f0d6fc631d087622bc49057c59a3345eaa6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.74.136,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 02:15:40.638: INFO: Pod "test-cleanup-deployment-6755c7b765-5vwrc" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-6755c7b765-5vwrc test-cleanup-deployment-6755c7b765- deployment-3257  0cc0d097-f475-4a4f-a488-27ec96f5f1b3 221490 0 2022-10-25 02:15:40 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:6755c7b765] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-6755c7b765 19bf1156-9d7d-4c99-8139-cf1b3910ae66 0xc004392e37 0xc004392e38}] []  [{kube-controller-manager Update v1 2022-10-25 02:15:40 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"19bf1156-9d7d-4c99-8139-cf1b3910ae66\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-29hjn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-29hjn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Oct 25 02:15:40.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3257" for this suite.

• [SLOW TEST:5.214 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":356,"completed":123,"skipped":2249,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:15:40.689: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Oct 25 02:15:56.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4639" for this suite.

• [SLOW TEST:16.307 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":356,"completed":124,"skipped":2303,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:15:56.997: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
STEP: referencing a single matching pod
STEP: referencing matching pods with named port
STEP: creating empty Endpoints and EndpointSlices for no matching Pods
STEP: recreating EndpointSlices after they've been deleted
Oct 25 02:16:17.314: INFO: EndpointSlice for Service endpointslice-5565/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Oct 25 02:16:27.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5565" for this suite.

• [SLOW TEST:30.375 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","total":356,"completed":125,"skipped":2317,"failed":0}
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:16:27.373: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Oct 25 02:16:40.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9881" for this suite.

• [SLOW TEST:13.246 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":356,"completed":126,"skipped":2321,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:16:40.621: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 02:16:40.682: INFO: Waiting up to 5m0s for pod "downwardapi-volume-adef38b6-739a-477f-bedd-7f637c006350" in namespace "projected-3820" to be "Succeeded or Failed"
Oct 25 02:16:40.689: INFO: Pod "downwardapi-volume-adef38b6-739a-477f-bedd-7f637c006350": Phase="Pending", Reason="", readiness=false. Elapsed: 7.572831ms
Oct 25 02:16:42.705: INFO: Pod "downwardapi-volume-adef38b6-739a-477f-bedd-7f637c006350": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023804169s
Oct 25 02:16:44.720: INFO: Pod "downwardapi-volume-adef38b6-739a-477f-bedd-7f637c006350": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038478571s
STEP: Saw pod success
Oct 25 02:16:44.720: INFO: Pod "downwardapi-volume-adef38b6-739a-477f-bedd-7f637c006350" satisfied condition "Succeeded or Failed"
Oct 25 02:16:44.728: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-adef38b6-739a-477f-bedd-7f637c006350 container client-container: <nil>
STEP: delete the pod
Oct 25 02:16:44.766: INFO: Waiting for pod downwardapi-volume-adef38b6-739a-477f-bedd-7f637c006350 to disappear
Oct 25 02:16:44.773: INFO: Pod downwardapi-volume-adef38b6-739a-477f-bedd-7f637c006350 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Oct 25 02:16:44.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3820" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":356,"completed":127,"skipped":2334,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:16:44.801: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 25 02:16:44.868: INFO: Waiting up to 5m0s for pod "pod-3a2893c1-244e-432c-aa20-85f3bcdf07da" in namespace "emptydir-9163" to be "Succeeded or Failed"
Oct 25 02:16:44.875: INFO: Pod "pod-3a2893c1-244e-432c-aa20-85f3bcdf07da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.988039ms
Oct 25 02:16:46.886: INFO: Pod "pod-3a2893c1-244e-432c-aa20-85f3bcdf07da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018066674s
Oct 25 02:16:48.899: INFO: Pod "pod-3a2893c1-244e-432c-aa20-85f3bcdf07da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031649209s
STEP: Saw pod success
Oct 25 02:16:48.900: INFO: Pod "pod-3a2893c1-244e-432c-aa20-85f3bcdf07da" satisfied condition "Succeeded or Failed"
Oct 25 02:16:48.905: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-3a2893c1-244e-432c-aa20-85f3bcdf07da container test-container: <nil>
STEP: delete the pod
Oct 25 02:16:48.948: INFO: Waiting for pod pod-3a2893c1-244e-432c-aa20-85f3bcdf07da to disappear
Oct 25 02:16:48.955: INFO: Pod pod-3a2893c1-244e-432c-aa20-85f3bcdf07da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 02:16:48.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9163" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":128,"skipped":2345,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:16:48.976: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-de58a27c-23b5-4af3-87ba-70fc292368e9
STEP: Creating a pod to test consume configMaps
Oct 25 02:16:49.039: INFO: Waiting up to 5m0s for pod "pod-configmaps-b48f5f86-edf1-47f6-8e41-98c7c30065c9" in namespace "configmap-8147" to be "Succeeded or Failed"
Oct 25 02:16:49.050: INFO: Pod "pod-configmaps-b48f5f86-edf1-47f6-8e41-98c7c30065c9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.168124ms
Oct 25 02:16:51.057: INFO: Pod "pod-configmaps-b48f5f86-edf1-47f6-8e41-98c7c30065c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018021611s
Oct 25 02:16:53.066: INFO: Pod "pod-configmaps-b48f5f86-edf1-47f6-8e41-98c7c30065c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027435631s
STEP: Saw pod success
Oct 25 02:16:53.066: INFO: Pod "pod-configmaps-b48f5f86-edf1-47f6-8e41-98c7c30065c9" satisfied condition "Succeeded or Failed"
Oct 25 02:16:53.072: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-configmaps-b48f5f86-edf1-47f6-8e41-98c7c30065c9 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 25 02:16:53.125: INFO: Waiting for pod pod-configmaps-b48f5f86-edf1-47f6-8e41-98c7c30065c9 to disappear
Oct 25 02:16:53.131: INFO: Pod pod-configmaps-b48f5f86-edf1-47f6-8e41-98c7c30065c9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 02:16:53.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8147" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":356,"completed":129,"skipped":2346,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:16:53.152: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Starting the proxy
Oct 25 02:16:53.192: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-7592 proxy --unix-socket=/tmp/kubectl-proxy-unix4131741173/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 02:16:53.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7592" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":356,"completed":130,"skipped":2368,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity 
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:16:53.253: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename csistoragecapacity
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/storage.k8s.io
STEP: getting /apis/storage.k8s.io/v1
STEP: creating
STEP: watching
Oct 25 02:16:53.327: INFO: starting watch
STEP: getting
STEP: listing in namespace
STEP: listing across namespaces
STEP: patching
STEP: updating
Oct 25 02:16:53.382: INFO: waiting for watch events with expected annotations in namespace
Oct 25 02:16:53.382: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:188
Oct 25 02:16:53.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-9763" for this suite.
•{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","total":356,"completed":131,"skipped":2390,"failed":0}
SSSSS
------------------------------
[sig-instrumentation] Events API 
  should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:16:53.461: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of events
STEP: get a list of Events with a label in the current namespace
STEP: delete a list of events
Oct 25 02:16:53.534: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:188
Oct 25 02:16:53.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9859" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","total":356,"completed":132,"skipped":2395,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:16:53.613: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 02:16:53.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3214" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","total":356,"completed":133,"skipped":2444,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:16:53.748: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Oct 25 02:17:00.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7503" for this suite.

• [SLOW TEST:7.098 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":356,"completed":134,"skipped":2494,"failed":0}
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:17:00.847: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Oct 25 02:17:00.913: INFO: Waiting up to 5m0s for pod "downward-api-7aad78bb-8be9-4b1e-9e53-f80d61e29eed" in namespace "downward-api-4394" to be "Succeeded or Failed"
Oct 25 02:17:00.921: INFO: Pod "downward-api-7aad78bb-8be9-4b1e-9e53-f80d61e29eed": Phase="Pending", Reason="", readiness=false. Elapsed: 7.914224ms
Oct 25 02:17:02.931: INFO: Pod "downward-api-7aad78bb-8be9-4b1e-9e53-f80d61e29eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018424839s
Oct 25 02:17:04.947: INFO: Pod "downward-api-7aad78bb-8be9-4b1e-9e53-f80d61e29eed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033747098s
STEP: Saw pod success
Oct 25 02:17:04.947: INFO: Pod "downward-api-7aad78bb-8be9-4b1e-9e53-f80d61e29eed" satisfied condition "Succeeded or Failed"
Oct 25 02:17:04.954: INFO: Trying to get logs from node lab1-k8s-node-3 pod downward-api-7aad78bb-8be9-4b1e-9e53-f80d61e29eed container dapi-container: <nil>
STEP: delete the pod
Oct 25 02:17:04.997: INFO: Waiting for pod downward-api-7aad78bb-8be9-4b1e-9e53-f80d61e29eed to disappear
Oct 25 02:17:05.004: INFO: Pod downward-api-7aad78bb-8be9-4b1e-9e53-f80d61e29eed no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Oct 25 02:17:05.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4394" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":356,"completed":135,"skipped":2500,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:17:05.029: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 25 02:17:05.090: INFO: Waiting up to 5m0s for pod "pod-5340eb8e-57ce-4677-88ec-ad7e6e6512ec" in namespace "emptydir-5213" to be "Succeeded or Failed"
Oct 25 02:17:05.102: INFO: Pod "pod-5340eb8e-57ce-4677-88ec-ad7e6e6512ec": Phase="Pending", Reason="", readiness=false. Elapsed: 12.078332ms
Oct 25 02:17:07.111: INFO: Pod "pod-5340eb8e-57ce-4677-88ec-ad7e6e6512ec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020973564s
Oct 25 02:17:09.126: INFO: Pod "pod-5340eb8e-57ce-4677-88ec-ad7e6e6512ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035564434s
STEP: Saw pod success
Oct 25 02:17:09.126: INFO: Pod "pod-5340eb8e-57ce-4677-88ec-ad7e6e6512ec" satisfied condition "Succeeded or Failed"
Oct 25 02:17:09.133: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-5340eb8e-57ce-4677-88ec-ad7e6e6512ec container test-container: <nil>
STEP: delete the pod
Oct 25 02:17:09.168: INFO: Waiting for pod pod-5340eb8e-57ce-4677-88ec-ad7e6e6512ec to disappear
Oct 25 02:17:09.176: INFO: Pod pod-5340eb8e-57ce-4677-88ec-ad7e6e6512ec no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 02:17:09.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5213" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":136,"skipped":2540,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:17:09.202: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Oct 25 02:17:21.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4627" for this suite.

• [SLOW TEST:12.096 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":356,"completed":137,"skipped":2558,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:17:21.300: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-configmap-ld9p
STEP: Creating a pod to test atomic-volume-subpath
Oct 25 02:17:21.372: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ld9p" in namespace "subpath-7824" to be "Succeeded or Failed"
Oct 25 02:17:21.384: INFO: Pod "pod-subpath-test-configmap-ld9p": Phase="Pending", Reason="", readiness=false. Elapsed: 11.471018ms
Oct 25 02:17:23.394: INFO: Pod "pod-subpath-test-configmap-ld9p": Phase="Running", Reason="", readiness=true. Elapsed: 2.021488024s
Oct 25 02:17:25.408: INFO: Pod "pod-subpath-test-configmap-ld9p": Phase="Running", Reason="", readiness=true. Elapsed: 4.035616049s
Oct 25 02:17:27.419: INFO: Pod "pod-subpath-test-configmap-ld9p": Phase="Running", Reason="", readiness=true. Elapsed: 6.04687584s
Oct 25 02:17:29.432: INFO: Pod "pod-subpath-test-configmap-ld9p": Phase="Running", Reason="", readiness=true. Elapsed: 8.05966516s
Oct 25 02:17:31.448: INFO: Pod "pod-subpath-test-configmap-ld9p": Phase="Running", Reason="", readiness=true. Elapsed: 10.075806236s
Oct 25 02:17:33.458: INFO: Pod "pod-subpath-test-configmap-ld9p": Phase="Running", Reason="", readiness=true. Elapsed: 12.085643554s
Oct 25 02:17:35.471: INFO: Pod "pod-subpath-test-configmap-ld9p": Phase="Running", Reason="", readiness=true. Elapsed: 14.099094688s
Oct 25 02:17:37.481: INFO: Pod "pod-subpath-test-configmap-ld9p": Phase="Running", Reason="", readiness=true. Elapsed: 16.109022849s
Oct 25 02:17:39.500: INFO: Pod "pod-subpath-test-configmap-ld9p": Phase="Running", Reason="", readiness=true. Elapsed: 18.127429433s
Oct 25 02:17:41.512: INFO: Pod "pod-subpath-test-configmap-ld9p": Phase="Running", Reason="", readiness=true. Elapsed: 20.139938156s
Oct 25 02:17:43.523: INFO: Pod "pod-subpath-test-configmap-ld9p": Phase="Running", Reason="", readiness=false. Elapsed: 22.151113367s
Oct 25 02:17:45.534: INFO: Pod "pod-subpath-test-configmap-ld9p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.16188549s
STEP: Saw pod success
Oct 25 02:17:45.534: INFO: Pod "pod-subpath-test-configmap-ld9p" satisfied condition "Succeeded or Failed"
Oct 25 02:17:45.542: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-subpath-test-configmap-ld9p container test-container-subpath-configmap-ld9p: <nil>
STEP: delete the pod
Oct 25 02:17:45.577: INFO: Waiting for pod pod-subpath-test-configmap-ld9p to disappear
Oct 25 02:17:45.582: INFO: Pod pod-subpath-test-configmap-ld9p no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ld9p
Oct 25 02:17:45.582: INFO: Deleting pod "pod-subpath-test-configmap-ld9p" in namespace "subpath-7824"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Oct 25 02:17:45.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7824" for this suite.

• [SLOW TEST:24.316 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","total":356,"completed":138,"skipped":2574,"failed":0}
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:17:45.618: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/framework/framework.go:652
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-9zpgd in namespace proxy-8528
I1025 02:17:45.694569      18 runners.go:193] Created replication controller with name: proxy-service-9zpgd, namespace: proxy-8528, replica count: 1
I1025 02:17:46.746175      18 runners.go:193] proxy-service-9zpgd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1025 02:17:47.746346      18 runners.go:193] proxy-service-9zpgd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1025 02:17:48.746513      18 runners.go:193] proxy-service-9zpgd Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 25 02:17:48.757: INFO: setup took 3.094108329s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct 25 02:17:48.776: INFO: (0) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 18.330433ms)
Oct 25 02:17:48.777: INFO: (0) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 19.64344ms)
Oct 25 02:17:48.780: INFO: (0) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 22.530552ms)
Oct 25 02:17:48.781: INFO: (0) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 22.956971ms)
Oct 25 02:17:48.781: INFO: (0) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 23.368867ms)
Oct 25 02:17:48.781: INFO: (0) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 23.455263ms)
Oct 25 02:17:48.781: INFO: (0) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 23.627362ms)
Oct 25 02:17:48.781: INFO: (0) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 23.510093ms)
Oct 25 02:17:48.782: INFO: (0) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 24.32525ms)
Oct 25 02:17:48.782: INFO: (0) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 24.584895ms)
Oct 25 02:17:48.783: INFO: (0) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 25.375582ms)
Oct 25 02:17:48.783: INFO: (0) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 25.245332ms)
Oct 25 02:17:48.784: INFO: (0) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 25.995492ms)
Oct 25 02:17:48.784: INFO: (0) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 26.266827ms)
Oct 25 02:17:48.784: INFO: (0) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 26.261887ms)
Oct 25 02:17:48.785: INFO: (0) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 26.957561ms)
Oct 25 02:17:48.797: INFO: (1) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 12.705938ms)
Oct 25 02:17:48.800: INFO: (1) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 15.374819ms)
Oct 25 02:17:48.801: INFO: (1) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 15.948268ms)
Oct 25 02:17:48.803: INFO: (1) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 17.796966ms)
Oct 25 02:17:48.806: INFO: (1) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 20.894004ms)
Oct 25 02:17:48.806: INFO: (1) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 20.976155ms)
Oct 25 02:17:48.806: INFO: (1) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 20.929769ms)
Oct 25 02:17:48.806: INFO: (1) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 21.672872ms)
Oct 25 02:17:48.808: INFO: (1) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 22.768903ms)
Oct 25 02:17:48.808: INFO: (1) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 22.796722ms)
Oct 25 02:17:48.808: INFO: (1) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 22.847573ms)
Oct 25 02:17:48.808: INFO: (1) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 23.043108ms)
Oct 25 02:17:48.808: INFO: (1) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 23.23044ms)
Oct 25 02:17:48.808: INFO: (1) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 23.256424ms)
Oct 25 02:17:48.809: INFO: (1) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 24.181756ms)
Oct 25 02:17:48.810: INFO: (1) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 25.249569ms)
Oct 25 02:17:48.819: INFO: (2) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 7.842682ms)
Oct 25 02:17:48.823: INFO: (2) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 12.347408ms)
Oct 25 02:17:48.824: INFO: (2) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 12.77798ms)
Oct 25 02:17:48.824: INFO: (2) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 13.684567ms)
Oct 25 02:17:48.825: INFO: (2) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 14.049714ms)
Oct 25 02:17:48.826: INFO: (2) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 15.166348ms)
Oct 25 02:17:48.827: INFO: (2) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 15.743153ms)
Oct 25 02:17:48.827: INFO: (2) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 15.872907ms)
Oct 25 02:17:48.827: INFO: (2) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 16.3325ms)
Oct 25 02:17:48.836: INFO: (2) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 24.766239ms)
Oct 25 02:17:48.836: INFO: (2) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 25.527074ms)
Oct 25 02:17:48.836: INFO: (2) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 25.659838ms)
Oct 25 02:17:48.837: INFO: (2) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 25.706568ms)
Oct 25 02:17:48.837: INFO: (2) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 25.883214ms)
Oct 25 02:17:48.837: INFO: (2) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 25.761866ms)
Oct 25 02:17:48.837: INFO: (2) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 26.549181ms)
Oct 25 02:17:48.854: INFO: (3) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 17.15186ms)
Oct 25 02:17:48.855: INFO: (3) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 17.400113ms)
Oct 25 02:17:48.858: INFO: (3) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 20.556632ms)
Oct 25 02:17:48.858: INFO: (3) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 20.762664ms)
Oct 25 02:17:48.858: INFO: (3) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 20.534585ms)
Oct 25 02:17:48.859: INFO: (3) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 21.697412ms)
Oct 25 02:17:48.860: INFO: (3) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 22.36368ms)
Oct 25 02:17:48.860: INFO: (3) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 22.409336ms)
Oct 25 02:17:48.864: INFO: (3) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 26.523337ms)
Oct 25 02:17:48.865: INFO: (3) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 27.385342ms)
Oct 25 02:17:48.867: INFO: (3) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 29.601242ms)
Oct 25 02:17:48.868: INFO: (3) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 31.02022ms)
Oct 25 02:17:48.869: INFO: (3) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 31.098462ms)
Oct 25 02:17:48.869: INFO: (3) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 31.034875ms)
Oct 25 02:17:48.869: INFO: (3) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 31.438035ms)
Oct 25 02:17:48.869: INFO: (3) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 31.95675ms)
Oct 25 02:17:48.882: INFO: (4) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 12.024977ms)
Oct 25 02:17:48.882: INFO: (4) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 12.328494ms)
Oct 25 02:17:48.883: INFO: (4) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 12.937886ms)
Oct 25 02:17:48.883: INFO: (4) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 13.325822ms)
Oct 25 02:17:48.884: INFO: (4) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 14.207545ms)
Oct 25 02:17:48.884: INFO: (4) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 13.964369ms)
Oct 25 02:17:48.885: INFO: (4) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 15.239146ms)
Oct 25 02:17:48.887: INFO: (4) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 17.334908ms)
Oct 25 02:17:48.887: INFO: (4) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 17.568533ms)
Oct 25 02:17:48.888: INFO: (4) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 18.855464ms)
Oct 25 02:17:48.889: INFO: (4) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 19.567526ms)
Oct 25 02:17:48.889: INFO: (4) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 19.553223ms)
Oct 25 02:17:48.890: INFO: (4) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 20.015873ms)
Oct 25 02:17:48.890: INFO: (4) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 20.350175ms)
Oct 25 02:17:48.890: INFO: (4) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 20.234369ms)
Oct 25 02:17:48.892: INFO: (4) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 22.924417ms)
Oct 25 02:17:48.904: INFO: (5) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 11.673181ms)
Oct 25 02:17:48.906: INFO: (5) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 13.064574ms)
Oct 25 02:17:48.909: INFO: (5) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 16.16349ms)
Oct 25 02:17:48.910: INFO: (5) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 16.642182ms)
Oct 25 02:17:48.910: INFO: (5) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 16.924062ms)
Oct 25 02:17:48.910: INFO: (5) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 17.57782ms)
Oct 25 02:17:48.911: INFO: (5) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 17.513989ms)
Oct 25 02:17:48.911: INFO: (5) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 17.319892ms)
Oct 25 02:17:48.913: INFO: (5) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 19.627035ms)
Oct 25 02:17:48.913: INFO: (5) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 19.546177ms)
Oct 25 02:17:48.914: INFO: (5) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 21.003513ms)
Oct 25 02:17:48.915: INFO: (5) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 22.331204ms)
Oct 25 02:17:48.915: INFO: (5) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 22.03804ms)
Oct 25 02:17:48.915: INFO: (5) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 22.672579ms)
Oct 25 02:17:48.916: INFO: (5) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 22.991107ms)
Oct 25 02:17:48.917: INFO: (5) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 23.402315ms)
Oct 25 02:17:48.925: INFO: (6) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 7.825687ms)
Oct 25 02:17:48.927: INFO: (6) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 9.714834ms)
Oct 25 02:17:48.928: INFO: (6) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 11.238961ms)
Oct 25 02:17:48.929: INFO: (6) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 12.090869ms)
Oct 25 02:17:48.929: INFO: (6) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 12.341965ms)
Oct 25 02:17:48.930: INFO: (6) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 13.205049ms)
Oct 25 02:17:48.933: INFO: (6) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 15.966239ms)
Oct 25 02:17:48.934: INFO: (6) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 16.887511ms)
Oct 25 02:17:48.934: INFO: (6) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 16.797044ms)
Oct 25 02:17:48.934: INFO: (6) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 17.247729ms)
Oct 25 02:17:48.935: INFO: (6) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 17.814075ms)
Oct 25 02:17:48.935: INFO: (6) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 18.270912ms)
Oct 25 02:17:48.936: INFO: (6) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 18.59793ms)
Oct 25 02:17:48.936: INFO: (6) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 19.342625ms)
Oct 25 02:17:48.937: INFO: (6) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 19.975063ms)
Oct 25 02:17:48.938: INFO: (6) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 20.698969ms)
Oct 25 02:17:48.947: INFO: (7) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 9.462003ms)
Oct 25 02:17:48.950: INFO: (7) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 11.930648ms)
Oct 25 02:17:48.950: INFO: (7) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 12.249155ms)
Oct 25 02:17:48.954: INFO: (7) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 15.695015ms)
Oct 25 02:17:48.954: INFO: (7) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 15.593218ms)
Oct 25 02:17:48.954: INFO: (7) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 15.882397ms)
Oct 25 02:17:48.954: INFO: (7) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 15.923867ms)
Oct 25 02:17:48.956: INFO: (7) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 17.640981ms)
Oct 25 02:17:48.956: INFO: (7) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 17.78092ms)
Oct 25 02:17:48.956: INFO: (7) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 18.266333ms)
Oct 25 02:17:48.956: INFO: (7) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 18.413815ms)
Oct 25 02:17:48.958: INFO: (7) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 19.177191ms)
Oct 25 02:17:48.958: INFO: (7) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 20.056074ms)
Oct 25 02:17:48.959: INFO: (7) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 20.986522ms)
Oct 25 02:17:48.960: INFO: (7) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 22.177732ms)
Oct 25 02:17:48.961: INFO: (7) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 23.521486ms)
Oct 25 02:17:48.972: INFO: (8) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 10.853429ms)
Oct 25 02:17:48.973: INFO: (8) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 11.040833ms)
Oct 25 02:17:48.975: INFO: (8) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 13.135866ms)
Oct 25 02:17:48.975: INFO: (8) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 13.582401ms)
Oct 25 02:17:48.976: INFO: (8) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 14.153793ms)
Oct 25 02:17:48.976: INFO: (8) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 14.308182ms)
Oct 25 02:17:48.976: INFO: (8) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 14.529836ms)
Oct 25 02:17:48.977: INFO: (8) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 15.092741ms)
Oct 25 02:17:48.979: INFO: (8) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 17.246622ms)
Oct 25 02:17:48.979: INFO: (8) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 17.426181ms)
Oct 25 02:17:48.980: INFO: (8) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 18.280131ms)
Oct 25 02:17:48.981: INFO: (8) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 19.536149ms)
Oct 25 02:17:48.981: INFO: (8) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 19.652583ms)
Oct 25 02:17:48.981: INFO: (8) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 19.757506ms)
Oct 25 02:17:48.983: INFO: (8) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 21.288824ms)
Oct 25 02:17:48.984: INFO: (8) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 22.436118ms)
Oct 25 02:17:48.993: INFO: (9) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 8.388256ms)
Oct 25 02:17:48.994: INFO: (9) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 9.223281ms)
Oct 25 02:17:48.995: INFO: (9) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 10.689229ms)
Oct 25 02:17:48.997: INFO: (9) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 12.479638ms)
Oct 25 02:17:48.998: INFO: (9) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 12.924229ms)
Oct 25 02:17:48.998: INFO: (9) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 13.148063ms)
Oct 25 02:17:48.999: INFO: (9) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 14.716973ms)
Oct 25 02:17:49.001: INFO: (9) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 16.169353ms)
Oct 25 02:17:49.001: INFO: (9) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 16.732718ms)
Oct 25 02:17:49.002: INFO: (9) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 17.417194ms)
Oct 25 02:17:49.007: INFO: (9) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 22.201207ms)
Oct 25 02:17:49.007: INFO: (9) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 22.078681ms)
Oct 25 02:17:49.007: INFO: (9) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 22.468844ms)
Oct 25 02:17:49.007: INFO: (9) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 22.486062ms)
Oct 25 02:17:49.007: INFO: (9) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 22.54063ms)
Oct 25 02:17:49.009: INFO: (9) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 24.259871ms)
Oct 25 02:17:49.019: INFO: (10) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 9.748743ms)
Oct 25 02:17:49.020: INFO: (10) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 10.496843ms)
Oct 25 02:17:49.020: INFO: (10) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 10.922558ms)
Oct 25 02:17:49.020: INFO: (10) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 10.98492ms)
Oct 25 02:17:49.022: INFO: (10) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 12.516981ms)
Oct 25 02:17:49.023: INFO: (10) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 13.967803ms)
Oct 25 02:17:49.023: INFO: (10) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 14.290761ms)
Oct 25 02:17:49.025: INFO: (10) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 15.398416ms)
Oct 25 02:17:49.025: INFO: (10) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 15.483343ms)
Oct 25 02:17:49.026: INFO: (10) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 16.786995ms)
Oct 25 02:17:49.026: INFO: (10) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 16.898392ms)
Oct 25 02:17:49.027: INFO: (10) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 17.042766ms)
Oct 25 02:17:49.027: INFO: (10) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 17.167879ms)
Oct 25 02:17:49.029: INFO: (10) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 19.74293ms)
Oct 25 02:17:49.029: INFO: (10) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 19.6582ms)
Oct 25 02:17:49.031: INFO: (10) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 21.732393ms)
Oct 25 02:17:49.043: INFO: (11) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 11.37781ms)
Oct 25 02:17:49.049: INFO: (11) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 17.327418ms)
Oct 25 02:17:49.049: INFO: (11) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 17.332586ms)
Oct 25 02:17:49.049: INFO: (11) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 17.393235ms)
Oct 25 02:17:49.049: INFO: (11) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 17.815233ms)
Oct 25 02:17:49.050: INFO: (11) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 18.634982ms)
Oct 25 02:17:49.054: INFO: (11) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 21.981059ms)
Oct 25 02:17:49.054: INFO: (11) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 21.999327ms)
Oct 25 02:17:49.054: INFO: (11) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 22.676462ms)
Oct 25 02:17:49.054: INFO: (11) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 22.040927ms)
Oct 25 02:17:49.054: INFO: (11) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 22.105843ms)
Oct 25 02:17:49.054: INFO: (11) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 22.702014ms)
Oct 25 02:17:49.054: INFO: (11) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 22.235632ms)
Oct 25 02:17:49.054: INFO: (11) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 22.203369ms)
Oct 25 02:17:49.056: INFO: (11) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 23.392814ms)
Oct 25 02:17:49.056: INFO: (11) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 23.825105ms)
Oct 25 02:17:49.069: INFO: (12) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 13.689127ms)
Oct 25 02:17:49.079: INFO: (12) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 23.269142ms)
Oct 25 02:17:49.079: INFO: (12) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 23.546827ms)
Oct 25 02:17:49.079: INFO: (12) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 23.548707ms)
Oct 25 02:17:49.080: INFO: (12) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 24.045125ms)
Oct 25 02:17:49.080: INFO: (12) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 23.644258ms)
Oct 25 02:17:49.080: INFO: (12) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 23.477224ms)
Oct 25 02:17:49.080: INFO: (12) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 24.273088ms)
Oct 25 02:17:49.080: INFO: (12) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 24.29592ms)
Oct 25 02:17:49.081: INFO: (12) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 24.687299ms)
Oct 25 02:17:49.081: INFO: (12) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 24.525744ms)
Oct 25 02:17:49.089: INFO: (12) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 32.846659ms)
Oct 25 02:17:49.089: INFO: (12) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 33.115723ms)
Oct 25 02:17:49.090: INFO: (12) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 33.556899ms)
Oct 25 02:17:49.091: INFO: (12) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 34.67053ms)
Oct 25 02:17:49.092: INFO: (12) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 35.596028ms)
Oct 25 02:17:49.106: INFO: (13) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 13.833902ms)
Oct 25 02:17:49.109: INFO: (13) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 16.39583ms)
Oct 25 02:17:49.109: INFO: (13) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 16.695658ms)
Oct 25 02:17:49.110: INFO: (13) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 17.763667ms)
Oct 25 02:17:49.110: INFO: (13) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 17.981339ms)
Oct 25 02:17:49.111: INFO: (13) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 19.116417ms)
Oct 25 02:17:49.112: INFO: (13) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 19.265278ms)
Oct 25 02:17:49.112: INFO: (13) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 20.638286ms)
Oct 25 02:17:49.118: INFO: (13) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 25.267062ms)
Oct 25 02:17:49.118: INFO: (13) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 25.305642ms)
Oct 25 02:17:49.118: INFO: (13) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 25.406642ms)
Oct 25 02:17:49.119: INFO: (13) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 26.834116ms)
Oct 25 02:17:49.119: INFO: (13) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 27.119085ms)
Oct 25 02:17:49.119: INFO: (13) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 27.164297ms)
Oct 25 02:17:49.124: INFO: (13) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 31.720044ms)
Oct 25 02:17:49.124: INFO: (13) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 31.863003ms)
Oct 25 02:17:49.136: INFO: (14) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 11.971314ms)
Oct 25 02:17:49.137: INFO: (14) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 12.511488ms)
Oct 25 02:17:49.138: INFO: (14) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 13.929341ms)
Oct 25 02:17:49.139: INFO: (14) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 14.525956ms)
Oct 25 02:17:49.143: INFO: (14) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 18.122102ms)
Oct 25 02:17:49.143: INFO: (14) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 18.226887ms)
Oct 25 02:17:49.143: INFO: (14) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 18.332216ms)
Oct 25 02:17:49.144: INFO: (14) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 20.074555ms)
Oct 25 02:17:49.145: INFO: (14) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 20.227613ms)
Oct 25 02:17:49.145: INFO: (14) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 20.563317ms)
Oct 25 02:17:49.146: INFO: (14) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 21.91813ms)
Oct 25 02:17:49.146: INFO: (14) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 21.799444ms)
Oct 25 02:17:49.147: INFO: (14) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 22.858025ms)
Oct 25 02:17:49.148: INFO: (14) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 23.321303ms)
Oct 25 02:17:49.149: INFO: (14) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 24.707568ms)
Oct 25 02:17:49.150: INFO: (14) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 25.262887ms)
Oct 25 02:17:49.160: INFO: (15) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 10.466287ms)
Oct 25 02:17:49.165: INFO: (15) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 14.961995ms)
Oct 25 02:17:49.165: INFO: (15) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 15.087977ms)
Oct 25 02:17:49.165: INFO: (15) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 15.221424ms)
Oct 25 02:17:49.165: INFO: (15) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 15.257886ms)
Oct 25 02:17:49.167: INFO: (15) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 16.795456ms)
Oct 25 02:17:49.167: INFO: (15) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 16.790696ms)
Oct 25 02:17:49.167: INFO: (15) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 17.623796ms)
Oct 25 02:17:49.168: INFO: (15) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 17.761279ms)
Oct 25 02:17:49.168: INFO: (15) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 17.983038ms)
Oct 25 02:17:49.168: INFO: (15) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 18.247589ms)
Oct 25 02:17:49.168: INFO: (15) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 18.486028ms)
Oct 25 02:17:49.169: INFO: (15) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 18.99781ms)
Oct 25 02:17:49.169: INFO: (15) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 18.834542ms)
Oct 25 02:17:49.169: INFO: (15) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 19.005367ms)
Oct 25 02:17:49.170: INFO: (15) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 19.870725ms)
Oct 25 02:17:49.183: INFO: (16) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 13.260941ms)
Oct 25 02:17:49.183: INFO: (16) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 13.44744ms)
Oct 25 02:17:49.184: INFO: (16) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 13.650641ms)
Oct 25 02:17:49.184: INFO: (16) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 13.684736ms)
Oct 25 02:17:49.185: INFO: (16) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 15.179677ms)
Oct 25 02:17:49.188: INFO: (16) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 17.795377ms)
Oct 25 02:17:49.188: INFO: (16) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 17.632ms)
Oct 25 02:17:49.190: INFO: (16) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 19.594847ms)
Oct 25 02:17:49.190: INFO: (16) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 20.097696ms)
Oct 25 02:17:49.190: INFO: (16) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 20.019411ms)
Oct 25 02:17:49.191: INFO: (16) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 21.138387ms)
Oct 25 02:17:49.192: INFO: (16) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 21.33018ms)
Oct 25 02:17:49.192: INFO: (16) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 21.297384ms)
Oct 25 02:17:49.194: INFO: (16) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 23.728027ms)
Oct 25 02:17:49.195: INFO: (16) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 24.788873ms)
Oct 25 02:17:49.197: INFO: (16) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 27.01022ms)
Oct 25 02:17:49.207: INFO: (17) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 9.889015ms)
Oct 25 02:17:49.210: INFO: (17) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 11.956895ms)
Oct 25 02:17:49.210: INFO: (17) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 12.768301ms)
Oct 25 02:17:49.211: INFO: (17) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 13.665907ms)
Oct 25 02:17:49.213: INFO: (17) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 15.067353ms)
Oct 25 02:17:49.213: INFO: (17) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 15.107122ms)
Oct 25 02:17:49.213: INFO: (17) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 15.344642ms)
Oct 25 02:17:49.213: INFO: (17) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 15.660572ms)
Oct 25 02:17:49.215: INFO: (17) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 17.253308ms)
Oct 25 02:17:49.215: INFO: (17) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 17.200391ms)
Oct 25 02:17:49.216: INFO: (17) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 17.967614ms)
Oct 25 02:17:49.219: INFO: (17) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 21.268129ms)
Oct 25 02:17:49.219: INFO: (17) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 21.79925ms)
Oct 25 02:17:49.223: INFO: (17) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 25.440484ms)
Oct 25 02:17:49.227: INFO: (17) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 29.287105ms)
Oct 25 02:17:49.227: INFO: (17) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 29.273635ms)
Oct 25 02:17:49.239: INFO: (18) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 11.603607ms)
Oct 25 02:17:49.242: INFO: (18) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 14.527366ms)
Oct 25 02:17:49.242: INFO: (18) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 15.072782ms)
Oct 25 02:17:49.242: INFO: (18) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 14.787841ms)
Oct 25 02:17:49.242: INFO: (18) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 14.902743ms)
Oct 25 02:17:49.245: INFO: (18) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 17.323245ms)
Oct 25 02:17:49.247: INFO: (18) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 19.578298ms)
Oct 25 02:17:49.248: INFO: (18) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 20.928154ms)
Oct 25 02:17:49.249: INFO: (18) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 21.568299ms)
Oct 25 02:17:49.249: INFO: (18) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 22.029282ms)
Oct 25 02:17:49.251: INFO: (18) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 23.991903ms)
Oct 25 02:17:49.251: INFO: (18) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 23.846816ms)
Oct 25 02:17:49.252: INFO: (18) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 24.435564ms)
Oct 25 02:17:49.253: INFO: (18) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 25.707235ms)
Oct 25 02:17:49.253: INFO: (18) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 25.783153ms)
Oct 25 02:17:49.253: INFO: (18) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 25.943479ms)
Oct 25 02:17:49.265: INFO: (19) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">... (200; 11.649115ms)
Oct 25 02:17:49.265: INFO: (19) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 11.845481ms)
Oct 25 02:17:49.266: INFO: (19) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr/proxy/rewriteme">test</a> (200; 12.755996ms)
Oct 25 02:17:49.267: INFO: (19) /api/v1/namespaces/proxy-8528/pods/http:proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 13.527629ms)
Oct 25 02:17:49.268: INFO: (19) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:162/proxy/: bar (200; 14.811659ms)
Oct 25 02:17:49.269: INFO: (19) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:443/proxy/tlsrewritem... (200; 15.379868ms)
Oct 25 02:17:49.269: INFO: (19) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/: <a href="/api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:1080/proxy/rewriteme">test<... (200; 15.565109ms)
Oct 25 02:17:49.270: INFO: (19) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname1/proxy/: tls baz (200; 16.260988ms)
Oct 25 02:17:49.270: INFO: (19) /api/v1/namespaces/proxy-8528/services/https:proxy-service-9zpgd:tlsportname2/proxy/: tls qux (200; 17.066401ms)
Oct 25 02:17:49.274: INFO: (19) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname2/proxy/: bar (200; 20.121363ms)
Oct 25 02:17:49.276: INFO: (19) /api/v1/namespaces/proxy-8528/pods/proxy-service-9zpgd-8mkwr:160/proxy/: foo (200; 22.463601ms)
Oct 25 02:17:49.276: INFO: (19) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:460/proxy/: tls baz (200; 22.773858ms)
Oct 25 02:17:49.279: INFO: (19) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname2/proxy/: bar (200; 25.834718ms)
Oct 25 02:17:49.286: INFO: (19) /api/v1/namespaces/proxy-8528/pods/https:proxy-service-9zpgd-8mkwr:462/proxy/: tls qux (200; 32.286189ms)
Oct 25 02:17:49.286: INFO: (19) /api/v1/namespaces/proxy-8528/services/http:proxy-service-9zpgd:portname1/proxy/: foo (200; 32.619929ms)
Oct 25 02:17:49.287: INFO: (19) /api/v1/namespaces/proxy-8528/services/proxy-service-9zpgd:portname1/proxy/: foo (200; 33.737532ms)
STEP: deleting ReplicationController proxy-service-9zpgd in namespace proxy-8528, will wait for the garbage collector to delete the pods
Oct 25 02:17:49.361: INFO: Deleting ReplicationController proxy-service-9zpgd took: 16.919294ms
Oct 25 02:17:49.463: INFO: Terminating ReplicationController proxy-service-9zpgd pods took: 101.320939ms
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Oct 25 02:17:50.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8528" for this suite.

• [SLOW TEST:5.279 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":356,"completed":139,"skipped":2576,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:17:50.897: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-map-d6abcadb-3c43-4e4d-8552-ed6712d3cb15
STEP: Creating a pod to test consume secrets
Oct 25 02:17:50.964: INFO: Waiting up to 5m0s for pod "pod-secrets-009ad575-c935-447d-aa27-4cc666c43ef3" in namespace "secrets-3079" to be "Succeeded or Failed"
Oct 25 02:17:50.975: INFO: Pod "pod-secrets-009ad575-c935-447d-aa27-4cc666c43ef3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.940576ms
Oct 25 02:17:52.983: INFO: Pod "pod-secrets-009ad575-c935-447d-aa27-4cc666c43ef3": Phase="Running", Reason="", readiness=false. Elapsed: 2.019369114s
Oct 25 02:17:54.995: INFO: Pod "pod-secrets-009ad575-c935-447d-aa27-4cc666c43ef3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031562713s
STEP: Saw pod success
Oct 25 02:17:54.995: INFO: Pod "pod-secrets-009ad575-c935-447d-aa27-4cc666c43ef3" satisfied condition "Succeeded or Failed"
Oct 25 02:17:55.003: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-secrets-009ad575-c935-447d-aa27-4cc666c43ef3 container secret-volume-test: <nil>
STEP: delete the pod
Oct 25 02:17:55.045: INFO: Waiting for pod pod-secrets-009ad575-c935-447d-aa27-4cc666c43ef3 to disappear
Oct 25 02:17:55.051: INFO: Pod pod-secrets-009ad575-c935-447d-aa27-4cc666c43ef3 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Oct 25 02:17:55.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3079" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":140,"skipped":2626,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:17:55.081: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-9b3ea64c-8883-41b6-9f00-32bbb857b92f
STEP: Creating a pod to test consume configMaps
Oct 25 02:17:55.156: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ec97f343-4a41-4384-9a74-63f9ab35acff" in namespace "projected-6346" to be "Succeeded or Failed"
Oct 25 02:17:55.163: INFO: Pod "pod-projected-configmaps-ec97f343-4a41-4384-9a74-63f9ab35acff": Phase="Pending", Reason="", readiness=false. Elapsed: 7.404338ms
Oct 25 02:17:57.172: INFO: Pod "pod-projected-configmaps-ec97f343-4a41-4384-9a74-63f9ab35acff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016627939s
Oct 25 02:17:59.186: INFO: Pod "pod-projected-configmaps-ec97f343-4a41-4384-9a74-63f9ab35acff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030728523s
STEP: Saw pod success
Oct 25 02:17:59.186: INFO: Pod "pod-projected-configmaps-ec97f343-4a41-4384-9a74-63f9ab35acff" satisfied condition "Succeeded or Failed"
Oct 25 02:17:59.193: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-projected-configmaps-ec97f343-4a41-4384-9a74-63f9ab35acff container agnhost-container: <nil>
STEP: delete the pod
Oct 25 02:17:59.233: INFO: Waiting for pod pod-projected-configmaps-ec97f343-4a41-4384-9a74-63f9ab35acff to disappear
Oct 25 02:17:59.242: INFO: Pod pod-projected-configmaps-ec97f343-4a41-4384-9a74-63f9ab35acff no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Oct 25 02:17:59.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6346" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":141,"skipped":2697,"failed":0}

------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints 
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:17:59.271: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Oct 25 02:17:59.339: INFO: Waiting up to 1m0s for all nodes to be ready
Oct 25 02:18:59.409: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:18:59.417: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:18:59.491: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: Value: Forbidden: may not be changed in an update.
Oct 25 02:18:59.499: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: Value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:188
Oct 25 02:18:59.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-6742" for this suite.
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:18:59.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-1712" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:60.490 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","total":356,"completed":142,"skipped":2697,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run 
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:18:59.761: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Oct 25 02:18:59.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-5934 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Oct 25 02:18:59.884: INFO: stderr: ""
Oct 25 02:18:59.884: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run
Oct 25 02:18:59.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-5934 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "k8s.gcr.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Oct 25 02:19:00.076: INFO: stderr: ""
Oct 25 02:19:00.076: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Oct 25 02:19:00.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-5934 delete pods e2e-test-httpd-pod'
Oct 25 02:19:01.955: INFO: stderr: ""
Oct 25 02:19:01.955: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 02:19:01.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5934" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","total":356,"completed":143,"skipped":2717,"failed":0}
SSS
------------------------------
[sig-node] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:19:01.984: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
Oct 25 02:19:02.056: INFO: The status of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:19:04.067: INFO: The status of Pod test-pod is Running (Ready = true)
STEP: Creating hostNetwork=true pod
Oct 25 02:19:04.096: INFO: The status of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:19:06.115: INFO: The status of Pod test-host-network-pod is Running (Ready = true)
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct 25 02:19:06.121: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6439 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:19:06.121: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:19:06.122: INFO: ExecWithOptions: Clientset creation
Oct 25 02:19:06.122: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6439/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Oct 25 02:19:06.203: INFO: Exec stderr: ""
Oct 25 02:19:06.203: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6439 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:19:06.203: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:19:06.204: INFO: ExecWithOptions: Clientset creation
Oct 25 02:19:06.204: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6439/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Oct 25 02:19:06.287: INFO: Exec stderr: ""
Oct 25 02:19:06.287: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6439 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:19:06.287: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:19:06.287: INFO: ExecWithOptions: Clientset creation
Oct 25 02:19:06.287: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6439/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Oct 25 02:19:06.361: INFO: Exec stderr: ""
Oct 25 02:19:06.361: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6439 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:19:06.361: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:19:06.362: INFO: ExecWithOptions: Clientset creation
Oct 25 02:19:06.362: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6439/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Oct 25 02:19:06.433: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct 25 02:19:06.433: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6439 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:19:06.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:19:06.434: INFO: ExecWithOptions: Clientset creation
Oct 25 02:19:06.434: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6439/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Oct 25 02:19:06.510: INFO: Exec stderr: ""
Oct 25 02:19:06.510: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6439 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:19:06.510: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:19:06.510: INFO: ExecWithOptions: Clientset creation
Oct 25 02:19:06.510: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6439/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Oct 25 02:19:06.574: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct 25 02:19:06.574: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6439 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:19:06.574: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:19:06.575: INFO: ExecWithOptions: Clientset creation
Oct 25 02:19:06.575: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6439/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Oct 25 02:19:06.655: INFO: Exec stderr: ""
Oct 25 02:19:06.655: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6439 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:19:06.655: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:19:06.656: INFO: ExecWithOptions: Clientset creation
Oct 25 02:19:06.656: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6439/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Oct 25 02:19:06.722: INFO: Exec stderr: ""
Oct 25 02:19:06.722: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6439 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:19:06.722: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:19:06.722: INFO: ExecWithOptions: Clientset creation
Oct 25 02:19:06.722: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6439/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Oct 25 02:19:06.809: INFO: Exec stderr: ""
Oct 25 02:19:06.809: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6439 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:19:06.809: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:19:06.809: INFO: ExecWithOptions: Clientset creation
Oct 25 02:19:06.809: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6439/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Oct 25 02:19:06.884: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:188
Oct 25 02:19:06.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6439" for this suite.
•{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":144,"skipped":2720,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:19:06.910: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating Pod
STEP: Reading file content from the nginx-container
Oct 25 02:19:08.994: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-935 PodName:pod-sharedvolume-ddfcd360-3a72-45c8-a364-231e10b2c3bb ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:19:08.995: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:19:08.995: INFO: ExecWithOptions: Clientset creation
Oct 25 02:19:08.995: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/emptydir-935/pods/pod-sharedvolume-ddfcd360-3a72-45c8-a364-231e10b2c3bb/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Oct 25 02:19:09.074: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 02:19:09.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-935" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":356,"completed":145,"skipped":2744,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:19:09.102: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:19:09.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6646" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":356,"completed":146,"skipped":2755,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:19:09.180: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-8369264c-43a9-474e-9bb8-183470ef8684
STEP: Creating a pod to test consume configMaps
Oct 25 02:19:09.245: INFO: Waiting up to 5m0s for pod "pod-configmaps-355243cd-66c2-4162-90b4-f9d86d11b7e3" in namespace "configmap-3403" to be "Succeeded or Failed"
Oct 25 02:19:09.257: INFO: Pod "pod-configmaps-355243cd-66c2-4162-90b4-f9d86d11b7e3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.350552ms
Oct 25 02:19:11.270: INFO: Pod "pod-configmaps-355243cd-66c2-4162-90b4-f9d86d11b7e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024758861s
Oct 25 02:19:13.278: INFO: Pod "pod-configmaps-355243cd-66c2-4162-90b4-f9d86d11b7e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032615194s
STEP: Saw pod success
Oct 25 02:19:13.278: INFO: Pod "pod-configmaps-355243cd-66c2-4162-90b4-f9d86d11b7e3" satisfied condition "Succeeded or Failed"
Oct 25 02:19:13.285: INFO: Trying to get logs from node lab1-k8s-node-2 pod pod-configmaps-355243cd-66c2-4162-90b4-f9d86d11b7e3 container agnhost-container: <nil>
STEP: delete the pod
Oct 25 02:19:13.330: INFO: Waiting for pod pod-configmaps-355243cd-66c2-4162-90b4-f9d86d11b7e3 to disappear
Oct 25 02:19:13.335: INFO: Pod pod-configmaps-355243cd-66c2-4162-90b4-f9d86d11b7e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 02:19:13.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3403" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":356,"completed":147,"skipped":2775,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:19:13.364: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct 25 02:19:13.425: INFO: Waiting up to 5m0s for pod "pod-8063e0b6-4b1f-425b-bb06-ab22b914a035" in namespace "emptydir-6296" to be "Succeeded or Failed"
Oct 25 02:19:13.435: INFO: Pod "pod-8063e0b6-4b1f-425b-bb06-ab22b914a035": Phase="Pending", Reason="", readiness=false. Elapsed: 9.48962ms
Oct 25 02:19:15.448: INFO: Pod "pod-8063e0b6-4b1f-425b-bb06-ab22b914a035": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022403899s
Oct 25 02:19:17.456: INFO: Pod "pod-8063e0b6-4b1f-425b-bb06-ab22b914a035": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030876525s
STEP: Saw pod success
Oct 25 02:19:17.457: INFO: Pod "pod-8063e0b6-4b1f-425b-bb06-ab22b914a035" satisfied condition "Succeeded or Failed"
Oct 25 02:19:17.462: INFO: Trying to get logs from node lab1-k8s-node-2 pod pod-8063e0b6-4b1f-425b-bb06-ab22b914a035 container test-container: <nil>
STEP: delete the pod
Oct 25 02:19:17.506: INFO: Waiting for pod pod-8063e0b6-4b1f-425b-bb06-ab22b914a035 to disappear
Oct 25 02:19:17.511: INFO: Pod pod-8063e0b6-4b1f-425b-bb06-ab22b914a035 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 02:19:17.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6296" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":148,"skipped":2826,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:19:17.536: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a Pod with a 'name' label pod-adoption-release is created
Oct 25 02:19:17.608: INFO: The status of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:19:19.620: INFO: The status of Pod pod-adoption-release is Running (Ready = true)
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct 25 02:19:20.665: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Oct 25 02:19:21.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3191" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":356,"completed":149,"skipped":2836,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:19:21.741: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-map-462e6157-47a7-485b-a2e1-978930f21cbe
STEP: Creating a pod to test consume secrets
Oct 25 02:19:21.812: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-649139af-2a49-4c42-9424-e8428c33f2d0" in namespace "projected-6006" to be "Succeeded or Failed"
Oct 25 02:19:21.823: INFO: Pod "pod-projected-secrets-649139af-2a49-4c42-9424-e8428c33f2d0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.530334ms
Oct 25 02:19:23.841: INFO: Pod "pod-projected-secrets-649139af-2a49-4c42-9424-e8428c33f2d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028554928s
Oct 25 02:19:25.854: INFO: Pod "pod-projected-secrets-649139af-2a49-4c42-9424-e8428c33f2d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041420114s
STEP: Saw pod success
Oct 25 02:19:25.854: INFO: Pod "pod-projected-secrets-649139af-2a49-4c42-9424-e8428c33f2d0" satisfied condition "Succeeded or Failed"
Oct 25 02:19:25.861: INFO: Trying to get logs from node lab1-k8s-node-2 pod pod-projected-secrets-649139af-2a49-4c42-9424-e8428c33f2d0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 25 02:19:25.896: INFO: Waiting for pod pod-projected-secrets-649139af-2a49-4c42-9424-e8428c33f2d0 to disappear
Oct 25 02:19:25.903: INFO: Pod pod-projected-secrets-649139af-2a49-4c42-9424-e8428c33f2d0 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Oct 25 02:19:25.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6006" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":150,"skipped":2876,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:19:25.926: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-1240
STEP: creating service affinity-nodeport-transition in namespace services-1240
STEP: creating replication controller affinity-nodeport-transition in namespace services-1240
I1025 02:19:26.034614      18 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-1240, replica count: 3
I1025 02:19:29.085252      18 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 25 02:19:29.118: INFO: Creating new exec pod
Oct 25 02:19:32.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-1240 exec execpod-affinityn2vn4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Oct 25 02:19:32.327: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Oct 25 02:19:32.327: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 02:19:32.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-1240 exec execpod-affinityn2vn4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.48.113 80'
Oct 25 02:19:32.498: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.48.113 80\nConnection to 10.233.48.113 80 port [tcp/http] succeeded!\n"
Oct 25 02:19:32.498: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 02:19:32.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-1240 exec execpod-affinityn2vn4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.1.121 31735'
Oct 25 02:19:32.648: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.128.1.121 31735\nConnection to 10.128.1.121 31735 port [tcp/*] succeeded!\n"
Oct 25 02:19:32.648: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 02:19:32.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-1240 exec execpod-affinityn2vn4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.2.74 31735'
Oct 25 02:19:32.780: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.128.2.74 31735\nConnection to 10.128.2.74 31735 port [tcp/*] succeeded!\n"
Oct 25 02:19:32.780: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 02:19:32.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-1240 exec execpod-affinityn2vn4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.128.0.176:31735/ ; done'
Oct 25 02:19:33.074: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n"
Oct 25 02:19:33.074: INFO: stdout: "\naffinity-nodeport-transition-gdvm7\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-8c6tb\naffinity-nodeport-transition-gdvm7\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-8c6tb\naffinity-nodeport-transition-gdvm7\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-8c6tb\naffinity-nodeport-transition-gdvm7\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-8c6tb\naffinity-nodeport-transition-gdvm7\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-8c6tb\naffinity-nodeport-transition-gdvm7"
Oct 25 02:19:33.074: INFO: Received response from host: affinity-nodeport-transition-gdvm7
Oct 25 02:19:33.074: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.074: INFO: Received response from host: affinity-nodeport-transition-8c6tb
Oct 25 02:19:33.074: INFO: Received response from host: affinity-nodeport-transition-gdvm7
Oct 25 02:19:33.074: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.074: INFO: Received response from host: affinity-nodeport-transition-8c6tb
Oct 25 02:19:33.074: INFO: Received response from host: affinity-nodeport-transition-gdvm7
Oct 25 02:19:33.074: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.074: INFO: Received response from host: affinity-nodeport-transition-8c6tb
Oct 25 02:19:33.074: INFO: Received response from host: affinity-nodeport-transition-gdvm7
Oct 25 02:19:33.074: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.074: INFO: Received response from host: affinity-nodeport-transition-8c6tb
Oct 25 02:19:33.074: INFO: Received response from host: affinity-nodeport-transition-gdvm7
Oct 25 02:19:33.074: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.075: INFO: Received response from host: affinity-nodeport-transition-8c6tb
Oct 25 02:19:33.075: INFO: Received response from host: affinity-nodeport-transition-gdvm7
Oct 25 02:19:33.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-1240 exec execpod-affinityn2vn4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.128.0.176:31735/ ; done'
Oct 25 02:19:33.369: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31735/\n"
Oct 25 02:19:33.369: INFO: stdout: "\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp\naffinity-nodeport-transition-g8cgp"
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Received response from host: affinity-nodeport-transition-g8cgp
Oct 25 02:19:33.369: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-1240, will wait for the garbage collector to delete the pods
Oct 25 02:19:33.466: INFO: Deleting ReplicationController affinity-nodeport-transition took: 15.452795ms
Oct 25 02:19:33.567: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 101.056361ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 02:19:35.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1240" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:10.022 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":151,"skipped":2892,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:19:35.948: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:19:35.983: INFO: Creating deployment "test-recreate-deployment"
Oct 25 02:19:35.993: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct 25 02:19:36.012: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Oct 25 02:19:38.029: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct 25 02:19:38.037: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct 25 02:19:38.054: INFO: Updating deployment test-recreate-deployment
Oct 25 02:19:38.054: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 25 02:19:38.183: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-8355  7c3051a9-1742-4a19-8845-4a5dc1616e8e 223394 2 2022-10-25 02:19:35 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-10-25 02:19:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 02:19:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003d1db98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-10-25 02:19:38 +0000 UTC,LastTransitionTime:2022-10-25 02:19:38 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-cd8586fc7" is progressing.,LastUpdateTime:2022-10-25 02:19:38 +0000 UTC,LastTransitionTime:2022-10-25 02:19:36 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Oct 25 02:19:38.191: INFO: New ReplicaSet "test-recreate-deployment-cd8586fc7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-cd8586fc7  deployment-8355  ca27388b-e051-461b-a87c-d33efe63f658 223392 1 2022-10-25 02:19:38 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 7c3051a9-1742-4a19-8845-4a5dc1616e8e 0xc002949e20 0xc002949e21}] []  [{kube-controller-manager Update apps/v1 2022-10-25 02:19:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c3051a9-1742-4a19-8845-4a5dc1616e8e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 02:19:38 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: cd8586fc7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002949eb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 25 02:19:38.191: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct 25 02:19:38.191: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-845d658455  deployment-8355  c0f88c92-3847-4ea1-b18c-8f6dc7b449fb 223384 2 2022-10-25 02:19:35 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:845d658455] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 7c3051a9-1742-4a19-8845-4a5dc1616e8e 0xc002949c67 0xc002949c68}] []  [{kube-controller-manager Update apps/v1 2022-10-25 02:19:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c3051a9-1742-4a19-8845-4a5dc1616e8e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 02:19:38 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 845d658455,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:845d658455] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002949db8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 25 02:19:38.199: INFO: Pod "test-recreate-deployment-cd8586fc7-29f52" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-cd8586fc7-29f52 test-recreate-deployment-cd8586fc7- deployment-8355  d041c218-3b21-4ad9-bdb3-a1b5ca9aeb2a 223396 0 2022-10-25 02:19:38 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[] [{apps/v1 ReplicaSet test-recreate-deployment-cd8586fc7 ca27388b-e051-461b-a87c-d33efe63f658 0xc003456c00 0xc003456c01}] []  [{kube-controller-manager Update v1 2022-10-25 02:19:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ca27388b-e051-461b-a87c-d33efe63f658\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 02:19:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ltrbm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ltrbm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:19:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:19:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:19:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:19:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.178,PodIP:,StartTime:2022-10-25 02:19:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Oct 25 02:19:38.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8355" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":356,"completed":152,"skipped":2900,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:19:38.226: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 25 02:19:46.337: INFO: DNS probes using dns-4070/dns-test-b8b375c9-115c-483d-b366-a5b3da61f4b2 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Oct 25 02:19:46.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4070" for this suite.

• [SLOW TEST:8.165 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":356,"completed":153,"skipped":2922,"failed":0}
[sig-node] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:19:46.392: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name secret-emptykey-test-259317e3-2077-49e2-afb5-5485373ec598
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Oct 25 02:19:46.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6502" for this suite.
•{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","total":356,"completed":154,"skipped":2922,"failed":0}

------------------------------
[sig-node] Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:19:46.462: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Oct 25 02:19:48.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-956" for this suite.
•{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":356,"completed":155,"skipped":2922,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:19:48.618: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Oct 25 02:19:48.684: INFO: Waiting up to 1m0s for all nodes to be ready
Oct 25 02:20:48.747: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create pods that use 4/5 of node resources.
Oct 25 02:20:48.804: INFO: Created pod: pod0-0-sched-preemption-low-priority
Oct 25 02:20:48.822: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Oct 25 02:20:48.866: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Oct 25 02:20:48.896: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Oct 25 02:20:48.945: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Oct 25 02:20:48.958: INFO: Created pod: pod2-1-sched-preemption-medium-priority
Oct 25 02:20:48.991: INFO: Created pod: pod3-0-sched-preemption-medium-priority
Oct 25 02:20:49.003: INFO: Created pod: pod3-1-sched-preemption-medium-priority
Oct 25 02:20:49.055: INFO: Created pod: pod4-0-sched-preemption-medium-priority
Oct 25 02:20:49.070: INFO: Created pod: pod4-1-sched-preemption-medium-priority
Oct 25 02:20:49.104: INFO: Created pod: pod5-0-sched-preemption-medium-priority
Oct 25 02:20:49.128: INFO: Created pod: pod5-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a high priority pod that has same requirements as that of lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:21:01.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-6174" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:72.950 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","total":356,"completed":156,"skipped":2934,"failed":0}
[sig-scheduling] SchedulerPreemption [Serial] 
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:21:01.568: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename sched-preemption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Oct 25 02:21:01.647: INFO: Waiting up to 1m0s for all nodes to be ready
Oct 25 02:22:01.727: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create pods that use 4/5 of node resources.
Oct 25 02:22:01.779: INFO: Created pod: pod0-0-sched-preemption-low-priority
Oct 25 02:22:01.800: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Oct 25 02:22:01.857: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Oct 25 02:22:01.872: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Oct 25 02:22:01.913: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Oct 25 02:22:01.923: INFO: Created pod: pod2-1-sched-preemption-medium-priority
Oct 25 02:22:01.983: INFO: Created pod: pod3-0-sched-preemption-medium-priority
Oct 25 02:22:02.034: INFO: Created pod: pod3-1-sched-preemption-medium-priority
Oct 25 02:22:02.077: INFO: Created pod: pod4-0-sched-preemption-medium-priority
Oct 25 02:22:02.097: INFO: Created pod: pod4-1-sched-preemption-medium-priority
Oct 25 02:22:02.132: INFO: Created pod: pod5-0-sched-preemption-medium-priority
Oct 25 02:22:02.175: INFO: Created pod: pod5-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a critical pod that use same resources as that of a lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:22:10.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3031" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:69.138 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","total":356,"completed":157,"skipped":2934,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:22:10.706: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 25 02:22:10.778: INFO: Waiting up to 5m0s for pod "pod-c4426f96-cab4-4362-8aa7-8bda95d2db8b" in namespace "emptydir-9234" to be "Succeeded or Failed"
Oct 25 02:22:10.792: INFO: Pod "pod-c4426f96-cab4-4362-8aa7-8bda95d2db8b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.50028ms
Oct 25 02:22:12.806: INFO: Pod "pod-c4426f96-cab4-4362-8aa7-8bda95d2db8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028342271s
Oct 25 02:22:14.817: INFO: Pod "pod-c4426f96-cab4-4362-8aa7-8bda95d2db8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039857475s
STEP: Saw pod success
Oct 25 02:22:14.818: INFO: Pod "pod-c4426f96-cab4-4362-8aa7-8bda95d2db8b" satisfied condition "Succeeded or Failed"
Oct 25 02:22:14.824: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-c4426f96-cab4-4362-8aa7-8bda95d2db8b container test-container: <nil>
STEP: delete the pod
Oct 25 02:22:14.878: INFO: Waiting for pod pod-c4426f96-cab4-4362-8aa7-8bda95d2db8b to disappear
Oct 25 02:22:14.885: INFO: Pod pod-c4426f96-cab4-4362-8aa7-8bda95d2db8b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 02:22:14.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9234" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":158,"skipped":2943,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:22:14.914: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:22:14.973: INFO: created pod
Oct 25 02:22:14.973: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-874" to be "Succeeded or Failed"
Oct 25 02:22:14.980: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 7.016776ms
Oct 25 02:22:17.003: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030860468s
Oct 25 02:22:19.011: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038361627s
STEP: Saw pod success
Oct 25 02:22:19.011: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Oct 25 02:22:49.012: INFO: polling logs
Oct 25 02:22:49.026: INFO: Pod logs: 
I1025 02:22:15.759553       1 log.go:195] OK: Got token
I1025 02:22:15.759582       1 log.go:195] validating with in-cluster discovery
I1025 02:22:15.760861       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
I1025 02:22:15.760891       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-874:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1666665135, NotBefore:1666664535, IssuedAt:1666664535, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-874", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"2d1bedfa-7ad8-4b99-8c34-c3f054550345"}}}
I1025 02:22:15.794840       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
I1025 02:22:15.803786       1 log.go:195] OK: Validated signature on JWT
I1025 02:22:15.803870       1 log.go:195] OK: Got valid claims from token!
I1025 02:22:15.803887       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-874:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1666665135, NotBefore:1666664535, IssuedAt:1666664535, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-874", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"2d1bedfa-7ad8-4b99-8c34-c3f054550345"}}}

Oct 25 02:22:49.026: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Oct 25 02:22:49.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-874" for this suite.

• [SLOW TEST:34.167 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","total":356,"completed":159,"skipped":2955,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:22:49.083: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 25 02:22:52.188: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Oct 25 02:22:52.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2309" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":160,"skipped":2997,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:22:52.247: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of events
Oct 25 02:22:52.304: INFO: created test-event-1
Oct 25 02:22:52.314: INFO: created test-event-2
Oct 25 02:22:52.322: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace
STEP: delete collection of events
Oct 25 02:22:52.330: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
Oct 25 02:22:52.377: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:188
Oct 25 02:22:52.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8106" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","total":356,"completed":161,"skipped":3010,"failed":0}

------------------------------
[sig-node] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:22:52.410: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-48687dd2-f8ab-4df5-8ccf-3a4f15a997cc in namespace container-probe-2301
Oct 25 02:22:54.483: INFO: Started pod liveness-48687dd2-f8ab-4df5-8ccf-3a4f15a997cc in namespace container-probe-2301
STEP: checking the pod's current state and verifying that restartCount is present
Oct 25 02:22:54.491: INFO: Initial restart count of pod liveness-48687dd2-f8ab-4df5-8ccf-3a4f15a997cc is 0
Oct 25 02:23:14.622: INFO: Restart count of pod container-probe-2301/liveness-48687dd2-f8ab-4df5-8ccf-3a4f15a997cc is now 1 (20.13090365s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Oct 25 02:23:14.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2301" for this suite.

• [SLOW TEST:22.260 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":356,"completed":162,"skipped":3010,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:23:14.674: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name s-test-opt-del-0f07dd73-dd69-41c8-bdca-e950dc45d357
STEP: Creating secret with name s-test-opt-upd-b84af2ef-f53d-4b12-819e-5348fdfb95d8
STEP: Creating the pod
Oct 25 02:23:14.781: INFO: The status of Pod pod-projected-secrets-ff5c67db-802e-45bd-94a6-e5065e204c28 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:23:16.792: INFO: The status of Pod pod-projected-secrets-ff5c67db-802e-45bd-94a6-e5065e204c28 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-0f07dd73-dd69-41c8-bdca-e950dc45d357
STEP: Updating secret s-test-opt-upd-b84af2ef-f53d-4b12-819e-5348fdfb95d8
STEP: Creating secret with name s-test-opt-create-4ce2b183-6013-4551-85af-34c0b0747c7f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Oct 25 02:23:20.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7173" for this suite.

• [SLOW TEST:6.321 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":163,"skipped":3053,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:23:20.995: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:23:21.064: INFO: The status of Pod test-webserver-11f652f6-08a4-4b73-8bdb-3dfb2a2afa32 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:23:23.075: INFO: The status of Pod test-webserver-11f652f6-08a4-4b73-8bdb-3dfb2a2afa32 is Running (Ready = false)
Oct 25 02:23:25.076: INFO: The status of Pod test-webserver-11f652f6-08a4-4b73-8bdb-3dfb2a2afa32 is Running (Ready = false)
Oct 25 02:23:27.074: INFO: The status of Pod test-webserver-11f652f6-08a4-4b73-8bdb-3dfb2a2afa32 is Running (Ready = false)
Oct 25 02:23:29.078: INFO: The status of Pod test-webserver-11f652f6-08a4-4b73-8bdb-3dfb2a2afa32 is Running (Ready = false)
Oct 25 02:23:31.077: INFO: The status of Pod test-webserver-11f652f6-08a4-4b73-8bdb-3dfb2a2afa32 is Running (Ready = false)
Oct 25 02:23:33.082: INFO: The status of Pod test-webserver-11f652f6-08a4-4b73-8bdb-3dfb2a2afa32 is Running (Ready = false)
Oct 25 02:23:35.076: INFO: The status of Pod test-webserver-11f652f6-08a4-4b73-8bdb-3dfb2a2afa32 is Running (Ready = false)
Oct 25 02:23:37.077: INFO: The status of Pod test-webserver-11f652f6-08a4-4b73-8bdb-3dfb2a2afa32 is Running (Ready = false)
Oct 25 02:23:39.075: INFO: The status of Pod test-webserver-11f652f6-08a4-4b73-8bdb-3dfb2a2afa32 is Running (Ready = false)
Oct 25 02:23:41.079: INFO: The status of Pod test-webserver-11f652f6-08a4-4b73-8bdb-3dfb2a2afa32 is Running (Ready = false)
Oct 25 02:23:43.080: INFO: The status of Pod test-webserver-11f652f6-08a4-4b73-8bdb-3dfb2a2afa32 is Running (Ready = true)
Oct 25 02:23:43.086: INFO: Container started at 2022-10-25 02:23:21 +0000 UTC, pod became ready at 2022-10-25 02:23:41 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Oct 25 02:23:43.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2417" for this suite.

• [SLOW TEST:22.122 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":356,"completed":164,"skipped":3068,"failed":0}
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:23:43.117: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 02:23:43.179: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d8ac0a64-2943-43ce-b8d7-c1cb4c279fca" in namespace "downward-api-6059" to be "Succeeded or Failed"
Oct 25 02:23:43.189: INFO: Pod "downwardapi-volume-d8ac0a64-2943-43ce-b8d7-c1cb4c279fca": Phase="Pending", Reason="", readiness=false. Elapsed: 10.302746ms
Oct 25 02:23:45.201: INFO: Pod "downwardapi-volume-d8ac0a64-2943-43ce-b8d7-c1cb4c279fca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022240239s
Oct 25 02:23:47.215: INFO: Pod "downwardapi-volume-d8ac0a64-2943-43ce-b8d7-c1cb4c279fca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035616231s
STEP: Saw pod success
Oct 25 02:23:47.215: INFO: Pod "downwardapi-volume-d8ac0a64-2943-43ce-b8d7-c1cb4c279fca" satisfied condition "Succeeded or Failed"
Oct 25 02:23:47.221: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-d8ac0a64-2943-43ce-b8d7-c1cb4c279fca container client-container: <nil>
STEP: delete the pod
Oct 25 02:23:47.256: INFO: Waiting for pod downwardapi-volume-d8ac0a64-2943-43ce-b8d7-c1cb4c279fca to disappear
Oct 25 02:23:47.263: INFO: Pod downwardapi-volume-d8ac0a64-2943-43ce-b8d7-c1cb4c279fca no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Oct 25 02:23:47.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6059" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":356,"completed":165,"skipped":3071,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:23:47.294: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 02:23:47.769: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 02:23:50.819: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:24:01.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1325" for this suite.
STEP: Destroying namespace "webhook-1325-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:13.854 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":356,"completed":166,"skipped":3071,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:24:01.149: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override command
Oct 25 02:24:01.211: INFO: Waiting up to 5m0s for pod "client-containers-f05ea422-01e1-483a-a9c9-af05d3ee32f0" in namespace "containers-8047" to be "Succeeded or Failed"
Oct 25 02:24:01.221: INFO: Pod "client-containers-f05ea422-01e1-483a-a9c9-af05d3ee32f0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.614061ms
Oct 25 02:24:03.228: INFO: Pod "client-containers-f05ea422-01e1-483a-a9c9-af05d3ee32f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017125647s
Oct 25 02:24:05.239: INFO: Pod "client-containers-f05ea422-01e1-483a-a9c9-af05d3ee32f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028475611s
STEP: Saw pod success
Oct 25 02:24:05.239: INFO: Pod "client-containers-f05ea422-01e1-483a-a9c9-af05d3ee32f0" satisfied condition "Succeeded or Failed"
Oct 25 02:24:05.247: INFO: Trying to get logs from node lab1-k8s-node-3 pod client-containers-f05ea422-01e1-483a-a9c9-af05d3ee32f0 container agnhost-container: <nil>
STEP: delete the pod
Oct 25 02:24:05.286: INFO: Waiting for pod client-containers-f05ea422-01e1-483a-a9c9-af05d3ee32f0 to disappear
Oct 25 02:24:05.292: INFO: Pod client-containers-f05ea422-01e1-483a-a9c9-af05d3ee32f0 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Oct 25 02:24:05.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8047" for this suite.
•{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","total":356,"completed":167,"skipped":3093,"failed":0}
SSSSSS
------------------------------
[sig-apps] Job 
  should apply changes to a job status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:24:05.319: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should apply changes to a job status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensure pods equal to paralellism count is attached to the job
STEP: patching /status
STEP: updating /status
STEP: get /status
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Oct 25 02:24:07.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-825" for this suite.
•{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","total":356,"completed":168,"skipped":3099,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:24:07.544: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Oct 25 02:24:09.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-8666" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","total":356,"completed":169,"skipped":3129,"failed":0}
SSSSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:24:09.730: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod busybox-e291bbfb-1996-4911-af76-a97dbf6214c6 in namespace container-probe-219
Oct 25 02:24:11.813: INFO: Started pod busybox-e291bbfb-1996-4911-af76-a97dbf6214c6 in namespace container-probe-219
STEP: checking the pod's current state and verifying that restartCount is present
Oct 25 02:24:11.821: INFO: Initial restart count of pod busybox-e291bbfb-1996-4911-af76-a97dbf6214c6 is 0
Oct 25 02:25:02.134: INFO: Restart count of pod container-probe-219/busybox-e291bbfb-1996-4911-af76-a97dbf6214c6 is now 1 (50.312659336s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Oct 25 02:25:02.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-219" for this suite.

• [SLOW TEST:52.459 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":356,"completed":170,"skipped":3135,"failed":0}
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:25:02.189: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-88c04c2f-2b03-43d6-9184-bd643d0542dd
STEP: Creating a pod to test consume secrets
Oct 25 02:25:02.284: INFO: Waiting up to 5m0s for pod "pod-secrets-3714623b-4f26-442c-a82c-fd2b2ab77488" in namespace "secrets-304" to be "Succeeded or Failed"
Oct 25 02:25:02.301: INFO: Pod "pod-secrets-3714623b-4f26-442c-a82c-fd2b2ab77488": Phase="Pending", Reason="", readiness=false. Elapsed: 16.143971ms
Oct 25 02:25:04.313: INFO: Pod "pod-secrets-3714623b-4f26-442c-a82c-fd2b2ab77488": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027946156s
Oct 25 02:25:06.326: INFO: Pod "pod-secrets-3714623b-4f26-442c-a82c-fd2b2ab77488": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040860804s
STEP: Saw pod success
Oct 25 02:25:06.326: INFO: Pod "pod-secrets-3714623b-4f26-442c-a82c-fd2b2ab77488" satisfied condition "Succeeded or Failed"
Oct 25 02:25:06.331: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-secrets-3714623b-4f26-442c-a82c-fd2b2ab77488 container secret-volume-test: <nil>
STEP: delete the pod
Oct 25 02:25:06.376: INFO: Waiting for pod pod-secrets-3714623b-4f26-442c-a82c-fd2b2ab77488 to disappear
Oct 25 02:25:06.381: INFO: Pod pod-secrets-3714623b-4f26-442c-a82c-fd2b2ab77488 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Oct 25 02:25:06.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-304" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":171,"skipped":3137,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:25:06.408: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 25 02:25:06.469: INFO: Waiting up to 5m0s for pod "pod-ce87ca08-09a0-4010-95df-e32fdd3961ee" in namespace "emptydir-2736" to be "Succeeded or Failed"
Oct 25 02:25:06.481: INFO: Pod "pod-ce87ca08-09a0-4010-95df-e32fdd3961ee": Phase="Pending", Reason="", readiness=false. Elapsed: 12.281503ms
Oct 25 02:25:08.493: INFO: Pod "pod-ce87ca08-09a0-4010-95df-e32fdd3961ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024158266s
Oct 25 02:25:10.503: INFO: Pod "pod-ce87ca08-09a0-4010-95df-e32fdd3961ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033983458s
STEP: Saw pod success
Oct 25 02:25:10.503: INFO: Pod "pod-ce87ca08-09a0-4010-95df-e32fdd3961ee" satisfied condition "Succeeded or Failed"
Oct 25 02:25:10.510: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-ce87ca08-09a0-4010-95df-e32fdd3961ee container test-container: <nil>
STEP: delete the pod
Oct 25 02:25:10.553: INFO: Waiting for pod pod-ce87ca08-09a0-4010-95df-e32fdd3961ee to disappear
Oct 25 02:25:10.561: INFO: Pod pod-ce87ca08-09a0-4010-95df-e32fdd3961ee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 02:25:10.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2736" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":172,"skipped":3143,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:25:10.588: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-projected-all-test-volume-9c669589-cff9-4037-8d8a-1152bc302281
STEP: Creating secret with name secret-projected-all-test-volume-daf50782-4aa7-4642-ba2b-556a880e268e
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct 25 02:25:10.669: INFO: Waiting up to 5m0s for pod "projected-volume-ae242290-6dfd-4691-8389-b789d7fe0b18" in namespace "projected-4058" to be "Succeeded or Failed"
Oct 25 02:25:10.679: INFO: Pod "projected-volume-ae242290-6dfd-4691-8389-b789d7fe0b18": Phase="Pending", Reason="", readiness=false. Elapsed: 9.824981ms
Oct 25 02:25:12.693: INFO: Pod "projected-volume-ae242290-6dfd-4691-8389-b789d7fe0b18": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023809418s
Oct 25 02:25:14.705: INFO: Pod "projected-volume-ae242290-6dfd-4691-8389-b789d7fe0b18": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035468291s
STEP: Saw pod success
Oct 25 02:25:14.705: INFO: Pod "projected-volume-ae242290-6dfd-4691-8389-b789d7fe0b18" satisfied condition "Succeeded or Failed"
Oct 25 02:25:14.710: INFO: Trying to get logs from node lab1-k8s-node-3 pod projected-volume-ae242290-6dfd-4691-8389-b789d7fe0b18 container projected-all-volume-test: <nil>
STEP: delete the pod
Oct 25 02:25:14.762: INFO: Waiting for pod projected-volume-ae242290-6dfd-4691-8389-b789d7fe0b18 to disappear
Oct 25 02:25:14.767: INFO: Pod projected-volume-ae242290-6dfd-4691-8389-b789d7fe0b18 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:188
Oct 25 02:25:14.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4058" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":356,"completed":173,"skipped":3148,"failed":0}
SSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:25:14.791: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Oct 25 02:25:14.863: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:25:16.877: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Oct 25 02:25:16.901: INFO: The status of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:25:18.912: INFO: The status of Pod pod-with-poststart-exec-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 25 02:25:18.958: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 25 02:25:18.963: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 25 02:25:20.963: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 25 02:25:20.972: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Oct 25 02:25:20.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5590" for this suite.

• [SLOW TEST:6.207 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":356,"completed":174,"skipped":3154,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] 
  should support CSR API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:25:20.998: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename certificates
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support CSR API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/certificates.k8s.io
STEP: getting /apis/certificates.k8s.io/v1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Oct 25 02:25:21.587: INFO: starting watch
STEP: patching
STEP: updating
Oct 25 02:25:21.613: INFO: waiting for watch events with expected annotations
Oct 25 02:25:21.613: INFO: saw patched and updated annotations
STEP: getting /approval
STEP: patching /approval
STEP: updating /approval
STEP: getting /status
STEP: patching /status
STEP: updating /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:25:21.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-5753" for this suite.
•{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","total":356,"completed":175,"skipped":3167,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:25:21.800: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:25:21.845: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Oct 25 02:25:30.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-8586 --namespace=crd-publish-openapi-8586 create -f -'
Oct 25 02:25:31.548: INFO: stderr: ""
Oct 25 02:25:31.548: INFO: stdout: "e2e-test-crd-publish-openapi-1751-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Oct 25 02:25:31.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-8586 --namespace=crd-publish-openapi-8586 delete e2e-test-crd-publish-openapi-1751-crds test-cr'
Oct 25 02:25:31.714: INFO: stderr: ""
Oct 25 02:25:31.714: INFO: stdout: "e2e-test-crd-publish-openapi-1751-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Oct 25 02:25:31.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-8586 --namespace=crd-publish-openapi-8586 apply -f -'
Oct 25 02:25:32.584: INFO: stderr: ""
Oct 25 02:25:32.584: INFO: stdout: "e2e-test-crd-publish-openapi-1751-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Oct 25 02:25:32.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-8586 --namespace=crd-publish-openapi-8586 delete e2e-test-crd-publish-openapi-1751-crds test-cr'
Oct 25 02:25:32.653: INFO: stderr: ""
Oct 25 02:25:32.653: INFO: stdout: "e2e-test-crd-publish-openapi-1751-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Oct 25 02:25:32.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-8586 explain e2e-test-crd-publish-openapi-1751-crds'
Oct 25 02:25:33.563: INFO: stderr: ""
Oct 25 02:25:33.563: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-1751-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:25:36.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8586" for this suite.

• [SLOW TEST:14.817 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":356,"completed":176,"skipped":3195,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:25:36.617: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 02:25:36.664: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cbc8e99b-ce6f-4c2f-b5b5-ba6a3a3e28b1" in namespace "projected-2811" to be "Succeeded or Failed"
Oct 25 02:25:36.669: INFO: Pod "downwardapi-volume-cbc8e99b-ce6f-4c2f-b5b5-ba6a3a3e28b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.823776ms
Oct 25 02:25:38.679: INFO: Pod "downwardapi-volume-cbc8e99b-ce6f-4c2f-b5b5-ba6a3a3e28b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01558188s
Oct 25 02:25:40.691: INFO: Pod "downwardapi-volume-cbc8e99b-ce6f-4c2f-b5b5-ba6a3a3e28b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026914148s
STEP: Saw pod success
Oct 25 02:25:40.691: INFO: Pod "downwardapi-volume-cbc8e99b-ce6f-4c2f-b5b5-ba6a3a3e28b1" satisfied condition "Succeeded or Failed"
Oct 25 02:25:40.696: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-cbc8e99b-ce6f-4c2f-b5b5-ba6a3a3e28b1 container client-container: <nil>
STEP: delete the pod
Oct 25 02:25:40.741: INFO: Waiting for pod downwardapi-volume-cbc8e99b-ce6f-4c2f-b5b5-ba6a3a3e28b1 to disappear
Oct 25 02:25:40.746: INFO: Pod downwardapi-volume-cbc8e99b-ce6f-4c2f-b5b5-ba6a3a3e28b1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Oct 25 02:25:40.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2811" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":356,"completed":177,"skipped":3207,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:25:40.770: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-35c86756-a691-4514-bed1-b67422025dd7
STEP: Creating a pod to test consume configMaps
Oct 25 02:25:40.827: INFO: Waiting up to 5m0s for pod "pod-configmaps-87b25bbe-72db-4c51-925d-a4dde5c569df" in namespace "configmap-234" to be "Succeeded or Failed"
Oct 25 02:25:40.839: INFO: Pod "pod-configmaps-87b25bbe-72db-4c51-925d-a4dde5c569df": Phase="Pending", Reason="", readiness=false. Elapsed: 11.471553ms
Oct 25 02:25:42.848: INFO: Pod "pod-configmaps-87b25bbe-72db-4c51-925d-a4dde5c569df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020797492s
Oct 25 02:25:44.860: INFO: Pod "pod-configmaps-87b25bbe-72db-4c51-925d-a4dde5c569df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03306629s
STEP: Saw pod success
Oct 25 02:25:44.860: INFO: Pod "pod-configmaps-87b25bbe-72db-4c51-925d-a4dde5c569df" satisfied condition "Succeeded or Failed"
Oct 25 02:25:44.866: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-configmaps-87b25bbe-72db-4c51-925d-a4dde5c569df container agnhost-container: <nil>
STEP: delete the pod
Oct 25 02:25:44.906: INFO: Waiting for pod pod-configmaps-87b25bbe-72db-4c51-925d-a4dde5c569df to disappear
Oct 25 02:25:44.912: INFO: Pod pod-configmaps-87b25bbe-72db-4c51-925d-a4dde5c569df no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 02:25:44.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-234" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":178,"skipped":3232,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:25:44.934: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:25:44.992: INFO: The status of Pod server-envvars-de5b5df5-a93a-466b-9c0a-1a91416e154a is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:25:47.002: INFO: The status of Pod server-envvars-de5b5df5-a93a-466b-9c0a-1a91416e154a is Running (Ready = true)
Oct 25 02:25:47.049: INFO: Waiting up to 5m0s for pod "client-envvars-ce546328-cc8c-4960-896e-ec20e28bbdbb" in namespace "pods-868" to be "Succeeded or Failed"
Oct 25 02:25:47.054: INFO: Pod "client-envvars-ce546328-cc8c-4960-896e-ec20e28bbdbb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.505669ms
Oct 25 02:25:49.065: INFO: Pod "client-envvars-ce546328-cc8c-4960-896e-ec20e28bbdbb": Phase="Running", Reason="", readiness=false. Elapsed: 2.01626559s
Oct 25 02:25:51.076: INFO: Pod "client-envvars-ce546328-cc8c-4960-896e-ec20e28bbdbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027574479s
STEP: Saw pod success
Oct 25 02:25:51.076: INFO: Pod "client-envvars-ce546328-cc8c-4960-896e-ec20e28bbdbb" satisfied condition "Succeeded or Failed"
Oct 25 02:25:51.082: INFO: Trying to get logs from node lab1-k8s-node-3 pod client-envvars-ce546328-cc8c-4960-896e-ec20e28bbdbb container env3cont: <nil>
STEP: delete the pod
Oct 25 02:25:51.115: INFO: Waiting for pod client-envvars-ce546328-cc8c-4960-896e-ec20e28bbdbb to disappear
Oct 25 02:25:51.126: INFO: Pod client-envvars-ce546328-cc8c-4960-896e-ec20e28bbdbb no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Oct 25 02:25:51.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-868" for this suite.

• [SLOW TEST:6.212 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":356,"completed":179,"skipped":3252,"failed":0}
S
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:25:51.147: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Oct 25 02:25:51.178: INFO: Waiting up to 1m0s for all nodes to be ready
Oct 25 02:26:51.222: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:26:51.228: INFO: Starting informer...
STEP: Starting pods...
Oct 25 02:26:51.455: INFO: Pod1 is running on lab1-k8s-node-3. Tainting Node
Oct 25 02:26:53.693: INFO: Pod2 is running on lab1-k8s-node-3. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Oct 25 02:27:00.082: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Oct 25 02:27:20.115: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:27:20.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-4237" for this suite.

• [SLOW TEST:89.039 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":356,"completed":180,"skipped":3253,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:27:20.186: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Oct 25 02:27:20.230: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Oct 25 02:27:24.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4805" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":356,"completed":181,"skipped":3266,"failed":0}
SSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:27:24.139: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-2167
Oct 25 02:27:24.197: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:27:26.211: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Oct 25 02:27:26.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-2167 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Oct 25 02:27:26.379: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Oct 25 02:27:26.379: INFO: stdout: "ipvs"
Oct 25 02:27:26.379: INFO: proxyMode: ipvs
Oct 25 02:27:26.403: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Oct 25 02:27:26.408: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-2167
STEP: creating replication controller affinity-clusterip-timeout in namespace services-2167
I1025 02:27:26.445071      18 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-2167, replica count: 3
I1025 02:27:29.496146      18 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 25 02:27:29.513: INFO: Creating new exec pod
Oct 25 02:27:32.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-2167 exec execpod-affinityccdt8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Oct 25 02:27:32.701: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-timeout 80\n+ echo hostName\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Oct 25 02:27:32.701: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 02:27:32.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-2167 exec execpod-affinityccdt8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.9.106 80'
Oct 25 02:27:32.848: INFO: stderr: "+ nc -v -t -w 2 10.233.9.106 80\n+ echo hostName\nConnection to 10.233.9.106 80 port [tcp/http] succeeded!\n"
Oct 25 02:27:32.848: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 02:27:32.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-2167 exec execpod-affinityccdt8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.9.106:80/ ; done'
Oct 25 02:27:33.092: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n"
Oct 25 02:27:33.092: INFO: stdout: "\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4\naffinity-clusterip-timeout-xt9d4"
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Received response from host: affinity-clusterip-timeout-xt9d4
Oct 25 02:27:33.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-2167 exec execpod-affinityccdt8 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.233.9.106:80/'
Oct 25 02:27:33.233: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n"
Oct 25 02:27:33.233: INFO: stdout: "affinity-clusterip-timeout-xt9d4"
Oct 25 02:29:43.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-2167 exec execpod-affinityccdt8 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.233.9.106:80/'
Oct 25 02:29:43.381: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.233.9.106:80/\n"
Oct 25 02:29:43.382: INFO: stdout: "affinity-clusterip-timeout-pk5dm"
Oct 25 02:29:43.382: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-2167, will wait for the garbage collector to delete the pods
Oct 25 02:29:43.480: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 13.937194ms
Oct 25 02:29:43.581: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.871736ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 02:29:46.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2167" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:141.898 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":182,"skipped":3272,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease 
  lease API should be available [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:29:46.037: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] lease API should be available [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:188
Oct 25 02:29:46.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-8713" for this suite.
•{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","total":356,"completed":183,"skipped":3296,"failed":0}
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:29:46.206: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:29:46.251: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct 25 02:29:51.269: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 25 02:29:51.269: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct 25 02:29:53.278: INFO: Creating deployment "test-rollover-deployment"
Oct 25 02:29:53.297: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct 25 02:29:55.311: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct 25 02:29:55.324: INFO: Ensure that both replica sets have 1 created replica
Oct 25 02:29:55.338: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct 25 02:29:55.357: INFO: Updating deployment test-rollover-deployment
Oct 25 02:29:55.357: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct 25 02:29:57.376: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct 25 02:29:57.390: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct 25 02:29:57.401: INFO: all replica sets need to contain the pod-template-hash label
Oct 25 02:29:57.401: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 29, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 25 02:29:59.419: INFO: all replica sets need to contain the pod-template-hash label
Oct 25 02:29:59.419: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 29, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 25 02:30:01.418: INFO: all replica sets need to contain the pod-template-hash label
Oct 25 02:30:01.418: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 29, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 25 02:30:03.415: INFO: all replica sets need to contain the pod-template-hash label
Oct 25 02:30:03.415: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 29, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 25 02:30:05.418: INFO: all replica sets need to contain the pod-template-hash label
Oct 25 02:30:05.418: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 29, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 29, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 25 02:30:07.418: INFO: 
Oct 25 02:30:07.418: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 25 02:30:07.436: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-1214  48538655-af0b-4f64-a51a-57f2e302b119 227307 2 2022-10-25 02:29:53 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-10-25 02:29:55 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 02:30:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00356f088 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-10-25 02:29:53 +0000 UTC,LastTransitionTime:2022-10-25 02:29:53 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-779c67f4f8" has successfully progressed.,LastUpdateTime:2022-10-25 02:30:06 +0000 UTC,LastTransitionTime:2022-10-25 02:29:53 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct 25 02:30:07.442: INFO: New ReplicaSet "test-rollover-deployment-779c67f4f8" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-779c67f4f8  deployment-1214  884efe68-aa10-418c-a190-9c404c56b44d 227297 2 2022-10-25 02:29:55 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 48538655-af0b-4f64-a51a-57f2e302b119 0xc00356f627 0xc00356f628}] []  [{kube-controller-manager Update apps/v1 2022-10-25 02:29:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"48538655-af0b-4f64-a51a-57f2e302b119\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 02:30:06 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 779c67f4f8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00356f8c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 25 02:30:07.442: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct 25 02:30:07.442: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-1214  1c04ba01-51cd-4dfe-af21-0deef031bb14 227306 2 2022-10-25 02:29:46 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 48538655-af0b-4f64-a51a-57f2e302b119 0xc00356f407 0xc00356f408}] []  [{e2e.test Update apps/v1 2022-10-25 02:29:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 02:30:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"48538655-af0b-4f64-a51a-57f2e302b119\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-10-25 02:30:06 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00356f4c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 25 02:30:07.442: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-87f8f6dcf  deployment-1214  47742cc6-5c5c-47b0-bd46-4bfb0255db9f 227245 2 2022-10-25 02:29:53 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:87f8f6dcf] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 48538655-af0b-4f64-a51a-57f2e302b119 0xc00356f930 0xc00356f931}] []  [{kube-controller-manager Update apps/v1 2022-10-25 02:29:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"48538655-af0b-4f64-a51a-57f2e302b119\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 02:29:55 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 87f8f6dcf,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:87f8f6dcf] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00356f9d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 25 02:30:07.447: INFO: Pod "test-rollover-deployment-779c67f4f8-gkg5r" is available:
&Pod{ObjectMeta:{test-rollover-deployment-779c67f4f8-gkg5r test-rollover-deployment-779c67f4f8- deployment-1214  aaa3513f-3dce-4d14-a1be-d939939e4cd9 227261 0 2022-10-25 02:29:55 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[cni.projectcalico.org/containerID:111c48882bd5914a80a828231a6235ce792f2feeffd82857c0871b4861a3f212 cni.projectcalico.org/podIP:10.233.74.191/32 cni.projectcalico.org/podIPs:10.233.74.191/32] [{apps/v1 ReplicaSet test-rollover-deployment-779c67f4f8 884efe68-aa10-418c-a190-9c404c56b44d 0xc00356ff77 0xc00356ff78}] []  [{kube-controller-manager Update v1 2022-10-25 02:29:55 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"884efe68-aa10-418c-a190-9c404c56b44d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-10-25 02:29:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-25 02:29:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.74.191\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h594j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h594j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:29:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:29:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:29:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:29:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.178,PodIP:10.233.74.191,StartTime:2022-10-25 02:29:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 02:29:56 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e,ContainerID:containerd://b78a4a03a42e585d632c50ebf1d3140ec42fe3bc99776e7af802c8b7072095ee,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.74.191,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Oct 25 02:30:07.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1214" for this suite.

• [SLOW TEST:21.262 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":356,"completed":184,"skipped":3301,"failed":0}
S
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:30:07.469: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-4682
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-4682
STEP: creating replication controller externalsvc in namespace services-4682
I1025 02:30:07.567265      18 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4682, replica count: 2
I1025 02:30:10.618047      18 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Oct 25 02:30:10.659: INFO: Creating new exec pod
Oct 25 02:30:12.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-4682 exec execpod44crb -- /bin/sh -x -c nslookup clusterip-service.services-4682.svc.cluster.local'
Oct 25 02:30:12.869: INFO: stderr: "+ nslookup clusterip-service.services-4682.svc.cluster.local\n"
Oct 25 02:30:12.869: INFO: stdout: "Server:\t\t169.254.25.10\nAddress:\t169.254.25.10#53\n\nclusterip-service.services-4682.svc.cluster.local\tcanonical name = externalsvc.services-4682.svc.cluster.local.\nName:\texternalsvc.services-4682.svc.cluster.local\nAddress: 10.233.9.249\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4682, will wait for the garbage collector to delete the pods
Oct 25 02:30:12.945: INFO: Deleting ReplicationController externalsvc took: 15.169275ms
Oct 25 02:30:13.046: INFO: Terminating ReplicationController externalsvc pods took: 100.865529ms
Oct 25 02:30:15.086: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 02:30:15.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4682" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:7.664 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":356,"completed":185,"skipped":3302,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:30:15.139: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Oct 25 02:30:15.175: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Oct 25 02:30:33.304: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:30:41.265: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:30:59.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6445" for this suite.

• [SLOW TEST:44.005 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":356,"completed":186,"skipped":3318,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:30:59.146: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-1e28174a-5686-4fc5-acc4-7adee0561b23
STEP: Creating a pod to test consume configMaps
Oct 25 02:30:59.197: INFO: Waiting up to 5m0s for pod "pod-configmaps-997a54b5-043d-45c6-b4b2-00aa9b273dcf" in namespace "configmap-2327" to be "Succeeded or Failed"
Oct 25 02:30:59.204: INFO: Pod "pod-configmaps-997a54b5-043d-45c6-b4b2-00aa9b273dcf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.809751ms
Oct 25 02:31:01.218: INFO: Pod "pod-configmaps-997a54b5-043d-45c6-b4b2-00aa9b273dcf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021250315s
Oct 25 02:31:03.227: INFO: Pod "pod-configmaps-997a54b5-043d-45c6-b4b2-00aa9b273dcf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030079569s
STEP: Saw pod success
Oct 25 02:31:03.227: INFO: Pod "pod-configmaps-997a54b5-043d-45c6-b4b2-00aa9b273dcf" satisfied condition "Succeeded or Failed"
Oct 25 02:31:03.233: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-configmaps-997a54b5-043d-45c6-b4b2-00aa9b273dcf container agnhost-container: <nil>
STEP: delete the pod
Oct 25 02:31:03.275: INFO: Waiting for pod pod-configmaps-997a54b5-043d-45c6-b4b2-00aa9b273dcf to disappear
Oct 25 02:31:03.280: INFO: Pod pod-configmaps-997a54b5-043d-45c6-b4b2-00aa9b273dcf no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 02:31:03.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2327" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":187,"skipped":3359,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:31:03.305: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with configMap that has name projected-configmap-test-upd-401b77c0-0dae-4171-b616-1a3a991bff80
STEP: Creating the pod
Oct 25 02:31:03.376: INFO: The status of Pod pod-projected-configmaps-5fdd3ad2-0f52-4af7-9819-c5161090bd36 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:31:05.387: INFO: The status of Pod pod-projected-configmaps-5fdd3ad2-0f52-4af7-9819-c5161090bd36 is Running (Ready = true)
STEP: Updating configmap projected-configmap-test-upd-401b77c0-0dae-4171-b616-1a3a991bff80
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Oct 25 02:31:07.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8618" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":188,"skipped":3386,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:31:07.467: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Oct 25 02:31:07.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-3875" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","total":356,"completed":189,"skipped":3400,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:31:07.563: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 25 02:31:10.649: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Oct 25 02:31:10.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7801" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":190,"skipped":3420,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:31:10.723: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:31:10.825: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct 25 02:31:10.840: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:31:10.840: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched.
Oct 25 02:31:10.928: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:31:10.928: INFO: Node lab1-k8s-node-2 is running 0 daemon pod, expected 1
Oct 25 02:31:11.937: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:31:11.937: INFO: Node lab1-k8s-node-2 is running 0 daemon pod, expected 1
Oct 25 02:31:12.937: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Oct 25 02:31:12.937: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct 25 02:31:12.982: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Oct 25 02:31:12.982: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Oct 25 02:31:13.989: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:31:13.989: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct 25 02:31:14.006: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:31:14.007: INFO: Node lab1-k8s-node-2 is running 0 daemon pod, expected 1
Oct 25 02:31:15.015: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:31:15.015: INFO: Node lab1-k8s-node-2 is running 0 daemon pod, expected 1
Oct 25 02:31:16.014: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:31:16.014: INFO: Node lab1-k8s-node-2 is running 0 daemon pod, expected 1
Oct 25 02:31:17.016: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Oct 25 02:31:17.016: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3320, will wait for the garbage collector to delete the pods
Oct 25 02:31:17.097: INFO: Deleting DaemonSet.extensions daemon-set took: 10.271049ms
Oct 25 02:31:17.198: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.882918ms
Oct 25 02:31:19.207: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:31:19.207: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct 25 02:31:19.214: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"227892"},"items":null}

Oct 25 02:31:19.219: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"227892"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:31:19.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3320" for this suite.

• [SLOW TEST:8.572 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":356,"completed":191,"skipped":3428,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:31:19.299: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a job [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-1359, will wait for the garbage collector to delete the pods
Oct 25 02:31:21.414: INFO: Deleting Job.batch foo took: 12.31034ms
Oct 25 02:31:21.515: INFO: Terminating Job.batch foo pods took: 100.976305ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Oct 25 02:31:53.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1359" for this suite.

• [SLOW TEST:34.545 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":356,"completed":192,"skipped":3443,"failed":0}
S
------------------------------
[sig-apps] CronJob 
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:31:53.845: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a suspended cronjob
STEP: Ensuring no jobs are scheduled
STEP: Ensuring no job exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Oct 25 02:36:53.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5002" for this suite.

• [SLOW TEST:300.085 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","total":356,"completed":193,"skipped":3444,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:36:53.931: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Oct 25 02:36:53.971: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying pod deletion was observed
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Oct 25 02:36:58.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1881" for this suite.
•{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","total":356,"completed":194,"skipped":3454,"failed":0}
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:36:58.273: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a Pod with a 'name' label pod-adoption is created
Oct 25 02:36:58.330: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:37:00.341: INFO: The status of Pod pod-adoption is Running (Ready = true)
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Oct 25 02:37:01.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4451" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":356,"completed":195,"skipped":3461,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:37:01.394: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/framework/framework.go:652
STEP: validating api versions
Oct 25 02:37:01.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-2589 api-versions'
Oct 25 02:37:01.491: INFO: stderr: ""
Oct 25 02:37:01.491: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1\nevents.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\nnode.k8s.io/v1beta1\npolicy/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nsnapshot.storage.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 02:37:01.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2589" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":356,"completed":196,"skipped":3472,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:37:01.510: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:79
Oct 25 02:37:01.545: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the sample API server.
Oct 25 02:37:01.877: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct 25 02:37:03.954: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 25 02:37:05.962: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 25 02:37:07.963: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 25 02:37:09.964: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 25 02:37:11.965: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 37, 1, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 25 02:37:15.395: INFO: Waited 1.422726814s for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}'
STEP: List APIServices
Oct 25 02:37:15.465: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:69
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:188
Oct 25 02:37:16.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-9048" for this suite.

• [SLOW TEST:14.640 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":356,"completed":197,"skipped":3488,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:37:16.151: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Oct 25 02:37:16.529: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 02:37:19.565: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:37:19.572: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:37:27.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5039" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139

• [SLOW TEST:11.708 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":356,"completed":198,"skipped":3507,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should replace a pod template [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:37:27.863: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename podtemplate
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should replace a pod template [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a pod template
STEP: Replace a pod template
Oct 25 02:37:27.921: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Oct 25 02:37:27.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-1414" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","total":356,"completed":199,"skipped":3559,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:37:27.939: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5804
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5804
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5804
Oct 25 02:37:28.008: INFO: Found 0 stateful pods, waiting for 1
Oct 25 02:37:38.017: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct 25 02:37:38.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-5804 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 25 02:37:38.194: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 25 02:37:38.194: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 25 02:37:38.194: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 25 02:37:38.201: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 25 02:37:48.209: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 25 02:37:48.209: INFO: Waiting for statefulset status.replicas updated to 0
Oct 25 02:37:48.234: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999803s
Oct 25 02:37:49.244: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994271642s
Oct 25 02:37:50.253: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.984717937s
Oct 25 02:37:51.261: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.97554813s
Oct 25 02:37:52.269: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.967719869s
Oct 25 02:37:53.277: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.960038519s
Oct 25 02:37:54.284: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.951992899s
Oct 25 02:37:55.294: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.944644424s
Oct 25 02:37:56.304: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.934313979s
Oct 25 02:37:57.311: INFO: Verifying statefulset ss doesn't scale past 1 for another 924.785026ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5804
Oct 25 02:37:58.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-5804 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 25 02:37:58.466: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 25 02:37:58.466: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 25 02:37:58.466: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 25 02:37:58.472: INFO: Found 1 stateful pods, waiting for 3
Oct 25 02:38:08.481: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 25 02:38:08.481: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 25 02:38:08.481: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct 25 02:38:08.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-5804 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 25 02:38:08.639: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 25 02:38:08.639: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 25 02:38:08.639: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 25 02:38:08.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-5804 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 25 02:38:08.805: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 25 02:38:08.805: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 25 02:38:08.805: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 25 02:38:08.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-5804 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 25 02:38:08.956: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 25 02:38:08.956: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 25 02:38:08.956: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 25 02:38:08.956: INFO: Waiting for statefulset status.replicas updated to 0
Oct 25 02:38:08.964: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Oct 25 02:38:18.980: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 25 02:38:18.980: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 25 02:38:18.980: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 25 02:38:19.005: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999737s
Oct 25 02:38:20.013: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993419457s
Oct 25 02:38:21.022: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985149858s
Oct 25 02:38:22.031: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.975676013s
Oct 25 02:38:23.041: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.966016084s
Oct 25 02:38:24.048: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.957472975s
Oct 25 02:38:25.059: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.949600424s
Oct 25 02:38:26.074: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.939245781s
Oct 25 02:38:27.082: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.924165457s
Oct 25 02:38:28.090: INFO: Verifying statefulset ss doesn't scale past 3 for another 916.455878ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5804
Oct 25 02:38:29.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-5804 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 25 02:38:29.247: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 25 02:38:29.247: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 25 02:38:29.247: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 25 02:38:29.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-5804 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 25 02:38:29.393: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 25 02:38:29.393: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 25 02:38:29.393: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 25 02:38:29.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-5804 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 25 02:38:29.540: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 25 02:38:29.540: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 25 02:38:29.540: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 25 02:38:29.540: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct 25 02:38:39.569: INFO: Deleting all statefulset in ns statefulset-5804
Oct 25 02:38:39.576: INFO: Scaling statefulset ss to 0
Oct 25 02:38:39.596: INFO: Waiting for statefulset status.replicas updated to 0
Oct 25 02:38:39.601: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Oct 25 02:38:39.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5804" for this suite.

• [SLOW TEST:71.717 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":356,"completed":200,"skipped":3602,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:38:39.656: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 25 02:38:43.788: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Oct 25 02:38:43.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3067" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":356,"completed":201,"skipped":3610,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:38:43.846: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 25 02:38:43.898: INFO: Waiting up to 5m0s for pod "pod-af3c5ebd-4632-4680-9898-421316f4943e" in namespace "emptydir-4819" to be "Succeeded or Failed"
Oct 25 02:38:43.904: INFO: Pod "pod-af3c5ebd-4632-4680-9898-421316f4943e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.214639ms
Oct 25 02:38:45.914: INFO: Pod "pod-af3c5ebd-4632-4680-9898-421316f4943e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015190624s
Oct 25 02:38:47.922: INFO: Pod "pod-af3c5ebd-4632-4680-9898-421316f4943e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023567299s
STEP: Saw pod success
Oct 25 02:38:47.922: INFO: Pod "pod-af3c5ebd-4632-4680-9898-421316f4943e" satisfied condition "Succeeded or Failed"
Oct 25 02:38:47.927: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-af3c5ebd-4632-4680-9898-421316f4943e container test-container: <nil>
STEP: delete the pod
Oct 25 02:38:47.974: INFO: Waiting for pod pod-af3c5ebd-4632-4680-9898-421316f4943e to disappear
Oct 25 02:38:47.978: INFO: Pod pod-af3c5ebd-4632-4680-9898-421316f4943e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 02:38:47.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4819" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":202,"skipped":3623,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:38:47.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:188
Oct 25 02:38:48.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6622" for this suite.
•{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":356,"completed":203,"skipped":3632,"failed":0}

------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:38:48.081: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap that has name configmap-test-emptyKey-7cf18b52-f458-418b-8ea5-3909d6e95521
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 02:38:48.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1246" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":356,"completed":204,"skipped":3632,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:38:48.130: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in container's command
Oct 25 02:38:48.173: INFO: Waiting up to 5m0s for pod "var-expansion-ec56cce4-2d33-42cb-b558-44f9ea5c8d49" in namespace "var-expansion-5346" to be "Succeeded or Failed"
Oct 25 02:38:48.179: INFO: Pod "var-expansion-ec56cce4-2d33-42cb-b558-44f9ea5c8d49": Phase="Pending", Reason="", readiness=false. Elapsed: 5.349671ms
Oct 25 02:38:50.189: INFO: Pod "var-expansion-ec56cce4-2d33-42cb-b558-44f9ea5c8d49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015178617s
Oct 25 02:38:52.199: INFO: Pod "var-expansion-ec56cce4-2d33-42cb-b558-44f9ea5c8d49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025969248s
STEP: Saw pod success
Oct 25 02:38:52.200: INFO: Pod "var-expansion-ec56cce4-2d33-42cb-b558-44f9ea5c8d49" satisfied condition "Succeeded or Failed"
Oct 25 02:38:52.204: INFO: Trying to get logs from node lab1-k8s-node-3 pod var-expansion-ec56cce4-2d33-42cb-b558-44f9ea5c8d49 container dapi-container: <nil>
STEP: delete the pod
Oct 25 02:38:52.235: INFO: Waiting for pod var-expansion-ec56cce4-2d33-42cb-b558-44f9ea5c8d49 to disappear
Oct 25 02:38:52.241: INFO: Pod var-expansion-ec56cce4-2d33-42cb-b558-44f9ea5c8d49 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Oct 25 02:38:52.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5346" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":356,"completed":205,"skipped":3649,"failed":0}
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:38:52.261: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ReplicationController
STEP: waiting for RC to be added
STEP: waiting for available Replicas
STEP: patching ReplicationController
STEP: waiting for RC to be modified
STEP: patching ReplicationController status
STEP: waiting for RC to be modified
STEP: waiting for available Replicas
STEP: fetching ReplicationController status
STEP: patching ReplicationController scale
STEP: waiting for RC to be modified
STEP: waiting for ReplicationController's scale to be the max amount
STEP: fetching ReplicationController; ensuring that it's patched
STEP: updating ReplicationController status
STEP: waiting for RC to be modified
STEP: listing all ReplicationControllers
STEP: checking that ReplicationController has expected values
STEP: deleting ReplicationControllers by collection
STEP: waiting for ReplicationController to have a DELETED watchEvent
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Oct 25 02:38:55.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5670" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","total":356,"completed":206,"skipped":3654,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:38:55.065: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:39:08.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7700" for this suite.
STEP: Destroying namespace "nsdeletetest-1549" for this suite.
Oct 25 02:39:08.230: INFO: Namespace nsdeletetest-1549 was already deleted
STEP: Destroying namespace "nsdeletetest-4173" for this suite.

• [SLOW TEST:13.178 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":356,"completed":207,"skipped":3661,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:39:08.244: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Oct 25 02:39:08.298: INFO: The status of Pod labelsupdateb1d6d16a-2dc2-47f3-a786-7fda70b3ab7b is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:39:10.308: INFO: The status of Pod labelsupdateb1d6d16a-2dc2-47f3-a786-7fda70b3ab7b is Running (Ready = true)
Oct 25 02:39:10.843: INFO: Successfully updated pod "labelsupdateb1d6d16a-2dc2-47f3-a786-7fda70b3ab7b"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Oct 25 02:39:14.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2138" for this suite.

• [SLOW TEST:6.658 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":356,"completed":208,"skipped":3670,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:39:14.905: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Oct 25 02:39:14.946: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-4559  93e53d48-6d7a-484a-b13b-56cd1828d834 230150 0 2022-10-25 02:39:14 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2022-10-25 02:39:14 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n4bxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n4bxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 02:39:14.951: INFO: The status of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:39:16.964: INFO: The status of Pod test-dns-nameservers is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Oct 25 02:39:16.964: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-4559 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:39:16.964: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:39:16.964: INFO: ExecWithOptions: Clientset creation
Oct 25 02:39:16.965: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-4559/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod...
Oct 25 02:39:17.056: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-4559 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 02:39:17.056: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:39:17.057: INFO: ExecWithOptions: Clientset creation
Oct 25 02:39:17.057: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/dns-4559/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 25 02:39:17.142: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Oct 25 02:39:17.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4559" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":356,"completed":209,"skipped":3728,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:39:17.189: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating replication controller my-hostname-basic-75f2cd1a-3da6-4e99-8487-64a846a576c6
Oct 25 02:39:17.233: INFO: Pod name my-hostname-basic-75f2cd1a-3da6-4e99-8487-64a846a576c6: Found 0 pods out of 1
Oct 25 02:39:22.259: INFO: Pod name my-hostname-basic-75f2cd1a-3da6-4e99-8487-64a846a576c6: Found 1 pods out of 1
Oct 25 02:39:22.259: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-75f2cd1a-3da6-4e99-8487-64a846a576c6" are running
Oct 25 02:39:22.265: INFO: Pod "my-hostname-basic-75f2cd1a-3da6-4e99-8487-64a846a576c6-tk8jl" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-25 02:39:17 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-25 02:39:18 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-25 02:39:18 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-10-25 02:39:17 +0000 UTC Reason: Message:}])
Oct 25 02:39:22.265: INFO: Trying to dial the pod
Oct 25 02:39:27.294: INFO: Controller my-hostname-basic-75f2cd1a-3da6-4e99-8487-64a846a576c6: Got expected result from replica 1 [my-hostname-basic-75f2cd1a-3da6-4e99-8487-64a846a576c6-tk8jl]: "my-hostname-basic-75f2cd1a-3da6-4e99-8487-64a846a576c6-tk8jl", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Oct 25 02:39:27.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9736" for this suite.

• [SLOW TEST:10.128 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":356,"completed":210,"skipped":3736,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:39:27.319: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-b183f41d-4c65-43a0-99d6-6fd5cc3504e0
STEP: Creating a pod to test consume configMaps
Oct 25 02:39:27.372: INFO: Waiting up to 5m0s for pod "pod-configmaps-43b8c089-22b2-482c-9014-579c78c4d9ed" in namespace "configmap-4571" to be "Succeeded or Failed"
Oct 25 02:39:27.377: INFO: Pod "pod-configmaps-43b8c089-22b2-482c-9014-579c78c4d9ed": Phase="Pending", Reason="", readiness=false. Elapsed: 4.883302ms
Oct 25 02:39:29.387: INFO: Pod "pod-configmaps-43b8c089-22b2-482c-9014-579c78c4d9ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014688534s
Oct 25 02:39:31.398: INFO: Pod "pod-configmaps-43b8c089-22b2-482c-9014-579c78c4d9ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025708052s
STEP: Saw pod success
Oct 25 02:39:31.398: INFO: Pod "pod-configmaps-43b8c089-22b2-482c-9014-579c78c4d9ed" satisfied condition "Succeeded or Failed"
Oct 25 02:39:31.403: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-configmaps-43b8c089-22b2-482c-9014-579c78c4d9ed container agnhost-container: <nil>
STEP: delete the pod
Oct 25 02:39:31.434: INFO: Waiting for pod pod-configmaps-43b8c089-22b2-482c-9014-579c78c4d9ed to disappear
Oct 25 02:39:31.438: INFO: Pod pod-configmaps-43b8c089-22b2-482c-9014-579c78c4d9ed no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 02:39:31.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4571" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":211,"skipped":3754,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:39:31.456: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:39:37.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3813" for this suite.
STEP: Destroying namespace "nsdeletetest-9382" for this suite.
Oct 25 02:39:37.664: INFO: Namespace nsdeletetest-9382 was already deleted
STEP: Destroying namespace "nsdeletetest-5575" for this suite.

• [SLOW TEST:6.222 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":356,"completed":212,"skipped":3781,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:39:37.679: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:39:37.774: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct 25 02:39:37.804: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:39:37.804: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 02:39:38.825: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Oct 25 02:39:38.825: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 02:39:39.820: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 6
Oct 25 02:39:39.820: INFO: Number of running nodes: 6, number of available pods: 6 in daemonset daemon-set
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct 25 02:39:39.874: INFO: Wrong image for pod: daemon-set-5cd58. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:39.874: INFO: Wrong image for pod: daemon-set-7f7b8. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:39.874: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:39.874: INFO: Wrong image for pod: daemon-set-g49zf. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:39.874: INFO: Wrong image for pod: daemon-set-hknqk. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:40.895: INFO: Wrong image for pod: daemon-set-5cd58. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:40.895: INFO: Wrong image for pod: daemon-set-7f7b8. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:40.895: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:40.895: INFO: Wrong image for pod: daemon-set-g49zf. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:40.895: INFO: Wrong image for pod: daemon-set-hknqk. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:41.897: INFO: Wrong image for pod: daemon-set-5cd58. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:41.897: INFO: Wrong image for pod: daemon-set-7f7b8. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:41.897: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:41.898: INFO: Wrong image for pod: daemon-set-g49zf. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:41.898: INFO: Wrong image for pod: daemon-set-hknqk. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:42.918: INFO: Wrong image for pod: daemon-set-5cd58. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:42.918: INFO: Wrong image for pod: daemon-set-7f7b8. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:42.918: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:42.918: INFO: Wrong image for pod: daemon-set-g49zf. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:42.918: INFO: Wrong image for pod: daemon-set-hknqk. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:42.918: INFO: Pod daemon-set-pl2l9 is not available
Oct 25 02:39:43.896: INFO: Wrong image for pod: daemon-set-5cd58. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:43.896: INFO: Wrong image for pod: daemon-set-7f7b8. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:43.896: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:43.896: INFO: Wrong image for pod: daemon-set-g49zf. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:43.896: INFO: Wrong image for pod: daemon-set-hknqk. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:43.896: INFO: Pod daemon-set-pl2l9 is not available
Oct 25 02:39:44.894: INFO: Wrong image for pod: daemon-set-5cd58. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:44.894: INFO: Wrong image for pod: daemon-set-7f7b8. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:44.894: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:44.894: INFO: Wrong image for pod: daemon-set-g49zf. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:45.897: INFO: Wrong image for pod: daemon-set-5cd58. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:45.897: INFO: Wrong image for pod: daemon-set-7f7b8. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:45.897: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:45.897: INFO: Pod daemon-set-9vxv6 is not available
Oct 25 02:39:45.897: INFO: Wrong image for pod: daemon-set-g49zf. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:46.894: INFO: Wrong image for pod: daemon-set-5cd58. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:46.894: INFO: Wrong image for pod: daemon-set-7f7b8. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:46.894: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:46.894: INFO: Pod daemon-set-9vxv6 is not available
Oct 25 02:39:46.894: INFO: Wrong image for pod: daemon-set-g49zf. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:47.894: INFO: Wrong image for pod: daemon-set-5cd58. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:47.894: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:47.894: INFO: Wrong image for pod: daemon-set-g49zf. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:48.897: INFO: Wrong image for pod: daemon-set-5cd58. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:48.897: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:48.897: INFO: Wrong image for pod: daemon-set-g49zf. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:48.897: INFO: Pod daemon-set-l56r7 is not available
Oct 25 02:39:49.895: INFO: Wrong image for pod: daemon-set-5cd58. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:49.895: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:50.896: INFO: Wrong image for pod: daemon-set-5cd58. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:50.896: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:50.896: INFO: Pod daemon-set-w49n2 is not available
Oct 25 02:39:51.896: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:52.894: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:52.894: INFO: Pod daemon-set-sljxf is not available
Oct 25 02:39:53.899: INFO: Wrong image for pod: daemon-set-8wzmx. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Oct 25 02:39:53.899: INFO: Pod daemon-set-sljxf is not available
Oct 25 02:39:56.895: INFO: Pod daemon-set-n8qss is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Oct 25 02:39:56.930: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Oct 25 02:39:56.930: INFO: Node lab1-k8s-node-2 is running 0 daemon pod, expected 1
Oct 25 02:39:57.949: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Oct 25 02:39:57.949: INFO: Node lab1-k8s-node-2 is running 0 daemon pod, expected 1
Oct 25 02:39:58.949: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 6
Oct 25 02:39:58.949: INFO: Number of running nodes: 6, number of available pods: 6 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4305, will wait for the garbage collector to delete the pods
Oct 25 02:39:59.051: INFO: Deleting DaemonSet.extensions daemon-set took: 13.837814ms
Oct 25 02:39:59.152: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.696185ms
Oct 25 02:40:01.262: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:40:01.262: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct 25 02:40:01.267: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"230732"},"items":null}

Oct 25 02:40:01.273: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"230732"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:40:01.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4305" for this suite.

• [SLOW TEST:23.657 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":356,"completed":213,"skipped":3793,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version 
  should find the server version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:40:01.342: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename server-version
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should find the server version [Conformance]
  test/e2e/framework/framework.go:652
STEP: Request ServerVersion
STEP: Confirm major version
Oct 25 02:40:01.382: INFO: Major version: 1
STEP: Confirm minor version
Oct 25 02:40:01.382: INFO: cleanMinorVersion: 24
Oct 25 02:40:01.382: INFO: Minor version: 24
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:188
Oct 25 02:40:01.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-2584" for this suite.
•{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","total":356,"completed":214,"skipped":3874,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:40:01.405: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should support proxy with --port 0  [Conformance]
  test/e2e/framework/framework.go:652
STEP: starting the proxy server
Oct 25 02:40:01.461: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-8638 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 02:40:01.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8638" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":356,"completed":215,"skipped":3889,"failed":0}

------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:40:01.528: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7839
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a new StatefulSet
Oct 25 02:40:01.595: INFO: Found 0 stateful pods, waiting for 3
Oct 25 02:40:11.612: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 25 02:40:11.612: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 25 02:40:11.612: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct 25 02:40:11.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-7839 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 25 02:40:11.785: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 25 02:40:11.785: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 25 02:40:11.785: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Oct 25 02:40:21.844: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct 25 02:40:31.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-7839 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 25 02:40:32.037: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 25 02:40:32.037: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 25 02:40:32.037: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision
Oct 25 02:40:42.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-7839 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 25 02:40:42.231: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 25 02:40:42.231: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 25 02:40:42.231: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 25 02:40:52.295: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct 25 02:41:02.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=statefulset-7839 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 25 02:41:02.471: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 25 02:41:02.471: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 25 02:41:02.471: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct 25 02:41:12.514: INFO: Deleting all statefulset in ns statefulset-7839
Oct 25 02:41:12.519: INFO: Scaling statefulset ss2 to 0
Oct 25 02:41:22.555: INFO: Waiting for statefulset status.replicas updated to 0
Oct 25 02:41:22.560: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Oct 25 02:41:22.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7839" for this suite.

• [SLOW TEST:81.085 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":356,"completed":216,"skipped":3889,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:41:22.614: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1540
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Oct 25 02:41:22.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3561 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2'
Oct 25 02:41:22.749: INFO: stderr: ""
Oct 25 02:41:22.749: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1544
Oct 25 02:41:22.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3561 delete pods e2e-test-httpd-pod'
Oct 25 02:41:24.792: INFO: stderr: ""
Oct 25 02:41:24.792: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 02:41:24.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3561" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":356,"completed":217,"skipped":3891,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:41:24.817: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a cronjob
STEP: Ensuring more than one job is running at a time
STEP: Ensuring at least two running jobs exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Oct 25 02:43:00.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-7124" for this suite.

• [SLOW TEST:96.081 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","total":356,"completed":218,"skipped":3907,"failed":0}
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:43:00.898: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Oct 25 02:43:00.942: INFO: Waiting up to 5m0s for pod "downward-api-4ebad25e-85ff-4a1b-a8c6-241f8b6852e4" in namespace "downward-api-1457" to be "Succeeded or Failed"
Oct 25 02:43:00.949: INFO: Pod "downward-api-4ebad25e-85ff-4a1b-a8c6-241f8b6852e4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.837813ms
Oct 25 02:43:02.956: INFO: Pod "downward-api-4ebad25e-85ff-4a1b-a8c6-241f8b6852e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01377193s
Oct 25 02:43:04.968: INFO: Pod "downward-api-4ebad25e-85ff-4a1b-a8c6-241f8b6852e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026155361s
STEP: Saw pod success
Oct 25 02:43:04.968: INFO: Pod "downward-api-4ebad25e-85ff-4a1b-a8c6-241f8b6852e4" satisfied condition "Succeeded or Failed"
Oct 25 02:43:04.974: INFO: Trying to get logs from node lab1-k8s-node-2 pod downward-api-4ebad25e-85ff-4a1b-a8c6-241f8b6852e4 container dapi-container: <nil>
STEP: delete the pod
Oct 25 02:43:05.027: INFO: Waiting for pod downward-api-4ebad25e-85ff-4a1b-a8c6-241f8b6852e4 to disappear
Oct 25 02:43:05.034: INFO: Pod downward-api-4ebad25e-85ff-4a1b-a8c6-241f8b6852e4 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Oct 25 02:43:05.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1457" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":356,"completed":219,"skipped":3907,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:43:05.056: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Oct 25 02:43:05.088: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Oct 25 02:43:10.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4235" for this suite.

• [SLOW TEST:5.467 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":356,"completed":220,"skipped":3928,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:43:10.524: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Oct 25 02:43:10.553: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 02:43:18.642: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:43:36.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3550" for this suite.

• [SLOW TEST:26.043 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":356,"completed":221,"skipped":3944,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:43:36.570: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Oct 25 02:43:38.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-8748" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","total":356,"completed":222,"skipped":4032,"failed":0}
SSSSSSSS
------------------------------
[sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:43:38.743: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating server pod server in namespace prestop-1345
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-1345
STEP: Deleting pre-stop pod
Oct 25 02:43:47.889: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:188
Oct 25 02:43:47.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-1345" for this suite.

• [SLOW TEST:9.200 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":356,"completed":223,"skipped":4040,"failed":0}
SSSSS
------------------------------
[sig-apps] CronJob 
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:43:47.943: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename cronjob
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ForbidConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring no more jobs are scheduled
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Oct 25 02:49:02.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-8445" for this suite.

• [SLOW TEST:314.133 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","total":356,"completed":224,"skipped":4045,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:49:02.076: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct 25 02:49:02.192: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6206  cc9e2724-4d73-49ea-88c6-7fcc5778f911 233214 0 2022-10-25 02:49:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-10-25 02:49:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 25 02:49:02.193: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6206  cc9e2724-4d73-49ea-88c6-7fcc5778f911 233215 0 2022-10-25 02:49:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-10-25 02:49:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 25 02:49:02.193: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6206  cc9e2724-4d73-49ea-88c6-7fcc5778f911 233216 0 2022-10-25 02:49:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-10-25 02:49:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct 25 02:49:12.271: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6206  cc9e2724-4d73-49ea-88c6-7fcc5778f911 233267 0 2022-10-25 02:49:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-10-25 02:49:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 25 02:49:12.271: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6206  cc9e2724-4d73-49ea-88c6-7fcc5778f911 233268 0 2022-10-25 02:49:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-10-25 02:49:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 25 02:49:12.271: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6206  cc9e2724-4d73-49ea-88c6-7fcc5778f911 233269 0 2022-10-25 02:49:02 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-10-25 02:49:02 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Oct 25 02:49:12.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6206" for this suite.

• [SLOW TEST:10.218 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":356,"completed":225,"skipped":4102,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:49:12.297: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:49:12.339: INFO: Creating pod...
Oct 25 02:49:14.374: INFO: Creating service...
Oct 25 02:49:14.395: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3980/pods/agnhost/proxy/some/path/with/DELETE
Oct 25 02:49:14.406: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Oct 25 02:49:14.406: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3980/pods/agnhost/proxy/some/path/with/GET
Oct 25 02:49:14.414: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Oct 25 02:49:14.414: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3980/pods/agnhost/proxy/some/path/with/HEAD
Oct 25 02:49:14.420: INFO: http.Client request:HEAD | StatusCode:200
Oct 25 02:49:14.420: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3980/pods/agnhost/proxy/some/path/with/OPTIONS
Oct 25 02:49:14.427: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Oct 25 02:49:14.427: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3980/pods/agnhost/proxy/some/path/with/PATCH
Oct 25 02:49:14.436: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Oct 25 02:49:14.436: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3980/pods/agnhost/proxy/some/path/with/POST
Oct 25 02:49:14.443: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Oct 25 02:49:14.443: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3980/pods/agnhost/proxy/some/path/with/PUT
Oct 25 02:49:14.450: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Oct 25 02:49:14.450: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3980/services/test-service/proxy/some/path/with/DELETE
Oct 25 02:49:14.460: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Oct 25 02:49:14.460: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3980/services/test-service/proxy/some/path/with/GET
Oct 25 02:49:14.473: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Oct 25 02:49:14.475: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3980/services/test-service/proxy/some/path/with/HEAD
Oct 25 02:49:14.486: INFO: http.Client request:HEAD | StatusCode:200
Oct 25 02:49:14.486: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3980/services/test-service/proxy/some/path/with/OPTIONS
Oct 25 02:49:14.498: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Oct 25 02:49:14.498: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3980/services/test-service/proxy/some/path/with/PATCH
Oct 25 02:49:14.510: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Oct 25 02:49:14.510: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3980/services/test-service/proxy/some/path/with/POST
Oct 25 02:49:14.521: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Oct 25 02:49:14.521: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-3980/services/test-service/proxy/some/path/with/PUT
Oct 25 02:49:14.533: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Oct 25 02:49:14.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3980" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","total":356,"completed":226,"skipped":4122,"failed":0}
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:49:14.558: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:49:14.598: INFO: Creating pod...
Oct 25 02:49:16.629: INFO: Creating service...
Oct 25 02:49:16.649: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8168/pods/agnhost/proxy?method=DELETE
Oct 25 02:49:16.658: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Oct 25 02:49:16.658: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8168/pods/agnhost/proxy?method=OPTIONS
Oct 25 02:49:16.666: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Oct 25 02:49:16.666: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8168/pods/agnhost/proxy?method=PATCH
Oct 25 02:49:16.674: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Oct 25 02:49:16.674: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8168/pods/agnhost/proxy?method=POST
Oct 25 02:49:16.681: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Oct 25 02:49:16.681: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8168/pods/agnhost/proxy?method=PUT
Oct 25 02:49:16.689: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Oct 25 02:49:16.689: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8168/services/e2e-proxy-test-service/proxy?method=DELETE
Oct 25 02:49:16.700: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Oct 25 02:49:16.700: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8168/services/e2e-proxy-test-service/proxy?method=OPTIONS
Oct 25 02:49:16.711: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Oct 25 02:49:16.711: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8168/services/e2e-proxy-test-service/proxy?method=PATCH
Oct 25 02:49:16.732: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Oct 25 02:49:16.732: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8168/services/e2e-proxy-test-service/proxy?method=POST
Oct 25 02:49:16.763: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Oct 25 02:49:16.763: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8168/services/e2e-proxy-test-service/proxy?method=PUT
Oct 25 02:49:16.779: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Oct 25 02:49:16.779: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8168/pods/agnhost/proxy?method=GET
Oct 25 02:49:16.791: INFO: http.Client request:GET StatusCode:301
Oct 25 02:49:16.791: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8168/services/e2e-proxy-test-service/proxy?method=GET
Oct 25 02:49:16.807: INFO: http.Client request:GET StatusCode:301
Oct 25 02:49:16.807: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8168/pods/agnhost/proxy?method=HEAD
Oct 25 02:49:16.815: INFO: http.Client request:HEAD StatusCode:301
Oct 25 02:49:16.815: INFO: Starting http.Client for https://10.233.0.1:443/api/v1/namespaces/proxy-8168/services/e2e-proxy-test-service/proxy?method=HEAD
Oct 25 02:49:16.829: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Oct 25 02:49:16.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8168" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","total":356,"completed":227,"skipped":4129,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:49:16.853: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-1b6a2162-d098-44fa-9507-514eb6f0b77b in namespace container-probe-1087
Oct 25 02:49:18.928: INFO: Started pod liveness-1b6a2162-d098-44fa-9507-514eb6f0b77b in namespace container-probe-1087
STEP: checking the pod's current state and verifying that restartCount is present
Oct 25 02:49:18.935: INFO: Initial restart count of pod liveness-1b6a2162-d098-44fa-9507-514eb6f0b77b is 0
Oct 25 02:49:39.074: INFO: Restart count of pod container-probe-1087/liveness-1b6a2162-d098-44fa-9507-514eb6f0b77b is now 1 (20.139480028s elapsed)
Oct 25 02:49:59.198: INFO: Restart count of pod container-probe-1087/liveness-1b6a2162-d098-44fa-9507-514eb6f0b77b is now 2 (40.262656998s elapsed)
Oct 25 02:50:19.324: INFO: Restart count of pod container-probe-1087/liveness-1b6a2162-d098-44fa-9507-514eb6f0b77b is now 3 (1m0.388685846s elapsed)
Oct 25 02:50:39.453: INFO: Restart count of pod container-probe-1087/liveness-1b6a2162-d098-44fa-9507-514eb6f0b77b is now 4 (1m20.518392395s elapsed)
Oct 25 02:51:47.893: INFO: Restart count of pod container-probe-1087/liveness-1b6a2162-d098-44fa-9507-514eb6f0b77b is now 5 (2m28.958058818s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Oct 25 02:51:47.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1087" for this suite.

• [SLOW TEST:151.107 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":356,"completed":228,"skipped":4137,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:51:47.966: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5787.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-5787.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5787.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-5787.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 25 02:51:50.096: INFO: DNS probes using dns-5787/dns-test-c0214b52-a70b-4cad-ade2-c447069453cb succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Oct 25 02:51:50.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5787" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","total":356,"completed":229,"skipped":4161,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:51:50.166: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1412
STEP: creating an pod
Oct 25 02:51:50.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6922 run logs-generator --image=k8s.gcr.io/e2e-test-images/agnhost:2.39 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Oct 25 02:51:50.302: INFO: stderr: ""
Oct 25 02:51:50.302: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for log generator to start.
Oct 25 02:51:50.302: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Oct 25 02:51:50.302: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-6922" to be "running and ready, or succeeded"
Oct 25 02:51:50.312: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 10.397228ms
Oct 25 02:51:52.321: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.018944301s
Oct 25 02:51:52.321: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Oct 25 02:51:52.321: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Oct 25 02:51:52.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6922 logs logs-generator logs-generator'
Oct 25 02:51:52.402: INFO: stderr: ""
Oct 25 02:51:52.402: INFO: stdout: "I1025 02:51:51.060087       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/bhm4 321\nI1025 02:51:51.260914       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/tpb 593\nI1025 02:51:51.460213       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/26qr 332\nI1025 02:51:51.660583       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/gnk 313\nI1025 02:51:51.860959       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/cc4v 239\nI1025 02:51:52.060236       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/7cs 599\nI1025 02:51:52.260573       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/kt9h 300\n"
STEP: limiting log lines
Oct 25 02:51:52.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6922 logs logs-generator logs-generator --tail=1'
Oct 25 02:51:52.490: INFO: stderr: ""
Oct 25 02:51:52.490: INFO: stdout: "I1025 02:51:52.460949       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/dlbw 219\n"
Oct 25 02:51:52.490: INFO: got output "I1025 02:51:52.460949       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/dlbw 219\n"
STEP: limiting log bytes
Oct 25 02:51:52.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6922 logs logs-generator logs-generator --limit-bytes=1'
Oct 25 02:51:52.586: INFO: stderr: ""
Oct 25 02:51:52.586: INFO: stdout: "I"
Oct 25 02:51:52.586: INFO: got output "I"
STEP: exposing timestamps
Oct 25 02:51:52.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6922 logs logs-generator logs-generator --tail=1 --timestamps'
Oct 25 02:51:52.657: INFO: stderr: ""
Oct 25 02:51:52.657: INFO: stdout: "2022-10-25T02:51:52.660345448Z I1025 02:51:52.660239       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/wkx 278\n"
Oct 25 02:51:52.657: INFO: got output "2022-10-25T02:51:52.660345448Z I1025 02:51:52.660239       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/wkx 278\n"
STEP: restricting to a time range
Oct 25 02:51:55.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6922 logs logs-generator logs-generator --since=1s'
Oct 25 02:51:55.244: INFO: stderr: ""
Oct 25 02:51:55.244: INFO: stdout: "I1025 02:51:54.260982       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/4bfg 204\nI1025 02:51:54.460183       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/ndg 501\nI1025 02:51:54.660578       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/jd9 414\nI1025 02:51:54.860927       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/hk6 386\nI1025 02:51:55.060233       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/g29t 588\n"
Oct 25 02:51:55.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6922 logs logs-generator logs-generator --since=24h'
Oct 25 02:51:55.319: INFO: stderr: ""
Oct 25 02:51:55.319: INFO: stdout: "I1025 02:51:51.060087       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/bhm4 321\nI1025 02:51:51.260914       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/tpb 593\nI1025 02:51:51.460213       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/26qr 332\nI1025 02:51:51.660583       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/gnk 313\nI1025 02:51:51.860959       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/cc4v 239\nI1025 02:51:52.060236       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/7cs 599\nI1025 02:51:52.260573       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/kt9h 300\nI1025 02:51:52.460949       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/dlbw 219\nI1025 02:51:52.660239       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/wkx 278\nI1025 02:51:52.860750       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/b5w7 433\nI1025 02:51:53.060968       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/kube-system/pods/nzch 554\nI1025 02:51:53.260180       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/9c8z 441\nI1025 02:51:53.460541       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/nb8 445\nI1025 02:51:53.660864       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/vwv2 520\nI1025 02:51:53.860161       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/kube-system/pods/h87x 415\nI1025 02:51:54.060188       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/5jnh 395\nI1025 02:51:54.260982       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/4bfg 204\nI1025 02:51:54.460183       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/ndg 501\nI1025 02:51:54.660578       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/jd9 414\nI1025 02:51:54.860927       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/hk6 386\nI1025 02:51:55.060233       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/g29t 588\nI1025 02:51:55.260392       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/29z 234\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1417
Oct 25 02:51:55.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6922 delete pod logs-generator'
Oct 25 02:51:56.026: INFO: stderr: ""
Oct 25 02:51:56.026: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 02:51:56.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6922" for this suite.

• [SLOW TEST:5.887 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1409
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":356,"completed":230,"skipped":4188,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:51:56.053: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 02:51:56.473: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 02:51:59.517: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:51:59.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8179" for this suite.
STEP: Destroying namespace "webhook-8179-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":356,"completed":231,"skipped":4190,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff 
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:51:59.785: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/framework/framework.go:652
STEP: create deployment with httpd image
Oct 25 02:51:59.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-9532 create -f -'
Oct 25 02:52:00.474: INFO: stderr: ""
Oct 25 02:52:00.474: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image
Oct 25 02:52:00.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-9532 diff -f -'
Oct 25 02:52:01.286: INFO: rc: 1
Oct 25 02:52:01.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-9532 delete -f -'
Oct 25 02:52:01.362: INFO: stderr: ""
Oct 25 02:52:01.362: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 02:52:01.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9532" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","total":356,"completed":232,"skipped":4241,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:52:01.398: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Oct 25 02:52:17.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2112" for this suite.

• [SLOW TEST:16.294 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":356,"completed":233,"skipped":4243,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:52:17.693: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a ReplicaSet
STEP: Verify that the required pods have come up
Oct 25 02:52:17.749: INFO: Pod name sample-pod: Found 0 pods out of 3
Oct 25 02:52:22.758: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running
Oct 25 02:52:22.764: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets
STEP: DeleteCollection of the ReplicaSets
STEP: After DeleteCollection verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Oct 25 02:52:22.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2500" for this suite.

• [SLOW TEST:5.167 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","total":356,"completed":234,"skipped":4325,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:52:22.863: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Oct 25 02:52:22.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7040" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":356,"completed":235,"skipped":4357,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:52:22.995: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-bbcb1985-7271-4ebd-b406-bb54568288c5
STEP: Creating a pod to test consume configMaps
Oct 25 02:52:23.062: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7de4de7e-5ca6-456b-8b21-d00072fc9497" in namespace "projected-1890" to be "Succeeded or Failed"
Oct 25 02:52:23.078: INFO: Pod "pod-projected-configmaps-7de4de7e-5ca6-456b-8b21-d00072fc9497": Phase="Pending", Reason="", readiness=false. Elapsed: 15.377655ms
Oct 25 02:52:25.091: INFO: Pod "pod-projected-configmaps-7de4de7e-5ca6-456b-8b21-d00072fc9497": Phase="Running", Reason="", readiness=false. Elapsed: 2.029020597s
Oct 25 02:52:27.108: INFO: Pod "pod-projected-configmaps-7de4de7e-5ca6-456b-8b21-d00072fc9497": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046080305s
STEP: Saw pod success
Oct 25 02:52:27.108: INFO: Pod "pod-projected-configmaps-7de4de7e-5ca6-456b-8b21-d00072fc9497" satisfied condition "Succeeded or Failed"
Oct 25 02:52:27.114: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-projected-configmaps-7de4de7e-5ca6-456b-8b21-d00072fc9497 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 25 02:52:27.145: INFO: Waiting for pod pod-projected-configmaps-7de4de7e-5ca6-456b-8b21-d00072fc9497 to disappear
Oct 25 02:52:27.151: INFO: Pod pod-projected-configmaps-7de4de7e-5ca6-456b-8b21-d00072fc9497 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Oct 25 02:52:27.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1890" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":356,"completed":236,"skipped":4375,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:52:27.171: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a test event
STEP: listing all events in all namespaces
STEP: patching the test event
STEP: fetching the test event
STEP: deleting the test event
STEP: listing all events in all namespaces
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:188
Oct 25 02:52:27.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7096" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":356,"completed":237,"skipped":4396,"failed":0}

------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:52:27.281: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Oct 25 02:52:27.347: INFO: The status of Pod labelsupdatea7dd13c3-0e5e-44b3-8c1f-ad935ce6637c is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:52:29.360: INFO: The status of Pod labelsupdatea7dd13c3-0e5e-44b3-8c1f-ad935ce6637c is Running (Ready = true)
Oct 25 02:52:29.900: INFO: Successfully updated pod "labelsupdatea7dd13c3-0e5e-44b3-8c1f-ad935ce6637c"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Oct 25 02:52:33.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2839" for this suite.

• [SLOW TEST:6.685 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":356,"completed":238,"skipped":4396,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:52:33.967: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 02:52:34.467: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 02:52:37.508: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:52:37.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-649" for this suite.
STEP: Destroying namespace "webhook-649-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":356,"completed":239,"skipped":4413,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:52:37.759: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir volume type on node default medium
Oct 25 02:52:37.827: INFO: Waiting up to 5m0s for pod "pod-63f741e8-050f-4e0d-ac94-df5f955c2f1a" in namespace "emptydir-4179" to be "Succeeded or Failed"
Oct 25 02:52:37.839: INFO: Pod "pod-63f741e8-050f-4e0d-ac94-df5f955c2f1a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.193425ms
Oct 25 02:52:39.851: INFO: Pod "pod-63f741e8-050f-4e0d-ac94-df5f955c2f1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023478175s
Oct 25 02:52:41.864: INFO: Pod "pod-63f741e8-050f-4e0d-ac94-df5f955c2f1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036648649s
STEP: Saw pod success
Oct 25 02:52:41.864: INFO: Pod "pod-63f741e8-050f-4e0d-ac94-df5f955c2f1a" satisfied condition "Succeeded or Failed"
Oct 25 02:52:41.871: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-63f741e8-050f-4e0d-ac94-df5f955c2f1a container test-container: <nil>
STEP: delete the pod
Oct 25 02:52:41.903: INFO: Waiting for pod pod-63f741e8-050f-4e0d-ac94-df5f955c2f1a to disappear
Oct 25 02:52:41.909: INFO: Pod pod-63f741e8-050f-4e0d-ac94-df5f955c2f1a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 02:52:41.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4179" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":240,"skipped":4457,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:52:41.936: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-6563
STEP: creating service affinity-nodeport in namespace services-6563
STEP: creating replication controller affinity-nodeport in namespace services-6563
I1025 02:52:42.018135      18 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-6563, replica count: 3
I1025 02:52:45.068683      18 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 25 02:52:45.100: INFO: Creating new exec pod
Oct 25 02:52:48.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-6563 exec execpod-affinitykwgd2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Oct 25 02:52:48.311: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Oct 25 02:52:48.311: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 02:52:48.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-6563 exec execpod-affinitykwgd2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.50.63 80'
Oct 25 02:52:48.448: INFO: stderr: "+ nc -v -t -w 2 10.233.50.63 80\n+ echo hostName\nConnection to 10.233.50.63 80 port [tcp/http] succeeded!\n"
Oct 25 02:52:48.448: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 02:52:48.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-6563 exec execpod-affinitykwgd2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.1.178 31776'
Oct 25 02:52:48.587: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.128.1.178 31776\nConnection to 10.128.1.178 31776 port [tcp/*] succeeded!\n"
Oct 25 02:52:48.587: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 02:52:48.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-6563 exec execpod-affinitykwgd2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.0.176 31776'
Oct 25 02:52:48.731: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.128.0.176 31776\nConnection to 10.128.0.176 31776 port [tcp/*] succeeded!\n"
Oct 25 02:52:48.731: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 02:52:48.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-6563 exec execpod-affinitykwgd2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.128.0.176:31776/ ; done'
Oct 25 02:52:48.971: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:31776/\n"
Oct 25 02:52:48.971: INFO: stdout: "\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h\naffinity-nodeport-5cb8h"
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Received response from host: affinity-nodeport-5cb8h
Oct 25 02:52:48.971: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-6563, will wait for the garbage collector to delete the pods
Oct 25 02:52:49.080: INFO: Deleting ReplicationController affinity-nodeport took: 11.445371ms
Oct 25 02:52:49.180: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.428434ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 02:52:51.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6563" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:9.446 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":241,"skipped":4472,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces 
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:52:51.382: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:52:51.425: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename disruption-2
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: listing a collection of PDBs across all namespaces
STEP: listing a collection of PDBs in namespace disruption-5391
STEP: deleting a collection of PDBs
STEP: Waiting for the PDB collection to be deleted
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:188
Oct 25 02:52:57.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-7635" for this suite.
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Oct 25 02:52:57.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-5391" for this suite.

• [SLOW TEST:6.251 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","total":356,"completed":242,"skipped":4481,"failed":0}
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:52:57.633: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 02:52:57.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7896" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":356,"completed":243,"skipped":4482,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:52:57.754: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:52:57.839: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"0b568ec0-4ab0-4cab-93f9-f240e869607f", Controller:(*bool)(0xc0042141ca), BlockOwnerDeletion:(*bool)(0xc0042141cb)}}
Oct 25 02:52:57.850: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"722a06b8-1be4-494c-960a-5edf7e4497c8", Controller:(*bool)(0xc004214432), BlockOwnerDeletion:(*bool)(0xc004214433)}}
Oct 25 02:52:57.862: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"2152ecc2-576c-4a20-88b9-26ad359bdba6", Controller:(*bool)(0xc004214672), BlockOwnerDeletion:(*bool)(0xc004214673)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Oct 25 02:53:02.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6192" for this suite.

• [SLOW TEST:5.182 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":356,"completed":244,"skipped":4502,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:53:02.938: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:297
[It] should create and stop a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a replication controller
Oct 25 02:53:02.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-5271 create -f -'
Oct 25 02:53:03.182: INFO: stderr: ""
Oct 25 02:53:03.182: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 25 02:53:03.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-5271 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 25 02:53:03.256: INFO: stderr: ""
Oct 25 02:53:03.256: INFO: stdout: "update-demo-nautilus-f952s update-demo-nautilus-t27db "
Oct 25 02:53:03.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-5271 get pods update-demo-nautilus-f952s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 25 02:53:03.322: INFO: stderr: ""
Oct 25 02:53:03.322: INFO: stdout: ""
Oct 25 02:53:03.322: INFO: update-demo-nautilus-f952s is created but not running
Oct 25 02:53:08.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-5271 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Oct 25 02:53:08.391: INFO: stderr: ""
Oct 25 02:53:08.391: INFO: stdout: "update-demo-nautilus-f952s update-demo-nautilus-t27db "
Oct 25 02:53:08.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-5271 get pods update-demo-nautilus-f952s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 25 02:53:08.465: INFO: stderr: ""
Oct 25 02:53:08.465: INFO: stdout: "true"
Oct 25 02:53:08.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-5271 get pods update-demo-nautilus-f952s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct 25 02:53:08.536: INFO: stderr: ""
Oct 25 02:53:08.536: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Oct 25 02:53:08.536: INFO: validating pod update-demo-nautilus-f952s
Oct 25 02:53:08.545: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 25 02:53:08.545: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 25 02:53:08.545: INFO: update-demo-nautilus-f952s is verified up and running
Oct 25 02:53:08.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-5271 get pods update-demo-nautilus-t27db -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Oct 25 02:53:08.602: INFO: stderr: ""
Oct 25 02:53:08.602: INFO: stdout: "true"
Oct 25 02:53:08.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-5271 get pods update-demo-nautilus-t27db -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Oct 25 02:53:08.664: INFO: stderr: ""
Oct 25 02:53:08.664: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Oct 25 02:53:08.664: INFO: validating pod update-demo-nautilus-t27db
Oct 25 02:53:08.674: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 25 02:53:08.674: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 25 02:53:08.674: INFO: update-demo-nautilus-t27db is verified up and running
STEP: using delete to clean up resources
Oct 25 02:53:08.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-5271 delete --grace-period=0 --force -f -'
Oct 25 02:53:08.739: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 25 02:53:08.739: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 25 02:53:08.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-5271 get rc,svc -l name=update-demo --no-headers'
Oct 25 02:53:08.867: INFO: stderr: "No resources found in kubectl-5271 namespace.\n"
Oct 25 02:53:08.867: INFO: stdout: ""
Oct 25 02:53:08.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-5271 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 25 02:53:08.952: INFO: stderr: ""
Oct 25 02:53:08.952: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 02:53:08.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5271" for this suite.

• [SLOW TEST:6.043 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:295
    should create and stop a replication controller  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":356,"completed":245,"skipped":4545,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:53:08.980: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-8863
STEP: creating service affinity-clusterip in namespace services-8863
STEP: creating replication controller affinity-clusterip in namespace services-8863
I1025 02:53:09.055698      18 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-8863, replica count: 3
I1025 02:53:12.115066      18 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 25 02:53:12.138: INFO: Creating new exec pod
Oct 25 02:53:15.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-8863 exec execpod-affinityvcwrg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Oct 25 02:53:15.336: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Oct 25 02:53:15.336: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 02:53:15.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-8863 exec execpod-affinityvcwrg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.62.206 80'
Oct 25 02:53:15.488: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.62.206 80\nConnection to 10.233.62.206 80 port [tcp/http] succeeded!\n"
Oct 25 02:53:15.488: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 02:53:15.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-8863 exec execpod-affinityvcwrg -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.233.62.206:80/ ; done'
Oct 25 02:53:15.716: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.233.62.206:80/\n"
Oct 25 02:53:15.716: INFO: stdout: "\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm\naffinity-clusterip-r7hjm"
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Received response from host: affinity-clusterip-r7hjm
Oct 25 02:53:15.716: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-8863, will wait for the garbage collector to delete the pods
Oct 25 02:53:15.834: INFO: Deleting ReplicationController affinity-clusterip took: 14.615091ms
Oct 25 02:53:15.935: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.776669ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 02:53:18.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8863" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:9.442 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":246,"skipped":4566,"failed":0}
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:53:18.423: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Oct 25 02:53:18.485: INFO: The status of Pod annotationupdatec6b3023f-cc65-42c6-a18d-e2bcb9603c11 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:53:20.497: INFO: The status of Pod annotationupdatec6b3023f-cc65-42c6-a18d-e2bcb9603c11 is Running (Ready = true)
Oct 25 02:53:21.043: INFO: Successfully updated pod "annotationupdatec6b3023f-cc65-42c6-a18d-e2bcb9603c11"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Oct 25 02:53:25.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7694" for this suite.

• [SLOW TEST:6.702 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":356,"completed":247,"skipped":4571,"failed":0}
SSS
------------------------------
[sig-node] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:53:25.126: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:53:25.171: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: creating the pod
STEP: submitting the pod to kubernetes
Oct 25 02:53:25.199: INFO: The status of Pod pod-logs-websocket-f424dadf-ffb3-440e-a810-7451fe25a8c9 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:53:27.214: INFO: The status of Pod pod-logs-websocket-f424dadf-ffb3-440e-a810-7451fe25a8c9 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Oct 25 02:53:27.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5239" for this suite.
•{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":356,"completed":248,"skipped":4574,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:53:27.272: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-ff17ad21-3f13-4585-b64a-f9be95036227
STEP: Creating a pod to test consume configMaps
Oct 25 02:53:27.333: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-70adfd5d-8385-46ab-94a3-d4dbe587ddf2" in namespace "projected-1265" to be "Succeeded or Failed"
Oct 25 02:53:27.343: INFO: Pod "pod-projected-configmaps-70adfd5d-8385-46ab-94a3-d4dbe587ddf2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.79107ms
Oct 25 02:53:29.356: INFO: Pod "pod-projected-configmaps-70adfd5d-8385-46ab-94a3-d4dbe587ddf2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02306471s
Oct 25 02:53:31.367: INFO: Pod "pod-projected-configmaps-70adfd5d-8385-46ab-94a3-d4dbe587ddf2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03412934s
STEP: Saw pod success
Oct 25 02:53:31.367: INFO: Pod "pod-projected-configmaps-70adfd5d-8385-46ab-94a3-d4dbe587ddf2" satisfied condition "Succeeded or Failed"
Oct 25 02:53:31.374: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-projected-configmaps-70adfd5d-8385-46ab-94a3-d4dbe587ddf2 container agnhost-container: <nil>
STEP: delete the pod
Oct 25 02:53:31.423: INFO: Waiting for pod pod-projected-configmaps-70adfd5d-8385-46ab-94a3-d4dbe587ddf2 to disappear
Oct 25 02:53:31.429: INFO: Pod pod-projected-configmaps-70adfd5d-8385-46ab-94a3-d4dbe587ddf2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Oct 25 02:53:31.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1265" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":249,"skipped":4609,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:53:31.449: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-secret-rqzz
STEP: Creating a pod to test atomic-volume-subpath
Oct 25 02:53:31.521: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-rqzz" in namespace "subpath-6468" to be "Succeeded or Failed"
Oct 25 02:53:31.526: INFO: Pod "pod-subpath-test-secret-rqzz": Phase="Pending", Reason="", readiness=false. Elapsed: 5.331918ms
Oct 25 02:53:33.536: INFO: Pod "pod-subpath-test-secret-rqzz": Phase="Running", Reason="", readiness=true. Elapsed: 2.014698158s
Oct 25 02:53:35.547: INFO: Pod "pod-subpath-test-secret-rqzz": Phase="Running", Reason="", readiness=true. Elapsed: 4.025893429s
Oct 25 02:53:37.559: INFO: Pod "pod-subpath-test-secret-rqzz": Phase="Running", Reason="", readiness=true. Elapsed: 6.037823064s
Oct 25 02:53:39.571: INFO: Pod "pod-subpath-test-secret-rqzz": Phase="Running", Reason="", readiness=true. Elapsed: 8.05005107s
Oct 25 02:53:41.583: INFO: Pod "pod-subpath-test-secret-rqzz": Phase="Running", Reason="", readiness=true. Elapsed: 10.062351489s
Oct 25 02:53:43.592: INFO: Pod "pod-subpath-test-secret-rqzz": Phase="Running", Reason="", readiness=true. Elapsed: 12.071291149s
Oct 25 02:53:45.606: INFO: Pod "pod-subpath-test-secret-rqzz": Phase="Running", Reason="", readiness=true. Elapsed: 14.085067581s
Oct 25 02:53:47.622: INFO: Pod "pod-subpath-test-secret-rqzz": Phase="Running", Reason="", readiness=true. Elapsed: 16.101360117s
Oct 25 02:53:49.637: INFO: Pod "pod-subpath-test-secret-rqzz": Phase="Running", Reason="", readiness=true. Elapsed: 18.115944725s
Oct 25 02:53:51.653: INFO: Pod "pod-subpath-test-secret-rqzz": Phase="Running", Reason="", readiness=true. Elapsed: 20.131626747s
Oct 25 02:53:53.662: INFO: Pod "pod-subpath-test-secret-rqzz": Phase="Running", Reason="", readiness=false. Elapsed: 22.141126899s
Oct 25 02:53:55.676: INFO: Pod "pod-subpath-test-secret-rqzz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.155153472s
STEP: Saw pod success
Oct 25 02:53:55.676: INFO: Pod "pod-subpath-test-secret-rqzz" satisfied condition "Succeeded or Failed"
Oct 25 02:53:55.685: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-subpath-test-secret-rqzz container test-container-subpath-secret-rqzz: <nil>
STEP: delete the pod
Oct 25 02:53:55.721: INFO: Waiting for pod pod-subpath-test-secret-rqzz to disappear
Oct 25 02:53:55.726: INFO: Pod pod-subpath-test-secret-rqzz no longer exists
STEP: Deleting pod pod-subpath-test-secret-rqzz
Oct 25 02:53:55.727: INFO: Deleting pod "pod-subpath-test-secret-rqzz" in namespace "subpath-6468"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Oct 25 02:53:55.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6468" for this suite.

• [SLOW TEST:24.307 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","total":356,"completed":250,"skipped":4619,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:53:55.760: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Namespace
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:53:55.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8223" for this suite.
STEP: Destroying namespace "nspatchtest-f816d101-837e-4ea4-8362-aeac14315d35-5304" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":356,"completed":251,"skipped":4668,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:53:55.884: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 02:53:55.929: INFO: Waiting up to 5m0s for pod "downwardapi-volume-388bde8c-e3cf-4a79-8fd0-ded06950a00b" in namespace "projected-1194" to be "Succeeded or Failed"
Oct 25 02:53:55.934: INFO: Pod "downwardapi-volume-388bde8c-e3cf-4a79-8fd0-ded06950a00b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.019531ms
Oct 25 02:53:57.948: INFO: Pod "downwardapi-volume-388bde8c-e3cf-4a79-8fd0-ded06950a00b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018394024s
Oct 25 02:53:59.959: INFO: Pod "downwardapi-volume-388bde8c-e3cf-4a79-8fd0-ded06950a00b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030127739s
STEP: Saw pod success
Oct 25 02:53:59.959: INFO: Pod "downwardapi-volume-388bde8c-e3cf-4a79-8fd0-ded06950a00b" satisfied condition "Succeeded or Failed"
Oct 25 02:53:59.965: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-388bde8c-e3cf-4a79-8fd0-ded06950a00b container client-container: <nil>
STEP: delete the pod
Oct 25 02:53:59.997: INFO: Waiting for pod downwardapi-volume-388bde8c-e3cf-4a79-8fd0-ded06950a00b to disappear
Oct 25 02:54:00.002: INFO: Pod downwardapi-volume-388bde8c-e3cf-4a79-8fd0-ded06950a00b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Oct 25 02:54:00.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1194" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":252,"skipped":4682,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:54:00.033: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 02:54:00.096: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a04bf29-dd5c-4a10-82b3-53e827e480b9" in namespace "downward-api-7825" to be "Succeeded or Failed"
Oct 25 02:54:00.103: INFO: Pod "downwardapi-volume-4a04bf29-dd5c-4a10-82b3-53e827e480b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.299573ms
Oct 25 02:54:02.114: INFO: Pod "downwardapi-volume-4a04bf29-dd5c-4a10-82b3-53e827e480b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017804713s
Oct 25 02:54:04.125: INFO: Pod "downwardapi-volume-4a04bf29-dd5c-4a10-82b3-53e827e480b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028794031s
STEP: Saw pod success
Oct 25 02:54:04.126: INFO: Pod "downwardapi-volume-4a04bf29-dd5c-4a10-82b3-53e827e480b9" satisfied condition "Succeeded or Failed"
Oct 25 02:54:04.131: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-4a04bf29-dd5c-4a10-82b3-53e827e480b9 container client-container: <nil>
STEP: delete the pod
Oct 25 02:54:04.168: INFO: Waiting for pod downwardapi-volume-4a04bf29-dd5c-4a10-82b3-53e827e480b9 to disappear
Oct 25 02:54:04.174: INFO: Pod downwardapi-volume-4a04bf29-dd5c-4a10-82b3-53e827e480b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Oct 25 02:54:04.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7825" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":253,"skipped":4736,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:54:04.196: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating Indexed job
STEP: Ensuring job reaches completions
STEP: Ensuring pods with index for job exist
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Oct 25 02:54:12.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2470" for this suite.

• [SLOW TEST:8.101 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","total":356,"completed":254,"skipped":4796,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:54:12.298: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7630
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-7630
I1025 02:54:12.392595      18 runners.go:193] Created replication controller with name: externalname-service, namespace: services-7630, replica count: 2
Oct 25 02:54:15.446: INFO: Creating new exec pod
I1025 02:54:15.446013      18 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 25 02:54:18.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-7630 exec execpodks8x4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Oct 25 02:54:18.642: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct 25 02:54:18.642: INFO: stdout: "externalname-service-d5gcr"
Oct 25 02:54:18.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-7630 exec execpodks8x4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.26.93 80'
Oct 25 02:54:18.771: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.26.93 80\nConnection to 10.233.26.93 80 port [tcp/http] succeeded!\n"
Oct 25 02:54:18.771: INFO: stdout: ""
Oct 25 02:54:19.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-7630 exec execpodks8x4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.26.93 80'
Oct 25 02:54:19.926: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.26.93 80\nConnection to 10.233.26.93 80 port [tcp/http] succeeded!\n"
Oct 25 02:54:19.926: INFO: stdout: "externalname-service-d5gcr"
Oct 25 02:54:19.926: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 02:54:19.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7630" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:7.703 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":356,"completed":255,"skipped":4815,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:54:20.001: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct 25 02:54:20.051: INFO: Pod name pod-release: Found 0 pods out of 1
Oct 25 02:54:25.066: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Oct 25 02:54:25.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8493" for this suite.

• [SLOW TEST:5.146 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":356,"completed":256,"skipped":4839,"failed":0}
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:54:25.147: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3255
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:54:25.222: INFO: Found 0 stateful pods, waiting for 1
Oct 25 02:54:35.238: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet
Oct 25 02:54:35.294: INFO: Found 1 stateful pods, waiting for 2
Oct 25 02:54:45.311: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 25 02:54:45.311: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets
STEP: Delete all of the StatefulSets
STEP: Verify that StatefulSets have been deleted
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct 25 02:54:45.358: INFO: Deleting all statefulset in ns statefulset-3255
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Oct 25 02:54:45.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3255" for this suite.

• [SLOW TEST:20.273 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","total":356,"completed":257,"skipped":4842,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:54:45.421: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 02:54:45.856: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 02:54:48.918: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:54:48.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9861" for this suite.
STEP: Destroying namespace "webhook-9861-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":356,"completed":258,"skipped":4856,"failed":0}
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:54:49.100: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6543
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/framework/framework.go:652
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6543
STEP: Waiting until pod test-pod will start running in namespace statefulset-6543
STEP: Creating statefulset with conflicting port in namespace statefulset-6543
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6543
Oct 25 02:54:53.243: INFO: Observed stateful pod in namespace: statefulset-6543, name: ss-0, uid: d47ab21a-90df-4363-8123-050b74305e95, status phase: Pending. Waiting for statefulset controller to delete.
Oct 25 02:54:53.274: INFO: Observed stateful pod in namespace: statefulset-6543, name: ss-0, uid: d47ab21a-90df-4363-8123-050b74305e95, status phase: Failed. Waiting for statefulset controller to delete.
Oct 25 02:54:53.287: INFO: Observed stateful pod in namespace: statefulset-6543, name: ss-0, uid: d47ab21a-90df-4363-8123-050b74305e95, status phase: Failed. Waiting for statefulset controller to delete.
Oct 25 02:54:53.292: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6543
STEP: Removing pod with conflicting port in namespace statefulset-6543
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6543 and will be in running state
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct 25 02:54:57.370: INFO: Deleting all statefulset in ns statefulset-6543
Oct 25 02:54:57.376: INFO: Scaling statefulset ss to 0
Oct 25 02:55:07.421: INFO: Waiting for statefulset status.replicas updated to 0
Oct 25 02:55:07.426: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Oct 25 02:55:07.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6543" for this suite.

• [SLOW TEST:18.375 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":356,"completed":259,"skipped":4858,"failed":0}
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:55:07.476: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:55:07.509: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct 25 02:55:07.526: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 25 02:55:12.549: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 25 02:55:12.549: INFO: Creating deployment "test-rolling-update-deployment"
Oct 25 02:55:12.559: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct 25 02:55:12.574: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct 25 02:55:14.589: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct 25 02:55:14.599: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 25 02:55:14.616: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-8146  92fcf068-e8ec-470a-bb9e-3aa655aa49b8 236293 1 2022-10-25 02:55:12 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2022-10-25 02:55:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 02:55:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035f28a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-10-25 02:55:12 +0000 UTC,LastTransitionTime:2022-10-25 02:55:12 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-67c8f74c6c" has successfully progressed.,LastUpdateTime:2022-10-25 02:55:13 +0000 UTC,LastTransitionTime:2022-10-25 02:55:12 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct 25 02:55:14.625: INFO: New ReplicaSet "test-rolling-update-deployment-67c8f74c6c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-67c8f74c6c  deployment-8146  91c4e1f1-5089-4aef-ad39-d053b197843b 236283 1 2022-10-25 02:55:12 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 92fcf068-e8ec-470a-bb9e-3aa655aa49b8 0xc0035f2dc7 0xc0035f2dc8}] []  [{kube-controller-manager Update apps/v1 2022-10-25 02:55:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"92fcf068-e8ec-470a-bb9e-3aa655aa49b8\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 02:55:13 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67c8f74c6c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035f2e78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 25 02:55:14.626: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct 25 02:55:14.626: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-8146  cd846d3e-f8ec-4699-99fa-81ab5a91e537 236292 2 2022-10-25 02:55:07 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 92fcf068-e8ec-470a-bb9e-3aa655aa49b8 0xc0035f2c87 0xc0035f2c88}] []  [{e2e.test Update apps/v1 2022-10-25 02:55:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 02:55:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"92fcf068-e8ec-470a-bb9e-3aa655aa49b8\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-10-25 02:55:13 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0035f2d48 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 25 02:55:14.631: INFO: Pod "test-rolling-update-deployment-67c8f74c6c-ps25w" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-67c8f74c6c-ps25w test-rolling-update-deployment-67c8f74c6c- deployment-8146  a4c5ff92-8c97-4836-915a-99a1e4a08f1c 236282 0 2022-10-25 02:55:12 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[cni.projectcalico.org/containerID:0afb30edfdac47159db6332fdfafe3d7a8d0502061c1bd534032bf6e29250ef4 cni.projectcalico.org/podIP:10.233.74.253/32 cni.projectcalico.org/podIPs:10.233.74.253/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-67c8f74c6c 91c4e1f1-5089-4aef-ad39-d053b197843b 0xc0026bd6f7 0xc0026bd6f8}] []  [{kube-controller-manager Update v1 2022-10-25 02:55:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"91c4e1f1-5089-4aef-ad39-d053b197843b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-10-25 02:55:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-25 02:55:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.74.253\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jhfwg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jhfwg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:55:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:55:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:55:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:55:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.178,PodIP:10.233.74.253,StartTime:2022-10-25 02:55:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 02:55:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e,ContainerID:containerd://1df8abc9b8c97ecee19546ac4f629bf87d7fd6b8f98529c6ba48936f11c3881b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.74.253,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Oct 25 02:55:14.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8146" for this suite.

• [SLOW TEST:7.179 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":356,"completed":260,"skipped":4862,"failed":0}
SSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:55:14.655: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:55:14.712: INFO: The status of Pod busybox-host-aliases42d28b0e-806a-4dca-9b2a-7e740c2e085e is Pending, waiting for it to be Running (with Ready = true)
Oct 25 02:55:16.725: INFO: The status of Pod busybox-host-aliases42d28b0e-806a-4dca-9b2a-7e740c2e085e is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Oct 25 02:55:16.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9065" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":261,"skipped":4866,"failed":0}

------------------------------
[sig-network] EndpointSlice 
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:55:16.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/discovery.k8s.io
STEP: getting /apis/discovery.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Oct 25 02:55:16.877: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Oct 25 02:55:16.885: INFO: starting watch
STEP: patching
STEP: updating
Oct 25 02:55:16.915: INFO: waiting for watch events with expected annotations
Oct 25 02:55:16.915: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Oct 25 02:55:16.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5306" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","total":356,"completed":262,"skipped":4866,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:55:17.011: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 02:55:17.081: INFO: Waiting up to 5m0s for pod "downwardapi-volume-397f786d-4128-4328-9f7d-75cd9456106b" in namespace "downward-api-5153" to be "Succeeded or Failed"
Oct 25 02:55:17.087: INFO: Pod "downwardapi-volume-397f786d-4128-4328-9f7d-75cd9456106b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.286422ms
Oct 25 02:55:19.101: INFO: Pod "downwardapi-volume-397f786d-4128-4328-9f7d-75cd9456106b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020272669s
Oct 25 02:55:21.113: INFO: Pod "downwardapi-volume-397f786d-4128-4328-9f7d-75cd9456106b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031877794s
STEP: Saw pod success
Oct 25 02:55:21.113: INFO: Pod "downwardapi-volume-397f786d-4128-4328-9f7d-75cd9456106b" satisfied condition "Succeeded or Failed"
Oct 25 02:55:21.122: INFO: Trying to get logs from node lab1-k8s-node-2 pod downwardapi-volume-397f786d-4128-4328-9f7d-75cd9456106b container client-container: <nil>
STEP: delete the pod
Oct 25 02:55:21.168: INFO: Waiting for pod downwardapi-volume-397f786d-4128-4328-9f7d-75cd9456106b to disappear
Oct 25 02:55:21.174: INFO: Pod downwardapi-volume-397f786d-4128-4328-9f7d-75cd9456106b no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Oct 25 02:55:21.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5153" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":356,"completed":263,"skipped":4868,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:55:21.201: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod with failed condition
STEP: updating the pod
Oct 25 02:57:21.813: INFO: Successfully updated pod "var-expansion-0b3ba8b8-950a-4ad2-807f-143c3401648a"
STEP: waiting for pod running
STEP: deleting the pod gracefully
Oct 25 02:57:23.832: INFO: Deleting pod "var-expansion-0b3ba8b8-950a-4ad2-807f-143c3401648a" in namespace "var-expansion-1077"
Oct 25 02:57:23.849: INFO: Wait up to 5m0s for pod "var-expansion-0b3ba8b8-950a-4ad2-807f-143c3401648a" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Oct 25 02:57:55.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1077" for this suite.

• [SLOW TEST:154.694 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","total":356,"completed":264,"skipped":4877,"failed":0}
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:57:55.895: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 02:57:55.972: INFO: Waiting up to 5m0s for pod "downwardapi-volume-10f1d263-972f-41b1-b2dd-9e682c9e78fe" in namespace "projected-1306" to be "Succeeded or Failed"
Oct 25 02:57:55.978: INFO: Pod "downwardapi-volume-10f1d263-972f-41b1-b2dd-9e682c9e78fe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.247373ms
Oct 25 02:57:57.991: INFO: Pod "downwardapi-volume-10f1d263-972f-41b1-b2dd-9e682c9e78fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01923028s
Oct 25 02:58:00.005: INFO: Pod "downwardapi-volume-10f1d263-972f-41b1-b2dd-9e682c9e78fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033692955s
STEP: Saw pod success
Oct 25 02:58:00.005: INFO: Pod "downwardapi-volume-10f1d263-972f-41b1-b2dd-9e682c9e78fe" satisfied condition "Succeeded or Failed"
Oct 25 02:58:00.011: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-10f1d263-972f-41b1-b2dd-9e682c9e78fe container client-container: <nil>
STEP: delete the pod
Oct 25 02:58:00.056: INFO: Waiting for pod downwardapi-volume-10f1d263-972f-41b1-b2dd-9e682c9e78fe to disappear
Oct 25 02:58:00.062: INFO: Pod downwardapi-volume-10f1d263-972f-41b1-b2dd-9e682c9e78fe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Oct 25 02:58:00.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1306" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":265,"skipped":4878,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:58:00.087: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:58:02.178: INFO: Deleting pod "var-expansion-f4298cd9-12d2-40f9-98bc-b9fee4010a7b" in namespace "var-expansion-4030"
Oct 25 02:58:02.193: INFO: Wait up to 5m0s for pod "var-expansion-f4298cd9-12d2-40f9-98bc-b9fee4010a7b" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Oct 25 02:58:04.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4030" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","total":356,"completed":266,"skipped":4909,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:58:04.246: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:58:04.286: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Oct 25 02:58:13.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-4524 --namespace=crd-publish-openapi-4524 create -f -'
Oct 25 02:58:14.106: INFO: stderr: ""
Oct 25 02:58:14.107: INFO: stdout: "e2e-test-crd-publish-openapi-6171-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Oct 25 02:58:14.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-4524 --namespace=crd-publish-openapi-4524 delete e2e-test-crd-publish-openapi-6171-crds test-cr'
Oct 25 02:58:14.224: INFO: stderr: ""
Oct 25 02:58:14.224: INFO: stdout: "e2e-test-crd-publish-openapi-6171-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Oct 25 02:58:14.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-4524 --namespace=crd-publish-openapi-4524 apply -f -'
Oct 25 02:58:15.101: INFO: stderr: ""
Oct 25 02:58:15.101: INFO: stdout: "e2e-test-crd-publish-openapi-6171-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Oct 25 02:58:15.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-4524 --namespace=crd-publish-openapi-4524 delete e2e-test-crd-publish-openapi-6171-crds test-cr'
Oct 25 02:58:15.186: INFO: stderr: ""
Oct 25 02:58:15.186: INFO: stdout: "e2e-test-crd-publish-openapi-6171-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Oct 25 02:58:15.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=crd-publish-openapi-4524 explain e2e-test-crd-publish-openapi-6171-crds'
Oct 25 02:58:15.831: INFO: stderr: ""
Oct 25 02:58:15.831: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6171-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:58:19.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4524" for this suite.

• [SLOW TEST:15.648 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":356,"completed":267,"skipped":4919,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:58:19.896: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Oct 25 02:58:19.962: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Oct 25 02:58:19.979: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Oct 25 02:58:19.979: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Oct 25 02:58:20.011: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Oct 25 02:58:20.011: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Oct 25 02:58:20.032: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Oct 25 02:58:20.032: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Oct 25 02:58:27.110: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:188
Oct 25 02:58:27.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-5821" for this suite.

• [SLOW TEST:7.277 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":356,"completed":268,"skipped":4941,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:58:27.175: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4033.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4033.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4033.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4033.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4033.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4033.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4033.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4033.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4033.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4033.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4033.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4033.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 2.58.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.58.2_udp@PTR;check="$$(dig +tcp +noall +answer +search 2.58.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.58.2_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4033.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4033.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4033.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4033.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4033.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4033.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4033.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4033.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4033.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4033.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4033.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4033.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 2.58.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.58.2_udp@PTR;check="$$(dig +tcp +noall +answer +search 2.58.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.58.2_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 25 02:58:29.322: INFO: Unable to read wheezy_udp@dns-test-service.dns-4033.svc.cluster.local from pod dns-4033/dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62: the server could not find the requested resource (get pods dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62)
Oct 25 02:58:29.331: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4033.svc.cluster.local from pod dns-4033/dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62: the server could not find the requested resource (get pods dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62)
Oct 25 02:58:29.338: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4033.svc.cluster.local from pod dns-4033/dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62: the server could not find the requested resource (get pods dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62)
Oct 25 02:58:29.351: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4033.svc.cluster.local from pod dns-4033/dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62: the server could not find the requested resource (get pods dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62)
Oct 25 02:58:29.394: INFO: Unable to read jessie_udp@dns-test-service.dns-4033.svc.cluster.local from pod dns-4033/dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62: the server could not find the requested resource (get pods dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62)
Oct 25 02:58:29.408: INFO: Unable to read jessie_tcp@dns-test-service.dns-4033.svc.cluster.local from pod dns-4033/dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62: the server could not find the requested resource (get pods dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62)
Oct 25 02:58:29.417: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4033.svc.cluster.local from pod dns-4033/dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62: the server could not find the requested resource (get pods dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62)
Oct 25 02:58:29.425: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4033.svc.cluster.local from pod dns-4033/dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62: the server could not find the requested resource (get pods dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62)
Oct 25 02:58:29.464: INFO: Lookups using dns-4033/dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62 failed for: [wheezy_udp@dns-test-service.dns-4033.svc.cluster.local wheezy_tcp@dns-test-service.dns-4033.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4033.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4033.svc.cluster.local jessie_udp@dns-test-service.dns-4033.svc.cluster.local jessie_tcp@dns-test-service.dns-4033.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4033.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4033.svc.cluster.local]

Oct 25 02:58:34.601: INFO: DNS probes using dns-4033/dns-test-5ca4641c-4bc4-40e9-9eac-f0cb5ee85a62 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Oct 25 02:58:34.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4033" for this suite.

• [SLOW TEST:7.571 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":356,"completed":269,"skipped":4990,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  should validate Deployment Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:58:34.747: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Deployment
Oct 25 02:58:34.811: INFO: Creating simple deployment test-deployment-d68c4
Oct 25 02:58:34.838: INFO: deployment "test-deployment-d68c4" doesn't have the required revision set
STEP: Getting /status
Oct 25 02:58:36.877: INFO: Deployment test-deployment-d68c4 has Conditions: [{Available True 2022-10-25 02:58:35 +0000 UTC 2022-10-25 02:58:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-10-25 02:58:35 +0000 UTC 2022-10-25 02:58:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d68c4-688c4d6789" has successfully progressed.}]
STEP: updating Deployment Status
Oct 25 02:58:36.895: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 58, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 58, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.October, 25, 2, 58, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.October, 25, 2, 58, 34, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-d68c4-688c4d6789\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated
Oct 25 02:58:36.899: INFO: Observed &Deployment event: ADDED
Oct 25 02:58:36.899: INFO: Observed Deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-25 02:58:34 +0000 UTC 2022-10-25 02:58:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d68c4-688c4d6789"}
Oct 25 02:58:36.899: INFO: Observed &Deployment event: MODIFIED
Oct 25 02:58:36.899: INFO: Observed Deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-25 02:58:34 +0000 UTC 2022-10-25 02:58:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d68c4-688c4d6789"}
Oct 25 02:58:36.899: INFO: Observed Deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-10-25 02:58:34 +0000 UTC 2022-10-25 02:58:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Oct 25 02:58:36.900: INFO: Observed &Deployment event: MODIFIED
Oct 25 02:58:36.900: INFO: Observed Deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-10-25 02:58:34 +0000 UTC 2022-10-25 02:58:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Oct 25 02:58:36.900: INFO: Observed Deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-25 02:58:34 +0000 UTC 2022-10-25 02:58:34 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-d68c4-688c4d6789" is progressing.}
Oct 25 02:58:36.900: INFO: Observed &Deployment event: MODIFIED
Oct 25 02:58:36.900: INFO: Observed Deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-10-25 02:58:35 +0000 UTC 2022-10-25 02:58:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Oct 25 02:58:36.900: INFO: Observed Deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-25 02:58:35 +0000 UTC 2022-10-25 02:58:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d68c4-688c4d6789" has successfully progressed.}
Oct 25 02:58:36.900: INFO: Observed &Deployment event: MODIFIED
Oct 25 02:58:36.900: INFO: Observed Deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-10-25 02:58:35 +0000 UTC 2022-10-25 02:58:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Oct 25 02:58:36.900: INFO: Observed Deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-25 02:58:35 +0000 UTC 2022-10-25 02:58:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d68c4-688c4d6789" has successfully progressed.}
Oct 25 02:58:36.900: INFO: Found Deployment test-deployment-d68c4 in namespace deployment-7627 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Oct 25 02:58:36.900: INFO: Deployment test-deployment-d68c4 has an updated status
STEP: patching the Statefulset Status
Oct 25 02:58:36.900: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Oct 25 02:58:36.913: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched
Oct 25 02:58:36.917: INFO: Observed &Deployment event: ADDED
Oct 25 02:58:36.917: INFO: Observed deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-25 02:58:34 +0000 UTC 2022-10-25 02:58:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d68c4-688c4d6789"}
Oct 25 02:58:36.917: INFO: Observed &Deployment event: MODIFIED
Oct 25 02:58:36.917: INFO: Observed deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-25 02:58:34 +0000 UTC 2022-10-25 02:58:34 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d68c4-688c4d6789"}
Oct 25 02:58:36.917: INFO: Observed deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-10-25 02:58:34 +0000 UTC 2022-10-25 02:58:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Oct 25 02:58:36.917: INFO: Observed &Deployment event: MODIFIED
Oct 25 02:58:36.917: INFO: Observed deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-10-25 02:58:34 +0000 UTC 2022-10-25 02:58:34 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Oct 25 02:58:36.917: INFO: Observed deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-25 02:58:34 +0000 UTC 2022-10-25 02:58:34 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-d68c4-688c4d6789" is progressing.}
Oct 25 02:58:36.918: INFO: Observed &Deployment event: MODIFIED
Oct 25 02:58:36.918: INFO: Observed deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-10-25 02:58:35 +0000 UTC 2022-10-25 02:58:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Oct 25 02:58:36.918: INFO: Observed deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-25 02:58:35 +0000 UTC 2022-10-25 02:58:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d68c4-688c4d6789" has successfully progressed.}
Oct 25 02:58:36.918: INFO: Observed &Deployment event: MODIFIED
Oct 25 02:58:36.918: INFO: Observed deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-10-25 02:58:35 +0000 UTC 2022-10-25 02:58:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Oct 25 02:58:36.918: INFO: Observed deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-10-25 02:58:35 +0000 UTC 2022-10-25 02:58:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d68c4-688c4d6789" has successfully progressed.}
Oct 25 02:58:36.918: INFO: Observed deployment test-deployment-d68c4 in namespace deployment-7627 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Oct 25 02:58:36.918: INFO: Observed &Deployment event: MODIFIED
Oct 25 02:58:36.918: INFO: Found deployment test-deployment-d68c4 in namespace deployment-7627 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Oct 25 02:58:36.918: INFO: Deployment test-deployment-d68c4 has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 25 02:58:36.924: INFO: Deployment "test-deployment-d68c4":
&Deployment{ObjectMeta:{test-deployment-d68c4  deployment-7627  d1e2d363-0860-44aa-ad87-2e28088795e9 237281 1 2022-10-25 02:58:34 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2022-10-25 02:58:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-10-25 02:58:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-10-25 02:58:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049ffa38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-d68c4-688c4d6789",LastUpdateTime:2022-10-25 02:58:36 +0000 UTC,LastTransitionTime:2022-10-25 02:58:36 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct 25 02:58:36.932: INFO: New ReplicaSet "test-deployment-d68c4-688c4d6789" of Deployment "test-deployment-d68c4":
&ReplicaSet{ObjectMeta:{test-deployment-d68c4-688c4d6789  deployment-7627  ebac5d51-d494-4543-86a1-89a82a96c67f 237272 1 2022-10-25 02:58:34 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-d68c4 d1e2d363-0860-44aa-ad87-2e28088795e9 0xc0049ffe27 0xc0049ffe28}] []  [{kube-controller-manager Update apps/v1 2022-10-25 02:58:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d1e2d363-0860-44aa-ad87-2e28088795e9\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 02:58:35 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 688c4d6789,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049ffed8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 25 02:58:36.939: INFO: Pod "test-deployment-d68c4-688c4d6789-8l9kp" is available:
&Pod{ObjectMeta:{test-deployment-d68c4-688c4d6789-8l9kp test-deployment-d68c4-688c4d6789- deployment-7627  81e671ff-7edd-48b0-a0e3-d8a4bb1bdfad 237271 0 2022-10-25 02:58:34 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[cni.projectcalico.org/containerID:5e53ad1c4ed63b931eaa0164898a3331e274c581c62bff55d9fc43edef558f7a cni.projectcalico.org/podIP:10.233.74.4/32 cni.projectcalico.org/podIPs:10.233.74.4/32] [{apps/v1 ReplicaSet test-deployment-d68c4-688c4d6789 ebac5d51-d494-4543-86a1-89a82a96c67f 0xc0028702b0 0xc0028702b1}] []  [{kube-controller-manager Update v1 2022-10-25 02:58:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ebac5d51-d494-4543-86a1-89a82a96c67f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-10-25 02:58:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-25 02:58:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.74.4\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nm26d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nm26d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:58:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:58:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:58:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 02:58:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.178,PodIP:10.233.74.4,StartTime:2022-10-25 02:58:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 02:58:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6e398ca9948d50c042d96c369334cd416954ee9d0fb66ea997e7d77efcd093fe,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.74.4,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Oct 25 02:58:36.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7627" for this suite.
•{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","total":356,"completed":270,"skipped":5018,"failed":0}
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:58:36.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 02:58:37.115: INFO: Create a RollingUpdate DaemonSet
Oct 25 02:58:37.128: INFO: Check that daemon pods launch on every node of the cluster
Oct 25 02:58:37.154: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:58:37.154: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 02:58:38.197: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:58:38.197: INFO: Node lab1-k8s-master-1 is running 0 daemon pod, expected 1
Oct 25 02:58:39.188: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 6
Oct 25 02:58:39.188: INFO: Number of running nodes: 6, number of available pods: 6 in daemonset daemon-set
Oct 25 02:58:39.188: INFO: Update the DaemonSet to trigger a rollout
Oct 25 02:58:39.205: INFO: Updating DaemonSet daemon-set
Oct 25 02:58:42.276: INFO: Roll back the DaemonSet before rollout is complete
Oct 25 02:58:42.319: INFO: Updating DaemonSet daemon-set
Oct 25 02:58:42.319: INFO: Make sure DaemonSet rollback is complete
Oct 25 02:58:42.338: INFO: Wrong image for pod: daemon-set-k7vz4. Expected: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Oct 25 02:58:42.338: INFO: Pod daemon-set-k7vz4 is not available
Oct 25 02:58:45.392: INFO: Pod daemon-set-m2kvp is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9024, will wait for the garbage collector to delete the pods
Oct 25 02:58:45.507: INFO: Deleting DaemonSet.extensions daemon-set took: 12.731856ms
Oct 25 02:58:45.608: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.562905ms
Oct 25 02:58:47.420: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Oct 25 02:58:47.420: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Oct 25 02:58:47.427: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"237550"},"items":null}

Oct 25 02:58:47.433: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"237550"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Oct 25 02:58:47.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9024" for this suite.

• [SLOW TEST:10.565 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":356,"completed":271,"skipped":5022,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:58:47.535: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
STEP: set up a multi version CRD
Oct 25 02:58:47.579: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 02:59:11.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3106" for this suite.

• [SLOW TEST:24.484 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":356,"completed":272,"skipped":5039,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:59:12.020: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8512.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8512.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8512.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8512.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 25 02:59:14.137: INFO: File jessie_udp@dns-test-service-3.dns-8512.svc.cluster.local from pod  dns-8512/dns-test-e1eba4b4-cba7-43ff-b111-d63d34a5a944 contains '' instead of 'foo.example.com.'
Oct 25 02:59:14.137: INFO: Lookups using dns-8512/dns-test-e1eba4b4-cba7-43ff-b111-d63d34a5a944 failed for: [jessie_udp@dns-test-service-3.dns-8512.svc.cluster.local]

Oct 25 02:59:19.152: INFO: DNS probes using dns-test-e1eba4b4-cba7-43ff-b111-d63d34a5a944 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8512.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8512.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8512.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8512.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 25 02:59:21.253: INFO: File wheezy_udp@dns-test-service-3.dns-8512.svc.cluster.local from pod  dns-8512/dns-test-a0099e19-5006-44c3-9254-4a53ea154489 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 25 02:59:21.260: INFO: File jessie_udp@dns-test-service-3.dns-8512.svc.cluster.local from pod  dns-8512/dns-test-a0099e19-5006-44c3-9254-4a53ea154489 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 25 02:59:21.260: INFO: Lookups using dns-8512/dns-test-a0099e19-5006-44c3-9254-4a53ea154489 failed for: [wheezy_udp@dns-test-service-3.dns-8512.svc.cluster.local jessie_udp@dns-test-service-3.dns-8512.svc.cluster.local]

Oct 25 02:59:26.277: INFO: File wheezy_udp@dns-test-service-3.dns-8512.svc.cluster.local from pod  dns-8512/dns-test-a0099e19-5006-44c3-9254-4a53ea154489 contains '' instead of 'bar.example.com.'
Oct 25 02:59:26.285: INFO: File jessie_udp@dns-test-service-3.dns-8512.svc.cluster.local from pod  dns-8512/dns-test-a0099e19-5006-44c3-9254-4a53ea154489 contains '' instead of 'bar.example.com.'
Oct 25 02:59:26.285: INFO: Lookups using dns-8512/dns-test-a0099e19-5006-44c3-9254-4a53ea154489 failed for: [wheezy_udp@dns-test-service-3.dns-8512.svc.cluster.local jessie_udp@dns-test-service-3.dns-8512.svc.cluster.local]

Oct 25 02:59:31.279: INFO: DNS probes using dns-test-a0099e19-5006-44c3-9254-4a53ea154489 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8512.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8512.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8512.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8512.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 25 02:59:33.453: INFO: DNS probes using dns-test-528e11d2-8d59-4304-8220-25999cd10064 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Oct 25 02:59:33.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8512" for this suite.

• [SLOW TEST:21.503 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":356,"completed":273,"skipped":5057,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:59:33.523: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 02:59:33.571: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e1a08ac8-421f-4846-bf1b-47a17fe48730" in namespace "downward-api-1754" to be "Succeeded or Failed"
Oct 25 02:59:33.577: INFO: Pod "downwardapi-volume-e1a08ac8-421f-4846-bf1b-47a17fe48730": Phase="Pending", Reason="", readiness=false. Elapsed: 5.904395ms
Oct 25 02:59:35.585: INFO: Pod "downwardapi-volume-e1a08ac8-421f-4846-bf1b-47a17fe48730": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014033044s
Oct 25 02:59:37.601: INFO: Pod "downwardapi-volume-e1a08ac8-421f-4846-bf1b-47a17fe48730": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029532981s
STEP: Saw pod success
Oct 25 02:59:37.601: INFO: Pod "downwardapi-volume-e1a08ac8-421f-4846-bf1b-47a17fe48730" satisfied condition "Succeeded or Failed"
Oct 25 02:59:37.607: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-e1a08ac8-421f-4846-bf1b-47a17fe48730 container client-container: <nil>
STEP: delete the pod
Oct 25 02:59:37.693: INFO: Waiting for pod downwardapi-volume-e1a08ac8-421f-4846-bf1b-47a17fe48730 to disappear
Oct 25 02:59:37.699: INFO: Pod downwardapi-volume-e1a08ac8-421f-4846-bf1b-47a17fe48730 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Oct 25 02:59:37.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1754" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":274,"skipped":5106,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:59:37.726: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
Oct 25 02:59:50.464: INFO: 70 pods remaining
Oct 25 02:59:50.464: INFO: 70 pods has nil DeletionTimestamp
Oct 25 02:59:50.464: INFO: 
STEP: Gathering metrics
Oct 25 02:59:55.494: INFO: The status of Pod kube-controller-manager-lab1-k8s-master-3 is Running (Ready = true)
Oct 25 02:59:55.564: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Oct 25 02:59:55.564: INFO: Deleting pod "simpletest-rc-to-be-deleted-2g26r" in namespace "gc-9928"
Oct 25 02:59:55.592: INFO: Deleting pod "simpletest-rc-to-be-deleted-2nx9f" in namespace "gc-9928"
Oct 25 02:59:55.623: INFO: Deleting pod "simpletest-rc-to-be-deleted-48hz2" in namespace "gc-9928"
Oct 25 02:59:55.660: INFO: Deleting pod "simpletest-rc-to-be-deleted-4g2x7" in namespace "gc-9928"
Oct 25 02:59:55.698: INFO: Deleting pod "simpletest-rc-to-be-deleted-4h7kz" in namespace "gc-9928"
Oct 25 02:59:55.722: INFO: Deleting pod "simpletest-rc-to-be-deleted-4m8dh" in namespace "gc-9928"
Oct 25 02:59:55.760: INFO: Deleting pod "simpletest-rc-to-be-deleted-52tvh" in namespace "gc-9928"
Oct 25 02:59:55.781: INFO: Deleting pod "simpletest-rc-to-be-deleted-57ghs" in namespace "gc-9928"
Oct 25 02:59:55.809: INFO: Deleting pod "simpletest-rc-to-be-deleted-58qcv" in namespace "gc-9928"
Oct 25 02:59:55.840: INFO: Deleting pod "simpletest-rc-to-be-deleted-5nzjh" in namespace "gc-9928"
Oct 25 02:59:55.871: INFO: Deleting pod "simpletest-rc-to-be-deleted-5v5b6" in namespace "gc-9928"
Oct 25 02:59:55.927: INFO: Deleting pod "simpletest-rc-to-be-deleted-64n75" in namespace "gc-9928"
Oct 25 02:59:55.975: INFO: Deleting pod "simpletest-rc-to-be-deleted-6cm85" in namespace "gc-9928"
Oct 25 02:59:56.004: INFO: Deleting pod "simpletest-rc-to-be-deleted-6gzk4" in namespace "gc-9928"
Oct 25 02:59:56.037: INFO: Deleting pod "simpletest-rc-to-be-deleted-6njgg" in namespace "gc-9928"
Oct 25 02:59:56.064: INFO: Deleting pod "simpletest-rc-to-be-deleted-79kcx" in namespace "gc-9928"
Oct 25 02:59:56.118: INFO: Deleting pod "simpletest-rc-to-be-deleted-7kqw4" in namespace "gc-9928"
Oct 25 02:59:56.181: INFO: Deleting pod "simpletest-rc-to-be-deleted-7wj94" in namespace "gc-9928"
Oct 25 02:59:56.261: INFO: Deleting pod "simpletest-rc-to-be-deleted-8644k" in namespace "gc-9928"
Oct 25 02:59:56.311: INFO: Deleting pod "simpletest-rc-to-be-deleted-8bc99" in namespace "gc-9928"
Oct 25 02:59:56.350: INFO: Deleting pod "simpletest-rc-to-be-deleted-8cfgb" in namespace "gc-9928"
Oct 25 02:59:56.386: INFO: Deleting pod "simpletest-rc-to-be-deleted-8dvth" in namespace "gc-9928"
Oct 25 02:59:56.452: INFO: Deleting pod "simpletest-rc-to-be-deleted-8jvgs" in namespace "gc-9928"
Oct 25 02:59:56.537: INFO: Deleting pod "simpletest-rc-to-be-deleted-8rfqz" in namespace "gc-9928"
Oct 25 02:59:56.590: INFO: Deleting pod "simpletest-rc-to-be-deleted-8sr2m" in namespace "gc-9928"
Oct 25 02:59:56.647: INFO: Deleting pod "simpletest-rc-to-be-deleted-9xmgc" in namespace "gc-9928"
Oct 25 02:59:56.695: INFO: Deleting pod "simpletest-rc-to-be-deleted-b7lx8" in namespace "gc-9928"
Oct 25 02:59:56.770: INFO: Deleting pod "simpletest-rc-to-be-deleted-bfpk7" in namespace "gc-9928"
Oct 25 02:59:56.842: INFO: Deleting pod "simpletest-rc-to-be-deleted-bgmk6" in namespace "gc-9928"
Oct 25 02:59:56.920: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqz9p" in namespace "gc-9928"
Oct 25 02:59:57.015: INFO: Deleting pod "simpletest-rc-to-be-deleted-bsk85" in namespace "gc-9928"
Oct 25 02:59:57.173: INFO: Deleting pod "simpletest-rc-to-be-deleted-bwvl8" in namespace "gc-9928"
Oct 25 02:59:57.286: INFO: Deleting pod "simpletest-rc-to-be-deleted-c8zw9" in namespace "gc-9928"
Oct 25 02:59:57.378: INFO: Deleting pod "simpletest-rc-to-be-deleted-cp5k2" in namespace "gc-9928"
Oct 25 02:59:57.430: INFO: Deleting pod "simpletest-rc-to-be-deleted-csgx4" in namespace "gc-9928"
Oct 25 02:59:57.476: INFO: Deleting pod "simpletest-rc-to-be-deleted-cvj8m" in namespace "gc-9928"
Oct 25 02:59:57.539: INFO: Deleting pod "simpletest-rc-to-be-deleted-cwfgm" in namespace "gc-9928"
Oct 25 02:59:57.587: INFO: Deleting pod "simpletest-rc-to-be-deleted-d8x2k" in namespace "gc-9928"
Oct 25 02:59:57.663: INFO: Deleting pod "simpletest-rc-to-be-deleted-dbtll" in namespace "gc-9928"
Oct 25 02:59:57.751: INFO: Deleting pod "simpletest-rc-to-be-deleted-fbmrc" in namespace "gc-9928"
Oct 25 02:59:57.804: INFO: Deleting pod "simpletest-rc-to-be-deleted-g2qfk" in namespace "gc-9928"
Oct 25 02:59:57.879: INFO: Deleting pod "simpletest-rc-to-be-deleted-g82jm" in namespace "gc-9928"
Oct 25 02:59:57.941: INFO: Deleting pod "simpletest-rc-to-be-deleted-ggjkr" in namespace "gc-9928"
Oct 25 02:59:58.030: INFO: Deleting pod "simpletest-rc-to-be-deleted-gphdl" in namespace "gc-9928"
Oct 25 02:59:58.126: INFO: Deleting pod "simpletest-rc-to-be-deleted-gpwbl" in namespace "gc-9928"
Oct 25 02:59:58.216: INFO: Deleting pod "simpletest-rc-to-be-deleted-grp26" in namespace "gc-9928"
Oct 25 02:59:58.264: INFO: Deleting pod "simpletest-rc-to-be-deleted-gt78d" in namespace "gc-9928"
Oct 25 02:59:58.323: INFO: Deleting pod "simpletest-rc-to-be-deleted-gz7wc" in namespace "gc-9928"
Oct 25 02:59:58.408: INFO: Deleting pod "simpletest-rc-to-be-deleted-j6qlp" in namespace "gc-9928"
Oct 25 02:59:58.452: INFO: Deleting pod "simpletest-rc-to-be-deleted-j84lm" in namespace "gc-9928"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Oct 25 02:59:58.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9928" for this suite.

• [SLOW TEST:20.881 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":356,"completed":275,"skipped":5135,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:59:58.608: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating an Endpoint
STEP: waiting for available Endpoint
STEP: listing all Endpoints
STEP: updating the Endpoint
STEP: fetching the Endpoint
STEP: patching the Endpoint
STEP: fetching the Endpoint
STEP: deleting the Endpoint by Collection
STEP: waiting for Endpoint deletion
STEP: fetching the Endpoint
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 02:59:58.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8440" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","total":356,"completed":276,"skipped":5147,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 02:59:58.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 02:59:59.268: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 03:00:02.358: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 03:00:02.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1515" for this suite.
STEP: Destroying namespace "webhook-1515-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":356,"completed":277,"skipped":5149,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:00:02.620: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4786 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4786;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4786 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4786;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4786.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4786.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4786.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4786.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4786.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4786.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4786.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4786.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4786.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4786.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4786.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4786.svc;check="$$(dig +notcp +noall +answer +search 192.50.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.50.192_udp@PTR;check="$$(dig +tcp +noall +answer +search 192.50.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.50.192_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4786 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4786;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4786 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4786;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4786.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4786.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4786.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4786.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4786.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4786.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4786.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4786.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4786.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4786.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4786.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4786.svc;check="$$(dig +notcp +noall +answer +search 192.50.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.50.192_udp@PTR;check="$$(dig +tcp +noall +answer +search 192.50.233.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.233.50.192_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 25 03:00:04.788: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.800: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.807: INFO: Unable to read wheezy_udp@dns-test-service.dns-4786 from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.818: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4786 from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.825: INFO: Unable to read wheezy_udp@dns-test-service.dns-4786.svc from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.832: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4786.svc from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.840: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4786.svc from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.849: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4786.svc from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.891: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.898: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.905: INFO: Unable to read jessie_udp@dns-test-service.dns-4786 from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.914: INFO: Unable to read jessie_tcp@dns-test-service.dns-4786 from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.924: INFO: Unable to read jessie_udp@dns-test-service.dns-4786.svc from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.931: INFO: Unable to read jessie_tcp@dns-test-service.dns-4786.svc from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.938: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4786.svc from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.946: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4786.svc from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:04.979: INFO: Lookups using dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4786 wheezy_tcp@dns-test-service.dns-4786 wheezy_udp@dns-test-service.dns-4786.svc wheezy_tcp@dns-test-service.dns-4786.svc wheezy_udp@_http._tcp.dns-test-service.dns-4786.svc wheezy_tcp@_http._tcp.dns-test-service.dns-4786.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4786 jessie_tcp@dns-test-service.dns-4786 jessie_udp@dns-test-service.dns-4786.svc jessie_tcp@dns-test-service.dns-4786.svc jessie_udp@_http._tcp.dns-test-service.dns-4786.svc jessie_tcp@_http._tcp.dns-test-service.dns-4786.svc]

Oct 25 03:00:10.031: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4786.svc from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:10.040: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4786.svc from pod dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e: the server could not find the requested resource (get pods dns-test-c943000c-4a48-47aa-8183-ff77a86d388e)
Oct 25 03:00:10.189: INFO: Lookups using dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-4786.svc wheezy_tcp@_http._tcp.dns-test-service.dns-4786.svc]

Oct 25 03:00:15.161: INFO: DNS probes using dns-4786/dns-test-c943000c-4a48-47aa-8183-ff77a86d388e succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Oct 25 03:00:15.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4786" for this suite.

• [SLOW TEST:12.722 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":356,"completed":278,"skipped":5172,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:00:15.343: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 03:00:16.015: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 03:00:19.058: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 03:00:19.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1704" for this suite.
STEP: Destroying namespace "webhook-1704-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":356,"completed":279,"skipped":5210,"failed":0}
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:00:19.354: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Oct 25 03:00:19.394: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 25 03:00:19.410: INFO: Waiting for terminating namespaces to be deleted...
Oct 25 03:00:19.419: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-master-1 before test
Oct 25 03:00:19.438: INFO: calico-node-p96g7 from kube-system started at 2022-10-24 13:36:57 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.438: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 03:00:19.438: INFO: csi-cinder-nodeplugin-rpg8q from kube-system started at 2022-10-24 13:24:56 +0000 UTC (3 container statuses recorded)
Oct 25 03:00:19.438: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 03:00:19.438: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 03:00:19.438: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 03:00:19.438: INFO: kube-apiserver-lab1-k8s-master-1 from kube-system started at 2022-10-24 13:25:02 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.438: INFO: 	Container kube-apiserver ready: true, restart count 0
Oct 25 03:00:19.438: INFO: kube-controller-manager-lab1-k8s-master-1 from kube-system started at 2022-10-24 13:25:02 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.438: INFO: 	Container kube-controller-manager ready: true, restart count 2
Oct 25 03:00:19.438: INFO: kube-proxy-s6wnk from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.438: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 03:00:19.438: INFO: kube-scheduler-lab1-k8s-master-1 from kube-system started at 2022-10-24 13:25:02 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.438: INFO: 	Container kube-scheduler ready: true, restart count 1
Oct 25 03:00:19.438: INFO: metrics-server-54d48d8c7-mcnqp from kube-system started at 2022-10-24 13:25:08 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.438: INFO: 	Container metrics-server ready: true, restart count 0
Oct 25 03:00:19.438: INFO: nodelocaldns-lkpsg from kube-system started at 2022-10-24 13:24:07 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.438: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 03:00:19.438: INFO: openstack-cloud-controller-manager-dv986 from kube-system started at 2022-10-24 10:53:46 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.438: INFO: 	Container openstack-cloud-controller-manager ready: true, restart count 2
Oct 25 03:00:19.438: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-mshb5 from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 03:00:19.438: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 03:00:19.439: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 03:00:19.439: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-master-2 before test
Oct 25 03:00:19.451: INFO: calico-node-vqr8k from kube-system started at 2022-10-24 13:35:46 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.451: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 03:00:19.451: INFO: coredns-74d6c5659f-dcc4x from kube-system started at 2022-10-24 13:36:35 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.451: INFO: 	Container coredns ready: true, restart count 0
Oct 25 03:00:19.451: INFO: csi-cinder-nodeplugin-qw5tr from kube-system started at 2022-10-24 13:24:51 +0000 UTC (3 container statuses recorded)
Oct 25 03:00:19.451: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 03:00:19.451: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 03:00:19.451: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 03:00:19.451: INFO: dns-autoscaler-78676459f6-7hpdl from kube-system started at 2022-10-24 13:29:51 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.451: INFO: 	Container autoscaler ready: true, restart count 0
Oct 25 03:00:19.451: INFO: kube-apiserver-lab1-k8s-master-2 from kube-system started at 2022-10-24 13:29:45 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.451: INFO: 	Container kube-apiserver ready: true, restart count 0
Oct 25 03:00:19.451: INFO: kube-controller-manager-lab1-k8s-master-2 from kube-system started at 2022-10-24 11:16:13 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.451: INFO: 	Container kube-controller-manager ready: true, restart count 0
Oct 25 03:00:19.451: INFO: kube-proxy-vrr69 from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.451: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 03:00:19.451: INFO: kube-scheduler-lab1-k8s-master-2 from kube-system started at 2022-10-24 13:15:08 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.451: INFO: 	Container kube-scheduler ready: true, restart count 0
Oct 25 03:00:19.451: INFO: nodelocaldns-xr5sh from kube-system started at 2022-10-24 13:24:05 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.451: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 03:00:19.451: INFO: openstack-cloud-controller-manager-27jr7 from kube-system started at 2022-10-24 11:12:57 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.451: INFO: 	Container openstack-cloud-controller-manager ready: true, restart count 2
Oct 25 03:00:19.451: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-pr8xq from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 03:00:19.451: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 03:00:19.451: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 03:00:19.451: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-master-3 before test
Oct 25 03:00:19.469: INFO: calico-node-bp6ts from kube-system started at 2022-10-24 13:34:44 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.469: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 03:00:19.469: INFO: coredns-74d6c5659f-m6zm9 from kube-system started at 2022-10-24 13:36:27 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.469: INFO: 	Container coredns ready: true, restart count 0
Oct 25 03:00:19.469: INFO: csi-cinder-nodeplugin-x2dl8 from kube-system started at 2022-10-24 13:24:53 +0000 UTC (3 container statuses recorded)
Oct 25 03:00:19.469: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 03:00:19.469: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 03:00:19.469: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 03:00:19.469: INFO: kube-apiserver-lab1-k8s-master-3 from kube-system started at 2022-10-24 13:34:08 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.469: INFO: 	Container kube-apiserver ready: true, restart count 0
Oct 25 03:00:19.469: INFO: kube-controller-manager-lab1-k8s-master-3 from kube-system started at 2022-10-24 13:31:36 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.469: INFO: 	Container kube-controller-manager ready: true, restart count 0
Oct 25 03:00:19.469: INFO: kube-proxy-4fvsp from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.469: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 03:00:19.469: INFO: kube-scheduler-lab1-k8s-master-3 from kube-system started at 2022-10-24 13:34:07 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.469: INFO: 	Container kube-scheduler ready: true, restart count 1
Oct 25 03:00:19.469: INFO: nodelocaldns-2lsxm from kube-system started at 2022-10-24 13:24:05 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.469: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 03:00:19.469: INFO: openstack-cloud-controller-manager-4jzsk from kube-system started at 2022-10-24 11:44:40 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.469: INFO: 	Container openstack-cloud-controller-manager ready: true, restart count 1
Oct 25 03:00:19.469: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-8w5gv from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 03:00:19.469: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 03:00:19.469: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 03:00:19.469: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-node-1 before test
Oct 25 03:00:19.484: INFO: calico-node-5ddpv from kube-system started at 2022-10-24 13:44:52 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.484: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 03:00:19.484: INFO: csi-cinder-controllerplugin-5f5b5c795f-lrxvf from kube-system started at 2022-10-24 13:46:01 +0000 UTC (6 container statuses recorded)
Oct 25 03:00:19.484: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 03:00:19.484: INFO: 	Container csi-attacher ready: true, restart count 0
Oct 25 03:00:19.484: INFO: 	Container csi-provisioner ready: true, restart count 0
Oct 25 03:00:19.484: INFO: 	Container csi-resizer ready: true, restart count 0
Oct 25 03:00:19.484: INFO: 	Container csi-snapshotter ready: true, restart count 0
Oct 25 03:00:19.484: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 03:00:19.484: INFO: csi-cinder-nodeplugin-l5nps from kube-system started at 2022-10-24 13:44:52 +0000 UTC (3 container statuses recorded)
Oct 25 03:00:19.484: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 03:00:19.484: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 03:00:19.484: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 03:00:19.484: INFO: kube-proxy-ltn2j from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.484: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 03:00:19.484: INFO: nginx-proxy-lab1-k8s-node-1 from kube-system started at 2022-10-24 13:45:14 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.484: INFO: 	Container nginx-proxy ready: true, restart count 0
Oct 25 03:00:19.484: INFO: nodelocaldns-22vhv from kube-system started at 2022-10-24 13:44:52 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.484: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 03:00:19.484: INFO: snapshot-controller-59c7b5464b-hgf7x from kube-system started at 2022-10-24 13:46:01 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.484: INFO: 	Container snapshot-controller ready: true, restart count 0
Oct 25 03:00:19.484: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-z9z72 from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 03:00:19.484: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 03:00:19.484: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 03:00:19.484: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-node-2 before test
Oct 25 03:00:19.496: INFO: calico-kube-controllers-8ff9fbd88-qkxfb from kube-system started at 2022-10-24 13:52:38 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.496: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 25 03:00:19.496: INFO: calico-node-t24sg from kube-system started at 2022-10-24 13:51:29 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.496: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 03:00:19.496: INFO: csi-cinder-nodeplugin-6lwfv from kube-system started at 2022-10-24 13:51:29 +0000 UTC (3 container statuses recorded)
Oct 25 03:00:19.496: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 03:00:19.496: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 03:00:19.496: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 03:00:19.496: INFO: kube-proxy-9z7jt from kube-system started at 2022-10-24 13:57:47 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.496: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 03:00:19.496: INFO: nginx-proxy-lab1-k8s-node-2 from kube-system started at 2022-10-24 13:51:52 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.496: INFO: 	Container nginx-proxy ready: true, restart count 0
Oct 25 03:00:19.496: INFO: nodelocaldns-hf2sj from kube-system started at 2022-10-24 13:51:29 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.496: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 03:00:19.496: INFO: sonobuoy-e2e-job-a74b57dba1144d0b from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 03:00:19.496: INFO: 	Container e2e ready: true, restart count 0
Oct 25 03:00:19.497: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 03:00:19.497: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-vwzzz from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 03:00:19.497: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 03:00:19.497: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 25 03:00:19.497: INFO: 
Logging pods the apiserver thinks is on node lab1-k8s-node-3 before test
Oct 25 03:00:19.509: INFO: calico-node-rnp6v from kube-system started at 2022-10-24 13:57:49 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.510: INFO: 	Container calico-node ready: true, restart count 0
Oct 25 03:00:19.510: INFO: csi-cinder-nodeplugin-ghwsv from kube-system started at 2022-10-25 02:27:20 +0000 UTC (3 container statuses recorded)
Oct 25 03:00:19.510: INFO: 	Container cinder-csi-plugin ready: true, restart count 0
Oct 25 03:00:19.510: INFO: 	Container liveness-probe ready: true, restart count 0
Oct 25 03:00:19.510: INFO: 	Container node-driver-registrar ready: true, restart count 0
Oct 25 03:00:19.510: INFO: kube-proxy-dfcgm from kube-system started at 2022-10-24 13:57:49 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.510: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 25 03:00:19.510: INFO: nginx-proxy-lab1-k8s-node-3 from kube-system started at 2022-10-24 13:58:11 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.510: INFO: 	Container nginx-proxy ready: true, restart count 0
Oct 25 03:00:19.510: INFO: nodelocaldns-2qn67 from kube-system started at 2022-10-24 13:57:49 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.510: INFO: 	Container node-cache ready: true, restart count 0
Oct 25 03:00:19.510: INFO: sonobuoy from sonobuoy started at 2022-10-25 01:39:35 +0000 UTC (1 container statuses recorded)
Oct 25 03:00:19.510: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 25 03:00:19.510: INFO: sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-ttkt7 from sonobuoy started at 2022-10-25 01:39:40 +0000 UTC (2 container statuses recorded)
Oct 25 03:00:19.510: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 25 03:00:19.510: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-dc72c33c-ff5c-42db-93cf-acb221602336 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.128.1.178 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-dc72c33c-ff5c-42db-93cf-acb221602336 off the node lab1-k8s-node-3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-dc72c33c-ff5c-42db-93cf-acb221602336
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Oct 25 03:05:23.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5453" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83

• [SLOW TEST:304.393 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":356,"completed":280,"skipped":5214,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:05:23.747: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-upd-2cd75a7d-5d97-4e7c-a471-103e594755be
STEP: Creating the pod
Oct 25 03:05:23.840: INFO: The status of Pod pod-configmaps-b5504994-755b-4586-be8d-8dd81f617c0f is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:05:25.852: INFO: The status of Pod pod-configmaps-b5504994-755b-4586-be8d-8dd81f617c0f is Running (Ready = true)
STEP: Updating configmap configmap-test-upd-2cd75a7d-5d97-4e7c-a471-103e594755be
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 03:05:27.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4363" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":281,"skipped":5220,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:05:27.956: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching services
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 03:05:28.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4144" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":356,"completed":282,"skipped":5234,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:05:28.025: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name cm-test-opt-del-fcb8561b-f6fc-4890-b749-04cd0094d1c1
STEP: Creating configMap with name cm-test-opt-upd-1108d007-3333-448d-8602-38afbc60741e
STEP: Creating the pod
Oct 25 03:05:28.108: INFO: The status of Pod pod-configmaps-f4f2bb27-95ac-44db-9ee0-79dc77ef59cf is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:05:30.119: INFO: The status of Pod pod-configmaps-f4f2bb27-95ac-44db-9ee0-79dc77ef59cf is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-fcb8561b-f6fc-4890-b749-04cd0094d1c1
STEP: Updating configmap cm-test-opt-upd-1108d007-3333-448d-8602-38afbc60741e
STEP: Creating configMap with name cm-test-opt-create-ce1f24b7-3d05-4ec3-a5f8-1afa8bcec7fb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 03:05:34.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8582" for this suite.

• [SLOW TEST:6.277 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":283,"skipped":5254,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:05:34.303: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-upd-d0d9de71-0e67-43cc-8871-75445a06ab8b
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 03:05:36.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8939" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":284,"skipped":5268,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:05:36.466: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Oct 25 03:05:52.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3503" for this suite.

• [SLOW TEST:16.166 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":356,"completed":285,"skipped":5279,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:05:52.633: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service nodeport-service with the type=NodePort in namespace services-2385
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-2385
STEP: creating replication controller externalsvc in namespace services-2385
I1025 03:05:52.762197      18 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2385, replica count: 2
I1025 03:05:55.812669      18 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Oct 25 03:05:55.863: INFO: Creating new exec pod
Oct 25 03:05:57.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-2385 exec execpod2bsv4 -- /bin/sh -x -c nslookup nodeport-service.services-2385.svc.cluster.local'
Oct 25 03:05:58.120: INFO: stderr: "+ nslookup nodeport-service.services-2385.svc.cluster.local\n"
Oct 25 03:05:58.120: INFO: stdout: "Server:\t\t169.254.25.10\nAddress:\t169.254.25.10#53\n\nnodeport-service.services-2385.svc.cluster.local\tcanonical name = externalsvc.services-2385.svc.cluster.local.\nName:\texternalsvc.services-2385.svc.cluster.local\nAddress: 10.233.49.54\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2385, will wait for the garbage collector to delete the pods
Oct 25 03:05:58.191: INFO: Deleting ReplicationController externalsvc took: 13.099606ms
Oct 25 03:05:58.291: INFO: Terminating ReplicationController externalsvc pods took: 100.440529ms
Oct 25 03:06:00.329: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 03:06:00.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2385" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:7.752 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":356,"completed":286,"skipped":5291,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:06:00.387: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Deployment
STEP: waiting for Deployment to be created
STEP: waiting for all Replicas to be Ready
Oct 25 03:06:00.453: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 25 03:06:00.453: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 25 03:06:00.469: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 25 03:06:00.469: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 25 03:06:00.494: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 25 03:06:00.494: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 25 03:06:00.535: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 25 03:06:00.535: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Oct 25 03:06:02.067: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Oct 25 03:06:02.067: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Oct 25 03:06:02.290: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment
Oct 25 03:06:02.316: INFO: observed event type ADDED
STEP: waiting for Replicas to scale
Oct 25 03:06:02.318: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0
Oct 25 03:06:02.318: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0
Oct 25 03:06:02.318: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0
Oct 25 03:06:02.318: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0
Oct 25 03:06:02.318: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0
Oct 25 03:06:02.318: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0
Oct 25 03:06:02.318: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0
Oct 25 03:06:02.318: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 0
Oct 25 03:06:02.318: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1
Oct 25 03:06:02.318: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1
Oct 25 03:06:02.318: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:02.318: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:02.318: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:02.318: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:02.331: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:02.331: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:02.362: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:02.362: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:02.413: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1
Oct 25 03:06:02.413: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1
Oct 25 03:06:04.098: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:04.098: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:04.122: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1
STEP: listing Deployments
Oct 25 03:06:04.134: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment
Oct 25 03:06:04.151: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1
STEP: fetching the DeploymentStatus
Oct 25 03:06:04.160: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct 25 03:06:04.169: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct 25 03:06:04.208: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct 25 03:06:04.242: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct 25 03:06:04.257: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Oct 25 03:06:05.097: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Oct 25 03:06:05.127: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Oct 25 03:06:05.140: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Oct 25 03:06:05.164: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Oct 25 03:06:05.182: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Oct 25 03:06:06.325: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus
STEP: fetching the DeploymentStatus
Oct 25 03:06:06.389: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1
Oct 25 03:06:06.389: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1
Oct 25 03:06:06.389: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1
Oct 25 03:06:06.389: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1
Oct 25 03:06:06.389: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 1
Oct 25 03:06:06.389: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:06.389: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:06.389: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:06.389: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:06.390: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 2
Oct 25 03:06:06.390: INFO: observed Deployment test-deployment in namespace deployment-5222 with ReadyReplicas 3
STEP: deleting the Deployment
Oct 25 03:06:06.407: INFO: observed event type MODIFIED
Oct 25 03:06:06.407: INFO: observed event type MODIFIED
Oct 25 03:06:06.407: INFO: observed event type MODIFIED
Oct 25 03:06:06.408: INFO: observed event type MODIFIED
Oct 25 03:06:06.408: INFO: observed event type MODIFIED
Oct 25 03:06:06.408: INFO: observed event type MODIFIED
Oct 25 03:06:06.408: INFO: observed event type MODIFIED
Oct 25 03:06:06.408: INFO: observed event type MODIFIED
Oct 25 03:06:06.408: INFO: observed event type MODIFIED
Oct 25 03:06:06.408: INFO: observed event type MODIFIED
Oct 25 03:06:06.408: INFO: observed event type MODIFIED
Oct 25 03:06:06.408: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 25 03:06:06.415: INFO: Log out all the ReplicaSets if there is no deployment created
Oct 25 03:06:06.425: INFO: ReplicaSet "test-deployment-6b48c869b6":
&ReplicaSet{ObjectMeta:{test-deployment-6b48c869b6  deployment-5222  97876541-9d24-4fb5-a673-e29165229f67 242105 3 2022-10-25 03:06:00 +0000 UTC <nil> <nil> map[pod-template-hash:6b48c869b6 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 8c2061d3-c665-4381-9a87-362f23b760af 0xc002b73f57 0xc002b73f58}] []  [{kube-controller-manager Update apps/v1 2022-10-25 03:06:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8c2061d3-c665-4381-9a87-362f23b760af\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 03:06:04 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 6b48c869b6,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:6b48c869b6 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002b73fe0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Oct 25 03:06:06.432: INFO: ReplicaSet "test-deployment-84b949bdfc":
&ReplicaSet{ObjectMeta:{test-deployment-84b949bdfc  deployment-5222  99729f8e-ce0c-423e-98c4-3ced39a78053 242228 4 2022-10-25 03:06:02 +0000 UTC <nil> <nil> map[pod-template-hash:84b949bdfc test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 8c2061d3-c665-4381-9a87-362f23b760af 0xc002ce4047 0xc002ce4048}] []  [{kube-controller-manager Update apps/v1 2022-10-25 03:06:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8c2061d3-c665-4381-9a87-362f23b760af\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 03:06:06 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 84b949bdfc,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:84b949bdfc test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/pause:3.7 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002ce40d0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Oct 25 03:06:06.443: INFO: pod: "test-deployment-84b949bdfc-8kvqc":
&Pod{ObjectMeta:{test-deployment-84b949bdfc-8kvqc test-deployment-84b949bdfc- deployment-5222  72b8bd65-a66f-4ad7-8077-7d517878dfce 242225 0 2022-10-25 03:06:02 +0000 UTC 2022-10-25 03:06:07 +0000 UTC 0xc002ce5388 map[pod-template-hash:84b949bdfc test-deployment-static:true] map[cni.projectcalico.org/containerID:ed7317ffb50e60e98a78996dcd19ef1585bca1aaa25c556fbc2e6e0d8695d51c cni.projectcalico.org/podIP:10.233.74.42/32 cni.projectcalico.org/podIPs:10.233.74.42/32] [{apps/v1 ReplicaSet test-deployment-84b949bdfc 99729f8e-ce0c-423e-98c4-3ced39a78053 0xc002ce54b7 0xc002ce54b8}] []  [{Go-http-client Update v1 2022-10-25 03:06:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-10-25 03:06:02 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99729f8e-ce0c-423e-98c4-3ced39a78053\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 03:06:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.74.42\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-57d4b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/pause:3.7,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-57d4b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 03:06:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 03:06:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 03:06:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 03:06:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.178,PodIP:10.233.74.42,StartTime:2022-10-25 03:06:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 03:06:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/pause:3.7,ImageID:k8s.gcr.io/pause@sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c,ContainerID:containerd://e4e10e2a7edcd96136368c1e3f5cf9941d792fb66cc3b59c0ff695c65ce17de7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.74.42,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Oct 25 03:06:06.443: INFO: pod: "test-deployment-84b949bdfc-bw99g":
&Pod{ObjectMeta:{test-deployment-84b949bdfc-bw99g test-deployment-84b949bdfc- deployment-5222  d1ce0003-b0dc-4475-a2c0-257d3d74eb0b 242181 0 2022-10-25 03:06:04 +0000 UTC 2022-10-25 03:06:06 +0000 UTC 0xc002ce5c30 map[pod-template-hash:84b949bdfc test-deployment-static:true] map[cni.projectcalico.org/containerID:75de6247d020b54381a554ce8760f48513ce050b0175fbbb6ed64f5090d9173d cni.projectcalico.org/podIP:10.233.64.131/32 cni.projectcalico.org/podIPs:10.233.64.131/32] [{apps/v1 ReplicaSet test-deployment-84b949bdfc 99729f8e-ce0c-423e-98c4-3ced39a78053 0xc002ce5cb7 0xc002ce5cb8}] []  [{Go-http-client Update v1 2022-10-25 03:06:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-10-25 03:06:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99729f8e-ce0c-423e-98c4-3ced39a78053\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-10-25 03:06:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.131\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7nb7l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/pause:3.7,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7nb7l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 03:06:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 03:06:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 03:06:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 03:06:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.121,PodIP:10.233.64.131,StartTime:2022-10-25 03:06:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 03:06:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/pause:3.7,ImageID:k8s.gcr.io/pause@sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c,ContainerID:containerd://76b60916e90be1da175bc71d37a2a007e2ed1f8da9fd44ff82ad32a34859c193,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.131,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Oct 25 03:06:06.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5222" for this suite.

• [SLOW TEST:6.092 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","total":356,"completed":287,"skipped":5302,"failed":0}
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:06:06.481: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-421
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 25 03:06:06.524: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Oct 25 03:06:06.656: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:06:08.687: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:06:10.668: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:06:12.669: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:06:14.667: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:06:16.668: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:06:18.669: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:06:20.669: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:06:22.670: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:06:24.667: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:06:26.672: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:06:28.669: INFO: The status of Pod netserver-0 is Running (Ready = true)
Oct 25 03:06:28.681: INFO: The status of Pod netserver-1 is Running (Ready = true)
Oct 25 03:06:28.692: INFO: The status of Pod netserver-2 is Running (Ready = true)
Oct 25 03:06:28.704: INFO: The status of Pod netserver-3 is Running (Ready = true)
Oct 25 03:06:28.717: INFO: The status of Pod netserver-4 is Running (Ready = true)
Oct 25 03:06:28.728: INFO: The status of Pod netserver-5 is Running (Ready = true)
STEP: Creating test pods
Oct 25 03:06:30.777: INFO: Setting MaxTries for pod polling to 66 for networking test based on endpoint count 6
Oct 25 03:06:30.777: INFO: Breadth first check of 10.233.99.65 on host 10.128.0.176...
Oct 25 03:06:30.784: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.74.38:9080/dial?request=hostname&protocol=udp&host=10.233.99.65&port=8081&tries=1'] Namespace:pod-network-test-421 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:06:30.784: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:06:30.785: INFO: ExecWithOptions: Clientset creation
Oct 25 03:06:30.785: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-421/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.74.38%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.99.65%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 25 03:06:30.869: INFO: Waiting for responses: map[]
Oct 25 03:06:30.869: INFO: reached 10.233.99.65 after 0/1 tries
Oct 25 03:06:30.869: INFO: Breadth first check of 10.233.107.57 on host 10.128.2.74...
Oct 25 03:06:30.876: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.74.38:9080/dial?request=hostname&protocol=udp&host=10.233.107.57&port=8081&tries=1'] Namespace:pod-network-test-421 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:06:30.876: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:06:30.876: INFO: ExecWithOptions: Clientset creation
Oct 25 03:06:30.877: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-421/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.74.38%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.107.57%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 25 03:06:30.963: INFO: Waiting for responses: map[]
Oct 25 03:06:30.963: INFO: reached 10.233.107.57 after 0/1 tries
Oct 25 03:06:30.963: INFO: Breadth first check of 10.233.105.55 on host 10.128.2.108...
Oct 25 03:06:30.970: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.74.38:9080/dial?request=hostname&protocol=udp&host=10.233.105.55&port=8081&tries=1'] Namespace:pod-network-test-421 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:06:30.971: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:06:30.971: INFO: ExecWithOptions: Clientset creation
Oct 25 03:06:30.971: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-421/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.74.38%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.105.55%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 25 03:06:31.049: INFO: Waiting for responses: map[]
Oct 25 03:06:31.049: INFO: reached 10.233.105.55 after 0/1 tries
Oct 25 03:06:31.049: INFO: Breadth first check of 10.233.95.80 on host 10.128.1.213...
Oct 25 03:06:31.056: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.74.38:9080/dial?request=hostname&protocol=udp&host=10.233.95.80&port=8081&tries=1'] Namespace:pod-network-test-421 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:06:31.056: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:06:31.057: INFO: ExecWithOptions: Clientset creation
Oct 25 03:06:31.057: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-421/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.74.38%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.95.80%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 25 03:06:31.134: INFO: Waiting for responses: map[]
Oct 25 03:06:31.134: INFO: reached 10.233.95.80 after 0/1 tries
Oct 25 03:06:31.134: INFO: Breadth first check of 10.233.64.133 on host 10.128.1.121...
Oct 25 03:06:31.141: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.74.38:9080/dial?request=hostname&protocol=udp&host=10.233.64.133&port=8081&tries=1'] Namespace:pod-network-test-421 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:06:31.141: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:06:31.141: INFO: ExecWithOptions: Clientset creation
Oct 25 03:06:31.141: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-421/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.74.38%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.64.133%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 25 03:06:31.226: INFO: Waiting for responses: map[]
Oct 25 03:06:31.226: INFO: reached 10.233.64.133 after 0/1 tries
Oct 25 03:06:31.226: INFO: Breadth first check of 10.233.74.44 on host 10.128.1.178...
Oct 25 03:06:31.235: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.74.38:9080/dial?request=hostname&protocol=udp&host=10.233.74.44&port=8081&tries=1'] Namespace:pod-network-test-421 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:06:31.235: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:06:31.235: INFO: ExecWithOptions: Clientset creation
Oct 25 03:06:31.235: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-421/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.233.74.38%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.233.74.44%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Oct 25 03:06:31.313: INFO: Waiting for responses: map[]
Oct 25 03:06:31.313: INFO: reached 10.233.74.44 after 0/1 tries
Oct 25 03:06:31.313: INFO: Going to retry 0 out of 6 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Oct 25 03:06:31.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-421" for this suite.

• [SLOW TEST:24.855 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":356,"completed":288,"skipped":5305,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:06:31.337: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1574
[It] should update a single-container pod's image  [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Oct 25 03:06:31.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3983 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Oct 25 03:06:31.452: INFO: stderr: ""
Oct 25 03:06:31.452: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Oct 25 03:06:36.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3983 get pod e2e-test-httpd-pod -o json'
Oct 25 03:06:36.605: INFO: stderr: ""
Oct 25 03:06:36.605: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"8ace88b3eca8465307cf09fb81b1bfb9925a64ee879383b07bf045c341ea1eaa\",\n            \"cni.projectcalico.org/podIP\": \"10.233.74.45/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.233.74.45/32\"\n        },\n        \"creationTimestamp\": \"2022-10-25T03:06:31Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3983\",\n        \"resourceVersion\": \"242496\",\n        \"uid\": \"9b37fb43-70fe-4d92-8c1a-c2d83778888a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-2ddd8\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"lab1-k8s-node-3\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-2ddd8\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-10-25T03:06:31Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-10-25T03:06:33Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-10-25T03:06:33Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-10-25T03:06:31Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://745d50f61db7ade51d5c569700a58c2a7976e683c3098100e1c1fe40fff3c2d3\",\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-10-25T03:06:32Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.128.1.178\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.74.45\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.233.74.45\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-10-25T03:06:31Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct 25 03:06:36.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3983 replace -f -'
Oct 25 03:06:37.510: INFO: stderr: ""
Oct 25 03:06:37.510: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/busybox:1.29-2
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1578
Oct 25 03:06:37.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-3983 delete pods e2e-test-httpd-pod'
Oct 25 03:06:39.233: INFO: stderr: ""
Oct 25 03:06:39.233: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 03:06:39.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3983" for this suite.

• [SLOW TEST:7.925 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1571
    should update a single-container pod's image  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":356,"completed":289,"skipped":5319,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:06:39.263: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 03:06:39.306: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 03:07:40.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5907" for this suite.

• [SLOW TEST:61.212 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":356,"completed":290,"skipped":5334,"failed":0}
SSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:07:40.476: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Oct 25 03:07:43.070: INFO: Successfully updated pod "adopt-release-g8tj4"
STEP: Checking that the Job readopts the Pod
Oct 25 03:07:43.071: INFO: Waiting up to 15m0s for pod "adopt-release-g8tj4" in namespace "job-9958" to be "adopted"
Oct 25 03:07:43.076: INFO: Pod "adopt-release-g8tj4": Phase="Running", Reason="", readiness=true. Elapsed: 5.562239ms
Oct 25 03:07:45.088: INFO: Pod "adopt-release-g8tj4": Phase="Running", Reason="", readiness=true. Elapsed: 2.017474433s
Oct 25 03:07:45.088: INFO: Pod "adopt-release-g8tj4" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Oct 25 03:07:45.620: INFO: Successfully updated pod "adopt-release-g8tj4"
STEP: Checking that the Job releases the Pod
Oct 25 03:07:45.620: INFO: Waiting up to 15m0s for pod "adopt-release-g8tj4" in namespace "job-9958" to be "released"
Oct 25 03:07:45.632: INFO: Pod "adopt-release-g8tj4": Phase="Running", Reason="", readiness=true. Elapsed: 11.379468ms
Oct 25 03:07:47.649: INFO: Pod "adopt-release-g8tj4": Phase="Running", Reason="", readiness=true. Elapsed: 2.028471227s
Oct 25 03:07:47.649: INFO: Pod "adopt-release-g8tj4" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Oct 25 03:07:47.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9958" for this suite.

• [SLOW TEST:7.204 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":356,"completed":291,"skipped":5338,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:07:47.683: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Oct 25 03:08:12.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-850" for this suite.

• [SLOW TEST:24.573 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":356,"completed":292,"skipped":5386,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:08:12.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 03:08:12.332: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 25 03:08:17.354: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Scaling up "test-rs" replicaset 
Oct 25 03:08:17.379: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet
Oct 25 03:08:17.451: INFO: observed ReplicaSet test-rs in namespace replicaset-9202 with ReadyReplicas 1, AvailableReplicas 1
Oct 25 03:08:17.468: INFO: observed ReplicaSet test-rs in namespace replicaset-9202 with ReadyReplicas 1, AvailableReplicas 1
Oct 25 03:08:17.492: INFO: observed ReplicaSet test-rs in namespace replicaset-9202 with ReadyReplicas 1, AvailableReplicas 1
Oct 25 03:08:18.565: INFO: observed ReplicaSet test-rs in namespace replicaset-9202 with ReadyReplicas 2, AvailableReplicas 2
Oct 25 03:08:19.045: INFO: observed Replicaset test-rs in namespace replicaset-9202 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Oct 25 03:08:19.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9202" for this suite.

• [SLOW TEST:6.818 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","total":356,"completed":293,"skipped":5396,"failed":0}
SSSSS
------------------------------
[sig-node] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:08:19.074: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-664f7482-318a-41fc-8674-503042dfbedf
STEP: Creating a pod to test consume secrets
Oct 25 03:08:19.145: INFO: Waiting up to 5m0s for pod "pod-secrets-bf3352f6-8fcb-4a5b-a5ad-351532e89544" in namespace "secrets-8209" to be "Succeeded or Failed"
Oct 25 03:08:19.151: INFO: Pod "pod-secrets-bf3352f6-8fcb-4a5b-a5ad-351532e89544": Phase="Pending", Reason="", readiness=false. Elapsed: 6.200758ms
Oct 25 03:08:21.162: INFO: Pod "pod-secrets-bf3352f6-8fcb-4a5b-a5ad-351532e89544": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017114136s
Oct 25 03:08:23.177: INFO: Pod "pod-secrets-bf3352f6-8fcb-4a5b-a5ad-351532e89544": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031848473s
STEP: Saw pod success
Oct 25 03:08:23.177: INFO: Pod "pod-secrets-bf3352f6-8fcb-4a5b-a5ad-351532e89544" satisfied condition "Succeeded or Failed"
Oct 25 03:08:23.183: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-secrets-bf3352f6-8fcb-4a5b-a5ad-351532e89544 container secret-env-test: <nil>
STEP: delete the pod
Oct 25 03:08:23.246: INFO: Waiting for pod pod-secrets-bf3352f6-8fcb-4a5b-a5ad-351532e89544 to disappear
Oct 25 03:08:23.252: INFO: Pod pod-secrets-bf3352f6-8fcb-4a5b-a5ad-351532e89544 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Oct 25 03:08:23.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8209" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":356,"completed":294,"skipped":5401,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Pods 
  should be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:08:23.280: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
Oct 25 03:08:23.343: INFO: The status of Pod pod-update-3b4a06b1-4414-4e78-97b2-b9f2baddf5c5 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:08:25.357: INFO: The status of Pod pod-update-3b4a06b1-4414-4e78-97b2-b9f2baddf5c5 is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 25 03:08:25.892: INFO: Successfully updated pod "pod-update-3b4a06b1-4414-4e78-97b2-b9f2baddf5c5"
STEP: verifying the updated pod is in kubernetes
Oct 25 03:08:25.905: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Oct 25 03:08:25.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4250" for this suite.
•{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","total":356,"completed":295,"skipped":5410,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:08:25.929: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-b77cf622-fcf4-435d-9fd5-42a4b6c8532f
STEP: Creating a pod to test consume configMaps
Oct 25 03:08:25.993: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-48c65ba8-e8f1-4ec3-9d86-754a91bdc7e2" in namespace "projected-4932" to be "Succeeded or Failed"
Oct 25 03:08:26.005: INFO: Pod "pod-projected-configmaps-48c65ba8-e8f1-4ec3-9d86-754a91bdc7e2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.836769ms
Oct 25 03:08:28.019: INFO: Pod "pod-projected-configmaps-48c65ba8-e8f1-4ec3-9d86-754a91bdc7e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026169267s
Oct 25 03:08:30.028: INFO: Pod "pod-projected-configmaps-48c65ba8-e8f1-4ec3-9d86-754a91bdc7e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035277504s
STEP: Saw pod success
Oct 25 03:08:30.028: INFO: Pod "pod-projected-configmaps-48c65ba8-e8f1-4ec3-9d86-754a91bdc7e2" satisfied condition "Succeeded or Failed"
Oct 25 03:08:30.035: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-projected-configmaps-48c65ba8-e8f1-4ec3-9d86-754a91bdc7e2 container agnhost-container: <nil>
STEP: delete the pod
Oct 25 03:08:30.076: INFO: Waiting for pod pod-projected-configmaps-48c65ba8-e8f1-4ec3-9d86-754a91bdc7e2 to disappear
Oct 25 03:08:30.082: INFO: Pod pod-projected-configmaps-48c65ba8-e8f1-4ec3-9d86-754a91bdc7e2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Oct 25 03:08:30.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4932" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":356,"completed":296,"skipped":5416,"failed":0}
SSS
------------------------------
[sig-node] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:08:30.105: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
Oct 25 03:08:30.162: INFO: The status of Pod pod-update-activedeadlineseconds-2cbb5f84-18d7-4e29-b476-afe4eaa57e8b is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:08:32.174: INFO: The status of Pod pod-update-activedeadlineseconds-2cbb5f84-18d7-4e29-b476-afe4eaa57e8b is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 25 03:08:32.711: INFO: Successfully updated pod "pod-update-activedeadlineseconds-2cbb5f84-18d7-4e29-b476-afe4eaa57e8b"
Oct 25 03:08:32.712: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-2cbb5f84-18d7-4e29-b476-afe4eaa57e8b" in namespace "pods-7572" to be "terminated due to deadline exceeded"
Oct 25 03:08:32.718: INFO: Pod "pod-update-activedeadlineseconds-2cbb5f84-18d7-4e29-b476-afe4eaa57e8b": Phase="Running", Reason="", readiness=true. Elapsed: 5.936318ms
Oct 25 03:08:34.732: INFO: Pod "pod-update-activedeadlineseconds-2cbb5f84-18d7-4e29-b476-afe4eaa57e8b": Phase="Running", Reason="", readiness=true. Elapsed: 2.019406765s
Oct 25 03:08:36.752: INFO: Pod "pod-update-activedeadlineseconds-2cbb5f84-18d7-4e29-b476-afe4eaa57e8b": Phase="Running", Reason="", readiness=false. Elapsed: 4.040246171s
Oct 25 03:08:38.765: INFO: Pod "pod-update-activedeadlineseconds-2cbb5f84-18d7-4e29-b476-afe4eaa57e8b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.052474794s
Oct 25 03:08:38.765: INFO: Pod "pod-update-activedeadlineseconds-2cbb5f84-18d7-4e29-b476-afe4eaa57e8b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Oct 25 03:08:38.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7572" for this suite.

• [SLOW TEST:8.684 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":356,"completed":297,"skipped":5419,"failed":0}
SSS
------------------------------
[sig-api-machinery] Discovery 
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:08:38.790: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename discovery
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 03:08:39.064: INFO: Checking APIGroup: apiregistration.k8s.io
Oct 25 03:08:39.065: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Oct 25 03:08:39.065: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Oct 25 03:08:39.065: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Oct 25 03:08:39.065: INFO: Checking APIGroup: apps
Oct 25 03:08:39.067: INFO: PreferredVersion.GroupVersion: apps/v1
Oct 25 03:08:39.067: INFO: Versions found [{apps/v1 v1}]
Oct 25 03:08:39.067: INFO: apps/v1 matches apps/v1
Oct 25 03:08:39.067: INFO: Checking APIGroup: events.k8s.io
Oct 25 03:08:39.068: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Oct 25 03:08:39.068: INFO: Versions found [{events.k8s.io/v1 v1} {events.k8s.io/v1beta1 v1beta1}]
Oct 25 03:08:39.068: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Oct 25 03:08:39.068: INFO: Checking APIGroup: authentication.k8s.io
Oct 25 03:08:39.069: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Oct 25 03:08:39.069: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Oct 25 03:08:39.069: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Oct 25 03:08:39.069: INFO: Checking APIGroup: authorization.k8s.io
Oct 25 03:08:39.071: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Oct 25 03:08:39.071: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Oct 25 03:08:39.071: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Oct 25 03:08:39.071: INFO: Checking APIGroup: autoscaling
Oct 25 03:08:39.072: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Oct 25 03:08:39.072: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta1 v2beta1} {autoscaling/v2beta2 v2beta2}]
Oct 25 03:08:39.072: INFO: autoscaling/v2 matches autoscaling/v2
Oct 25 03:08:39.072: INFO: Checking APIGroup: batch
Oct 25 03:08:39.073: INFO: PreferredVersion.GroupVersion: batch/v1
Oct 25 03:08:39.073: INFO: Versions found [{batch/v1 v1} {batch/v1beta1 v1beta1}]
Oct 25 03:08:39.073: INFO: batch/v1 matches batch/v1
Oct 25 03:08:39.073: INFO: Checking APIGroup: certificates.k8s.io
Oct 25 03:08:39.075: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Oct 25 03:08:39.075: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Oct 25 03:08:39.075: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Oct 25 03:08:39.075: INFO: Checking APIGroup: networking.k8s.io
Oct 25 03:08:39.076: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Oct 25 03:08:39.076: INFO: Versions found [{networking.k8s.io/v1 v1}]
Oct 25 03:08:39.076: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Oct 25 03:08:39.076: INFO: Checking APIGroup: policy
Oct 25 03:08:39.077: INFO: PreferredVersion.GroupVersion: policy/v1
Oct 25 03:08:39.077: INFO: Versions found [{policy/v1 v1} {policy/v1beta1 v1beta1}]
Oct 25 03:08:39.077: INFO: policy/v1 matches policy/v1
Oct 25 03:08:39.077: INFO: Checking APIGroup: rbac.authorization.k8s.io
Oct 25 03:08:39.078: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Oct 25 03:08:39.078: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Oct 25 03:08:39.078: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Oct 25 03:08:39.078: INFO: Checking APIGroup: storage.k8s.io
Oct 25 03:08:39.079: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Oct 25 03:08:39.080: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Oct 25 03:08:39.080: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Oct 25 03:08:39.080: INFO: Checking APIGroup: admissionregistration.k8s.io
Oct 25 03:08:39.081: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Oct 25 03:08:39.081: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Oct 25 03:08:39.081: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Oct 25 03:08:39.081: INFO: Checking APIGroup: apiextensions.k8s.io
Oct 25 03:08:39.082: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Oct 25 03:08:39.082: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Oct 25 03:08:39.082: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Oct 25 03:08:39.082: INFO: Checking APIGroup: scheduling.k8s.io
Oct 25 03:08:39.084: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Oct 25 03:08:39.084: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Oct 25 03:08:39.084: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Oct 25 03:08:39.084: INFO: Checking APIGroup: coordination.k8s.io
Oct 25 03:08:39.085: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Oct 25 03:08:39.085: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Oct 25 03:08:39.085: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Oct 25 03:08:39.085: INFO: Checking APIGroup: node.k8s.io
Oct 25 03:08:39.088: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Oct 25 03:08:39.088: INFO: Versions found [{node.k8s.io/v1 v1} {node.k8s.io/v1beta1 v1beta1}]
Oct 25 03:08:39.088: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Oct 25 03:08:39.088: INFO: Checking APIGroup: discovery.k8s.io
Oct 25 03:08:39.089: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Oct 25 03:08:39.089: INFO: Versions found [{discovery.k8s.io/v1 v1} {discovery.k8s.io/v1beta1 v1beta1}]
Oct 25 03:08:39.089: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Oct 25 03:08:39.089: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Oct 25 03:08:39.090: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Oct 25 03:08:39.090: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Oct 25 03:08:39.090: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Oct 25 03:08:39.090: INFO: Checking APIGroup: crd.projectcalico.org
Oct 25 03:08:39.092: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Oct 25 03:08:39.092: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Oct 25 03:08:39.092: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
Oct 25 03:08:39.092: INFO: Checking APIGroup: snapshot.storage.k8s.io
Oct 25 03:08:39.093: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
Oct 25 03:08:39.093: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1} {snapshot.storage.k8s.io/v1beta1 v1beta1}]
Oct 25 03:08:39.093: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
Oct 25 03:08:39.093: INFO: Checking APIGroup: metrics.k8s.io
Oct 25 03:08:39.095: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Oct 25 03:08:39.095: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Oct 25 03:08:39.095: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:188
Oct 25 03:08:39.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-6447" for this suite.
•{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","total":356,"completed":298,"skipped":5422,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:08:39.118: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-0522d7b9-de21-4713-9108-56587bc8ba4b
STEP: Creating a pod to test consume configMaps
Oct 25 03:08:39.177: INFO: Waiting up to 5m0s for pod "pod-configmaps-a2123416-e850-47bc-b5da-bf0433cb2681" in namespace "configmap-2221" to be "Succeeded or Failed"
Oct 25 03:08:39.187: INFO: Pod "pod-configmaps-a2123416-e850-47bc-b5da-bf0433cb2681": Phase="Pending", Reason="", readiness=false. Elapsed: 9.880433ms
Oct 25 03:08:41.199: INFO: Pod "pod-configmaps-a2123416-e850-47bc-b5da-bf0433cb2681": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022141525s
Oct 25 03:08:43.217: INFO: Pod "pod-configmaps-a2123416-e850-47bc-b5da-bf0433cb2681": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039931113s
STEP: Saw pod success
Oct 25 03:08:43.217: INFO: Pod "pod-configmaps-a2123416-e850-47bc-b5da-bf0433cb2681" satisfied condition "Succeeded or Failed"
Oct 25 03:08:43.223: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-configmaps-a2123416-e850-47bc-b5da-bf0433cb2681 container agnhost-container: <nil>
STEP: delete the pod
Oct 25 03:08:43.270: INFO: Waiting for pod pod-configmaps-a2123416-e850-47bc-b5da-bf0433cb2681 to disappear
Oct 25 03:08:43.275: INFO: Pod pod-configmaps-a2123416-e850-47bc-b5da-bf0433cb2681 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 03:08:43.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2221" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":356,"completed":299,"skipped":5442,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:08:43.299: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 25 03:08:43.364: INFO: Waiting up to 5m0s for pod "pod-ee929bab-2800-432b-a2a7-cd597e24eb75" in namespace "emptydir-7796" to be "Succeeded or Failed"
Oct 25 03:08:43.377: INFO: Pod "pod-ee929bab-2800-432b-a2a7-cd597e24eb75": Phase="Pending", Reason="", readiness=false. Elapsed: 13.147316ms
Oct 25 03:08:45.390: INFO: Pod "pod-ee929bab-2800-432b-a2a7-cd597e24eb75": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0260563s
Oct 25 03:08:47.403: INFO: Pod "pod-ee929bab-2800-432b-a2a7-cd597e24eb75": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039043961s
STEP: Saw pod success
Oct 25 03:08:47.403: INFO: Pod "pod-ee929bab-2800-432b-a2a7-cd597e24eb75" satisfied condition "Succeeded or Failed"
Oct 25 03:08:47.408: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-ee929bab-2800-432b-a2a7-cd597e24eb75 container test-container: <nil>
STEP: delete the pod
Oct 25 03:08:47.449: INFO: Waiting for pod pod-ee929bab-2800-432b-a2a7-cd597e24eb75 to disappear
Oct 25 03:08:47.455: INFO: Pod pod-ee929bab-2800-432b-a2a7-cd597e24eb75 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 03:08:47.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7796" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":300,"skipped":5448,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:08:47.484: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-projected-2xqs
STEP: Creating a pod to test atomic-volume-subpath
Oct 25 03:08:47.551: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-2xqs" in namespace "subpath-5669" to be "Succeeded or Failed"
Oct 25 03:08:47.557: INFO: Pod "pod-subpath-test-projected-2xqs": Phase="Pending", Reason="", readiness=false. Elapsed: 5.681329ms
Oct 25 03:08:49.570: INFO: Pod "pod-subpath-test-projected-2xqs": Phase="Running", Reason="", readiness=true. Elapsed: 2.018824897s
Oct 25 03:08:51.584: INFO: Pod "pod-subpath-test-projected-2xqs": Phase="Running", Reason="", readiness=true. Elapsed: 4.032812225s
Oct 25 03:08:53.597: INFO: Pod "pod-subpath-test-projected-2xqs": Phase="Running", Reason="", readiness=true. Elapsed: 6.045785064s
Oct 25 03:08:55.610: INFO: Pod "pod-subpath-test-projected-2xqs": Phase="Running", Reason="", readiness=true. Elapsed: 8.059339905s
Oct 25 03:08:57.625: INFO: Pod "pod-subpath-test-projected-2xqs": Phase="Running", Reason="", readiness=true. Elapsed: 10.074010508s
Oct 25 03:08:59.639: INFO: Pod "pod-subpath-test-projected-2xqs": Phase="Running", Reason="", readiness=true. Elapsed: 12.088187966s
Oct 25 03:09:01.652: INFO: Pod "pod-subpath-test-projected-2xqs": Phase="Running", Reason="", readiness=true. Elapsed: 14.101011089s
Oct 25 03:09:03.665: INFO: Pod "pod-subpath-test-projected-2xqs": Phase="Running", Reason="", readiness=true. Elapsed: 16.113859863s
Oct 25 03:09:05.677: INFO: Pod "pod-subpath-test-projected-2xqs": Phase="Running", Reason="", readiness=true. Elapsed: 18.126543693s
Oct 25 03:09:07.712: INFO: Pod "pod-subpath-test-projected-2xqs": Phase="Running", Reason="", readiness=true. Elapsed: 20.160754917s
Oct 25 03:09:09.725: INFO: Pod "pod-subpath-test-projected-2xqs": Phase="Running", Reason="", readiness=false. Elapsed: 22.174187733s
Oct 25 03:09:11.738: INFO: Pod "pod-subpath-test-projected-2xqs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.187617694s
STEP: Saw pod success
Oct 25 03:09:11.739: INFO: Pod "pod-subpath-test-projected-2xqs" satisfied condition "Succeeded or Failed"
Oct 25 03:09:11.744: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-subpath-test-projected-2xqs container test-container-subpath-projected-2xqs: <nil>
STEP: delete the pod
Oct 25 03:09:11.801: INFO: Waiting for pod pod-subpath-test-projected-2xqs to disappear
Oct 25 03:09:11.806: INFO: Pod pod-subpath-test-projected-2xqs no longer exists
STEP: Deleting pod pod-subpath-test-projected-2xqs
Oct 25 03:09:11.806: INFO: Deleting pod "pod-subpath-test-projected-2xqs" in namespace "subpath-5669"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Oct 25 03:09:11.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5669" for this suite.

• [SLOW TEST:24.360 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","total":356,"completed":301,"skipped":5491,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:09:11.844: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct 25 03:09:11.926: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-76  0a099de8-e689-40a5-a2c0-9870e8d1bd25 243661 0 2022-10-25 03:09:11 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-10-25 03:09:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 25 03:09:11.927: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-76  0a099de8-e689-40a5-a2c0-9870e8d1bd25 243662 0 2022-10-25 03:09:11 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-10-25 03:09:11 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Oct 25 03:09:11.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-76" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":356,"completed":302,"skipped":5492,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:09:11.950: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 25 03:09:12.005: INFO: Waiting up to 5m0s for pod "pod-f6c38e22-0eb1-43a9-b86d-8379b23c75fc" in namespace "emptydir-8751" to be "Succeeded or Failed"
Oct 25 03:09:12.011: INFO: Pod "pod-f6c38e22-0eb1-43a9-b86d-8379b23c75fc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.142935ms
Oct 25 03:09:14.023: INFO: Pod "pod-f6c38e22-0eb1-43a9-b86d-8379b23c75fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018436925s
Oct 25 03:09:16.036: INFO: Pod "pod-f6c38e22-0eb1-43a9-b86d-8379b23c75fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03100683s
STEP: Saw pod success
Oct 25 03:09:16.036: INFO: Pod "pod-f6c38e22-0eb1-43a9-b86d-8379b23c75fc" satisfied condition "Succeeded or Failed"
Oct 25 03:09:16.041: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-f6c38e22-0eb1-43a9-b86d-8379b23c75fc container test-container: <nil>
STEP: delete the pod
Oct 25 03:09:16.080: INFO: Waiting for pod pod-f6c38e22-0eb1-43a9-b86d-8379b23c75fc to disappear
Oct 25 03:09:16.088: INFO: Pod pod-f6c38e22-0eb1-43a9-b86d-8379b23c75fc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 03:09:16.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8751" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":303,"skipped":5532,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:09:16.121: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 03:09:16.155: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Oct 25 03:09:18.229: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Oct 25 03:09:19.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7030" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":356,"completed":304,"skipped":5599,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:09:19.271: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating pod
Oct 25 03:09:19.338: INFO: The status of Pod pod-hostip-2bfb2eed-b36a-458e-a51e-55b51594fc16 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:09:21.350: INFO: The status of Pod pod-hostip-2bfb2eed-b36a-458e-a51e-55b51594fc16 is Running (Ready = true)
Oct 25 03:09:21.360: INFO: Pod pod-hostip-2bfb2eed-b36a-458e-a51e-55b51594fc16 has hostIP: 10.128.1.178
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Oct 25 03:09:21.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9376" for this suite.
•{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","total":356,"completed":305,"skipped":5672,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:09:21.387: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Oct 25 03:09:21.454: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:09:23.467: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Oct 25 03:09:23.488: INFO: The status of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:09:25.500: INFO: The status of Pod pod-with-prestop-exec-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Oct 25 03:09:25.522: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 25 03:09:25.528: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 25 03:09:27.529: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 25 03:09:27.541: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 25 03:09:29.529: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 25 03:09:29.542: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Oct 25 03:09:29.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3780" for this suite.

• [SLOW TEST:8.205 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":356,"completed":306,"skipped":5719,"failed":0}
SSSS
------------------------------
[sig-node] ConfigMap 
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:09:29.592: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ConfigMap
STEP: fetching the ConfigMap
STEP: patching the ConfigMap
STEP: listing all ConfigMaps in all namespaces with a label selector
STEP: deleting the ConfigMap by collection with a label selector
STEP: listing all ConfigMaps in test namespace
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 03:09:29.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5940" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","total":356,"completed":307,"skipped":5723,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:09:29.705: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-fcd8bdbd-9d09-4ce7-854d-d942593bc6ae
STEP: Creating a pod to test consume secrets
Oct 25 03:09:29.765: INFO: Waiting up to 5m0s for pod "pod-secrets-d453a3d6-7c16-40c5-957a-3604184840af" in namespace "secrets-3940" to be "Succeeded or Failed"
Oct 25 03:09:29.774: INFO: Pod "pod-secrets-d453a3d6-7c16-40c5-957a-3604184840af": Phase="Pending", Reason="", readiness=false. Elapsed: 8.349696ms
Oct 25 03:09:31.786: INFO: Pod "pod-secrets-d453a3d6-7c16-40c5-957a-3604184840af": Phase="Running", Reason="", readiness=false. Elapsed: 2.021045473s
Oct 25 03:09:33.799: INFO: Pod "pod-secrets-d453a3d6-7c16-40c5-957a-3604184840af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033865733s
STEP: Saw pod success
Oct 25 03:09:33.799: INFO: Pod "pod-secrets-d453a3d6-7c16-40c5-957a-3604184840af" satisfied condition "Succeeded or Failed"
Oct 25 03:09:33.805: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-secrets-d453a3d6-7c16-40c5-957a-3604184840af container secret-volume-test: <nil>
STEP: delete the pod
Oct 25 03:09:33.838: INFO: Waiting for pod pod-secrets-d453a3d6-7c16-40c5-957a-3604184840af to disappear
Oct 25 03:09:33.844: INFO: Pod pod-secrets-d453a3d6-7c16-40c5-957a-3604184840af no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Oct 25 03:09:33.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3940" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":308,"skipped":5730,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:09:33.869: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check is all data is printed  [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 03:09:33.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6985 version'
Oct 25 03:09:33.957: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Oct 25 03:09:33.957: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.6\", GitCommit:\"b39bf148cd654599a52e867485c02c4f9d28b312\", GitTreeState:\"clean\", BuildDate:\"2022-09-21T13:19:24Z\", GoVersion:\"go1.18.6\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.4\nServer Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.6\", GitCommit:\"b39bf148cd654599a52e867485c02c4f9d28b312\", GitTreeState:\"clean\", BuildDate:\"2022-09-21T13:12:04Z\", GoVersion:\"go1.18.6\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 03:09:33.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6985" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":356,"completed":309,"skipped":5730,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:09:33.983: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 03:09:34.024: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Creating first CR 
Oct 25 03:09:41.672: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-25T03:09:41Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-25T03:09:41Z]] name:name1 resourceVersion:244035 uid:7261e5cf-3664-46b4-a853-33d9d3125f0c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Oct 25 03:09:51.694: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-25T03:09:51Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-25T03:09:51Z]] name:name2 resourceVersion:244066 uid:ff1f0fdf-3059-4521-b20b-f4951cb8b820] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Oct 25 03:10:01.716: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-25T03:09:41Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-25T03:10:01Z]] name:name1 resourceVersion:244095 uid:7261e5cf-3664-46b4-a853-33d9d3125f0c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Oct 25 03:10:11.746: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-25T03:09:51Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-25T03:10:11Z]] name:name2 resourceVersion:244126 uid:ff1f0fdf-3059-4521-b20b-f4951cb8b820] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Oct 25 03:10:21.763: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-25T03:09:41Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-25T03:10:01Z]] name:name1 resourceVersion:244155 uid:7261e5cf-3664-46b4-a853-33d9d3125f0c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Oct 25 03:10:31.795: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-10-25T03:09:51Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-10-25T03:10:11Z]] name:name2 resourceVersion:244187 uid:ff1f0fdf-3059-4521-b20b-f4951cb8b820] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 03:10:42.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-2645" for this suite.

• [SLOW TEST:68.378 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":356,"completed":310,"skipped":5761,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:10:42.365: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 03:10:42.487: INFO: The status of Pod busybox-scheduling-fb4ce779-4a6d-4211-b2dc-bcba4d27f4af is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:10:44.500: INFO: The status of Pod busybox-scheduling-fb4ce779-4a6d-4211-b2dc-bcba4d27f4af is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Oct 25 03:10:44.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7073" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":356,"completed":311,"skipped":5786,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:10:44.546: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap configmap-8293/configmap-test-e1a264e5-d25c-4813-a711-e31efab8175a
STEP: Creating a pod to test consume configMaps
Oct 25 03:10:44.626: INFO: Waiting up to 5m0s for pod "pod-configmaps-7eece0da-58d3-4b2c-90ed-07f9d767d4f5" in namespace "configmap-8293" to be "Succeeded or Failed"
Oct 25 03:10:44.632: INFO: Pod "pod-configmaps-7eece0da-58d3-4b2c-90ed-07f9d767d4f5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.773032ms
Oct 25 03:10:46.644: INFO: Pod "pod-configmaps-7eece0da-58d3-4b2c-90ed-07f9d767d4f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017793973s
Oct 25 03:10:48.658: INFO: Pod "pod-configmaps-7eece0da-58d3-4b2c-90ed-07f9d767d4f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031397432s
STEP: Saw pod success
Oct 25 03:10:48.658: INFO: Pod "pod-configmaps-7eece0da-58d3-4b2c-90ed-07f9d767d4f5" satisfied condition "Succeeded or Failed"
Oct 25 03:10:48.664: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-configmaps-7eece0da-58d3-4b2c-90ed-07f9d767d4f5 container env-test: <nil>
STEP: delete the pod
Oct 25 03:10:48.702: INFO: Waiting for pod pod-configmaps-7eece0da-58d3-4b2c-90ed-07f9d767d4f5 to disappear
Oct 25 03:10:48.709: INFO: Pod pod-configmaps-7eece0da-58d3-4b2c-90ed-07f9d767d4f5 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Oct 25 03:10:48.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8293" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":356,"completed":312,"skipped":5799,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:10:48.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 03:10:48.791: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-902f9128-6d47-4527-9ff9-4a9def1b7a3a" in namespace "security-context-test-8459" to be "Succeeded or Failed"
Oct 25 03:10:48.800: INFO: Pod "alpine-nnp-false-902f9128-6d47-4527-9ff9-4a9def1b7a3a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.720344ms
Oct 25 03:10:50.812: INFO: Pod "alpine-nnp-false-902f9128-6d47-4527-9ff9-4a9def1b7a3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020584508s
Oct 25 03:10:52.824: INFO: Pod "alpine-nnp-false-902f9128-6d47-4527-9ff9-4a9def1b7a3a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032879692s
Oct 25 03:10:54.838: INFO: Pod "alpine-nnp-false-902f9128-6d47-4527-9ff9-4a9def1b7a3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.047298266s
Oct 25 03:10:54.838: INFO: Pod "alpine-nnp-false-902f9128-6d47-4527-9ff9-4a9def1b7a3a" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Oct 25 03:10:54.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8459" for this suite.

• [SLOW TEST:6.142 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:298
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":313,"skipped":5813,"failed":0}
SSSSS
------------------------------
[sig-node] RuntimeClass 
   should support RuntimeClasses API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:10:54.876: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/node.k8s.io
STEP: getting /apis/node.k8s.io/v1
STEP: creating
STEP: watching
Oct 25 03:10:54.964: INFO: starting watch
STEP: getting
STEP: listing
STEP: patching
STEP: updating
Oct 25 03:10:55.017: INFO: waiting for watch events with expected annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Oct 25 03:10:55.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-5236" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","total":356,"completed":314,"skipped":5818,"failed":0}
SSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:10:55.108: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service multi-endpoint-test in namespace services-5582
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5582 to expose endpoints map[]
Oct 25 03:10:55.190: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Oct 25 03:10:56.222: INFO: successfully validated that service multi-endpoint-test in namespace services-5582 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-5582
Oct 25 03:10:56.267: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:10:58.279: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5582 to expose endpoints map[pod1:[100]]
Oct 25 03:10:58.301: INFO: successfully validated that service multi-endpoint-test in namespace services-5582 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-5582
Oct 25 03:10:58.320: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:11:00.338: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5582 to expose endpoints map[pod1:[100] pod2:[101]]
Oct 25 03:11:00.375: INFO: successfully validated that service multi-endpoint-test in namespace services-5582 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods
Oct 25 03:11:00.375: INFO: Creating new exec pod
Oct 25 03:11:03.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-5582 exec execpod2mckm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Oct 25 03:11:03.561: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Oct 25 03:11:03.561: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 03:11:03.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-5582 exec execpod2mckm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.17.12 80'
Oct 25 03:11:03.711: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.17.12 80\nConnection to 10.233.17.12 80 port [tcp/http] succeeded!\n"
Oct 25 03:11:03.711: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 03:11:03.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-5582 exec execpod2mckm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Oct 25 03:11:03.850: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Oct 25 03:11:03.850: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 03:11:03.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-5582 exec execpod2mckm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.17.12 81'
Oct 25 03:11:03.991: INFO: stderr: "+ nc -v -t -w 2 10.233.17.12 81\n+ echo hostName\nConnection to 10.233.17.12 81 port [tcp/*] succeeded!\n"
Oct 25 03:11:03.991: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-5582
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5582 to expose endpoints map[pod2:[101]]
Oct 25 03:11:04.051: INFO: successfully validated that service multi-endpoint-test in namespace services-5582 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-5582
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5582 to expose endpoints map[]
Oct 25 03:11:04.113: INFO: successfully validated that service multi-endpoint-test in namespace services-5582 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 03:11:04.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5582" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:9.069 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":356,"completed":315,"skipped":5825,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:11:04.177: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1159.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1159.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1159.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1159.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1159.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1159.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1159.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1159.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 25 03:11:06.295: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local from pod dns-1159/dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2: the server could not find the requested resource (get pods dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2)
Oct 25 03:11:06.303: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local from pod dns-1159/dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2: the server could not find the requested resource (get pods dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2)
Oct 25 03:11:06.311: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1159.svc.cluster.local from pod dns-1159/dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2: the server could not find the requested resource (get pods dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2)
Oct 25 03:11:06.318: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1159.svc.cluster.local from pod dns-1159/dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2: the server could not find the requested resource (get pods dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2)
Oct 25 03:11:06.326: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local from pod dns-1159/dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2: the server could not find the requested resource (get pods dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2)
Oct 25 03:11:06.334: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local from pod dns-1159/dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2: the server could not find the requested resource (get pods dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2)
Oct 25 03:11:06.342: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1159.svc.cluster.local from pod dns-1159/dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2: the server could not find the requested resource (get pods dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2)
Oct 25 03:11:06.351: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1159.svc.cluster.local from pod dns-1159/dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2: the server could not find the requested resource (get pods dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2)
Oct 25 03:11:06.351: INFO: Lookups using dns-1159/dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1159.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1159.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1159.svc.cluster.local jessie_udp@dns-test-service-2.dns-1159.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1159.svc.cluster.local]

Oct 25 03:11:11.414: INFO: DNS probes using dns-1159/dns-test-4525c78d-cbec-41f9-a4dc-f10b9a7fd8b2 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Oct 25 03:11:11.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1159" for this suite.

• [SLOW TEST:7.335 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":356,"completed":316,"skipped":5835,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:11:11.513: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 03:11:11.573: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9c2b7a39-2896-459d-b3d3-570dcdac9e15" in namespace "downward-api-5844" to be "Succeeded or Failed"
Oct 25 03:11:11.583: INFO: Pod "downwardapi-volume-9c2b7a39-2896-459d-b3d3-570dcdac9e15": Phase="Pending", Reason="", readiness=false. Elapsed: 9.517618ms
Oct 25 03:11:13.595: INFO: Pod "downwardapi-volume-9c2b7a39-2896-459d-b3d3-570dcdac9e15": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022217164s
Oct 25 03:11:15.609: INFO: Pod "downwardapi-volume-9c2b7a39-2896-459d-b3d3-570dcdac9e15": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035466793s
STEP: Saw pod success
Oct 25 03:11:15.609: INFO: Pod "downwardapi-volume-9c2b7a39-2896-459d-b3d3-570dcdac9e15" satisfied condition "Succeeded or Failed"
Oct 25 03:11:15.614: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-9c2b7a39-2896-459d-b3d3-570dcdac9e15 container client-container: <nil>
STEP: delete the pod
Oct 25 03:11:15.646: INFO: Waiting for pod downwardapi-volume-9c2b7a39-2896-459d-b3d3-570dcdac9e15 to disappear
Oct 25 03:11:15.651: INFO: Pod downwardapi-volume-9c2b7a39-2896-459d-b3d3-570dcdac9e15 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Oct 25 03:11:15.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5844" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":317,"skipped":5836,"failed":0}
SSS
------------------------------
[sig-node] RuntimeClass 
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:11:15.672: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename runtimeclass
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Deleting RuntimeClass runtimeclass-1526-delete-me
STEP: Waiting for the RuntimeClass to disappear
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Oct 25 03:11:15.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1526" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","total":356,"completed":318,"skipped":5839,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:11:15.780: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-9615
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 25 03:11:15.815: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Oct 25 03:11:15.955: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:11:17.968: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:11:19.968: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:11:21.964: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:11:23.967: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:11:25.968: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:11:27.969: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:11:29.969: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:11:31.965: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:11:33.966: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:11:35.967: INFO: The status of Pod netserver-0 is Running (Ready = false)
Oct 25 03:11:37.967: INFO: The status of Pod netserver-0 is Running (Ready = true)
Oct 25 03:11:37.978: INFO: The status of Pod netserver-1 is Running (Ready = true)
Oct 25 03:11:37.989: INFO: The status of Pod netserver-2 is Running (Ready = true)
Oct 25 03:11:38.002: INFO: The status of Pod netserver-3 is Running (Ready = true)
Oct 25 03:11:38.014: INFO: The status of Pod netserver-4 is Running (Ready = true)
Oct 25 03:11:38.024: INFO: The status of Pod netserver-5 is Running (Ready = true)
STEP: Creating test pods
Oct 25 03:11:40.101: INFO: Setting MaxTries for pod polling to 66 for networking test based on endpoint count 6
Oct 25 03:11:40.101: INFO: Going to poll 10.233.99.67 on port 8081 at least 0 times, with a maximum of 66 tries before failing
Oct 25 03:11:40.106: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.99.67 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9615 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:11:40.106: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:11:40.106: INFO: ExecWithOptions: Clientset creation
Oct 25 03:11:40.107: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9615/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.99.67+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 25 03:11:41.197: INFO: Found all 1 expected endpoints: [netserver-0]
Oct 25 03:11:41.197: INFO: Going to poll 10.233.107.58 on port 8081 at least 0 times, with a maximum of 66 tries before failing
Oct 25 03:11:41.208: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.107.58 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9615 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:11:41.208: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:11:41.209: INFO: ExecWithOptions: Clientset creation
Oct 25 03:11:41.209: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9615/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.107.58+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 25 03:11:42.299: INFO: Found all 1 expected endpoints: [netserver-1]
Oct 25 03:11:42.299: INFO: Going to poll 10.233.105.56 on port 8081 at least 0 times, with a maximum of 66 tries before failing
Oct 25 03:11:42.308: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.105.56 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9615 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:11:42.308: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:11:42.309: INFO: ExecWithOptions: Clientset creation
Oct 25 03:11:42.309: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9615/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.105.56+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 25 03:11:43.395: INFO: Found all 1 expected endpoints: [netserver-2]
Oct 25 03:11:43.395: INFO: Going to poll 10.233.95.82 on port 8081 at least 0 times, with a maximum of 66 tries before failing
Oct 25 03:11:43.404: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.95.82 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9615 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:11:43.404: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:11:43.404: INFO: ExecWithOptions: Clientset creation
Oct 25 03:11:43.404: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9615/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.95.82+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 25 03:11:44.475: INFO: Found all 1 expected endpoints: [netserver-3]
Oct 25 03:11:44.475: INFO: Going to poll 10.233.64.138 on port 8081 at least 0 times, with a maximum of 66 tries before failing
Oct 25 03:11:44.484: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.64.138 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9615 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:11:44.484: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:11:44.485: INFO: ExecWithOptions: Clientset creation
Oct 25 03:11:44.485: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9615/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.64.138+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 25 03:11:45.555: INFO: Found all 1 expected endpoints: [netserver-4]
Oct 25 03:11:45.555: INFO: Going to poll 10.233.74.74 on port 8081 at least 0 times, with a maximum of 66 tries before failing
Oct 25 03:11:45.566: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.233.74.74 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9615 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:11:45.566: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:11:45.567: INFO: ExecWithOptions: Clientset creation
Oct 25 03:11:45.567: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/pod-network-test-9615/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.233.74.74+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Oct 25 03:11:46.649: INFO: Found all 1 expected endpoints: [netserver-5]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Oct 25 03:11:46.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9615" for this suite.

• [SLOW TEST:30.905 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":319,"skipped":5849,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  Deployment should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:11:46.686: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 03:11:46.728: INFO: Creating simple deployment test-new-deployment
Oct 25 03:11:46.763: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the deployment Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Oct 25 03:11:48.863: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-5976  bb4c1c19-32ac-4ee4-bd86-606d799e1e82 244853 3 2022-10-25 03:11:46 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-10-25 03:11:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 03:11:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0025a2118 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-10-25 03:11:47 +0000 UTC,LastTransitionTime:2022-10-25 03:11:47 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-55df494869" has successfully progressed.,LastUpdateTime:2022-10-25 03:11:47 +0000 UTC,LastTransitionTime:2022-10-25 03:11:46 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct 25 03:11:48.869: INFO: New ReplicaSet "test-new-deployment-55df494869" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-55df494869  deployment-5976  607a8397-477e-4db0-b6f7-a3d91075930e 244860 2 2022-10-25 03:11:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment bb4c1c19-32ac-4ee4-bd86-606d799e1e82 0xc0044929f7 0xc0044929f8}] []  [{kube-controller-manager Update apps/v1 2022-10-25 03:11:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bb4c1c19-32ac-4ee4-bd86-606d799e1e82\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-10-25 03:11:47 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 55df494869,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004492a88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 25 03:11:48.877: INFO: Pod "test-new-deployment-55df494869-hvw4f" is available:
&Pod{ObjectMeta:{test-new-deployment-55df494869-hvw4f test-new-deployment-55df494869- deployment-5976  bf300577-1b65-495f-acf6-b02e30277735 244841 0 2022-10-25 03:11:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[cni.projectcalico.org/containerID:51c972969954f0cfbf1ef14b5899c4a13282f32101aa37ca3c3b48acb7cfa393 cni.projectcalico.org/podIP:10.233.64.139/32 cni.projectcalico.org/podIPs:10.233.64.139/32] [{apps/v1 ReplicaSet test-new-deployment-55df494869 607a8397-477e-4db0-b6f7-a3d91075930e 0xc0025a2547 0xc0025a2548}] []  [{kube-controller-manager Update v1 2022-10-25 03:11:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"607a8397-477e-4db0-b6f7-a3d91075930e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-10-25 03:11:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-10-25 03:11:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.233.64.139\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tvrql,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tvrql,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 03:11:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 03:11:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 03:11:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 03:11:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.1.121,PodIP:10.233.64.139,StartTime:2022-10-25 03:11:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-10-25 03:11:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://30d4415d911f625661381c16cc3829203507ee065039e980798ab1d10b8ec749,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.233.64.139,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 25 03:11:48.877: INFO: Pod "test-new-deployment-55df494869-kws6n" is not available:
&Pod{ObjectMeta:{test-new-deployment-55df494869-kws6n test-new-deployment-55df494869- deployment-5976  d16af1f5-825e-43fd-becc-bd9674520cd9 244858 0 2022-10-25 03:11:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [{apps/v1 ReplicaSet test-new-deployment-55df494869 607a8397-477e-4db0-b6f7-a3d91075930e 0xc0025a2757 0xc0025a2758}] []  [{kube-controller-manager Update v1 2022-10-25 03:11:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"607a8397-477e-4db0-b6f7-a3d91075930e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5s4x5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5s4x5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:lab1-k8s-node-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-10-25 03:11:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Oct 25 03:11:48.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5976" for this suite.
•{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","total":356,"completed":320,"skipped":5926,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:11:48.915: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-configmap-vbxj
STEP: Creating a pod to test atomic-volume-subpath
Oct 25 03:11:49.030: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vbxj" in namespace "subpath-1032" to be "Succeeded or Failed"
Oct 25 03:11:49.036: INFO: Pod "pod-subpath-test-configmap-vbxj": Phase="Pending", Reason="", readiness=false. Elapsed: 5.568493ms
Oct 25 03:11:51.049: INFO: Pod "pod-subpath-test-configmap-vbxj": Phase="Running", Reason="", readiness=true. Elapsed: 2.018615207s
Oct 25 03:11:53.093: INFO: Pod "pod-subpath-test-configmap-vbxj": Phase="Running", Reason="", readiness=true. Elapsed: 4.062503373s
Oct 25 03:11:55.105: INFO: Pod "pod-subpath-test-configmap-vbxj": Phase="Running", Reason="", readiness=true. Elapsed: 6.074864922s
Oct 25 03:11:57.129: INFO: Pod "pod-subpath-test-configmap-vbxj": Phase="Running", Reason="", readiness=true. Elapsed: 8.099290512s
Oct 25 03:11:59.146: INFO: Pod "pod-subpath-test-configmap-vbxj": Phase="Running", Reason="", readiness=true. Elapsed: 10.115952368s
Oct 25 03:12:01.163: INFO: Pod "pod-subpath-test-configmap-vbxj": Phase="Running", Reason="", readiness=true. Elapsed: 12.132683449s
Oct 25 03:12:03.175: INFO: Pod "pod-subpath-test-configmap-vbxj": Phase="Running", Reason="", readiness=true. Elapsed: 14.144615027s
Oct 25 03:12:05.188: INFO: Pod "pod-subpath-test-configmap-vbxj": Phase="Running", Reason="", readiness=true. Elapsed: 16.157876213s
Oct 25 03:12:07.200: INFO: Pod "pod-subpath-test-configmap-vbxj": Phase="Running", Reason="", readiness=true. Elapsed: 18.169840966s
Oct 25 03:12:09.213: INFO: Pod "pod-subpath-test-configmap-vbxj": Phase="Running", Reason="", readiness=true. Elapsed: 20.18291692s
Oct 25 03:12:11.225: INFO: Pod "pod-subpath-test-configmap-vbxj": Phase="Running", Reason="", readiness=false. Elapsed: 22.195262081s
Oct 25 03:12:13.238: INFO: Pod "pod-subpath-test-configmap-vbxj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.208410226s
STEP: Saw pod success
Oct 25 03:12:13.239: INFO: Pod "pod-subpath-test-configmap-vbxj" satisfied condition "Succeeded or Failed"
Oct 25 03:12:13.245: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-subpath-test-configmap-vbxj container test-container-subpath-configmap-vbxj: <nil>
STEP: delete the pod
Oct 25 03:12:13.282: INFO: Waiting for pod pod-subpath-test-configmap-vbxj to disappear
Oct 25 03:12:13.297: INFO: Pod pod-subpath-test-configmap-vbxj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-vbxj
Oct 25 03:12:13.297: INFO: Deleting pod "pod-subpath-test-configmap-vbxj" in namespace "subpath-1032"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Oct 25 03:12:13.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1032" for this suite.

• [SLOW TEST:24.430 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","total":356,"completed":321,"skipped":5933,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:12:13.347: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:188
Oct 25 03:12:13.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9561" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":356,"completed":322,"skipped":5969,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:12:13.415: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 25 03:12:14.158: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 25 03:12:17.198: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 03:12:17.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4022" for this suite.
STEP: Destroying namespace "webhook-4022-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":356,"completed":323,"skipped":6010,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:12:17.458: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override arguments
Oct 25 03:12:17.520: INFO: Waiting up to 5m0s for pod "client-containers-aa954577-65ed-49ce-aaaa-6c3007dd25ee" in namespace "containers-6500" to be "Succeeded or Failed"
Oct 25 03:12:17.529: INFO: Pod "client-containers-aa954577-65ed-49ce-aaaa-6c3007dd25ee": Phase="Pending", Reason="", readiness=false. Elapsed: 8.928662ms
Oct 25 03:12:19.540: INFO: Pod "client-containers-aa954577-65ed-49ce-aaaa-6c3007dd25ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019954651s
Oct 25 03:12:21.554: INFO: Pod "client-containers-aa954577-65ed-49ce-aaaa-6c3007dd25ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034295899s
STEP: Saw pod success
Oct 25 03:12:21.555: INFO: Pod "client-containers-aa954577-65ed-49ce-aaaa-6c3007dd25ee" satisfied condition "Succeeded or Failed"
Oct 25 03:12:21.560: INFO: Trying to get logs from node lab1-k8s-node-3 pod client-containers-aa954577-65ed-49ce-aaaa-6c3007dd25ee container agnhost-container: <nil>
STEP: delete the pod
Oct 25 03:12:21.606: INFO: Waiting for pod client-containers-aa954577-65ed-49ce-aaaa-6c3007dd25ee to disappear
Oct 25 03:12:21.611: INFO: Pod client-containers-aa954577-65ed-49ce-aaaa-6c3007dd25ee no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Oct 25 03:12:21.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6500" for this suite.
•{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","total":356,"completed":324,"skipped":6052,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:12:21.642: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 03:12:21.681: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Oct 25 03:12:27.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6614" for this suite.

• [SLOW TEST:6.140 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":356,"completed":325,"skipped":6056,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:12:27.783: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service endpoint-test2 in namespace services-9319
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9319 to expose endpoints map[]
Oct 25 03:12:27.886: INFO: successfully validated that service endpoint-test2 in namespace services-9319 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-9319
Oct 25 03:12:27.905: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:12:29.917: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9319 to expose endpoints map[pod1:[80]]
Oct 25 03:12:29.941: INFO: successfully validated that service endpoint-test2 in namespace services-9319 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1
Oct 25 03:12:29.941: INFO: Creating new exec pod
Oct 25 03:12:32.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-9319 exec execpodk6rwq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Oct 25 03:12:33.147: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Oct 25 03:12:33.147: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 03:12:33.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-9319 exec execpodk6rwq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.0.125 80'
Oct 25 03:12:33.296: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.0.125 80\nConnection to 10.233.0.125 80 port [tcp/http] succeeded!\n"
Oct 25 03:12:33.296: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-9319
Oct 25 03:12:33.323: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:12:35.334: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9319 to expose endpoints map[pod1:[80] pod2:[80]]
Oct 25 03:12:35.362: INFO: successfully validated that service endpoint-test2 in namespace services-9319 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2
Oct 25 03:12:36.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-9319 exec execpodk6rwq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Oct 25 03:12:36.497: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Oct 25 03:12:36.497: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 03:12:36.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-9319 exec execpodk6rwq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.0.125 80'
Oct 25 03:12:36.637: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.0.125 80\nConnection to 10.233.0.125 80 port [tcp/http] succeeded!\n"
Oct 25 03:12:36.637: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-9319
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9319 to expose endpoints map[pod2:[80]]
Oct 25 03:12:36.749: INFO: successfully validated that service endpoint-test2 in namespace services-9319 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2
Oct 25 03:12:37.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-9319 exec execpodk6rwq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Oct 25 03:12:37.888: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Oct 25 03:12:37.888: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 03:12:37.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-9319 exec execpodk6rwq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.0.125 80'
Oct 25 03:12:38.051: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.0.125 80\nConnection to 10.233.0.125 80 port [tcp/http] succeeded!\n"
Oct 25 03:12:38.051: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-9319
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9319 to expose endpoints map[]
Oct 25 03:12:38.121: INFO: successfully validated that service endpoint-test2 in namespace services-9319 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 03:12:38.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9319" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:10.414 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":356,"completed":326,"skipped":6059,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:12:38.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 03:12:38.256: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c6eead63-41e2-47f7-b459-6d1e27e3c46f" in namespace "downward-api-8704" to be "Succeeded or Failed"
Oct 25 03:12:38.274: INFO: Pod "downwardapi-volume-c6eead63-41e2-47f7-b459-6d1e27e3c46f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.003513ms
Oct 25 03:12:40.286: INFO: Pod "downwardapi-volume-c6eead63-41e2-47f7-b459-6d1e27e3c46f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030313403s
Oct 25 03:12:42.298: INFO: Pod "downwardapi-volume-c6eead63-41e2-47f7-b459-6d1e27e3c46f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042053716s
STEP: Saw pod success
Oct 25 03:12:42.298: INFO: Pod "downwardapi-volume-c6eead63-41e2-47f7-b459-6d1e27e3c46f" satisfied condition "Succeeded or Failed"
Oct 25 03:12:42.304: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-c6eead63-41e2-47f7-b459-6d1e27e3c46f container client-container: <nil>
STEP: delete the pod
Oct 25 03:12:42.345: INFO: Waiting for pod downwardapi-volume-c6eead63-41e2-47f7-b459-6d1e27e3c46f to disappear
Oct 25 03:12:42.352: INFO: Pod downwardapi-volume-c6eead63-41e2-47f7-b459-6d1e27e3c46f no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Oct 25 03:12:42.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8704" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":356,"completed":327,"skipped":6060,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:12:42.373: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override all
Oct 25 03:12:42.443: INFO: Waiting up to 5m0s for pod "client-containers-15ace9cd-9338-4d08-80d7-016d25953c99" in namespace "containers-7228" to be "Succeeded or Failed"
Oct 25 03:12:42.462: INFO: Pod "client-containers-15ace9cd-9338-4d08-80d7-016d25953c99": Phase="Pending", Reason="", readiness=false. Elapsed: 18.748854ms
Oct 25 03:12:44.475: INFO: Pod "client-containers-15ace9cd-9338-4d08-80d7-016d25953c99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031773099s
Oct 25 03:12:46.488: INFO: Pod "client-containers-15ace9cd-9338-4d08-80d7-016d25953c99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044135161s
STEP: Saw pod success
Oct 25 03:12:46.488: INFO: Pod "client-containers-15ace9cd-9338-4d08-80d7-016d25953c99" satisfied condition "Succeeded or Failed"
Oct 25 03:12:46.493: INFO: Trying to get logs from node lab1-k8s-node-3 pod client-containers-15ace9cd-9338-4d08-80d7-016d25953c99 container agnhost-container: <nil>
STEP: delete the pod
Oct 25 03:12:46.525: INFO: Waiting for pod client-containers-15ace9cd-9338-4d08-80d7-016d25953c99 to disappear
Oct 25 03:12:46.530: INFO: Pod client-containers-15ace9cd-9338-4d08-80d7-016d25953c99 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Oct 25 03:12:46.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7228" for this suite.
•{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":356,"completed":328,"skipped":6090,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:12:46.552: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Oct 25 03:12:47.384: INFO: The status of Pod kube-controller-manager-lab1-k8s-master-3 is Running (Ready = true)
Oct 25 03:12:47.468: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Oct 25 03:12:47.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1000" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":356,"completed":329,"skipped":6140,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:12:47.510: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 03:12:47.577: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: creating the pod
STEP: submitting the pod to kubernetes
Oct 25 03:12:47.600: INFO: The status of Pod pod-exec-websocket-8e9121f4-ab49-43f5-8f30-3b0731e99b12 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:12:49.613: INFO: The status of Pod pod-exec-websocket-8e9121f4-ab49-43f5-8f30-3b0731e99b12 is Running (Ready = true)
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Oct 25 03:12:49.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2312" for this suite.
•{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":356,"completed":330,"skipped":6167,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:12:49.714: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Oct 25 03:12:49.775: INFO: The status of Pod annotationupdate30b7bcfb-8c11-4118-a118-aab559bab684 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:12:51.783: INFO: The status of Pod annotationupdate30b7bcfb-8c11-4118-a118-aab559bab684 is Running (Ready = true)
Oct 25 03:12:52.332: INFO: Successfully updated pod "annotationupdate30b7bcfb-8c11-4118-a118-aab559bab684"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Oct 25 03:12:56.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2688" for this suite.

• [SLOW TEST:6.693 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":356,"completed":331,"skipped":6187,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount projected service account token [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:12:56.407: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should mount projected service account token [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test service account token: 
Oct 25 03:12:56.462: INFO: Waiting up to 5m0s for pod "test-pod-809219ca-68b6-4572-b200-f954de0772c1" in namespace "svcaccounts-1128" to be "Succeeded or Failed"
Oct 25 03:12:56.474: INFO: Pod "test-pod-809219ca-68b6-4572-b200-f954de0772c1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.640237ms
Oct 25 03:12:58.488: INFO: Pod "test-pod-809219ca-68b6-4572-b200-f954de0772c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025838771s
Oct 25 03:13:00.502: INFO: Pod "test-pod-809219ca-68b6-4572-b200-f954de0772c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039355551s
STEP: Saw pod success
Oct 25 03:13:00.502: INFO: Pod "test-pod-809219ca-68b6-4572-b200-f954de0772c1" satisfied condition "Succeeded or Failed"
Oct 25 03:13:00.507: INFO: Trying to get logs from node lab1-k8s-node-2 pod test-pod-809219ca-68b6-4572-b200-f954de0772c1 container agnhost-container: <nil>
STEP: delete the pod
Oct 25 03:13:00.550: INFO: Waiting for pod test-pod-809219ca-68b6-4572-b200-f954de0772c1 to disappear
Oct 25 03:13:00.556: INFO: Pod test-pod-809219ca-68b6-4572-b200-f954de0772c1 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Oct 25 03:13:00.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1128" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","total":356,"completed":332,"skipped":6206,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:13:00.593: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct 25 03:13:00.645: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1506  45686c36-cca1-431d-987c-eed4df364ff4 245678 0 2022-10-25 03:13:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-10-25 03:13:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 25 03:13:00.646: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1506  45686c36-cca1-431d-987c-eed4df364ff4 245678 0 2022-10-25 03:13:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-10-25 03:13:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct 25 03:13:00.660: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1506  45686c36-cca1-431d-987c-eed4df364ff4 245679 0 2022-10-25 03:13:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-10-25 03:13:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 25 03:13:00.660: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1506  45686c36-cca1-431d-987c-eed4df364ff4 245679 0 2022-10-25 03:13:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-10-25 03:13:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct 25 03:13:00.675: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1506  45686c36-cca1-431d-987c-eed4df364ff4 245680 0 2022-10-25 03:13:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-10-25 03:13:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 25 03:13:00.675: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1506  45686c36-cca1-431d-987c-eed4df364ff4 245680 0 2022-10-25 03:13:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-10-25 03:13:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct 25 03:13:00.686: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1506  45686c36-cca1-431d-987c-eed4df364ff4 245681 0 2022-10-25 03:13:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-10-25 03:13:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 25 03:13:00.687: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1506  45686c36-cca1-431d-987c-eed4df364ff4 245681 0 2022-10-25 03:13:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-10-25 03:13:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct 25 03:13:00.694: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1506  4964303c-bb67-441d-b922-35b360f0449b 245682 0 2022-10-25 03:13:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-10-25 03:13:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 25 03:13:00.695: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1506  4964303c-bb67-441d-b922-35b360f0449b 245682 0 2022-10-25 03:13:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-10-25 03:13:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct 25 03:13:10.739: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1506  4964303c-bb67-441d-b922-35b360f0449b 245741 0 2022-10-25 03:13:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-10-25 03:13:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Oct 25 03:13:10.739: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1506  4964303c-bb67-441d-b922-35b360f0449b 245741 0 2022-10-25 03:13:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-10-25 03:13:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Oct 25 03:13:20.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1506" for this suite.

• [SLOW TEST:20.191 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":356,"completed":333,"skipped":6253,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:13:20.785: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Oct 25 03:13:20.836: INFO: Waiting up to 5m0s for pod "downward-api-41f12d6a-2341-4142-b3e1-84b1ea17f72c" in namespace "downward-api-3388" to be "Succeeded or Failed"
Oct 25 03:13:20.843: INFO: Pod "downward-api-41f12d6a-2341-4142-b3e1-84b1ea17f72c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.431767ms
Oct 25 03:13:22.854: INFO: Pod "downward-api-41f12d6a-2341-4142-b3e1-84b1ea17f72c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017255913s
Oct 25 03:13:24.868: INFO: Pod "downward-api-41f12d6a-2341-4142-b3e1-84b1ea17f72c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031326336s
STEP: Saw pod success
Oct 25 03:13:24.868: INFO: Pod "downward-api-41f12d6a-2341-4142-b3e1-84b1ea17f72c" satisfied condition "Succeeded or Failed"
Oct 25 03:13:24.874: INFO: Trying to get logs from node lab1-k8s-node-3 pod downward-api-41f12d6a-2341-4142-b3e1-84b1ea17f72c container dapi-container: <nil>
STEP: delete the pod
Oct 25 03:13:24.917: INFO: Waiting for pod downward-api-41f12d6a-2341-4142-b3e1-84b1ea17f72c to disappear
Oct 25 03:13:24.924: INFO: Pod downward-api-41f12d6a-2341-4142-b3e1-84b1ea17f72c no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Oct 25 03:13:24.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3388" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":356,"completed":334,"skipped":6306,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] HostPort 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:13:24.949: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename hostport
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled
Oct 25 03:13:25.031: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:13:27.046: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.128.1.178 on the node which pod1 resides and expect scheduled
Oct 25 03:13:27.064: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:13:29.079: INFO: The status of Pod pod2 is Running (Ready = false)
Oct 25 03:13:31.077: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.128.1.178 but use UDP protocol on the node which pod2 resides
Oct 25 03:13:31.095: INFO: The status of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:13:33.105: INFO: The status of Pod pod3 is Running (Ready = true)
Oct 25 03:13:33.126: INFO: The status of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:13:35.140: INFO: The status of Pod e2e-host-exec is Running (Ready = true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323
Oct 25 03:13:35.145: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.128.1.178 http://127.0.0.1:54323/hostname] Namespace:hostport-2407 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:13:35.145: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:13:35.146: INFO: ExecWithOptions: Clientset creation
Oct 25 03:13:35.146: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-2407/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.128.1.178+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.128.1.178, port: 54323
Oct 25 03:13:35.213: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.128.1.178:54323/hostname] Namespace:hostport-2407 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:13:35.214: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:13:35.214: INFO: ExecWithOptions: Clientset creation
Oct 25 03:13:35.214: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-2407/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.128.1.178%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.128.1.178, port: 54323 UDP
Oct 25 03:13:35.297: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vuz -w 5 10.128.1.178 54323] Namespace:hostport-2407 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Oct 25 03:13:35.297: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
Oct 25 03:13:35.297: INFO: ExecWithOptions: Clientset creation
Oct 25 03:13:35.298: INFO: ExecWithOptions: execute(POST https://10.233.0.1:443/api/v1/namespaces/hostport-2407/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=nc+-vuz+-w+5+10.128.1.178+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:188
Oct 25 03:13:40.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-2407" for this suite.

• [SLOW TEST:15.468 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","total":356,"completed":335,"skipped":6316,"failed":0}
[sig-apps] ReplicaSet 
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:13:40.417: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota
Oct 25 03:13:40.499: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 25 03:13:45.523: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the replicaset Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Oct 25 03:13:45.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3469" for this suite.

• [SLOW TEST:5.206 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","total":356,"completed":336,"skipped":6316,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:13:45.627: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-5e4bde3d-880a-454d-930e-5706bc2c883e
STEP: Creating a pod to test consume secrets
Oct 25 03:13:45.763: INFO: Waiting up to 5m0s for pod "pod-secrets-c5db843c-b0f8-42fa-91b5-cbbd4c317674" in namespace "secrets-6875" to be "Succeeded or Failed"
Oct 25 03:13:45.826: INFO: Pod "pod-secrets-c5db843c-b0f8-42fa-91b5-cbbd4c317674": Phase="Pending", Reason="", readiness=false. Elapsed: 62.901044ms
Oct 25 03:13:47.837: INFO: Pod "pod-secrets-c5db843c-b0f8-42fa-91b5-cbbd4c317674": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07381365s
Oct 25 03:13:49.849: INFO: Pod "pod-secrets-c5db843c-b0f8-42fa-91b5-cbbd4c317674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.086022099s
STEP: Saw pod success
Oct 25 03:13:49.849: INFO: Pod "pod-secrets-c5db843c-b0f8-42fa-91b5-cbbd4c317674" satisfied condition "Succeeded or Failed"
Oct 25 03:13:49.855: INFO: Trying to get logs from node lab1-k8s-node-2 pod pod-secrets-c5db843c-b0f8-42fa-91b5-cbbd4c317674 container secret-volume-test: <nil>
STEP: delete the pod
Oct 25 03:13:49.889: INFO: Waiting for pod pod-secrets-c5db843c-b0f8-42fa-91b5-cbbd4c317674 to disappear
Oct 25 03:13:49.894: INFO: Pod pod-secrets-c5db843c-b0f8-42fa-91b5-cbbd4c317674 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Oct 25 03:13:49.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6875" for this suite.
STEP: Destroying namespace "secret-namespace-739" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":356,"completed":337,"skipped":6333,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:13:49.933: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 25 03:13:49.984: INFO: Waiting up to 5m0s for pod "pod-beb4b7e5-88c5-48ca-a8ef-8334d5b3ca4e" in namespace "emptydir-3030" to be "Succeeded or Failed"
Oct 25 03:13:49.991: INFO: Pod "pod-beb4b7e5-88c5-48ca-a8ef-8334d5b3ca4e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.578793ms
Oct 25 03:13:52.004: INFO: Pod "pod-beb4b7e5-88c5-48ca-a8ef-8334d5b3ca4e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0200806s
Oct 25 03:13:54.019: INFO: Pod "pod-beb4b7e5-88c5-48ca-a8ef-8334d5b3ca4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034510397s
STEP: Saw pod success
Oct 25 03:13:54.019: INFO: Pod "pod-beb4b7e5-88c5-48ca-a8ef-8334d5b3ca4e" satisfied condition "Succeeded or Failed"
Oct 25 03:13:54.024: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-beb4b7e5-88c5-48ca-a8ef-8334d5b3ca4e container test-container: <nil>
STEP: delete the pod
Oct 25 03:13:54.060: INFO: Waiting for pod pod-beb4b7e5-88c5-48ca-a8ef-8334d5b3ca4e to disappear
Oct 25 03:13:54.066: INFO: Pod pod-beb4b7e5-88c5-48ca-a8ef-8334d5b3ca4e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 03:13:54.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3030" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":338,"skipped":6344,"failed":0}

------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:13:54.092: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-03393910-16f6-47d0-8e55-3608b2b68e4b
STEP: Creating a pod to test consume configMaps
Oct 25 03:13:54.156: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2257b427-f7d8-4092-9971-c836ced5e0b5" in namespace "projected-3484" to be "Succeeded or Failed"
Oct 25 03:13:54.180: INFO: Pod "pod-projected-configmaps-2257b427-f7d8-4092-9971-c836ced5e0b5": Phase="Pending", Reason="", readiness=false. Elapsed: 23.531258ms
Oct 25 03:13:56.190: INFO: Pod "pod-projected-configmaps-2257b427-f7d8-4092-9971-c836ced5e0b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033467615s
Oct 25 03:13:58.202: INFO: Pod "pod-projected-configmaps-2257b427-f7d8-4092-9971-c836ced5e0b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045911537s
STEP: Saw pod success
Oct 25 03:13:58.203: INFO: Pod "pod-projected-configmaps-2257b427-f7d8-4092-9971-c836ced5e0b5" satisfied condition "Succeeded or Failed"
Oct 25 03:13:58.209: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-projected-configmaps-2257b427-f7d8-4092-9971-c836ced5e0b5 container agnhost-container: <nil>
STEP: delete the pod
Oct 25 03:13:58.275: INFO: Waiting for pod pod-projected-configmaps-2257b427-f7d8-4092-9971-c836ced5e0b5 to disappear
Oct 25 03:13:58.280: INFO: Pod pod-projected-configmaps-2257b427-f7d8-4092-9971-c836ced5e0b5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Oct 25 03:13:58.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3484" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":339,"skipped":6344,"failed":0}

------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:13:58.304: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Oct 25 03:14:38.713: INFO: The status of Pod kube-controller-manager-lab1-k8s-master-3 is Running (Ready = true)
Oct 25 03:14:38.815: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Oct 25 03:14:38.815: INFO: Deleting pod "simpletest.rc-22w94" in namespace "gc-3988"
Oct 25 03:14:38.841: INFO: Deleting pod "simpletest.rc-2d5cz" in namespace "gc-3988"
Oct 25 03:14:38.892: INFO: Deleting pod "simpletest.rc-2ntxk" in namespace "gc-3988"
Oct 25 03:14:38.930: INFO: Deleting pod "simpletest.rc-2txm4" in namespace "gc-3988"
Oct 25 03:14:38.969: INFO: Deleting pod "simpletest.rc-45v5l" in namespace "gc-3988"
Oct 25 03:14:39.045: INFO: Deleting pod "simpletest.rc-48scs" in namespace "gc-3988"
Oct 25 03:14:39.097: INFO: Deleting pod "simpletest.rc-4j5fl" in namespace "gc-3988"
Oct 25 03:14:39.129: INFO: Deleting pod "simpletest.rc-4k8m4" in namespace "gc-3988"
Oct 25 03:14:39.177: INFO: Deleting pod "simpletest.rc-4ldnt" in namespace "gc-3988"
Oct 25 03:14:39.237: INFO: Deleting pod "simpletest.rc-55pxt" in namespace "gc-3988"
Oct 25 03:14:39.271: INFO: Deleting pod "simpletest.rc-5bwv2" in namespace "gc-3988"
Oct 25 03:14:39.311: INFO: Deleting pod "simpletest.rc-5dqwj" in namespace "gc-3988"
Oct 25 03:14:39.370: INFO: Deleting pod "simpletest.rc-5f45k" in namespace "gc-3988"
Oct 25 03:14:39.418: INFO: Deleting pod "simpletest.rc-5jmzt" in namespace "gc-3988"
Oct 25 03:14:39.461: INFO: Deleting pod "simpletest.rc-5qnl6" in namespace "gc-3988"
Oct 25 03:14:39.498: INFO: Deleting pod "simpletest.rc-5zqtl" in namespace "gc-3988"
Oct 25 03:14:39.542: INFO: Deleting pod "simpletest.rc-689r9" in namespace "gc-3988"
Oct 25 03:14:39.602: INFO: Deleting pod "simpletest.rc-697q7" in namespace "gc-3988"
Oct 25 03:14:39.659: INFO: Deleting pod "simpletest.rc-6k2vj" in namespace "gc-3988"
Oct 25 03:14:39.769: INFO: Deleting pod "simpletest.rc-75t92" in namespace "gc-3988"
Oct 25 03:14:39.863: INFO: Deleting pod "simpletest.rc-7b2cz" in namespace "gc-3988"
Oct 25 03:14:39.953: INFO: Deleting pod "simpletest.rc-7c6wt" in namespace "gc-3988"
Oct 25 03:14:40.010: INFO: Deleting pod "simpletest.rc-7kqr6" in namespace "gc-3988"
Oct 25 03:14:40.084: INFO: Deleting pod "simpletest.rc-7mjjm" in namespace "gc-3988"
Oct 25 03:14:40.133: INFO: Deleting pod "simpletest.rc-7vc8c" in namespace "gc-3988"
Oct 25 03:14:40.201: INFO: Deleting pod "simpletest.rc-8b4mm" in namespace "gc-3988"
Oct 25 03:14:40.292: INFO: Deleting pod "simpletest.rc-8pxr4" in namespace "gc-3988"
Oct 25 03:14:40.339: INFO: Deleting pod "simpletest.rc-9j6t8" in namespace "gc-3988"
Oct 25 03:14:40.432: INFO: Deleting pod "simpletest.rc-9tshl" in namespace "gc-3988"
Oct 25 03:14:40.493: INFO: Deleting pod "simpletest.rc-9v9r7" in namespace "gc-3988"
Oct 25 03:14:40.556: INFO: Deleting pod "simpletest.rc-b8qcb" in namespace "gc-3988"
Oct 25 03:14:40.602: INFO: Deleting pod "simpletest.rc-bbbmq" in namespace "gc-3988"
Oct 25 03:14:40.652: INFO: Deleting pod "simpletest.rc-c5hnh" in namespace "gc-3988"
Oct 25 03:14:40.721: INFO: Deleting pod "simpletest.rc-c5vwz" in namespace "gc-3988"
Oct 25 03:14:40.796: INFO: Deleting pod "simpletest.rc-cdhnl" in namespace "gc-3988"
Oct 25 03:14:40.909: INFO: Deleting pod "simpletest.rc-csxnw" in namespace "gc-3988"
Oct 25 03:14:40.956: INFO: Deleting pod "simpletest.rc-d4zgq" in namespace "gc-3988"
Oct 25 03:14:41.018: INFO: Deleting pod "simpletest.rc-dcjr7" in namespace "gc-3988"
Oct 25 03:14:41.080: INFO: Deleting pod "simpletest.rc-dv9nt" in namespace "gc-3988"
Oct 25 03:14:41.145: INFO: Deleting pod "simpletest.rc-f5c4m" in namespace "gc-3988"
Oct 25 03:14:41.241: INFO: Deleting pod "simpletest.rc-f8tbm" in namespace "gc-3988"
Oct 25 03:14:41.287: INFO: Deleting pod "simpletest.rc-fl9h5" in namespace "gc-3988"
Oct 25 03:14:41.376: INFO: Deleting pod "simpletest.rc-ft5cx" in namespace "gc-3988"
Oct 25 03:14:41.427: INFO: Deleting pod "simpletest.rc-fvjfr" in namespace "gc-3988"
Oct 25 03:14:41.459: INFO: Deleting pod "simpletest.rc-gdvf2" in namespace "gc-3988"
Oct 25 03:14:41.515: INFO: Deleting pod "simpletest.rc-grkcl" in namespace "gc-3988"
Oct 25 03:14:41.582: INFO: Deleting pod "simpletest.rc-h2z8f" in namespace "gc-3988"
Oct 25 03:14:41.652: INFO: Deleting pod "simpletest.rc-h8t24" in namespace "gc-3988"
Oct 25 03:14:41.721: INFO: Deleting pod "simpletest.rc-h9vlf" in namespace "gc-3988"
Oct 25 03:14:41.777: INFO: Deleting pod "simpletest.rc-hgjvw" in namespace "gc-3988"
Oct 25 03:14:41.861: INFO: Deleting pod "simpletest.rc-hhtnn" in namespace "gc-3988"
Oct 25 03:14:41.934: INFO: Deleting pod "simpletest.rc-hv5wq" in namespace "gc-3988"
Oct 25 03:14:42.003: INFO: Deleting pod "simpletest.rc-hxprr" in namespace "gc-3988"
Oct 25 03:14:42.081: INFO: Deleting pod "simpletest.rc-hxqp4" in namespace "gc-3988"
Oct 25 03:14:42.193: INFO: Deleting pod "simpletest.rc-j9qrk" in namespace "gc-3988"
Oct 25 03:14:42.277: INFO: Deleting pod "simpletest.rc-jl5k2" in namespace "gc-3988"
Oct 25 03:14:42.387: INFO: Deleting pod "simpletest.rc-jq56h" in namespace "gc-3988"
Oct 25 03:14:42.448: INFO: Deleting pod "simpletest.rc-jtwl6" in namespace "gc-3988"
Oct 25 03:14:42.508: INFO: Deleting pod "simpletest.rc-jwjnh" in namespace "gc-3988"
Oct 25 03:14:42.563: INFO: Deleting pod "simpletest.rc-jzb4n" in namespace "gc-3988"
Oct 25 03:14:42.762: INFO: Deleting pod "simpletest.rc-kmcrm" in namespace "gc-3988"
Oct 25 03:14:42.850: INFO: Deleting pod "simpletest.rc-krhxs" in namespace "gc-3988"
Oct 25 03:14:43.008: INFO: Deleting pod "simpletest.rc-l4j7k" in namespace "gc-3988"
Oct 25 03:14:43.078: INFO: Deleting pod "simpletest.rc-lsx2z" in namespace "gc-3988"
Oct 25 03:14:43.206: INFO: Deleting pod "simpletest.rc-lttpf" in namespace "gc-3988"
Oct 25 03:14:43.283: INFO: Deleting pod "simpletest.rc-mkmc2" in namespace "gc-3988"
Oct 25 03:14:43.344: INFO: Deleting pod "simpletest.rc-mvdvh" in namespace "gc-3988"
Oct 25 03:14:43.385: INFO: Deleting pod "simpletest.rc-mvpq4" in namespace "gc-3988"
Oct 25 03:14:43.470: INFO: Deleting pod "simpletest.rc-mxtkt" in namespace "gc-3988"
Oct 25 03:14:43.517: INFO: Deleting pod "simpletest.rc-n95c4" in namespace "gc-3988"
Oct 25 03:14:43.558: INFO: Deleting pod "simpletest.rc-ngg9l" in namespace "gc-3988"
Oct 25 03:14:43.582: INFO: Deleting pod "simpletest.rc-njx4f" in namespace "gc-3988"
Oct 25 03:14:43.641: INFO: Deleting pod "simpletest.rc-p5992" in namespace "gc-3988"
Oct 25 03:14:43.680: INFO: Deleting pod "simpletest.rc-pl977" in namespace "gc-3988"
Oct 25 03:14:43.730: INFO: Deleting pod "simpletest.rc-pmtpj" in namespace "gc-3988"
Oct 25 03:14:43.776: INFO: Deleting pod "simpletest.rc-pv6kd" in namespace "gc-3988"
Oct 25 03:14:43.841: INFO: Deleting pod "simpletest.rc-qljv5" in namespace "gc-3988"
Oct 25 03:14:43.869: INFO: Deleting pod "simpletest.rc-qnlqk" in namespace "gc-3988"
Oct 25 03:14:43.987: INFO: Deleting pod "simpletest.rc-qrgxw" in namespace "gc-3988"
Oct 25 03:14:44.054: INFO: Deleting pod "simpletest.rc-rfmbx" in namespace "gc-3988"
Oct 25 03:14:44.158: INFO: Deleting pod "simpletest.rc-rrv4l" in namespace "gc-3988"
Oct 25 03:14:44.289: INFO: Deleting pod "simpletest.rc-rxg84" in namespace "gc-3988"
Oct 25 03:14:44.371: INFO: Deleting pod "simpletest.rc-rz694" in namespace "gc-3988"
Oct 25 03:14:44.430: INFO: Deleting pod "simpletest.rc-svkz6" in namespace "gc-3988"
Oct 25 03:14:44.604: INFO: Deleting pod "simpletest.rc-t5psz" in namespace "gc-3988"
Oct 25 03:14:44.701: INFO: Deleting pod "simpletest.rc-trd55" in namespace "gc-3988"
Oct 25 03:14:44.763: INFO: Deleting pod "simpletest.rc-twh8r" in namespace "gc-3988"
Oct 25 03:14:44.801: INFO: Deleting pod "simpletest.rc-vf28s" in namespace "gc-3988"
Oct 25 03:14:44.878: INFO: Deleting pod "simpletest.rc-vmn6z" in namespace "gc-3988"
Oct 25 03:14:44.933: INFO: Deleting pod "simpletest.rc-vs7c4" in namespace "gc-3988"
Oct 25 03:14:44.980: INFO: Deleting pod "simpletest.rc-w8rbk" in namespace "gc-3988"
Oct 25 03:14:45.042: INFO: Deleting pod "simpletest.rc-x54w6" in namespace "gc-3988"
Oct 25 03:14:45.121: INFO: Deleting pod "simpletest.rc-x68jn" in namespace "gc-3988"
Oct 25 03:14:45.189: INFO: Deleting pod "simpletest.rc-x6gl7" in namespace "gc-3988"
Oct 25 03:14:45.260: INFO: Deleting pod "simpletest.rc-xfvrl" in namespace "gc-3988"
Oct 25 03:14:45.303: INFO: Deleting pod "simpletest.rc-z475l" in namespace "gc-3988"
Oct 25 03:14:45.364: INFO: Deleting pod "simpletest.rc-z4zx8" in namespace "gc-3988"
Oct 25 03:14:45.412: INFO: Deleting pod "simpletest.rc-z5sw7" in namespace "gc-3988"
Oct 25 03:14:45.486: INFO: Deleting pod "simpletest.rc-zcwnq" in namespace "gc-3988"
Oct 25 03:14:45.562: INFO: Deleting pod "simpletest.rc-zdctk" in namespace "gc-3988"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Oct 25 03:14:45.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3988" for this suite.

• [SLOW TEST:47.373 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":356,"completed":340,"skipped":6344,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:14:45.678: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in volume subpath
Oct 25 03:14:45.848: INFO: Waiting up to 5m0s for pod "var-expansion-a94e9bb0-0edb-46b0-9a83-46ff9b665ba9" in namespace "var-expansion-8449" to be "Succeeded or Failed"
Oct 25 03:14:45.867: INFO: Pod "var-expansion-a94e9bb0-0edb-46b0-9a83-46ff9b665ba9": Phase="Pending", Reason="", readiness=false. Elapsed: 19.278593ms
Oct 25 03:14:47.880: INFO: Pod "var-expansion-a94e9bb0-0edb-46b0-9a83-46ff9b665ba9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031943497s
Oct 25 03:14:49.893: INFO: Pod "var-expansion-a94e9bb0-0edb-46b0-9a83-46ff9b665ba9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045506616s
STEP: Saw pod success
Oct 25 03:14:49.893: INFO: Pod "var-expansion-a94e9bb0-0edb-46b0-9a83-46ff9b665ba9" satisfied condition "Succeeded or Failed"
Oct 25 03:14:49.899: INFO: Trying to get logs from node lab1-k8s-node-3 pod var-expansion-a94e9bb0-0edb-46b0-9a83-46ff9b665ba9 container dapi-container: <nil>
STEP: delete the pod
Oct 25 03:14:49.943: INFO: Waiting for pod var-expansion-a94e9bb0-0edb-46b0-9a83-46ff9b665ba9 to disappear
Oct 25 03:14:49.949: INFO: Pod var-expansion-a94e9bb0-0edb-46b0-9a83-46ff9b665ba9 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Oct 25 03:14:49.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8449" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","total":356,"completed":341,"skipped":6364,"failed":0}
SSSS
------------------------------
[sig-network] EndpointSlice 
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:14:49.978: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename endpointslice
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 03:14:50.040: INFO: Endpoints addresses: [10.128.0.176 10.128.2.108 10.128.2.74] , ports: [6443]
Oct 25 03:14:50.040: INFO: EndpointSlices addresses: [10.128.0.176 10.128.2.108 10.128.2.74] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Oct 25 03:14:50.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-2495" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","total":356,"completed":342,"skipped":6368,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:14:50.066: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 03:14:50.122: INFO: The status of Pod busybox-readonly-fs8d0f8b74-2ff8-4167-98f4-6dfd7a25eb9e is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:14:52.133: INFO: The status of Pod busybox-readonly-fs8d0f8b74-2ff8-4167-98f4-6dfd7a25eb9e is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Oct 25 03:14:52.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6786" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":343,"skipped":6378,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:14:52.178: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Oct 25 03:14:53.372: INFO: The status of Pod kube-controller-manager-lab1-k8s-master-3 is Running (Ready = true)
Oct 25 03:14:53.475: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Oct 25 03:14:53.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4331" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":356,"completed":344,"skipped":6387,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:14:53.501: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Oct 25 03:15:04.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4449" for this suite.

• [SLOW TEST:11.161 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":356,"completed":345,"skipped":6394,"failed":0}
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:15:04.663: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 25 03:15:04.718: INFO: Waiting up to 5m0s for pod "pod-8e50fbd6-65f8-4aad-9f12-e2a937eb383b" in namespace "emptydir-796" to be "Succeeded or Failed"
Oct 25 03:15:04.724: INFO: Pod "pod-8e50fbd6-65f8-4aad-9f12-e2a937eb383b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.337283ms
Oct 25 03:15:06.736: INFO: Pod "pod-8e50fbd6-65f8-4aad-9f12-e2a937eb383b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017850719s
Oct 25 03:15:08.747: INFO: Pod "pod-8e50fbd6-65f8-4aad-9f12-e2a937eb383b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029436354s
STEP: Saw pod success
Oct 25 03:15:08.748: INFO: Pod "pod-8e50fbd6-65f8-4aad-9f12-e2a937eb383b" satisfied condition "Succeeded or Failed"
Oct 25 03:15:08.754: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-8e50fbd6-65f8-4aad-9f12-e2a937eb383b container test-container: <nil>
STEP: delete the pod
Oct 25 03:15:08.798: INFO: Waiting for pod pod-8e50fbd6-65f8-4aad-9f12-e2a937eb383b to disappear
Oct 25 03:15:08.803: INFO: Pod pod-8e50fbd6-65f8-4aad-9f12-e2a937eb383b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 03:15:08.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-796" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":346,"skipped":6394,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:15:08.832: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pdb
STEP: Waiting for the pdb to be processed
STEP: updating the pdb
STEP: Waiting for the pdb to be processed
STEP: patching the pdb
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be deleted
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Oct 25 03:15:15.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4362" for this suite.

• [SLOW TEST:6.201 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","total":356,"completed":347,"skipped":6415,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:15:15.037: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 25 03:15:15.085: INFO: Waiting up to 5m0s for pod "pod-dd47bc15-acde-40d9-85d9-c29e7634ce2b" in namespace "emptydir-9397" to be "Succeeded or Failed"
Oct 25 03:15:15.092: INFO: Pod "pod-dd47bc15-acde-40d9-85d9-c29e7634ce2b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.772367ms
Oct 25 03:15:17.109: INFO: Pod "pod-dd47bc15-acde-40d9-85d9-c29e7634ce2b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024907461s
Oct 25 03:15:19.123: INFO: Pod "pod-dd47bc15-acde-40d9-85d9-c29e7634ce2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038671569s
STEP: Saw pod success
Oct 25 03:15:19.123: INFO: Pod "pod-dd47bc15-acde-40d9-85d9-c29e7634ce2b" satisfied condition "Succeeded or Failed"
Oct 25 03:15:19.130: INFO: Trying to get logs from node lab1-k8s-node-3 pod pod-dd47bc15-acde-40d9-85d9-c29e7634ce2b container test-container: <nil>
STEP: delete the pod
Oct 25 03:15:19.179: INFO: Waiting for pod pod-dd47bc15-acde-40d9-85d9-c29e7634ce2b to disappear
Oct 25 03:15:19.186: INFO: Pod pod-dd47bc15-acde-40d9-85d9-c29e7634ce2b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Oct 25 03:15:19.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9397" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":348,"skipped":6459,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:15:19.214: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
STEP: listing events with field selection filtering on source
STEP: listing events with field selection filtering on reportingController
STEP: getting the test event
STEP: patching the test event
STEP: getting the test event
STEP: updating the test event
STEP: getting the test event
STEP: deleting the test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:188
Oct 25 03:15:19.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-379" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":356,"completed":349,"skipped":6478,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:15:19.390: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename disruption
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pdb that targets all three pods in a test replica set
STEP: Waiting for the pdb to be processed
STEP: First trying to evict a pod which shouldn't be evictable
STEP: Waiting for all pods to be running
Oct 25 03:15:21.471: INFO: pods: 0 < 3
STEP: locating a running pod
STEP: Updating the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
STEP: Waiting for the pdb to observed all healthy pods
STEP: Patching the pdb to disallow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
STEP: locating a running pod
STEP: Deleting the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be deleted
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Oct 25 03:15:27.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2761" for this suite.

• [SLOW TEST:8.397 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","total":356,"completed":350,"skipped":6492,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:15:27.787: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Oct 25 03:15:27.862: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:15:29.875: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Oct 25 03:15:29.902: INFO: The status of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:15:31.915: INFO: The status of Pod pod-with-prestop-http-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Oct 25 03:15:31.934: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 25 03:15:31.942: INFO: Pod pod-with-prestop-http-hook still exists
Oct 25 03:15:33.943: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 25 03:15:33.953: INFO: Pod pod-with-prestop-http-hook still exists
Oct 25 03:15:35.943: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 25 03:15:35.955: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Oct 25 03:15:35.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9616" for this suite.

• [SLOW TEST:8.203 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":356,"completed":351,"skipped":6522,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:15:35.992: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2233
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating statefulset ss in namespace statefulset-2233
Oct 25 03:15:36.081: INFO: Found 0 stateful pods, waiting for 1
Oct 25 03:15:46.096: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label
STEP: Getting /status
Oct 25 03:15:46.124: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status
Oct 25 03:15:46.140: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated
Oct 25 03:15:46.142: INFO: Observed &StatefulSet event: ADDED
Oct 25 03:15:46.143: INFO: Found Statefulset ss in namespace statefulset-2233 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Oct 25 03:15:46.143: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status
Oct 25 03:15:46.143: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Oct 25 03:15:46.154: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched
Oct 25 03:15:46.156: INFO: Observed &StatefulSet event: ADDED
Oct 25 03:15:46.156: INFO: Observed Statefulset ss in namespace statefulset-2233 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Oct 25 03:15:46.156: INFO: Observed &StatefulSet event: MODIFIED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Oct 25 03:15:46.156: INFO: Deleting all statefulset in ns statefulset-2233
Oct 25 03:15:46.162: INFO: Scaling statefulset ss to 0
Oct 25 03:15:56.197: INFO: Waiting for statefulset status.replicas updated to 0
Oct 25 03:15:56.205: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Oct 25 03:15:56.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2233" for this suite.

• [SLOW TEST:20.267 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","total":356,"completed":352,"skipped":6533,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:15:56.260: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/framework/framework.go:652
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4664.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4664.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4664.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4664.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 25 03:15:58.376: INFO: DNS probes using dns-4664/dns-test-fc716ed3-702a-4742-9108-e3401f643369 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Oct 25 03:15:58.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4664" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","total":356,"completed":353,"skipped":6575,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:15:58.437: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-8056
Oct 25 03:15:58.505: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Oct 25 03:16:00.520: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Oct 25 03:16:00.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-8056 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Oct 25 03:16:00.671: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Oct 25 03:16:00.671: INFO: stdout: "ipvs"
Oct 25 03:16:00.671: INFO: proxyMode: ipvs
Oct 25 03:16:00.691: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Oct 25 03:16:00.697: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-8056
STEP: creating replication controller affinity-nodeport-timeout in namespace services-8056
I1025 03:16:00.743509      18 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-8056, replica count: 3
I1025 03:16:03.797038      18 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 25 03:16:03.820: INFO: Creating new exec pod
Oct 25 03:16:06.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-8056 exec execpod-affinityqhv4t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Oct 25 03:16:07.019: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-timeout 80\n+ echo hostName\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Oct 25 03:16:07.019: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 03:16:07.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-8056 exec execpod-affinityqhv4t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.233.39.54 80'
Oct 25 03:16:07.168: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.233.39.54 80\nConnection to 10.233.39.54 80 port [tcp/http] succeeded!\n"
Oct 25 03:16:07.168: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 03:16:07.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-8056 exec execpod-affinityqhv4t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.2.108 30416'
Oct 25 03:16:07.334: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.128.2.108 30416\nConnection to 10.128.2.108 30416 port [tcp/*] succeeded!\n"
Oct 25 03:16:07.334: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 03:16:07.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-8056 exec execpod-affinityqhv4t -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.128.1.178 30416'
Oct 25 03:16:07.478: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.128.1.178 30416\nConnection to 10.128.1.178 30416 port [tcp/*] succeeded!\n"
Oct 25 03:16:07.478: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Oct 25 03:16:07.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-8056 exec execpod-affinityqhv4t -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.128.0.176:30416/ ; done'
Oct 25 03:16:07.728: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n"
Oct 25 03:16:07.728: INFO: stdout: "\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr\naffinity-nodeport-timeout-tj8sr"
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Received response from host: affinity-nodeport-timeout-tj8sr
Oct 25 03:16:07.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-8056 exec execpod-affinityqhv4t -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.128.0.176:30416/'
Oct 25 03:16:07.886: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n"
Oct 25 03:16:07.886: INFO: stdout: "affinity-nodeport-timeout-tj8sr"
Oct 25 03:18:17.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=services-8056 exec execpod-affinityqhv4t -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.128.0.176:30416/'
Oct 25 03:18:18.051: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.128.0.176:30416/\n"
Oct 25 03:18:18.051: INFO: stdout: "affinity-nodeport-timeout-jc567"
Oct 25 03:18:18.051: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-8056, will wait for the garbage collector to delete the pods
Oct 25 03:18:18.156: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 12.96345ms
Oct 25 03:18:18.257: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.825046ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Oct 25 03:18:20.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8056" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:142.397 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":354,"skipped":6605,"failed":0}
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:18:20.835: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Oct 25 03:18:20.897: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4f3e6ba-6dcc-47a8-83d4-a94711813f11" in namespace "downward-api-702" to be "Succeeded or Failed"
Oct 25 03:18:20.904: INFO: Pod "downwardapi-volume-b4f3e6ba-6dcc-47a8-83d4-a94711813f11": Phase="Pending", Reason="", readiness=false. Elapsed: 7.542011ms
Oct 25 03:18:22.916: INFO: Pod "downwardapi-volume-b4f3e6ba-6dcc-47a8-83d4-a94711813f11": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019311975s
Oct 25 03:18:24.925: INFO: Pod "downwardapi-volume-b4f3e6ba-6dcc-47a8-83d4-a94711813f11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028271515s
STEP: Saw pod success
Oct 25 03:18:24.925: INFO: Pod "downwardapi-volume-b4f3e6ba-6dcc-47a8-83d4-a94711813f11" satisfied condition "Succeeded or Failed"
Oct 25 03:18:24.931: INFO: Trying to get logs from node lab1-k8s-node-3 pod downwardapi-volume-b4f3e6ba-6dcc-47a8-83d4-a94711813f11 container client-container: <nil>
STEP: delete the pod
Oct 25 03:18:24.977: INFO: Waiting for pod downwardapi-volume-b4f3e6ba-6dcc-47a8-83d4-a94711813f11 to disappear
Oct 25 03:18:24.987: INFO: Pod downwardapi-volume-b4f3e6ba-6dcc-47a8-83d4-a94711813f11 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Oct 25 03:18:24.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-702" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":356,"completed":355,"skipped":6608,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Oct 25 03:18:25.022: INFO: >>> kubeConfig: /tmp/kubeconfig-3055319084
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/framework/framework.go:652
Oct 25 03:18:25.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6807 create -f -'
Oct 25 03:18:25.966: INFO: stderr: ""
Oct 25 03:18:25.966: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Oct 25 03:18:25.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6807 create -f -'
Oct 25 03:18:27.258: INFO: stderr: ""
Oct 25 03:18:27.258: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Oct 25 03:18:28.273: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 25 03:18:28.273: INFO: Found 1 / 1
Oct 25 03:18:28.273: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 25 03:18:28.279: INFO: Selector matched 1 pods for map[app:agnhost]
Oct 25 03:18:28.279: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 25 03:18:28.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6807 describe pod agnhost-primary-gc895'
Oct 25 03:18:28.350: INFO: stderr: ""
Oct 25 03:18:28.350: INFO: stdout: "Name:         agnhost-primary-gc895\nNamespace:    kubectl-6807\nPriority:     0\nNode:         lab1-k8s-node-3/10.128.1.178\nStart Time:   Tue, 25 Oct 2022 03:18:26 +0000\nLabels:       app=agnhost\n              role=primary\nAnnotations:  cni.projectcalico.org/containerID: f95d0875acd6067ac06689e0f20830f88cc9fea8b9531d8758a7e62e69dd7801\n              cni.projectcalico.org/podIP: 10.233.74.119/32\n              cni.projectcalico.org/podIPs: 10.233.74.119/32\nStatus:       Running\nIP:           10.233.74.119\nIPs:\n  IP:           10.233.74.119\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://1aee7e456fb0b2cc951c1e789bed189ae79977fa5404a667e7f70f690700eea7\n    Image:          k8s.gcr.io/e2e-test-images/agnhost:2.39\n    Image ID:       k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 25 Oct 2022 03:18:27 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-7mrj2 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-7mrj2:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-6807/agnhost-primary-gc895 to lab1-k8s-node-3\n  Normal  Pulled     2s    kubelet            Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.39\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Oct 25 03:18:28.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6807 describe rc agnhost-primary'
Oct 25 03:18:28.426: INFO: stderr: ""
Oct 25 03:18:28.426: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-6807\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        k8s.gcr.io/e2e-test-images/agnhost:2.39\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-gc895\n"
Oct 25 03:18:28.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6807 describe service agnhost-primary'
Oct 25 03:18:28.508: INFO: stderr: ""
Oct 25 03:18:28.508: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-6807\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.233.30.171\nIPs:               10.233.30.171\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.233.74.119:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct 25 03:18:28.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6807 describe node lab1-k8s-master-1'
Oct 25 03:18:28.652: INFO: stderr: ""
Oct 25 03:18:28.652: INFO: stdout: "Name:               lab1-k8s-master-1\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=v1-c2-m8-d80\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=se-sto\n                    failure-domain.beta.kubernetes.io/zone=sto1\n                    k8s.elx.cloud/control-plane-node-replaced=true\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=lab1-k8s-master-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\n                    node.kubernetes.io/instance-type=v1-c2-m8-d80\n                    topology.cinder.csi.openstack.org/zone=sto1\n                    topology.kubernetes.io/region=se-sto\n                    topology.kubernetes.io/zone=sto1\nAnnotations:        alpha.kubernetes.io/provided-node-ip: 10.128.0.176\n                    csi.volume.kubernetes.io/nodeid: {\"cinder.csi.openstack.org\":\"86c9877e-b800-4d39-b423-bcc2bbd1090c\"}\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:////var/run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.128.0.176/22\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.233.99.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 24 Oct 2022 10:51:35 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  lab1-k8s-master-1\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 25 Oct 2022 03:18:25 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 24 Oct 2022 13:37:53 +0000   Mon, 24 Oct 2022 13:37:53 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 25 Oct 2022 03:18:23 +0000   Mon, 24 Oct 2022 11:24:08 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 25 Oct 2022 03:18:23 +0000   Mon, 24 Oct 2022 11:24:08 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 25 Oct 2022 03:18:23 +0000   Mon, 24 Oct 2022 11:24:08 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 25 Oct 2022 03:18:23 +0000   Mon, 24 Oct 2022 13:25:02 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.128.0.176\n  ExternalIP:  217.61.247.126\n  Hostname:    lab1-k8s-master-1\nCapacity:\n  cpu:                2\n  ephemeral-storage:  40470732Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8148652Ki\n  pods:               110\nAllocatable:\n  cpu:                1550m\n  ephemeral-storage:  37297826550\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7259820Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 86c9877eb8004d39b423bcc2bbd1090c\n  System UUID:                86c9877e-b800-4d39-b423-bcc2bbd1090c\n  Boot ID:                    b5618a2e-158d-404f-9439-3bdcd914ec7e\n  Kernel Version:             5.4.0-113-generic\n  OS Image:                   Ubuntu 20.04.4 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.24.6\n  Kube-Proxy Version:         v1.24.6\nPodCIDR:                      10.233.64.0/24\nPodCIDRs:                     10.233.64.0/24\nProviderID:                   openstack:///86c9877e-b800-4d39-b423-bcc2bbd1090c\nNon-terminated Pods:          (10 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-p96g7                                          150m (9%)     2 (129%)    64M (0%)         500M (6%)      13h\n  kube-system                 csi-cinder-nodeplugin-rpg8q                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         13h\n  kube-system                 kube-apiserver-lab1-k8s-master-1                           250m (16%)    0 (0%)      0 (0%)           0 (0%)         13h\n  kube-system                 kube-controller-manager-lab1-k8s-master-1                  200m (12%)    0 (0%)      0 (0%)           0 (0%)         13h\n  kube-system                 kube-proxy-s6wnk                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         13h\n  kube-system                 kube-scheduler-lab1-k8s-master-1                           100m (6%)     0 (0%)      0 (0%)           0 (0%)         13h\n  kube-system                 metrics-server-54d48d8c7-mcnqp                             100m (6%)     100m (6%)   200Mi (2%)       200Mi (2%)     13h\n  kube-system                 nodelocaldns-lkpsg                                         100m (6%)     0 (0%)      70Mi (0%)        200Mi (2%)     13h\n  kube-system                 openstack-cloud-controller-manager-dv986                   200m (12%)    0 (0%)      0 (0%)           0 (0%)         16h\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-99ec253e1d934329-mshb5    0 (0%)        0 (0%)      0 (0%)           0 (0%)         98m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests        Limits\n  --------           --------        ------\n  cpu                1100m (70%)     2100m (135%)\n  memory             347115520 (4%)  919430400 (12%)\n  ephemeral-storage  0 (0%)          0 (0%)\n  hugepages-1Gi      0 (0%)          0 (0%)\n  hugepages-2Mi      0 (0%)          0 (0%)\nEvents:              <none>\n"
Oct 25 03:18:28.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3055319084 --namespace=kubectl-6807 describe namespace kubectl-6807'
Oct 25 03:18:28.735: INFO: stderr: ""
Oct 25 03:18:28.735: INFO: stdout: "Name:         kubectl-6807\nLabels:       e2e-framework=kubectl\n              e2e-run=00d69ad5-ea54-47cd-b701-0540ff718100\n              kubernetes.io/metadata.name=kubectl-6807\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Oct 25 03:18:28.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6807" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":356,"completed":356,"skipped":6612,"failed":0}
SSSSSOct 25 03:18:28.761: INFO: Running AfterSuite actions on all nodes
Oct 25 03:18:28.761: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func19.2
Oct 25 03:18:28.761: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Oct 25 03:18:28.761: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func8.2
Oct 25 03:18:28.761: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Oct 25 03:18:28.761: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Oct 25 03:18:28.761: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Oct 25 03:18:28.761: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
Oct 25 03:18:28.761: INFO: Running AfterSuite actions on node 1
Oct 25 03:18:28.761: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/sonobuoy/results/junit_01.xml
{"msg":"Test Suite completed","total":356,"completed":356,"skipped":6617,"failed":0}

Ran 356 of 6973 Specs in 5914.104 seconds
SUCCESS! -- 356 Passed | 0 Failed | 0 Pending | 6617 Skipped
PASS

Ginkgo ran 1 suite in 1h38m35.683146716s
Test Suite Passed
